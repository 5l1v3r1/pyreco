__FILENAME__ = canada
'''
Script to sort out the tags imported from ca.ckan.net to thedatahub.org and
got mangled in the process.
'''

import re
from optparse import OptionParser
import copy

import ckanclient
from status import Status

def sort_out_tags(source_ckan_uri,
                  dest_ckan_uri, dest_api_key,
                  ):
    ckan1 = ckanclient.CkanClient(base_location=source_ckan_uri)
    ckan2 = ckanclient.CkanClient(base_location=dest_ckan_uri,
                                  api_key=dest_api_key)

    # ensure group exists
    group = 'country-ca'
    assert group in set(ckan2.group_register_get())
    group_to_change = 'canadagov'

    # work out tag mappings
    tag_status = Status('tag mapping')
    tag_replace_map = {}
    source_tags = ckan1.tag_register_get()
    for tag in source_tags:
        mangled_tag = re.sub('[-._]', '', tag)
        replacement_tag = tag
        # Change underscores to hyphens
        replacement_tag = replacement_tag.replace('_', '-')
        # Remove trailing punctuation
        if replacement_tag[-1] in '_-.':
            replacement_tag = replacement_tag[:-1]
        if replacement_tag[0] in '_-.':
            replacement_tag = replacement_tag[1:]
        if mangled_tag == replacement_tag:
            tag_status.record('Unchanged', mangled_tag, do_print=False)
            continue
        if mangled_tag in tag_replace_map and tag_replace_map[mangled_tag] != replacement_tag:
            print 'Warning - can\'t differentiate %s : %s / %s' % \
                  (mangled_tag, tag_replace_map[mangled_tag], replacement_tag)
        tag_status.record('Mapping added', '%s:%s' % (mangled_tag, replacement_tag), do_print=False)
        tag_replace_map[mangled_tag] = replacement_tag
    example_map = tag_replace_map.items()[0]
    print tag_status

    # Custom mappings
    tag_replace_map['metaimportedfromcackannet'] = 'meta.imported-from-ca-ckan-net'

    # edit packages
    pkg_status = Status('Packages')
    pkgs = ckan2.group_entity_get(group)['packages']
    print 'Packages in the group: %i' % len(pkgs)
    for pkg_name in pkgs:
        pkg = ckan2.package_entity_get(pkg_name)
        original_pkg = copy.deepcopy(pkg)

        # Change tags
        edited_tags = [tag_replace_map.get(tag, tag) for tag in pkg['tags']]
        if 'canada' in edited_tags:
            edited_tags.remove('canada')

        if group_to_change in pkg['groups']:
            pkg['groups'].remove(group_to_change)
            edited_tags.append('canada-gov')

        if set(pkg['tags']) != set(edited_tags):
            pkg['tags'] = edited_tags
            print '%s: %r -> %r' % (pkg_name, sorted(original_pkg['tags']), sorted(edited_tags))

        if pkg == original_pkg:
            pkg_status.record('Unchanged', pkg_name)
            continue

        try:
            ckan2.package_entity_put(pkg)
        except ckanclient.CkanApiError, e:
            pkg_status.record('Error: %r' % e.args, pkg_name)
            continue
        
        pkg_status.record('Successfully changed', pkg_name)

    print pkg_status

usage = '''%prog [OPTIONS] <source_ckan_api_uri> <destination_ckan_api_uri>
Recopy tags that got mangled in Canadian copy.'''
parser = OptionParser(usage=usage)
parser.add_option("-k", "--destination-ckan-api-key", dest="destination_ckan_api_key",
                  help="Destination CKAN's API key", metavar="API-KEY")

(options, args) = parser.parse_args()

assert len(args) == 2, 'The source and destination CKAN API URIs are the only two arguments. Found: %r' % args
source_ckan_uri, destination_ckan_uri = args
print 'Key: ', options.destination_ckan_api_key

sort_out_tags(source_ckan_uri,
              destination_ckan_uri,
              options.destination_ckan_api_key,
)

########NEW FILE########
__FILENAME__ = ckan-correct-tags
# Utility script to strip commas out of tag names
# (in there because of bugs in form script that did not strip commas):w

import os
# here_dir = os.path.dirname(os.path.abspath(__file__))
# conf_dir = os.path.dirname(os.path.dirname(here_dir))
conf_dir = os.path.abspath('./')
print conf_dir
conf_file = os.path.join(conf_dir, 'development.ini')
# conf_file = os.path.join(conf_dir, 'ckan.net.ini')

from paste.deploy import loadapp, CONFIG
import paste.deploy

conf = paste.deploy.appconfig('config:' + conf_file)
CONFIG.push_process_config({'app_conf': conf.local_conf,
                            'global_conf': conf.global_conf}) 

import ckan.models

def correct():
    print 'Beginning processing'
    for tag in ckan.models.Tag.select():
        print 'Processing tag: ', tag.name
        if tag.name.endswith(','):
            print 'Tag with comma found'
            correct_name = tag.name[:-1]
            print 'Correct name: ', correct_name
            # is there a tag already out there with this name?
            existing = list(ckan.models.Tag.selectBy(name=correct_name))
            if len(existing) == 0: # no -- then just rename
                print 'Renaming'
                tag.name = correct_name
            else:
                print 'Replacing'
                replacement = existing[0]
                pkgtags = ckan.models.package.PackageTag.selectBy(tag=tag)
                for pkg2tag in pkgtags:
                    # replace or delete -- should  check whether already has the
                    # link ... but will not bother as assume no-one has ever done
                    # economics and economics, for same package
                    pkg2tag.tag == replacement
                tag.purge()

def test_setup():
    tag = ckan.models.Tag(name='blah2,')
    tag2 = ckan.models.Tag(name='russian,')
    pkg = ckan.models.Package.selectBy(name='annakarenina')
    ckan.models.PackageTag(tag=tag, package=pkg)
    ckan.models.PackageTag(tag=tag2, package=pkg)

# test_setup()
correct()

########NEW FILE########
__FILENAME__ = ckan-edit-tags
import os

import loadconfig
path = os.path.abspath('development.ini')
loadconfig.load_config(path)

import ckan.model as model

ukgov = model.Group.by_name(u'ukgov')
if not ukgov:
    model.Session.add(model.Group(name=u'ukgov'))
    model.repo.commit_and_remove()

pkgs = model.Session.query(model.Package).all()
ukgov = model.Group.by_name(u'ukgov')
for pkg in pkgs:
    print 'Package: ', pkg.name
    
    # Add packages to group ukgov
    if pkg not in ukgov.packages:
        ukgov.packages.append(pkg)
        print 'Added to group'

    # Add extra 'import_source'
    if not pkg.extras.has_key('import_source'):
        pkg.extras['import_source'] = 'Manual 28, Oct 09'
        print 'Added source'

rev = model.repo.new_revision() 
rev.author = u'auto-loader'
rev.message = u'Add tag and group'

model.repo.commit_and_remove()

########NEW FILE########
__FILENAME__ = ckan-edit-tags2
import os

import loadconfig
path = os.path.abspath('development.ini')
loadconfig.load_config(path)

import ckan.model as model

for pkg in model.Session.query(model.Package):
    source = pkg.extras.get('import_source', u'')
    ns = pkg.extras.get('national_statistic', u'')
    remove_national_statistic = not source.startswith('ONS-') and ns == 'yes'
    print 'Package: name=%s national_statistic=%s source=%s remove_ns=%s' % (pkg.name, ns, source, remove_national_statistic)
    
    if remove_national_statistic:
        pkg.extras['national_statistic'] = u''

        rev = model.repo.new_revision() 
        rev.author = u'auto-loader'
        rev.message = u'Removed unconfirmed national_statistic designation'

        model.Session.commit()

model.Session.remove()

########NEW FILE########
__FILENAME__ = ckan-hmg-breakdown
import os

import loadconfig
path = os.path.abspath('development.ini')
loadconfig.load_config(path)

import ckan.model as model
from ckan.lib.dumper import SimpleDumper


q_packages = model.Session.query(model.Package)
print 'Total packages: %i' % q_packages.count()

active = model.State.ACTIVE
q_active = q_packages.filter_by(state=active)
print 'Active packages: %i' % q_active.count()

q_group = q_packages.join('groups').filter(model.Group.name==u'ukgov')
print 'Packages in group ukgov: %i' % q_group.count()

print_those_not_in_group = True
if print_those_not_in_group:
    in_group = [pkg.name for pkg in q_group]
    not_in_group = []

pkgs_by_source = {}
for pkg in q_packages:
    if pkg.extras.get('national_statistic', None) == 'yes':
        print pkg.extras.get('national_statistic'), pkg.extras.get('import_source', u'')
    if pkg.extras.has_key('import_source'):
        source = pkg.extras['import_source']
        if '-' in source:
            source = source[:source.find('-')]
    elif pkg.extras.has_key('co_id'):
        source = 'CO Spreadsheet Dec 2009'
    elif pkg.extras.has_key('update frequency'):
        source = 'DATA4NR Dec 2009'
    elif pkg.extras.get('external_reference', u'').startswith('DATA4NR'):
        source = 'DATA4NR Jan 2010'
    elif pkg.extras.get('external_reference', u'') == u'ONSHUB':
        source = 'ONS'
    else:
        source = 'manual'

    if not pkgs_by_source.has_key(source):
        pkgs_by_source[source] = []
    pkgs_by_source[source].append(pkg)

    if print_those_not_in_group:
        if pkg.name not in in_group:
            not_in_group.append(pkg.name)
if print_those_not_in_group:
    if not_in_group:
        print ' Not in the group: %s' % ', '.join(not_in_group)
    
for source, pkgs in pkgs_by_source.items():
    print 'Source: %s \t items: %i' % (source, len(pkgs))

##ons_pkgs_titles = []
##for pkg in pkgs_by_source['ONS']:
##    ons_pkgs_titles.append('%s (%s)' % (pkg.title, len(pkg.resources)))
##ons_pkgs_titles.sort()
##print 'ONS Packages:'
##for title in ons_pkgs_titles:
##    print title

########NEW FILE########
__FILENAME__ = ckan-hmg-update-licenses
import os

import loadconfig
path = os.path.abspath('development.ini')
loadconfig.load_config(path)

import ckan.model as model

non_compliant_crown = model.License.by_name(u'Non-OKD Compliant::Crown Copyright').id
compliant_crown = model.License.by_name(u'OKD Compliant::UK Crown Copyright with data.gov.uk rights').id
click_use = model.License.by_name(u'OKD Compliant::UK Click Use PSI').id
hesa = model.License.by_name(u'OKD Compliant::Higher Education Statistics Agency Copyright with data.gov.uk rights').id
assert non_compliant_crown
assert compliant_crown
assert click_use
assert hesa

q_packages = model.Session.query(model.Package)

changes = {}
def made_change(description, package_name):
    if not changes.has_key(description):
        changes[description] = []
    changes[description].append(package_name)

def new_revision():
    rev = model.repo.new_revision() 
    rev.author = 'license-updater'
    rev.message = u'Update of licenses to OKD compliant'
new_revision()

pkg_names = [pkg.name for pkg in q_packages.all()]
for i, pkg_name in enumerate(pkg_names):
    pkg = model.Package.by_name(pkg_name)
    assert pkg
    if pkg.author_email and 'hesa.ac.uk' in pkg.author_email:
        pkg.license = model.Session.query(model.License).get(hesa)
        made_change('HESA license', pkg.name)
    elif pkg.license.id == non_compliant_crown:
        pkg.license = model.Session.query(model.License).get(compliant_crown)
        made_change('Crown Copyright -> Crown Copyright OKD compliant', pkg.name)
    elif pkg.license.id == click_use:
        pkg.license = model.Session.query(model.License).get(compliant_crown)
        made_change('Click Use -> Crown Copyright OKD compliant', pkg.name)
    else:
        made_change('No change - left as license %s' % pkg.license, pkg.name)
    model.Session.flush()

    if i+1 % 100 == 0:
        model.repo.commit_and_remove()
        new_revision()

model.repo.commit_and_remove()

for description, packages in changes.items():
    print 'CHANGE: %s (%i)' % (description, len(packages))

########NEW FILE########
__FILENAME__ = ckan-rest-edit-tags
import sys
from optparse import OptionParser

import ckanclient

class TagEditor:
    def __init__(self, host, api_key):
        if not host.startswith('http://'):
            host = 'http://' + host
        host = host + '/api'
        self.ckan = ckanclient.CkanClient(base_location=host, api_key=api_key)
        
    def get_packages_by_tag_search(self, tagname):
        res = self.ckan.package_search('', {'tags':tagname, 'all_fields':1})
        status = self.ckan.last_status
        assert status == 200, status
        packages = res['results']
        return packages

    def get_package_names_by_tag(self, tagname):
        res = self.ckan.tag_entity_get(tagname)
        assert self.ckan.last_status == 200, self.ckan.last_status
        packages = res
        return packages

    def edit_tags(self, pkg_name, add_tags, remove_tags):
        pkg = self.ckan.package_entity_get(pkg_name)
        if self.ckan.last_status != 200:
            print 'Error! Package: %s Error reading package: %s' % (pkg_name, self.ckan.last_status)
            return self.ckan.last_status
        tags = set()
        for tag in pkg['tags']:
            tags.add(tag)
        tags_before = tags.copy()
        for tag in add_tags:
            tags.add(tag)
        for tag in remove_tags:
            tags.discard(tag)
        if tags == tags_before:
            print "PKG %s: no change" % (pkg_name)
            return
        print "PKG %s: %i->%i tags" % (pkg_name, len(tags_before), len(tags))
        self.ckan.package_entity_put({'name':pkg_name,
                                      'tags':list(tags)})
        if self.ckan.last_status != 200:
            print 'Error! Package: %s Error writing package: %s' % (pkg_name, self.ckan.last_status)
            return self.ckan.last_status
        return self.ckan.last_status 
        

if __name__ == "__main__":
    usage = "usage: %prog [options] ckan-host"
    parser = OptionParser(usage=usage)
    parser.add_option("-k", "--apikey", dest="apikey", 
                      help="API key")

    (options, args) = parser.parse_args()

    if not args:
        parser.print_help()
        sys.exit(0)
        
    ckan_host = args[0]
    te = TagEditor(ckan_host, options.apikey)

    pkg_names = te.get_package_names_by_tag('ckanupload.esw.200910')
    for pkg_name in pkg_names:
        te.edit_tags(pkg_name, ['lod', 'linkeddata'], ['linked-open-data'])

########NEW FILE########
__FILENAME__ = ckan_edit_local
'''Script for doing various edits to ckan data that is stored on a local
CKAN instance'''

import os
import sys
from optparse import OptionParser

from running_stats import StatsCount, StatsList
from revision_manager import RevisionManager

def ons_prefix():
    '''Remove "http://www.statistics.gov.uk/" from resource IDs derived from ONS'''
    from ckan import model
    prefix = 'http://www.statistics.gov.uk/'
    pkgs_changed = []
    for pkg in model.Session.query(model.Package):
        is_changed = False
        for resource in pkg.resources:
            is_changed = is_changed or prefix in resource.description
            if is_changed:
                resource.description = resource.description.replace(prefix, '')
        if is_changed:
            rev = model.repo.new_revision() 
            rev.author = u'auto-loader'
            rev.message = u'Removed domain from ONS IDs'

            model.Session.commit()

            pkgs_changed.append(pkg.name)
    
    model.Session.remove()
    print 'Removed ONS prefix from %i packages out of %i' % (len(pkgs_changed), model.Session.query(model.Package).count())
            
def dump_data4nr_names(csv_filepath):
    '''Dumps a list of the old and new names for packages in data4nr csv data'''
    from ckan.getdata.data4nr import Data4Nr
    import csv

    data4nr = Data4Nr()
    assert os.path.exists(csv_filepath)
    f_obj = open(csv_filepath, "r")
    reader = csv.reader(f_obj)
    index = 0
    reader.next()
    for row_list in reader:
        data4nr_dict = data4nr._parse_line(row_list, index)
        if data4nr_dict:
            old_name, new_name = data4nr._create_name(data4nr_dict)
            print '%s %s' % (old_name, new_name)
        index += 1

def munge_old_data4nr_names(old_names_filepath):
    '''Matches list of old Data4Nr names to new names
    Format of a line of old_names file is like:
       [0] => accident_and_emergency_statistics_2000-2001_to_2008-2009
    This routine tries to match this old_name to a name in the current database
    '''
    from ckan import model
    assert os.path.exists(old_names_filepath)
    f_obj = open(old_names_filepath, 'r')
    for line in f_obj:
        ignore, old_name = line.split('=>')
        old_name = old_name.strip()
        bit_of_name = old_name
        new_name = None
        while bit_of_name:
            if model.Package.by_name(unicode(bit_of_name)):
                new_name = bit_of_name
                break
            bit_of_name = bit_of_name[:-1]
        if new_name:
            print '%s %s' % (old_name, new_name)
        else:
            print '%s UNKNOWN' % old_name
    f_obj.close()
            
def canada_extras():
    keys_changed = StatsCount()
    unmapped_keys = StatsList()
    licenses_changed = StatsCount()
    unmapped_licenses = StatsList()
    licenses = StatsList()
    key_mapping = {
        'Level of Government':'level_of_government',
        }
    license_mapping = {
        # CS: bad_spelling ignore
        'http://geogratis.ca/geogratis/en/licence.jsp':'geogratis',
        'Crown Copyright':'canada-crown',
        }
    from ckan import model
    rev = RevisionManager('Standardize extra keys', 10)
    for pkg in model.Session.query(model.Package):
        for old_key, new_key in key_mapping.items():
            if pkg.extras.has_key(old_key):
                rev.before_change()
                pkg.extras[new_key] = pkg.extras[old_key]
                del pkg.extras[old_key]
                keys_changed.increment(old_key)
                rev.after_change()
        for license_key in ('License', 'License URL'):
            if pkg.extras.has_key(license_key):
                old_license = pkg.extras[license_key]
                if old_license in license_mapping:
                    rev.before_change()
                    pkg.license_id = unicode(license_mapping[old_license])
                    del pkg.extras[license_key]
                    licenses_changed.increment(old_license)
                    rev.after_change()
                else:
                    unmapped_licenses.add(old_license, pkg.name)
        licenses.add(pkg.license_id, pkg.name)
        for key in pkg.extras.keys():
            if key not in key_mapping.keys() and \
               key not in key_mapping.values():
                unmapped_keys.add(key, pkg.name)
    rev.finished()
    print 'Packages: %i' % model.Session.query(model.Package).count()
    print 'Changed keys:\n', keys_changed.report()
    print 'Unmapped keys:\n', unmapped_keys.report()
    print 'Changed licenses:\n', licenses_changed.report()
    print 'Unmapped licenses:\n', unmapped_licenses.report()
    print 'Licenses:\n', licenses.report()

if __name__ == '__main__':
    usage = '''usage: %prog [options] <command>
    commands:
        ons-prefix - Remove ONS prefix in resources
        dump_data4nr_names - Dump list of old/new package names for Data4Nr csv file
        munge_old_data4nr_names - Matches list of old Data4Nr names to new names
        canada_extras - Standardise keys of Canada extra fields
    ''' # NB Options are automatically listed
    parser = OptionParser(usage=usage)
    parser.add_option('-c', '--config', dest='config', help='Config filepath', default='development.ini')
    parser.add_option('-f', '--file', dest='filepath', help='Input filepath')

    (options, args) = parser.parse_args()
    if len(args) < 1:
        parser.print_help()
        sys.exit(0)
    command = args[0]

    if options.config:
        import loadconfig
        path = os.path.abspath(options.config)
        loadconfig.load_config(path)
            
    if command == 'ons-prefix':
        ons_prefix()
    elif command == 'dump_data4nr_names':
        dump_data4nr_names(options.filepath)
    elif command == 'munge_old_data4nr_names':
        munge_old_data4nr_names(options.filepath)
    elif command == 'canada_extras':
        canada_extras()
    else:
        print 'Command %r not found' % command
        print usage

########NEW FILE########
__FILENAME__ = ckan_spam
# purge revisions associated with a specific package name and after a certain
# revision number

# path to config file
cfg_path = 'INSERT YOUR PATH'
# name of pkg to examine
pkg_name = 'mis-uiowa'
# revision id to start at
# all revisions above this associated with pkg will be purged
start_at_id = 472

# holder for author blacklist
authors = {}

import os

import sqlobject

import loadconfig
path = os.path.abspath(cfg_path)
loadconfig.load_config(path)

import ckan.models as model

import ckan.commands.revision
def purge(revision):
    author = revision.author
    authors[author] = authors.get(author, 0) + 1
    cmd = ckan.commands.revision.PurgeRevision(
            revision=revision,
            leave_record=False)
    print 'Purging revision: %s' % revision.id
    cmd.execute()

def purge_packages_by_name():
    pkg = model.Package.byName(pkg_name)
    # for efficiency reasons best to have revisions in descending order
    sel = model.PackageRevision.select(
            sqlobject.AND(model.PackageRevision.q.baseID==pkg.id,
                model.PackageRevision.q.revisionID>=start_at_id),
            orderBy=-model.PackageRevision.q.revisionID,
            )
    print 'Total number of spam revisions:', sel.count()
    for item in sel:
        # testing
        # if item.revisionID > 700 and item.revisionID < 720:
        #     print item.revisionID
        # if item.revisionID < 1000:
        #    break
        purge(item.revision)

def purge_revisions_by_id(id_list):
    for id in id_list:
        rev = model.Revision.get(id)
        purge(rev)

# purge_revisions_by_id([514, 515, 516, 462, 469, 1867, 1866, 1833, 795])

print 'Blacklisted IPs:', authors.keys()
print 'Distribution of Spam by IP:', authors

########NEW FILE########
__FILENAME__ = copy-ckan-2-ckan
import ckanclient
from optparse import OptionParser
import re

'''
Script for copying packages from one CKAN instance to another using the API
for both.

Some of the commands used:
$ pg_dump -f dump_ckan/nederland.ckan.net.pg_dump -U okfn nederland
$ rsync --progress -z okfn@eu5.okfn.org:/home/okfn/dump_ckan/* /home/dread/db_backup/communities/
$ paster db clean && paster db load /home/dread/db_backup/communities/nederland.ckan.net.pg_dump
$ python bin/copy-ckan-2-ckan.py -k tester -g country-si -t "Slovenia" -s si.ckan.net http://127.0.0.1:5000/api http://127.0.0.1:5001/api
'''

def copy_packages(source_ckan_uri,
                  dest_ckan_uri, dest_api_key,
                  dest_group_name, dest_group_title,
                  site_name, filter,
                  ):
    ckan1 = ckanclient.CkanClient(base_location=source_ckan_uri)
    ckan2 = ckanclient.CkanClient(base_location=dest_ckan_uri,
                                  api_key=dest_api_key)

    # ensure pkg references will be the same type
    ckan1_api_version = ckan1.api_version_get()
    ckan2_api_version = ckan2.api_version_get()
    assert ckan1_api_version == ckan2_api_version

    # ensure group exists
    existing_groups = set(ckan2.group_register_get())
    def add_group_if_needed(group_name, group_title=None, fetch_title=False):
        if group_name not in existing_groups:
            if fetch_title:
                group_title = ckan1.group_entity_get(group_name)['title']
            group = {'name': group_name,
                     'title': group_title}
            ckan2.group_register_post(group)
            existing_groups.add(group_name)
            print 'Created group: %s' % group_name

    if dest_group_name:
        add_group_if_needed(dest_group_name, dest_group_title)

    existing_pkgs = ckan2.package_register_get()

    if site_name:
        import_tag = 'meta.imported-from.%s' % re.sub('[^a-zA-Z0-9-_.]', '', site_name)
        print 'Tagging with: %s' % import_tag
    else:
        import_tag = None
    
    # go through all packages
    package_list = ckan1.package_register_get()
    print 'Found %i packages to copy' % len(package_list)

    if filter:
        filter_re = re.compile(filter)
        package_list = [pkg for pkg in package_list \
                        if filter_re.match(pkg)]
        print 'Filtered down to %i packages' % len(package_list)
    
    for package_ref in package_list[:]:
        try:
            pkg = ckan1.package_entity_get(package_ref)
        except ckanclient.CkanApiNotAuthorizedError:
            print '!! Not authorized: %s' % package_ref
            package_list.remove(package_ref)
            continue
        print 'Got package: %s' % pkg['name']

        # put in groups
        for group_name in pkg['groups']:
            add_group_if_needed(group_name, fetch_title=True)
        if dest_group_name:
            # only works on CKAN 1.5.1 so add all at end anyway
            pkg['groups'].append(dest_group_name)

        del pkg['id']

        if import_tag:
            pkg['tags'].append(import_tag)

        # munge non-conformant tags
        pkg['tags'] = [munge_tag(tag) for tag in pkg['tags']]

        # do the copy
        if package_ref in existing_pkgs:
            existing_pkg = ckan2.package_entity_get(pkg['name'])
            pkg_returned = ckan2.package_entity_put(pkg)
            print '...updated'
        else:
            pkg_returned = ckan2.package_register_post(pkg)
            print '...created'
        groups_not_added_to = set(pkg['groups']) - set(pkg_returned['groups']) - set((dest_group_name or []))
        # packages don't get added to the group before when CKAN <= 1.5 so
        # we have to do this now
        for group_ref in groups_not_added_to:
            group = ckan2.group_entity_get(group_ref)
            group['packages'].append(pkg['name'])
            ckan2.group_entity_put(group)
            print '...and added to group %s' % group_ref

    if dest_group_name:
        group = ckan2.group_entity_get(dest_group_name)
        pkgs_to_add_to_group = list(set(package_list) - set(group['packages']))
        if pkgs_to_add_to_group:
            print 'Adding %i packages to group %s: %r' % (len(pkgs_to_add_to_group), dest_group_name, pkgs_to_add_to_group)
            group['packages'].extend(pkgs_to_add_to_group)
            ckan2.group_entity_put(group)

def _munge_to_length(string, min_length, max_length):
    '''Pad/truncates a string'''
    if len(string) < min_length:
        string += '_' * (min_length - len(string))
    if len(string) > max_length:
        string = string[:max_length]
    return string

MIN_TAG_LENGTH, MAX_TAG_LENGTH = (2, 100)

def munge_tag(tag):
    tag = tag.lower().strip()
    tag = re.sub(r'[^a-zA-Z0-9 ]', '', tag).replace(' ', '-')
    tag = _munge_to_length(tag, MIN_TAG_LENGTH, MAX_TAG_LENGTH)
    return tag

usage = '''%prog [OPTIONS] <source_ckan_api_uri> <destination_ckan_api_uri>
Copy datasets from ckan to another and put them in a group.'''
parser = OptionParser(usage=usage)
parser.add_option("-k", "--destination-ckan-api-key", dest="destination_ckan_api_key",
                  help="Destination CKAN's API key", metavar="API-KEY")
parser.add_option("-g", "--group-name", dest="group_name",
                  help="Destination CKAN group's name")
parser.add_option("-t", "--group-title", dest="group_title",
                  help="Destination CKAN group's title")
parser.add_option("-s", "--site-name", dest="site_name",
                  help="Name of source CKAN site - so source can be tagged")
parser.add_option("-f", "--filter", dest="filter",
                  help="Filter package names (regex format)")

(options, args) = parser.parse_args()

assert len(args) == 2, 'The source and destination CKAN API URIs are the only two arguments. Found: %r' % args
source_ckan_uri, destination_ckan_uri = args
print 'Key: ', options.destination_ckan_api_key

copy_packages(source_ckan_uri,
              destination_ckan_uri,
              options.destination_ckan_api_key,
              options.group_name, options.group_title,
              options.site_name, options.filter)

########NEW FILE########
__FILENAME__ = dump-ukgov
# Best to cut and paste this into a paster shell

import ckan.model as model
from ckan.lib.dumper import SimpleDumper

query = model.Session.query(model.Package)

active = model.State.ACTIVE
query = query.filter_by(state=active)

query = query.join('groups').filter(model.Group.name==u'ukgov')

filepath_base = 'hmg.dump'

SimpleDumper().dump(open(filepath_base+'.csv', 'w'), 'csv', query)
SimpleDumper().dump(open(filepath_base+'.json', 'w'), 'json', query)


########NEW FILE########
__FILENAME__ = dump_23_pkgs
import os

xl_filename = '28pkgs.xls'
import loadconfig
path = os.path.abspath('development.ini')
loadconfig.load_config(path)

import ckan.model as model
import ckan.lib.dumper as dumper

pkg_to_xl_dict = dumper.PackagesXlWriter.pkg_to_xl_dict

count = 0
xl_dicts = []
for pkg in model.Session.query(model.Package):
    if pkg.revision.author == 'frontend':
        count += 1
        print pkg.name
        xl_dict = pkg_to_xl_dict(pkg)
        xl_dicts.append(xl_dict)

print 'Found %i matching packages' % count

dumper_ = dumper.PackagesXlWriter(xl_dicts)
dumper_.add_col_titles(('notes', 'url', 'resource-0-url', 'resource-0-format', 'resource-0-description', 'author', 'author_email', 'state', 'version', 'tags', 'groups', 'license' ))
dumper_.save(open(xl_filename, 'wb'))
print 'Saved in %s' % xl_filename

########NEW FILE########
__FILENAME__ = fixes
# Various fixes to CKAN DB
# Directions for use:
# Start a paster shell and then import and use

import ckan.model as model

# 2010-01-16: Corrections to broken package_tags in ckan.net (from long ago it
# seems)
# also package resource (revision id not set during migration!)
def fix_package_tags():
    # all package_tag_revision objects have a revision
    # 5 package_tag objects have either no package_id or no tag_id (and also absent
    # in package_tag_revisoin)

    # copy over revision_id from package_tag_revision into package
    # delete package_tag where pkgid/tagid is absent
    count = 0
    for pkgtag in model.Session.query(model.PackageTag).filter_by(revision_id=None):
        comparer = lambda x,y: x.revision.timestamp > y.revision.timestamp
        revs = sorted(pkgtag.all_revisions, cmp=comparer)
        mostrecent = revs[0]
        pkgtag.revision_id = mostrecent.revision_id
        count += 1
    print('Updated %s PackageTags' % count)
    model.Session.commit()
    
    count = 0
    # every one w/o a tag_id is also w/o package_id
    for pkgtagrev in model.Session.query(model.PackageTagRevision).filter_by(package_id=None):
        pkgtagrev.package_id = pkgtagrev.continuity.package_id
        pkgtagrev.tag_id = pkgtagrev.continuity.tag_id
        count += 1
    print('Updated %s PackageTagRevisions' % count)
    model.Session.commit()

    count = 0
    for pkgtag in model.Session.query(model.PackageTag).filter_by(package_id=None):
        pkgtag.purge()
        count += 1
    print('Deleted %s PackageTags' % count)
    model.Session.commit()


########NEW FILE########
__FILENAME__ = loadconfig
import os

def load_config(path):
    # OLD: pylons 0.9.4 and before version ...
    # conf_file = os.path.abspath(path)
    # from paste.deploy import loadapp, CONFIG
    # import paste.deploy

    # conf = paste.deploy.appconfig('config:' + conf_file)
    # CONFIG.push_process_config({'app_conf': conf.local_conf,
    #   'global_conf': conf.global_conf}) 

    import paste.deploy
    conf = paste.deploy.appconfig('config:' + path)
    import ckan
    ckan.config.environment.load_environment(conf.global_conf,
            conf.local_conf)



########NEW FILE########
__FILENAME__ = ons-load
import os

data_path = os.path.expanduser('~/ckan-local/data/')

def load_month(month, year):
    assert month < 13
    assert year > 2000
    data_filepath = os.path.join(data_path, 'ons_hub_%s_%#02d.xml' % (year, month))
    try:
        cmd = 'paster db load-onshub %s' % (data_filepath)
        print cmd
        response = os.system(cmd)
        print '\n%s %r' % (data_filepath, response)
    except Exception, e:
        print '\nEXCEPTION %s %r' % (data_filepath, e.args)


load_month(1, 2010)
for year in (2009, 2008, 2007, 2006, 2005, 2004):
    for month in range(12):
        load_month(month+1, year)


########NEW FILE########
__FILENAME__ = revision_manager
class RevisionManager(object):
    '''Revision manager
    * Keep track of revisions and changes inside a loop.
    * Group a bunch of changes into one revision.
    '''
    def __init__(self, change_message, changes_per_commit=10):
        self.change_message = unicode(change_message)
        self.num_changes_since_commit = 0
        self.changes_per_commit = changes_per_commit
        from ckan import model
        self.Session = model.Session

    def _revision_changes(self):
        return self.Session.new or self.Session.dirty

    def before_change(self):
        '''Call this before a change to a revisioned object'''
        if self.num_changes_since_commit == 0:
            assert not self._revision_changes()
            from ckan import model
            self.rev = model.repo.new_revision() 
            self.rev.author = u'auto-edit'
            if self.change_message:
                self.rev.message = self.change_message
        self.num_changes_since_commit += 1

    def after_change(self, force_commit=False):
        '''Call this after a change to a revisioned object. Should be
        same number of after_change calls as before_change'''
        its_about_time = self.num_changes_since_commit >= self.changes_per_commit
        if its_about_time:
            assert self._revision_changes()
        if force_commit or its_about_time:
            from ckan import model
            model.Session.commit()
            self.num_changes_since_commit = 0
        
    def finished(self):
        '''Call this after all changes'''
        if self.num_changes_since_commit:
            self.after_change(force_commit=True)
        from ckan import model
        model.Session.remove()

########NEW FILE########
__FILENAME__ = running_stats
'''Tool for a script to keep track changes performed on a large number
of objects.

StatsCount - when you are counting incidences of a small set of outcomes
StatsList - when you also want to remember an ID associated with each incidence

Examples:

from running_stats import StatsCount
package_stats = StatsCount()
for package in packages:
    if package.enabled:
        package.delete()
        package_stats.increment('deleted')
    else:
        package_stats.increment('not deleted')    
print package_stats.report()
> deleted: 30
> not deleted: 70
    
from running_stats import StatsList
package_stats = StatsList()
for package in packages:
    if package.enabled:
        package.delete()
        package_stats.add('deleted', package.name)
    else:
        package_stats.add('not deleted' package.name)
print package_stats.report()
> deleted: 30 pollution-uk, flood-regions, river-quality, ...
> not deleted: 70 spending-bristol, ... 

'''

import copy

class StatsCount(dict):
    # {category:count}
    _init_value = 0
    report_value_limit = 150
    
    def _init_category(self, category):
        if not self.has_key(category):
            self[category] = copy.deepcopy(self._init_value)
        
    def increment(self, category):
        self._init_category(category)
        self[category] += 1

    def report_value(self, category):
        value = repr(self[category])
        if len(value) > self.report_value_limit:
            value = value[:self.report_value_limit] + '...'
        return value

    def report(self, indent=1):
        lines = []
        categories = self.keys()
        categories.sort()
        indent_str = '\t' * indent
        for category in categories:
            value = self.report_value(category)
            lines.append(indent_str + '%s: %s' % (category, value))
        if not categories:
            lines = [indent_str + 'None']
        return '\n'.join(lines)

class StatsList(StatsCount):
    # {category:count}
    _init_value = []

    def add(self, category, value):
        self._init_category(category)
        self[category].append(value)

    def report_value(self, category):
        value = self[category]
        value_str = '%i %r' % (len(value), value)
        if len(value_str) > self.report_value_limit:
            value_str = value_str[:self.report_value_limit] + '...'
        return value_str

########NEW FILE########
__FILENAME__ = status
from collections import defaultdict

class Status:
    '''When looping through objects and doing operations to them,
    this is a useful object to keep track of what happens and
    summarise the numbers at the end.'''
    def __init__(self, obj_type_str=None):
        self.obj_type_str = obj_type_str
        self.pkg_status = defaultdict(list) # reason: [pkgs]
        
    def record(self, status_category, pkg_name, do_print=True):
        self.pkg_status[status_category].append(pkg_name)
        if do_print:
            print '%s: %s' % (pkg_name, status_category)
        
    def __str__(self):
        status = '\nStatus'
        if self.obj_type_str:
            status += ' of: %s' % self.obj_type_str
        status += '\n'
        status += '\n'.join([ \
            '%s: %i (e.g. %s)' % (category, len(pkg_names), sorted(pkg_names)[0]) \
            for (category, pkg_names) in self.pkg_status.items()])
        status += '\nTotal: %i\n' % sum([len(pkg_names) for pkg_names in self.pkg_status.values()])
        return status
        

########NEW FILE########
__FILENAME__ = talisckan
import sys
from optparse import OptionParser

import ckanclient
import ckan.lib.talis as talis

class TalisCkan:
    def __init__(self, ckan_host, store, talisuser, talispassword):
        api_key = None
        
        # ckan connection
        if not ckan_host.startswith('http://'):
            ckan_host = 'http://' + ckan_host
        ckan_host = ckan_host + '/api'
        self.ckan = ckanclient.CkanClient(base_location=ckan_host,
                                          api_key=api_key)

        # talis connection
        talis.TalisLogin.init(store, talisuser, talispassword)
        self._talis = talis.Talis()
        
    def get_ckan_package_names(self):
        res = self.ckan.package_register_get()
        assert self.ckan.last_status == 200, self.ckan.last_status
        packages = res
        return packages

    def load_to_talis(self, pkg_name):
        print '=== Loading %s ===' % pkg_name
        res = self.ckan.package_entity_get(pkg_name)
        if self.ckan.last_status != 200:
            print 'Failed to read CKAN package %s: %s' % (pkg_name, self.ckan.last_status)
            return
        pkg_dict = res
        res = self._talis.post_pkg(pkg_dict)
        if res:
            print 'Failed to post package %s to Talis: %s' % (pkg_name, res)
            return
##        res = self._talis.get_pkg(pkg_name)
##        assert res, res
##        print 'Done!'

    def dump_talis(self, pkg_names):
        if pkg_names:
            for pkg_name in pkg_names:
                print self._talis.get_pkg(pkg_name)
        else:
            # TODO
            print self._talis.dump()

        
if __name__ == '__main__':
    usage = '''usage: %prog [options] <command>
    commands:
        dump_talis - show contents of packages in talis
        load_ckan_to_talis - 
    '''
    parser = OptionParser(usage=usage)
#    parser.add_option('-k', '--apikey', dest='apikey', help='API key')
    parser.add_option('-c', '--ckanhost', dest='ckanhost', help='CKAN host name', default='www.ckan.net')
    parser.add_option('-s', '--store', dest='store', help='Talis store name', default='ckan-dev1')
    parser.add_option('-u', '--talislogin', dest='talislogin', help='Talis login details: "username:password"', default='ckan')
#    parser.add_option('-u', '--talisusername', dest='talisuser', help='Talis user name', default='ckan')
    parser.add_option('-p', '--packages', dest='packages', help='Quoted list of packages', default='')
    parser.add_option('', '--startfrompackage', dest='startpackage', help='Package to start from', default='')

    (options, args) = parser.parse_args()
    if len(args) < 1:
        parser.print_help()
        sys.exit(0)
    command = args[0]

    if ':' in options.talislogin:
        talisuser, talispassword = options.talislogin.split(':')
    else:
        talisuser, talispassword = options.talislogin, ''

    tc = TalisCkan(options.ckanhost, options.store, talisuser, talispassword)

    pkg_names = None
    if options.startpackage:
        start_index = pkg_names.index(options.startpackage)
        assert start_index
        pkg_names = pkg_names[start_index:]
    if options.packages:
        pkgs = options.packages.replace(',', ' ')
        pkg_names = pkgs.split() if ' ' in pkgs else [pkgs]
            
    if command == 'load_ckan_to_talis':
        pkg_names = tc.get_ckan_package_names()
        start_index = 0
        for pkg_name in pkg_names:
            tc.load_to_talis(pkg_name)
    elif command == 'dump_talis':
        tc.dump_talis(pkg_names)

########NEW FILE########
__FILENAME__ = webstore_test
'''This is a test using the real setup with elasticsearch.

It requires you to run nginx on port 8088 with config as per
https://github.com/okfn/elastic-proxy/blob/master/elasticproxy plus,
obviously, elasticsearch on port 9200.
'''
import json
import paste.fixture
import paste.proxy
import urllib2

ckan_url = 'http://localhost:8088'
app = paste.proxy.Proxy(ckan_url)
testapp = paste.fixture.TestApp(app)

class TestWebstoreExternal:
    def test_01(self):
        out = testapp.get('/api/rest/dataset/annakarenina')
        dataset = json.loads(out.body)
        resource_id = dataset['resources'][0]['id']

        offset = '/api/data/%s' % resource_id
        res = testapp.get(offset, status=400)
        assert res.status == 400

        offset = '/api/data/%s/_search?q=a' % resource_id
        res = testapp.get(offset)
        assert res.status == 200
        out = json.loads(res.body)
        assert out['hits']['total'] == 0

        data = {
            "user": "hamlet",
            "post_date": "2009-11-15T13:12:00",
            "message": "Trying out elasticsearch, so far so good?"
            }
        data = json.dumps(data)
        offset = '/api/data/%s' % resource_id
        testapp.put(offset + '/1', data)
        out = testapp.get(offset + '/1')
        outdata = json.loads(out.body)
        assert outdata['_source']['user'] == 'hamlet', outdata

        offset = '/api/data/%s/_search?q=hamlet' % resource_id
        res = testapp.get(offset)
        assert res.status == 200
        out = json.loads(res.body)
        assert out['hits']['total'] == 1, out

        # TODO: test delete ...
#        offset = '/api/data/%s' % resource_id
#        testapp.delete(offset + '/1')
#
#        offset = '/api/data/%s/_search?q=hamlet' % resource_id
#        res = testapp.get(offset)
#        assert res.status == 200
#        out = json.loads(res.body)
#        assert out['hits']['total'] == 0, out


########NEW FILE########
__FILENAME__ = ckan_nose_plugin
from nose.plugins import Plugin
from inspect import isclass
import hashlib
import os
import sys
import re
import pkg_resources
from paste.deploy import loadapp
from pylons import config
import unittest
import time

class CkanNose(Plugin):
    settings = None

    def startContext(self, ctx):
        # import needs to be here or setup happens too early
        import ckan.model as model

        if 'new_tests' in repr(ctx):
            # We don't want to do the stuff below for new-style tests.
            if not CkanNose.settings.reset_database:
                model.repo.tables_created_and_initialised = True
            return

        if isclass(ctx):
            if hasattr(ctx, "no_db") and ctx.no_db:
                return
            if (not CkanNose.settings.reset_database
                    and not CkanNose.settings.ckan_migration):
                model.Session.close_all()
                model.repo.tables_created_and_initialised = True
                model.repo.rebuild_db()
                self.is_first_test = False
            elif self.is_first_test or CkanNose.settings.ckan_migration:
                model.Session.close_all()
                model.repo.clean_db()
                self.is_first_test = False
                if CkanNose.settings.ckan_migration:
                    model.Session.close_all()
                    model.repo.upgrade_db()

            ## This is to make sure the configuration is run again.
            ## Plugins use configure to make their own tables and they
            ## may need to be recreated to make tests work.
            from ckan.plugins import PluginImplementations
            from ckan.plugins.interfaces import IConfigurable
            for plugin in PluginImplementations(IConfigurable):
                plugin.configure(config)

            # init_db is run at the start of every class because
            # when you use an in-memory sqlite db, it appears that
            # the db is destroyed after every test when you Session.Remove().
            model.repo.init_db()

    def options(self, parser, env):
        parser.add_option(
            '--ckan',
            action='store_true',
            dest='is_ckan',
            help='Always set this when testing CKAN.')
        parser.add_option(
            '--ckan-migration',
            action='store_true',
            dest='ckan_migration',
            help='set this when wanting to test migrations')
        parser.add_option(
            '--docstrings',
            action='store_true',
            dest='docstrings',
            help='set this to display test docstrings instead of module names')
        parser.add_option(
            '--segments',
            dest='segments',
            help='A string containing a hex digits that represent which of'
                 'the 16 test segments to run. i.e 15af will run segments 1,5,a,f')
        parser.add_option(
            '--reset-db',
            action='store_true',
            dest='reset_database',
            help='drop database and reinitialize before tests are run')

    def wantClass(self, cls):
        name = cls.__name__

        wanted = (not cls.__name__.startswith('_')
                  and (issubclass(cls, unittest.TestCase)
                       or re.search('(?:^|[\b_\./-])[Tt]est', name)
                      ))
        
        if self.segments and str(hashlib.md5(name).hexdigest())[0] not in self.segments:
            return False

        return wanted

    def finalize(self, report):
        if self.segments:
            print 'Segments: %s' % self.segments

    def configure(self, settings, config):
        CkanNose.settings = settings
        if settings.is_ckan:
            self.enabled = True
            self.is_first_test = True
        self.segments = settings.segments

    def describeTest(self, test):
        if not CkanNose.settings.docstrings:
            # display module name instead of docstring
            return False

    def startTest(self, test):
        """
        startTest: start timing.
        """
##        self._started = time.time()

    def stopTest(self, test):
        """
        stopTest: stop timing, canonicalize the test name, and save
        the run time.
        """
##        runtime = time.time() - self._started
##
##        # CTB: HACK!
##        f = open('times.txt', 'a')
##
##        testname = str(test)
##        #if ' ' in testname:
##        #    testname = testname.split(' ')[1]
##
##        f.write('%s,%s\n' % (testname, str(runtime)))
##
##        f.close()

########NEW FILE########
__FILENAME__ = common
# This file contains commonly used parts of external libraries. The idea is
# to help in removing helpers from being used as a dependency by many files
# but at the same time making it easy to change for example the json lib
# used.
#
# NOTE:  This file is specificaly created for
# from ckan.common import x, y, z to be allowed


from pylons.i18n import _, ungettext
from pylons import g, c, request, session, response
import simplejson as json

try:
    from collections import OrderedDict  # from python 2.7
except ImportError:
    from sqlalchemy.util import OrderedDict

########NEW FILE########
__FILENAME__ = environment
# -*- coding: utf-8 -*-
"""Pylons environment configuration"""
import os
import logging
import warnings
from urlparse import urlparse

import pylons
from paste.deploy.converters import asbool
import sqlalchemy
from pylons import config
from genshi.template import TemplateLoader
from genshi.filters.i18n import Translator

import ckan.config.routing as routing
import ckan.model as model
import ckan.plugins as p
import ckan.lib.helpers as h
import ckan.lib.app_globals as app_globals
import ckan.lib.render as render
import ckan.lib.search as search
import ckan.logic as logic
import ckan.new_authz as new_authz
import ckan.lib.jinja_extensions as jinja_extensions

from ckan.common import _, ungettext

log = logging.getLogger(__name__)


# Suppress benign warning 'Unbuilt egg for setuptools'
warnings.simplefilter('ignore', UserWarning)


class _Helpers(object):
    ''' Helper object giving access to template helpers stopping
    missing functions from causing template exceptions. Useful if
    templates have helper functions provided by extensions that have
    not been enabled. '''
    def __init__(self, helpers):
        self.helpers = helpers
        self._setup()

    def _setup(self):
        helpers = self.helpers
        functions = {}
        allowed = helpers.__allowed_functions__[:]
        # list of functions due to be deprecated
        self.deprecated = []

        for helper in dir(helpers):
            if helper not in allowed:
                self.deprecated.append(helper)
                continue
            functions[helper] = getattr(helpers, helper)
            if helper in allowed:
                allowed.remove(helper)
        self.functions = functions

        if allowed:
            raise Exception('Template helper function(s) `%s` not defined'
                            % ', '.join(allowed))

        # extend helper functions with ones supplied by plugins
        extra_helpers = []
        for plugin in p.PluginImplementations(p.ITemplateHelpers):
            helpers = plugin.get_helpers()
            for helper in helpers:
                if helper in extra_helpers:
                    raise Exception('overwritting extra helper %s' % helper)
                extra_helpers.append(helper)
                functions[helper] = helpers[helper]
        # logging
        self.log = logging.getLogger('ckan.helpers')

    @classmethod
    def null_function(cls, *args, **kw):
        ''' This function is returned if no helper is found. The idea is
        to try to allow templates to be rendered even if helpers are
        missing.  Returning the empty string seems to work well.'''
        return ''

    def __getattr__(self, name):
        ''' return the function/object requested '''
        if name in self.functions:
            if name in self.deprecated:
                msg = 'Template helper function `%s` is deprecated' % name
                self.log.warn(msg)
            return self.functions[name]
        else:
            if name in self.deprecated:
                msg = ('Template helper function `{0}` is not available '
                       'because it has been deprecated.'.format(name))
                self.log.critical(msg)
            else:
                msg = 'Helper function `%s` could not be found\n ' \
                      '(are you missing an extension?)' % name
                self.log.critical(msg)
            return self.null_function


def load_environment(global_conf, app_conf):
    """Configure the Pylons environment via the ``pylons.config``
    object.  This code should only need to be run once.
    """

    ######  Pylons monkey-patch
    # this must be run at a time when the env is semi-setup, thus inlined here.
    # Required by the deliverance plugin and iATI
    from pylons.wsgiapp import PylonsApp
    import pkg_resources
    find_controller_generic = PylonsApp.find_controller

    # This is from pylons 1.0 source, will monkey-patch into 0.9.7
    def find_controller(self, controller):
        if controller in self.controller_classes:
            return self.controller_classes[controller]
        # Check to see if its a dotted name
        if '.' in controller or ':' in controller:
            mycontroller = pkg_resources \
                .EntryPoint \
                .parse('x=%s' % controller).load(False)
            self.controller_classes[controller] = mycontroller
            return mycontroller
        return find_controller_generic(self, controller)
    PylonsApp.find_controller = find_controller
    ###### END evil monkey-patch

    os.environ['CKAN_CONFIG'] = global_conf['__file__']

    # Pylons paths
    root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    paths = dict(root=root,
                 controllers=os.path.join(root, 'controllers'),
                 static_files=os.path.join(root, 'public'),
                 templates=[])

    # Initialize config with the basic options
    config.init_app(global_conf, app_conf, package='ckan', paths=paths)

    #################################################################
    #                                                               #
    #                   HORRIBLE GENSHI HACK                        #
    #                                                               #
    #################################################################
    #                                                               #
    # Genshi does strange things to get stuff out of the template   #
    # variables.  This stops it from handling properties in the     #
    # correct way as it returns the property rather than the actual #
    # value of the property.                                        #
    #                                                               #
    # By overriding lookup_attr() in the LookupBase class we are    #
    # able to get the required behaviour.  Using @property allows   #
    # us to move functionality out of templates whilst maintaining  #
    # backwards compatability.                                      #
    #                                                               #
    #################################################################

    '''
    This code is based on Genshi code

    Copyright © 2006-2012 Edgewall Software
    All rights reserved.

    Redistribution and use in source and binary forms, with or
    without modification, are permitted provided that the following
    conditions are met:

        Redistributions of source code must retain the above copyright
        notice, this list of conditions and the following disclaimer.

        Redistributions in binary form must reproduce the above
        copyright notice, this list of conditions and the following
        disclaimer in the documentation and/or other materials provided
        with the distribution.

        The name of the author may not be used to endorse or promote
        products derived from this software without specific prior
        written permission.

    THIS SOFTWARE IS PROVIDED BY THE AUTHOR "AS IS" AND ANY EXPRESS OR
    IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
    WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
    ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
    DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
    DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
    GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
    INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
    IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
    OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
    IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
    '''
    from genshi.template.eval import LookupBase

    @classmethod
    def genshi_lookup_attr(cls, obj, key):
        __traceback_hide__ = True
        try:
            val = getattr(obj, key)
        except AttributeError:
            if hasattr(obj.__class__, key):
                raise
            else:
                try:
                    val = obj[key]
                except (KeyError, TypeError):
                    val = cls.undefined(key, owner=obj)
        if isinstance(val, property):
            val = val.fget()
        return val

    setattr(LookupBase, 'lookup_attr', genshi_lookup_attr)
    del genshi_lookup_attr
    del LookupBase

    #################################################################
    #                                                               #
    #                       END OF GENSHI HACK                      #
    #                                                               #
    #################################################################

    # Setup the SQLAlchemy database engine
    # Suppress a couple of sqlalchemy warnings
    msgs = ['^Unicode type received non-unicode bind param value',
            "^Did not recognize type 'BIGINT' of column 'size'",
            "^Did not recognize type 'tsvector' of column 'search_vector'"
            ]
    for msg in msgs:
        warnings.filterwarnings('ignore', msg, sqlalchemy.exc.SAWarning)

    # load all CKAN plugins
    p.load_all(config)


def update_config():
    ''' This code needs to be run when the config is changed to take those
    changes into account. '''

    for plugin in p.PluginImplementations(p.IConfigurer):
        # must do update in place as this does not work:
        # config = plugin.update_config(config)
        plugin.update_config(config)

    root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    # This is set up before globals are initialized
    site_id = os.environ.get('CKAN_SITE_ID')
    if site_id:
        config['ckan.site_id'] = site_id

    site_url = config.get('ckan.site_url', '')
    ckan_host = config['ckan.host'] = urlparse(site_url).netloc
    if config.get('ckan.site_id') is None:
        if ':' in ckan_host:
            ckan_host, port = ckan_host.split(':')
        assert ckan_host, 'You need to configure ckan.site_url or ' \
                          'ckan.site_id for SOLR search-index rebuild to work.'
        config['ckan.site_id'] = ckan_host

    # ensure that a favicon has been set
    favicon = config.get('ckan.favicon', '/images/icons/ckan.ico')
    config['ckan.favicon'] = favicon

    # Init SOLR settings and check if the schema is compatible
    #from ckan.lib.search import SolrSettings, check_solr_schema_version

    # lib.search is imported here as we need the config enabled and parsed
    search.SolrSettings.init(config.get('solr_url'),
                             config.get('solr_user'),
                             config.get('solr_password'))
    search.check_solr_schema_version()

    routes_map = routing.make_map()
    config['routes.map'] = routes_map
    # The RoutesMiddleware needs its mapper updating if it exists
    if 'routes.middleware' in config:
        config['routes.middleware'].mapper = routes_map
    config['routes.named_routes'] = routing.named_routes
    config['pylons.app_globals'] = app_globals.app_globals
    # initialise the globals
    config['pylons.app_globals']._init()

    # add helper functions
    helpers = _Helpers(h)
    config['pylons.h'] = helpers

    ## redo template setup to use genshi.search_path
    ## (so remove std template setup)
    legacy_templates_path = os.path.join(root, 'templates_legacy')
    jinja2_templates_path = os.path.join(root, 'templates')
    if asbool(config.get('ckan.legacy_templates', 'no')):
        # We want the new template path for extra snippets like the
        # dataviewer and also for some testing stuff
        template_paths = [legacy_templates_path, jinja2_templates_path]
    else:
        template_paths = [jinja2_templates_path, legacy_templates_path]

    extra_template_paths = config.get('extra_template_paths', '')
    if extra_template_paths:
        # must be first for them to override defaults
        template_paths = extra_template_paths.split(',') + template_paths
    config['pylons.app_globals'].template_paths = template_paths

    # Translator (i18n)
    translator = Translator(pylons.translator)

    def template_loaded(template):
        translator.setup(template)

    # Markdown ignores the logger config, so to get rid of excessive
    # markdown debug messages in the log, set it to the level of the
    # root logger.
    logging.getLogger("MARKDOWN").setLevel(logging.getLogger().level)

    # Create the Genshi TemplateLoader
    config['pylons.app_globals'].genshi_loader = TemplateLoader(
        template_paths, auto_reload=True, callback=template_loaded)

    # Create Jinja2 environment
    env = jinja_extensions.Environment(
        loader=jinja_extensions.CkanFileSystemLoader(template_paths),
        autoescape=True,
        extensions=['jinja2.ext.do', 'jinja2.ext.with_',
                    jinja_extensions.SnippetExtension,
                    jinja_extensions.CkanExtend,
                    jinja_extensions.CkanInternationalizationExtension,
                    jinja_extensions.LinkForExtension,
                    jinja_extensions.ResourceExtension,
                    jinja_extensions.UrlForStaticExtension,
                    jinja_extensions.UrlForExtension]
    )
    env.install_gettext_callables(_, ungettext, newstyle=True)
    # custom filters
    env.filters['empty_and_escape'] = jinja_extensions.empty_and_escape
    env.filters['truncate'] = jinja_extensions.truncate
    config['pylons.app_globals'].jinja_env = env

    # CONFIGURATION OPTIONS HERE (note: all config options will override
    # any Pylons config options)

    ckan_db = os.environ.get('CKAN_DB')
    if ckan_db:
        config['sqlalchemy.url'] = ckan_db

    # for postgresql we want to enforce utf-8
    sqlalchemy_url = config.get('sqlalchemy.url', '')
    if sqlalchemy_url.startswith('postgresql://'):
        extras = {'client_encoding': 'utf8'}
    else:
        extras = {}

    engine = sqlalchemy.engine_from_config(config, 'sqlalchemy.', **extras)

    if not model.meta.engine:
        model.init_model(engine)

    for plugin in p.PluginImplementations(p.IConfigurable):
        plugin.configure(config)

    # reset the template cache - we do this here so that when we load the
    # environment it is clean
    render.reset_template_info_cache()

    # clear other caches
    logic.clear_actions_cache()
    new_authz.clear_auth_functions_cache()

    # Here we create the site user if they are not already in the database
    try:
        logic.get_action('get_site_user')({'ignore_auth': True}, None)
    except (sqlalchemy.exc.ProgrammingError, sqlalchemy.exc.OperationalError):
        # (ProgrammingError for Postgres, OperationalError for SQLite)
        # The database is not initialised.  This is a bit dirty.  This occurs
        # when running tests.
        pass
    except sqlalchemy.exc.InternalError:
        # The database is not initialised.  Travis hits this
        pass
    # if an extension or our code does not finish
    # transaction properly db cli commands can fail
    model.Session.remove()

########NEW FILE########
__FILENAME__ = install
import re

from pylons.util import PylonsInstaller

import ckan


class CKANInstaller(PylonsInstaller):

    def config_content(self, command, vars):
        ckan_version = ckan.__version__
        ckan_base_version = re.sub('[^0-9\.]', '', ckan_version)
        if ckan_base_version == ckan_version:
            ckan_doc_version = 'ckan-{0}'.format(ckan_version)
        else:
            ckan_doc_version = 'latest'

        vars.setdefault('doc_version', ckan_doc_version)

        return super(CKANInstaller, self).config_content(command, vars)

########NEW FILE########
__FILENAME__ = middleware
"""Pylons middleware initialization"""
import urllib
import urllib2
import logging
import json
import hashlib
import os

import sqlalchemy as sa
from beaker.middleware import CacheMiddleware, SessionMiddleware
from paste.cascade import Cascade
from paste.registry import RegistryManager
from paste.urlparser import StaticURLParser
from paste.deploy.converters import asbool
from pylons import config
from pylons.middleware import ErrorHandler, StatusCodeRedirect
from pylons.wsgiapp import PylonsApp
from routes.middleware import RoutesMiddleware
from repoze.who.config import WhoConfig
from repoze.who.middleware import PluggableAuthenticationMiddleware
from repoze.who.plugins.auth_tkt import make_plugin as auth_tkt_make_plugin
from fanstatic import Fanstatic

from ckan.plugins import PluginImplementations
from ckan.plugins.interfaces import IMiddleware
from ckan.lib.i18n import get_locales_from_config
import ckan.lib.uploader as uploader

from ckan.config.environment import load_environment
import ckan.lib.app_globals as app_globals


def make_app(conf, full_stack=True, static_files=True, **app_conf):
    """Create a Pylons WSGI application and return it

    ``conf``
        The inherited configuration for this application. Normally from
        the [DEFAULT] section of the Paste ini file.

    ``full_stack``
        Whether this application provides a full WSGI stack (by default,
        meaning it handles its own exceptions and errors). Disable
        full_stack when this application is "managed" by another WSGI
        middleware.

    ``static_files``
        Whether this application serves its own static files; disable
        when another web server is responsible for serving them.

    ``app_conf``
        The application's local configuration. Normally specified in
        the [app:<name>] section of the Paste ini file (where <name>
        defaults to main).

    """
    # Configure the Pylons environment
    load_environment(conf, app_conf)

    # The Pylons WSGI app
    app = PylonsApp()
    # set pylons globals
    app_globals.reset()

    for plugin in PluginImplementations(IMiddleware):
        app = plugin.make_middleware(app, config)

    # Routing/Session/Cache Middleware
    app = RoutesMiddleware(app, config['routes.map'])
    # we want to be able to retrieve the routes middleware to be able to update
    # the mapper.  We store it in the pylons config to allow this.
    config['routes.middleware'] = app
    app = SessionMiddleware(app, config)
    app = CacheMiddleware(app, config)

    # CUSTOM MIDDLEWARE HERE (filtered by error handling middlewares)
    #app = QueueLogMiddleware(app)

    # Fanstatic
    if asbool(config.get('debug', False)):
        fanstatic_config = {
            'versioning': True,
            'recompute_hashes': True,
            'minified': False,
            'bottom': True,
            'bundle': False,
        }
    else:
        fanstatic_config = {
            'versioning': True,
            'recompute_hashes': False,
            'minified': True,
            'bottom': True,
            'bundle': True,
        }
    app = Fanstatic(app, **fanstatic_config)

    if asbool(full_stack):
        # Handle Python exceptions
        app = ErrorHandler(app, conf, **config['pylons.errorware'])

        # Display error documents for 401, 403, 404 status codes (and
        # 500 when debug is disabled)
        if asbool(config['debug']):
            app = StatusCodeRedirect(app, [400, 404])
        else:
            app = StatusCodeRedirect(app, [400, 404, 500])

    # Initialize repoze.who
    who_parser = WhoConfig(conf['here'])
    who_parser.parse(open(app_conf['who.config_file']))

    if asbool(config.get('openid_enabled', 'true')):
        from repoze.who.plugins.openid.identification import OpenIdIdentificationPlugin
        # Monkey patches for repoze.who.openid
        # Fixes #1659 - enable log-out when CKAN mounted at non-root URL
        from ckan.lib import repoze_patch
        OpenIdIdentificationPlugin.identify = repoze_patch.identify
        OpenIdIdentificationPlugin.redirect_to_logged_in = repoze_patch.redirect_to_logged_in
        OpenIdIdentificationPlugin._redirect_to_loginform = repoze_patch._redirect_to_loginform
        OpenIdIdentificationPlugin.challenge = repoze_patch.challenge

        who_parser.identifiers = [i for i in who_parser.identifiers if \
                not isinstance(i, OpenIdIdentificationPlugin)]
        who_parser.challengers = [i for i in who_parser.challengers if \
                not isinstance(i, OpenIdIdentificationPlugin)]

    app = PluggableAuthenticationMiddleware(app,
                who_parser.identifiers,
                who_parser.authenticators,
                who_parser.challengers,
                who_parser.mdproviders,
                who_parser.request_classifier,
                who_parser.challenge_decider,
                logging.getLogger('repoze.who'),
                logging.WARN,  # ignored
                who_parser.remote_user_key,
           )

    # Establish the Registry for this application
    app = RegistryManager(app)

    app = I18nMiddleware(app, config)

    if asbool(static_files):
        # Serve static files
        static_max_age = None if not asbool(config.get('ckan.cache_enabled')) \
            else int(config.get('ckan.static_max_age', 3600))

        static_app = StaticURLParser(config['pylons.paths']['static_files'],
                cache_max_age=static_max_age)
        static_parsers = [static_app, app]

        storage_directory = uploader.get_storage_path()
        if storage_directory:
            path = os.path.join(storage_directory, 'storage')
            try:
                os.makedirs(path)
            except OSError, e:
                ## errno 17 is file already exists
                if e.errno != 17:
                    raise

            storage_app = StaticURLParser(path,
                cache_max_age=static_max_age)
            static_parsers.insert(0, storage_app)

        # Configurable extra static file paths
        extra_static_parsers = []
        for public_path in config.get('extra_public_paths', '').split(','):
            if public_path.strip():
                extra_static_parsers.append(
                    StaticURLParser(public_path.strip(),
                        cache_max_age=static_max_age)
                )
        app = Cascade(extra_static_parsers + static_parsers)

    # Page cache
    if asbool(config.get('ckan.page_cache_enabled')):
        app = PageCacheMiddleware(app, config)

    # Tracking
    if asbool(config.get('ckan.tracking_enabled', 'false')):
        app = TrackingMiddleware(app, config)

    return app

def ckan_auth_tkt_make_app(**kw):
    if not len(kw.get('secret', '')) or kw.get('secret') == 'somesecret':
        kw['secret'] = config['beaker.session.secret']
    return auth_tkt_make_plugin(**kw)


class I18nMiddleware(object):
    """I18n Middleware selects the language based on the url
    eg /fr/home is French"""
    def __init__(self, app, config):
        self.app = app
        self.default_locale = config.get('ckan.locale_default', 'en')
        self.local_list = get_locales_from_config()

    def __call__(self, environ, start_response):
        # strip the language selector from the requested url
        # and set environ variables for the language selected
        # CKAN_LANG is the language code eg en, fr
        # CKAN_LANG_IS_DEFAULT is set to True or False
        # CKAN_CURRENT_URL is set to the current application url

        # We only update once for a request so we can keep
        # the language and original url which helps with 404 pages etc
        if 'CKAN_LANG' not in environ:
            path_parts = environ['PATH_INFO'].split('/')
            if len(path_parts) > 1 and path_parts[1] in self.local_list:
                environ['CKAN_LANG'] = path_parts[1]
                environ['CKAN_LANG_IS_DEFAULT'] = False
                # rewrite url
                if len(path_parts) > 2:
                    environ['PATH_INFO'] = '/'.join([''] + path_parts[2:])
                else:
                    environ['PATH_INFO'] = '/'
            else:
                environ['CKAN_LANG'] = self.default_locale
                environ['CKAN_LANG_IS_DEFAULT'] = True

            # Current application url
            path_info = environ['PATH_INFO']
            # sort out weird encodings
            path_info = '/'.join(urllib.quote(pce, '') for pce in path_info.split('/'))

            qs = environ.get('QUERY_STRING')

            if qs:
                # sort out weird encodings
                #qs = urllib.quote(qs, '')
                environ['CKAN_CURRENT_URL'] = '%s?%s' % (path_info, qs)
            else:
                environ['CKAN_CURRENT_URL'] = path_info

        return self.app(environ, start_response)


class PageCacheMiddleware(object):
    ''' A simple page cache that can store and serve pages. It uses
    Redis as storage. It caches pages that have a http status code of
    200, use the GET method. Only non-logged in users receive cached
    pages.
    Cachable pages are indicated by a environ CKAN_PAGE_CACHABLE
    variable.'''

    def __init__(self, app, config):
        self.app = app
        import redis    # only import if used
        self.redis = redis  # we need to reference this within the class
        self.redis_exception = redis.exceptions.ConnectionError
        self.redis_connection = None

    def __call__(self, environ, start_response):

        def _start_response(status, response_headers, exc_info=None):
            # This wrapper allows us to get the status and headers.
            environ['CKAN_PAGE_STATUS'] = status
            environ['CKAN_PAGE_HEADERS'] = response_headers
            return start_response(status, response_headers, exc_info)

        # Only use cache for GET requests
        # REMOTE_USER is used by some tests.
        if environ['REQUEST_METHOD'] != 'GET' or environ.get('REMOTE_USER'):
            return self.app(environ, start_response)

        # If there is a ckan cookie (or auth_tkt) we avoid the cache.
        # We want to allow other cookies like google analytics ones :(
        cookie_string = environ.get('HTTP_COOKIE')
        if cookie_string:
            for cookie in cookie_string.split(';'):
                if cookie.startswith('ckan') or cookie.startswith('auth_tkt'):
                    return self.app(environ, start_response)

        # Make our cache key
        key = 'page:%s?%s' % (environ['PATH_INFO'], environ['QUERY_STRING'])

        # Try to connect if we don't have a connection. Doing this here
        # allows the redis server to be unavailable at times.
        if self.redis_connection is None:
            try:
                self.redis_connection = self.redis.StrictRedis()
                self.redis_connection.flushdb()
            except self.redis_exception:
                # Connection may have failed at flush so clear it.
                self.redis_connection = None
                return self.app(environ, start_response)

        # If cached return cached result
        try:
            result = self.redis_connection.lrange(key, 0, 2)
        except self.redis_exception:
            # Connection failed so clear it and return the page as normal.
            self.redis_connection = None
            return self.app(environ, start_response)

        if result:
            headers = json.loads(result[1])
            # Convert headers from list to tuples.
            headers = [(str(key), str(value)) for key, value in headers]
            start_response(str(result[0]), headers)
            # Returning a huge string slows down the server. Therefore we
            # cut it up into more usable chunks.
            page = result[2]
            out = []
            total = len(page)
            position = 0
            size = 4096
            while position < total:
                out.append(page[position:position + size])
                position += size
            return out

        # Generate the response from our application.
        page = self.app(environ, _start_response)

        # Only cache http status 200 pages
        if not environ['CKAN_PAGE_STATUS'].startswith('200'):
            return page

        cachable = False
        if environ.get('CKAN_PAGE_CACHABLE'):
            cachable = True

        # Cache things if cachable.
        if cachable:
            # Make sure we consume any file handles etc.
            page_string = ''.join(list(page))
            # Use a pipe to add page in a transaction.
            pipe = self.redis_connection.pipeline()
            pipe.rpush(key, environ['CKAN_PAGE_STATUS'])
            pipe.rpush(key, json.dumps(environ['CKAN_PAGE_HEADERS']))
            pipe.rpush(key, page_string)
            pipe.execute()
        return page


class TrackingMiddleware(object):

    def __init__(self, app, config):
        self.app = app
        self.engine = sa.create_engine(config.get('sqlalchemy.url'))

    def __call__(self, environ, start_response):
        path = environ['PATH_INFO']
        method = environ.get('REQUEST_METHOD')
        if path == '/_tracking' and method == 'POST':
            # do the tracking
            # get the post data
            payload = environ['wsgi.input'].read()
            parts = payload.split('&')
            data = {}
            for part in parts:
                k, v = part.split('=')
                data[k] = urllib2.unquote(v).decode("utf8")
            start_response('200 OK', [('Content-Type', 'text/html')])
            # we want a unique anonomized key for each user so that we do
            # not count multiple clicks from the same user.
            key = ''.join([
                environ['HTTP_USER_AGENT'],
                environ['REMOTE_ADDR'],
                environ.get('HTTP_ACCEPT_LANGUAGE', ''),
                environ.get('HTTP_ACCEPT_ENCODING', ''),
            ])
            key = hashlib.md5(key).hexdigest()
            # store key/data here
            sql = '''INSERT INTO tracking_raw
                     (user_key, url, tracking_type)
                     VALUES (%s, %s, %s)'''
            self.engine.execute(sql, key, data.get('url'), data.get('type'))
            return []
        return self.app(environ, start_response)

########NEW FILE########
__FILENAME__ = routing
"""Routes configuration

The more specific and detailed routes should be defined first so they
may take precedent over the more generic routes. For more information
refer to the routes manual at http://routes.groovie.org/docs/

"""
import re

from pylons import config
from routes.mapper import SubMapper, Mapper as _Mapper

import ckan.plugins as p

named_routes = {}


class Mapper(_Mapper):
    ''' This Mapper allows us to intercept the connect calls used by routes
    so that we can collect named routes and later use them to create links
    via some helper functions like build_nav(). '''

    def connect(self, *args, **kw):
        '''Connect a new route, storing any named routes for later.

        This custom connect() method wraps the standard connect() method,
        and additionally saves any named routes that are connected in a dict
        ckan.routing.named_routes, which ends up being accessible via the
        Pylons config as config['routes.named_routes'].

        Also takes some additional params:

        :param ckan_icon: name of the icon to be associated with this route,
            e.g. 'group', 'time'
        :type ckan_icon: string
        :param highlight_actions: space-separated list of controller actions
            that should be treated as the same as this named route for menu
            highlighting purposes, e.g. 'index search'
        :type highlight_actions: string

        '''
        ckan_icon = kw.pop('ckan_icon', None)
        highlight_actions = kw.pop('highlight_actions', kw.get('action', ''))
        out = _Mapper.connect(self, *args, **kw)
        if len(args) == 1 or args[0].startswith('_redirect_'):
            return out
        # we have a named route
        needed = []
        matches = re.findall('\{([^:}]*)(\}|:)', args[1])
        for match in matches:
            needed.append(match[0])
        route_data = {
            'icon': ckan_icon,
            # needed lists the names of the parameters that need defining
            # for the route to be generated
            'needed': needed,
            'controller': kw.get('controller'),
            'action': kw.get('action', ''),
            'highlight_actions': highlight_actions
        }
        named_routes[args[0]] = route_data
        return out


def make_map():
    """Create, configure and return the routes Mapper"""
    # import controllers here rather than at root level because
    # pylons config is initialised by this point.

    # Helpers to reduce code clutter
    GET = dict(method=['GET'])
    PUT = dict(method=['PUT'])
    POST = dict(method=['POST'])
    DELETE = dict(method=['DELETE'])
    GET_POST = dict(method=['GET', 'POST'])
    PUT_POST = dict(method=['PUT', 'POST'])
    PUT_POST_DELETE = dict(method=['PUT', 'POST', 'DELETE'])
    OPTIONS = dict(method=['OPTIONS'])

    import ckan.lib.plugins as lib_plugins
    lib_plugins.reset_package_plugins()

    map = Mapper(directory=config['pylons.paths']['controllers'],
                 always_scan=config['debug'])
    map.minimization = False
    map.explicit = True

    # The ErrorController route (handles 404/500 error pages); it should
    # likely stay at the top, ensuring it can always be resolved.
    map.connect('/error/{action}', controller='error')
    map.connect('/error/{action}/{id}', controller='error')

    map.connect('*url', controller='home', action='cors_options',
                conditions=OPTIONS)

    # CUSTOM ROUTES HERE
    for plugin in p.PluginImplementations(p.IRoutes):
        map = plugin.before_map(map)

    map.connect('home', '/', controller='home', action='index')
    map.connect('about', '/about', controller='home', action='about')

    # CKAN API versioned.
    register_list = [
        'package',
        'dataset',
        'resource',
        'tag',
        'group',
        'related',
        'revision',
        'licenses',
        'rating',
        'user',
        'activity'
    ]
    register_list_str = '|'.join(register_list)

    # /api ver 3 or none
    with SubMapper(map, controller='api', path_prefix='/api{ver:/3|}',
                   ver='/3') as m:
        m.connect('/action/{logic_function}', action='action',
                  conditions=GET_POST)

    # /api ver 1, 2, 3 or none
    with SubMapper(map, controller='api', path_prefix='/api{ver:/1|/2|/3|}',
                   ver='/1') as m:
        m.connect('', action='get_api')
        m.connect('/search/{register}', action='search')

    # /api ver 1, 2 or none
    with SubMapper(map, controller='api', path_prefix='/api{ver:/1|/2|}',
                   ver='/1') as m:
        m.connect('/tag_counts', action='tag_counts')
        m.connect('/rest', action='index')
        m.connect('/qos/throughput/', action='throughput', conditions=GET)

    # /api/rest ver 1, 2 or none
    with SubMapper(map, controller='api', path_prefix='/api{ver:/1|/2|}',
                   ver='/1', requirements=dict(register=register_list_str)
                   ) as m:

        m.connect('/rest/{register}', action='list', conditions=GET)
        m.connect('/rest/{register}', action='create', conditions=POST)
        m.connect('/rest/{register}/{id}', action='show', conditions=GET)
        m.connect('/rest/{register}/{id}', action='update', conditions=PUT)
        m.connect('/rest/{register}/{id}', action='update', conditions=POST)
        m.connect('/rest/{register}/{id}', action='delete', conditions=DELETE)
        m.connect('/rest/{register}/{id}/:subregister', action='list',
                  conditions=GET)
        m.connect('/rest/{register}/{id}/:subregister', action='create',
                  conditions=POST)
        m.connect('/rest/{register}/{id}/:subregister/{id2}', action='create',
                  conditions=POST)
        m.connect('/rest/{register}/{id}/:subregister/{id2}', action='show',
                  conditions=GET)
        m.connect('/rest/{register}/{id}/:subregister/{id2}', action='update',
                  conditions=PUT)
        m.connect('/rest/{register}/{id}/:subregister/{id2}', action='delete',
                  conditions=DELETE)

    # /api/util ver 1, 2 or none
    with SubMapper(map, controller='api', path_prefix='/api{ver:/1|/2|}',
                   ver='/1') as m:
        m.connect('/util/user/autocomplete', action='user_autocomplete')
        m.connect('/util/is_slug_valid', action='is_slug_valid',
                  conditions=GET)
        m.connect('/util/dataset/autocomplete', action='dataset_autocomplete',
                  conditions=GET)
        m.connect('/util/tag/autocomplete', action='tag_autocomplete',
                  conditions=GET)
        m.connect('/util/resource/format_autocomplete',
                  action='format_autocomplete', conditions=GET)
        m.connect('/util/resource/format_icon',
                  action='format_icon', conditions=GET)
        m.connect('/util/group/autocomplete', action='group_autocomplete')
        m.connect('/util/markdown', action='markdown')
        m.connect('/util/dataset/munge_name', action='munge_package_name')
        m.connect('/util/dataset/munge_title_to_name',
                  action='munge_title_to_package_name')
        m.connect('/util/tag/munge', action='munge_tag')
        m.connect('/util/status', action='status')
        m.connect('/util/snippet/{snippet_path:.*}', action='snippet')
        m.connect('/i18n/{lang}', action='i18n_js_translations')

    ###########
    ## /END API
    ###########

    map.redirect('/packages', '/dataset')
    map.redirect('/packages/{url:.*}', '/dataset/{url}')
    map.redirect('/package', '/dataset')
    map.redirect('/package/{url:.*}', '/dataset/{url}')

    with SubMapper(map, controller='related') as m:
        m.connect('related_new', '/dataset/{id}/related/new', action='new')
        m.connect('related_edit', '/dataset/{id}/related/edit/{related_id}',
                  action='edit')
        m.connect('related_delete', '/dataset/{id}/related/delete/{related_id}',
                  action='delete')
        m.connect('related_list', '/dataset/{id}/related', action='list',
                  ckan_icon='picture')
        m.connect('related_read', '/related/{id}', action='read')
        m.connect('related_dashboard', '/related', action='dashboard')

    with SubMapper(map, controller='package') as m:
        m.connect('search', '/dataset', action='search',
                  highlight_actions='index search')
        m.connect('add dataset', '/dataset/new', action='new')
        m.connect('/dataset/{action}',
                  requirements=dict(action='|'.join([
                      'list',
                      'autocomplete',
                      'search'
                  ])))

        m.connect('/dataset/{action}/{id}/{revision}', action='read_ajax',
                  requirements=dict(action='|'.join([
                      'read',
                      'edit',
                      'history',
                  ])))
        m.connect('/dataset/{action}/{id}',
                  requirements=dict(action='|'.join([
                      'new_metadata',
                      'new_resource',
                      'history',
                      'read_ajax',
                      'history_ajax',
                      'follow',
                      'activity',
                      'groups',
                      'unfollow',
                      'delete',
                      'api_data',
                  ])))
        m.connect('dataset_edit', '/dataset/edit/{id}', action='edit',
                  ckan_icon='edit')
        m.connect('dataset_followers', '/dataset/followers/{id}',
                  action='followers', ckan_icon='group')
        m.connect('dataset_activity', '/dataset/activity/{id}',
                  action='activity', ckan_icon='time')
        m.connect('/dataset/activity/{id}/{offset}', action='activity')
        m.connect('dataset_groups', '/dataset/groups/{id}',
                  action='groups', ckan_icon='group')
        m.connect('/dataset/{id}.{format}', action='read')
        m.connect('dataset_resources', '/dataset/resources/{id}',
                  action='resources', ckan_icon='reorder')
        m.connect('dataset_read', '/dataset/{id}', action='read',
                  ckan_icon='sitemap')
        m.connect('/dataset/{id}/resource/{resource_id}',
                  action='resource_read')
        m.connect('/dataset/{id}/resource_delete/{resource_id}',
                  action='resource_delete')
        m.connect('resource_edit', '/dataset/{id}/resource_edit/{resource_id}',
                  action='resource_edit', ckan_icon='edit')
        m.connect('/dataset/{id}/resource/{resource_id}/download',
                  action='resource_download')
        m.connect('/dataset/{id}/resource/{resource_id}/download/{filename}',
                  action='resource_download')
        m.connect('/dataset/{id}/resource/{resource_id}/embed',
                  action='resource_embedded_dataviewer')
        m.connect('/dataset/{id}/resource/{resource_id}/viewer',
                  action='resource_embedded_dataviewer', width="960",
                  height="800")
        m.connect('/dataset/{id}/resource/{resource_id}/preview',
                  action='resource_datapreview')

    # group
    map.redirect('/groups', '/group')
    map.redirect('/groups/{url:.*}', '/group/{url}')

    ##to get back formalchemy uncomment these lines
    ##map.connect('/group/new', controller='group_formalchemy', action='new')
    ##map.connect('/group/edit/{id}', controller='group_formalchemy', action='edit')

    # These named routes are used for custom group forms which will use the
    # names below based on the group.type ('group' is the default type)
    with SubMapper(map, controller='group') as m:
        m.connect('group_index', '/group', action='index',
                  highlight_actions='index search')
        m.connect('group_list', '/group/list', action='list')
        m.connect('group_new', '/group/new', action='new')
        m.connect('group_action', '/group/{action}/{id}',
                  requirements=dict(action='|'.join([
                      'edit',
                      'delete',
                      'member_new',
                      'member_delete',
                      'history',
                      'followers',
                      'follow',
                      'unfollow',
                      'admins',
                      'activity',
                  ])))
        m.connect('group_about', '/group/about/{id}', action='about',
                  ckan_icon='info-sign'),
        m.connect('group_edit', '/group/edit/{id}', action='edit',
                  ckan_icon='edit')
        m.connect('group_members', '/group/members/{id}', action='members',
                  ckan_icon='group'),
        m.connect('group_activity', '/group/activity/{id}/{offset}',
                  action='activity', ckan_icon='time'),
        m.connect('group_read', '/group/{id}', action='read',
                  ckan_icon='sitemap')

    # organizations these basically end up being the same as groups
    with SubMapper(map, controller='organization') as m:
        m.connect('organizations_index', '/organization', action='index')
        m.connect('/organization/list', action='list')
        m.connect('/organization/new', action='new')
        m.connect('/organization/{action}/{id}',
                  requirements=dict(action='|'.join([
                      'delete',
                      'admins',
                      'member_new',
                      'member_delete',
                      'history'
                  ])))
        m.connect('organization_activity', '/organization/activity/{id}',
                  action='activity', ckan_icon='time')
        m.connect('organization_read', '/organization/{id}', action='read')
        m.connect('organization_about', '/organization/about/{id}',
                  action='about', ckan_icon='info-sign')
        m.connect('organization_read', '/organization/{id}', action='read',
                  ckan_icon='sitemap')
        m.connect('organization_edit', '/organization/edit/{id}',
                  action='edit', ckan_icon='edit')
        m.connect('organization_members', '/organization/members/{id}',
                  action='members', ckan_icon='group')
        m.connect('organization_bulk_process',
                  '/organization/bulk_process/{id}',
                  action='bulk_process', ckan_icon='sitemap')
    lib_plugins.register_package_plugins(map)
    lib_plugins.register_group_plugins(map)

    # tags
    map.redirect('/tags', '/tag')
    map.redirect('/tags/{url:.*}', '/tag/{url}')
    map.redirect('/tag/read/{url:.*}', '/tag/{url}',
                 _redirect_code='301 Moved Permanently')
    map.connect('/tag', controller='tag', action='index')
    map.connect('/tag/{id}', controller='tag', action='read')
    # users
    map.redirect('/users/{url:.*}', '/user/{url}')
    map.redirect('/user/', '/user')
    with SubMapper(map, controller='user') as m:
        m.connect('/user/edit', action='edit')
        # Note: openid users have slashes in their ids, so need the wildcard
        # in the route.
        m.connect('/user/activity/{id}/{offset}', action='activity')
        m.connect('user_activity_stream', '/user/activity/{id}',
                  action='activity', ckan_icon='time')
        m.connect('user_dashboard', '/dashboard', action='dashboard',
                  ckan_icon='list')
        m.connect('user_dashboard_datasets', '/dashboard/datasets',
                  action='dashboard_datasets', ckan_icon='sitemap')
        m.connect('user_dashboard_groups', '/dashboard/groups',
                  action='dashboard_groups', ckan_icon='group')
        m.connect('user_dashboard_organizations', '/dashboard/organizations',
                  action='dashboard_organizations', ckan_icon='building')
        m.connect('/dashboard/{offset}', action='dashboard')
        m.connect('user_follow', '/user/follow/{id}', action='follow')
        m.connect('/user/unfollow/{id}', action='unfollow')
        m.connect('user_followers', '/user/followers/{id:.*}',
                  action='followers', ckan_icon='group')
        m.connect('user_edit', '/user/edit/{id:.*}', action='edit',
                  ckan_icon='cog')
        m.connect('user_delete', '/user/delete/{id}', action='delete')
        m.connect('/user/reset/{id:.*}', action='perform_reset')
        m.connect('register', '/user/register', action='register')
        m.connect('login', '/user/login', action='login')
        m.connect('/user/_logout', action='logout')
        m.connect('/user/logged_in', action='logged_in')
        m.connect('/user/logged_out', action='logged_out')
        m.connect('/user/logged_out_redirect', action='logged_out_page')
        m.connect('/user/reset', action='request_reset')
        m.connect('/user/me', action='me')
        m.connect('/user/set_lang/{lang}', action='set_lang')
        m.connect('user_datasets', '/user/{id:.*}', action='read',
                  ckan_icon='sitemap')
        m.connect('user_index', '/user', action='index')

    with SubMapper(map, controller='revision') as m:
        m.connect('/revision', action='index')
        m.connect('/revision/edit/{id}', action='edit')
        m.connect('/revision/diff/{id}', action='diff')
        m.connect('/revision/list', action='list')
        m.connect('/revision/{id}', action='read')

    # feeds
    with SubMapper(map, controller='feed') as m:
        m.connect('/feeds/group/{id}.atom', action='group')
        m.connect('/feeds/organization/{id}.atom', action='organization')
        m.connect('/feeds/tag/{id}.atom', action='tag')
        m.connect('/feeds/dataset.atom', action='general')
        m.connect('/feeds/custom.atom', action='custom')

    map.connect('ckanadmin_index', '/ckan-admin', controller='admin',
                action='index', ckan_icon='legal')
    map.connect('ckanadmin_config', '/ckan-admin/config', controller='admin',
                action='config', ckan_icon='check')
    map.connect('ckanadmin', '/ckan-admin/{action}', controller='admin')

    # Storage routes
    with SubMapper(map, controller='ckan.controllers.storage:StorageAPIController') as m:
        m.connect('storage_api', '/api/storage', action='index')
        m.connect('storage_api_set_metadata', '/api/storage/metadata/{label:.*}',
                  action='set_metadata', conditions=PUT_POST)
        m.connect('storage_api_get_metadata', '/api/storage/metadata/{label:.*}',
                  action='get_metadata', conditions=GET)
        m.connect('storage_api_auth_request',
                  '/api/storage/auth/request/{label:.*}',
                  action='auth_request')
        m.connect('storage_api_auth_form',
                  '/api/storage/auth/form/{label:.*}',
                  action='auth_form')

    with SubMapper(map, controller='ckan.controllers.storage:StorageController') as m:
        m.connect('storage_upload', '/storage/upload',
                  action='upload')
        m.connect('storage_upload_handle', '/storage/upload_handle',
                  action='upload_handle')
        m.connect('storage_upload_success', '/storage/upload/success',
                  action='success')
        m.connect('storage_upload_success_empty', '/storage/upload/success_empty',
                  action='success_empty')
        m.connect('storage_file', '/storage/f/{label:.*}',
                  action='file')

    with SubMapper(map, controller='util') as m:
        m.connect('/i18n/strings_{lang}.js', action='i18n_js_strings')
        m.connect('/util/redirect', action='redirect')
        m.connect('/testing/primer', action='primer')
        m.connect('/testing/markup', action='markup')

    for plugin in p.PluginImplementations(p.IRoutes):
        map = plugin.after_map(map)

    # sometimes we get requests for favicon.ico we should redirect to
    # the real favicon location.
    map.redirect('/favicon.ico', config.get('ckan.favicon'))

    map.redirect('/*(url)/', '/{url}',
                 _redirect_code='301 Moved Permanently')
    map.connect('/*url', controller='template', action='view')

    return map

########NEW FILE########
__FILENAME__ = admin
from pylons import config

import ckan.lib.base as base
import ckan.lib.helpers as h
import ckan.lib.app_globals as app_globals
import ckan.model as model
import ckan.logic as logic
import ckan.new_authz

c = base.c
request = base.request
_ = base._

def get_sysadmins():
    q = model.Session.query(model.User).filter(model.User.sysadmin==True)
    return q.all()


class AdminController(base.BaseController):
    def __before__(self, action, **params):
        super(AdminController, self).__before__(action, **params)
        context = {'model': model,
                   'user': c.user, 'auth_user_obj': c.userobj}
        try:
            logic.check_access('sysadmin', context, {})
        except logic.NotAuthorized:
            base.abort(401, _('Need to be system administrator to administer'))
        c.revision_change_state_allowed = True

    def _get_config_form_items(self):
        # Styles for use in the form.select() macro.
        styles = [{'text': 'Default', 'value': '/base/css/main.css'},
                  {'text': 'Red', 'value': '/base/css/red.css'},
                  {'text': 'Green', 'value': '/base/css/green.css'},
                  {'text': 'Maroon', 'value': '/base/css/maroon.css'},
                  {'text': 'Fuchsia', 'value': '/base/css/fuchsia.css'}]

        homepages = [{'value': '1', 'text': 'Introductory area, search, featured group and featured organization'},
                     {'value': '2', 'text': 'Search, stats, introductory area, featured organization and featured group'},
                     {'value': '3', 'text': 'Search, introductory area and stats'}]

        items = [
            {'name': 'ckan.site_title', 'control': 'input', 'label': _('Site Title'), 'placeholder': ''},
            {'name': 'ckan.main_css', 'control': 'select', 'options': styles, 'label': _('Style'), 'placeholder': ''},
            {'name': 'ckan.site_description', 'control': 'input', 'label': _('Site Tag Line'), 'placeholder': ''},
            {'name': 'ckan.site_logo', 'control': 'input', 'label': _('Site Tag Logo'), 'placeholder': ''},
            {'name': 'ckan.site_about', 'control': 'markdown', 'label': _('About'), 'placeholder': _('About page text')},
            {'name': 'ckan.site_intro_text', 'control': 'markdown', 'label': _('Intro Text'), 'placeholder': _('Text on home page')},
            {'name': 'ckan.site_custom_css', 'control': 'textarea', 'label': _('Custom CSS'), 'placeholder': _('Customisable css inserted into the page header')},
            {'name': 'ckan.homepage_style', 'control': 'select', 'options': homepages, 'label': _('Homepage'), 'placeholder': ''},
        ]
        return items

    def reset_config(self):
        if 'cancel' in request.params:
            h.redirect_to(controller='admin', action='config')

        if request.method == 'POST':
            # remove sys info items
            for item in self._get_config_form_items():
                name = item['name']
                app_globals.delete_global(name)
            # reset to values in config
            app_globals.reset()
            h.redirect_to(controller='admin', action='config')

        return base.render('admin/confirm_reset.html')

    def config(self):

        items = self._get_config_form_items()
        data = request.POST
        if 'save' in data:
            # update config from form
            for item in items:
                name = item['name']
                if name in data:
                    app_globals.set_global(name, data[name])
            app_globals.reset()
            h.redirect_to(controller='admin', action='config')

        data = {}
        for item in items:
            name = item['name']
            data[name] = config.get(name)

        vars = {'data': data, 'errors': {}, 'form_items': items}
        return base.render('admin/config.html',
                           extra_vars = vars)

    def index(self):
        #now pass the list of sysadmins
        c.sysadmins = [a.name for a in get_sysadmins()]

        return base.render('admin/index.html')


    def trash(self):
        c.deleted_revisions = model.Session.query(
            model.Revision).filter_by(state=model.State.DELETED)
        c.deleted_packages = model.Session.query(
            model.Package).filter_by(state=model.State.DELETED)
        if not request.params or (len(request.params) == 1 and '__no_cache__'
                                  in request.params):
            return base.render('admin/trash.html')
        else:
            # NB: we repeat retrieval of of revisions
            # this is obviously inefficient (but probably not *that* bad)
            # but has to be done to avoid (odd) sqlalchemy errors (when doing
            # purge packages) of form: "this object already exists in the
            # session"
            msgs = []
            if ('purge-packages' in request.params) or ('purge-revisions' in
                                                        request.params):
                if 'purge-packages' in request.params:
                    revs_to_purge = []
                    for pkg in c.deleted_packages:
                        revisions = [x[0] for x in pkg.all_related_revisions]
                        # ensure no accidental purging of other(non-deleted)
                        # packages initially just avoided purging revisions
                        # where non-deleted packages were affected
                        # however this lead to confusing outcomes e.g.
                        # we succesfully deleted revision in which package
                        # was deleted (so package now active again) but no
                        # other revisions
                        problem = False
                        for r in revisions:
                            affected_pkgs = set(r.packages).\
                                difference(set(c.deleted_packages))
                            if affected_pkgs:
                                msg = _('Cannot purge package %s as '
                                        'associated revision %s includes '
                                        'non-deleted packages %s')
                                msg = msg % (pkg.id, r.id, [pkg.id for r
                                                            in affected_pkgs])
                                msgs.append(msg)
                                problem = True
                                break
                        if not problem:
                            revs_to_purge += [r.id for r in revisions]
                    model.Session.remove()
                else:
                    revs_to_purge = [rev.id for rev in c.deleted_revisions]
                revs_to_purge = list(set(revs_to_purge))
                for id in revs_to_purge:
                    revision = model.Session.query(model.Revision).get(id)
                    try:
                        # TODO deleting the head revision corrupts the edit
                        # page Ensure that whatever 'head' pointer is used
                        # gets moved down to the next revision
                        model.repo.purge_revision(revision, leave_record=False)
                    except Exception, inst:
                        msg = _('Problem purging revision %s: %s') % (id, inst)
                        msgs.append(msg)
                h.flash_success(_('Purge complete'))
            else:
                msgs.append(_('Action not implemented.'))

            for msg in msgs:
                h.flash_error(msg)
            h.redirect_to(controller='admin', action='trash')

########NEW FILE########
__FILENAME__ = api
import os.path
import logging
import cgi
import datetime
import glob
import urllib

from webob.multidict import UnicodeMultiDict
from paste.util.multidict import MultiDict

import ckan.model as model
import ckan.logic as logic
import ckan.lib.base as base
import ckan.lib.helpers as h
import ckan.lib.search as search
import ckan.lib.navl.dictization_functions
import ckan.lib.jsonp as jsonp
import ckan.lib.munge as munge

from ckan.common import _, c, request, response


log = logging.getLogger(__name__)

# shortcuts
get_action = logic.get_action
NotAuthorized = logic.NotAuthorized
NotFound = logic.NotFound
ValidationError = logic.ValidationError
DataError = ckan.lib.navl.dictization_functions.DataError

IGNORE_FIELDS = ['q']
CONTENT_TYPES = {
    'text': 'text/plain;charset=utf-8',
    'html': 'text/html;charset=utf-8',
    'json': 'application/json;charset=utf-8',
}


class ApiController(base.BaseController):

    _actions = {}

    def __call__(self, environ, start_response):
        # we need to intercept and fix the api version
        # as it will have a "/" at the start
        routes_dict = environ['pylons.routes_dict']
        api_version = routes_dict.get('ver')
        if api_version:
            api_version = api_version[1:]
            routes_dict['ver'] = int(api_version)

        self._identify_user()
        try:
            context = {'model': model, 'user': c.user or c.author,
                       'auth_user_obj': c.userobj}
            logic.check_access('site_read', context)
        except NotAuthorized:
            response_msg = self._finish(403,
                                        _('Not authorized to see this page'))
            # Call start_response manually instead of the parent __call__
            # because we want to end the request instead of continuing.
            response_msg = response_msg.encode('utf8')
            body = '%i %s' % (response.status_int, response_msg)
            start_response(body, response.headers.items())
            return [response_msg]

        # avoid status_code_redirect intercepting error responses
        environ['pylons.status_code_redirect'] = True
        return base.BaseController.__call__(self, environ, start_response)

    def _finish(self, status_int, response_data=None,
                content_type='text'):
        '''When a controller method has completed, call this method
        to prepare the response.
        @return response message - return this value from the controller
                                   method
                 e.g. return self._finish(404, 'Package not found')
        '''
        assert(isinstance(status_int, int))
        response.status_int = status_int
        response_msg = ''
        if response_data is not None:
            response.headers['Content-Type'] = CONTENT_TYPES[content_type]
            if content_type == 'json':
                response_msg = h.json.dumps(response_data)
            else:
                response_msg = response_data
            # Support "JSONP" callback.
            if status_int == 200 and 'callback' in request.params and \
                (request.method == 'GET' or
                 c.logic_function and request.method == 'POST'):
                # escape callback to remove '<', '&', '>' chars
                callback = cgi.escape(request.params['callback'])
                response_msg = self._wrap_jsonp(callback, response_msg)
        return response_msg

    def _finish_ok(self, response_data=None,
                   content_type='json',
                   resource_location=None):
        '''If a controller method has completed successfully then
        calling this method will prepare the response.
        @param resource_location - specify this if a new
           resource has just been created.
        @return response message - return this value from the controller
                                   method
                                   e.g. return self._finish_ok(pkg_dict)
        '''
        if resource_location:
            status_int = 201
            self._set_response_header('Location', resource_location)
        else:
            status_int = 200

        return self._finish(status_int, response_data, content_type)

    def _finish_not_authz(self, extra_msg=None):
        response_data = _('Access denied')
        if extra_msg:
            response_data = '%s - %s' % (response_data, extra_msg)
        return self._finish(403, response_data, 'json')

    def _finish_not_found(self, extra_msg=None):
        response_data = _('Not found')
        if extra_msg:
            response_data = '%s - %s' % (response_data, extra_msg)
        return self._finish(404, response_data, 'json')

    def _finish_bad_request(self, extra_msg=None):
        response_data = _('Bad request')
        if extra_msg:
            response_data = '%s - %s' % (response_data, extra_msg)
        return self._finish(400, response_data, 'json')

    def _wrap_jsonp(self, callback, response_msg):
        return '%s(%s);' % (callback, response_msg)

    def _set_response_header(self, name, value):
        try:
            value = str(value)
        except Exception, inst:
            msg = "Couldn't convert '%s' header value '%s' to string: %s" % \
                (name, value, inst)
            raise Exception(msg)
        response.headers[name] = value

    def get_api(self, ver=None):
        response_data = {}
        response_data['version'] = ver
        return self._finish_ok(response_data)

    def snippet(self, snippet_path, ver=None):
        ''' Renders and returns a snippet used by ajax calls '''
        # we only allow snippets in templates/ajax_snippets and it's subdirs
        snippet_path = u'ajax_snippets/' + snippet_path
        return base.render(snippet_path, extra_vars=dict(request.params))

    def action(self, logic_function, ver=None):
        try:
            function = get_action(logic_function)
        except KeyError:
            log.error('Can\'t find logic function: %s' % logic_function)
            return self._finish_bad_request(
                _('Action name not known: %s') % logic_function)

        context = {'model': model, 'session': model.Session, 'user': c.user,
                   'api_version': ver, 'auth_user_obj': c.userobj}
        model.Session()._context = context
        return_dict = {'help': function.__doc__}
        try:
            side_effect_free = getattr(function, 'side_effect_free', False)
            request_data = self._get_request_data(try_url_params=
                                                  side_effect_free)
        except ValueError, inst:
            log.error('Bad request data: %s' % inst)
            return self._finish_bad_request(
                _('JSON Error: %s') % inst)
        if not isinstance(request_data, dict):
            # this occurs if request_data is blank
            log.error('Bad request data - not dict: %r' % request_data)
            return self._finish_bad_request(
                _('Bad request data: %s') %
                'Request data JSON decoded to %r but '
                'it needs to be a dictionary.' % request_data)
        # if callback is specified we do not want to send that to the search
        if 'callback' in request_data:
            del request_data['callback']
        try:
            result = function(context, request_data)
            return_dict['success'] = True
            return_dict['result'] = result
        except DataError, e:
            log.error('Format incorrect: %s - %s' % (e.error, request_data))
            return_dict['error'] = {'__type': 'Integrity Error',
                                    'message': e.error,
                                    'data': request_data}
            return_dict['success'] = False
            return self._finish(400, return_dict, content_type='json')
        except NotAuthorized, e:
            return_dict['error'] = {'__type': 'Authorization Error',
                                    'message': _('Access denied')}
            return_dict['success'] = False
            
            if e.extra_msg:
                return_dict['error']['message'] += ': %s' % e.extra_msg

            return self._finish(403, return_dict, content_type='json')
        except NotFound, e:
            return_dict['error'] = {'__type': 'Not Found Error',
                                    'message': _('Not found')}
            if e.extra_msg:
                return_dict['error']['message'] += ': %s' % e.extra_msg
            return_dict['success'] = False
            return self._finish(404, return_dict, content_type='json')
        except ValidationError, e:
            error_dict = e.error_dict
            error_dict['__type'] = 'Validation Error'
            return_dict['error'] = error_dict
            return_dict['success'] = False
            # CS nasty_string ignore
            log.error('Validation error: %r' % str(e.error_dict))
            return self._finish(409, return_dict, content_type='json')
        except search.SearchQueryError, e:
            return_dict['error'] = {'__type': 'Search Query Error',
                                    'message': 'Search Query is invalid: %r' %
                                    e.args}
            return_dict['success'] = False
            return self._finish(400, return_dict, content_type='json')
        except search.SearchError, e:
            return_dict['error'] = {'__type': 'Search Error',
                                    'message': 'Search error: %r' % e.args}
            return_dict['success'] = False
            return self._finish(409, return_dict, content_type='json')
        except search.SearchIndexError, e:
            return_dict['error'] = {'__type': 'Search Index Error',
                    'message': 'Unable to add package to search index: %s' %
                    str(e)}
            return_dict['success'] = False
            return self._finish(500, return_dict, content_type='json')
        return self._finish_ok(return_dict)

    def _get_action_from_map(self, action_map, register, subregister):
        ''' Helper function to get the action function specified in
            the action map'''

        # translate old package calls to use dataset
        if register == 'package':
            register = 'dataset'

        action = action_map.get((register, subregister))
        if not action:
            action = action_map.get(register)
        if action:
            return get_action(action)

    def list(self, ver=None, register=None, subregister=None, id=None):
        context = {'model': model, 'session': model.Session,
                   'user': c.user, 'api_version': ver,
                   'auth_user_obj': c.userobj}
        log.debug('listing: %s' % context)
        action_map = {
            'revision': 'revision_list',
            'group': 'group_list',
            'dataset': 'package_list',
            'tag': 'tag_list',
            'related': 'related_list',
            'licenses': 'license_list',
            ('dataset', 'relationships'): 'package_relationships_list',
            ('dataset', 'revisions'): 'package_revision_list',
            ('dataset', 'activity'): 'package_activity_list',
            ('group', 'activity'): 'group_activity_list',
            ('user', 'activity'): 'user_activity_list',
            ('user', 'dashboard_activity'): 'dashboard_activity_list',
            ('activity', 'details'): 'activity_detail_list',
        }

        action = self._get_action_from_map(action_map, register, subregister)
        if not action:
            return self._finish_bad_request(
                _('Cannot list entity of this type: %s') % register)
        try:
            return self._finish_ok(action(context, {'id': id}))
        except NotFound, e:
            extra_msg = e.extra_msg
            return self._finish_not_found(extra_msg)
        except NotAuthorized, e:
            extra_msg = e.extra_msg
            return self._finish_not_authz(extra_msg)

    def show(self, ver=None, register=None, subregister=None,
             id=None, id2=None):
        action_map = {
            'revision': 'revision_show',
            'group': 'group_show_rest',
            'tag': 'tag_show_rest',
            'related': 'related_show',
            'dataset': 'package_show_rest',
            ('dataset', 'relationships'): 'package_relationships_list',
        }
        for type in model.PackageRelationship.get_all_types():
            action_map[('dataset', type)] = 'package_relationships_list'

        context = {'model': model, 'session': model.Session, 'user': c.user,
                   'api_version': ver, 'auth_user_obj': c.userobj}
        data_dict = {'id': id, 'id2': id2, 'rel': subregister}

        log.debug('show: %s' % context)

        action = self._get_action_from_map(action_map, register, subregister)
        if not action:
            return self._finish_bad_request(
                _('Cannot read entity of this type: %s') % register)
        try:
            return self._finish_ok(action(context, data_dict))
        except NotFound, e:
            extra_msg = e.extra_msg
            return self._finish_not_found(extra_msg)
        except NotAuthorized, e:
            extra_msg = e.extra_msg
            return self._finish_not_authz(extra_msg)

    def _represent_package(self, package):
        return package.as_dict(ref_package_by=self.ref_package_by,
                               ref_group_by=self.ref_group_by)

    def create(self, ver=None, register=None, subregister=None,
               id=None, id2=None):

        action_map = {
            'group': 'group_create_rest',
            'dataset': 'package_create_rest',
            'rating': 'rating_create',
            'related': 'related_create',
            ('dataset', 'relationships'): 'package_relationship_create_rest',
        }
        for type in model.PackageRelationship.get_all_types():
            action_map[('dataset', type)] = 'package_relationship_create_rest'

        context = {'model': model, 'session': model.Session, 'user': c.user,
                   'api_version': ver, 'auth_user_obj': c.userobj}
        log.debug('create: %s' % (context))
        try:
            request_data = self._get_request_data()
            data_dict = {'id': id, 'id2': id2, 'rel': subregister}
            data_dict.update(request_data)
        except ValueError, inst:
            return self._finish_bad_request(
                _('JSON Error: %s') % inst)

        action = self._get_action_from_map(action_map, register, subregister)
        if not action:
            return self._finish_bad_request(
                _('Cannot create new entity of this type: %s %s') %
                (register, subregister))

        try:
            response_data = action(context, data_dict)
            location = None
            if "id" in data_dict:
                location = str('%s/%s' % (request.path.replace('package',
                                                               'dataset'),
                                          data_dict.get("id")))
            return self._finish_ok(response_data,
                                   resource_location=location)
        except NotAuthorized, e:
            extra_msg = e.extra_msg
            return self._finish_not_authz(extra_msg)
        except NotFound, e:
            extra_msg = e.extra_msg
            return self._finish_not_found(extra_msg)
        except ValidationError, e:
            # CS: nasty_string ignore
            log.error('Validation error: %r' % str(e.error_dict))
            return self._finish(409, e.error_dict, content_type='json')
        except DataError, e:
            log.error('Format incorrect: %s - %s' % (e.error, request_data))
            error_dict = {
                'success': False,
                'error': {'__type': 'Integrity Error',
                                    'message': e.error,
                                    'data': request_data}}
            return self._finish(400, error_dict, content_type='json')
        except search.SearchIndexError:
            log.error('Unable to add package to search index: %s' %
                      request_data)
            return self._finish(500,
                                _(u'Unable to add package to search index') %
                                request_data)
        except:
            model.Session.rollback()
            raise

    def update(self, ver=None, register=None, subregister=None,
               id=None, id2=None):
        action_map = {
            'dataset': 'package_update_rest',
            'group': 'group_update_rest',
            ('dataset', 'relationships'): 'package_relationship_update_rest',
        }
        for type in model.PackageRelationship.get_all_types():
            action_map[('dataset', type)] = 'package_relationship_update_rest'

        context = {'model': model, 'session': model.Session, 'user': c.user,
                   'api_version': ver, 'id': id, 'auth_user_obj': c.userobj}
        log.debug('update: %s' % (context))
        try:
            request_data = self._get_request_data()
            data_dict = {'id': id, 'id2': id2, 'rel': subregister}
            data_dict.update(request_data)
        except ValueError, inst:
            return self._finish_bad_request(
                _('JSON Error: %s') % inst)

        action = self._get_action_from_map(action_map, register, subregister)
        if not action:
            return self._finish_bad_request(
                _('Cannot update entity of this type: %s') %
                register.encode('utf-8'))
        try:
            response_data = action(context, data_dict)
            return self._finish_ok(response_data)
        except NotAuthorized, e:
            extra_msg = e.extra_msg
            return self._finish_not_authz(extra_msg)
        except NotFound, e:
            extra_msg = e.extra_msg
            return self._finish_not_found(extra_msg)
        except ValidationError, e:
            # CS: nasty_string ignore
            log.error('Validation error: %r' % str(e.error_dict))
            return self._finish(409, e.error_dict, content_type='json')
        except DataError, e:
            log.error('Format incorrect: %s - %s' % (e.error, request_data))
            error_dict = {
                'success': False,
                'error': {'__type': 'Integrity Error',
                                    'message': e.error,
                                    'data': request_data}}
            return self._finish(400, error_dict, content_type='json')
        except search.SearchIndexError:
            log.error('Unable to update search index: %s' % request_data)
            return self._finish(500, _(u'Unable to update search index') %
                                request_data)

    def delete(self, ver=None, register=None, subregister=None,
               id=None, id2=None):
        action_map = {
            'group': 'group_delete',
            'dataset': 'package_delete',
            'related': 'related_delete',
            ('dataset', 'relationships'): 'package_relationship_delete_rest',
        }
        for type in model.PackageRelationship.get_all_types():
            action_map[('dataset', type)] = 'package_relationship_delete_rest'

        context = {'model': model, 'session': model.Session, 'user': c.user,
                   'api_version': ver, 'auth_user_obj': c.userobj}

        data_dict = {'id': id, 'id2': id2, 'rel': subregister}

        log.debug('delete %s/%s/%s/%s' % (register, id, subregister, id2))

        action = self._get_action_from_map(action_map, register, subregister)
        if not action:
            return self._finish_bad_request(
                _('Cannot delete entity of this type: %s %s') %
                (register, subregister or ''))
        try:
            response_data = action(context, data_dict)
            return self._finish_ok(response_data)
        except NotAuthorized, e:
            extra_msg = e.extra_msg
            return self._finish_not_authz(extra_msg)
        except NotFound, e:
            extra_msg = e.extra_msg
            return self._finish_not_found(extra_msg)
        except ValidationError, e:
            # CS: nasty_string ignore
            log.error('Validation error: %r' % str(e.error_dict))
            return self._finish(409, e.error_dict, content_type='json')

    def search(self, ver=None, register=None):

        log.debug('search %s params: %r' % (register, request.params))
        if register == 'revision':
            since_time = None
            if 'since_id' in request.params:
                id = request.params['since_id']
                if not id:
                    return self._finish_bad_request(
                        _(u'No revision specified'))
                rev = model.Session.query(model.Revision).get(id)
                if rev is None:
                    return self._finish_not_found(
                        _(u'There is no revision with id: %s') % id)
                since_time = rev.timestamp
            elif 'since_time' in request.params:
                since_time_str = request.params['since_time']
                try:
                    since_time = h.date_str_to_datetime(since_time_str)
                except ValueError, inst:
                    return self._finish_bad_request('ValueError: %s' % inst)
            else:
                return self._finish_bad_request(
                    _("Missing search term ('since_id=UUID' or " +
                            " 'since_time=TIMESTAMP')"))
            revs = model.Session.query(model.Revision).\
                filter(model.Revision.timestamp > since_time)
            return self._finish_ok([rev.id for rev in revs])
        elif register in ['dataset', 'package', 'resource']:
            try:
                params = MultiDict(self._get_search_params(request.params))
            except ValueError, e:
                return self._finish_bad_request(
                    _('Could not read parameters: %r' % e))

            # if using API v2, default to returning the package ID if
            # no field list is specified
            if register in ['dataset', 'package'] and not params.get('fl'):
                params['fl'] = 'id' if ver == 2 else 'name'

            try:
                if register == 'resource':
                    query = search.query_for(model.Resource)

                    # resource search still uses ckan query parser
                    options = search.QueryOptions()
                    for k, v in params.items():
                        if (k in search.DEFAULT_OPTIONS.keys()):
                            options[k] = v
                    options.update(params)
                    options.username = c.user
                    options.search_tags = False
                    options.return_objects = False
                    query_fields = MultiDict()
                    for field, value in params.items():
                        field = field.strip()
                        if field in search.DEFAULT_OPTIONS.keys() or \
                                field in IGNORE_FIELDS:
                            continue
                        values = [value]
                        if isinstance(value, list):
                            values = value
                        for v in values:
                            query_fields.add(field, v)

                    results = query.run(
                        query=params.get('q'),
                        fields=query_fields,
                        options=options
                    )
                else:
                    # For package searches in API v3 and higher, we can pass
                    # parameters straight to Solr.
                    if ver in [1, 2]:
                        # Otherwise, put all unrecognised ones into the q
                        # parameter
                        params = search.\
                            convert_legacy_parameters_to_solr(params)
                    query = search.query_for(model.Package)

                    # Remove any existing fq param and set the capacity to
                    # public
                    if 'fq' in params:
                        del params['fq']
                    params['fq'] = '+capacity:public'
                    # if callback is specified we do not want to send that to
                    # the search
                    if 'callback' in params:
                        del params['callback']
                    results = query.run(params)
                return self._finish_ok(results)
            except search.SearchError, e:
                log.exception(e)
                return self._finish_bad_request(
                    _('Bad search option: %s') % e)
        else:
            return self._finish_not_found(
                _('Unknown register: %s') % register)

    @classmethod
    def _get_search_params(cls, request_params):
        if 'qjson' in request_params:
            try:
                qjson_param = request_params['qjson'].replace('\\\\u', '\\u')
                params = h.json.loads(qjson_param, encoding='utf8')
            except ValueError, e:
                raise ValueError(_('Malformed qjson value: %r')
                                 % e)
        elif len(request_params) == 1 and \
            len(request_params.values()[0]) < 2 and \
                request_params.keys()[0].startswith('{'):
            # e.g. {some-json}='1' or {some-json}=''
            params = h.json.loads(request_params.keys()[0], encoding='utf8')
        else:
            params = request_params
        if not isinstance(params, (UnicodeMultiDict, dict)):
            msg = _('Request params must be in form ' +
                    'of a json encoded dictionary.')
            raise ValueError(msg)
        return params

    def markdown(self, ver=None):
        raw_markdown = request.params.get('q', '')
        results = h.render_markdown(raw_markdown)

        return self._finish_ok(results)

    def tag_counts(self, ver=None):
        c.q = request.params.get('q', '')

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}

        tag_names = get_action('tag_list')(context, {})
        results = []
        for tag_name in tag_names:
            tag_count = len(context['model'].Tag.get(tag_name).packages)
            results.append((tag_name, tag_count))
        return self._finish_ok(results)

    def throughput(self, ver=None):
        qos = self._calc_throughput()
        qos = str(qos)
        return self._finish_ok(qos)

    def _calc_throughput(self, ver=None):
        period = 10  # Seconds.
        timing_cache_path = self._get_timing_cache_path()
        call_count = 0
        for t in range(0, period):
            expr = '%s/%s*' % (
                timing_cache_path,
                (datetime.datetime.now() -
                 datetime.timedelta(0, t)).isoformat()[0:19],
            )
            call_count += len(glob.glob(expr))
        # Todo: Clear old records.
        return float(call_count) / period

    @jsonp.jsonpify
    def user_autocomplete(self):
        q = request.params.get('q', '')
        limit = request.params.get('limit', 20)
        user_list = []
        if q:
            context = {'model': model, 'session': model.Session,
                       'user': c.user or c.author, 'auth_user_obj': c.userobj}

            data_dict = {'q': q, 'limit': limit}

            user_list = get_action('user_autocomplete')(context, data_dict)
        return user_list

    @jsonp.jsonpify
    def group_autocomplete(self):
        q = request.params.get('q', '')
        t = request.params.get('type', None)
        limit = request.params.get('limit', 20)
        try:
            limit = int(limit)
        except:
            limit = 20
        limit = min(50, limit)

        query = model.Group.search_by_name_or_title(q, t)

        def convert_to_dict(user):
            out = {}
            for k in ['id', 'name', 'title']:
                out[k] = getattr(user, k)
            return out

        query = query.limit(limit)
        out = map(convert_to_dict, query.all())
        return out

    def is_slug_valid(self):

        def package_exists(val):
            if model.Session.query(model.Package) \
                .autoflush(False).filter_by(name=val).count():
                return True
            return False

        def group_exists(val):
            if model.Session.query(model.Group) \
                    .autoflush(False).filter_by(name=val).count():
                return True
            return False

        slug = request.params.get('slug') or ''
        slugtype = request.params.get('type') or ''
        # TODO: We need plugins to be able to register new disallowed names
        disallowed = ['new', 'edit', 'search']
        if slugtype == u'package':
            response_data = dict(valid=not (package_exists(slug)
                                 or slug in disallowed))
            return self._finish_ok(response_data)
        if slugtype == u'group':
            response_data = dict(valid=not (group_exists(slug) or
                                 slug in disallowed))
            return self._finish_ok(response_data)
        return self._finish_bad_request('Bad slug type: %s' % slugtype)

    def dataset_autocomplete(self):
        q = request.params.get('incomplete', '')
        limit = request.params.get('limit', 10)
        package_dicts = []
        if q:
            context = {'model': model, 'session': model.Session,
                       'user': c.user or c.author, 'auth_user_obj': c.userobj}

            data_dict = {'q': q, 'limit': limit}

            package_dicts = get_action('package_autocomplete')(context,
                                                               data_dict)

        resultSet = {'ResultSet': {'Result': package_dicts}}
        return self._finish_ok(resultSet)

    def tag_autocomplete(self):
        q = request.params.get('incomplete', '')
        limit = request.params.get('limit', 10)
        tag_names = []
        if q:
            context = {'model': model, 'session': model.Session,
                       'user': c.user or c.author, 'auth_user_obj': c.userobj}

            data_dict = {'q': q, 'limit': limit}

            tag_names = get_action('tag_autocomplete')(context, data_dict)

        resultSet = {
            'ResultSet': {
                'Result': [{'Name': tag} for tag in tag_names]
            }
        }
        return self._finish_ok(resultSet)

    def format_autocomplete(self):
        q = request.params.get('incomplete', '')
        limit = request.params.get('limit', 5)
        formats = []
        if q:
            context = {'model': model, 'session': model.Session,
                       'user': c.user or c.author, 'auth_user_obj': c.userobj}
            data_dict = {'q': q, 'limit': limit}
            formats = get_action('format_autocomplete')(context, data_dict)

        resultSet = {
            'ResultSet': {
                'Result': [{'Format': format} for format in formats]
            }
        }
        return self._finish_ok(resultSet)

    def munge_package_name(self):
        name = request.params.get('name')
        munged_name = munge.munge_name(name)
        return self._finish_ok(munged_name)

    def munge_title_to_package_name(self):
        name = request.params.get('title') or request.params.get('name')
        munged_name = munge.munge_title_to_name(name)
        return self._finish_ok(munged_name)

    def munge_tag(self):
        tag = request.params.get('tag') or request.params.get('name')
        munged_tag = munge.munge_tag(tag)
        return self._finish_ok(munged_tag)

    def format_icon(self):
        f = request.params.get('format')
        out = {
            'format': f,
            'icon': h.icon_url(h.format_icon(f))
        }
        return self._finish_ok(out)

    def status(self):
        context = {'model': model, 'session': model.Session}
        data_dict = {}
        status = get_action('status_show')(context, data_dict)
        return self._finish_ok(status)

    def i18n_js_translations(self, lang):
        ''' translation strings for front end '''
        ckan_path = os.path.join(os.path.dirname(__file__), '..')
        source = os.path.abspath(os.path.join(ckan_path, 'public',
                                 'base', 'i18n', '%s.js' % lang))
        response.headers['Content-Type'] = CONTENT_TYPES['json']
        if not os.path.exists(source):
            return '{}'
        f = open(source, 'r')
        return(f)

    @classmethod
    def _get_request_data(cls, try_url_params=False):
        '''Returns a dictionary, extracted from a request.

        If there is no data, None or "" is returned.
        ValueError will be raised if the data is not a JSON-formatted dict.

        The data is retrieved as a JSON-encoded dictionary from the request
        body.  Or, if the `try_url_params` argument is True and the request is
        a GET request, then an attempt is made to read the data from the url
        parameters of the request.

        try_url_params
            If try_url_params is False, then the data_dict is read from the
            request body.

            If try_url_params is True and the request is a GET request then the
            data is read from the url parameters.  The resulting dict will only
            be 1 level deep, with the url-param fields being the keys.  If a
            single key has more than one value specified, then the value will
            be a list of strings, otherwise just a string.

        '''
        def make_unicode(entity):
            '''Cast bare strings and strings in lists or dicts to Unicode. '''
            if isinstance(entity, str):
                return unicode(entity)
            elif isinstance(entity, list):
                new_items = []
                for item in entity:
                    new_items.append(make_unicode(item))
                return new_items
            elif isinstance(entity, dict):
                new_dict = {}
                for key, val in entity.items():
                    new_dict[key] = make_unicode(val)
                return new_dict
            else:
                return entity

        cls.log.debug('Retrieving request params: %r' % request.params)
        cls.log.debug('Retrieving request POST: %r' % request.POST)
        cls.log.debug('Retrieving request GET: %r' % request.GET)
        request_data = None
        if request.POST and request.content_type == 'multipart/form-data':
            request_data = dict(request.POST)
        elif request.POST:
            try:
                keys = request.POST.keys()
                # Parsing breaks if there is a = in the value, so for now
                # we will check if the data is actually all in a single key
                if keys and request.POST[keys[0]] in [u'1', u'']:
                    request_data = keys[0]
                else:
                    request_data = urllib.unquote_plus(request.body)
            except Exception, inst:
                msg = "Could not find the POST data: %r : %s" % \
                      (request.POST, inst)
                raise ValueError(msg)

        elif try_url_params and request.GET:
            return request.GET.mixed()

        else:
            try:
                if request.method in ['POST', 'PUT']:
                    request_data = request.body
                else:
                    request_data = None
            except Exception, inst:
                msg = "Could not extract request body data: %s" % \
                      (inst)
                raise ValueError(msg)
            cls.log.debug('Retrieved request body: %r' % request.body)
            if not request_data:
                if not try_url_params:
                    msg = "No request body data"
                    raise ValueError(msg)
                else:
                    request_data = {}
        if request_data and request.content_type != 'multipart/form-data':
            try:
                request_data = h.json.loads(request_data, encoding='utf8')
            except ValueError, e:
                raise ValueError('Error decoding JSON data. '
                                 'Error: %r '
                                 'JSON data extracted from the request: %r' %
                                 (e, request_data))
            if not isinstance(request_data, dict):
                raise ValueError('Request data JSON decoded to %r but '
                                 'it needs to be a dictionary.' % request_data)
            # ensure unicode values
            for key, val in request_data.items():
                # if val is str then assume it is ascii, since json converts
                # utf8 encoded JSON to unicode
                request_data[key] = make_unicode(val)
        cls.log.debug('Request data extracted: %r' % request_data)
        return request_data

########NEW FILE########
__FILENAME__ = error
import cgi

from paste.urlparser import PkgResourcesParser
from pylons import request, tmpl_context as c
from pylons.controllers.util import forward
from webhelpers.html.builder import literal

from ckan.lib.base import BaseController
from ckan.lib.base import render


class ErrorController(BaseController):
    """Generates error documents as and when they are required.

    The ErrorDocuments middleware forwards to ErrorController when error
    related status codes are returned from the application.

    This behaviour can be altered by changing the parameters to the
    ErrorDocuments middleware in your config/middleware.py file.

    """

    def document(self):
        """Render the error document"""
        original_request = request.environ.get('pylons.original_request')
        original_response = request.environ.get('pylons.original_response')
        # When a request (e.g. from a web-bot) is direct, not a redirect
        # from a page. #1176
        if not original_response:
            return 'There is no error.'
        # Bypass error template for API operations.
        if original_request and original_request.path.startswith('/api'):
            return original_response.body
        # Otherwise, decorate original response with error template.
        c.content = literal(original_response.unicode_body) or \
            cgi.escape(request.GET.get('message', ''))
        c.prefix = request.environ.get('SCRIPT_NAME', ''),
        c.code = cgi.escape(request.GET.get('code',
                            str(original_response.status_int))),
        return render('error_document_template.html')

    def img(self, id):
        """Serve Pylons' stock images"""
        return self._serve_file('/'.join(['media/img', id]))

    def style(self, id):
        """Serve Pylons' stock stylesheets"""
        return self._serve_file('/'.join(['media/style', id]))

    def _serve_file(self, path):
        """Call Paste's FileApp (a WSGI application) to serve the file
        at the specified path
        """
        request.environ['PATH_INFO'] = '/%s' % path
        return forward(PkgResourcesParser('pylons', 'pylons'))

########NEW FILE########
__FILENAME__ = feed
"""
The feed controller produces Atom feeds of datasets.

 * datasets belonging to a particular group.
 * datasets tagged with a particular tag.
 * datasets that match an arbitrary search.

TODO: document paged feeds

Other feeds are available elsewhere in the code, but these provide feeds
of the revision history, rather than a feed of datasets.

 * ``ckan/controllers/group.py`` provides an atom feed of a group's
   revision history.
 * ``ckan/controllers/package.py`` provides an atom feed of a dataset's
   revision history.
 * ``ckan/controllers/revision.py`` provides an atom feed of the repository's
   revision history.

"""
# TODO fix imports
import logging
import urlparse

import webhelpers.feedgenerator
from pylons import config

import ckan.model as model
import ckan.lib.base as base
import ckan.lib.helpers as h
import ckan.logic as logic

from ckan.common import _, g, c, request, response, json

# TODO make the item list configurable
ITEMS_LIMIT = 20

log = logging.getLogger(__name__)


def _package_search(data_dict):
    """
    Helper method that wraps the package_search action.

     * unless overridden, sorts results by metadata_modified date
     * unless overridden, sets a default item limit
    """
    context = {'model': model, 'session': model.Session,
               'user': c.user or c.author, 'auth_user_obj': c.userobj}

    if 'sort' not in data_dict or not data_dict['sort']:
        data_dict['sort'] = 'metadata_modified desc'

    if 'rows' not in data_dict or not data_dict['rows']:
        data_dict['rows'] = ITEMS_LIMIT

    # package_search action modifies the data_dict, so keep our copy intact.
    query = logic.get_action('package_search')(context, data_dict.copy())

    return query['count'], query['results']


def _create_atom_id(resource_path, authority_name=None, date_string=None):
    """
    Helper method that creates an atom id for a feed or entry.

    An id must be unique, and must not change over time.  ie - once published,
    it represents an atom feed or entry uniquely, and forever.  See [4]:

        When an Atom Document is relocated, migrated, syndicated,
        republished, exported, or imported, the content of its atom:id
        element MUST NOT change.  Put another way, an atom:id element
        pertains to all instantiations of a particular Atom entry or feed;
        revisions retain the same content in their atom:id elements.  It is
        suggested that the atom:id element be stored along with the
        associated resource.

    resource_path
        The resource path that uniquely identifies the feed or element.  This
        mustn't be something that changes over time for a given entry or feed.
        And does not necessarily need to be resolvable.

        e.g. ``"/group/933f3857-79fd-4beb-a835-c0349e31ce76"`` could represent
        the feed of datasets belonging to the identified group.

    authority_name
        The domain name or email address of the publisher of the feed.  See [3]
        for more details.  If ``None`` then the domain name is taken from the
        config file.  First trying ``ckan.feeds.authority_name``, and failing
        that, it uses ``ckan.site_url``.  Again, this should not change over
        time.

    date_string
        A string representing a date on which the authority_name is owned by
        the publisher of the feed.

        e.g. ``"2012-03-22"``

        Again, this should not change over time.

        If date_string is None, then an attempt is made to read the config
        option ``ckan.feeds.date``.  If that's not available,
        then the date_string is not used in the generation of the atom id.

    Following the methods outlined in [1], [2] and [3], this function produces
    tagURIs like:
    ``"tag:thedatahub.org,2012:/group/933f3857-79fd-4beb-a835-c0349e31ce76"``.

    If not enough information is provide to produce a valid tagURI, then only
    the resource_path is used, e.g.: ::

        "http://thedatahub.org/group/933f3857-79fd-4beb-a835-c0349e31ce76"

    or

        "/group/933f3857-79fd-4beb-a835-c0349e31ce76"

    The latter of which is only used if no site_url is available.   And it
    should be noted will result in an invalid feed.

    [1] http://web.archive.org/web/20110514113830/http://diveintomark.org/\
    archives/2004/05/28/howto-atom-id
    [2] http://www.taguri.org/
    [3] http://tools.ietf.org/html/rfc4151#section-2.1
    [4] http://www.ietf.org/rfc/rfc4287
    """
    if authority_name is None:
        authority_name = config.get('ckan.feeds.authority_name', '').strip()
        if not authority_name:
            site_url = config.get('ckan.site_url', '').strip()
            authority_name = urlparse.urlparse(site_url).netloc

    if not authority_name:
        log.warning('No authority_name available for feed generation.  '
                    'Generated feed will be invalid.')

    if date_string is None:
        date_string = config.get('ckan.feeds.date', '')

    if not date_string:
        log.warning('No date_string available for feed generation.  '
                    'Please set the "ckan.feeds.date" config value.')

        # Don't generate a tagURI without a date as it wouldn't be valid.
        # This is best we can do, and if the site_url is not set, then
        # this still results in an invalid feed.
        site_url = config.get('ckan.site_url', '')
        return '/'.join([site_url, resource_path])

    tagging_entity = ','.join([authority_name, date_string])
    return ':'.join(['tag', tagging_entity, resource_path])


class FeedController(base.BaseController):
    base_url = config.get('ckan.site_url')

    def _alternate_url(self, params, **kwargs):
        search_params = params.copy()
        search_params.update(kwargs)

        # Can't count on the page sizes being the same on the search results
        # view.  So provide an alternate link to the first page, regardless
        # of the page we're looking at in the feed.
        search_params.pop('page', None)
        return self._feed_url(search_params,
                              controller='package',
                              action='search')

    def _group_or_organization(self, obj_dict, is_org):

        data_dict, params = self._parse_url_params()
        key = 'owner_org' if is_org else 'groups'
        data_dict['fq'] = '%s:"%s"' % (key, obj_dict['id'],)
        group_type = 'organization'
        if not is_org:
            group_type = 'group'

        item_count, results = _package_search(data_dict)

        navigation_urls = self._navigation_urls(params,
                                                item_count=item_count,
                                                limit=data_dict['rows'],
                                                controller='feed',
                                                action=group_type,
                                                id=obj_dict['name'])
        feed_url = self._feed_url(params,
                                  controller='feed',
                                  action=group_type,
                                  id=obj_dict['name'])

        guid = _create_atom_id(u'/feeds/group/%s.atom' %
                               obj_dict['name'])
        alternate_url = self._alternate_url(params, groups=obj_dict['name'])
        desc = u'Recently created or updated datasets on %s by group: "%s"' %\
            (g.site_title, obj_dict['title'])
        title = u'%s - Group: "%s"' %\
            (g.site_title, obj_dict['title'])

        if is_org:
            guid = _create_atom_id(u'/feeds/organization/%s.atom' %
                                   obj_dict['name'])
            alternate_url = self._alternate_url(params,
                                                organization=obj_dict['name'])
            desc = u'Recently created or  updated datasets on %s '\
                'by organization: "%s"' % (g.site_title, obj_dict['title'])
            title = u'%s - Organization: "%s"' %\
                (g.site_title, obj_dict['title'])

        return self.output_feed(results,
                                feed_title=title,
                                feed_description=desc,
                                feed_link=alternate_url,
                                feed_guid=guid,
                                feed_url=feed_url,
                                navigation_urls=navigation_urls)

    def group(self, id):
        try:
            context = {'model': model, 'session': model.Session,
                       'user': c.user or c.author, 'auth_user_obj': c.userobj}
            group_dict = logic.get_action('group_show')(context, {'id': id})
        except logic.NotFound:
            base.abort(404, _('Group not found'))

        return self._group_or_organization(group_dict, is_org=False)

    def organization(self, id):
        try:
            context = {'model': model, 'session': model.Session,
                       'user': c.user or c.author, 'auth_user_obj': c.userobj}
            group_dict = logic.get_action('organization_show')(context,
                                                               {'id': id})
        except logic.NotFound:
            base.abort(404, _('Organization not found'))

        return self._group_or_organization(group_dict, is_org=True)

    def tag(self, id):
        data_dict, params = self._parse_url_params()
        data_dict['fq'] = 'tags:"%s"' % id

        item_count, results = _package_search(data_dict)

        navigation_urls = self._navigation_urls(params,
                                                item_count=item_count,
                                                limit=data_dict['rows'],
                                                controller='feed',
                                                action='tag',
                                                id=id)

        feed_url = self._feed_url(params,
                                  controller='feed',
                                  action='tag',
                                  id=id)

        alternate_url = self._alternate_url(params, tags=id)

        return self.output_feed(results,
                                feed_title=u'%s - Tag: "%s"' %
                                (g.site_title, id),
                                feed_description=u'Recently created or '
                                'updated datasets on %s by tag: "%s"' %
                                (g.site_title, id),
                                feed_link=alternate_url,
                                feed_guid=_create_atom_id
                                (u'/feeds/tag/%s.atom' % id),
                                feed_url=feed_url,
                                navigation_urls=navigation_urls)

    def general(self):
        data_dict, params = self._parse_url_params()
        data_dict['q'] = '*:*'

        item_count, results = _package_search(data_dict)

        navigation_urls = self._navigation_urls(params,
                                                item_count=item_count,
                                                limit=data_dict['rows'],
                                                controller='feed',
                                                action='general')

        feed_url = self._feed_url(params,
                                  controller='feed',
                                  action='general')

        alternate_url = self._alternate_url(params)

        return self.output_feed(results,
                                feed_title=g.site_title,
                                feed_description=u'Recently created or '
                                'updated datasets on %s' % g.site_title,
                                feed_link=alternate_url,
                                feed_guid=_create_atom_id
                                (u'/feeds/dataset.atom'),
                                feed_url=feed_url,
                                navigation_urls=navigation_urls)

    # TODO check search params
    def custom(self):
        q = request.params.get('q', u'')
        fq = ''
        search_params = {}
        for (param, value) in request.params.items():
            if param not in ['q', 'page', 'sort'] \
                    and len(value) and not param.startswith('_'):
                search_params[param] = value
                fq += ' %s:"%s"' % (param, value)

        try:
            page = int(request.params.get('page', 1))
        except ValueError:
            base.abort(400, _('"page" parameter must be a positive integer'))
        if page < 0:
            base.abort(400, _('"page" parameter must be a positive integer'))

        limit = ITEMS_LIMIT
        data_dict = {
            'q': q,
            'fq': fq,
            'start': (page - 1) * limit,
            'rows': limit,
            'sort': request.params.get('sort', None),
        }

        item_count, results = _package_search(data_dict)

        navigation_urls = self._navigation_urls(request.params,
                                                item_count=item_count,
                                                limit=data_dict['rows'],
                                                controller='feed',
                                                action='custom')

        feed_url = self._feed_url(request.params,
                                  controller='feed',
                                  action='custom')

        atom_url = h._url_with_params('/feeds/custom.atom',
                                      search_params.items())

        alternate_url = self._alternate_url(request.params)

        return self.output_feed(results,
                                feed_title=u'%s - Custom query' % g.site_title,
                                feed_description=u'Recently created or updated'
                                ' datasets on %s. Custom query: \'%s\'' %
                                (g.site_title, q),
                                feed_link=alternate_url,
                                feed_guid=_create_atom_id(atom_url),
                                feed_url=feed_url,
                                navigation_urls=navigation_urls)

    def output_feed(self, results, feed_title, feed_description,
                    feed_link, feed_url, navigation_urls, feed_guid):
        author_name = config.get('ckan.feeds.author_name', '').strip() or \
            config.get('ckan.site_id', '').strip()
        author_link = config.get('ckan.feeds.author_link', '').strip() or \
            config.get('ckan.site_url', '').strip()

        # TODO language
        feed = _FixedAtom1Feed(
            title=feed_title,
            link=feed_link,
            description=feed_description,
            language=u'en',
            author_name=author_name,
            author_link=author_link,
            feed_guid=feed_guid,
            feed_url=feed_url,
            previous_page=navigation_urls['previous'],
            next_page=navigation_urls['next'],
            first_page=navigation_urls['first'],
            last_page=navigation_urls['last'],
        )

        for pkg in results:
            feed.add_item(
                title=pkg.get('title', ''),
                link=self.base_url + h.url_for(controller='package',
                                               action='read',
                                               id=pkg['id']),
                description=pkg.get('notes', ''),
                updated=h.date_str_to_datetime(pkg.get('metadata_modified')),
                published=h.date_str_to_datetime(pkg.get('metadata_created')),
                unique_id=_create_atom_id(u'/dataset/%s' % pkg['id']),
                author_name=pkg.get('author', ''),
                author_email=pkg.get('author_email', ''),
                categories=[t['name'] for t in pkg.get('tags', [])],
                enclosure=webhelpers.feedgenerator.Enclosure(
                    self.base_url + h.url_for(controller='api',
                                              register='package',
                                              action='show',
                                              id=pkg['name'],
                                              ver='2'),
                    unicode(len(json.dumps(pkg))),   # TODO fix this
                    u'application/json')
            )
        response.content_type = feed.mime_type
        return feed.writeString('utf-8')

    #### CLASS PRIVATE METHODS ####

    def _feed_url(self, query, controller, action, **kwargs):
        """
        Constructs the url for the given action.  Encoding the query
        parameters.
        """
        path = h.url_for(controller=controller, action=action, **kwargs)
        return h._url_with_params(self.base_url + path, query.items())

    def _navigation_urls(self, query, controller, action,
                         item_count, limit, **kwargs):
        """
        Constructs and returns first, last, prev and next links for paging
        """
        urls = dict((rel, None) for rel in 'previous next first last'.split())

        page = int(query.get('page', 1))

        # first: remove any page parameter
        first_query = query.copy()
        first_query.pop('page', None)
        urls['first'] = self._feed_url(first_query, controller,
                                       action, **kwargs)

        # last: add last page parameter
        last_page = (item_count / limit) + min(1, item_count % limit)
        last_query = query.copy()
        last_query['page'] = last_page
        urls['last'] = self._feed_url(last_query, controller,
                                      action, **kwargs)

        # previous
        if page > 1:
            previous_query = query.copy()
            previous_query['page'] = page - 1
            urls['previous'] = self._feed_url(previous_query, controller,
                                              action, **kwargs)
        else:
            urls['previous'] = None

        # next
        if page < last_page:
            next_query = query.copy()
            next_query['page'] = page + 1
            urls['next'] = self._feed_url(next_query, controller,
                                          action, **kwargs)
        else:
            urls['next'] = None

        return urls

    def _parse_url_params(self):
        """
        Constructs a search-query dict from the URL query parameters.

        Returns the constructed search-query dict, and the valid URL
        query parameters.
        """
        try:
            page = int(request.params.get('page', 1)) or 1
        except ValueError:
            base.abort(400, _('"page" parameter must be a positive integer'))
        if page < 0:
            base.abort(400, _('"page" parameter must be a positive integer'))

        limit = ITEMS_LIMIT
        data_dict = {
            'start': (page - 1) * limit,
            'rows': limit
        }

        # Filter ignored query parameters
        valid_params = ['page']
        params = dict((p, request.params.get(p)) for p in valid_params
                      if p in request.params)
        return data_dict, params


# TODO paginated feed
class _FixedAtom1Feed(webhelpers.feedgenerator.Atom1Feed):
    """
    The Atom1Feed defined in webhelpers doesn't provide all the fields we
    might want to publish.

     * In Atom1Feed, each <entry> is created with identical <updated> and
       <published> fields.  See [1] (webhelpers 1.2) for details.

       So, this class fixes that by allow an item to set both an <updated> and
       <published> field.

     * In Atom1Feed, the feed description is not used.  So this class uses the
       <subtitle> field to publish that.

       [1] https://bitbucket.org/bbangert/webhelpers/src/f5867a319abf/\
       webhelpers/feedgenerator.py#cl-373
    """

    def add_item(self, *args, **kwargs):
        """
        Drop the pubdate field from the new item.
        """
        if 'pubdate' in kwargs:
            kwargs.pop('pubdate')
        defaults = {'updated': None, 'published': None}
        defaults.update(kwargs)
        super(_FixedAtom1Feed, self).add_item(*args, **defaults)

    def latest_post_date(self):
        """
        Calculates the latest post date from the 'updated' fields,
        rather than the 'pubdate' fields.
        """
        updates = [item['updated'] for item in self.items
                   if item['updated'] is not None]
        if not len(updates):  # delegate to parent for default behaviour
            return super(_FixedAtom1Feed, self).latest_post_date()
        return max(updates)

    def add_item_elements(self, handler, item):
        """
        Add the <updated> and <published> fields to each entry that's written
        to the handler.
        """
        super(_FixedAtom1Feed, self).add_item_elements(handler, item)

        dfunc = webhelpers.feedgenerator.rfc3339_date

        if(item['updated']):
            handler.addQuickElement(u'updated',
                                    dfunc(item['updated']).decode('utf-8'))

        if(item['published']):
            handler.addQuickElement(u'published',
                                    dfunc(item['published']).decode('utf-8'))

    def add_root_elements(self, handler):
        """
        Add additional feed fields.

         * Add the <subtitle> field from the feed description
         * Add links other pages of the logical feed.
        """
        super(_FixedAtom1Feed, self).add_root_elements(handler)

        handler.addQuickElement(u'subtitle', self.feed['description'])

        for page in ['previous', 'next', 'first', 'last']:
            if self.feed.get(page + '_page', None):
                handler.addQuickElement(u'link', u'',
                                        {'rel': page,
                                         'href':
                                            self.feed.get(page + '_page')})

########NEW FILE########
__FILENAME__ = group
import re
import os
import logging
import genshi
import cgi
import datetime
from urllib import urlencode

from pylons.i18n import get_lang

import ckan.lib.base as base
import ckan.lib.helpers as h
import ckan.lib.maintain as maintain
import ckan.lib.navl.dictization_functions as dict_fns
import ckan.logic as logic
import ckan.lib.search as search
import ckan.model as model
import ckan.new_authz as new_authz
import ckan.lib.plugins
import ckan.plugins as plugins
from ckan.common import OrderedDict, c, g, request, _

log = logging.getLogger(__name__)

render = base.render
abort = base.abort

NotFound = logic.NotFound
NotAuthorized = logic.NotAuthorized
ValidationError = logic.ValidationError
check_access = logic.check_access
get_action = logic.get_action
tuplize_dict = logic.tuplize_dict
clean_dict = logic.clean_dict
parse_params = logic.parse_params

lookup_group_plugin = ckan.lib.plugins.lookup_group_plugin


class GroupController(base.BaseController):

    group_type = 'group'

    ## hooks for subclasses

    def _group_form(self, group_type=None):
        return lookup_group_plugin(group_type).group_form()

    def _form_to_db_schema(self, group_type=None):
        return lookup_group_plugin(group_type).form_to_db_schema()

    def _db_to_form_schema(self, group_type=None):
        '''This is an interface to manipulate data from the database
        into a format suitable for the form (optional)'''
        return lookup_group_plugin(group_type).db_to_form_schema()

    def _setup_template_variables(self, context, data_dict, group_type=None):
        return lookup_group_plugin(group_type).\
            setup_template_variables(context, data_dict)

    def _new_template(self, group_type):
        return lookup_group_plugin(group_type).new_template()

    def _index_template(self, group_type):
        return lookup_group_plugin(group_type).index_template()

    def _about_template(self, group_type):
        return lookup_group_plugin(group_type).about_template()

    def _read_template(self, group_type):
        return lookup_group_plugin(group_type).read_template()

    def _history_template(self, group_type):
        return lookup_group_plugin(group_type).history_template()

    def _edit_template(self, group_type):
        return lookup_group_plugin(group_type).edit_template()

    def _activity_template(self, group_type):
        return lookup_group_plugin(group_type).activity_template()

    def _admins_template(self, group_type):
        return lookup_group_plugin(group_type).admins_template()

    def _bulk_process_template(self, group_type):
        return lookup_group_plugin(group_type).bulk_process_template()

    ## end hooks
    def _replace_group_org(self, string):
        ''' substitute organization for group if this is an org'''
        if self.group_type == 'organization':
            string = re.sub('^group', 'organization', string)
        return string

    def _action(self, action_name):
        ''' select the correct group/org action '''
        return get_action(self._replace_group_org(action_name))

    def _check_access(self, action_name, *args, **kw):
        ''' select the correct group/org check_access '''
        return check_access(self._replace_group_org(action_name), *args, **kw)

    def _render_template(self, template_name):
        ''' render the correct group/org template '''
        return render(self._replace_group_org(template_name))

    def _redirect_to(self, *args, **kw):
        ''' wrapper to ensue the correct controller is used '''
        if self.group_type == 'organization' and 'controller' in kw:
            kw['controller'] = 'organization'
        return h.redirect_to(*args, **kw)

    def _url_for(self, *args, **kw):
        ''' wrapper to ensue the correct controller is used '''
        if self.group_type == 'organization' and 'controller' in kw:
            kw['controller'] = 'organization'
        return h.url_for(*args, **kw)

    def _guess_group_type(self, expecting_name=False):
        """
            Guess the type of group from the URL handling the case
            where there is a prefix on the URL (such as /data/organization)
        """
        parts = [x for x in request.path.split('/') if x]

        idx = -1
        if expecting_name:
            idx = -2

        gt = parts[idx]
        if gt == 'group':
            gt = None

        return gt

    def index(self):
        group_type = self._guess_group_type()

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'for_view': True,
                   'with_private': False}

        q = c.q = request.params.get('q', '')
        data_dict = {'all_fields': True, 'q': q}
        sort_by = c.sort_by_selected = request.params.get('sort')
        if sort_by:
            data_dict['sort'] = sort_by
        try:
            self._check_access('site_read', context)
        except NotAuthorized:
            abort(401, _('Not authorized to see this page'))

        # pass user info to context as needed to view private datasets of
        # orgs correctly
        if c.userobj:
            context['user_id'] = c.userobj.id
            context['user_is_admin'] = c.userobj.sysadmin

        results = self._action('group_list')(context, data_dict)

        c.page = h.Page(
            collection=results,
            page=request.params.get('page', 1),
            url=h.pager_url,
            items_per_page=21
        )
        return render(self._index_template(group_type))

    def read(self, id, limit=20):
        group_type = self._get_group_type(id.split('@')[0])
        if group_type != self.group_type:
            abort(404, _('Incorrect group type'))

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author,
                   'schema': self._db_to_form_schema(group_type=group_type),
                   'for_view': True}
        data_dict = {'id': id}

        # unicode format (decoded from utf8)
        q = c.q = request.params.get('q', '')

        try:
            # Do not query for the group datasets when dictizing, as they will
            # be ignored and get requested on the controller anyway
            context['include_datasets'] = False
            c.group_dict = self._action('group_show')(context, data_dict)
            c.group = context['group']
        except NotFound:
            abort(404, _('Group not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read group %s') % id)

        self._read(id, limit)
        return render(self._read_template(c.group_dict['type']))

    def _read(self, id, limit):
        ''' This is common code used by both read and bulk_process'''
        group_type = self._get_group_type(id.split('@')[0])
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author,
                   'schema': self._db_to_form_schema(group_type=group_type),
                   'for_view': True, 'extras_as_string': True}

        q = c.q = request.params.get('q', '')
        # Search within group
        if c.group_dict.get('is_organization'):
            q += ' owner_org:"%s"' % c.group_dict.get('id')
        else:
            q += ' groups:"%s"' % c.group_dict.get('name')

        c.description_formatted = h.render_markdown(c.group_dict.get('description'))

        context['return_query'] = True

        # c.group_admins is used by CKAN's legacy (Genshi) templates only,
        # if we drop support for those then we can delete this line.
        c.group_admins = new_authz.get_group_or_org_admin_ids(c.group.id)

        try:
            page = int(request.params.get('page', 1))
        except ValueError, e:
            abort(400, ('"page" parameter must be an integer'))

        # most search operations should reset the page counter:
        params_nopage = [(k, v) for k, v in request.params.items()
                         if k != 'page']
        #sort_by = request.params.get('sort', 'name asc')
        sort_by = request.params.get('sort', None)

        def search_url(params):
            if group_type == 'organization':
                if c.action == 'bulk_process':
                    url = self._url_for(controller='organization',
                                        action='bulk_process',
                                        id=id)
                else:
                    url = self._url_for(controller='organization',
                                        action='read',
                                        id=id)
            else:
                url = self._url_for(controller='group', action='read', id=id)
            params = [(k, v.encode('utf-8') if isinstance(v, basestring)
                       else str(v)) for k, v in params]
            return url + u'?' + urlencode(params)

        def drill_down_url(**by):
            return h.add_url_param(alternative_url=None,
                                   controller='group', action='read',
                                   extras=dict(id=c.group_dict.get('name')),
                                   new_params=by)

        c.drill_down_url = drill_down_url

        def remove_field(key, value=None, replace=None):
            return h.remove_url_param(key, value=value, replace=replace,
                                      controller='group', action='read',
                                      extras=dict(id=c.group_dict.get('name')))

        c.remove_field = remove_field

        def pager_url(q=None, page=None):
            params = list(params_nopage)
            params.append(('page', page))
            return search_url(params)

        try:
            c.fields = []
            search_extras = {}
            for (param, value) in request.params.items():
                if not param in ['q', 'page', 'sort'] \
                        and len(value) and not param.startswith('_'):
                    if not param.startswith('ext_'):
                        c.fields.append((param, value))
                        q += ' %s: "%s"' % (param, value)
                    else:
                        search_extras[param] = value

            fq = 'capacity:"public"'
            user_member_of_orgs = [org['id'] for org
                                   in h.organizations_available('read')]

            if (c.group and c.group.id in user_member_of_orgs):
                fq = ''
                context['ignore_capacity_check'] = True

            facets = OrderedDict()

            default_facet_titles = {'organization': _('Organizations'),
                                    'groups': _('Groups'),
                                    'tags': _('Tags'),
                                    'res_format': _('Formats'),
                                    'license_id': _('Licenses')}

            for facet in g.facets:
                if facet in default_facet_titles:
                    facets[facet] = default_facet_titles[facet]
                else:
                    facets[facet] = facet

            # Facet titles
            for plugin in plugins.PluginImplementations(plugins.IFacets):
                if self.group_type == 'organization':
                    facets = plugin.organization_facets(
                        facets, self.group_type, None)
                else:
                    facets = plugin.group_facets(
                        facets, self.group_type, None)

            if 'capacity' in facets and (self.group_type != 'organization' or
                                         not user_member_of_orgs):
                del facets['capacity']

            c.facet_titles = facets

            data_dict = {
                'q': q,
                'fq': fq,
                'facet.field': facets.keys(),
                'rows': limit,
                'sort': sort_by,
                'start': (page - 1) * limit,
                'extras': search_extras
            }

            context_ = dict((k, v) for (k, v) in context.items() if k != 'schema')
            query = get_action('package_search')(context_, data_dict)

            c.page = h.Page(
                collection=query['results'],
                page=page,
                url=pager_url,
                item_count=query['count'],
                items_per_page=limit
            )

            c.group_dict['package_count'] = query['count']
            c.facets = query['facets']
            maintain.deprecate_context_item('facets',
                                            'Use `c.search_facets` instead.')

            c.search_facets = query['search_facets']
            c.search_facets_limits = {}
            for facet in c.facets.keys():
                limit = int(request.params.get('_%s_limit' % facet,
                                               g.facets_default_number))
                c.search_facets_limits[facet] = limit
            c.page.items = query['results']

            c.sort_by_selected = sort_by

        except search.SearchError, se:
            log.error('Group search error: %r', se.args)
            c.query_error = True
            c.facets = {}
            c.page = h.Page(collection=[])

        self._setup_template_variables(context, {'id':id},
            group_type=group_type)

    def bulk_process(self, id):
        ''' Allow bulk processing of datasets for an organization.  Make
        private/public or delete. For organization admins.'''

        group_type = self._get_group_type(id.split('@')[0])

        if group_type != 'organization':
            # FIXME: better error
            raise Exception('Must be an organization')

        # check we are org admin

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author,
                   'schema': self._db_to_form_schema(group_type=group_type),
                   'for_view': True, 'extras_as_string': True}
        data_dict = {'id': id}

        try:
            # Do not query for the group datasets when dictizing, as they will
            # be ignored and get requested on the controller anyway
            context['include_datasets'] = False
            c.group_dict = self._action('group_show')(context, data_dict)
            c.group = context['group']
        except NotFound:
            abort(404, _('Group not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read group %s') % id)

        #use different form names so that ie7 can be detected
        form_names = set(["bulk_action.public", "bulk_action.delete",
                          "bulk_action.private"])
        actions_in_form = set(request.params.keys())
        actions = form_names.intersection(actions_in_form)
        # If no action then just show the datasets
        if not actions:
            # unicode format (decoded from utf8)
            limit = 500
            self._read(id, limit)
            c.packages = c.page.items
            return render(self._bulk_process_template(group_type))

        #ie7 puts all buttons in form params but puts submitted one twice
        for key, value in dict(request.params.dict_of_lists()).items():
            if len(value) == 2:
                action = key.split('.')[-1]
                break
        else:
            #normal good browser form submission
            action = actions.pop().split('.')[-1]

        # process the action first find the datasets to perform the action on.
        # they are prefixed by dataset_ in the form data
        datasets = []
        for param in request.params:
            if param.startswith('dataset_'):
                datasets.append(param[8:])

        action_functions = {
            'private': 'bulk_update_private',
            'public': 'bulk_update_public',
            'delete': 'bulk_update_delete',
        }

        data_dict = {'datasets': datasets, 'org_id': c.group_dict['id']}

        try:
            get_action(action_functions[action])(context, data_dict)
        except NotAuthorized:
            abort(401, _('Not authorized to perform bulk update'))
        base.redirect(h.url_for(controller='organization',
                                action='bulk_process',
                                id=id))

    def new(self, data=None, errors=None, error_summary=None):
        group_type = self._guess_group_type(True)
        if data:
            data['type'] = group_type

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author,
                   'save': 'save' in request.params,
                   'parent': request.params.get('parent', None)}
        try:
            self._check_access('group_create', context)
        except NotAuthorized:
            abort(401, _('Unauthorized to create a group'))

        if context['save'] and not data:
            return self._save_new(context, group_type)

        data = data or {}
        if not data.get('image_url', '').startswith('http'):
            data.pop('image_url', None)

        errors = errors or {}
        error_summary = error_summary or {}
        vars = {'data': data, 'errors': errors,
                'error_summary': error_summary, 'action': 'new'}

        self._setup_template_variables(context, data, group_type=group_type)
        c.form = render(self._group_form(group_type=group_type),
                        extra_vars=vars)
        return render(self._new_template(group_type))

    def edit(self, id, data=None, errors=None, error_summary=None):
        group_type = self._get_group_type(id.split('@')[0])
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author,
                   'save': 'save' in request.params,
                   'for_edit': True,
                   'parent': request.params.get('parent', None)
                   }
        data_dict = {'id': id}

        if context['save'] and not data:
            return self._save_edit(id, context)

        try:
            old_data = self._action('group_show')(context, data_dict)
            c.grouptitle = old_data.get('title')
            c.groupname = old_data.get('name')
            data = data or old_data
        except NotFound:
            abort(404, _('Group not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read group %s') % '')

        group = context.get("group")
        c.group = group
        c.group_dict = self._action('group_show')(context, data_dict)

        try:
            self._check_access('group_update', context)
        except NotAuthorized, e:
            abort(401, _('User %r not authorized to edit %s') % (c.user, id))

        errors = errors or {}
        vars = {'data': data, 'errors': errors,
                'error_summary': error_summary, 'action': 'edit'}

        self._setup_template_variables(context, data, group_type=group_type)
        c.form = render(self._group_form(group_type), extra_vars=vars)
        return render(self._edit_template(c.group.type))

    def _get_group_type(self, id):
        """
        Given the id of a group it determines the type of a group given
        a valid id/name for the group.
        """
        group = model.Group.get(id)
        if not group:
            return None
        return group.type

    def _save_new(self, context, group_type=None):
        try:
            data_dict = clean_dict(dict_fns.unflatten(
                tuplize_dict(parse_params(request.params))))
            data_dict['type'] = group_type or 'group'
            context['message'] = data_dict.get('log_message', '')
            data_dict['users'] = [{'name': c.user, 'capacity': 'admin'}]
            group = self._action('group_create')(context, data_dict)

            # Redirect to the appropriate _read route for the type of group
            h.redirect_to(group['type'] + '_read', id=group['name'])
        except NotAuthorized:
            abort(401, _('Unauthorized to read group %s') % '')
        except NotFound, e:
            abort(404, _('Group not found'))
        except dict_fns.DataError:
            abort(400, _(u'Integrity Error'))
        except ValidationError, e:
            errors = e.error_dict
            error_summary = e.error_summary
            return self.new(data_dict, errors, error_summary)

    def _force_reindex(self, grp):
        ''' When the group name has changed, we need to force a reindex
        of the datasets within the group, otherwise they will stop
        appearing on the read page for the group (as they're connected via
        the group name)'''
        group = model.Group.get(grp['name'])
        for dataset in group.packages():
            search.rebuild(dataset.name)

    def _save_edit(self, id, context):
        try:
            data_dict = clean_dict(dict_fns.unflatten(
                tuplize_dict(parse_params(request.params))))
            context['message'] = data_dict.get('log_message', '')
            data_dict['id'] = id
            context['allow_partial_update'] = True
            group = self._action('group_update')(context, data_dict)
            if id != group['name']:
                self._force_reindex(group)

            h.redirect_to('%s_read' % group['type'], id=group['name'])
        except NotAuthorized:
            abort(401, _('Unauthorized to read group %s') % id)
        except NotFound, e:
            abort(404, _('Group not found'))
        except dict_fns.DataError:
            abort(400, _(u'Integrity Error'))
        except ValidationError, e:
            errors = e.error_dict
            error_summary = e.error_summary
            return self.edit(id, data_dict, errors, error_summary)

    def authz(self, id):
        group = model.Group.get(id)
        if group is None:
            abort(404, _('Group not found'))
        c.groupname = group.name
        c.grouptitle = group.display_name

        try:
            context = \
                {'model': model, 'user': c.user or c.author, 'group': group}
            self._check_access('group_edit_permissions', context)
            c.authz_editable = True
            c.group = context['group']
        except NotAuthorized:
            c.authz_editable = False
        if not c.authz_editable:
            abort(401,
                  _('User %r not authorized to edit %s authorizations') %
                   (c.user, id))

        roles = self._handle_update_of_authz(group)
        self._prepare_authz_info_for_render(roles)
        return render('group/authz.html')

    def delete(self, id):
        if 'cancel' in request.params:
            self._redirect_to(controller='group', action='edit', id=id)

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author}

        try:
            self._check_access('group_delete', context, {'id': id})
        except NotAuthorized:
            abort(401, _('Unauthorized to delete group %s') % '')

        try:
            if request.method == 'POST':
                self._action('group_delete')(context, {'id': id})
                if self.group_type == 'organization':
                    h.flash_notice(_('Organization has been deleted.'))
                else:
                    h.flash_notice(_('Group has been deleted.'))
                self._redirect_to(controller='group', action='index')
            c.group_dict = self._action('group_show')(context, {'id': id})
        except NotAuthorized:
            abort(401, _('Unauthorized to delete group %s') % '')
        except NotFound:
            abort(404, _('Group not found'))
        return self._render_template('group/confirm_delete.html')

    def members(self, id):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author}

        try:
            c.members = self._action('member_list')(
                context, {'id': id, 'object_type': 'user'}
            )
            c.group_dict = self._action('group_show')(context, {'id': id})
        except NotAuthorized:
            abort(401, _('Unauthorized to delete group %s') % '')
        except NotFound:
            abort(404, _('Group not found'))
        return self._render_template('group/members.html')

    def member_new(self, id):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author}

        #self._check_access('group_delete', context, {'id': id})
        try:
            if request.method == 'POST':
                data_dict = clean_dict(dict_fns.unflatten(
                    tuplize_dict(parse_params(request.params))))
                data_dict['id'] = id

                email = data_dict.get('email')
                if email:
                    user_data_dict = {
                        'email': email,
                        'group_id': data_dict['id'],
                        'role': data_dict['role']
                    }
                    del data_dict['email']
                    user_dict = self._action('user_invite')(context,
                            user_data_dict)
                    data_dict['username'] = user_dict['name']

                c.group_dict = self._action('group_member_create')(context, data_dict)
                self._redirect_to(controller='group', action='members', id=id)
            else:
                user = request.params.get('user')
                if user:
                    c.user_dict = get_action('user_show')(context, {'id': user})
                    c.user_role = new_authz.users_role_for_group_or_org(id, user) or 'member'
                else:
                    c.user_role = 'member'
                c.group_dict = self._action('group_show')(context, {'id': id})
                group_type = 'organization' if c.group_dict['is_organization'] else 'group'
                c.roles = self._action('member_roles_list')(
                    context, {'group_type': group_type}
                )
        except NotAuthorized:
            abort(401, _('Unauthorized to add member to group %s') % '')
        except NotFound:
            abort(404, _('Group not found'))
        except ValidationError, e:
            h.flash_error(e.error_summary)
        return self._render_template('group/member_new.html')

    def member_delete(self, id):
        if 'cancel' in request.params:
            self._redirect_to(controller='group', action='members', id=id)

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author}

        try:
            self._check_access('group_member_delete', context, {'id': id})
        except NotAuthorized:
            abort(401, _('Unauthorized to delete group %s members') % '')

        try:
            user_id = request.params.get('user')
            if request.method == 'POST':
                self._action('group_member_delete')(context, {'id': id, 'user_id': user_id})
                h.flash_notice(_('Group member has been deleted.'))
                self._redirect_to(controller='group', action='members', id=id)
            c.user_dict = self._action('user_show')(context, {'id': user_id})
            c.user_id = user_id
            c.group_id = id
        except NotAuthorized:
            abort(401, _('Unauthorized to delete group %s') % '')
        except NotFound:
            abort(404, _('Group not found'))
        return self._render_template('group/confirm_delete_member.html')

    def history(self, id):
        if 'diff' in request.params or 'selected1' in request.params:
            try:
                params = {'id': request.params.getone('group_name'),
                          'diff': request.params.getone('selected1'),
                          'oldid': request.params.getone('selected2'),
                          }
            except KeyError, e:
                if 'group_name' in dict(request.params):
                    id = request.params.getone('group_name')
                c.error = \
                    _('Select two revisions before doing the comparison.')
            else:
                params['diff_entity'] = 'group'
                h.redirect_to(controller='revision', action='diff', **params)

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author,
                   'schema': self._db_to_form_schema()}
        data_dict = {'id': id}
        try:
            c.group_dict = self._action('group_show')(context, data_dict)
            c.group_revisions = self._action('group_revision_list')(context,
                                                                    data_dict)
            #TODO: remove
            # Still necessary for the authz check in group/layout.html
            c.group = context['group']
        except NotFound:
            abort(404, _('Group not found'))
        except NotAuthorized:
            abort(401, _('User %r not authorized to edit %r') % (c.user, id))

        format = request.params.get('format', '')
        if format == 'atom':
            # Generate and return Atom 1.0 document.
            from webhelpers.feedgenerator import Atom1Feed
            feed = Atom1Feed(
                title=_(u'CKAN Group Revision History'),
                link=self._url_for(controller='group', action='read',
                                   id=c.group_dict['name']),
                description=_(u'Recent changes to CKAN Group: ') +
                c.group_dict['display_name'],
                language=unicode(get_lang()),
            )
            for revision_dict in c.group_revisions:
                revision_date = h.date_str_to_datetime(
                    revision_dict['timestamp'])
                try:
                    dayHorizon = int(request.params.get('days'))
                except:
                    dayHorizon = 30
                dayAge = (datetime.datetime.now() - revision_date).days
                if dayAge >= dayHorizon:
                    break
                if revision_dict['message']:
                    item_title = u'%s' % revision_dict['message'].\
                        split('\n')[0]
                else:
                    item_title = u'%s' % revision_dict['id']
                item_link = h.url_for(controller='revision', action='read',
                                      id=revision_dict['id'])
                item_description = _('Log message: ')
                item_description += '%s' % (revision_dict['message'] or '')
                item_author_name = revision_dict['author']
                item_pubdate = revision_date
                feed.add_item(
                    title=item_title,
                    link=item_link,
                    description=item_description,
                    author_name=item_author_name,
                    pubdate=item_pubdate,
                )
            feed.content_type = 'application/atom+xml'
            return feed.writeString('utf-8')
        return render(self._history_template(c.group_dict['type']))

    def activity(self, id, offset=0):
        '''Render this group's public activity stream page.'''

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'for_view': True}
        try:
            c.group_dict = self._get_group_dict(id)
        except NotFound:
            abort(404, _('Group not found'))
        except NotAuthorized:
            abort(401,
                  _('Unauthorized to read group {group_id}').format(
                      group_id=id))

        # Add the group's activity stream (already rendered to HTML) to the
        # template context for the group/read.html template to retrieve later.
        c.group_activity_stream = self._action('group_activity_list_html')(
            context, {'id': c.group_dict['id'], 'offset': offset})

        return render(self._activity_template(c.group_dict['type']))

    def follow(self, id):
        '''Start following this group.'''
        context = {'model': model,
                   'session': model.Session,
                   'user': c.user or c.author}
        data_dict = {'id': id}
        try:
            get_action('follow_group')(context, data_dict)
            group_dict = get_action('group_show')(context, data_dict)
            h.flash_success(_("You are now following {0}").format(
                group_dict['title']))
        except ValidationError as e:
            error_message = (e.extra_msg or e.message or e.error_summary
                             or e.error_dict)
            h.flash_error(error_message)
        except NotAuthorized as e:
            h.flash_error(e.extra_msg)
        h.redirect_to(controller='group', action='read', id=id)

    def unfollow(self, id):
        '''Stop following this group.'''
        context = {'model': model,
                   'session': model.Session,
                   'user': c.user or c.author}
        data_dict = {'id': id}
        try:
            get_action('unfollow_group')(context, data_dict)
            group_dict = get_action('group_show')(context, data_dict)
            h.flash_success(_("You are no longer following {0}").format(
                group_dict['title']))
        except ValidationError as e:
            error_message = (e.extra_msg or e.message or e.error_summary
                             or e.error_dict)
            h.flash_error(error_message)
        except (NotFound, NotAuthorized) as e:
            error_message = e.extra_msg or e.message
            h.flash_error(error_message)
        h.redirect_to(controller='group', action='read', id=id)

    def followers(self, id):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author}
        c.group_dict = self._get_group_dict(id)
        try:
            c.followers = get_action('group_follower_list')(context, {'id': id})
        except NotAuthorized:
            abort(401, _('Unauthorized to view followers %s') % '')
        return render('group/followers.html')

    def admins(self, id):
        c.group_dict = self._get_group_dict(id)
        c.admins = new_authz.get_group_or_org_admin_ids(id)
        return render(self._admins_template(c.group_dict['type']))

    def about(self, id):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author}
        c.group_dict = self._get_group_dict(id)
        group_type = c.group_dict['type']
        self._setup_template_variables(context, {'id': id},
                                       group_type=group_type)
        return render(self._about_template(group_type))

    def _get_group_dict(self, id):
        ''' returns the result of group_show action or aborts if there is a
        problem '''
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author,
                   'for_view': True}
        try:
            return self._action('group_show')(context, {'id': id})
        except NotFound:
            abort(404, _('Group not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read group %s') % id)

    def _render_edit_form(self, fs):
        # errors arrive in c.error and fs.errors
        c.fieldset = fs
        return render('group/edit_form.html')

    def _update(self, fs, group_name, group_id):
        '''
        Writes the POST data (associated with a group edit) to the database
        @input c.error
        '''
        validation = fs.validate()
        if not validation:
            c.form = self._render_edit_form(fs)
            raise base.ValidationException(fs)

        try:
            fs.sync()
        except Exception, inst:
            model.Session.rollback()
            raise
        else:
            model.Session.commit()

    def _update_authz(self, fs):
        validation = fs.validate()
        if not validation:
            c.form = self._render_edit_form(fs)
            raise base.ValidationException(fs)
        try:
            fs.sync()
        except Exception, inst:
            model.Session.rollback()
            raise
        else:
            model.Session.commit()

########NEW FILE########
__FILENAME__ = home
from pylons import config, cache
import sqlalchemy.exc

import ckan.logic as logic
import ckan.lib.maintain as maintain
import ckan.lib.search as search
import ckan.lib.base as base
import ckan.model as model
import ckan.lib.helpers as h

from ckan.common import _, g, c

CACHE_PARAMETERS = ['__cache', '__no_cache__']

# horrible hack
dirty_cached_group_stuff = None


class HomeController(base.BaseController):
    repo = model.repo

    def __before__(self, action, **env):
        try:
            base.BaseController.__before__(self, action, **env)
            context = {'model': model, 'user': c.user or c.author,
                       'auth_user_obj': c.userobj}
            logic.check_access('site_read', context)
        except logic.NotAuthorized:
            base.abort(401, _('Not authorized to see this page'))
        except (sqlalchemy.exc.ProgrammingError,
                sqlalchemy.exc.OperationalError), e:
            # postgres and sqlite errors for missing tables
            msg = str(e)
            if ('relation' in msg and 'does not exist' in msg) or \
                    ('no such table' in msg):
                # table missing, major database problem
                base.abort(503, _('This site is currently off-line. Database '
                                  'is not initialised.'))
                # TODO: send an email to the admin person (#1285)
            else:
                raise

    def index(self):
        try:
            # package search
            context = {'model': model, 'session': model.Session,
                       'user': c.user or c.author, 'auth_user_obj': c.userobj}
            data_dict = {
                'q': '*:*',
                'facet.field': g.facets,
                'rows': 4,
                'start': 0,
                'sort': 'views_recent desc',
                'fq': 'capacity:"public"'
            }
            query = logic.get_action('package_search')(
                context, data_dict)
            c.search_facets = query['search_facets']
            c.package_count = query['count']
            c.datasets = query['results']

            c.facets = query['facets']
            maintain.deprecate_context_item(
                'facets',
                'Use `c.search_facets` instead.')

            c.search_facets = query['search_facets']

            c.facet_titles = {
                'organization': _('Organizations'),
                'groups': _('Groups'),
                'tags': _('Tags'),
                'res_format': _('Formats'),
                'license': _('Licenses'),
            }

            data_dict = {'sort': 'packages', 'all_fields': 1}
            # only give the terms to group dictize that are returned in the
            # facets as full results take a lot longer
            if 'groups' in c.search_facets:
                data_dict['groups'] = [
                    item['name'] for item in c.search_facets['groups']['items']
                ]
            c.groups = logic.get_action('group_list')(context, data_dict)
        except search.SearchError:
            c.package_count = 0
            c.groups = []

        if c.userobj is not None:
            msg = None
            url = h.url_for(controller='user', action='edit')
            is_google_id = \
                c.userobj.name.startswith(
                    'https://www.google.com/accounts/o8/id')
            if not c.userobj.email and (is_google_id and
                                        not c.userobj.fullname):
                msg = _(u'Please <a href="{link}">update your profile</a>'
                        u' and add your email address and your full name. '
                        u'{site} uses your email address'
                        u' if you need to reset your password.'.format(
                            link=url, site=g.site_title))
            elif not c.userobj.email:
                msg = _('Please <a href="%s">update your profile</a>'
                        ' and add your email address. ') % url + \
                    _('%s uses your email address'
                        ' if you need to reset your password.') \
                    % g.site_title
            elif is_google_id and not c.userobj.fullname:
                msg = _('Please <a href="%s">update your profile</a>'
                        ' and add your full name.') % (url)
            if msg:
                h.flash_notice(msg, allow_html=True)

        # START OF DIRTYNESS
        def get_group(id):
            def _get_group_type(id):
                """
                Given the id of a group it determines the type of a group given
                a valid id/name for the group.
                """
                group = model.Group.get(id)
                if not group:
                    return None
                return group.type

            def db_to_form_schema(group_type=None):
                from ckan.lib.plugins import lookup_group_plugin
                return lookup_group_plugin(group_type).db_to_form_schema()

            group_type = _get_group_type(id.split('@')[0])
            context = {'model': model, 'session': model.Session,
                       'ignore_auth': True,
                       'user': c.user or c.author,
                       'auth_user_obj': c.userobj,
                       'schema': db_to_form_schema(group_type=group_type),
                       'limits': {'packages': 2},
                       'for_view': True}
            data_dict = {'id': id}

            try:
                group_dict = logic.get_action('group_show')(context, data_dict)
            except logic.NotFound:
                return None

            return {'group_dict': group_dict}

        global dirty_cached_group_stuff
        if not dirty_cached_group_stuff:
            groups_data = []
            groups = config.get('ckan.featured_groups', '').split()

            for group_name in groups:
                group = get_group(group_name)
                if group:
                    groups_data.append(group)
                if len(groups_data) == 2:
                    break

            # c.groups is from the solr query above
            if len(groups_data) < 2 and len(c.groups) > 0:
                group = get_group(c.groups[0]['name'])
                if group:
                    groups_data.append(group)
            if len(groups_data) < 2 and len(c.groups) > 1:
                group = get_group(c.groups[1]['name'])
                if group:
                    groups_data.append(group)
            # We get all the packages or at least too many so
            # limit it to just 2
            for group in groups_data:
                group['group_dict']['packages'] = \
                    group['group_dict']['packages'][:2]
            #now add blanks so we have two
            while len(groups_data) < 2:
                groups_data.append({'group_dict': {}})
            # cache for later use
            dirty_cached_group_stuff = groups_data

        c.group_package_stuff = dirty_cached_group_stuff

        # END OF DIRTYNESS
        return base.render('home/index.html', cache_force=True)

    def license(self):
        return base.render('home/license.html')

    def about(self):
        return base.render('home/about.html')

    def cache(self, id):
        '''Manual way to clear the caches'''
        if id == 'clear':
            wui_caches = ['stats']
            for cache_name in wui_caches:
                cache_ = cache.get_cache(cache_name, type='dbm')
                cache_.clear()
            return 'Cleared caches: %s' % ', '.join(wui_caches)

    def cors_options(self, url=None):
        # just return 200 OK and empty data
        return ''

########NEW FILE########
__FILENAME__ = organization
import ckan.controllers.group as group


class OrganizationController(group.GroupController):
    ''' The organization controller is pretty much just the group
    controller. It has a few templates defined that are different and sets
    the group_type to organization so that the group controller knows that
    it is in fact the organization controller.  All the main logical
    differences are therefore in the group controller.

    The main differences the group controller provides for organizations are
    a few wrapper functions that swap organization for group when rendering
    templates, redirecting or calling logic actions '''

    # this makes us use organization actions
    group_type = 'organization'

    def _guess_group_type(self, expecting_name=False):
        return 'organization'

########NEW FILE########
__FILENAME__ = package
import logging
from urllib import urlencode
import datetime
import os
import mimetypes
import cgi

from pylons import config
from genshi.template import MarkupTemplate
from genshi.template.text import NewTextTemplate
from paste.deploy.converters import asbool
import paste.fileapp

import ckan.logic as logic
import ckan.lib.base as base
import ckan.lib.maintain as maintain
import ckan.lib.package_saver as package_saver
import ckan.lib.i18n as i18n
import ckan.lib.navl.dictization_functions as dict_fns
import ckan.lib.accept as accept
import ckan.lib.helpers as h
import ckan.model as model
import ckan.lib.datapreview as datapreview
import ckan.lib.plugins
import ckan.lib.uploader as uploader
import ckan.plugins as p
import ckan.lib.render

from ckan.common import OrderedDict, _, json, request, c, g, response
from home import CACHE_PARAMETERS

log = logging.getLogger(__name__)

render = base.render
abort = base.abort
redirect = base.redirect

NotFound = logic.NotFound
NotAuthorized = logic.NotAuthorized
ValidationError = logic.ValidationError
check_access = logic.check_access
get_action = logic.get_action
tuplize_dict = logic.tuplize_dict
clean_dict = logic.clean_dict
parse_params = logic.parse_params
flatten_to_string_key = logic.flatten_to_string_key

lookup_package_plugin = ckan.lib.plugins.lookup_package_plugin


def _encode_params(params):
    return [(k, v.encode('utf-8') if isinstance(v, basestring) else str(v))
            for k, v in params]


def url_with_params(url, params):
    params = _encode_params(params)
    return url + u'?' + urlencode(params)


def search_url(params, package_type=None):
    if not package_type or package_type == 'dataset':
        url = h.url_for(controller='package', action='search')
    else:
        url = h.url_for('{0}_search'.format(package_type))
    return url_with_params(url, params)


class PackageController(base.BaseController):

    def _package_form(self, package_type=None):
        return lookup_package_plugin(package_type).package_form()

    def _setup_template_variables(self, context, data_dict, package_type=None):
        return lookup_package_plugin(package_type).\
            setup_template_variables(context, data_dict)

    def _new_template(self, package_type):
        return lookup_package_plugin(package_type).new_template()

    def _edit_template(self, package_type):
        return lookup_package_plugin(package_type).edit_template()

    def _search_template(self, package_type):
        return lookup_package_plugin(package_type).search_template()

    def _read_template(self, package_type):
        return lookup_package_plugin(package_type).read_template()

    def _history_template(self, package_type):
        return lookup_package_plugin(package_type).history_template()

    def _guess_package_type(self, expecting_name=False):
        """
            Guess the type of package from the URL handling the case
            where there is a prefix on the URL (such as /data/package)
        """

        # Special case: if the rot URL '/' has been redirected to the package
        # controller (e.g. by an IRoutes extension) then there's nothing to do
        # here.
        if request.path == '/':
            return 'dataset'

        parts = [x for x in request.path.split('/') if x]

        idx = -1
        if expecting_name:
            idx = -2

        pt = parts[idx]
        if pt == 'package':
            pt = 'dataset'

        return pt

    def search(self):
        from ckan.lib.search import SearchError

        package_type = self._guess_package_type()

        try:
            context = {'model': model, 'user': c.user or c.author,
                       'auth_user_obj': c.userobj}
            check_access('site_read', context)
        except NotAuthorized:
            abort(401, _('Not authorized to see this page'))

        # unicode format (decoded from utf8)
        q = c.q = request.params.get('q', u'')
        c.query_error = False
        try:
            page = int(request.params.get('page', 1))
        except ValueError, e:
            abort(400, ('"page" parameter must be an integer'))
        limit = g.datasets_per_page

        # most search operations should reset the page counter:
        params_nopage = [(k, v) for k, v in request.params.items()
                         if k != 'page']

        def drill_down_url(alternative_url=None, **by):
            return h.add_url_param(alternative_url=alternative_url,
                                   controller='package', action='search',
                                   new_params=by)

        c.drill_down_url = drill_down_url

        def remove_field(key, value=None, replace=None):
            return h.remove_url_param(key, value=value, replace=replace,
                                  controller='package', action='search')

        c.remove_field = remove_field

        sort_by = request.params.get('sort', None)
        params_nosort = [(k, v) for k, v in params_nopage if k != 'sort']

        def _sort_by(fields):
            """
            Sort by the given list of fields.

            Each entry in the list is a 2-tuple: (fieldname, sort_order)

            eg - [('metadata_modified', 'desc'), ('name', 'asc')]

            If fields is empty, then the default ordering is used.
            """
            params = params_nosort[:]

            if fields:
                sort_string = ', '.join('%s %s' % f for f in fields)
                params.append(('sort', sort_string))
            return search_url(params, package_type)

        c.sort_by = _sort_by
        if sort_by is None:
            c.sort_by_fields = []
        else:
            c.sort_by_fields = [field.split()[0]
                                for field in sort_by.split(',')]

        def pager_url(q=None, page=None):
            params = list(params_nopage)
            params.append(('page', page))
            return search_url(params, package_type)

        c.search_url_params = urlencode(_encode_params(params_nopage))

        try:
            c.fields = []
            # c.fields_grouped will contain a dict of params containing
            # a list of values eg {'tags':['tag1', 'tag2']}
            c.fields_grouped = {}
            search_extras = {}
            fq = ''
            for (param, value) in request.params.items():
                if param not in ['q', 'page', 'sort'] \
                        and len(value) and not param.startswith('_'):
                    if not param.startswith('ext_'):
                        c.fields.append((param, value))
                        fq += ' %s:"%s"' % (param, value)
                        if param not in c.fields_grouped:
                            c.fields_grouped[param] = [value]
                        else:
                            c.fields_grouped[param].append(value)
                    else:
                        search_extras[param] = value

            context = {'model': model, 'session': model.Session,
                       'user': c.user or c.author, 'for_view': True,
                       'auth_user_obj': c.userobj}

            if package_type and package_type != 'dataset':
                # Only show datasets of this particular type
                fq += ' +dataset_type:{type}'.format(type=package_type)
            else:
                # Unless changed via config options, don't show non standard
                # dataset types on the default search page
                if not asbool(config.get('ckan.search.show_all_types', 'False')):
                    fq += ' +dataset_type:dataset'

            facets = OrderedDict()

            default_facet_titles = {
                    'organization': _('Organizations'),
                    'groups': _('Groups'),
                    'tags': _('Tags'),
                    'res_format': _('Formats'),
                    'license_id': _('Licenses'),
                    }

            for facet in g.facets:
                if facet in default_facet_titles:
                    facets[facet] = default_facet_titles[facet]
                else:
                    facets[facet] = facet

            # Facet titles
            for plugin in p.PluginImplementations(p.IFacets):
                facets = plugin.dataset_facets(facets, package_type)

            c.facet_titles = facets

            data_dict = {
                'q': q,
                'fq': fq.strip(),
                'facet.field': facets.keys(),
                'rows': limit,
                'start': (page - 1) * limit,
                'sort': sort_by,
                'extras': search_extras
            }

            query = get_action('package_search')(context, data_dict)
            c.sort_by_selected = query['sort']

            c.page = h.Page(
                collection=query['results'],
                page=page,
                url=pager_url,
                item_count=query['count'],
                items_per_page=limit
            )
            c.facets = query['facets']
            c.search_facets = query['search_facets']
            c.page.items = query['results']
        except SearchError, se:
            log.error('Dataset search error: %r', se.args)
            c.query_error = True
            c.facets = {}
            c.search_facets = {}
            c.page = h.Page(collection=[])
        c.search_facets_limits = {}
        for facet in c.search_facets.keys():
            try:
                limit = int(request.params.get('_%s_limit' % facet,
                                               g.facets_default_number))
            except ValueError:
                abort(400, _('Parameter "{parameter_name}" is not '
                             'an integer').format(
                                 parameter_name='_%s_limit' % facet
                             ))
            c.search_facets_limits[facet] = limit

        maintain.deprecate_context_item(
          'facets',
          'Use `c.search_facets` instead.')

        self._setup_template_variables(context, {},
                                       package_type=package_type)

        return render(self._search_template(package_type))

    def _content_type_from_extension(self, ext):
        ct, mu, ext = accept.parse_extension(ext)
        if not ct:
            return None, None, None,
        return ct, ext, (NewTextTemplate, MarkupTemplate)[mu]

    def _content_type_from_accept(self):
        """
        Given a requested format this method determines the content-type
        to set and the genshi template loader to use in order to render
        it accurately.  TextTemplate must be used for non-xml templates
        whilst all that are some sort of XML should use MarkupTemplate.
        """
        ct, mu, ext = accept.parse_header(request.headers.get('Accept', ''))
        return ct, ext, (NewTextTemplate, MarkupTemplate)[mu]

    def resources(self, id):
        package_type = self._get_package_type(id.split('@')[0])
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'for_view': True,
                   'auth_user_obj': c.userobj}
        data_dict = {'id': id}

        try:
            check_access('package_update', context, data_dict)
        except NotAuthorized, e:
            abort(401, _('User %r not authorized to edit %s') % (c.user, id))
        # check if package exists
        try:
            c.pkg_dict = get_action('package_show')(context, data_dict)
            c.pkg = context['package']
        except NotFound:
            abort(404, _('Dataset not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read package %s') % id)

        self._setup_template_variables(context, {'id': id},
                                       package_type=package_type)

        return render('package/resources.html')

    def read(self, id, format='html'):
        if not format == 'html':
            ctype, extension, loader = \
                self._content_type_from_extension(format)
            if not ctype:
                # An unknown format, we'll carry on in case it is a
                # revision specifier and re-constitute the original id
                id = "%s.%s" % (id, format)
                ctype, format, loader = "text/html; charset=utf-8", "html", \
                    MarkupTemplate
        else:
            ctype, format, loader = self._content_type_from_accept()

        response.headers['Content-Type'] = ctype

        package_type = self._get_package_type(id.split('@')[0])
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'for_view': True,
                   'auth_user_obj': c.userobj}
        data_dict = {'id': id}

        # interpret @<revision_id> or @<date> suffix
        split = id.split('@')
        if len(split) == 2:
            data_dict['id'], revision_ref = split
            if model.is_id(revision_ref):
                context['revision_id'] = revision_ref
            else:
                try:
                    date = h.date_str_to_datetime(revision_ref)
                    context['revision_date'] = date
                except TypeError, e:
                    abort(400, _('Invalid revision format: %r') % e.args)
                except ValueError, e:
                    abort(400, _('Invalid revision format: %r') % e.args)
        elif len(split) > 2:
            abort(400, _('Invalid revision format: %r') %
                  'Too many "@" symbols')

        # check if package exists
        try:
            c.pkg_dict = get_action('package_show')(context, data_dict)
            c.pkg = context['package']
        except NotFound:
            abort(404, _('Dataset not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read package %s') % id)

        # used by disqus plugin
        c.current_package_id = c.pkg.id
        c.related_count = c.pkg.related_count

        # can the resources be previewed?
        for resource in c.pkg_dict['resources']:
            resource['can_be_previewed'] = self._resource_preview(
                {'resource': resource, 'package': c.pkg_dict})

        self._setup_template_variables(context, {'id': id},
                                       package_type=package_type)

        package_saver.PackageSaver().render_package(c.pkg_dict, context)

        template = self._read_template(package_type)
        template = template[:template.index('.') + 1] + format

        try:
            return render(template, loader_class=loader)
        except ckan.lib.render.TemplateNotFound:
            msg = _("Viewing {package_type} datasets in {format} format is "
                    "not supported (template file {file} not found).".format(
                    package_type=package_type, format=format, file=template))
            abort(404, msg)

        assert False, "We should never get here"

    def history(self, id):
        package_type = self._get_package_type(id.split('@')[0])

        if 'diff' in request.params or 'selected1' in request.params:
            try:
                params = {'id': request.params.getone('pkg_name'),
                          'diff': request.params.getone('selected1'),
                          'oldid': request.params.getone('selected2'),
                          }
            except KeyError, e:
                if 'pkg_name' in dict(request.params):
                    id = request.params.getone('pkg_name')
                c.error = \
                    _('Select two revisions before doing the comparison.')
            else:
                params['diff_entity'] = 'package'
                h.redirect_to(controller='revision', action='diff', **params)

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}
        data_dict = {'id': id}
        try:
            c.pkg_dict = get_action('package_show')(context, data_dict)
            c.pkg_revisions = get_action('package_revision_list')(context,
                                                                  data_dict)
            # TODO: remove
            # Still necessary for the authz check in group/layout.html
            c.pkg = context['package']

        except NotAuthorized:
            abort(401, _('Unauthorized to read package %s') % '')
        except NotFound:
            abort(404, _('Dataset not found'))

        format = request.params.get('format', '')
        if format == 'atom':
            # Generate and return Atom 1.0 document.
            from webhelpers.feedgenerator import Atom1Feed
            feed = Atom1Feed(
                title=_(u'CKAN Dataset Revision History'),
                link=h.url_for(controller='revision', action='read',
                               id=c.pkg_dict['name']),
                description=_(u'Recent changes to CKAN Dataset: ') +
                (c.pkg_dict['title'] or ''),
                language=unicode(i18n.get_lang()),
            )
            for revision_dict in c.pkg_revisions:
                revision_date = h.date_str_to_datetime(
                    revision_dict['timestamp'])
                try:
                    dayHorizon = int(request.params.get('days'))
                except:
                    dayHorizon = 30
                dayAge = (datetime.datetime.now() - revision_date).days
                if dayAge >= dayHorizon:
                    break
                if revision_dict['message']:
                    item_title = u'%s' % revision_dict['message'].\
                        split('\n')[0]
                else:
                    item_title = u'%s' % revision_dict['id']
                item_link = h.url_for(controller='revision', action='read',
                                      id=revision_dict['id'])
                item_description = _('Log message: ')
                item_description += '%s' % (revision_dict['message'] or '')
                item_author_name = revision_dict['author']
                item_pubdate = revision_date
                feed.add_item(
                    title=item_title,
                    link=item_link,
                    description=item_description,
                    author_name=item_author_name,
                    pubdate=item_pubdate,
                )
            response.headers['Content-Type'] = 'application/atom+xml'
            return feed.writeString('utf-8')

        c.related_count = c.pkg.related_count
        return render(self._history_template(c.pkg_dict.get('type',
                                                            package_type)))

    def new(self, data=None, errors=None, error_summary=None):
        package_type = self._guess_package_type(True)

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj,
                   'save': 'save' in request.params}

        # Package needs to have a organization group in the call to
        # check_access and also to save it
        try:
            check_access('package_create', context)
        except NotAuthorized:
            abort(401, _('Unauthorized to create a package'))

        if context['save'] and not data:
            return self._save_new(context, package_type=package_type)

        data = data or clean_dict(dict_fns.unflatten(tuplize_dict(parse_params(
            request.params, ignore_keys=CACHE_PARAMETERS))))
        c.resources_json = h.json.dumps(data.get('resources', []))
        # convert tags if not supplied in data
        if data and not data.get('tag_string'):
            data['tag_string'] = ', '.join(
                h.dict_list_reduce(data.get('tags', {}), 'name'))

        errors = errors or {}
        error_summary = error_summary or {}
        # in the phased add dataset we need to know that
        # we have already completed stage 1
        stage = ['active']
        if data.get('state') == 'draft':
            stage = ['active', 'complete']
        elif data.get('state') == 'draft-complete':
            stage = ['active', 'complete', 'complete']

        # if we are creating from a group then this allows the group to be
        # set automatically
        data['group_id'] = request.params.get('group') or \
            request.params.get('groups__0__id')

        vars = {'data': data, 'errors': errors,
                'error_summary': error_summary,
                'action': 'new', 'stage': stage}
        c.errors_json = h.json.dumps(errors)

        self._setup_template_variables(context, {},
                                       package_type=package_type)

        # TODO: This check is to maintain backwards compatibility with the
        # old way of creating custom forms. This behaviour is now deprecated.
        if hasattr(self, 'package_form'):
            c.form = render(self.package_form, extra_vars=vars)
        else:
            c.form = render(self._package_form(package_type=package_type),
                            extra_vars=vars)
        return render(self._new_template(package_type),
                      extra_vars={'stage': stage})

    def resource_edit(self, id, resource_id, data=None, errors=None,
                      error_summary=None):
        if request.method == 'POST' and not data:
            data = data or clean_dict(dict_fns.unflatten(tuplize_dict(parse_params(
                request.POST))))
            # we don't want to include save as it is part of the form
            del data['save']

            context = {'model': model, 'session': model.Session,
                       'api_version': 3, 'for_edit': True,
                       'user': c.user or c.author, 'auth_user_obj': c.userobj}

            data['package_id'] = id
            try:
                if resource_id:
                    data['id'] = resource_id
                    get_action('resource_update')(context, data)
                else:
                    get_action('resource_create')(context, data)
            except ValidationError, e:
                errors = e.error_dict
                error_summary = e.error_summary
                return self.resource_edit(id, resource_id, data,
                                          errors, error_summary)
            except NotAuthorized:
                abort(401, _('Unauthorized to edit this resource'))
            redirect(h.url_for(controller='package', action='resource_read',
                               id=id, resource_id=resource_id))

        context = {'model': model, 'session': model.Session,
                   'api_version': 3, 'for_edit': True,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}
        pkg_dict = get_action('package_show')(context, {'id': id})
        if pkg_dict['state'].startswith('draft'):
            # dataset has not yet been fully created
            resource_dict = get_action('resource_show')(context, {'id': resource_id})
            fields = ['url', 'resource_type', 'format', 'name', 'description', 'id']
            data = {}
            for field in fields:
                data[field] = resource_dict[field]
            return self.new_resource(id, data=data)
        # resource is fully created
        try:
            resource_dict = get_action('resource_show')(context, {'id': resource_id})
        except NotFound:
            abort(404, _('Resource not found'))
        c.pkg_dict = pkg_dict
        c.resource = resource_dict
        # set the form action
        c.form_action = h.url_for(controller='package',
                                  action='resource_edit',
                                  resource_id=resource_id,
                                  id=id)
        if not data:
            data = resource_dict

        errors = errors or {}
        error_summary = error_summary or {}
        vars = {'data': data, 'errors': errors,
                'error_summary': error_summary, 'action': 'new'}
        return render('package/resource_edit.html', extra_vars=vars)

    def new_resource(self, id, data=None, errors=None, error_summary=None):
        ''' FIXME: This is a temporary action to allow styling of the
        forms. '''
        if request.method == 'POST' and not data:
            save_action = request.params.get('save')
            data = data or clean_dict(dict_fns.unflatten(tuplize_dict(parse_params(
                request.POST))))
            # we don't want to include save as it is part of the form
            del data['save']
            resource_id = data['id']
            del data['id']

            context = {'model': model, 'session': model.Session,
                       'user': c.user or c.author, 'auth_user_obj': c.userobj}

            # see if we have any data that we are trying to save
            data_provided = False
            for key, value in data.iteritems():
                if ((value or isinstance(value, cgi.FieldStorage))
                    and key != 'resource_type'):
                    data_provided = True
                    break

            if not data_provided and save_action != "go-dataset-complete":
                if save_action == 'go-dataset':
                    # go to final stage of adddataset
                    redirect(h.url_for(controller='package',
                                       action='edit', id=id))
                # see if we have added any resources
                try:
                    data_dict = get_action('package_show')(context, {'id': id})
                except NotAuthorized:
                    abort(401, _('Unauthorized to update dataset'))
                except NotFound:
                    abort(404,
                      _('The dataset {id} could not be found.').format(id=id))
                if not len(data_dict['resources']):
                    # no data so keep on page
                    msg = _('You must add at least one data resource')
                    # On new templates do not use flash message
                    if g.legacy_templates:
                        h.flash_error(msg)
                        redirect(h.url_for(controller='package',
                                           action='new_resource', id=id))
                    else:
                        errors = {}
                        error_summary = {_('Error'): msg}
                        return self.new_resource(id, data, errors, error_summary)
                # we have a resource so let them add metadata
                redirect(h.url_for(controller='package',
                                   action='new_metadata', id=id))

            data['package_id'] = id
            try:
                if resource_id:
                    data['id'] = resource_id
                    get_action('resource_update')(context, data)
                else:
                    get_action('resource_create')(context, data)
            except ValidationError, e:
                errors = e.error_dict
                error_summary = e.error_summary
                return self.new_resource(id, data, errors, error_summary)
            except NotAuthorized:
                abort(401, _('Unauthorized to create a resource'))
            except NotFound:
                abort(404,
                    _('The dataset {id} could not be found.').format(id=id))
            if save_action == 'go-metadata':
                # go to final stage of add dataset
                redirect(h.url_for(controller='package',
                                   action='new_metadata', id=id))
            elif save_action == 'go-dataset':
                # go to first stage of add dataset
                redirect(h.url_for(controller='package',
                                   action='edit', id=id))
            elif save_action == 'go-dataset-complete':
                # go to first stage of add dataset
                redirect(h.url_for(controller='package',
                                   action='read', id=id))
            else:
                # add more resources
                redirect(h.url_for(controller='package',
                                   action='new_resource', id=id))
        errors = errors or {}
        error_summary = error_summary or {}
        vars = {'data': data, 'errors': errors,
                'error_summary': error_summary, 'action': 'new'}
        vars['pkg_name'] = id
        # get resources for sidebar
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}
        try:
            pkg_dict = get_action('package_show')(context, {'id': id})
        except NotFound:
            abort(404, _('The dataset {id} could not be found.').format(id=id))
        # required for nav menu
        vars['pkg_dict'] = pkg_dict
        template = 'package/new_resource_not_draft.html'
        if pkg_dict['state'] == 'draft':
            vars['stage'] = ['complete', 'active']
            template = 'package/new_resource.html'
        elif pkg_dict['state'] == 'draft-complete':
            vars['stage'] = ['complete', 'active', 'complete']
            template = 'package/new_resource.html'
        return render(template, extra_vars=vars)

    def new_metadata(self, id, data=None, errors=None, error_summary=None):
        ''' FIXME: This is a temporary action to allow styling of the
        forms. '''
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}

        if request.method == 'POST' and not data:
            save_action = request.params.get('save')
            data = data or clean_dict(dict_fns.unflatten(tuplize_dict(parse_params(
                request.POST))))
            # we don't want to include save as it is part of the form
            del data['save']

            data_dict = get_action('package_show')(context, {'id': id})

            data_dict['id'] = id
            # update the state
            if save_action == 'finish':
                # we want this to go live when saved
                data_dict['state'] = 'active'
            elif save_action in ['go-resources', 'go-dataset']:
                data_dict['state'] = 'draft-complete'
            # allow the state to be changed
            context['allow_state_change'] = True
            data_dict.update(data)
            try:
                get_action('package_update')(context, data_dict)
            except ValidationError, e:
                errors = e.error_dict
                error_summary = e.error_summary
                return self.new_metadata(id, data, errors, error_summary)
            except NotAuthorized:
                abort(401, _('Unauthorized to update dataset'))
            if save_action == 'go-resources':
                # we want to go back to the add resources form stage
                redirect(h.url_for(controller='package',
                                   action='new_resource', id=id))
            elif save_action == 'go-dataset':
                # we want to go back to the add dataset stage
                redirect(h.url_for(controller='package',
                                   action='edit', id=id))

            redirect(h.url_for(controller='package', action='read', id=id))

        if not data:
            data = get_action('package_show')(context, {'id': id})
        errors = errors or {}
        error_summary = error_summary or {}
        vars = {'data': data, 'errors': errors, 'error_summary': error_summary}
        vars['pkg_name'] = id

        package_type = self._get_package_type(id)
        self._setup_template_variables(context, {},
                                       package_type=package_type)

        return render('package/new_package_metadata.html', extra_vars=vars)

    def edit(self, id, data=None, errors=None, error_summary=None):
        package_type = self._get_package_type(id)
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj,
                   'save': 'save' in request.params,
                   'moderated': config.get('moderated'),
                   'pending': True}

        if context['save'] and not data:
            return self._save_edit(id, context, package_type=package_type)
        try:
            c.pkg_dict = get_action('package_show')(context, {'id': id})
            context['for_edit'] = True
            old_data = get_action('package_show')(context, {'id': id})
            # old data is from the database and data is passed from the
            # user if there is a validation error. Use users data if there.
            if data:
                old_data.update(data)
            data = old_data
        except NotAuthorized:
            abort(401, _('Unauthorized to read package %s') % '')
        except NotFound:
            abort(404, _('Dataset not found'))
        # are we doing a multiphase add?
        if data.get('state', '').startswith('draft'):
            c.form_action = h.url_for(controller='package', action='new')
            c.form_style = 'new'
            return self.new(data=data, errors=errors,
                            error_summary=error_summary)

        c.pkg = context.get("package")
        c.resources_json = h.json.dumps(data.get('resources', []))

        try:
            check_access('package_update', context)
        except NotAuthorized, e:
            abort(401, _('User %r not authorized to edit %s') % (c.user, id))
        # convert tags if not supplied in data
        if data and not data.get('tag_string'):
            data['tag_string'] = ', '.join(h.dict_list_reduce(
                c.pkg_dict.get('tags', {}), 'name'))
        errors = errors or {}
        vars = {'data': data, 'errors': errors,
                'error_summary': error_summary, 'action': 'edit'}
        c.errors_json = h.json.dumps(errors)

        self._setup_template_variables(context, {'id': id},
                                       package_type=package_type)
        c.related_count = c.pkg.related_count

        # we have already completed stage 1
        vars['stage'] = ['active']
        if data.get('state') == 'draft':
            vars['stage'] = ['active', 'complete']
        elif data.get('state') == 'draft-complete':
            vars['stage'] = ['active', 'complete', 'complete']

        # TODO: This check is to maintain backwards compatibility with the
        # old way of creating custom forms. This behaviour is now deprecated.
        if hasattr(self, 'package_form'):
            c.form = render(self.package_form, extra_vars=vars)
        else:
            c.form = render(self._package_form(package_type=package_type),
                            extra_vars=vars)

        return render(self._edit_template(package_type),
                      extra_vars={'stage': vars['stage']})

    def read_ajax(self, id, revision=None):
        package_type = self._get_package_type(id)
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj,
                   'revision_id': revision}
        try:
            data = get_action('package_show')(context, {'id': id})
        except NotAuthorized:
            abort(401, _('Unauthorized to read package %s') % '')
        except NotFound:
            abort(404, _('Dataset not found'))

        data.pop('tags')
        data = flatten_to_string_key(data)
        response.headers['Content-Type'] = 'application/json;charset=utf-8'
        return h.json.dumps(data)

    def history_ajax(self, id):

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}
        data_dict = {'id': id}
        try:
            pkg_revisions = get_action('package_revision_list')(
                context, data_dict)
        except NotAuthorized:
            abort(401, _('Unauthorized to read package %s') % '')
        except NotFound:
            abort(404, _('Dataset not found'))

        data = []
        approved = False
        for num, revision in enumerate(pkg_revisions):
            if not approved and revision['approved_timestamp']:
                current_approved, approved = True, True
            else:
                current_approved = False

            data.append({'revision_id': revision['id'],
                         'message': revision['message'],
                         'timestamp': revision['timestamp'],
                         'author': revision['author'],
                         'approved': bool(revision['approved_timestamp']),
                         'current_approved': current_approved})

        response.headers['Content-Type'] = 'application/json;charset=utf-8'
        return h.json.dumps(data)

    def _get_package_type(self, id):
        """
        Given the id of a package it determines the plugin to load
        based on the package's type name (type). The plugin found
        will be returned, or None if there is no plugin associated with
        the type.
        """
        pkg = model.Package.get(id)
        if pkg:
            return pkg.type or 'dataset'
        return None

    def _tag_string_to_list(self, tag_string):
        ''' This is used to change tags from a sting to a list of dicts '''
        out = []
        for tag in tag_string.split(','):
            tag = tag.strip()
            if tag:
                out.append({'name': tag,
                            'state': 'active'})
        return out

    def _save_new(self, context, package_type=None):
        # The staged add dataset used the new functionality when the dataset is
        # partially created so we need to know if we actually are updating or
        # this is a real new.
        is_an_update = False
        ckan_phase = request.params.get('_ckan_phase')
        from ckan.lib.search import SearchIndexError
        try:
            data_dict = clean_dict(dict_fns.unflatten(
                tuplize_dict(parse_params(request.POST))))
            if ckan_phase:
                # prevent clearing of groups etc
                context['allow_partial_update'] = True
                # sort the tags
                data_dict['tags'] = self._tag_string_to_list(
                    data_dict['tag_string'])
                if data_dict.get('pkg_name'):
                    is_an_update = True
                    # This is actually an update not a save
                    data_dict['id'] = data_dict['pkg_name']
                    del data_dict['pkg_name']
                    # this is actually an edit not a save
                    pkg_dict = get_action('package_update')(context, data_dict)

                    if request.params['save'] == 'go-metadata':
                        # redirect to add metadata
                        url = h.url_for(controller='package',
                                        action='new_metadata',
                                        id=pkg_dict['name'])
                    else:
                        # redirect to add dataset resources
                        url = h.url_for(controller='package',
                                        action='new_resource',
                                        id=pkg_dict['name'])
                    redirect(url)
                # Make sure we don't index this dataset
                if request.params['save'] not in ['go-resource', 'go-metadata']:
                    data_dict['state'] = 'draft'
                # allow the state to be changed
                context['allow_state_change'] = True

            data_dict['type'] = package_type
            context['message'] = data_dict.get('log_message', '')
            pkg_dict = get_action('package_create')(context, data_dict)

            if ckan_phase:
                # redirect to add dataset resources
                url = h.url_for(controller='package',
                                action='new_resource',
                                id=pkg_dict['name'])
                redirect(url)

            self._form_save_redirect(pkg_dict['name'], 'new', package_type=package_type)
        except NotAuthorized:
            abort(401, _('Unauthorized to read package %s') % '')
        except NotFound, e:
            abort(404, _('Dataset not found'))
        except dict_fns.DataError:
            abort(400, _(u'Integrity Error'))
        except SearchIndexError, e:
            try:
                exc_str = unicode(repr(e.args))
            except Exception:  # We don't like bare excepts
                exc_str = unicode(str(e))
            abort(500, _(u'Unable to add package to search index.') + exc_str)
        except ValidationError, e:
            errors = e.error_dict
            error_summary = e.error_summary
            if is_an_update:
                # we need to get the state of the dataset to show the stage we
                # are on.
                pkg_dict = get_action('package_show')(context, data_dict)
                data_dict['state'] = pkg_dict['state']
                return self.edit(data_dict['id'], data_dict,
                                 errors, error_summary)
            data_dict['state'] = 'none'
            return self.new(data_dict, errors, error_summary)

    def _save_edit(self, name_or_id, context, package_type=None):
        from ckan.lib.search import SearchIndexError
        log.debug('Package save request name: %s POST: %r',
                  name_or_id, request.POST)
        try:
            data_dict = clean_dict(dict_fns.unflatten(
                tuplize_dict(parse_params(request.POST))))
            if '_ckan_phase' in data_dict:
                # we allow partial updates to not destroy existing resources
                context['allow_partial_update'] = True
                data_dict['tags'] = self._tag_string_to_list(
                    data_dict['tag_string'])
                del data_dict['_ckan_phase']
                del data_dict['save']
            context['message'] = data_dict.get('log_message', '')
            if not context['moderated']:
                context['pending'] = False
            data_dict['id'] = name_or_id
            pkg = get_action('package_update')(context, data_dict)
            if request.params.get('save', '') == 'Approve':
                get_action('make_latest_pending_package_active')(
                    context, data_dict)
            c.pkg = context['package']
            c.pkg_dict = pkg

            self._form_save_redirect(pkg['name'], 'edit', package_type=package_type)
        except NotAuthorized:
            abort(401, _('Unauthorized to read package %s') % id)
        except NotFound, e:
            abort(404, _('Dataset not found'))
        except dict_fns.DataError:
            abort(400, _(u'Integrity Error'))
        except SearchIndexError, e:
            try:
                exc_str = unicode(repr(e.args))
            except Exception:  # We don't like bare excepts
                exc_str = unicode(str(e))
            abort(500, _(u'Unable to update search index.') + exc_str)
        except ValidationError, e:
            errors = e.error_dict
            error_summary = e.error_summary
            return self.edit(name_or_id, data_dict, errors, error_summary)

    def _form_save_redirect(self, pkgname, action, package_type=None):
        '''This redirects the user to the CKAN package/read page,
        unless there is request parameter giving an alternate location,
        perhaps an external website.
        @param pkgname - Name of the package just edited
        @param action - What the action of the edit was
        '''
        assert action in ('new', 'edit')
        url = request.params.get('return_to') or \
            config.get('package_%s_return_url' % action)
        if url:
            url = url.replace('<NAME>', pkgname)
        else:
            if package_type is None or package_type == 'dataset':
                url = h.url_for(controller='package', action='read', id=pkgname)
            else:
                url = h.url_for('{0}_read'.format(package_type), id=pkgname)
        redirect(url)

    def _adjust_license_id_options(self, pkg, fs):
        options = fs.license_id.render_opts['options']
        is_included = False
        for option in options:
            license_id = option[1]
            if license_id == pkg.license_id:
                is_included = True
        if not is_included:
            options.insert(1, (pkg.license_id, pkg.license_id))

    def delete(self, id):

        if 'cancel' in request.params:
            h.redirect_to(controller='package', action='edit', id=id)

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}

        try:
            check_access('package_delete', context, {'id': id})
        except NotAuthorized:
            abort(401, _('Unauthorized to delete package %s') % '')

        try:
            if request.method == 'POST':
                get_action('package_delete')(context, {'id': id})
                h.flash_notice(_('Dataset has been deleted.'))
                h.redirect_to(controller='package', action='search')
            c.pkg_dict = get_action('package_show')(context, {'id': id})
        except NotAuthorized:
            abort(401, _('Unauthorized to delete package %s') % '')
        except NotFound:
            abort(404, _('Dataset not found'))
        return render('package/confirm_delete.html')

    def resource_delete(self, id, resource_id):

        if 'cancel' in request.params:
            h.redirect_to(controller='package', action='resource_edit', resource_id=resource_id, id=id)

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}

        try:
            check_access('package_delete', context, {'id': id})
        except NotAuthorized:
            abort(401, _('Unauthorized to delete package %s') % '')

        try:
            if request.method == 'POST':
                get_action('resource_delete')(context, {'id': resource_id})
                h.flash_notice(_('Resource has been deleted.'))
                h.redirect_to(controller='package', action='read', id=id)
            c.resource_dict = get_action('resource_show')(context, {'id': resource_id})
            c.pkg_id = id
        except NotAuthorized:
            abort(401, _('Unauthorized to delete resource %s') % '')
        except NotFound:
            abort(404, _('Resource not found'))
        return render('package/confirm_delete_resource.html')

    def autocomplete(self):
        # DEPRECATED in favour of /api/2/util/dataset/autocomplete
        q = unicode(request.params.get('q', ''))
        if not len(q):
            return ''

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}

        data_dict = {'q': q}
        packages = get_action('package_autocomplete')(context, data_dict)

        pkg_list = []
        for pkg in packages:
            pkg_list.append('%s|%s' % (pkg['match_displayed'].
                                       replace('|', ' '), pkg['name']))
        return '\n'.join(pkg_list)

    def _render_edit_form(self, fs, params={}, clear_session=False):
        # errors arrive in c.error and fs.errors
        c.log_message = params.get('log_message', '')
        # rgrp: expunge everything from session before dealing with
        # validation errors) so we don't have any problematic saves
        # when the fs.render causes a flush.
        # seb: If the session is *expunged*, then the form can't be
        # rendered; I've settled with a rollback for now, which isn't
        # necessarily what's wanted here.
        # dread: I think this only happened with tags because until
        # this changeset, Tag objects were created in the Renderer
        # every time you hit preview. So I don't believe we need to
        # clear the session any more. Just in case I'm leaving it in
        # with the log comments to find out.
        if clear_session:
            # log to see if clearing the session is ever required
            if model.Session.new or model.Session.dirty or \
                    model.Session.deleted:
                log.warn('Expunging session changes which were not expected: '
                         '%r %r %r', (model.Session.new, model.Session.dirty,
                                      model.Session.deleted))
            try:
                model.Session.rollback()
            except AttributeError:
                # older SQLAlchemy versions
                model.Session.clear()
        edit_form_html = fs.render()
        c.form = h.literal(edit_form_html)
        return h.literal(render('package/edit_form.html'))

    def _update_authz(self, fs):
        validation = fs.validate()
        if not validation:
            c.form = self._render_edit_form(fs, request.params)
            raise package_saver.ValidationException(fs)
        try:
            fs.sync()
        except Exception, inst:
            model.Session.rollback()
            raise
        else:
            model.Session.commit()

    def resource_read(self, id, resource_id):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}

        try:
            c.resource = get_action('resource_show')(context,
                                                     {'id': resource_id})
            c.package = get_action('package_show')(context, {'id': id})
            # required for nav menu
            c.pkg = context['package']
            c.pkg_dict = c.package
        except NotFound:
            abort(404, _('Resource not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read resource %s') % id)
        # get package license info
        license_id = c.package.get('license_id')
        try:
            c.package['isopen'] = model.Package.\
                get_license_register()[license_id].isopen()
        except KeyError:
            c.package['isopen'] = False

        # TODO: find a nicer way of doing this
        c.datastore_api = '%s/api/action' % config.get('ckan.site_url', '').rstrip('/')

        c.related_count = c.pkg.related_count

        c.resource['can_be_previewed'] = self._resource_preview(
            {'resource': c.resource, 'package': c.package})
        return render('package/resource_read.html')

    def _resource_preview(self, data_dict):
        return bool(datapreview.res_format(data_dict['resource'])
                    in datapreview.direct() + datapreview.loadable()
                    or datapreview.get_preview_plugin(
                        data_dict, return_first=True))

    def resource_download(self, id, resource_id, filename=None):
        """
        Provides a direct download by either redirecting the user to the url stored
         or downloading an uploaded file directly.
        """
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}

        try:
            rsc = get_action('resource_show')(context, {'id': resource_id})
            pkg = get_action('package_show')(context, {'id': id})
        except NotFound:
            abort(404, _('Resource not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read resource %s') % id)

        if rsc.get('url_type') == 'upload':
            upload = uploader.ResourceUpload(rsc)
            filepath = upload.get_path(rsc['id'])
            fileapp = paste.fileapp.FileApp(filepath)
            try:
               status, headers, app_iter = request.call_application(fileapp)
            except OSError:
               abort(404, _('Resource data not found'))
            response.headers.update(dict(headers))
            content_type, content_enc = mimetypes.guess_type(rsc.get('url',''))
            if content_type:
                response.headers['Content-Type'] = content_type
            response.status = status
            return app_iter
        elif not 'url' in rsc:
            abort(404, _('No download is available'))
        redirect(rsc['url'])

    def follow(self, id):
        '''Start following this dataset.'''
        context = {'model': model,
                   'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}
        data_dict = {'id': id}
        try:
            get_action('follow_dataset')(context, data_dict)
            package_dict = get_action('package_show')(context, data_dict)
            h.flash_success(_("You are now following {0}").format(
                package_dict['title']))
        except ValidationError as e:
            error_message = (e.extra_msg or e.message or e.error_summary
                    or e.error_dict)
            h.flash_error(error_message)
        except NotAuthorized as e:
            h.flash_error(e.extra_msg)
        h.redirect_to(controller='package', action='read', id=id)

    def unfollow(self, id):
        '''Stop following this dataset.'''
        context = {'model': model,
                   'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}
        data_dict = {'id': id}
        try:
            get_action('unfollow_dataset')(context, data_dict)
            package_dict = get_action('package_show')(context, data_dict)
            h.flash_success(_("You are no longer following {0}").format(
                package_dict['title']))
        except ValidationError as e:
            error_message = (e.extra_msg or e.message or e.error_summary
                    or e.error_dict)
            h.flash_error(error_message)
        except (NotFound, NotAuthorized) as e:
            error_message = e.extra_msg or e.message
            h.flash_error(error_message)
        h.redirect_to(controller='package', action='read', id=id)

    def followers(self, id=None):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'for_view': True,
                   'auth_user_obj': c.userobj}

        data_dict = {'id': id}
        try:
            c.pkg_dict = get_action('package_show')(context, data_dict)
            c.pkg = context['package']
            c.followers = get_action('dataset_follower_list')(context,
                    {'id': c.pkg_dict['id']})

            c.related_count = c.pkg.related_count
        except NotFound:
            abort(404, _('Dataset not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read package %s') % id)

        return render('package/followers.html')

    def groups(self, id):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'for_view': True,
                   'auth_user_obj': c.userobj, 'use_cache': False}
        data_dict = {'id': id}
        try:
            c.pkg_dict = get_action('package_show')(context, data_dict)
        except NotFound:
            abort(404, _('Dataset not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read dataset %s') % id)

        if request.method == 'POST':
            new_group = request.POST.get('group_added')
            if new_group:
                data_dict = {"id": new_group,
                             "object": id,
                             "object_type": 'package',
                             "capacity": 'public'}
                try:
                    get_action('member_create')(context, data_dict)
                except NotFound:
                    abort(404, _('Group not found'))

            removed_group = None
            for param in request.POST:
                if param.startswith('group_remove'):
                    removed_group = param.split('.')[-1]
                    break
            if removed_group:
                data_dict = {"id": removed_group,
                             "object": id,
                             "object_type": 'package'}

                try:
                    get_action('member_delete')(context, data_dict)
                except NotFound:
                    abort(404, _('Group not found'))
            redirect(h.url_for(controller='package',
                               action='groups', id=id))



        context['is_member'] = True
        users_groups = get_action('group_list_authz')(context, data_dict)

        pkg_group_ids = set(group['id'] for group
                         in c.pkg_dict.get('groups', []))
        user_group_ids = set(group['id'] for group
                          in users_groups)

        c.group_dropdown = [[group['id'], group['display_name']]
                           for group in users_groups if
                           group['id'] not in pkg_group_ids]

        for group in c.pkg_dict.get('groups', []):
            group['user_member'] = (group['id'] in user_group_ids)

        return render('package/group_list.html')

    def activity(self, id):
        '''Render this package's public activity stream page.'''

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'for_view': True,
                   'auth_user_obj': c.userobj}
        data_dict = {'id': id}
        try:
            c.pkg_dict = get_action('package_show')(context, data_dict)
            c.pkg = context['package']
            c.package_activity_stream = get_action(
                    'package_activity_list_html')(context,
                            {'id': c.pkg_dict['id']})
            c.related_count = c.pkg.related_count
        except NotFound:
            abort(404, _('Dataset not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read dataset %s') % id)

        return render('package/activity.html')

    def resource_embedded_dataviewer(self, id, resource_id,
                                     width=500, height=500):
        """
        Embeded page for a read-only resource dataview. Allows
        for width and height to be specified as part of the
        querystring (as well as accepting them via routes).
        """
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}

        try:
            c.resource = get_action('resource_show')(context,
                                                     {'id': resource_id})
            c.package = get_action('package_show')(context, {'id': id})
            c.resource_json = h.json.dumps(c.resource)

            # double check that the resource belongs to the specified package
            if not c.resource['id'] in [r['id']
                                        for r in c.package['resources']]:
                raise NotFound

        except NotFound:
            abort(404, _('Resource not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read resource %s') % id)

        # Construct the recline state
        state_version = int(request.params.get('state_version', '1'))
        recline_state = self._parse_recline_state(request.params)
        if recline_state is None:
            abort(400, ('"state" parameter must be a valid recline '
                        'state (version %d)' % state_version))

        c.recline_state = h.json.dumps(recline_state)

        c.width = max(int(request.params.get('width', width)), 100)
        c.height = max(int(request.params.get('height', height)), 100)
        c.embedded = True

        return render('package/resource_embedded_dataviewer.html')

    def _parse_recline_state(self, params):
        state_version = int(request.params.get('state_version', '1'))
        if state_version != 1:
            return None

        recline_state = {}
        for k, v in request.params.items():
            try:
                v = h.json.loads(v)
            except ValueError:
                pass
            recline_state[k] = v

        recline_state.pop('width', None)
        recline_state.pop('height', None)
        recline_state['readOnly'] = True

        # previous versions of recline setup used elasticsearch_url attribute
        # for data api url - see http://trac.ckan.org/ticket/2639
        # fix by relocating this to url attribute which is the default location
        if 'dataset' in recline_state and 'elasticsearch_url' in recline_state['dataset']:
            recline_state['dataset']['url'] = recline_state['dataset']['elasticsearch_url']

        # Ensure only the currentView is available
        # default to grid view if none specified
        if not recline_state.get('currentView', None):
            recline_state['currentView'] = 'grid'
        for k in recline_state.keys():
            if k.startswith('view-') and \
                    not k.endswith(recline_state['currentView']):
                recline_state.pop(k)
        return recline_state

    def resource_datapreview(self, id, resource_id):
        '''
        Embeded page for a resource data-preview.

        Depending on the type, different previews are loaded.  This could be an
        img tag where the image is loaded directly or an iframe that embeds a
        webpage, recline or a pdf preview.
        '''
        context = {
            'model': model,
            'session': model.Session,
            'user': c.user or c.author,
            'auth_user_obj': c.userobj
        }

        try:
            c.resource = get_action('resource_show')(context,
                                                     {'id': resource_id})
            c.package = get_action('package_show')(context, {'id': id})

            data_dict = {'resource': c.resource, 'package': c.package}

            preview_plugin = datapreview.get_preview_plugin(data_dict)

            if preview_plugin is None:
                abort(409, _('No preview has been defined.'))

            preview_plugin.setup_template_variables(context, data_dict)
            c.resource_json = json.dumps(c.resource)
        except NotFound:
            abort(404, _('Resource not found'))
        except NotAuthorized:
            abort(401, _('Unauthorized to read resource %s') % id)
        else:
            return render(preview_plugin.preview_template(context, data_dict))

########NEW FILE########
__FILENAME__ = related
import urllib

import ckan.model as model
import ckan.logic as logic
import ckan.lib.base as base
import ckan.lib.helpers as h
import ckan.lib.navl.dictization_functions as df

from ckan.common import _, c


abort = base.abort
_get_action = logic.get_action


class RelatedController(base.BaseController):

    def new(self, id):
        return self._edit_or_new(id, None, False)

    def edit(self, id, related_id):
        return self._edit_or_new(id, related_id, True)

    def dashboard(self):
        """ List all related items regardless of dataset """
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj,
                   'for_view': True}
        data_dict = {
            'type_filter': base.request.params.get('type', ''),
            'sort': base.request.params.get('sort', ''),
            'featured': base.request.params.get('featured', '')
        }

        params_nopage = [(k, v) for k, v in base.request.params.items()
                         if k != 'page']
        try:
            page = int(base.request.params.get('page', 1))
        except ValueError:
            base.abort(400, ('"page" parameter must be an integer'))

        # Update ordering in the context
        related_list = logic.get_action('related_list')(context, data_dict)

        def search_url(params):
            url = h.url_for(controller='related', action='dashboard')
            params = [(k, v.encode('utf-8')
                      if isinstance(v, basestring) else str(v))
                      for k, v in params]
            return url + u'?' + urllib.urlencode(params)

        def pager_url(q=None, page=None):
            params = list(params_nopage)
            params.append(('page', page))
            return search_url(params)

        c.page = h.Page(
            collection=related_list,
            page=page,
            url=pager_url,
            item_count=len(related_list),
            items_per_page=9
        )

        c.filters = dict(params_nopage)

        c.type_options = self._type_options()
        c.sort_options = (
            {'value': '', 'text': _('Most viewed')},
            {'value': 'view_count_desc', 'text': _('Most Viewed')},
            {'value': 'view_count_asc', 'text': _('Least Viewed')},
            {'value': 'created_desc', 'text': _('Newest')},
            {'value': 'created_asc', 'text': _('Oldest')}
        )

        return base.render("related/dashboard.html")

    def read(self, id):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author,
                   'auth_user_obj': c.userobj,
                   'for_view': True}
        data_dict = {'id': id}

        try:
            logic.check_access('related_show', context, data_dict)
        except logic.NotAuthorized:
            base.abort(401, _('Not authorized to see this page'))

        related = model.Session.query(model.Related) \
            .filter(model.Related.id == id).first()
        if not related:
            base.abort(404, _('The requested related item was not found'))

        related.view_count = model.Related.view_count + 1

        model.Session.add(related)
        model.Session.commit()

        base.redirect(related.url)

    def list(self, id):
        """ List all related items for a specific dataset """
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author,
                   'auth_user_obj': c.userobj,
                   'for_view': True}
        data_dict = {'id': id}

        try:
            logic.check_access('package_show', context, data_dict)
        except logic.NotFound:
            base.abort(404, base._('Dataset not found'))
        except logic.NotAuthorized:
            base.abort(401, base._('Not authorized to see this page'))

        try:
            c.pkg_dict = logic.get_action('package_show')(context, data_dict)
            c.related_list = logic.get_action('related_list')(context,
                                                              data_dict)
            c.pkg = context['package']
            c.resources_json = h.json.dumps(c.pkg_dict.get('resources', []))
        except logic.NotFound:
            base.abort(404, base._('Dataset not found'))
        except logic.NotAuthorized:
            base.abort(401, base._('Unauthorized to read package %s') % id)

        return base.render("package/related_list.html")

    def _edit_or_new(self, id, related_id, is_edit):
        """
        Edit and New were too similar and so I've put the code together
        and try and do as much up front as possible.
        """
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj,
                   'for_view': True}
        data_dict = {}

        if is_edit:
            tpl = 'related/edit.html'
            auth_name = 'related_update'
            auth_dict = {'id': related_id}
            action_name = 'related_update'

            try:
                related = logic.get_action('related_show')(
                    context, {'id': related_id})
            except logic.NotFound:
                base.abort(404, _('Related item not found'))
        else:
            tpl = 'related/new.html'
            auth_name = 'related_create'
            auth_dict = {}
            action_name = 'related_create'

        try:
            logic.check_access(auth_name, context, auth_dict)
        except logic.NotAuthorized:
            base.abort(401, base._('Not authorized'))

        try:
            c.pkg_dict = logic.get_action('package_show')(context, {'id': id})
        except logic.NotFound:
            base.abort(404, _('Package not found'))

        data, errors, error_summary = {}, {}, {}

        if base.request.method == "POST":
            try:
                data = logic.clean_dict(
                    df.unflatten(
                        logic.tuplize_dict(
                            logic.parse_params(base.request.params))))

                if is_edit:
                    data['id'] = related_id
                else:
                    data['dataset_id'] = id
                data['owner_id'] = c.userobj.id

                related = logic.get_action(action_name)(context, data)

                if not is_edit:
                    h.flash_success(_("Related item was successfully created"))
                else:
                    h.flash_success(_("Related item was successfully updated"))

                h.redirect_to(
                    controller='related', action='list', id=c.pkg_dict['name'])
            except df.DataError:
                base.abort(400, _(u'Integrity Error'))
            except logic.ValidationError, e:
                errors = e.error_dict
                error_summary = e.error_summary
        else:
            if is_edit:
                data = related

        c.types = self._type_options()

        c.pkg_id = id
        vars = {'data': data, 'errors': errors, 'error_summary': error_summary}
        c.form = base.render("related/edit_form.html", extra_vars=vars)
        return base.render(tpl)

    def delete(self, id, related_id):
        if 'cancel' in base.request.params:
            h.redirect_to(controller='related', action='edit',
                          id=id, related_id=related_id)

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj}

        try:
            if base.request.method == 'POST':
                logic.get_action('related_delete')(context, {'id': related_id})
                h.flash_notice(_('Related item has been deleted.'))
                h.redirect_to(controller='package', action='read', id=id)
            c.related_dict = logic.get_action('related_show')(
                context, {'id': related_id})
            c.pkg_id = id
        except logic.NotAuthorized:
            base.abort(401, _('Unauthorized to delete related item %s') % '')
        except logic.NotFound:
            base.abort(404, _('Related item not found'))
        return base.render('related/confirm_delete.html')

    def _type_options(self):
        '''
        A tuple of options for the different related types for use in
        the form.select() template macro.
        '''
        return ({"text": _("API"), "value": "api"},
                {"text": _("Application"), "value": "application"},
                {"text": _("Idea"), "value": "idea"},
                {"text": _("News Article"), "value": "news_article"},
                {"text": _("Paper"), "value": "paper"},
                {"text": _("Post"), "value": "post"},
                {"text": _("Visualization"), "value": "visualization"})

########NEW FILE########
__FILENAME__ = revision
from datetime import datetime, timedelta

from pylons.i18n import get_lang

import ckan.logic as logic
import ckan.lib.base as base
import ckan.model as model
import ckan.lib.helpers as h

from ckan.common import _, c, request


class RevisionController(base.BaseController):

    def __before__(self, action, **env):
        base.BaseController.__before__(self, action, **env)

        context = {'model': model, 'user': c.user or c.author,
                   'auth_user_obj': c.userobj}
        if c.user:
            try:
                logic.check_access('revision_change_state', context)
                c.revision_change_state_allowed = True
            except logic.NotAuthorized:
                c.revision_change_state_allowed = False
        else:
            c.revision_change_state_allowed = False
        try:
            logic.check_access('site_read', context)
        except logic.NotAuthorized:
            base.abort(401, _('Not authorized to see this page'))

    def index(self):
        return self.list()

    def list(self):
        format = request.params.get('format', '')
        if format == 'atom':
            # Generate and return Atom 1.0 document.
            from webhelpers.feedgenerator import Atom1Feed
            feed = Atom1Feed(
                title=_(u'CKAN Repository Revision History'),
                link=h.url_for(controller='revision', action='list', id=''),
                description=_(u'Recent changes to the CKAN repository.'),
                language=unicode(get_lang()),
            )
            # TODO: make this configurable?
            # we do not want the system to fall over!
            maxresults = 200
            try:
                dayHorizon = int(request.params.get('days', 5))
            except:
                dayHorizon = 5
            ourtimedelta = timedelta(days=-dayHorizon)
            since_when = datetime.now() + ourtimedelta
            revision_query = model.repo.history()
            revision_query = revision_query.filter(
                model.Revision.timestamp >= since_when).filter(
                    model.Revision.id != None)
            revision_query = revision_query.limit(maxresults)
            for revision in revision_query:
                package_indications = []
                revision_changes = model.repo.list_changes(revision)
                resource_revisions = revision_changes[model.Resource]
                resource_group_revisions = \
                    revision_changes[model.ResourceGroup]
                package_extra_revisions = revision_changes[model.PackageExtra]
                for package in revision.packages:
                    if not package:
                        # package is None sometimes - I don't know why,
                        # but in the meantime while that is fixed,
                        # avoid an exception here
                        continue
                    if package.private:
                        continue
                    number = len(package.all_revisions)
                    package_revision = None
                    count = 0
                    for pr in package.all_revisions:
                        count += 1
                        if pr.revision.id == revision.id:
                            package_revision = pr
                            break
                    if package_revision and package_revision.state == \
                            model.State.DELETED:
                        transition = 'deleted'
                    elif package_revision and count == number:
                        transition = 'created'
                    else:
                        transition = 'updated'
                        for resource_revision in resource_revisions:
                            if resource_revision.continuity.resource_group.\
                                    package_id == package.id:
                                transition += ':resources'
                                break
                        for resource_group_revision in \
                                resource_group_revisions:
                            if resource_group_revision.package_id == \
                                    package.id:
                                transition += ':resource_group'
                                break
                        for package_extra_revision in package_extra_revisions:
                            if package_extra_revision.package_id == \
                                    package.id:
                                if package_extra_revision.key == \
                                        'date_updated':
                                    transition += ':date_updated'
                                    break
                    indication = "%s:%s" % (package.name, transition)
                    package_indications.append(indication)
                pkgs = u'[%s]' % ' '.join(package_indications)
                item_title = u'r%s ' % (revision.id)
                item_title += pkgs
                if revision.message:
                    item_title += ': %s' % (revision.message or '')
                item_link = h.url_for(controller='revision', action='read', id=revision.id)
                item_description = _('Datasets affected: %s.\n') % pkgs
                item_description += '%s' % (revision.message or '')
                item_author_name = revision.author
                item_pubdate = revision.timestamp
                feed.add_item(
                    title=item_title,
                    link=item_link,
                    description=item_description,
                    author_name=item_author_name,
                    pubdate=item_pubdate,
                )
            feed.content_type = 'application/atom+xml'
            return feed.writeString('utf-8')
        else:
            query = model.Session.query(model.Revision)
            c.page = h.Page(
                collection=query,
                page=request.params.get('page', 1),
                url=h.pager_url,
                items_per_page=20
            )
            return base.render('revision/list.html')

    def read(self, id=None):
        if id is None:
            base.abort(404)
        c.revision = model.Session.query(model.Revision).get(id)
        if c.revision is None:
            base.abort(404)

        pkgs = model.Session.query(model.PackageRevision).\
            filter_by(revision=c.revision)
        c.packages = [pkg.continuity for pkg in pkgs if not pkg.private]
        pkgtags = model.Session.query(model.PackageTagRevision).\
            filter_by(revision=c.revision)
        c.pkgtags = [pkgtag.continuity for pkgtag in pkgtags
                     if not pkgtag.package.private]
        grps = model.Session.query(model.GroupRevision).\
            filter_by(revision=c.revision)
        c.groups = [grp.continuity for grp in grps]
        return base.render('revision/read.html')

    def diff(self, id=None):
        if 'diff' not in request.params or 'oldid' not in request.params:
            base.abort(400)
        c.revision_from = model.Session.query(model.Revision).get(
            request.params.getone('oldid'))
        c.revision_to = model.Session.query(model.Revision).get(
            request.params.getone('diff'))

        c.diff_entity = request.params.get('diff_entity')
        if c.diff_entity == 'package':
            c.pkg = model.Package.by_name(id)
            diff = c.pkg.diff(c.revision_to, c.revision_from)
        elif c.diff_entity == 'group':
            c.group = model.Group.by_name(id)
            diff = c.group.diff(c.revision_to, c.revision_from)
        else:
            base.abort(400)

        c.diff = diff.items()
        c.diff.sort()
        return base.render('revision/diff.html')

    def edit(self, id=None):
        if id is None:
            base.abort(404)
        revision = model.Session.query(model.Revision).get(id)
        if revision is None:
            base.abort(404)
        action = request.params.get('action', '')
        if action in ['delete', 'undelete']:
            # this should be at a lower level (e.g. logic layer)
            if not c.revision_change_state_allowed:
                base.abort(401)
            if action == 'delete':
                revision.state = model.State.DELETED
            elif action == 'undelete':
                revision.state = model.State.ACTIVE
            model.Session.commit()
            h.flash_success(_('Revision updated'))
            h.redirect_to(
                h.url_for(controller='revision', action='read', id=id))

########NEW FILE########
__FILENAME__ = storage
import os
import re
import urllib
import uuid
from datetime import datetime
from cgi import FieldStorage

from ofs import get_impl
from pylons import request, response
from pylons.controllers.util import abort, redirect_to
from pylons import config
from paste.fileapp import FileApp
from paste.deploy.converters import asbool

from ckan.lib.base import BaseController, c, request, render, config, h, abort
from ckan.lib.jsonp import jsonpify
import ckan.model as model
import ckan.logic as logic

try:
    from cStringIO import StringIO
except ImportError:
    from StringIO import StringIO
try:
    import json
except:
    import simplejson as json

from logging import getLogger
log = getLogger(__name__)


BUCKET = config.get('ckan.storage.bucket', 'default')
key_prefix = config.get('ckan.storage.key_prefix', 'file/')

_eq_re = re.compile(r"^(.*)(=[0-9]*)$")


def fix_stupid_pylons_encoding(data):
    """
    Fix an apparent encoding problem when calling request.body
    TODO: Investigate whether this is fixed in later versions?
    """
    if data.startswith("%") or data.startswith("+"):
        data = urllib.unquote_plus(data)
    m = _eq_re.match(data)
    if m:
        data = m.groups()[0]
    return data


def create_pairtree_marker(folder):
    """ Creates the pairtree marker for tests if it doesn't exist """
    if not folder[:-1] == '/':
        folder = folder + '/'

    directory = os.path.dirname(folder)
    if not os.path.exists(directory):
        os.makedirs(directory)

    target = os.path.join(directory, 'pairtree_version0_1')
    if os.path.exists(target):
        return

    open(target, 'wb').close()


def get_ofs():
    """Return a configured instance of the appropriate OFS driver.
    """
    storage_backend = config['ofs.impl']
    kw = {}
    for k, v in config.items():
        if not k.startswith('ofs.') or k == 'ofs.impl':
            continue
        kw[k[4:]] = v

    # Make sure we have created the marker file to avoid pairtree issues
    if storage_backend == 'pairtree' and 'storage_dir' in kw:
        create_pairtree_marker(kw['storage_dir'])

    ofs = get_impl(storage_backend)(**kw)
    return ofs


def authorize(method, bucket, key, user, ofs):
    """
    Check authz for the user with a given bucket/key combo within a
    particular ofs implementation.
    """
    if not method in ['POST', 'GET', 'PUT', 'DELETE']:
        abort(400)
    if method != 'GET':
        # do not allow overwriting
        if ofs.exists(bucket, key):
            abort(409)
        # now check user stuff
        context = {'user': c.user,
                   'model': model}
        try:
            logic.check_access('file_upload', context, {})
        except logic.NotAuthorized:
            h.flash_error('Not authorized to upload files.')
            abort(401)


class StorageController(BaseController):
    '''Upload to storage backend.
    '''
    _ofs_impl = None

    @property
    def ofs(self):
        if not StorageController._ofs_impl:
            StorageController._ofs_impl = get_ofs()
        return StorageController._ofs_impl

    def upload(self):
        label = key_prefix + request.params.get('filepath', str(uuid.uuid4()))
        c.data = {
            'action': h.url_for('storage_upload_handle', qualified=False),
            'fields': [
                {
                    'name': 'key',
                    'value': label
                }
            ]
        }
        return render('storage/index.html')

    def upload_handle(self):
        bucket_id = BUCKET
        params = dict(request.params.items())
        stream = params.get('file')
        label = params.get('key')
        authorize('POST', BUCKET, label, c.userobj, self.ofs)
        if not label:
            abort(400, "No label")
        if not isinstance(stream, FieldStorage):
            abort(400, "No file stream.")
        del params['file']
        params['filename-original'] = stream.filename
        #params['_owner'] = c.userobj.name if c.userobj else ""
        params['uploaded-by'] = c.userobj.name if c.userobj else ""

        self.ofs.put_stream(bucket_id, label, stream.file, params)
        success_action_redirect = h.url_for(
            'storage_upload_success', qualified=True,
            bucket=BUCKET, label=label)
        # Do not redirect here as it breaks js file uploads (get infinite loop
        # in FF and crash in Chrome)
        return self.success(label)

    def success(self, label=None):
        label = request.params.get('label', label)
        h.flash_success('Upload successful')
        c.file_url = h.url_for('storage_file',
                               label=label,
                               qualified=True)
        c.upload_url = h.url_for('storage_upload')
        return render('storage/success.html')

    def success_empty(self, label=None):
        # very simple method that just returns 200 OK
        return ''

    def file(self, label):
        exists = self.ofs.exists(BUCKET, label)
        if not exists:
            # handle erroneous trailing slash by redirecting to url w/o slash
            if label.endswith('/'):
                label = label[:-1]
                # This may be best being cached_url until we have moved it into
                # permanent storage
                file_url = h.url_for('storage_file', label=label)
                h.redirect_to(file_url)
            else:
                abort(404)

        file_url = self.ofs.get_url(BUCKET, label)
        if file_url.startswith("file://"):
            metadata = self.ofs.get_metadata(BUCKET, label)
            filepath = file_url[len("file://"):]
            headers = {
                # 'Content-Disposition':'attachment; filename="%s"' % label,
                'Content-Type': metadata.get('_format', 'text/plain')}
            fapp = FileApp(filepath, headers=None, **headers)
            return fapp(request.environ, self.start_response)
        else:
            h.redirect_to(file_url.encode('ascii', 'ignore'))


class StorageAPIController(BaseController):
    _ofs_impl = None

    @property
    def ofs(self):
        if not StorageAPIController._ofs_impl:
            StorageAPIController._ofs_impl = get_ofs()
        return StorageAPIController._ofs_impl

    @jsonpify
    def index(self):
        info = {
            'metadata/{label}': {
                'description': 'Get or set metadata for this '
                               'item in storage', },
            'auth/request/{label}': {
                'description': self.auth_request.__doc__, },
            'auth/form/{label}': {
                'description': self.auth_form.__doc__, }}
        return info

    def set_metadata(self, label):
        bucket = BUCKET
        if not label.startswith("/"):
            label = "/" + label

        try:
            data = fix_stupid_pylons_encoding(request.body)
            if data:
                metadata = json.loads(data)
            else:
                metadata = {}
        except:
            abort(400)

        try:
            b = self.ofs._require_bucket(bucket)
        except:
            abort(409)

        k = self.ofs._get_key(b, label)
        if k is None:
            k = b.new_key(label)
            metadata = metadata.copy()
            metadata["_creation_time"] = str(datetime.utcnow())
            self.ofs._update_key_metadata(k, metadata)
            k.set_contents_from_file(StringIO(''))
        elif request.method == "PUT":
            old = self.ofs.get_metadata(bucket, label)
            to_delete = []
            for ok in old.keys():
                if ok not in metadata:
                    to_delete.append(ok)
            if to_delete:
                self.ofs.del_metadata_keys(bucket, label, to_delete)
            self.ofs.update_metadata(bucket, label, metadata)
        else:
            self.ofs.update_metadata(bucket, label, metadata)

        k.make_public()
        k.close()

        return self.get_metadata(bucket, label)

    @jsonpify
    def get_metadata(self, label):
        bucket = BUCKET
        storage_backend = config['ofs.impl']
        if storage_backend in ['google', 's3']:
            if not label.startswith("/"):
                label = "/" + label
            url = "https://%s%s" % (
                self.ofs.conn.calling_format.build_host(
                    self.ofs.conn.server_name(), bucket), label)
        else:
            url = h.url_for('storage_file',
                            label=label,
                            qualified=False
                            )
            if url.startswith('/'):
                url = config.get('ckan.site_url', '').rstrip('/') + url

        if not self.ofs.exists(bucket, label):
            abort(404)
        metadata = self.ofs.get_metadata(bucket, label)
        metadata["_location"] = url
        return metadata

    @jsonpify
    def auth_request(self, label):
        '''Provide authentication information for a request so a client can
        interact with backend storage directly.

        :param label: label.
        :param kwargs: sent either via query string for GET or json-encoded
            dict for POST). Interpreted as http headers for request plus an
            (optional) method parameter (being the HTTP method).

            Examples of headers are:

                Content-Type
                Content-Encoding (optional)
                Content-Length
                Content-MD5
                Expect (should be '100-Continue')

        :return: is a json hash containing various attributes including a
        headers dictionary containing an Authorization field which is good for
        15m.

        '''
        bucket = BUCKET
        if request.POST:
            try:
                data = fix_stupid_pylons_encoding(request.body)
                headers = json.loads(data)
            except Exception:
                from traceback import print_exc
                msg = StringIO()
                print_exc(msg)
                log.error(msg.seek(0).read())
                abort(400)
        else:
            headers = dict(request.params)
        if 'method' in headers:
            method = headers['method']
            del headers['method']
        else:
            method = 'POST'

        authorize(method, bucket, label, c.userobj, self.ofs)

        http_request = self.ofs.authenticate_request(method, bucket, label,
                                                     headers)
        return {
            'host': http_request.host,
            'method': http_request.method,
            'path': http_request.path,
            'headers': http_request.headers}

    def _get_remote_form_data(self, label):
        method = 'POST'
        content_length_range = \
            int(config.get('ckan.storage.max_content_length', 50000000))
        acl = 'public-read'
        fields = [{
            'name': self.ofs.conn.provider.metadata_prefix + 'uploaded-by',
            'value': c.userobj.id}]
        conditions = ['{"%s": "%s"}' % (x['name'], x['value']) for x in
                      fields]
        # In FF redirect to this breaks js upload as FF attempts to open file
        # (presumably because mimetype = javascript) and this stops js
        # success_action_redirect = h.url_for('storage_api_get_metadata',
        # qualified=True, label=label)
        success_action_redirect = h.url_for('storage_upload_success_empty',
                                            qualified=True,
                                            label=label)
        data = self.ofs.conn.build_post_form_args(
            BUCKET,
            label,
            expires_in=72000,
            max_content_length=content_length_range,
            success_action_redirect=success_action_redirect,
            acl=acl,
            fields=fields,
            conditions=conditions
        )
        # HACK: fix up some broken stuff from boto
        # e.g. should not have content-length-range in list of fields!
        storage_backend = config['ofs.impl']
        for idx, field in enumerate(data['fields']):
            if storage_backend == 'google':
                if field['name'] == 'AWSAccessKeyId':
                    field['name'] = 'GoogleAccessId'
            if field['name'] == 'content-length-range':
                del data['fields'][idx]
        return data

    def _get_form_data(self, label):
        storage_backend = config['ofs.impl']
        if storage_backend in ['google', 's3']:
            return self._get_remote_form_data(label)
        else:
            data = {
                'action': h.url_for('storage_upload_handle', qualified=False),
                'fields': [
                    {
                        'name': 'key',
                        'value': label
                    }
                ]
            }
            return data

    @jsonpify
    def auth_form(self, label):
        '''Provide fields for a form upload to storage including
        authentication.

        :param label: label.
        :return: json-encoded dictionary with action parameter and fields list.
        '''
        bucket = BUCKET
        if request.POST:
            try:
                data = fix_stupid_pylons_encoding(request.body)
                headers = json.loads(data)
            except Exception:
                from traceback import print_exc
                msg = StringIO()
                print_exc(msg)
                log.error(msg.seek(0).read())
                abort(400)
        else:
            headers = dict(request.params)

        method = 'POST'
        authorize(method, bucket, label, c.userobj, self.ofs)
        data = self._get_form_data(label)
        return data

########NEW FILE########
__FILENAME__ = tag
from pylons import config

import ckan.logic as logic
import ckan.model as model
import ckan.lib.base as base
import ckan.lib.helpers as h

from ckan.common import _, request, c


LIMIT = 25


class TagController(base.BaseController):

    def __before__(self, action, **env):
        base.BaseController.__before__(self, action, **env)
        try:
            context = {'model': model, 'user': c.user or c.author,
                       'auth_user_obj': c.userobj}
            logic.check_access('site_read', context)
        except logic.NotAuthorized:
            base.abort(401, _('Not authorized to see this page'))

    def index(self):
        c.q = request.params.get('q', '')

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj,
                   'for_view': True}

        data_dict = {'all_fields': True}

        if c.q:
            page = int(request.params.get('page', 1))
            data_dict['q'] = c.q
            data_dict['limit'] = LIMIT
            data_dict['offset'] = (page - 1) * LIMIT
            data_dict['return_objects'] = True

        results = logic.get_action('tag_list')(context, data_dict)

        if c.q:
            c.page = h.Page(
                collection=results,
                page=page,
                item_count=len(results),
                items_per_page=LIMIT
            )
            c.page.items = results
        else:
            c.page = h.AlphaPage(
                collection=results,
                page=request.params.get('page', 'A'),
                alpha_attribute='name',
                other_text=_('Other'),
            )

        return base.render('tag/index.html')

    def read(self, id):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj,
                   'for_view': True}

        data_dict = {'id': id}
        try:
            c.tag = logic.get_action('tag_show')(context, data_dict)
        except logic.NotFound:
            base.abort(404, _('Tag not found'))

        if h.asbool(config.get('ckan.legacy_templates', False)):
            return base.render('tag/read.html')
        else:
            h.redirect_to(controller='package', action='search',
                          tags=c.tag.get('name'))

########NEW FILE########
__FILENAME__ = template
import ckan.lib.base as base
import ckan.lib.render


class TemplateController(base.BaseController):

    def view(self, url):
        """By default, the final controller tried to fulfill the request
        when no other routes match. It may be used to display a template
        when all else fails, e.g.::

            def view(self, url):
                return render('/%s' % url)

        Or if you're using Mako and want to explicitly send a 404 (Not
        Found) response code when the requested template doesn't exist::

            import mako.exceptions

            def view(self, url):
                try:
                    return render('/%s' % url)
                except mako.exceptions.TopLevelLookupException:
                    abort(404)

        By default this controller aborts the request with a 404 (Not
        Found)
        """
        try:
            return base.render(url)
        except ckan.lib.render.TemplateNotFound:
            if url.endswith('.html'):
                base.abort(404)
            url += '.html'
            try:
                return base.render(url)
            except ckan.lib.render.TemplateNotFound:
                base.abort(404)

########NEW FILE########
__FILENAME__ = user
import logging
from urllib import quote

from pylons import config

import ckan.lib.base as base
import ckan.model as model
import ckan.lib.helpers as h
import ckan.new_authz as new_authz
import ckan.logic as logic
import ckan.logic.schema as schema
import ckan.lib.captcha as captcha
import ckan.lib.mailer as mailer
import ckan.lib.navl.dictization_functions as dictization_functions
import ckan.plugins as p

from ckan.common import _, c, g, request

log = logging.getLogger(__name__)


abort = base.abort
render = base.render
validate = base.validate

check_access = logic.check_access
get_action = logic.get_action
NotFound = logic.NotFound
NotAuthorized = logic.NotAuthorized
ValidationError = logic.ValidationError

DataError = dictization_functions.DataError
unflatten = dictization_functions.unflatten


class UserController(base.BaseController):
    def __before__(self, action, **env):
        base.BaseController.__before__(self, action, **env)
        try:
            context = {'model': model, 'user': c.user or c.author,
                       'auth_user_obj': c.userobj}
            check_access('site_read', context)
        except NotAuthorized:
            if c.action not in ('login', 'request_reset', 'perform_reset',):
                abort(401, _('Not authorized to see this page'))

    ## hooks for subclasses
    new_user_form = 'user/new_user_form.html'
    edit_user_form = 'user/edit_user_form.html'

    def _new_form_to_db_schema(self):
        return schema.user_new_form_schema()

    def _db_to_new_form_schema(self):
        '''This is an interface to manipulate data from the database
        into a format suitable for the form (optional)'''

    def _edit_form_to_db_schema(self):
        return schema.user_edit_form_schema()

    def _db_to_edit_form_schema(self):
        '''This is an interface to manipulate data from the database
        into a format suitable for the form (optional)'''

    def _setup_template_variables(self, context, data_dict):
        c.is_sysadmin = new_authz.is_sysadmin(c.user)
        try:
            user_dict = get_action('user_show')(context, data_dict)
        except NotFound:
            abort(404, _('User not found'))
        except NotAuthorized:
            abort(401, _('Not authorized to see this page'))
        c.user_dict = user_dict
        c.is_myself = user_dict['name'] == c.user
        c.about_formatted = h.render_markdown(user_dict['about'])

    ## end hooks

    def _get_repoze_handler(self, handler_name):
        '''Returns the URL that repoze.who will respond to and perform a
        login or logout.'''
        return getattr(request.environ['repoze.who.plugins']['friendlyform'],
                       handler_name)

    def index(self):
        LIMIT = 20

        page = int(request.params.get('page', 1))
        c.q = request.params.get('q', '')
        c.order_by = request.params.get('order_by', 'name')

        context = {'return_query': True, 'user': c.user or c.author,
                   'auth_user_obj': c.userobj}

        data_dict = {'q': c.q,
                     'order_by': c.order_by}
        try:
            check_access('user_list', context, data_dict)
        except NotAuthorized:
            abort(401, _('Not authorized to see this page'))

        users_list = get_action('user_list')(context, data_dict)

        c.page = h.Page(
            collection=users_list,
            page=page,
            url=h.pager_url,
            item_count=users_list.count(),
            items_per_page=LIMIT
        )
        return render('user/list.html')

    def read(self, id=None):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj,
                   'for_view': True}
        data_dict = {'id': id,
                     'user_obj': c.userobj}

        context['with_related'] = True

        self._setup_template_variables(context, data_dict)

        # The legacy templates have the user's activity stream on the user
        # profile page, new templates do not.
        if h.asbool(config.get('ckan.legacy_templates', False)):
            c.user_activity_stream = get_action('user_activity_list_html')(
                context, {'id': c.user_dict['id']})

        return render('user/read.html')

    def me(self, locale=None):
        if not c.user:
            h.redirect_to(locale=locale, controller='user', action='login',
                          id=None)
        user_ref = c.userobj.get_reference_preferred_for_uri()
        h.redirect_to(locale=locale, controller='user', action='dashboard',
                      id=user_ref)

    def register(self, data=None, errors=None, error_summary=None):
        context = {'model': model, 'session': model.Session, 'user': c.user,
                   'auth_user_obj': c.userobj}
        try:
            check_access('user_create', context)
        except NotAuthorized:
            abort(401, _('Unauthorized to register as a user.'))

        return self.new(data, errors, error_summary)

    def new(self, data=None, errors=None, error_summary=None):
        '''GET to display a form for registering a new user.
           or POST the form data to actually do the user registration.
        '''
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author,
                   'auth_user_obj': c.userobj,
                   'schema': self._new_form_to_db_schema(),
                   'save': 'save' in request.params}

        try:
            check_access('user_create', context)
        except NotAuthorized:
            abort(401, _('Unauthorized to create a user'))

        if context['save'] and not data:
            return self._save_new(context)

        if c.user and not data:
            # #1799 Don't offer the registration form if already logged in
            return render('user/logout_first.html')

        data = data or {}
        errors = errors or {}
        error_summary = error_summary or {}
        vars = {'data': data, 'errors': errors, 'error_summary': error_summary}

        c.is_sysadmin = new_authz.is_sysadmin(c.user)
        c.form = render(self.new_user_form, extra_vars=vars)
        return render('user/new.html')

    def delete(self, id):
        '''Delete user with id passed as parameter'''
        context = {'model': model,
                   'session': model.Session,
                   'user': c.user,
                   'auth_user_obj': c.userobj}
        data_dict = {'id': id}

        try:
            get_action('user_delete')(context, data_dict)
            user_index = h.url_for(controller='user', action='index')
            h.redirect_to(user_index)
        except NotAuthorized:
            msg = _('Unauthorized to delete user with id "{user_id}".')
            abort(401, msg.format(user_id=id))

    def _save_new(self, context):
        try:
            data_dict = logic.clean_dict(unflatten(
                logic.tuplize_dict(logic.parse_params(request.params))))
            context['message'] = data_dict.get('log_message', '')
            captcha.check_recaptcha(request)
            user = get_action('user_create')(context, data_dict)
        except NotAuthorized:
            abort(401, _('Unauthorized to create user %s') % '')
        except NotFound, e:
            abort(404, _('User not found'))
        except DataError:
            abort(400, _(u'Integrity Error'))
        except captcha.CaptchaError:
            error_msg = _(u'Bad Captcha. Please try again.')
            h.flash_error(error_msg)
            return self.new(data_dict)
        except ValidationError, e:
            errors = e.error_dict
            error_summary = e.error_summary
            return self.new(data_dict, errors, error_summary)
        if not c.user:
            # Redirect to a URL picked up by repoze.who which performs the
            # login
            login_url = self._get_repoze_handler('login_handler_path')

            # We need to pass the logged in URL as came_from parameter
            # otherwise we lose the language setting
            came_from = h.url_for(controller='user', action='logged_in',
                                  __ckan_no_root=True)
            redirect_url = '{0}?login={1}&password={2}&came_from={3}'
            h.redirect_to(redirect_url.format(
                login_url,
                str(data_dict['name']),
                quote(data_dict['password1'].encode('utf-8')),
                came_from))
        else:
            # #1799 User has managed to register whilst logged in - warn user
            # they are not re-logged in as new user.
            h.flash_success(_('User "%s" is now registered but you are still '
                            'logged in as "%s" from before') %
                            (data_dict['name'], c.user))
            return render('user/logout_first.html')

    def edit(self, id=None, data=None, errors=None, error_summary=None):
        context = {'save': 'save' in request.params,
                   'schema': self._edit_form_to_db_schema(),
                   'model': model, 'session': model.Session,
                   'user': c.user, 'auth_user_obj': c.userobj
                   }
        if id is None:
            if c.userobj:
                id = c.userobj.id
            else:
                abort(400, _('No user specified'))
        data_dict = {'id': id}

        try:
            check_access('user_update', context, data_dict)
        except NotAuthorized:
            abort(401, _('Unauthorized to edit a user.'))

        if (context['save']) and not data:
            return self._save_edit(id, context)

        try:
            old_data = get_action('user_show')(context, data_dict)

            schema = self._db_to_edit_form_schema()
            if schema:
                old_data, errors = validate(old_data, schema)

            c.display_name = old_data.get('display_name')
            c.user_name = old_data.get('name')

            data = data or old_data

        except NotAuthorized:
            abort(401, _('Unauthorized to edit user %s') % '')
        except NotFound:
            abort(404, _('User not found'))

        user_obj = context.get('user_obj')

        if not (new_authz.is_sysadmin(c.user)
                or c.user == user_obj.name):
            abort(401, _('User %s not authorized to edit %s') %
                  (str(c.user), id))

        errors = errors or {}
        vars = {'data': data, 'errors': errors, 'error_summary': error_summary}

        self._setup_template_variables({'model': model,
                                        'session': model.Session,
                                        'user': c.user or c.author},
                                       data_dict)

        c.is_myself = True
        c.show_email_notifications = h.asbool(
            config.get('ckan.activity_streams_email_notifications'))
        c.form = render(self.edit_user_form, extra_vars=vars)

        return render('user/edit.html')

    def _save_edit(self, id, context):
        try:
            data_dict = logic.clean_dict(unflatten(
                logic.tuplize_dict(logic.parse_params(request.params))))
            context['message'] = data_dict.get('log_message', '')
            data_dict['id'] = id

            # MOAN: Do I really have to do this here?
            if 'activity_streams_email_notifications' not in data_dict:
                data_dict['activity_streams_email_notifications'] = False

            user = get_action('user_update')(context, data_dict)
            h.flash_success(_('Profile updated'))
            h.redirect_to(controller='user', action='read', id=user['name'])
        except NotAuthorized:
            abort(401, _('Unauthorized to edit user %s') % id)
        except NotFound, e:
            abort(404, _('User not found'))
        except DataError:
            abort(400, _(u'Integrity Error'))
        except ValidationError, e:
            errors = e.error_dict
            error_summary = e.error_summary
            return self.edit(id, data_dict, errors, error_summary)

    def login(self, error=None):
        # Do any plugin login stuff
        for item in p.PluginImplementations(p.IAuthenticator):
            item.login()

        if 'error' in request.params:
            h.flash_error(request.params['error'])

        if request.environ['SCRIPT_NAME'] and g.openid_enabled:
            # #1662 restriction
            log.warn('Cannot mount CKAN at a URL and login with OpenID.')
            g.openid_enabled = False

        if not c.user:
            came_from = request.params.get('came_from')
            if not came_from:
                came_from = h.url_for(controller='user', action='logged_in',
                                      __ckan_no_root=True)
            c.login_handler = h.url_for(
                self._get_repoze_handler('login_handler_path'),
                came_from=came_from)
            if error:
                vars = {'error_summary': {'': error}}
            else:
                vars = {}
            return render('user/login.html', extra_vars=vars)
        else:
            return render('user/logout_first.html')

    def logged_in(self):
        # redirect if needed
        came_from = request.params.get('came_from', '')
        if h.url_is_local(came_from):
            return h.redirect_to(str(came_from))

        if c.user:
            context = None
            data_dict = {'id': c.user}

            user_dict = get_action('user_show')(context, data_dict)

            return self.me()
        else:
            err = _('Login failed. Bad username or password.')
            if g.openid_enabled:
                err += _(' (Or if using OpenID, it hasn\'t been associated '
                         'with a user account.)')
            if h.asbool(config.get('ckan.legacy_templates', 'false')):
                h.flash_error(err)
                h.redirect_to(controller='user',
                              action='login', came_from=came_from)
            else:
                return self.login(error=err)

    def logout(self):
        # Do any plugin logout stuff
        for item in p.PluginImplementations(p.IAuthenticator):
            item.logout()
        url = h.url_for(controller='user', action='logged_out_page',
                        __ckan_no_root=True)
        h.redirect_to(self._get_repoze_handler('logout_handler_path') +
                      '?came_from=' + url)

    def logged_out(self):
        # redirect if needed
        came_from = request.params.get('came_from', '')
        if h.url_is_local(came_from):
            return h.redirect_to(str(came_from))
        h.redirect_to(controller='user', action='logged_out_page')

    def logged_out_page(self):
        return render('user/logout.html')

    def request_reset(self):
        context = {'model': model, 'session': model.Session, 'user': c.user,
                   'auth_user_obj': c.userobj}
        data_dict = {'id': request.params.get('user')}
        try:
            check_access('request_reset', context)
        except NotAuthorized:
            abort(401, _('Unauthorized to request reset password.'))

        if request.method == 'POST':
            id = request.params.get('user')

            context = {'model': model,
                       'user': c.user}

            data_dict = {'id': id}
            user_obj = None
            try:
                user_dict = get_action('user_show')(context, data_dict)
                user_obj = context['user_obj']
            except NotFound:
                # Try searching the user
                del data_dict['id']
                data_dict['q'] = id

                if id and len(id) > 2:
                    user_list = get_action('user_list')(context, data_dict)
                    if len(user_list) == 1:
                        # This is ugly, but we need the user object for the
                        # mailer,
                        # and user_list does not return them
                        del data_dict['q']
                        data_dict['id'] = user_list[0]['id']
                        user_dict = get_action('user_show')(context, data_dict)
                        user_obj = context['user_obj']
                    elif len(user_list) > 1:
                        h.flash_error(_('"%s" matched several users') % (id))
                    else:
                        h.flash_error(_('No such user: %s') % id)
                else:
                    h.flash_error(_('No such user: %s') % id)

            if user_obj:
                try:
                    mailer.send_reset_link(user_obj)
                    h.flash_success(_('Please check your inbox for '
                                    'a reset code.'))
                    h.redirect_to('/')
                except mailer.MailerException, e:
                    h.flash_error(_('Could not send reset link: %s') %
                                  unicode(e))
        return render('user/request_reset.html')

    def perform_reset(self, id):
        # FIXME 403 error for invalid key is a non helpful page
        # FIXME We should reset the reset key when it is used to prevent
        # reuse of the url
        context = {'model': model, 'session': model.Session,
                   'user': id,
                   'keep_email': True}

        try:
            check_access('user_reset', context)
        except NotAuthorized:
            abort(401, _('Unauthorized to reset password.'))

        try:
            data_dict = {'id': id}
            user_dict = get_action('user_show')(context, data_dict)

            user_obj = context['user_obj']
        except NotFound, e:
            abort(404, _('User not found'))

        c.reset_key = request.params.get('key')
        if not mailer.verify_reset_link(user_obj, c.reset_key):
            h.flash_error(_('Invalid reset key. Please try again.'))
            abort(403)

        if request.method == 'POST':
            try:
                context['reset_password'] = True
                new_password = self._get_form_password()
                user_dict['password'] = new_password
                user_dict['reset_key'] = c.reset_key
                user_dict['state'] = model.State.ACTIVE
                user = get_action('user_update')(context, user_dict)

                h.flash_success(_("Your password has been reset."))
                h.redirect_to('/')
            except NotAuthorized:
                h.flash_error(_('Unauthorized to edit user %s') % id)
            except NotFound, e:
                h.flash_error(_('User not found'))
            except DataError:
                h.flash_error(_(u'Integrity Error'))
            except ValidationError, e:
                h.flash_error(u'%r' % e.error_dict)
            except ValueError, ve:
                h.flash_error(unicode(ve))

        c.user_dict = user_dict
        return render('user/perform_reset.html')

    def _get_form_password(self):
        password1 = request.params.getone('password1')
        password2 = request.params.getone('password2')
        if (password1 is not None and password1 != ''):
            if not len(password1) >= 4:
                raise ValueError(_('Your password must be 4 '
                                 'characters or longer.'))
            elif not password1 == password2:
                raise ValueError(_('The passwords you entered'
                                 ' do not match.'))
            return password1
        raise ValueError(_('You must provide a password'))

    def followers(self, id=None):
        context = {'for_view': True, 'user': c.user or c.author,
                   'auth_user_obj': c.userobj}
        data_dict = {'id': id, 'user_obj': c.userobj}
        self._setup_template_variables(context, data_dict)
        f = get_action('user_follower_list')
        try:
            c.followers = f(context, {'id': c.user_dict['id']})
        except NotAuthorized:
            abort(401, _('Unauthorized to view followers %s') % '')
        return render('user/followers.html')

    def activity(self, id, offset=0):
        '''Render this user's public activity stream page.'''

        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj,
                   'for_view': True}
        data_dict = {'id': id, 'user_obj': c.userobj}
        try:
            check_access('user_show', context, data_dict)
        except NotAuthorized:
            abort(401, _('Not authorized to see this page'))

        self._setup_template_variables(context, data_dict)

        c.user_activity_stream = get_action('user_activity_list_html')(
            context, {'id': c.user_dict['id'], 'offset': offset})

        return render('user/activity_stream.html')

    def _get_dashboard_context(self, filter_type=None, filter_id=None, q=None):
        '''Return a dict needed by the dashboard view to determine context.'''

        def display_name(followee):
            '''Return a display name for a user, group or dataset dict.'''
            display_name = followee.get('display_name')
            fullname = followee.get('fullname')
            title = followee.get('title')
            name = followee.get('name')
            return display_name or fullname or title or name

        if (filter_type and filter_id):
            context = {
                'model': model, 'session': model.Session,
                'user': c.user or c.author, 'auth_user_obj': c.userobj,
                'for_view': True
            }
            data_dict = {'id': filter_id}
            followee = None

            action_functions = {
                'dataset': 'package_show',
                'user': 'user_show',
                'group': 'group_show',
                'organization': 'organization_show',
            }
            action_function = logic.get_action(
                action_functions.get(filter_type))
            # Is this a valid type?
            if action_function is None:
                abort(404, _('Follow item not found'))
            try:
                followee = action_function(context, data_dict)
            except NotFound:
                abort(404, _('{0} not found').format(filter_type))
            except NotAuthorized:
                abort(401, _('Unauthorized to read {0} {1}').format(
                    filter_type, id))

            if followee is not None:
                return {
                    'filter_type': filter_type,
                    'q': q,
                    'context': display_name(followee),
                    'selected_id': followee.get('id'),
                    'dict': followee,
                }

        return {
            'filter_type': filter_type,
            'q': q,
            'context': _('Everything'),
            'selected_id': False,
            'dict': None,
        }

    def dashboard(self, id=None, offset=0):
        context = {'model': model, 'session': model.Session,
                   'user': c.user or c.author, 'auth_user_obj': c.userobj,
                   'for_view': True}
        data_dict = {'id': id, 'user_obj': c.userobj, 'offset': offset}
        self._setup_template_variables(context, data_dict)

        q = request.params.get('q', u'')
        filter_type = request.params.get('type', u'')
        filter_id = request.params.get('name', u'')

        c.followee_list = get_action('followee_list')(
            context, {'id': c.userobj.id, 'q': q})
        c.dashboard_activity_stream_context = self._get_dashboard_context(
            filter_type, filter_id, q)
        c.dashboard_activity_stream = h.dashboard_activity_stream(
            c.userobj.id, filter_type, filter_id, offset
        )

        # Mark the user's new activities as old whenever they view their
        # dashboard page.
        get_action('dashboard_mark_activities_old')(context, {})

        return render('user/dashboard.html')

    def dashboard_datasets(self):
        context = {'for_view': True, 'user': c.user or c.author,
                   'auth_user_obj': c.userobj}
        data_dict = {'user_obj': c.userobj}
        self._setup_template_variables(context, data_dict)
        return render('user/dashboard_datasets.html')

    def dashboard_organizations(self):
        context = {'for_view': True, 'user': c.user or c.author,
                   'auth_user_obj': c.userobj}
        data_dict = {'user_obj': c.userobj}
        self._setup_template_variables(context, data_dict)
        return render('user/dashboard_organizations.html')

    def dashboard_groups(self):
        context = {'for_view': True, 'user': c.user or c.author,
                   'auth_user_obj': c.userobj}
        data_dict = {'user_obj': c.userobj}
        self._setup_template_variables(context, data_dict)
        return render('user/dashboard_groups.html')

    def follow(self, id):
        '''Start following this user.'''
        context = {'model': model,
                   'session': model.Session,
                   'user': c.user or c.author,
                   'auth_user_obj': c.userobj}
        data_dict = {'id': id}
        try:
            get_action('follow_user')(context, data_dict)
            user_dict = get_action('user_show')(context, data_dict)
            h.flash_success(_("You are now following {0}").format(
                user_dict['display_name']))
        except ValidationError as e:
            error_message = (e.extra_msg or e.message or e.error_summary
                             or e.error_dict)
            h.flash_error(error_message)
        except NotAuthorized as e:
            h.flash_error(e.extra_msg)
        h.redirect_to(controller='user', action='read', id=id)

    def unfollow(self, id):
        '''Stop following this user.'''
        context = {'model': model,
                   'session': model.Session,
                   'user': c.user or c.author,
                   'auth_user_obj': c.userobj}
        data_dict = {'id': id}
        try:
            get_action('unfollow_user')(context, data_dict)
            user_dict = get_action('user_show')(context, data_dict)
            h.flash_success(_("You are no longer following {0}").format(
                user_dict['display_name']))
        except (NotFound, NotAuthorized) as e:
            error_message = e.extra_msg or e.message
            h.flash_error(error_message)
        except ValidationError as e:
            error_message = (e.error_summary or e.message or e.extra_msg
                             or e.error_dict)
            h.flash_error(error_message)
        h.redirect_to(controller='user', action='read', id=id)

########NEW FILE########
__FILENAME__ = util
import re

import ckan.lib.base as base
import ckan.lib.i18n as i18n
import ckan.lib.helpers as h
from ckan.common import _


class UtilController(base.BaseController):
    ''' Controller for functionality that has no real home'''

    def redirect(self):
        ''' redirect to the url parameter. '''
        url = base.request.params.get('url')
        if not url:
            base.abort(400, _('Missing Value') + ': url')

        if h.url_is_local(url):
            return base.redirect(url)
        else:
            base.abort(403, _('Redirecting to external site is not allowed.'))

    def primer(self):
        ''' Render all html components out onto a single page.
        This is useful for development/styling of ckan. '''
        return base.render('development/primer.html')

    def markup(self):
        ''' Render all html elements out onto a single page.
        This is useful for development/styling of ckan. '''
        return base.render('development/markup.html')

    def i18_js_strings(self, lang):
        ''' This is used to produce the translations for javascript. '''
        i18n.set_lang(lang)
        html = base.render('js_strings.html', cache_force=True)
        html = re.sub('<[^\>]*>', '', html)
        header = "text/javascript; charset=utf-8"
        base.response.headers['Content-type'] = header
        return html

########NEW FILE########
__FILENAME__ = exceptions
class CkanException(Exception):
    pass

class EmptyRevisionException(CkanException):
    pass

class CkanUrlException(Exception):
    pass

########NEW FILE########
__FILENAME__ = check_po_files
#!/usr/bin/env python
'''Script for checking for common translation mistakes in po files, see:

    paster check-po-files --help

for usage.

Requires polib <http://pypi.python.org/pypi/polib>:

    pip install polib

'''
import re
import paste.script.command

def simple_conv_specs(s):
    '''Return the simple Python string conversion specifiers in the string s.

    e.g. ['%s', '%i']

    See http://docs.python.org/library/stdtypes.html#string-formatting

    '''
    simple_conv_specs_re = re.compile('\%\w')
    return simple_conv_specs_re.findall(s)

def test_simple_conv_specs():
    assert simple_conv_specs("Authorization function not found: %s") == (
            ['%s'])
    assert simple_conv_specs("Problem purging revision %s: %s") == (
            ['%s', '%s'])
    assert simple_conv_specs(
            "Cannot create new entity of this type: %s %s") == ['%s', '%s']
    assert simple_conv_specs("Could not read parameters: %r") == ['%r']
    assert simple_conv_specs("User %r not authorized to edit %r") == (
            ['%r', '%r'])
    assert simple_conv_specs(
        "Please <a href=\"%s\">update your profile</a> and add your email "
        "address and your full name. "
        "%s uses your email address if you need to reset your password.") == (
                ['%s', '%s'])
    assert simple_conv_specs(
            "You can use %sMarkdown formatting%s here.") == ['%s', '%s']
    assert simple_conv_specs(
            "Name must be a maximum of %i characters long") == ['%i']
    assert simple_conv_specs("Blah blah %s blah %(key)s blah %i") == (
        ['%s', '%i'])

def mapping_keys(s):
    '''Return a sorted list of the mapping keys in the string s.

    e.g. ['%(name)s', '%(age)i']

    See http://docs.python.org/library/stdtypes.html#string-formatting

    '''
    mapping_keys_re = re.compile('\%\([^\)]*\)\w')
    return sorted(mapping_keys_re.findall(s))

def test_mapping_keys():
    assert mapping_keys(
            "You have requested your password on %(site_title)s to be reset.\n"
            "\n"
            "Please click the following link to confirm this request:\n"
            "\n"
            "   %(reset_link)s\n") == ['%(reset_link)s', '%(site_title)s']
    assert mapping_keys(
            "The input field %(name)s was not expected.") == ['%(name)s']
    assert mapping_keys(
            "[1:You searched for \"%(query)s\". ]%(number_of_results)s "
            "datasets found.") == ['%(number_of_results)s', '%(query)s']
    assert mapping_keys("Blah blah %s blah %(key)s blah %i") == (
        ['%(key)s']), mapping_keys("Blah blah %s blah %(key)s blah %i")

def replacement_fields(s):
    '''Return a sorted list of the Python replacement fields in the string s.

    e.g. ['{}', '{2}', '{object}', '{target}']

    See http://docs.python.org/library/string.html#formatstrings

    '''
    repl_fields_re = re.compile('\{[^\}]*\}')
    return sorted(repl_fields_re.findall(s))

def test_replacement_fields():
    assert replacement_fields(
            "{actor} added the tag {object} to the dataset {target}") == (
                    ['{actor}', '{object}', '{target}'])
    assert replacement_fields("{actor} updated their profile") == ['{actor}']

class CheckPoFiles(paste.script.command.Command):

    usage = "[FILE] ..."
    group_name = 'ckan'
    summary = 'Check po files for common mistakes'
    parser = paste.script.command.Command.standard_parser(verbose=True)

    def command(self):
        import polib

        test_simple_conv_specs()
        test_mapping_keys()
        test_replacement_fields()
        for path in self.args:
            print u'Checking file {}'.format(path)
            po = polib.pofile(path)
            for entry in po.translated_entries():
                if not entry.msgstr:
                    continue
                for function in (simple_conv_specs, mapping_keys,
                        replacement_fields):
                    if not function(entry.msgid) == function(entry.msgstr):
                        print "    Format specifiers don't match:"
                        print u'    {0} -> {1}'.format(entry.msgid, entry.msgstr)

########NEW FILE########
__FILENAME__ = rcssmin
#!/usr/bin/env python
# -*- coding: ascii -*-
#
# Copyright 2011, 2012
# Andr\xe9 Malo or his licensors, as applicable
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
r"""
==============
 CSS Minifier
==============

CSS Minifier.

The minifier is based on the semantics of the `YUI compressor`_\, which itself
is based on `the rule list by Isaac Schlueter`_\.

This module is a re-implementation aiming for speed instead of maximum
compression, so it can be used at runtime (rather than during a preprocessing
step). RCSSmin does syntactical compression only (removing spaces, comments
and possibly semicolons). It does not provide semantic compression (like
removing empty blocks, collapsing redundant properties etc). It does, however,
support various CSS hacks (by keeping them working as intended).

Here's a feature list:

- Strings are kept, except that escaped newlines are stripped
- Space/Comments before the very end or before various characters are
  stripped: ``:{});=>+],!`` (The colon (``:``) is a special case, a single
  space is kept if it's outside a ruleset.)
- Space/Comments at the very beginning or after various characters are
  stripped: ``{}(=:>+[,!``
- Optional space after unicode escapes is kept, resp. replaced by a simple
  space
- whitespaces inside ``url()`` definitions are stripped
- Comments starting with an exclamation mark (``!``) can be kept optionally.
- All other comments and/or whitespace characters are replaced by a single
  space.
- Multiple consecutive semicolons are reduced to one
- The last semicolon within a ruleset is stripped
- CSS Hacks supported:

  - IE7 hack (``>/**/``)
  - Mac-IE5 hack (``/*\*/.../**/``)
  - The boxmodelhack is supported naturally because it relies on valid CSS2
    strings
  - Between ``:first-line`` and the following comma or curly brace a space is
    inserted. (apparently it's needed for IE6)
  - Same for ``:first-letter``

rcssmin.c is a reimplementation of rcssmin.py in C and improves runtime up to
factor 50 or so (depending on the input).

Both python 2 (>= 2.4) and python 3 are supported.

.. _YUI compressor: https://github.com/yui/yuicompressor/

.. _the rule list by Isaac Schlueter: https://github.com/isaacs/cssmin/tree/
"""
__author__ = "Andr\xe9 Malo"
__author__ = getattr(__author__, 'decode', lambda x: __author__)('latin-1')
__docformat__ = "restructuredtext en"
__license__ = "Apache License, Version 2.0"
__version__ = '1.0.0'
__all__ = ['cssmin']

import re as _re


def _make_cssmin(python_only=False):
    """
    Generate CSS minifier.

    :Parameters:
      `python_only` : ``bool``
        Use only the python variant. If true, the c extension is not even
        tried to be loaded.

    :Return: Minifier
    :Rtype: ``callable``
    """
    # pylint: disable = W0612
    # ("unused" variables)

    # pylint: disable = R0911, R0912, R0914, R0915
    # (too many anything)

    if not python_only:
        try:
            import _rcssmin
        except ImportError:
            pass
        else:
            return _rcssmin.cssmin

    nl = r'(?:[\n\f]|\r\n?)' # pylint: disable = C0103
    spacechar = r'[\r\n\f\040\t]'

    unicoded = r'[0-9a-fA-F]{1,6}(?:[\040\n\t\f]|\r\n?)?'
    escaped = r'[^\n\r\f0-9a-fA-F]'
    escape = r'(?:\\(?:%(unicoded)s|%(escaped)s))' % locals()

    nmchar = r'[^\000-\054\056\057\072-\100\133-\136\140\173-\177]'
    #nmstart = r'[^\000-\100\133-\136\140\173-\177]'
    #ident = (r'(?:'
    #    r'-?(?:%(nmstart)s|%(escape)s)%(nmchar)s*(?:%(escape)s%(nmchar)s*)*'
    #r')') % locals()

    comment = r'(?:/\*[^*]*\*+(?:[^/*][^*]*\*+)*/)'

    # only for specific purposes. The bang is grouped:
    _bang_comment = r'(?:/\*(!?)[^*]*\*+(?:[^/*][^*]*\*+)*/)'

    string1 = \
        r'(?:\047[^\047\\\r\n\f]*(?:\\[^\r\n\f][^\047\\\r\n\f]*)*\047)'
    string2 = r'(?:"[^"\\\r\n\f]*(?:\\[^\r\n\f][^"\\\r\n\f]*)*")'
    strings = r'(?:%s|%s)' % (string1, string2)

    nl_string1 = \
        r'(?:\047[^\047\\\r\n\f]*(?:\\(?:[^\r]|\r\n?)[^\047\\\r\n\f]*)*\047)'
    nl_string2 = r'(?:"[^"\\\r\n\f]*(?:\\(?:[^\r]|\r\n?)[^"\\\r\n\f]*)*")'
    nl_strings = r'(?:%s|%s)' % (nl_string1, nl_string2)

    uri_nl_string1 = r'(?:\047[^\047\\]*(?:\\(?:[^\r]|\r\n?)[^\047\\]*)*\047)'
    uri_nl_string2 = r'(?:"[^"\\]*(?:\\(?:[^\r]|\r\n?)[^"\\]*)*")'
    uri_nl_strings = r'(?:%s|%s)' % (uri_nl_string1, uri_nl_string2)

    nl_escaped = r'(?:\\%(nl)s)' % locals()

    space = r'(?:%(spacechar)s|%(comment)s)' % locals()

    ie7hack = r'(?:>/\*\*/)'

    uri = (r'(?:'
        r'(?:[^\000-\040"\047()\\\177]*'
            r'(?:%(escape)s[^\000-\040"\047()\\\177]*)*)'
        r'(?:'
            r'(?:%(spacechar)s+|%(nl_escaped)s+)'
            r'(?:'
                r'(?:[^\000-\040"\047()\\\177]|%(escape)s|%(nl_escaped)s)'
                r'[^\000-\040"\047()\\\177]*'
                r'(?:%(escape)s[^\000-\040"\047()\\\177]*)*'
            r')+'
        r')*'
    r')') % locals()

    nl_unesc_sub = _re.compile(nl_escaped).sub

    uri_space_sub = _re.compile((
        r'(%(escape)s+)|%(spacechar)s+|%(nl_escaped)s+'
    ) % locals()).sub
    uri_space_subber = lambda m: m.groups()[0] or ''

    space_sub_simple = _re.compile((
        r'[\r\n\f\040\t;]+|(%(comment)s+)'
    ) % locals()).sub
    space_sub_banged = _re.compile((
        r'[\r\n\f\040\t;]+|(%(_bang_comment)s+)'
    ) % locals()).sub

    post_esc_sub = _re.compile(r'[\r\n\f\t]+').sub

    main_sub = _re.compile((
        r'([^\\"\047u>@\r\n\f\040\t/;:{}]+)'
        r'|(?<=[{}(=:>+[,!])(%(space)s+)'
        r'|^(%(space)s+)'
        r'|(%(space)s+)(?=(([:{});=>+\],!])|$)?)'
        r'|;(%(space)s*(?:;%(space)s*)*)(?=(\})?)'
        r'|(\{)'
        r'|(\})'
        r'|(%(strings)s)'
        r'|(?<!%(nmchar)s)url\(%(spacechar)s*('
                r'%(uri_nl_strings)s'
                r'|%(uri)s'
            r')%(spacechar)s*\)'
        r'|(@[mM][eE][dD][iI][aA])(?!%(nmchar)s)'
        r'|(%(ie7hack)s)(%(space)s*)'
        r'|(:[fF][iI][rR][sS][tT]-[lL]'
            r'(?:[iI][nN][eE]|[eE][tT][tT][eE][rR]))'
            r'(%(space)s*)(?=[{,])'
        r'|(%(nl_strings)s)'
        r'|(%(escape)s[^\\"\047u>@\r\n\f\040\t/;:{}]*)'
    ) % locals()).sub

    #print main_sub.__self__.pattern

    def main_subber(keep_bang_comments):
        """ Make main subber """
        in_macie5, in_rule, at_media = [0], [0], [0]

        if keep_bang_comments:
            space_sub = space_sub_banged
            def space_subber(match):
                """ Space|Comment subber """
                if match.lastindex:
                    group1, group2 = match.group(1, 2)
                    if group2:
                        if group1.endswith(r'\*/'):
                            in_macie5[0] = 1
                        else:
                            in_macie5[0] = 0
                        return group1
                    elif group1:
                        if group1.endswith(r'\*/'):
                            if in_macie5[0]:
                                return ''
                            in_macie5[0] = 1
                            return r'/*\*/'
                        elif in_macie5[0]:
                            in_macie5[0] = 0
                            return '/**/'
                return ''
        else:
            space_sub = space_sub_simple
            def space_subber(match):
                """ Space|Comment subber """
                if match.lastindex:
                    if match.group(1).endswith(r'\*/'):
                        if in_macie5[0]:
                            return ''
                        in_macie5[0] = 1
                        return r'/*\*/'
                    elif in_macie5[0]:
                        in_macie5[0] = 0
                        return '/**/'
                return ''

        def fn_space_post(group):
            """ space with token after """
            if group(5) is None or (
                    group(6) == ':' and not in_rule[0] and not at_media[0]):
                return ' ' + space_sub(space_subber, group(4))
            return space_sub(space_subber, group(4))

        def fn_semicolon(group):
            """ ; handler """
            return ';' + space_sub(space_subber, group(7))

        def fn_semicolon2(group):
            """ ; handler """
            if in_rule[0]:
                return space_sub(space_subber, group(7))
            return ';' + space_sub(space_subber, group(7))

        def fn_open(group):
            """ { handler """
            # pylint: disable = W0613
            if at_media[0]:
                at_media[0] -= 1
            else:
                in_rule[0] = 1
            return '{'

        def fn_close(group):
            """ } handler """
            # pylint: disable = W0613
            in_rule[0] = 0
            return '}'

        def fn_media(group):
            """ @media handler """
            at_media[0] += 1
            return group(13)

        def fn_ie7hack(group):
            """ IE7 Hack handler """
            if not in_rule[0] and not at_media[0]:
                in_macie5[0] = 0
                return group(14) + space_sub(space_subber, group(15))
            return '>' + space_sub(space_subber, group(15))

        table = (
            None,
            None,
            None,
            None,
            fn_space_post,                      # space with token after
            fn_space_post,                      # space with token after
            fn_space_post,                      # space with token after
            fn_semicolon,                       # semicolon
            fn_semicolon2,                      # semicolon
            fn_open,                            # {
            fn_close,                           # }
            lambda g: g(11),                    # string
            lambda g: 'url(%s)' % uri_space_sub(uri_space_subber, g(12)),
                                                # url(...)
            fn_media,                           # @media
            None,
            fn_ie7hack,                         # ie7hack
            None,
            lambda g: g(16) + ' ' + space_sub(space_subber, g(17)),
                                                # :first-line|letter followed
                                                # by [{,] (apparently space
                                                # needed for IE6)
            lambda g: nl_unesc_sub('', g(18)),  # nl_string
            lambda g: post_esc_sub(' ', g(19)), # escape
        )

        def func(match):
            """ Main subber """
            idx, group = match.lastindex, match.group
            if idx > 3:
                return table[idx](group)

            # shortcuts for frequent operations below:
            elif idx == 1:     # not interesting
                return group(1)
            #else: # space with token before or at the beginning
            return space_sub(space_subber, group(idx))

        return func

    def cssmin(style, keep_bang_comments=False): # pylint: disable = W0621
        """
        Minify CSS.

        :Parameters:
          `style` : ``str``
            CSS to minify

          `keep_bang_comments` : ``bool``
            Keep comments starting with an exclamation mark? (``/*!...*/``)

        :Return: Minified style
        :Rtype: ``str``
        """
        return main_sub(main_subber(keep_bang_comments), style)

    return cssmin

cssmin = _make_cssmin()


if __name__ == '__main__':
    def main():
        """ Main """
        import sys as _sys
        keep_bang_comments = (
            '-b' in _sys.argv[1:]
            or '-bp' in _sys.argv[1:]
            or '-pb' in _sys.argv[1:]
        )
        if '-p' in _sys.argv[1:] or '-bp' in _sys.argv[1:] \
                or '-pb' in _sys.argv[1:]:
            global cssmin # pylint: disable = W0603
            cssmin = _make_cssmin(python_only=True)
        _sys.stdout.write(cssmin(
            _sys.stdin.read(), keep_bang_comments=keep_bang_comments
        ))
    main()

########NEW FILE########
__FILENAME__ = rjsmin
#!/usr/bin/env python
# -*- coding: ascii -*-
#
# Copyright 2011, 2012
# Andr\xe9 Malo or his licensors, as applicable
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
r"""
=====================
 Javascript Minifier
=====================

rJSmin is a javascript minifier written in python.

The minifier is based on the semantics of `jsmin.c by Douglas Crockford`_\.

The module is a re-implementation aiming for speed, so it can be used at
runtime (rather than during a preprocessing step). Usually it produces the
same results as the original ``jsmin.c``. It differs in the following ways:

- there is no error detection: unterminated string, regex and comment
  literals are treated as regular javascript code and minified as such.
- Control characters inside string and regex literals are left untouched; they
  are not converted to spaces (nor to \n)
- Newline characters are not allowed inside string and regex literals, except
  for line continuations in string literals (ECMA-5).
- "return /regex/" is recognized correctly.
- "+ ++" and "- --" sequences are not collapsed to '+++' or '---'
- rJSmin does not handle streams, but only complete strings. (However, the
  module provides a "streamy" interface).

Since most parts of the logic are handled by the regex engine it's way
faster than the original python port of ``jsmin.c`` by Baruch Even. The speed
factor varies between about 6 and 55 depending on input and python version
(it gets faster the more compressed the input already is). Compared to the
speed-refactored python port by Dave St.Germain the performance gain is less
dramatic but still between 1.2 and 7. See the docs/BENCHMARKS file for
details.

rjsmin.c is a reimplementation of rjsmin.py in C and speeds it up even more.

Both python 2 and python 3 are supported.

.. _jsmin.c by Douglas Crockford:
   http://www.crockford.com/javascript/jsmin.c
"""
__author__ = "Andr\xe9 Malo"
__author__ = getattr(__author__, 'decode', lambda x: __author__)('latin-1')
__docformat__ = "restructuredtext en"
__license__ = "Apache License, Version 2.0"
__version__ = '1.0.3'
__all__ = ['jsmin']

import re as _re


def _make_jsmin(python_only=False):
    """
    Generate JS minifier based on `jsmin.c by Douglas Crockford`_

    .. _jsmin.c by Douglas Crockford:
       http://www.crockford.com/javascript/jsmin.c

    :Parameters:
      `python_only` : ``bool``
        Use only the python variant. If true, the c extension is not even
        tried to be loaded.

    :Return: Minifier
    :Rtype: ``callable``
    """
    # pylint: disable = R0912, R0914, W0612
    if not python_only:
        try:
            import _rjsmin
        except ImportError:
            pass
        else:
            return _rjsmin.jsmin
    try:
        xrange
    except NameError:
        xrange = range # pylint: disable = W0622

    space_chars = r'[\000-\011\013\014\016-\040]'

    line_comment = r'(?://[^\r\n]*)'
    space_comment = r'(?:/\*[^*]*\*+(?:[^/*][^*]*\*+)*/)'
    string1 = \
        r'(?:\047[^\047\\\r\n]*(?:\\(?:[^\r\n]|\r?\n|\r)[^\047\\\r\n]*)*\047)'
    string2 = r'(?:"[^"\\\r\n]*(?:\\(?:[^\r\n]|\r?\n|\r)[^"\\\r\n]*)*")'
    strings = r'(?:%s|%s)' % (string1, string2)

    charclass = r'(?:\[[^\\\]\r\n]*(?:\\[^\r\n][^\\\]\r\n]*)*\])'
    nospecial = r'[^/\\\[\r\n]'
    regex = r'(?:/(?![\r\n/*])%s*(?:(?:\\[^\r\n]|%s)%s*)*/)' % (
        nospecial, charclass, nospecial
    )
    space = r'(?:%s|%s)' % (space_chars, space_comment)
    newline = r'(?:%s?[\r\n])' % line_comment

    def fix_charclass(result):
        """ Fixup string of chars to fit into a regex char class """
        pos = result.find('-')
        if pos >= 0:
            result = r'%s%s-' % (result[:pos], result[pos + 1:])

        def sequentize(string):
            """
            Notate consecutive characters as sequence

            (1-4 instead of 1234)
            """
            first, last, result = None, None, []
            for char in map(ord, string):
                if last is None:
                    first = last = char
                elif last + 1 == char:
                    last = char
                else:
                    result.append((first, last))
                    first = last = char
            if last is not None:
                result.append((first, last))
            return ''.join(['%s%s%s' % (
                chr(first),
                last > first + 1 and '-' or '',
                last != first and chr(last) or ''
            ) for first, last in result])

        return _re.sub(r'([\000-\040\047])', # for better portability
            lambda m: '\\%03o' % ord(m.group(1)), (sequentize(result)
                .replace('\\', '\\\\')
                .replace('[', '\\[')
                .replace(']', '\\]')
            )
        )

    def id_literal_(what):
        """ Make id_literal like char class """
        match = _re.compile(what).match
        result = ''.join([
            chr(c) for c in xrange(127) if not match(chr(c))
        ])
        return '[^%s]' % fix_charclass(result)

    def not_id_literal_(keep):
        """ Make negated id_literal like char class """
        match = _re.compile(id_literal_(keep)).match
        result = ''.join([
            chr(c) for c in xrange(127) if not match(chr(c))
        ])
        return r'[%s]' % fix_charclass(result)

    not_id_literal = not_id_literal_(r'[a-zA-Z0-9_$]')
    preregex1 = r'[(,=:\[!&|?{};\r\n]'
    preregex2 = r'%(not_id_literal)sreturn' % locals()

    id_literal = id_literal_(r'[a-zA-Z0-9_$]')
    id_literal_open = id_literal_(r'[a-zA-Z0-9_${\[(+-]')
    id_literal_close = id_literal_(r'[a-zA-Z0-9_$}\])"\047+-]')

    space_sub = _re.compile((
        r'([^\047"/\000-\040]+)'
        r'|(%(strings)s[^\047"/\000-\040]*)'
        r'|(?:(?<=%(preregex1)s)%(space)s*(%(regex)s[^\047"/\000-\040]*))'
        r'|(?:(?<=%(preregex2)s)%(space)s*(%(regex)s[^\047"/\000-\040]*))'
        r'|(?<=%(id_literal_close)s)'
            r'%(space)s*(?:(%(newline)s)%(space)s*)+'
            r'(?=%(id_literal_open)s)'
        r'|(?<=%(id_literal)s)(%(space)s)+(?=%(id_literal)s)'
        r'|(?<=\+)(%(space)s)+(?=\+\+)'
        r'|(?<=-)(%(space)s)+(?=--)'
        r'|%(space)s+'
        r'|(?:%(newline)s%(space)s*)+'
    ) % locals()).sub
    #print space_sub.__self__.pattern

    def space_subber(match):
        """ Substitution callback """
        # pylint: disable = C0321, R0911
        groups = match.groups()
        if groups[0]: return groups[0]
        elif groups[1]: return groups[1]
        elif groups[2]: return groups[2]
        elif groups[3]: return groups[3]
        elif groups[4]: return '\n'
        elif groups[5] or groups[6] or groups[7]: return ' '
        else: return ''

    def jsmin(script): # pylint: disable = W0621
        r"""
        Minify javascript based on `jsmin.c by Douglas Crockford`_\.

        Instead of parsing the stream char by char, it uses a regular
        expression approach which minifies the whole script with one big
        substitution regex.

        .. _jsmin.c by Douglas Crockford:
           http://www.crockford.com/javascript/jsmin.c

        :Parameters:
          `script` : ``str``
            Script to minify

        :Return: Minified script
        :Rtype: ``str``
        """
        return space_sub(space_subber, '\n%s\n' % script).strip()

    return jsmin

jsmin = _make_jsmin()


def jsmin_for_posers(script):
    r"""
    Minify javascript based on `jsmin.c by Douglas Crockford`_\.

    Instead of parsing the stream char by char, it uses a regular
    expression approach which minifies the whole script with one big
    substitution regex.

    .. _jsmin.c by Douglas Crockford:
       http://www.crockford.com/javascript/jsmin.c

    :Warning: This function is the digest of a _make_jsmin() call. It just
              utilizes the resulting regex. It's just for fun here and may
              vanish any time. Use the `jsmin` function instead.

    :Parameters:
      `script` : ``str``
        Script to minify

    :Return: Minified script
    :Rtype: ``str``
    """
    def subber(match):
        """ Substitution callback """
        groups = match.groups()
        return (
            groups[0] or
            groups[1] or
            groups[2] or
            groups[3] or
            (groups[4] and '\n') or
            (groups[5] and ' ') or
            (groups[6] and ' ') or
            (groups[7] and ' ') or
            ''
        )

    return _re.sub(
        r'([^\047"/\000-\040]+)|((?:(?:\047[^\047\\\r\n]*(?:\\(?:[^\r\n]|\r?'
        r'\n|\r)[^\047\\\r\n]*)*\047)|(?:"[^"\\\r\n]*(?:\\(?:[^\r\n]|\r?\n|'
        r'\r)[^"\\\r\n]*)*"))[^\047"/\000-\040]*)|(?:(?<=[(,=:\[!&|?{};\r\n]'
        r')(?:[\000-\011\013\014\016-\040]|(?:/\*[^*]*\*+(?:[^/*][^*]*\*+)*/'
        r'))*((?:/(?![\r\n/*])[^/\\\[\r\n]*(?:(?:\\[^\r\n]|(?:\[[^\\\]\r\n]*'
        r'(?:\\[^\r\n][^\\\]\r\n]*)*\]))[^/\\\[\r\n]*)*/)[^\047"/\000-\040]*'
        r'))|(?:(?<=[\000-#%-,./:-@\[-^`{-~-]return)(?:[\000-\011\013\014\01'
        r'6-\040]|(?:/\*[^*]*\*+(?:[^/*][^*]*\*+)*/))*((?:/(?![\r\n/*])[^/'
        r'\\\[\r\n]*(?:(?:\\[^\r\n]|(?:\[[^\\\]\r\n]*(?:\\[^\r\n][^\\\]\r\n]'
        r'*)*\]))[^/\\\[\r\n]*)*/)[^\047"/\000-\040]*))|(?<=[^\000-!#%&(*,./'
        r':-@\[\\^`{|~])(?:[\000-\011\013\014\016-\040]|(?:/\*[^*]*\*+(?:[^/'
        r'*][^*]*\*+)*/))*(?:((?:(?://[^\r\n]*)?[\r\n]))(?:[\000-\011\013\01'
        r'4\016-\040]|(?:/\*[^*]*\*+(?:[^/*][^*]*\*+)*/))*)+(?=[^\000-#%-\04'
        r'7)*,./:-@\\-^`|-~])|(?<=[^\000-#%-,./:-@\[-^`{-~-])((?:[\000-\011'
        r'\013\014\016-\040]|(?:/\*[^*]*\*+(?:[^/*][^*]*\*+)*/)))+(?=[^\000-'
        r'#%-,./:-@\[-^`{-~-])|(?<=\+)((?:[\000-\011\013\014\016-\040]|(?:/'
        r'\*[^*]*\*+(?:[^/*][^*]*\*+)*/)))+(?=\+\+)|(?<=-)((?:[\000-\011\013'
        r'\014\016-\040]|(?:/\*[^*]*\*+(?:[^/*][^*]*\*+)*/)))+(?=--)|(?:[\00'
        r'0-\011\013\014\016-\040]|(?:/\*[^*]*\*+(?:[^/*][^*]*\*+)*/))+|(?:('
        r'?:(?://[^\r\n]*)?[\r\n])(?:[\000-\011\013\014\016-\040]|(?:/\*[^*]'
        r'*\*+(?:[^/*][^*]*\*+)*/))*)+', subber, '\n%s\n' % script
    ).strip()


if __name__ == '__main__':
    import sys as _sys
    _sys.stdout.write(jsmin(_sys.stdin.read()))

########NEW FILE########
__FILENAME__ = accept
"""
Simple accept header parsing to determins which content type we should deliver
back to the caller. This is mostly used by the rdf export functionality
"""
import re
import operator

# For parsing {name};q=x and {name} style fields from the accept header
accept_re = re.compile("^(?P<ct>[^;]+)[ \t]*(;[ \t]*q=(?P<q>[0-9.]+)){0,1}$")

accept_types = {
    #   Name         : ContentType,             Is Markup?, Extension
    "text/html": ("text/html; charset=utf-8",  True,  'html'),
    "text/n3": ("text/n3; charset=utf-8",    False, 'n3'),
    "application/rdf+xml": ("application/rdf+xml; charset=utf-8", True, 'rdf'),
}
accept_by_extension = {
    "rdf": "application/rdf+xml",
    "n3": "text/n3"
}


def parse_extension(file_ext):
    """
    If provided an extension, this function will return the details
    for that extension, if we know about it.
    """
    ext = accept_by_extension.get(file_ext, None)
    if ext:
        return accept_types[ext]
    return (None, None, None,)


def parse_header(accept_header=''):
    """
    Parses the supplied accept header and tries to determine
    which content types we can provide the response in that will keep the
    client happy.

    We will always provide html as the default if we can't see anything else
    but we will also need to take into account the q score.

    The return values are be content-type,is-markup,extension
    """
    if accept_header is None:
        accept_header = ""

    acceptable = {}
    for typ in accept_header.split(','):
        m = accept_re.match(typ)
        if m:
            key = m.groups(0)[0]
            qscore = m.groups(0)[2] or 1.0
            acceptable[key] = float(qscore)

    for ctype in sorted(acceptable.iteritems(),
                        key=operator.itemgetter(1),
                        reverse=True):
        if ctype[0] in accept_types:
            return accept_types[ctype[0]]

    return accept_types["text/html"]

########NEW FILE########
__FILENAME__ = activity_streams
import re

from webhelpers.html import literal

import ckan.lib.helpers as h
import ckan.lib.base as base
import ckan.logic as logic

from ckan.common import _

# get_snippet_*() functions replace placeholders like {user}, {dataset}, etc.
# in activity strings with HTML representations of particular users, datasets,
# etc.

def get_snippet_actor(activity, detail):
    return literal('''<span class="actor">%s</span>'''
        % (h.linked_user(activity['user_id'], 0, 30))
        )

def get_snippet_user(activity, detail):
    return literal('''<span>%s</span>'''
        % (h.linked_user(activity['object_id'], 0, 20))
        )

def get_snippet_dataset(activity, detail):
    data = activity['data']
    link = h.dataset_link(data.get('package') or data.get('dataset'))
    return literal('''<span>%s</span>'''
        % (link)
        )

def get_snippet_tag(activity, detail):
    return h.tag_link(detail['data']['tag'])

def get_snippet_group(activity, detail):
    link = h.group_link(activity['data']['group'])
    return literal('''<span>%s</span>'''
        % (link)
        )

def get_snippet_organization(activity, detail):
    return h.organization_link(activity['data']['group'])

def get_snippet_extra(activity, detail):
    return '"%s"' % detail['data']['package_extra']['key']

def get_snippet_resource(activity, detail):
    return h.resource_link(detail['data']['resource'],
                           activity['data']['package']['id'])

def get_snippet_related_item(activity, detail):
    return h.related_item_link(activity['data']['related'])

def get_snippet_related_type(activity, detail):
    # FIXME this needs to be translated
    return activity['data']['related']['type']

# activity_stream_string_*() functions return translatable string
# representations of activity types, the strings contain placeholders like
# {user}, {dataset} etc. to be replaced with snippets from the get_snippet_*()
# functions above.

def activity_stream_string_added_tag(context, activity):
    return _("{actor} added the tag {tag} to the dataset {dataset}")

def activity_stream_string_changed_group(context, activity):
    return _("{actor} updated the group {group}")

def activity_stream_string_changed_organization(context, activity):
    return _("{actor} updated the organization {organization}")

def activity_stream_string_changed_package(context, activity):
    return _("{actor} updated the dataset {dataset}")

def activity_stream_string_changed_package_extra(context, activity):
    return _("{actor} changed the extra {extra} of the dataset {dataset}")

def activity_stream_string_changed_resource(context, activity):
    return _("{actor} updated the resource {resource} in the dataset {dataset}")

def activity_stream_string_changed_user(context, activity):
    return _("{actor} updated their profile")

def activity_stream_string_changed_related_item(context, activity):
    if activity['data'].get('dataset'):
        return _("{actor} updated the {related_type} {related_item} of the "
                "dataset {dataset}")
    else:
        return _("{actor} updated the {related_type} {related_item}")

def activity_stream_string_deleted_group(context, activity):
    return _("{actor} deleted the group {group}")

def activity_stream_string_deleted_organization(context, activity):
    return _("{actor} deleted the organization {organization}")

def activity_stream_string_deleted_package(context, activity):
    return _("{actor} deleted the dataset {dataset}")

def activity_stream_string_deleted_package_extra(context, activity):
    return _("{actor} deleted the extra {extra} from the dataset {dataset}")

def activity_stream_string_deleted_resource(context, activity):
    return _("{actor} deleted the resource {resource} from the dataset "
             "{dataset}")

def activity_stream_string_new_group(context, activity):
    return _("{actor} created the group {group}")

def activity_stream_string_new_organization(context, activity):
    return _("{actor} created the organization {organization}")

def activity_stream_string_new_package(context, activity):
    return _("{actor} created the dataset {dataset}")

def activity_stream_string_new_package_extra(context, activity):
    return _("{actor} added the extra {extra} to the dataset {dataset}")

def activity_stream_string_new_resource(context, activity):
    return _("{actor} added the resource {resource} to the dataset {dataset}")

def activity_stream_string_new_user(context, activity):
    return _("{actor} signed up")

def activity_stream_string_removed_tag(context, activity):
    return _("{actor} removed the tag {tag} from the dataset {dataset}")

def activity_stream_string_deleted_related_item(context, activity):
    return _("{actor} deleted the related item {related_item}")

def activity_stream_string_follow_dataset(context, activity):
    return _("{actor} started following {dataset}")

def activity_stream_string_follow_user(context, activity):
    return _("{actor} started following {user}")

def activity_stream_string_follow_group(context, activity):
    return _("{actor} started following {group}")

def activity_stream_string_new_related_item(context, activity):
    if activity['data'].get('dataset'):
        return _("{actor} added the {related_type} {related_item} to the "
                 "dataset {dataset}")
    else:
        return _("{actor} added the {related_type} {related_item}")

# A dictionary mapping activity snippets to functions that expand the snippets.
activity_snippet_functions = {
    'actor': get_snippet_actor,
    'user': get_snippet_user,
    'dataset': get_snippet_dataset,
    'tag': get_snippet_tag,
    'group': get_snippet_group,
    'organization': get_snippet_organization,
    'extra': get_snippet_extra,
    'resource': get_snippet_resource,
    'related_item': get_snippet_related_item,
    'related_type': get_snippet_related_type,
}

# A dictionary mapping activity types to functions that return translatable
# string descriptions of the activity types.
activity_stream_string_functions = {
  'added tag': activity_stream_string_added_tag,
  'changed group': activity_stream_string_changed_group,
  'changed organization': activity_stream_string_changed_organization,
  'changed package': activity_stream_string_changed_package,
  'changed package_extra': activity_stream_string_changed_package_extra,
  'changed resource': activity_stream_string_changed_resource,
  'changed user': activity_stream_string_changed_user,
  'changed related item': activity_stream_string_changed_related_item,
  'deleted group': activity_stream_string_deleted_group,
  'deleted organization': activity_stream_string_deleted_organization,
  'deleted package': activity_stream_string_deleted_package,
  'deleted package_extra': activity_stream_string_deleted_package_extra,
  'deleted resource': activity_stream_string_deleted_resource,
  'new group': activity_stream_string_new_group,
  'new organization': activity_stream_string_new_organization,
  'new package': activity_stream_string_new_package,
  'new package_extra': activity_stream_string_new_package_extra,
  'new resource': activity_stream_string_new_resource,
  'new user': activity_stream_string_new_user,
  'removed tag': activity_stream_string_removed_tag,
  'deleted related item': activity_stream_string_deleted_related_item,
  'follow dataset': activity_stream_string_follow_dataset,
  'follow user': activity_stream_string_follow_user,
  'follow group': activity_stream_string_follow_group,
  'new related item': activity_stream_string_new_related_item,
}

# A dictionary mapping activity types to the icons associated to them
activity_stream_string_icons = {
  'added tag': 'tag',
  'changed group': 'group',
  'changed package': 'sitemap',
  'changed package_extra': 'edit',
  'changed resource': 'file',
  'changed user': 'user',
  'deleted group': 'group',
  'deleted package': 'sitemap',
  'deleted package_extra': 'edit',
  'deleted resource': 'file',
  'new group': 'group',
  'new package': 'sitemap',
  'new package_extra': 'edit',
  'new resource': 'file',
  'new user': 'user',
  'removed tag': 'tag',
  'deleted related item': 'picture',
  'follow dataset': 'sitemap',
  'follow user': 'user',
  'follow group': 'group',
  'new related item': 'picture',
  'changed organization': 'briefcase',
  'deleted organization': 'briefcase',
  'new organization': 'briefcase',
  'undefined': 'certificate', # This is when no activity icon can be found
}

# A list of activity types that may have details
activity_stream_actions_with_detail = ['changed package']

def activity_list_to_html(context, activity_stream, extra_vars):
    '''Return the given activity stream as a snippet of HTML.

    :param activity_stream: the activity stream to render
    :type activity_stream: list of activity dictionaries
    :param extra_vars: extra variables to pass to the activity stream items
        template when rendering it
    :type extra_vars: dictionary

    :rtype: HTML-formatted string

    '''
    activity_list = [] # These are the activity stream messages.
    for activity in activity_stream:
        detail = None
        activity_type = activity['activity_type']
        # Some activity types may have details.
        if activity_type in activity_stream_actions_with_detail:
            details = logic.get_action('activity_detail_list')(context=context,
                data_dict={'id': activity['id']})
            # If an activity has just one activity detail then render the
            # detail instead of the activity.
            if len(details) == 1:
                detail = details[0]
                object_type = detail['object_type']

                if object_type == 'PackageExtra':
                    object_type = 'package_extra'

                new_activity_type = '%s %s' % (detail['activity_type'],
                                            object_type.lower())
                if new_activity_type in activity_stream_string_functions:
                    activity_type = new_activity_type

        if not activity_type in activity_stream_string_functions:
            raise NotImplementedError("No activity renderer for activity "
                "type '%s'" % activity_type)

        if activity_type in activity_stream_string_icons:
            activity_icon = activity_stream_string_icons[activity_type]
        else:
            activity_icon = activity_stream_string_icons['undefined']

        activity_msg = activity_stream_string_functions[activity_type](context,
                activity)

        # Get the data needed to render the message.
        matches = re.findall('\{([^}]*)\}', activity_msg)
        data = {}
        for match in matches:
            snippet = activity_snippet_functions[match](activity, detail)
            data[str(match)] = snippet

        activity_list.append({'msg': activity_msg,
                              'type': activity_type.replace(' ', '-').lower(),
                              'icon': activity_icon,
                              'data': data,
                              'timestamp': activity['timestamp'],
                              'is_new': activity.get('is_new', False)})
    extra_vars['activities'] = activity_list
    return literal(base.render('activity_streams/activity_stream_items.html',
        extra_vars=extra_vars))

########NEW FILE########
__FILENAME__ = activity_streams_session_extension
from pylons import config
from sqlalchemy.orm.session import SessionExtension
from paste.deploy.converters import asbool
import logging

logger = logging.getLogger(__name__)


def activity_stream_item(obj, activity_type, revision, user_id):
    method = getattr(obj, "activity_stream_item", None)
    if callable(method):
        return method(activity_type, revision, user_id)
    else:
        logger.debug("Object did not have a suitable "
            "activity_stream_item() method, it must not be a package.")
        return None


def activity_stream_detail(obj, activity_id, activity_type):
    method = getattr(obj, "activity_stream_detail",
            None)
    if callable(method):
        return method(activity_id, activity_type)
    else:
        logger.debug("Object did not have a suitable  "
            "activity_stream_detail() method.")
        return None


class DatasetActivitySessionExtension(SessionExtension):
    """Session extension that emits activity stream activities for packages
    and related objects.

    An SQLAlchemy SessionExtension that watches for new, changed or deleted
    Packages or objects with related packages (Resources, PackageExtras..)
    being committed to the SQLAlchemy session and creates Activity and
    ActivityDetail objects for these activities.

    For most types of activity the Activity and ActivityDetail objects are
    created in the relevant ckan/logic/action/ functions, but for Packages and
    objects with related packages they are created by this class instead.

    """
    def before_commit(self, session):
        if not asbool(config.get('ckan.activity_streams_enabled', 'true')):
            return

        session.flush()

        try:
            object_cache = session._object_cache
            revision = session.revision
        except AttributeError:
            logger.debug('session had no _object_cache or no revision,'
                    ' skipping this commit', exc_info=True)
            return

        if revision.user:
            user_id = revision.user.id
        else:
            # If the user is not logged in then revision.user is None and
            # revision.author is their IP address. Just log them as 'not logged
            # in' rather than logging their IP address.
            user_id = 'not logged in'
        logger.debug('user_id: %s' % user_id)

        # The top-level objects that we will append to the activity table. The
        # keys here are package IDs, and the values are model.activity:Activity
        # objects.
        activities = {}

        # The second-level objects that we will append to the activity_detail
        # table. Each row in the activity table has zero or more related rows
        # in the activity_detail table. The keys here are activity IDs, and the
        # values are lists of model.activity:ActivityDetail objects.
        activity_details = {}

        # Log new packages first to prevent them from getting incorrectly
        # logged as changed packages.
        logger.debug("Looking for new packages...")
        for obj in object_cache['new']:
            logger.debug("Looking at object %s" % obj)
            activity = activity_stream_item(obj, 'new', revision, user_id)
            if activity is None:
                continue
            # If the object returns an activity stream item we know that the
            # object is a package.
            logger.debug("Looks like this object is a package")
            logger.debug("activity: %s" % activity)

            # Don't create activities for private datasets.
            if obj.private:
                continue

            activities[obj.id] = activity

            activity_detail = activity_stream_detail(obj, activity.id, "new")
            if activity_detail is not None:
                logger.debug("activity_detail: %s" % activity_detail)
                activity_details[activity.id] = [activity_detail]

        # Now process other objects.
        logger.debug("Looking for other objects...")
        for activity_type in ('new', 'changed', 'deleted'):
            objects = object_cache[activity_type]
            for obj in objects:
                logger.debug("Looking at %s object %s" % (activity_type, obj))

                if not hasattr(obj,"id"):
                    logger.debug("Object has no id, skipping...")
                    continue


                if activity_type == "new" and obj.id in activities:
                    logger.debug("This object was already logged as a new "
                            "package")
                    continue

                try:
                    related_packages = obj.related_packages()
                    logger.debug("related_packages: %s" % related_packages)
                except (AttributeError, TypeError):
                    logger.debug("Object did not have a suitable "
                            "related_packages() method, skipping it.")
                    continue

                for package in related_packages:
                    if package is None: continue

                    # Don't create activities for private datasets.
                    if package.private:
                        continue

                    if package.id in activities:
                        activity = activities[package.id]
                    else:
                        activity = activity_stream_item(package, "changed",
                                revision, user_id)
                        if activity is None: continue
                    logger.debug("activity: %s" % activity)

                    activity_detail = activity_stream_detail(obj, activity.id,
                            activity_type)
                    logger.debug("activity_detail: %s" % activity_detail)
                    if activity_detail is not None:
                        if not package.id in activities:
                            activities[package.id] = activity
                        if activity_details.has_key(activity.id):
                            activity_details[activity.id].append(
                                    activity_detail)
                        else:
                            activity_details[activity.id] =  [activity_detail]

        for key, activity in activities.items():
            logger.debug("Emitting activity: %s %s"
                    % (activity.id, activity.activity_type))
            session.add(activity)

        for key, activity_detail_list in activity_details.items():
            for activity_detail_obj in activity_detail_list:
                logger.debug("Emitting activity detail: %s %s %s"
                        % (activity_detail_obj.activity_id,
                            activity_detail_obj.activity_type,
                            activity_detail_obj.object_type))
                session.add(activity_detail_obj)

        session.flush()

########NEW FILE########
__FILENAME__ = alphabet_paginate
'''
Based on webhelpers.paginator, but:
 * each page is for items beginning with a particular letter
 * output is suitable for Bootstrap

 Example:
        c.page = h.Page(
            collection=query,
            page=request.params.get('page', 'A'),
        )
    Template:
        ${c.page.pager()}
        ${package_list(c.page.items)}
        ${c.page.pager()}
'''
from itertools import dropwhile
import re

from sqlalchemy import  __version__ as sqav
from sqlalchemy.orm.query import Query
from webhelpers.html.builder import HTML
from routes import url_for


class AlphaPage(object):
    def __init__(self, collection, alpha_attribute, page, other_text, paging_threshold=50,
                controller_name='tag'):
        '''
        @param collection - sqlalchemy query of all the items to paginate
        @param alpha_attribute - name of the attribute (on each item of the
                             collection) which has the string to paginate by
        @param page - the page identifier - the start character or other_text
        @param other_text - the (i18n-ized) string for items with
                            non-alphabetic first character.
        @param paging_threshold - the minimum number of items required to
                              start paginating them.
        @param controller_name - The name of the controller that will be linked to,
                            which defaults to tag.  The controller name should be the
                            same as the route so for some this will be the full
                            controller name such as 'A.B.controllers.C:ClassName'
        '''
        self.collection = collection
        self.alpha_attribute = alpha_attribute
        self.page = page
        self.other_text = other_text
        self.paging_threshold = paging_threshold
        self.controller_name = controller_name

        self.letters = [char for char in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'] + [self.other_text]
        
        # Work out which alphabet letters are 'available' i.e. have some results
        # because we grey-out those which aren't.
        self.available = dict( (c,0,) for c in self.letters )
        for c in self.collection:
            if isinstance(c, unicode):
                x = c[0]
            elif isinstance(c, dict):
                x = c[self.alpha_attribute][0]
            else:
                x = getattr(c, self.alpha_attribute)[0]
            x = x.upper()
            if x not in self.letters:
                x = self.other_text
            self.available[x] = self.available.get(x, 0) + 1

    def pager(self, q=None):
        '''Returns pager html - for navigating between the pages.
           e.g. Something like this:
             <ul class='pagination pagination-alphabet'>
                 <li class="active"><a href="/package/list?page=A">A</a></li>
                 <li><a href="/package/list?page=B">B</a></li>
                 <li><a href="/package/list?page=C">C</a></li>
                    ...
                 <li class="disabled"><a href="/package/list?page=Z">Z</a></li>
                 <li><a href="/package/list?page=Other">Other</a></li>
             </ul>
        '''
        if self.item_count < self.paging_threshold:
            return ''
        pages = []
        page = q or self.page
        for letter in self.letters:
            href = url_for(controller=self.controller_name, action='index', page=letter)
            link = HTML.a(href=href, c=letter)
            if letter != page:
                if self.available.get(letter, 0):
                    li_class = ''
                else:
                    li_class = 'disabled'
            else:
                li_class = 'active'
            attributes = {'class_': li_class} if li_class else {}
            page_element = HTML.li(link, **attributes)
            pages.append(page_element)
        ul = HTML.tag('ul', *pages)
        div = HTML.div(ul, class_='pagination pagination-alphabet')
        return div


    @property
    def items(self):
        '''Returns items on the current page.'''
        if isinstance(self.collection, Query):
            query = self.collection
            if sqav.startswith("0.4"):
                attribute = getattr(query.table.c,
                                    self.alpha_attribute)
            elif sqav.startswith("0.5"):
                 attribute = getattr(query._entity_zero().selectable.c,
                                     self.alpha_attribute)
            else:
                entity = getattr(query.column_descriptions[0]['expr'],
                                 self.alpha_attribute)
                query = query.add_columns(entity)
                column = dropwhile(lambda x: x['name'] != \
                                   self.alpha_attribute,
                                   query.column_descriptions)
                attribute = column.next()['expr']
            if self.item_count >= self.paging_threshold:
                if self.page != self.other_text:
                    query = query.filter(attribute.ilike(u'%s%%' % self.page))
                else:
                    # regexp search
                    query = query.filter(attribute.op('~')(u'^[^a-zA-Z].*'))
            query.order_by(attribute)
            return query.all()
        elif isinstance(self.collection,list):
            if self.item_count >= self.paging_threshold:
                if self.page != self.other_text:
                    if isinstance(self.collection[0], dict):
                        items = [x for x in self.collection if x[self.alpha_attribute][0:1].lower() == self.page.lower()]
                    elif isinstance(self.collection[0], unicode):
                        items = [x for x in self.collection if x[0:1].lower() == self.page.lower()]
                    else:
                        items = [x for x in self.collection if getattr(x,self.alpha_attribute)[0:1].lower() == self.page.lower()]
                else:
                    # regexp search
                    if isinstance(self.collection[0], dict):
                        items = [x for x in self.collection if re.match('^[^a-zA-Z].*',x[self.alpha_attribute])]
                    else:
                        items = [x for x in self.collection if re.match('^[^a-zA-Z].*',x)]
                items.sort()
            else:
                items = self.collection
            return items
        else:
            raise NotImplementedError

    @property
    def item_count(self):
        if isinstance(self.collection, Query):
            return self.collection.count()
        elif isinstance(self.collection,list):
            return len(self.collection)
        else:
            raise NotImplementedError

########NEW FILE########
__FILENAME__ = app_globals
''' The application's Globals object '''

import logging
import time
from threading import Lock
import re

from paste.deploy.converters import asbool
from pylons import config

import ckan
import ckan.model as model

log = logging.getLogger(__name__)


# mappings translate between config settings and globals because our naming
# conventions are not well defined and/or implemented
mappings = {
#   'config_key': 'globals_key',
}

# these config settings will get updated from system_info
auto_update = [
    'ckan.site_title',
    'ckan.site_logo',
    'ckan.site_url',
    'ckan.site_description',
    'ckan.site_about',
    'ckan.site_intro_text',
    'ckan.site_custom_css',
    'ckan.homepage_style',
]

config_details = {
    'ckan.favicon': {}, # default gets set in config.environment.py
    'ckan.template_head_end': {},
    'ckan.template_footer_end': {},
        # has been setup in load_environment():
    'ckan.site_id': {},
    'ckan.recaptcha.publickey': {'name': 'recaptcha_publickey'},
    'ckan.template_title_deliminater': {'default': '-'},
    'ckan.template_head_end': {},
    'ckan.template_footer_end': {},
    'ckan.dumps_url': {},
    'ckan.dumps_format': {},
    'ofs.impl': {'name': 'ofs_impl'},
    'ckan.homepage_style': {'default': '1'},

    # split string
    'search.facets': {'default': 'organization groups tags res_format license_id',
                      'type': 'split',
                      'name': 'facets'},
    'package_hide_extras': {'type': 'split'},
    'ckan.plugins': {'type': 'split'},

    # bool
    'openid_enabled': {'default': 'true', 'type' : 'bool'},
    'debug': {'default': 'false', 'type' : 'bool'},
    'ckan.debug_supress_header' : {'default': 'false', 'type' : 'bool'},
    'ckan.legacy_templates' : {'default': 'false', 'type' : 'bool'},
    'ckan.tracking_enabled' : {'default': 'false', 'type' : 'bool'},

    # int
    'ckan.datasets_per_page': {'default': '20', 'type': 'int'},
    'ckan.activity_list_limit': {'default': '30', 'type': 'int'},
    'search.facets.default': {'default': '10', 'type': 'int',
                             'name': 'facets_default_number'},
}


# A place to store the origional config options of we override them
_CONFIG_CACHE = {}

def set_main_css(css_file):
    ''' Sets the main_css using debug css if needed.  The css_file
    must be of the form file.css '''
    assert css_file.endswith('.css')
    if config.get('debug') and css_file == '/base/css/main.css':
        new_css = '/base/css/main.debug.css'
    else:
        new_css = css_file
    # FIXME we should check the css file exists
    app_globals.main_css = str(new_css)


def set_global(key, value):
    ''' helper function for getting value from database or config file '''
    model.set_system_info(key, value)
    setattr(app_globals, get_globals_key(key), value)
    model.set_system_info('ckan.config_update', str(time.time()))
    # update the config
    config[key] = value
    log.info('config `%s` set to `%s`' % (key, value))

def delete_global(key):
    model.delete_system_info(key)
    log.info('config `%s` deleted' % (key))

def get_globals_key(key):
    # create our globals key
    # these can be specified in mappings or else we remove
    # the `ckan.` part this is to keep the existing namings
    # set the value
    if key in mappings:
        return mappings[key]
    elif key.startswith('ckan.'):
        return key[5:]

def reset():
    ''' set updatable values from config '''
    def get_config_value(key, default=''):
        if model.meta.engine.has_table('system_info'):
            value = model.get_system_info(key)
        else:
            value = None
        config_value = config.get(key)
        # sort encodeings if needed
        if isinstance(config_value, str):
            try:
                config_value = config_value.decode('utf-8')
            except UnicodeDecodeError:
                config_value = config_value.decode('latin-1')
        # we want to store the config the first time we get here so we can
        # reset them if needed
        if key not in _CONFIG_CACHE:
            _CONFIG_CACHE[key] = config_value
        if value is not None:
            log.debug('config `%s` set to `%s` from db' % (key, value))
        else:
            value = _CONFIG_CACHE[key]
            if value:
                log.debug('config `%s` set to `%s` from config' % (key, value))
            else:
                value = default
        setattr(app_globals, get_globals_key(key), value)
        # update the config
        config[key] = value
        return value

    # update the config settings in auto update
    for key in auto_update:
        get_config_value(key)

    # cusom styling
    main_css = get_config_value('ckan.main_css', '/base/css/main.css')
    set_main_css(main_css)
    # site_url_nice
    site_url_nice = app_globals.site_url.replace('http://', '')
    site_url_nice = site_url_nice.replace('www.', '')
    app_globals.site_url_nice = site_url_nice

    if app_globals.site_logo:
        app_globals.header_class = 'header-image'
    elif not app_globals.site_description:
        app_globals.header_class = 'header-text-logo'
    else:
        app_globals.header_class = 'header-text-logo-tagline'




class _Globals(object):

    ''' Globals acts as a container for objects available throughout the
    life of the application. '''

    def __init__(self):
        '''One instance of Globals is created during application
        initialization and is available during requests via the
        'app_globals' variable
        '''
        self._init()
        self._config_update = None
        self._mutex = Lock()

    def _check_uptodate(self):
        ''' check the config is uptodate needed when several instances are
        running '''
        value = model.get_system_info('ckan.config_update')
        if self._config_update != value:
            if self._mutex.acquire(False):
                reset()
                self._config_update = value
                self._mutex.release()

    def _init(self):

        self.ckan_version = ckan.__version__
        self.ckan_base_version = re.sub('[^0-9\.]', '', self.ckan_version)
        if self.ckan_base_version == self.ckan_version:
            self.ckan_doc_version = 'ckan-{0}'.format(self.ckan_version)
        else:
            self.ckan_doc_version = 'latest'

        # process the config_details to set globals
        for name, options in config_details.items():
            if 'name' in options:
                key = options['name']
            elif name.startswith('ckan.'):
                key = name[5:]
            else:
                key = name
            value = config.get(name, options.get('default', ''))

            data_type = options.get('type')
            if data_type == 'bool':
                value = asbool(value)
            elif data_type == 'int':
                value = int(value)
            elif data_type == 'split':
                value = value.split()

            setattr(self, key, value)


app_globals = _Globals()
del _Globals

########NEW FILE########
__FILENAME__ = authenticator
import logging

from zope.interface import implements
from repoze.who.interfaces import IAuthenticator

from ckan.model import User, Session

log = logging.getLogger(__name__)

class OpenIDAuthenticator(object):
    implements(IAuthenticator)

    def authenticate(self, environ, identity):
        if 'repoze.who.plugins.openid.userid' in identity:
            openid = identity['repoze.who.plugins.openid.userid']
            user = User.by_openid(openid)
            if user is None or not user.is_active():
                return None
            else:
                return user.name
        return None


class UsernamePasswordAuthenticator(object):
    implements(IAuthenticator)

    def authenticate(self, environ, identity):
        if not ('login' in identity and 'password' in identity):
            return None

        login = identity['login']
        user = User.by_name(login)

        if user is None:
            log.debug('Login failed - username %r not found', login)
        elif not user.is_active():
            log.debug('Login as %r failed - user isn\'t active', login)
        elif not user.validate_password(identity['password']):
            log.debug('Login as %r failed - password not valid', login)
        else:
            return user.name

        return None


########NEW FILE########
__FILENAME__ = base
"""The base Controller API

Provides the BaseController class for subclassing.
"""
import logging
import time

from paste.deploy.converters import asbool
from pylons import cache, config, session
from pylons.controllers import WSGIController
from pylons.controllers.util import abort as _abort
from pylons.controllers.util import redirect_to, redirect
from pylons.decorators import jsonify, validate
from pylons.i18n import N_, gettext, ngettext
from pylons.templating import cached_template, pylons_globals
from genshi.template import MarkupTemplate
from genshi.template.text import NewTextTemplate
from webhelpers.html import literal

import ckan.exceptions
import ckan
import ckan.lib.i18n as i18n
import ckan.lib.render as render_
import ckan.lib.helpers as h
import ckan.lib.app_globals as app_globals
import ckan.plugins as p
import ckan.model as model
import ckan.lib.maintain as maintain

# These imports are for legacy usages and will be removed soon these should
# be imported directly from ckan.common for internal ckan code and via the
# plugins.toolkit for extensions.
from ckan.common import json, _, ungettext, c, g, request, response

log = logging.getLogger(__name__)

PAGINATE_ITEMS_PER_PAGE = 50

APIKEY_HEADER_NAME_KEY = 'apikey_header_name'
APIKEY_HEADER_NAME_DEFAULT = 'X-CKAN-API-Key'

ALLOWED_FIELDSET_PARAMS = ['package_form', 'restrict']


def abort(status_code=None, detail='', headers=None, comment=None):
    '''Abort the current request immediately by returning an HTTP exception.

    This is a wrapper for :py:func:`pylons.controllers.util.abort` that adds
    some CKAN custom behavior, including allowing
    :py:class:`~ckan.plugins.interfaces.IAuthenticator` plugins to alter the
    abort response, and showing flash messages in the web interface.

    '''
    if status_code == 401:
        # Allow IAuthenticator plugins to alter the abort
        for item in p.PluginImplementations(p.IAuthenticator):
            result = item.abort(status_code, detail, headers, comment)
            (status_code, detail, headers, comment) = result

    if detail and status_code != 503:
        h.flash_error(detail)
    # #1267 Convert detail to plain text, since WebOb 0.9.7.1 (which comes
    # with Lucid) causes an exception when unicode is received.
    detail = detail.encode('utf8')
    return _abort(status_code=status_code,
                  detail=detail,
                  headers=headers,
                  comment=comment)


def render_snippet(template_name, **kw):
    ''' Helper function for rendering snippets. Rendered html has
    comment tags added to show the template used. NOTE: unlike other
    render functions this takes a list of keywords instead of a dict for
    the extra template variables. '''
    # allow cache_force to be set in render function
    cache_force = kw.pop('cache_force', None)
    output = render(template_name, extra_vars=kw, cache_force=cache_force,
                    renderer='snippet')
    output = '\n<!-- Snippet %s start -->\n%s\n<!-- Snippet %s end -->\n' % (
        template_name, output, template_name)
    return literal(output)


def render_text(template_name, extra_vars=None, cache_force=None):
    '''Render a Genshi :py:class:`NewTextTemplate`.

    This is just a wrapper function that lets you render a Genshi
    :py:class:`NewTextTemplate` without having to pass ``method='text'`` or
    ``loader_class=NewTextTemplate`` (it passes them to
    :py:func:`~ckan.plugins.toolkit.render` for you).

    '''
    return render(template_name,
                  extra_vars=extra_vars,
                  cache_force=cache_force,
                  method='text',
                  loader_class=NewTextTemplate)


def render_jinja2(template_name, extra_vars):
    env = config['pylons.app_globals'].jinja_env
    template = env.get_template(template_name)
    return template.render(**extra_vars)


def render(template_name, extra_vars=None, cache_key=None, cache_type=None,
           cache_expire=None, method='xhtml', loader_class=MarkupTemplate,
           cache_force=None, renderer=None):
    '''Render a template and return the output.

    This is CKAN's main template rendering function.

    .. todo::

       Document the parameters of :py:func:`ckan.plugins.toolkit.render`.

    '''
    def render_template():
        globs = extra_vars or {}
        globs.update(pylons_globals())
        globs['actions'] = model.Action

        # Using pylons.url() directly destroys the localisation stuff so
        # we remove it so any bad templates crash and burn
        del globs['url']

        try:
            template_path, template_type = render_.template_info(template_name)
        except render_.TemplateNotFound:
            raise

        # snippets should not pass the context
        # but allow for legacy genshi templates
        if renderer == 'snippet' and template_type != 'genshi':
            del globs['c']
            del globs['tmpl_context']

        log.debug('rendering %s [%s]' % (template_path, template_type))
        if config.get('debug'):
            context_vars = globs.get('c')
            if context_vars:
                context_vars = dir(context_vars)
            debug_info = {'template_name': template_name,
                          'template_path': template_path,
                          'template_type': template_type,
                          'vars': globs,
                          'c_vars': context_vars,
                          'renderer': renderer}
            if 'CKAN_DEBUG_INFO' not in request.environ:
                request.environ['CKAN_DEBUG_INFO'] = []
            request.environ['CKAN_DEBUG_INFO'].append(debug_info)

        # Jinja2 templates
        if template_type == 'jinja2':
            # We don't want to have the config in templates it should be
            # accessed via g (app_globals) as this gives us flexability such
            # as changing via database settings.
            del globs['config']
            # TODO should we raise error if genshi filters??
            return render_jinja2(template_name, globs)

        # Genshi templates
        template = globs['app_globals'].genshi_loader.load(
            template_name.encode('utf-8'), cls=loader_class
        )
        stream = template.generate(**globs)

        for item in p.PluginImplementations(p.IGenshiStreamFilter):
            stream = item.filter(stream)

        if loader_class == NewTextTemplate:
            return literal(stream.render(method="text", encoding=None))

        return literal(stream.render(method=method, encoding=None,
                                     strip_whitespace=True))

    if 'Pragma' in response.headers:
        del response.headers["Pragma"]

    ## Caching Logic
    allow_cache = True
    # Force cache or not if explicit.
    if cache_force is not None:
        allow_cache = cache_force
    # Do not allow caching of pages for logged in users/flash messages etc.
    elif session.last_accessed:
        allow_cache = False
    # Tests etc.
    elif 'REMOTE_USER' in request.environ:
        allow_cache = False
    # Don't cache if based on a non-cachable template used in this.
    elif request.environ.get('__no_cache__'):
        allow_cache = False
    # Don't cache if we have set the __no_cache__ param in the query string.
    elif request.params.get('__no_cache__'):
        allow_cache = False
    # Don't cache if we have extra vars containing data.
    elif extra_vars:
        for k, v in extra_vars.iteritems():
            allow_cache = False
            break
    # Record cachability for the page cache if enabled
    request.environ['CKAN_PAGE_CACHABLE'] = allow_cache

    if allow_cache:
        response.headers["Cache-Control"] = "public"
        try:
            cache_expire = int(config.get('ckan.cache_expires', 0))
            response.headers["Cache-Control"] += \
                ", max-age=%s, must-revalidate" % cache_expire
        except ValueError:
            pass
    else:
        # We do not want caching.
        response.headers["Cache-Control"] = "private"
        # Prevent any further rendering from being cached.
        request.environ['__no_cache__'] = True
    log.debug('Template cache-control: %s' % response.headers["Cache-Control"])

    # Render Time :)
    try:
        return cached_template(template_name, render_template,
                               loader_class=loader_class)
    except ckan.exceptions.CkanUrlException, e:
        raise ckan.exceptions.CkanUrlException(
            '\nAn Exception has been raised for template %s\n%s' %
            (template_name, e.message))
    except render_.TemplateNotFound:
        raise


class ValidationException(Exception):
    pass


class BaseController(WSGIController):
    '''Base class for CKAN controller classes to inherit from.

    '''
    repo = model.repo
    log = logging.getLogger(__name__)

    def __before__(self, action, **params):
        c.__timer = time.time()
        c.__version__ = ckan.__version__
        app_globals.app_globals._check_uptodate()

        self._identify_user()

        i18n.handle_request(request, c)

        maintain.deprecate_context_item(
            'new_activities',
            'Use `h.new_activities` instead.')

    def _identify_user(self):
        '''Try to identify the user
        If the user is identified then:
          c.user = user name (unicode)
          c.userobj = user object
          c.author = user name
        otherwise:
          c.user = None
          c.userobj = None
          c.author = user's IP address (unicode)'''
        # see if it was proxied first
        c.remote_addr = request.environ.get('HTTP_X_FORWARDED_FOR', '')
        if not c.remote_addr:
            c.remote_addr = request.environ.get('REMOTE_ADDR',
                                                'Unknown IP Address')

        # Authentication plugins get a chance to run here break as soon as a
        # user is identified.
        authenticators = p.PluginImplementations(p.IAuthenticator)
        if authenticators:
            for item in authenticators:
                item.identify()
                if c.user:
                    break

        # We haven't identified the user so try the default methods
        if not c.user:
            self._identify_user_default()

        # If we have a user but not the userobj let's get the userobj.  This
        # means that IAuthenticator extensions do not need to access the user
        # model directly.
        if c.user and not c.userobj:
            c.userobj = model.User.by_name(c.user)

        # general settings
        if c.user:
            c.author = c.user
        else:
            c.author = c.remote_addr
        c.author = unicode(c.author)

    def _identify_user_default(self):
        '''
        Identifies the user using two methods:
        a) If they logged into the web interface then repoze.who will
           set REMOTE_USER.
        b) For API calls they may set a header with an API key.
        '''

        # environ['REMOTE_USER'] is set by repoze.who if it authenticates
        # a user's cookie or OpenID. But repoze.who doesn't check the user
        # (still) exists in our database - we need to do that here. (Another
        # way would be with an userid_checker, but that would mean another db
        # access.
        # See: http://docs.repoze.org/who/1.0/narr.html#module-repoze.who\
        # .plugins.sql )
        c.user = request.environ.get('REMOTE_USER', '')
        if c.user:
            c.user = c.user.decode('utf8')
            c.userobj = model.User.by_name(c.user)
            if c.userobj is None or not c.userobj.is_active():
                # This occurs when a user that was still logged in is deleted,
                # or when you are logged in, clean db
                # and then restart (or when you change your username)
                # There is no user object, so even though repoze thinks you
                # are logged in and your cookie has ckan_display_name, we
                # need to force user to logout and login again to get the
                # User object.
                session['lang'] = request.environ.get('CKAN_LANG')
                session.save()

                ev = request.environ
                if 'repoze.who.plugins' in ev:
                    pth = getattr(ev['repoze.who.plugins']['friendlyform'],
                                  'logout_handler_path')
                    h.redirect_to(pth)
        else:
            c.userobj = self._get_user_for_apikey()
            if c.userobj is not None:
                c.user = c.userobj.name

    def __call__(self, environ, start_response):
        """Invoke the Controller"""
        # WSGIController.__call__ dispatches to the Controller method
        # the request is routed to. This routing information is
        # available in environ['pylons.routes_dict']

        try:
            res = WSGIController.__call__(self, environ, start_response)
        finally:
            model.Session.remove()

        # Clean out any old cookies as they may contain api keys etc
        # This also improves the cachability of our pages as cookies
        # prevent proxy servers from caching content unless they have
        # been configured to ignore them.
        for cookie in request.cookies:
            if cookie.startswith('ckan') and cookie not in ['ckan']:
                response.delete_cookie(cookie)
            # Remove the ckan session cookie if not used e.g. logged out
            elif cookie == 'ckan' and not c.user:
                # Check session for valid data (including flash messages)
                # (DGU also uses session for a shopping basket-type behaviour)
                is_valid_cookie_data = False
                for key, value in session.items():
                    if not key.startswith('_') and value:
                        is_valid_cookie_data = True
                        break
                if not is_valid_cookie_data:
                    if session.id:
                        if not session.get('lang'):
                            self.log.debug('No session data any more - '
                                           'deleting session')
                            self.log.debug('Session: %r', session.items())
                            session.delete()
                    else:
                        response.delete_cookie(cookie)
                        self.log.debug('No session data any more - '
                                       'deleting session cookie')
            # Remove auth_tkt repoze.who cookie if user not logged in.
            elif cookie == 'auth_tkt' and not session.id:
                response.delete_cookie(cookie)

        return res

    def __after__(self, action, **params):
        self._set_cors()
        r_time = time.time() - c.__timer
        url = request.environ['CKAN_CURRENT_URL'].split('?')[0]
        log.info(' %s render time %.3f seconds' % (url, r_time))

    def _set_cors(self):
        response.headers['Access-Control-Allow-Origin'] = "*"
        response.headers['Access-Control-Allow-Methods'] = \
            "POST, PUT, GET, DELETE, OPTIONS"
        response.headers['Access-Control-Allow-Headers'] = \
            "X-CKAN-API-KEY, Authorization, Content-Type"

    def _get_user_for_apikey(self):
        apikey_header_name = config.get(APIKEY_HEADER_NAME_KEY,
                                        APIKEY_HEADER_NAME_DEFAULT)
        apikey = request.headers.get(apikey_header_name, '')
        if not apikey:
            apikey = request.environ.get(apikey_header_name, '')
        if not apikey:
            # For misunderstanding old documentation (now fixed).
            apikey = request.environ.get('HTTP_AUTHORIZATION', '')
        if not apikey:
            apikey = request.environ.get('Authorization', '')
            # Forget HTTP Auth credentials (they have spaces).
            if ' ' in apikey:
                apikey = ''
        if not apikey:
            return None
        self.log.debug("Received API Key: %s" % apikey)
        apikey = unicode(apikey)
        query = model.Session.query(model.User)
        user = query.filter_by(apikey=apikey).first()
        return user


# Include the '_' function in the public names
__all__ = [__name for __name in locals().keys() if not __name.startswith('_')
           or __name == '_']

########NEW FILE########
__FILENAME__ = captcha
from pylons import config

import urllib
import urllib2

def check_recaptcha(request):
    '''Check a user\'s recaptcha submission is valid, and raise CaptchaError
    on failure.'''
    recaptcha_private_key = config.get('ckan.recaptcha.privatekey', '')
    if not recaptcha_private_key:
        # Recaptcha not enabled
        return
    
    client_ip_address = request.environ.get('REMOTE_ADDR', 'Unknown IP Address')
    recaptcha_challenge_field = request.params.get('recaptcha_challenge_field')
    recaptcha_response_field = request.params.get('recaptcha_response_field',
            '')

    recaptcha_server_name = 'http://api-verify.recaptcha.net/verify'

    # recaptcha_response_field will be unicode if there are foreign chars in
    # the user input. So ee need to encode it as utf8 before urlencoding or
    # we get an exception (#1431).
    params = urllib.urlencode(dict(privatekey=recaptcha_private_key,
                                   remoteip=client_ip_address,
                                   challenge=recaptcha_challenge_field,
                                   response=recaptcha_response_field.encode('utf8')))
    f = urllib2.urlopen(recaptcha_server_name, params)
    data = f.read()
    f.close()
    if not data.lower().startswith('true'):
        raise CaptchaError()

class CaptchaError(ValueError):
    pass


########NEW FILE########
__FILENAME__ = celery_app
import ConfigParser
import os
import logging

from pylons import config as pylons_config
from pkg_resources import iter_entry_points, VersionConflict

log = logging.getLogger(__name__)

LIST_PARAMS = """CELERY_IMPORTS ADMINS ROUTES""".split()

from celery import Celery

celery = Celery()

config = ConfigParser.ConfigParser()

config_file = os.environ.get('CKAN_CONFIG')

if not config_file:
    config_file = os.path.join(
        os.path.dirname(os.path.abspath(__file__)), '../../development.ini')
config.read(config_file)


sqlalchemy_url = pylons_config.get('sqlalchemy.url')
if not sqlalchemy_url:
    sqlalchemy_url = config.get('app:main', 'sqlalchemy.url')


default_config = dict(
    BROKER_BACKEND='sqlalchemy',
    BROKER_HOST=sqlalchemy_url,
    CELERY_RESULT_DBURI=sqlalchemy_url,
    CELERY_RESULT_BACKEND='database',
    CELERY_RESULT_SERIALIZER='json',
    CELERY_TASK_SERIALIZER='json',
    CELERY_IMPORTS=[],
)

for entry_point in iter_entry_points(group='ckan.celery_task'):
    try:
        default_config['CELERY_IMPORTS'].extend(
            entry_point.load()()
        )
    except VersionConflict, e:
        error = 'ERROR in entry point load: %s %s' % (entry_point, e)
        log.critical(error)
        pass

try:
    for key, value in config.items('app:celery'):
        if key in LIST_PARAMS:
            default_config[key.upper()] = value.split()
        else:
            default_config[key.upper()] = value
except ConfigParser.NoSectionError:
    pass

# Thes update of configuration means it is only possible to set each
# key once so this is done once all of the options have been decided.
celery.conf.update(default_config)
celery.loader.conf.update(default_config)

########NEW FILE########
__FILENAME__ = cli
import collections
import csv
import multiprocessing as mp
import os
import datetime
import sys
from pprint import pprint
import re
import ckan.logic as logic
import ckan.model as model
import ckan.include.rjsmin as rjsmin
import ckan.include.rcssmin as rcssmin
import ckan.lib.fanstatic_resources as fanstatic_resources
import sqlalchemy as sa
import urlparse
import routes

import paste.script
from paste.registry import Registry
from paste.script.util.logging_config import fileConfig

#NB No CKAN imports are allowed until after the config file is loaded.
#   i.e. do the imports in methods, after _load_config is called.
#   Otherwise loggers get disabled.


def parse_db_config(config_key='sqlalchemy.url'):
    ''' Takes a config key for a database connection url and parses it into
    a dictionary. Expects a url like:

    'postgres://tester:pass@localhost/ckantest3'
    '''
    from pylons import config
    url = config[config_key]
    regex = [
        '^\s*(?P<db_type>\w*)',
        '://',
        '(?P<db_user>[^:]*)',
        ':?',
        '(?P<db_pass>[^@]*)',
        '@',
        '(?P<db_host>[^/:]*)',
        ':?',
        '(?P<db_port>[^/]*)',
        '/',
        '(?P<db_name>[\w.-]*)'
    ]
    db_details_match = re.match(''.join(regex), url)
    if not db_details_match:
        raise Exception('Could not extract db details from url: %r' % url)
    db_details = db_details_match.groupdict()
    return db_details


class MockTranslator(object):
    def gettext(self, value):
        return value

    def ugettext(self, value):
        return value

    def ungettext(self, singular, plural, n):
        if n > 1:
            return plural
        return singular

class CkanCommand(paste.script.command.Command):
    '''Base class for classes that implement CKAN paster commands to inherit.

    '''
    parser = paste.script.command.Command.standard_parser(verbose=True)
    parser.add_option('-c', '--config', dest='config',
            default='development.ini', help='Config file to use.')
    parser.add_option('-f', '--file',
        action='store',
        dest='file_path',
        help="File to dump results to (if needed)")
    default_verbosity = 1
    group_name = 'ckan'

    def _get_config(self):
        from paste.deploy import appconfig
        if not self.options.config:
            msg = 'No config file supplied'
            raise self.BadCommand(msg)
        self.filename = os.path.abspath(self.options.config)
        if not os.path.exists(self.filename):
            raise AssertionError('Config filename %r does not exist.' % self.filename)
        fileConfig(self.filename)
        return appconfig('config:' + self.filename)

    def _load_config(self):
        conf = self._get_config()
        assert 'ckan' not in dir() # otherwise loggers would be disabled
        # We have now loaded the config. Now we can import ckan for the
        # first time.
        from ckan.config.environment import load_environment
        load_environment(conf.global_conf, conf.local_conf)

        self.registry=Registry()
        self.registry.prepare()
        import pylons
        self.translator_obj = MockTranslator()
        self.registry.register(pylons.translator, self.translator_obj)

        if model.user_table.exists():
            # If the DB has already been initialized, create and register
            # a pylons context object, and add the site user to it, so the
            # auth works as in a normal web request
            c = pylons.util.AttribSafeContextObj()

            self.registry.register(pylons.c, c)

            self.site_user = logic.get_action('get_site_user')({'ignore_auth': True,
                'defer_commit': True}, {})

            pylons.c.user = self.site_user['name']
            pylons.c.userobj = model.User.get(self.site_user['name'])
            model.repo.commit_and_remove()

        ## give routes enough information to run url_for
        parsed = urlparse.urlparse(conf.get('ckan.site_url', 'http://0.0.0.0'))
        request_config = routes.request_config()
        request_config.host = parsed.netloc + parsed.path
        request_config.protocol = parsed.scheme

    def _setup_app(self):
        cmd = paste.script.appinstall.SetupCommand('setup-app')
        cmd.run([self.filename])


class ManageDb(CkanCommand):
    '''Perform various tasks on the database.

    db create                      - alias of db upgrade
    db init                        - create and put in default data
    db clean
    db upgrade [version no.]       - Data migrate
    db version                     - returns current version of data schema
    db dump FILE_PATH              - dump to a pg_dump file
    db dump-rdf DATASET_NAME FILE_PATH
    db simple-dump-csv FILE_PATH   - dump just datasets in CSV format
    db simple-dump-json FILE_PATH  - dump just datasets in JSON format
    db user-dump-csv FILE_PATH     - dump user information to a CSV file
    db send-rdf TALIS_STORE USERNAME PASSWORD
    db load FILE_PATH              - load a pg_dump from a file
    db load-only FILE_PATH         - load a pg_dump from a file but don\'t do
                                     the schema upgrade or search indexing
    db create-from-model           - create database from the model (indexes not made)
    db migrate-filestore           - migrate all uploaded data from the 2.1 filesore.
    '''
    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = None
    min_args = 1

    def command(self):
        self._load_config()
        import ckan.model as model
        import ckan.lib.search as search

        cmd = self.args[0]
        if cmd == 'init':

            model.repo.init_db()
            if self.verbose:
                print 'Initialising DB: SUCCESS'
        elif cmd == 'clean' or cmd == 'drop':

            # remove any *.pyc version files to prevent conflicts
            v_path = os.path.join(os.path.dirname(__file__),
                               '..', 'migration', 'versions', '*.pyc')
            import glob
            filelist = glob.glob(v_path)
            for f in filelist:
                os.remove(f)

            model.repo.clean_db()
            search.clear()
            if self.verbose:
                print 'Cleaning DB: SUCCESS'
        elif cmd == 'upgrade':
            if len(self.args) > 1:
                model.repo.upgrade_db(self.args[1])
            else:
                model.repo.upgrade_db()
        elif cmd == 'version':
            self.version()
        elif cmd == 'dump':
            self.dump()
        elif cmd == 'load':
            self.load()
        elif cmd == 'load-only':
            self.load(only_load=True)
        elif cmd == 'simple-dump-csv':
            self.simple_dump_csv()
        elif cmd == 'simple-dump-json':
            self.simple_dump_json()
        elif cmd == 'dump-rdf':
            self.dump_rdf()
        elif cmd == 'user-dump-csv':
            self.user_dump_csv()
        elif cmd == 'create-from-model':
            model.repo.create_db()
            if self.verbose:
                print 'Creating DB: SUCCESS'
        elif cmd == 'send-rdf':
            self.send_rdf()
        elif cmd == 'migrate-filestore':
            self.migrate_filestore()
        else:
            print 'Command %s not recognized' % cmd
            sys.exit(1)

    def _get_db_config(self):
        return parse_db_config()

    def _get_postgres_cmd(self, command):
        self.db_details = self._get_db_config()
        if self.db_details.get('db_type') not in ('postgres', 'postgresql'):
            raise AssertionError('Expected postgres database - not %r' % self.db_details.get('db_type'))
        pg_cmd = command
        pg_cmd += ' -U %(db_user)s' % self.db_details
        if self.db_details.get('db_pass') not in (None, ''):
            pg_cmd = 'export PGPASSWORD=%(db_pass)s && ' % self.db_details + pg_cmd
        if self.db_details.get('db_host') not in (None, ''):
            pg_cmd += ' -h %(db_host)s' % self.db_details
        if self.db_details.get('db_port') not in (None, ''):
            pg_cmd += ' -p %(db_port)s' % self.db_details
        return pg_cmd

    def _get_psql_cmd(self):
        psql_cmd = self._get_postgres_cmd('psql')
        psql_cmd += ' -d %(db_name)s' % self.db_details
        return psql_cmd

    def _postgres_dump(self, filepath):
        pg_dump_cmd = self._get_postgres_cmd('pg_dump')
        pg_dump_cmd += ' %(db_name)s' % self.db_details
        pg_dump_cmd += ' > %s' % filepath
        self._run_cmd(pg_dump_cmd)
        print 'Dumped database to: %s' % filepath

    def _postgres_load(self, filepath):
        import ckan.model as model
        assert not model.repo.are_tables_created(), "Tables already found. You need to 'db clean' before a load."
        pg_cmd = self._get_psql_cmd() + ' -f %s' % filepath
        self._run_cmd(pg_cmd)
        print 'Loaded CKAN database: %s' % filepath

    def _run_cmd(self, command_line):
        import subprocess
        retcode = subprocess.call(command_line, shell=True)
        if retcode != 0:
            raise SystemError('Command exited with errorcode: %i' % retcode)

    def dump(self):
        if len(self.args) < 2:
            print 'Need pg_dump filepath'
            return
        dump_path = self.args[1]

        psql_cmd = self._get_psql_cmd() + ' -f %s'
        pg_cmd = self._postgres_dump(dump_path)

    def load(self, only_load=False):
        if len(self.args) < 2:
            print 'Need pg_dump filepath'
            return
        dump_path = self.args[1]

        psql_cmd = self._get_psql_cmd() + ' -f %s'
        pg_cmd = self._postgres_load(dump_path)
        if not only_load:
            print 'Upgrading DB'
            import ckan.model as model
            model.repo.upgrade_db()

            print 'Rebuilding search index'
            import ckan.lib.search
            ckan.lib.search.rebuild()
        else:
            print 'Now remember you have to call \'db upgrade\' and then \'search-index rebuild\'.'
        print 'Done'

    def simple_dump_csv(self):
        import ckan.model as model
        if len(self.args) < 2:
            print 'Need csv file path'
            return
        dump_filepath = self.args[1]
        import ckan.lib.dumper as dumper
        dump_file = open(dump_filepath, 'w')
        dumper.SimpleDumper().dump(dump_file, format='csv')

    def simple_dump_json(self):
        import ckan.model as model
        if len(self.args) < 2:
            print 'Need json file path'
            return
        dump_filepath = self.args[1]
        import ckan.lib.dumper as dumper
        dump_file = open(dump_filepath, 'w')
        dumper.SimpleDumper().dump(dump_file, format='json')

    def dump_rdf(self):
        if len(self.args) < 3:
            print 'Need dataset name and rdf file path'
            return
        package_name = self.args[1]
        rdf_path = self.args[2]
        import ckan.model as model
        import ckan.lib.rdf as rdf
        pkg = model.Package.by_name(unicode(package_name))
        if not pkg:
            print 'Dataset name "%s" does not exist' % package_name
            return
        rdf = rdf.RdfExporter().export_package(pkg)
        f = open(rdf_path, 'w')
        f.write(rdf)
        f.close()

    def user_dump_csv(self):
        if len(self.args) < 2:
            print 'Need csv file path'
            return
        dump_filepath = self.args[1]
        import ckan.lib.dumper as dumper
        dump_file = open(dump_filepath, 'w')
        dumper.UserDumper().dump(dump_file)

    def send_rdf(self):
        if len(self.args) < 4:
            print 'Need all arguments: {talis-store} {username} {password}'
            return
        talis_store = self.args[1]
        username = self.args[2]
        password = self.args[3]
        import ckan.lib.talis
        talis = ckan.lib.talis.Talis()
        return talis.send_rdf(talis_store, username, password)

    def migrate_filestore(self):
        from ckan.model import Session
        import requests
        from ckan.lib.uploader import ResourceUpload
        results = Session.execute("select id, revision_id, url from resource "
                                  "where resource_type = 'file.upload' "
                                  "and (url_type <> 'upload' or url_type is null)"
                                  "and url like '%storage%'")
        for id, revision_id, url  in results:
            response = requests.get(url, stream=True)
            if response.status_code != 200:
                print "failed to fetch %s (code %s)" % (url,
                                                        response.status_code)
                continue
            resource_upload = ResourceUpload({'id': id})
            assert resource_upload.storage_path, "no storage configured aborting"

            directory = resource_upload.get_directory(id)
            filepath = resource_upload.get_path(id)
            try:
                os.makedirs(directory)
            except OSError, e:
                ## errno 17 is file already exists
                if e.errno != 17:
                    raise

            with open(filepath, 'wb+') as out:
                for chunk in response.iter_content(1024):
                    if chunk:
                        out.write(chunk)

            Session.execute("update resource set url_type = 'upload'"
                            "where id = '%s'"  % id)
            Session.execute("update resource_revision set url_type = 'upload'"
                            "where id = '%s' and "
                            "revision_id = '%s'" % (id, revision_id))
            Session.commit()
            print "Saved url %s" % url

    def version(self):
        from ckan.model import Session
        print Session.execute('select version from migrate_version;').fetchall()



class SearchIndexCommand(CkanCommand):
    '''Creates a search index for all datasets

    Usage:
      search-index [-i] [-o] [-r] [-e] rebuild [dataset_name]  - reindex dataset_name if given, if not then rebuild
                                                                 full search index (all datasets)
      search-index rebuild_fast                                - reindex using multiprocessing using all cores. 
                                                                 This acts in the same way as rubuild -r [EXPERIMENTAL]
      search-index check                                       - checks for datasets not indexed
      search-index show DATASET_NAME                           - shows index of a dataset
      search-index clear [dataset_name]                        - clears the search index for the provided dataset or
                                                                 for the whole ckan instance
    '''

    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 2
    min_args = 0

    def __init__(self,name):

        super(SearchIndexCommand,self).__init__(name)

        self.parser.add_option('-i', '--force', dest='force',
            action='store_true', default=False, help='Ignore exceptions when rebuilding the index')

        self.parser.add_option('-o', '--only-missing', dest='only_missing',
            action='store_true', default=False, help='Index non indexed datasets only')

        self.parser.add_option('-r', '--refresh', dest='refresh',
            action='store_true', default=False, help='Refresh current index (does not clear the existing one)')

        self.parser.add_option('-e', '--commit-each', dest='commit_each',
            action='store_true', default=False, help=
'''Perform a commit after indexing each dataset. This ensures that changes are
immediately available on the search, but slows significantly the process.
Default is false.'''
                    )

    def command(self):
        if not self.args:
            # default to printing help
            print self.usage
            return

        cmd = self.args[0]
        # Do not run load_config yet
        if cmd == 'rebuild_fast':
            self.rebuild_fast()
            return

        self._load_config()
        if cmd == 'rebuild':
            self.rebuild()
        elif cmd == 'check':
            self.check()
        elif cmd == 'show':
            self.show()
        elif cmd == 'clear':
            self.clear()
        else:
            print 'Command %s not recognized' % cmd

    def rebuild(self):
        from ckan.lib.search import rebuild, commit

        # BY default we don't commit after each request to Solr, as it is
        # a really heavy operation and slows things a lot

        if len(self.args) > 1:
            rebuild(self.args[1])
        else:
            rebuild(only_missing=self.options.only_missing,
                    force=self.options.force,
                    refresh=self.options.refresh,
                    defer_commit=(not self.options.commit_each))

        if not self.options.commit_each:
            commit()

    def check(self):
        from ckan.lib.search import check

        check()

    def show(self):
        from ckan.lib.search import show

        if not len(self.args) == 2:
            print 'Missing parameter: dataset-name'
            return
        index = show(self.args[1])
        pprint(index)

    def clear(self):
        from ckan.lib.search import clear

        package_id =self.args[1] if len(self.args) > 1 else None
        clear(package_id)

    def rebuild_fast(self):
        ###  Get out config but without starting pylons environment ####
        conf = self._get_config()

        ### Get ids using own engine, otherwise multiprocess will balk
        db_url = conf['sqlalchemy.url']
        engine = sa.create_engine(db_url)
        package_ids = []
        result = engine.execute("select id from package where state = 'active';")
        for row in result:
            package_ids.append(row[0])

        def start(ids):
            ## load actual enviroment for each subprocess, so each have thier own
            ## sa session
            self._load_config()
            from ckan.lib.search import rebuild, commit
            rebuild(package_ids=ids)
            commit()

        def chunks(l, n):
            """ Yield n successive chunks from l.
            """
            newn = int(len(l) / n)
            for i in xrange(0, n-1):
                yield l[i*newn:i*newn+newn]
            yield l[n*newn-newn:]

        processes = []
        for chunk in chunks(package_ids, mp.cpu_count()):
            process = mp.Process(target=start, args=(chunk,))
            processes.append(process)
            process.daemon = True
            process.start()

        for process in processes:
            process.join()

class Notification(CkanCommand):
    '''Send out modification notifications.

    In "replay" mode, an update signal is sent for each dataset in the database.

    Usage:
      notify replay                        - send out modification signals
    '''

    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 1
    min_args = 0

    def command(self):
        self._load_config()
        from ckan.model import Session, Package, DomainObjectOperation
        from ckan.model.modification import DomainObjectModificationExtension

        if not self.args:
            # default to run
            cmd = 'replay'
        else:
            cmd = self.args[0]

        if cmd == 'replay':
            dome = DomainObjectModificationExtension()
            for package in Session.query(Package):
                dome.notify(package, DomainObjectOperation.changed)
        else:
            print 'Command %s not recognized' % cmd


class RDFExport(CkanCommand):
    '''Export active datasets as RDF
    This command dumps out all currently active datasets as RDF into the
    specified folder.

    Usage:
      paster rdf-export /path/to/store/output
    '''
    summary = __doc__.split('\n')[0]
    usage = __doc__

    def command(self):
        self._load_config()

        if not self.args:
            # default to run
            print RDFExport.__doc__
        else:
            self.export_datasets( self.args[0] )

    def export_datasets(self, out_folder):
        '''
        Export datasets as RDF to an output folder.
        '''
        import urlparse
        import urllib2
        import pylons.config as config
        import ckan.model as model
        import ckan.logic as logic
        import ckan.lib.helpers as h

        # Create output folder if not exists
        if not os.path.isdir( out_folder ):
            os.makedirs( out_folder )

        fetch_url = config['ckan.site_url']
        user = logic.get_action('get_site_user')({'model': model, 'ignore_auth': True}, {})
        context = {'model': model, 'session': model.Session, 'user': user['name']}
        dataset_names = logic.get_action('package_list')(context, {})
        for dataset_name in dataset_names:
            dd = logic.get_action('package_show')(context, {'id':dataset_name })
            if not dd['state'] == 'active':
                continue

            url = h.url_for( controller='package',action='read',
                                                  id=dd['name'])

            url = urlparse.urljoin(fetch_url, url[1:]) + '.rdf'
            try:
                fname = os.path.join( out_folder, dd['name'] ) + ".rdf"
                r = urllib2.urlopen(url).read()
                with open(fname, 'wb') as f:
                    f.write(r)
            except IOError, ioe:
                sys.stderr.write( str(ioe) + "\n" )




class Sysadmin(CkanCommand):
    '''Gives sysadmin rights to a named user

    Usage:
      sysadmin                      - lists sysadmins
      sysadmin list                 - lists sysadmins
      sysadmin add USERNAME         - add a user as a sysadmin
      sysadmin remove USERNAME      - removes user from sysadmins
    '''

    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 2
    min_args = 0

    def command(self):
        self._load_config()
        import ckan.model as model

        cmd = self.args[0] if self.args else None
        if cmd == None or cmd == 'list':
            self.list()
        elif cmd == 'add':
            self.add()
        elif cmd == 'remove':
            self.remove()
        else:
            print 'Command %s not recognized' % cmd

    def list(self):
        import ckan.model as model
        print 'Sysadmins:'
        sysadmins = model.Session.query(model.User).filter_by(sysadmin=True)
        print 'count = %i' % sysadmins.count()
        for sysadmin in sysadmins:
            print '%s name=%s id=%s' % (sysadmin.__class__.__name__,
                                        sysadmin.name,
                                        sysadmin.id)

    def add(self):
        import ckan.model as model

        if len(self.args) < 2:
            print 'Need name of the user to be made sysadmin.'
            return
        username = self.args[1]

        user = model.User.by_name(unicode(username))
        if not user:
            print 'User "%s" not found' % username
            makeuser = raw_input('Create new user: %s? [y/n]' % username)
            if makeuser == 'y':
                password = UserCmd.password_prompt()
                print('Creating %s user' % username)
                user = model.User(name=unicode(username),
                                  password=password)
            else:
                print 'Exiting ...'
                return

        user.sysadmin = True
        model.Session.add(user)
        model.repo.commit_and_remove()
        print 'Added %s as sysadmin' % username

    def remove(self):
        import ckan.model as model

        if len(self.args) < 2:
            print 'Need name of the user to be made sysadmin.'
            return
        username = self.args[1]

        user = model.User.by_name(unicode(username))
        if not user:
            print 'Error: user "%s" not found!' % username
            return
        user.sysadmin = False
        model.repo.commit_and_remove()


class UserCmd(CkanCommand):
    '''Manage users

    Usage:
      user                            - lists users
      user list                       - lists users
      user USERNAME                   - shows user properties
      user add USERNAME [FIELD1=VALUE1 FIELD2=VALUE2 ...]
                                      - add a user (prompts for password
                                        if not supplied).
                                        Field can be: apikey
                                                      password
                                                      email
      user setpass USERNAME           - set user password (prompts)
      user remove USERNAME            - removes user from users
      user search QUERY               - searches for a user name
    '''
    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = None
    min_args = 0

    def command(self):
        self._load_config()
        import ckan.model as model

        if not self.args:
            self.list()
        else:
            cmd = self.args[0]
            if cmd == 'add':
                self.add()
            elif cmd == 'remove':
                self.remove()
            elif cmd == 'search':
                self.search()
            elif cmd == 'setpass':
                self.setpass()
            elif cmd == 'list':
                self.list()
            else:
                self.show()

    def get_user_str(self, user):
        user_str = 'name=%s' % user.name
        if user.name != user.display_name:
            user_str += ' display=%s' % user.display_name
        return user_str

    def list(self):
        import ckan.model as model
        print 'Users:'
        users = model.Session.query(model.User)
        print 'count = %i' % users.count()
        for user in users:
            print self.get_user_str(user)

    def show(self):
        import ckan.model as model

        username = self.args[0]
        user = model.User.get(unicode(username))
        print 'User: \n', user

    def setpass(self):
        import ckan.model as model

        if len(self.args) < 2:
            print 'Need name of the user.'
            return
        username = self.args[1]
        user = model.User.get(username)
        print('Editing user: %r' % user.name)

        password = self.password_prompt()
        user.password = password
        model.repo.commit_and_remove()
        print 'Done'

    def search(self):
        import ckan.model as model

        if len(self.args) < 2:
            print 'Need user name query string.'
            return
        query_str = self.args[1]

        query = model.User.search(query_str)
        print '%i users matching %r:' % (query.count(), query_str)
        for user in query.all():
            print self.get_user_str(user)

    @classmethod
    def password_prompt(cls):
        import getpass
        password1 = None
        while not password1:
            password1 = getpass.getpass('Password: ')
        password2 = getpass.getpass('Confirm password: ')
        if password1 != password2:
            print 'Passwords do not match'
            sys.exit(1)
        return password1

    def add(self):
        import ckan.model as model

        if len(self.args) < 2:
            print 'Need name of the user.'
            sys.exit(1)
        username = self.args[1]

        # parse args into data_dict
        data_dict = {'name': username}
        for arg in self.args[2:]:
            try:
                field, value = arg.split('=', 1)
                data_dict[field] = value
            except ValueError:
                raise ValueError('Could not parse arg: %r (expected "<option>=<value>)"' % arg)

        if 'password' not in data_dict:
            data_dict['password'] = self.password_prompt()

        print('Creating user: %r' % username)

        try:
            import ckan.logic as logic
            site_user = logic.get_action('get_site_user')({'model': model, 'ignore_auth': True}, {})
            context = {
                    'model': model,
                    'session': model.Session,
                    'ignore_auth': True,
                    'user': site_user['name'],
                    }
            user_dict = logic.get_action('user_create')(context, data_dict)
            pprint(user_dict)
        except logic.ValidationError, e:
            print e
            sys.exit(1)

    def remove(self):
        import ckan.model as model

        if len(self.args) < 2:
            print 'Need name of the user.'
            return
        username = self.args[1]

        user = model.User.by_name(unicode(username))
        if not user:
            print 'Error: user "%s" not found!' % username
            return
        user.delete()
        model.repo.commit_and_remove()
        print('Deleted user: %s' % username)


class DatasetCmd(CkanCommand):
    '''Manage datasets

    Usage:
      dataset DATASET_NAME|ID            - shows dataset properties
      dataset show DATASET_NAME|ID       - shows dataset properties
      dataset list                       - lists datasets
      dataset delete [DATASET_NAME|ID]   - changes dataset state to 'deleted'
      dataset purge [DATASET_NAME|ID]    - removes dataset from db entirely
    '''
    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 3
    min_args = 0

    def command(self):
        self._load_config()
        import ckan.model as model

        if not self.args:
            print self.usage
        else:
            cmd = self.args[0]
            if cmd == 'delete':
                self.delete(self.args[1])
            elif cmd == 'purge':
                self.purge(self.args[1])
            elif cmd == 'list':
                self.list()
            elif cmd == 'show':
                self.show(self.args[1])
            else:
                self.show(self.args[0])

    def list(self):
        import ckan.model as model
        print 'Datasets:'
        datasets = model.Session.query(model.Package)
        print 'count = %i' % datasets.count()
        for dataset in datasets:
            state = ('(%s)' % dataset.state) if dataset.state != 'active' \
                    else ''
            print '%s %s %s' % (dataset.id, dataset.name, state)

    def _get_dataset(self, dataset_ref):
        import ckan.model as model
        dataset = model.Package.get(unicode(dataset_ref))
        assert dataset, 'Could not find dataset matching reference: %r' % dataset_ref
        return dataset

    def show(self, dataset_ref):
        import pprint
        dataset = self._get_dataset(dataset_ref)
        pprint.pprint(dataset.as_dict())

    def delete(self, dataset_ref):
        import ckan.model as model
        dataset = self._get_dataset(dataset_ref)
        old_state = dataset.state

        rev = model.repo.new_revision()
        dataset.delete()
        model.repo.commit_and_remove()
        dataset = self._get_dataset(dataset_ref)
        print '%s %s -> %s' % (dataset.name, old_state, dataset.state)

    def purge(self, dataset_ref):
        import ckan.model as model
        dataset = self._get_dataset(dataset_ref)
        name = dataset.name

        rev = model.repo.new_revision()
        dataset.purge()
        model.repo.commit_and_remove()
        print '%s purged' % name


class Celery(CkanCommand):
    '''Celery daemon

    Usage:
        celeryd <run>            - run the celery daemon
        celeryd run concurrency  - run the celery daemon with
                                   argument 'concurrency'
        celeryd view             - view all tasks in the queue
        celeryd clean            - delete all tasks in the queue
    '''
    min_args = 0
    max_args = 2
    summary = __doc__.split('\n')[0]
    usage = __doc__

    def command(self):
        if not self.args:
            self.run_()
        else:
            cmd = self.args[0]
            if cmd == 'run':
                self.run_()
            elif cmd == 'view':
                self.view()
            elif cmd == 'clean':
                self.clean()
            else:
                print 'Command %s not recognized' % cmd
                sys.exit(1)

    def run_(self):
        os.environ['CKAN_CONFIG'] = os.path.abspath(self.options.config)
        from ckan.lib.celery_app import celery
        celery_args = []
        if len(self.args) == 2 and self.args[1] == 'concurrency':
            celery_args.append['--concurrency=1']
        celery.worker_main(argv=['celeryd', '--loglevel=INFO'] + celery_args)

    def view(self):
        self._load_config()
        import ckan.model as model
        from kombu.transport.sqlalchemy.models import Message
        q = model.Session.query(Message)
        q_visible = q.filter_by(visible=True)
        print '%i messages (total)' % q.count()
        print '%i visible messages' % q_visible.count()
        for message in q:
            if message.visible:
                print '%i: Visible' % (message.id)
            else:
                print '%i: Invisible Sent:%s' % (message.id, message.sent_at)

    def clean(self):
        self._load_config()
        import ckan.model as model
        query = model.Session.execute("select * from kombu_message")
        tasks_initially = query.rowcount
        if not tasks_initially:
            print 'No tasks to delete'
            sys.exit(0)
        query = model.Session.execute("delete from kombu_message")
        query = model.Session.execute("select * from kombu_message")
        tasks_afterwards = query.rowcount
        print '%i of %i tasks deleted' % (tasks_initially - tasks_afterwards,
                                          tasks_initially)
        if tasks_afterwards:
            print 'ERROR: Failed to delete all tasks'
            sys.exit(1)
        model.repo.commit_and_remove()


class Ratings(CkanCommand):
    '''Manage the ratings stored in the db

    Usage:
      ratings count                 - counts ratings
      ratings clean                 - remove all ratings
      ratings clean-anonymous       - remove only anonymous ratings
    '''

    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 1
    min_args = 1

    def command(self):
        self._load_config()
        import ckan.model as model

        cmd = self.args[0]
        if cmd == 'count':
            self.count()
        elif cmd == 'clean':
            self.clean()
        elif cmd == 'clean-anonymous':
            self.clean(user_ratings=False)
        else:
            print 'Command %s not recognized' % cmd

    def count(self):
        import ckan.model as model
        q = model.Session.query(model.Rating)
        print "%i ratings" % q.count()
        q = q.filter(model.Rating.user_id == None)
        print "of which %i are anonymous ratings" % q.count()

    def clean(self, user_ratings=True):
        import ckan.model as model
        q = model.Session.query(model.Rating)
        print "%i ratings" % q.count()
        if not user_ratings:
            q = q.filter(model.Rating.user_id == None)
            print "of which %i are anonymous ratings" % q.count()
        ratings = q.all()
        for rating in ratings:
            rating.purge()
        model.repo.commit_and_remove()


## Used by the Tracking class
_ViewCount = collections.namedtuple("ViewCount", "id name count")


class Tracking(CkanCommand):
    '''Update tracking statistics

    Usage:
      tracking update [start_date]       - update tracking stats
      tracking export FILE [start_date]  - export tracking stats to a csv file
    '''

    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 3
    min_args = 1

    def command(self):
        self._load_config()
        import ckan.model as model
        engine = model.meta.engine

        cmd = self.args[0]
        if cmd == 'update':
            start_date = self.args[1] if len(self.args) > 1 else None
            self.update_all(engine, start_date)
        elif cmd == 'export':
            if len(self.args) <= 1:
                print self.__class__.__doc__
                sys.exit(1)
            output_file = self.args[1]
            start_date = self.args[2] if len(self.args) > 2 else None
            self.update_all(engine, start_date)
            self.export_tracking(engine, output_file)
        else:
            print self.__class__.__doc__
            sys.exit(1)

    def update_all(self, engine, start_date=None):
        if start_date:
            start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')
        else:
            # No date given. See when we last have data for and get data
            # from 2 days before then in case new data is available.
            # If no date here then use 2011-01-01 as the start date
            sql = '''SELECT tracking_date from tracking_summary
                     ORDER BY tracking_date DESC LIMIT 1;'''
            result = engine.execute(sql).fetchall()
            if result:
                start_date = result[0]['tracking_date']
                start_date += datetime.timedelta(-2)
                # convert date to datetime
                combine = datetime.datetime.combine
                start_date = combine(start_date, datetime.time(0))
            else:
                start_date = datetime.datetime(2011, 1, 1)
        end_date = datetime.datetime.now()

        while start_date < end_date:
            stop_date = start_date + datetime.timedelta(1)
            self.update_tracking(engine, start_date)
            print 'tracking updated for %s' % start_date
            start_date = stop_date

    def _total_views(self, engine):
        sql = '''
            SELECT p.id,
                   p.name,
                   COALESCE(SUM(s.count), 0) AS total_views
               FROM package AS p
               LEFT OUTER JOIN tracking_summary AS s ON s.package_id = p.id
               GROUP BY p.id, p.name
               ORDER BY total_views DESC
        '''
        return [_ViewCount(*t) for t in engine.execute(sql).fetchall()]

    def _recent_views(self, engine, measure_from):
        sql = '''
            SELECT p.id,
                   p.name,
                   COALESCE(SUM(s.count), 0) AS total_views
               FROM package AS p
               LEFT OUTER JOIN tracking_summary AS s ON s.package_id = p.id
               WHERE s.tracking_date >= %(measure_from)s
               GROUP BY p.id, p.name
               ORDER BY total_views DESC
        '''
        return [_ViewCount(*t) for t in engine.execute(
                    sql, measure_from=str(measure_from)
                ).fetchall()]

    def export_tracking(self, engine, output_filename):
        '''Write tracking summary to a csv file.'''
        HEADINGS = [
            "dataset id",
            "dataset name",
            "total views",
            "recent views (last 2 weeks)",
        ]

        measure_from = datetime.date.today() - datetime.timedelta(days=14)
        recent_views = self._recent_views(engine, measure_from)
        total_views = self._total_views(engine)

        with open(output_filename, 'w') as fh:
            f_out = csv.writer(fh)
            f_out.writerow(HEADINGS)
            recent_views_for_id = dict((r.id, r.count) for r in recent_views)
            f_out.writerows([(r.id,
                              r.name,
                              r.count,
                              recent_views_for_id.get(r.id, 0))
                              for r in total_views])

    def update_tracking(self, engine, summary_date):
        PACKAGE_URL = '%/dataset/'
        # clear out existing data before adding new
        sql = '''DELETE FROM tracking_summary
                 WHERE tracking_date='%s'; ''' % summary_date
        engine.execute(sql)

        sql = '''SELECT DISTINCT url, user_key,
                     CAST(access_timestamp AS Date) AS tracking_date,
                     tracking_type INTO tracking_tmp
                 FROM tracking_raw
                 WHERE CAST(access_timestamp as Date)='%s';

                 INSERT INTO tracking_summary
                   (url, count, tracking_date, tracking_type)
                 SELECT url, count(user_key), tracking_date, tracking_type
                 FROM tracking_tmp
                 GROUP BY url, tracking_date, tracking_type;

                 DROP TABLE tracking_tmp;
                 COMMIT;''' % summary_date
        engine.execute(sql)

        # get ids for dataset urls
        sql = '''UPDATE tracking_summary t
                 SET package_id = COALESCE(
                        (SELECT id FROM package p
                        WHERE t.url LIKE  %s || p.name)
                     ,'~~not~found~~')
                 WHERE t.package_id IS NULL
                 AND tracking_type = 'page';'''
        engine.execute(sql, PACKAGE_URL)

        # update summary totals for resources
        sql = '''UPDATE tracking_summary t1
                 SET running_total = (
                    SELECT sum(count)
                    FROM tracking_summary t2
                    WHERE t1.url = t2.url
                    AND t2.tracking_date <= t1.tracking_date
                 )
                 ,recent_views = (
                    SELECT sum(count)
                    FROM tracking_summary t2
                    WHERE t1.url = t2.url
                    AND t2.tracking_date <= t1.tracking_date AND t2.tracking_date >= t1.tracking_date - 14
                 )
                 WHERE t1.running_total = 0 AND tracking_type = 'resource';'''
        engine.execute(sql)

        # update summary totals for pages
        sql = '''UPDATE tracking_summary t1
                 SET running_total = (
                    SELECT sum(count)
                    FROM tracking_summary t2
                    WHERE t1.package_id = t2.package_id
                    AND t2.tracking_date <= t1.tracking_date
                 )
                 ,recent_views = (
                    SELECT sum(count)
                    FROM tracking_summary t2
                    WHERE t1.package_id = t2.package_id
                    AND t2.tracking_date <= t1.tracking_date AND t2.tracking_date >= t1.tracking_date - 14
                 )
                 WHERE t1.running_total = 0 AND tracking_type = 'page'
                 AND t1.package_id IS NOT NULL
                 AND t1.package_id != '~~not~found~~';'''
        engine.execute(sql)

class PluginInfo(CkanCommand):
    '''Provide info on installed plugins.
    '''

    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 0
    min_args = 0

    def command(self):
        self.get_info()

    def get_info(self):
        ''' print info about current plugins from the .ini file'''
        import ckan.plugins as p
        self._load_config()
        interfaces = {}
        plugins = {}
        for name in dir(p):
            item = getattr(p, name)
            try:
                if issubclass(item, p.Interface):
                    interfaces[item] = {'class' : item}
            except TypeError:
                pass

        for interface in interfaces:
            for plugin in p.PluginImplementations(interface):
                name = plugin.name
                if name not in plugins:
                    plugins[name] = {'doc' : plugin.__doc__,
                                     'class' : plugin,
                                     'implements' : []}
                plugins[name]['implements'].append(interface.__name__)

        for plugin in plugins:
            p = plugins[plugin]
            print plugin + ':'
            print '-' * (len(plugin) + 1)
            if p['doc']:
                print p['doc']
            print 'Implements:'
            for i in p['implements']:
                extra = None
                if i == 'ITemplateHelpers':
                    extra = self.template_helpers(p['class'])
                if i == 'IActions':
                    extra = self.actions(p['class'])
                print '    %s' % i
                if extra:
                    print extra
            print


    def actions(self, cls):
        ''' Return readable action function info. '''
        actions = cls.get_actions()
        return self.function_info(actions)

    def template_helpers(self, cls):
        ''' Return readable helper function info. '''
        helpers = cls.get_helpers()
        return self.function_info(helpers)

    def function_info(self, functions):
        ''' Take a dict of functions and output readable info '''
        import inspect
        output = []
        for function_name in functions:
            fn = functions[function_name]
            args_info = inspect.getargspec(fn)
            params = args_info.args
            num_params = len(params)
            if args_info.varargs:
                params.append('*' + args_info.varargs)
            if args_info.keywords:
                params.append('**' + args_info.keywords)
            if args_info.defaults:
                offset = num_params - len(args_info.defaults)
                for i, v in enumerate(args_info.defaults):
                    params[i + offset] = params[i + offset] + '=' + repr(v)
            # is this a classmethod if so remove the first parameter
            if inspect.ismethod(fn) and inspect.isclass(fn.__self__):
                params = params[1:]
            params = ', '.join(params)
            output.append('        %s(%s)' % (function_name, params))
            # doc string
            if fn.__doc__:
                bits = fn.__doc__.split('\n')
                for bit in bits:
                    output.append('            %s' % bit)
        return ('\n').join(output)


class CreateTestDataCommand(CkanCommand):
    '''Create test data in the database.
    Tests can also delete the created objects easily with the delete() method.

    create-test-data              - annakarenina and warandpeace
    create-test-data search       - realistic data to test search
    create-test-data gov          - government style data
    create-test-data family       - package relationships data
    create-test-data user         - create a user 'tester' with api key 'tester'
    create-test-data translations - annakarenina, warandpeace, and some test
                                    translations of terms
    create-test-data vocabs       - annakerenina, warandpeace, and some test
                                    vocabularies
    create-test-data hierarchy    - hierarchy of groups
    '''
    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 1
    min_args = 0

    def command(self):
        self._load_config()
        self._setup_app()
        from ckan import plugins
        from create_test_data import CreateTestData

        if self.args:
            cmd = self.args[0]
        else:
            cmd = 'basic'
        if self.verbose:
            print 'Creating %s test data' % cmd
        if cmd == 'basic':
            CreateTestData.create_basic_test_data()
        elif cmd == 'user':
            CreateTestData.create_test_user()
            print 'Created user %r with password %r and apikey %r' % ('tester',
                    'tester', 'tester')
        elif cmd == 'search':
            CreateTestData.create_search_test_data()
        elif cmd == 'gov':
            CreateTestData.create_gov_test_data()
        elif cmd == 'family':
            CreateTestData.create_family_test_data()
        elif cmd == 'translations':
            CreateTestData.create_translations_test_data()
        elif cmd == 'vocabs':
            CreateTestData.create_vocabs_test_data()
        elif cmd == 'hierarchy':
            CreateTestData.create_group_hierarchy_test_data()
        else:
            print 'Command %s not recognized' % cmd
            raise NotImplementedError
        if self.verbose:
            print 'Creating %s test data: Complete!' % cmd

class Profile(CkanCommand):
    '''Code speed profiler
    Provide a ckan url and it will make the request and record
    how long each function call took in a file that can be read
    by runsnakerun.

    Usage:
       profile URL

    e.g. profile /data/search

    The result is saved in profile.data.search
    To view the profile in runsnakerun:
       runsnakerun ckan.data.search.profile

    You may need to install python module: cProfile
    '''
    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 1
    min_args = 1

    def _load_config_into_test_app(self):
        from paste.deploy import loadapp
        import paste.fixture
        if not self.options.config:
            msg = 'No config file supplied'
            raise self.BadCommand(msg)
        self.filename = os.path.abspath(self.options.config)
        if not os.path.exists(self.filename):
            raise AssertionError('Config filename %r does not exist.' % self.filename)
        fileConfig(self.filename)

        wsgiapp = loadapp('config:' + self.filename)
        self.app = paste.fixture.TestApp(wsgiapp)

    def command(self):
        self._load_config_into_test_app()

        import paste.fixture
        import cProfile
        import re

        url = self.args[0]

        def profile_url(url):
            try:
                res = self.app.get(url, status=[200], extra_environ={'REMOTE_USER': 'visitor'})
            except paste.fixture.AppError:
                print 'App error: ', url.strip()
            except KeyboardInterrupt:
                raise
            except:
                import traceback
                traceback.print_exc()
                print 'Unknown error: ', url.strip()

        output_filename = 'ckan%s.profile' % re.sub('[/?]', '.', url.replace('/', '.'))
        profile_command = "profile_url('%s')" % url
        cProfile.runctx(profile_command, globals(), locals(), filename=output_filename)
        print 'Written profile to: %s' % output_filename


class CreateColorSchemeCommand(CkanCommand):
    '''Create or remove a color scheme.

    After running this, you'll need to regenerate the css files. See paster's less command for details.

    color               - creates a random color scheme
    color clear         - clears any color scheme
    color <'HEX'>       - uses as base color eg '#ff00ff' must be quoted.
    color <VALUE>       - a float between 0.0 and 1.0 used as base hue
    color <COLOR_NAME>  - html color name used for base color eg lightblue
    '''

    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 1
    min_args = 0

    rules = [
        '@layoutLinkColor',
        '@mastheadBackgroundColor',
        '@btnPrimaryBackground',
        '@btnPrimaryBackgroundHighlight',
    ]

    # list of predefined colors
    color_list = {
        'aliceblue': '#f0fff8',
        'antiquewhite': '#faebd7',
        'aqua': '#00ffff',
        'aquamarine': '#7fffd4',
        'azure': '#f0ffff',
        'beige': '#f5f5dc',
        'bisque': '#ffe4c4',
        'black': '#000000',
        'blanchedalmond': '#ffebcd',
        'blue': '#0000ff',
        'blueviolet': '#8a2be2',
        'brown': '#a52a2a',
        'burlywood': '#deb887',
        'cadetblue': '#5f9ea0',
        'chartreuse': '#7fff00',
        'chocolate': '#d2691e',
        'coral': '#ff7f50',
        'cornflowerblue': '#6495ed',
        'cornsilk': '#fff8dc',
        'crimson': '#dc143c',
        'cyan': '#00ffff',
        'darkblue': '#00008b',
        'darkcyan': '#008b8b',
        'darkgoldenrod': '#b8860b',
        'darkgray': '#a9a9a9',
        'darkgrey': '#a9a9a9',
        'darkgreen': '#006400',
        'darkkhaki': '#bdb76b',
        'darkmagenta': '#8b008b',
        'darkolivegreen': '#556b2f',
        'darkorange': '#ff8c00',
        'darkorchid': '#9932cc',
        'darkred': '#8b0000',
        'darksalmon': '#e9967a',
        'darkseagreen': '#8fbc8f',
        'darkslateblue': '#483d8b',
        'darkslategray': '#2f4f4f',
        'darkslategrey': '#2f4f4f',
        'darkturquoise': '#00ced1',
        'darkviolet': '#9400d3',
        'deeppink': '#ff1493',
        'deepskyblue': '#00bfff',
        'dimgray': '#696969',
        'dimgrey': '#696969',
        'dodgerblue': '#1e90ff',
        'firebrick': '#b22222',
        'floralwhite': '#fffaf0',
        'forestgreen': '#228b22',
        'fuchsia': '#ff00ff',
        'gainsboro': '#dcdcdc',
        'ghostwhite': '#f8f8ff',
        'gold': '#ffd700',
        'goldenrod': '#daa520',
        'gray': '#808080',
        'grey': '#808080',
        'green': '#008000',
        'greenyellow': '#adff2f',
        'honeydew': '#f0fff0',
        'hotpink': '#ff69b4',
        'indianred ': '#cd5c5c',
        'indigo ': '#4b0082',
        'ivory': '#fffff0',
        'khaki': '#f0e68c',
        'lavender': '#e6e6fa',
        'lavenderblush': '#fff0f5',
        'lawngreen': '#7cfc00',
        'lemonchiffon': '#fffacd',
        'lightblue': '#add8e6',
        'lightcoral': '#f08080',
        'lightcyan': '#e0ffff',
        'lightgoldenrodyellow': '#fafad2',
        'lightgray': '#d3d3d3',
        'lightgrey': '#d3d3d3',
        'lightgreen': '#90ee90',
        'lightpink': '#ffb6c1',
        'lightsalmon': '#ffa07a',
        'lightseagreen': '#20b2aa',
        'lightskyblue': '#87cefa',
        'lightslategray': '#778899',
        'lightslategrey': '#778899',
        'lightsteelblue': '#b0c4de',
        'lightyellow': '#ffffe0',
        'lime': '#00ff00',
        'limegreen': '#32cd32',
        'linen': '#faf0e6',
        'magenta': '#ff00ff',
        'maroon': '#800000',
        'mediumaquamarine': '#66cdaa',
        'mediumblue': '#0000cd',
        'mediumorchid': '#ba55d3',
        'mediumpurple': '#9370d8',
        'mediumseagreen': '#3cb371',
        'mediumslateblue': '#7b68ee',
        'mediumspringgreen': '#00fa9a',
        'mediumturquoise': '#48d1cc',
        'mediumvioletred': '#c71585',
        'midnightblue': '#191970',
        'mintcream': '#f5fffa',
        'mistyrose': '#ffe4e1',
        'moccasin': '#ffe4b5',
        'navajowhite': '#ffdead',
        'navy': '#000080',
        'oldlace': '#fdf5e6',
        'olive': '#808000',
        'olivedrab': '#6b8e23',
        'orange': '#ffa500',
        'orangered': '#ff4500',
        'orchid': '#da70d6',
        'palegoldenrod': '#eee8aa',
        'palegreen': '#98fb98',
        'paleturquoise': '#afeeee',
        'palevioletred': '#d87093',
        'papayawhip': '#ffefd5',
        'peachpuff': '#ffdab9',
        'peru': '#cd853f',
        'pink': '#ffc0cb',
        'plum': '#dda0dd',
        'powderblue': '#b0e0e6',
        'purple': '#800080',
        'red': '#ff0000',
        'rosybrown': '#bc8f8f',
        'royalblue': '#4169e1',
        'saddlebrown': '#8b4513',
        'salmon': '#fa8072',
        'sandybrown': '#f4a460',
        'seagreen': '#2e8b57',
        'seashell': '#fff5ee',
        'sienna': '#a0522d',
        'silver': '#c0c0c0',
        'skyblue': '#87ceeb',
        'slateblue': '#6a5acd',
        'slategray': '#708090',
        'slategrey': '#708090',
        'snow': '#fffafa',
        'springgreen': '#00ff7f',
        'steelblue': '#4682b4',
        'tan': '#d2b48c',
        'teal': '#008080',
        'thistle': '#d8bfd8',
        'tomato': '#ff6347',
        'turquoise': '#40e0d0',
        'violet': '#ee82ee',
        'wheat': '#f5deb3',
        'white': '#ffffff',
        'whitesmoke': '#f5f5f5',
        'yellow': '#ffff00',
        'yellowgreen': '#9acd32',
    }

    def create_colors(self, hue, num_colors=5, saturation=None, lightness=None):
        if saturation is None:
            saturation = 0.9
        if lightness is None:
            lightness = 40
        else:
            lightness *= 100

        import math
        saturation -= math.trunc(saturation)

        print hue, saturation
        import colorsys
        ''' Create n related colours '''
        colors=[]
        for i in xrange(num_colors):
            ix = i * (1.0/num_colors)
            _lightness = (lightness + (ix * 40))/100.
            if _lightness > 1.0:
                _lightness = 1.0
            color = colorsys.hls_to_rgb(hue, _lightness, saturation)
            hex_color = '#'
            for part in color:
                hex_color += '%02x' % int(part * 255)
            # check and remove any bad values
            if not re.match('^\#[0-9a-f]{6}$', hex_color):
                hex_color='#FFFFFF'
            colors.append(hex_color)
        return colors

    def command(self):

        hue = None
        saturation = None
        lightness = None

        path = os.path.dirname(__file__)
        path = os.path.join(path, '..', 'public', 'base', 'less', 'custom.less')

        if self.args:
            arg = self.args[0]
            rgb = None
            if arg == 'clear':
                os.remove(path)
                print 'custom colors removed.'
            elif arg.startswith('#'):
                color = arg[1:]
                if len(color) == 3:
                    rgb = [int(x, 16) * 16 for x in color]
                elif len(color) == 6:
                    rgb = [int(x, 16) for x in re.findall('..', color)]
                else:
                    print 'ERROR: invalid color'
            elif arg.lower() in self.color_list:
                color = self.color_list[arg.lower()][1:]
                rgb = [int(x, 16) for x in re.findall('..', color)]
            else:
                try:
                    hue = float(self.args[0])
                except ValueError:
                    print 'ERROR argument `%s` not recognised' % arg
            if rgb:
                import colorsys
                hue, lightness, saturation = colorsys.rgb_to_hls(*rgb)
                lightness = lightness / 340
                # deal with greys
                if not (hue == 0.0 and saturation == 0.0):
                    saturation = None
        else:
            import random
            hue = random.random()
        if hue is not None:
            f = open(path, 'w')
            colors = self.create_colors(hue, saturation=saturation, lightness=lightness)
            for i in xrange(len(self.rules)):
                f.write('%s: %s;\n' % (self.rules[i], colors[i]))
                print '%s: %s;\n' % (self.rules[i], colors[i])
            f.close
            print 'Color scheme has been created.'
        print 'Make sure less is run for changes to take effect.'


class TranslationsCommand(CkanCommand):
    '''Translation helper functions

    trans js      - generate the javascript translations
    trans mangle  - mangle the zh_TW translations for testing
    '''

    summary = __doc__.split('\n')[0]
    usage = __doc__
    max_args = 1
    min_args = 1

    def command(self):
        self._load_config()
        from pylons import config
        self.ckan_path = os.path.join(os.path.dirname(__file__), '..')
        i18n_path = os.path.join(self.ckan_path, 'i18n')
        self.i18n_path = config.get('ckan.i18n_directory', i18n_path)
        command = self.args[0]
        if command == 'mangle':
            self.mangle_po()
        elif command == 'js':
            self.build_js_translations()
        else:
            print 'command not recognised'


    def po2dict(self, po, lang):
        '''Convert po object to dictionary data structure (ready for JSON).

        This function is from pojson
        https://bitbucket.org/obviel/pojson

Copyright (c) 2010, Fanstatic Developers
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:
    * Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.
    * Redistributions in binary form must reproduce the above copyright
      notice, this list of conditions and the following disclaimer in the
      documentation and/or other materials provided with the distribution.
    * Neither the name of the <organization> nor the
      names of its contributors may be used to endorse or promote products
      derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL FANSTATIC DEVELOPERS BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
'''
        result = {}

        result[''] = {}
        result['']['plural-forms'] = po.metadata['Plural-Forms']
        result['']['lang'] = lang
        result['']['domain'] = 'ckan'

        for entry in po:
            if entry.obsolete:
                continue
            # check if used in js file we only include these
            occurrences = entry.occurrences
            js_use = False
            for occurrence in occurrences:
                if occurrence[0].endswith('.js'):
                    js_use = True
                    continue
            if not js_use:
                continue
            if entry.msgstr:
                result[entry.msgid] = [None, entry.msgstr]
            elif entry.msgstr_plural:
                plural = [entry.msgid_plural]
                result[entry.msgid] = plural
                ordered_plural = sorted(entry.msgstr_plural.items())
                for order, msgstr in ordered_plural:
                    plural.append(msgstr)
        return result

    def build_js_translations(self):
        import polib
        import simplejson as json

        def create_js(source, lang):
            print 'Generating', lang
            po = polib.pofile(source)
            data = self.po2dict(po, lang)
            data = json.dumps(data, sort_keys=True,
                              ensure_ascii=False, indent=2 * ' ')
            out_dir = os.path.abspath(os.path.join(self.ckan_path, 'public',
                                                   'base', 'i18n'))
            out_file = open(os.path.join(out_dir, '%s.js' % lang), 'w')
            out_file.write(data.encode('utf-8'))
            out_file.close()

        for l in os.listdir(self.i18n_path):
            if os.path.isdir(os.path.join(self.i18n_path, l)):
                f = os.path.join(self.i18n_path, l, 'LC_MESSAGES', 'ckan.po')
                create_js(f, l)
        print 'Completed generating JavaScript translations'

    def mangle_po(self):
        ''' This will mangle the zh_TW translations for translation coverage
        testing.

        NOTE: This will destroy the current translations fot zh_TW
        '''
        import polib
        pot_path = os.path.join(self.i18n_path, 'ckan.pot')
        po = polib.pofile(pot_path)
        # we don't want to mangle the following items in strings
        # %(...)s  %s %0.3f %1$s %2$0.3f [1:...] {...} etc

        # sprintf bit after %
        spf_reg_ex = "\+?(0|'.)?-?\d*(.\d*)?[\%bcdeufosxX]"

        extract_reg_ex = '(\%\([^\)]*\)' + spf_reg_ex + \
                         '|\[\d*\:[^\]]*\]' + \
                         '|\{[^\}]*\}' + \
                         '|<[^>}]*>' + \
                         '|\%((\d)*\$)?' + spf_reg_ex + ')'

        for entry in po:
            msg = entry.msgid.encode('utf-8')
            matches = re.finditer(extract_reg_ex, msg)
            length = len(msg)
            position = 0
            translation = u''
            for match in matches:
                translation += '-' * (match.start() - position)
                position = match.end()
                translation += match.group(0)
            translation += '-' * (length - position)
            entry.msgstr = translation
        out_dir = os.path.join(self.i18n_path, 'zh_TW', 'LC_MESSAGES')
        try:
            os.makedirs(out_dir)
        except OSError:
            pass
        po.metadata['Plural-Forms'] = "nplurals=1; plural=0\n"
        out_po = os.path.join(out_dir, 'ckan.po')
        out_mo = os.path.join(out_dir, 'ckan.mo')
        po.save(out_po)
        po.save_as_mofile(out_mo)
        print 'zh_TW has been mangled'


class MinifyCommand(CkanCommand):
    '''Create minified versions of the given Javascript and CSS files.

    Usage:

        paster minify [--clean] PATH

    for example:

        paster minify ckan/public/base
        paster minify ckan/public/base/css/*.css
        paster minify ckan/public/base/css/red.css

    if the --clean option is provided any minified files will be removed.

    '''
    summary = __doc__.split('\n')[0]
    usage = __doc__
    min_args = 1

    exclude_dirs = ['vendor']

    def __init__(self, name):

        super(MinifyCommand, self).__init__(name)

        self.parser.add_option('--clean', dest='clean',
            action='store_true', default=False, help='remove any minified files in the path')

    def command(self):
        clean = getattr(self.options, 'clean', False)
        self._load_config()
        for base_path in self.args:
            if os.path.isfile(base_path):
                if clean:
                    self.clear_minifyed(base_path)
                else:
                    self.minify_file(base_path)
            elif os.path.isdir(base_path):
                for root, dirs, files in os.walk(base_path):
                    dirs[:] = [d for d in dirs if not d in self.exclude_dirs]
                    for filename in files:
                        path = os.path.join(root, filename)
                        if clean:
                            self.clear_minifyed(path)
                        else:
                            self.minify_file(path)
            else:
                # Path is neither a file or a dir?
                continue

    def clear_minifyed(self, path):
        path_only, extension = os.path.splitext(path)

        if extension not in ('.css', '.js'):
            # This is not a js or css file.
            return

        if path_only.endswith('.min'):
            print 'removing %s' % path
            os.remove(path)

    def minify_file(self, path):
        '''Create the minified version of the given file.

        If the file is not a .js or .css file (e.g. it's a .min.js or .min.css
        file, or it's some other type of file entirely) it will not be
        minifed.

        :param path: The path to the .js or .css file to minify

        '''
        path_only, extension = os.path.splitext(path)

        if path_only.endswith('.min'):
            # This is already a minified file.
            return

        if extension not in ('.css', '.js'):
            # This is not a js or css file.
            return

        path_min = fanstatic_resources.min_path(path)

        source = open(path, 'r').read()
        f = open(path_min, 'w')
        if path.endswith('.css'):
            f.write(rcssmin.cssmin(source))
        elif path.endswith('.js'):
            f.write(rjsmin.jsmin(source))
        f.close()
        print "Minified file '{0}'".format(path)


class LessCommand(CkanCommand):
    '''Compile all root less documents into their CSS counterparts

    Usage:

        paster less

    '''
    summary = __doc__.split('\n')[0]
    usage = __doc__
    min_args = 0

    def command(self):
        self.less()

    custom_css = {
        'fuchsia': '''
            @layoutLinkColor: #E73892;
            @footerTextColor: mix(#FFF, @layoutLinkColor, 60%);
            @footerLinkColor: @footerTextColor;
            @mastheadBackgroundColor: @layoutLinkColor;
            @btnPrimaryBackground: lighten(@layoutLinkColor, 10%);
            @btnPrimaryBackgroundHighlight: @layoutLinkColor;
            ''',

        'green': '''
            @layoutLinkColor: #2F9B45;
            @footerTextColor: mix(#FFF, @layoutLinkColor, 60%);
            @footerLinkColor: @footerTextColor;
            @mastheadBackgroundColor: @layoutLinkColor;
            @btnPrimaryBackground: lighten(@layoutLinkColor, 10%);
            @btnPrimaryBackgroundHighlight: @layoutLinkColor;
            ''',

        'red': '''
            @layoutLinkColor: #C14531;
            @footerTextColor: mix(#FFF, @layoutLinkColor, 60%);
            @footerLinkColor: @footerTextColor;
            @mastheadBackgroundColor: @layoutLinkColor;
            @btnPrimaryBackground: lighten(@layoutLinkColor, 10%);
            @btnPrimaryBackgroundHighlight: @layoutLinkColor;
            ''',

        'maroon': '''
            @layoutLinkColor: #810606;
            @footerTextColor: mix(#FFF, @layoutLinkColor, 60%);
            @footerLinkColor: @footerTextColor;
            @mastheadBackgroundColor: @layoutLinkColor;
            @btnPrimaryBackground: lighten(@layoutLinkColor, 10%);
            @btnPrimaryBackgroundHighlight: @layoutLinkColor;
            ''',
    }
    def less(self):
        ''' Compile less files '''
        import subprocess
        command = 'npm bin'
        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)
        output = process.communicate()
        directory = output[0].strip()
        less_bin = os.path.join(directory, 'lessc')

        root = os.path.join(os.path.dirname(__file__), '..', 'public', 'base')
        root = os.path.abspath(root)
        custom_less = os.path.join(root, 'less', 'custom.less')
        for color in self.custom_css:
            f = open(custom_less, 'w')
            f.write(self.custom_css[color])
            f.close()
            self.compile_less(root, less_bin, color)
        f = open(custom_less, 'w')
        f.write('// This file is needed in order for ./bin/less to compile in less 1.3.1+\n')
        f.close()
        self.compile_less(root, less_bin, 'main')



    def compile_less(self, root, less_bin, color):
        print 'compile %s.css' % color
        import subprocess
        main_less = os.path.join(root, 'less', 'main.less')
        main_css = os.path.join(root, 'css', '%s.css' % color)

        command = '%s %s %s' % (less_bin, main_less, main_css)

        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)
        output = process.communicate()



class FrontEndBuildCommand(CkanCommand):
    '''Creates and minifies css and JavaScript files

    Usage:

        paster front-end-build
    '''

    summary = __doc__.split('\n')[0]
    usage = __doc__
    min_args = 0

    def command(self):
        self._load_config()

        # Less css
        cmd = LessCommand('less')
        cmd.command()

        # js translation strings
        cmd = TranslationsCommand('trans')
        cmd.options = self.options
        cmd.args = ('js',)
        cmd.command()

        # minification
        cmd = MinifyCommand('minify')
        cmd.options = self.options
        root = os.path.join(os.path.dirname(__file__), '..', 'public', 'base')
        root = os.path.abspath(root)
        ckanext = os.path.join(os.path.dirname(__file__), '..', '..', 'ckanext')
        ckanext = os.path.abspath(ckanext)
        cmd.args = (root, ckanext)
        cmd.command()

########NEW FILE########
__FILENAME__ = create_test_data
import logging
from collections import defaultdict
import datetime

import ckan.model as model

log = logging.getLogger(__name__)

class CreateTestData(object):
    # keep track of the objects created by this class so that
    # tests can easy call delete() method to delete them all again.
    pkg_names = []
    tag_names = []
    group_names = set()
    user_refs = []

    author = u'tester'

    pkg_core_fields = ['name', 'title', 'version', 'url', 'notes',
                       'author', 'author_email',
                       'maintainer', 'maintainer_email',
                       ]
    @classmethod
    def create_basic_test_data(cls):
        cls.create()

    @classmethod
    def create_search_test_data(cls):
        cls.create_arbitrary(search_items)

    @classmethod
    def create_gov_test_data(cls, extra_users=[]):
        cls.create_arbitrary(gov_items, extra_user_names=extra_users)

    @classmethod
    def create_family_test_data(cls, extra_users=[]):
        cls.create_arbitrary(family_items,
                              relationships=family_relationships,
                              extra_user_names=extra_users)

    @classmethod
    def create_group_hierarchy_test_data(cls, extra_users=[]):
        cls.create_users(group_hierarchy_users)
        cls.create_groups(group_hierarchy_groups)
        cls.create_arbitrary(group_hierarchy_datasets)

    @classmethod
    def create_test_user(cls):
        tester = model.User.by_name(u'tester')
        if tester is None:
            tester = model.User(name=u'tester', apikey=u'tester',
                password=u'tester')
            model.Session.add(tester)
            model.Session.commit()
        model.Session.remove()
        cls.user_refs.append(u'tester')

    @classmethod

    def create_translations_test_data(cls):
        import ckan.model
        CreateTestData.create()
        rev = ckan.model.repo.new_revision()
        rev.author = CreateTestData.author
        rev.message = u'Creating test translations.'

        sysadmin_user = ckan.model.User.get('testsysadmin')
        package = ckan.model.Package.get('annakarenina')

        # Add some new tags to the package.
        # These tags are codes that are meant to be always translated before
        # display, if not into the user's current language then into the
        # fallback language.
        package.add_tags([ckan.model.Tag('123'), ckan.model.Tag('456'),
                ckan.model.Tag('789')])

        # Add the above translations to CKAN.
        for (lang_code, translations) in (('de', german_translations),
                ('fr', french_translations), ('en', english_translations)):
            for term in terms:
                if term in translations:
                    data_dict = {
                            'term': term,
                            'term_translation': translations[term],
                            'lang_code': lang_code,
                            }
                    context = {
                        'model': ckan.model,
                        'session': ckan.model.Session,
                        'user': sysadmin_user.name,
                    }
                    ckan.logic.action.update.term_translation_update(context,
                            data_dict)

        ckan.model.Session.commit()

    def create_vocabs_test_data(cls):
        import ckan.model
        CreateTestData.create()
        sysadmin_user = ckan.model.User.get('testsysadmin')
        annakarenina = ckan.model.Package.get('annakarenina')
        warandpeace = ckan.model.Package.get('warandpeace')

        # Create a couple of vocabularies.
        context = {
                'model': ckan.model,
                'session': ckan.model.Session,
                'user': sysadmin_user.name
                }
        data_dict = {
                'name': 'Genre',
                'tags': [{'name': 'Drama'}, {'name': 'Sci-Fi'},
                    {'name': 'Mystery'}],
                }
        ckan.logic.action.create.vocabulary_create(context, data_dict)

        data_dict = {
                'name': 'Actors',
                'tags': [{'name': 'keira-knightley'}, {'name': 'jude-law'},
                    {'name': 'alessio-boni'}],
                }
        ckan.logic.action.create.vocabulary_create(context, data_dict)

        # Add some vocab tags to some packages.
        genre_vocab = ckan.model.Vocabulary.get('Genre')
        actors_vocab = ckan.model.Vocabulary.get('Actors')
        annakarenina.add_tag_by_name('Drama', vocab=genre_vocab)
        annakarenina.add_tag_by_name('keira-knightley', vocab=actors_vocab)
        annakarenina.add_tag_by_name('jude-law', vocab=actors_vocab)
        warandpeace.add_tag_by_name('Drama', vocab=genre_vocab)
        warandpeace.add_tag_by_name('alessio-boni', vocab=actors_vocab)

    @classmethod
    def create_arbitrary(cls, package_dicts, relationships=[],
            extra_user_names=[], extra_group_names=[],
            admins=[]):
        '''Creates packages and a few extra objects as well at the
        same time if required.
        @param package_dicts - a list of dictionaries with the package
                               properties.
                               Extra keys allowed:
                               "admins" - list of user names to make admin
                                          for this package.
        @param extra_group_names - a list of group names to create. No
                               properties get set though.
        @param admins - a list of user names to make admins of all the
                               packages created.
        '''
        assert isinstance(relationships, (list, tuple))
        assert isinstance(extra_user_names, (list, tuple))
        assert isinstance(extra_group_names, (list, tuple))
        model.Session.remove()
        new_user_names = extra_user_names
        new_group_names = set()
        new_groups = {}


        admins_list = defaultdict(list) # package_name: admin_names
        if package_dicts:
            if isinstance(package_dicts, dict):
                package_dicts = [package_dicts]
            for item in package_dicts:
                rev = model.repo.new_revision()
                rev.author = cls.author
                rev.message = u'Creating test packages.'
                pkg_dict = {}
                for field in cls.pkg_core_fields:
                    if item.has_key(field):
                        pkg_dict[field] = unicode(item[field])
                if model.Package.by_name(pkg_dict['name']):
                    log.warning('Cannot create package "%s" as it already exists.' % \
                                    (pkg_dict['name']))
                    continue
                pkg = model.Package(**pkg_dict)
                model.Session.add(pkg)
                for attr, val in item.items():
                    if isinstance(val, str):
                        val = unicode(val)
                    if attr=='name':
                        continue
                    if attr in cls.pkg_core_fields:
                        pass
                    elif attr == 'download_url':
                        pkg.add_resource(unicode(val))
                    elif attr == 'resources':
                        assert isinstance(val, (list, tuple))
                        for res_dict in val:
                            non_extras = {}
                            for k, v in res_dict.items():
                                if k != 'extras':
                                    if not isinstance(v, datetime.datetime):
                                        v = unicode(v)
                                    non_extras[str(k)] = v
                            extras = dict([(str(k), unicode(v)) for k, v in res_dict.get('extras', {}).items()])
                            pkg.add_resource(extras=extras, **non_extras)
                    elif attr == 'tags':
                        if isinstance(val, (str, unicode)):
                            tags = val.split()
                        elif isinstance(val, list):
                            tags = val
                        else:
                            raise NotImplementedError
                        for tag_name in tags:
                            tag_name = unicode(tag_name)
                            tag = model.Tag.by_name(tag_name)
                            if not tag:
                                tag = model.Tag(name=tag_name)
                                cls.tag_names.append(tag_name)
                                model.Session.add(tag)
                            pkg.add_tag(tag)
                            model.Session.flush()
                    elif attr == 'groups':
                        model.Session.flush()
                        if isinstance(val, (str, unicode)):
                            group_names = val.split()
                        elif isinstance(val, list):
                            group_names = val
                        else:
                            raise NotImplementedError
                        for group_name in group_names:
                            group = model.Group.by_name(unicode(group_name))
                            if not group:
                                if not group_name in new_groups:
                                    group = model.Group(name=
                                                        unicode(group_name))
                                    model.Session.add(group)
                                    new_group_names.add(group_name)
                                    new_groups[group_name] = group
                                else:
                                    # If adding multiple packages with the same
                                    # group name, model.Group.by_name will not
                                    # find the group as the session has not yet
                                    # been committed at this point.  Fetch from
                                    # the new_groups dict instead.
                                    group = new_groups[group_name]
                            capacity = 'organization' if group.is_organization\
                                       else 'public'
                            member = model.Member(group=group, table_id=pkg.id,
                                                  table_name='package',
                                                  capacity=capacity)
                            model.Session.add(member)
                            if group.is_organization:
                                pkg.owner_org = group.id
                    elif attr == 'license':
                        pkg.license_id = val
                    elif attr == 'license_id':
                        pkg.license_id = val
                    elif attr == 'extras':
                        pkg.extras = val
                    elif attr == 'admins':
                        assert isinstance(val, list)
                        admins_list[item['name']].extend(val)
                        for user_name in val:
                            if user_name not in new_user_names:
                                new_user_names.append(user_name)
                    else:
                        raise NotImplementedError(attr)
                cls.pkg_names.append(item['name'])
                model.setup_default_user_roles(pkg, admins=[])
                for admin in admins:
                    admins_list[item['name']].append(admin)
                model.repo.commit_and_remove()

        needs_commit = False

        rev = model.repo.new_revision()
        for group_name in extra_group_names:
            group = model.Group(name=unicode(group_name))
            model.Session.add(group)
            new_group_names.add(group_name)
            needs_commit = True

        if needs_commit:
            model.repo.commit_and_remove()
            needs_commit = False

        # create users that have been identified as being needed
        for user_name in new_user_names:
            if not model.User.by_name(unicode(user_name)):
                user = model.User(name=unicode(user_name))
                model.Session.add(user)
                cls.user_refs.append(user_name)
                needs_commit = True

        if needs_commit:
            model.repo.commit_and_remove()
            needs_commit = False

        # setup authz for admins
        for pkg_name, admins in admins_list.items():
            pkg = model.Package.by_name(unicode(pkg_name))
            admins_obj_list = []
            for admin in admins:
                if isinstance(admin, model.User):
                    admin_obj = admin
                else:
                    admin_obj = model.User.by_name(unicode(admin))
                assert admin_obj, admin
                admins_obj_list.append(admin_obj)
            model.setup_default_user_roles(pkg, admins_obj_list)
            needs_commit = True

        # setup authz for groups just created
        for group_name in new_group_names:
            group = model.Group.by_name(unicode(group_name))
            model.setup_default_user_roles(group)
            cls.group_names.add(group_name)
            needs_commit = True

        if needs_commit:
            model.repo.commit_and_remove()
            needs_commit = False

        if relationships:
            rev = model.repo.new_revision()
            rev.author = cls.author
            rev.message = u'Creating package relationships.'

            def pkg(pkg_name):
                return model.Package.by_name(unicode(pkg_name))
            for subject_name, relationship, object_name in relationships:
                pkg(subject_name).add_relationship(
                    unicode(relationship), pkg(object_name))
                needs_commit = True

            model.repo.commit_and_remove()


    @classmethod
    def create_groups(cls, group_dicts, admin_user_name=None, auth_profile=""):
        '''A more featured interface for creating groups.
        All group fields can be filled, packages added, can have
        an admin user and be a member of other groups.'''
        rev = model.repo.new_revision()
        rev.author = cls.author
        if admin_user_name:
            admin_users = [model.User.by_name(admin_user_name)]
        else:
            admin_users = []
        assert isinstance(group_dicts, (list, tuple))
        group_attributes = set(('name', 'title', 'description', 'parent_id',
                                'type', 'is_organization'))
        for group_dict in group_dicts:
            if model.Group.by_name(unicode(group_dict['name'])):
                log.warning('Cannot create group "%s" as it already exists.' %
                            group_dict['name'])
                continue
            pkg_names = group_dict.pop('packages', [])
            group = model.Group(name=unicode(group_dict['name']))
            group.type = auth_profile or 'group'
            for key in group_dict:
                if key in group_attributes:
                    setattr(group, key, group_dict[key])
                elif key not in ('admins', 'editors', 'parent'):
                    group.extras[key] = group_dict[key]
            assert isinstance(pkg_names, (list, tuple))
            for pkg_name in pkg_names:
                pkg = model.Package.by_name(unicode(pkg_name))
                assert pkg, pkg_name
                member = model.Member(group=group, table_id=pkg.id,
                                      table_name='package')
                model.Session.add(member)
            model.Session.add(group)
            admins = [model.User.by_name(user_name)
                      for user_name in group_dict.get('admins', [])] + \
                     admin_users
            for admin in admins:
                member = model.Member(group=group, table_id=admin.id,
                                      table_name='user', capacity='admin')
                model.Session.add(member)
            editors = [model.User.by_name(user_name)
                       for user_name in group_dict.get('editors', [])]
            for editor in editors:
                member = model.Member(group=group, table_id=editor.id,
                                      table_name='user', capacity='editor')
                model.Session.add(member)
            # Need to commit the current Group for two reasons:
            # 1. It might have a parent, and the Member will need the Group.id
            #    value allocated on commit.
            # 2. The next Group created may have this Group as a parent so
            #    creation of the Member needs to refer to this one.
            model.Session.commit()
            rev = model.repo.new_revision()
            rev.author = cls.author
            # add it to a parent's group
            if 'parent' in group_dict:
                parent = model.Group.by_name(unicode(group_dict['parent']))
                assert parent, group_dict['parent']
                member = model.Member(group=group, table_id=parent.id,
                                      table_name='group', capacity='parent')
                model.Session.add(member)
            #model.setup_default_user_roles(group, admin_users)
            cls.group_names.add(group_dict['name'])
        model.repo.commit_and_remove()

    @classmethod
    def create(cls, auth_profile="", package_type=None):
        model.Session.remove()
        rev = model.repo.new_revision()
        # same name as user we create below
        rev.author = cls.author
        rev.message = u'''Creating test data.
 * Package: annakarenina
 * Package: warandpeace
 * Associated tags, etc etc
'''
        if auth_profile == "publisher":
            organization_group = model.Group(name=u"organization_group",
                                             type="organization")

        cls.pkg_names = [u'annakarenina', u'warandpeace']
        pkg1 = model.Package(name=cls.pkg_names[0], type=package_type)
        if auth_profile == "publisher":
            pkg1.group = organization_group
        model.Session.add(pkg1)
        pkg1.title = u'A Novel By Tolstoy'
        pkg1.version = u'0.7a'
        pkg1.url = u'http://www.annakarenina.com'
        # put an & in the url string to test escaping
        if 'alt_url' in model.Resource.get_extra_columns():
            configured_extras = ({'alt_url': u'alt123'},
                                 {'alt_url': u'alt345'})
        else:
            configured_extras = ({}, {})
        pr1 = model.Resource(
            url=u'http://www.annakarenina.com/download/x=1&y=2',
            format=u'plain text',
            description=u'Full text. Needs escaping: " Umlaut: \xfc',
            hash=u'abc123',
            extras={'size_extra': u'123'},
            **configured_extras[0]
            )
        pr2 = model.Resource(
            url=u'http://www.annakarenina.com/index.json',
            format=u'JSON',
            description=u'Index of the novel',
            hash=u'def456',
            extras={'size_extra': u'345'},
            **configured_extras[1]
            )
        model.Session.add(pr1)
        model.Session.add(pr2)
        pkg1.resource_groups_all[0].resources_all.append(pr1)
        pkg1.resource_groups_all[0].resources_all.append(pr2)
        pkg1.notes = u'''Some test notes

### A 3rd level heading

**Some bolded text.**

*Some italicized text.*

Foreign characters:
u with umlaut \xfc
66-style quote \u201c
foreign word: th\xfcmb

Needs escaping:
left arrow <

<http://ckan.net/>

'''
        pkg2 = model.Package(name=cls.pkg_names[1], type=package_type)
        tag1 = model.Tag(name=u'russian')
        tag2 = model.Tag(name=u'tolstoy')

        if auth_profile == "publisher":
            pkg2.group = organization_group

        # Flexible tag, allows spaces, upper-case,
        # and all punctuation except commas
        tag3 = model.Tag(name=u'Flexible \u30a1')

        for obj in [pkg2, tag1, tag2, tag3]:
            model.Session.add(obj)
        pkg1.add_tags([tag1, tag2, tag3])
        pkg2.add_tags([ tag1, tag3 ])
        cls.tag_names = [ t.name for t in (tag1, tag2, tag3) ]
        pkg1.license_id = u'other-open'
        pkg2.license_id = u'cc-nc' # closed license
        pkg2.title = u'A Wonderful Story'
        pkg1.extras = {u'genre':'romantic novel',
                       u'original media':'book'}
        # group
        david = model.Group(name=u'david',
                             title=u'Dave\'s books',
                             description=u'These are books that David likes.',
                             type=auth_profile or 'group')
        roger = model.Group(name=u'roger',
                             title=u'Roger\'s books',
                             description=u'Roger likes these books.',
                             type=auth_profile or 'group')
        for obj in [david, roger]:
            model.Session.add(obj)

        cls.group_names.add(u'david')
        cls.group_names.add(u'roger')

        model.Session.flush()

        model.Session.add(model.Member(table_id=pkg1.id, table_name='package', group=david))
        model.Session.add(model.Member(table_id=pkg2.id, table_name='package', group=david))
        model.Session.add(model.Member(table_id=pkg1.id, table_name='package', group=roger))
        # authz
        sysadmin = model.User(name=u'testsysadmin', password=u'testsysadmin')
        sysadmin.sysadmin = True
        model.Session.add_all([
            model.User(name=u'tester', apikey=u'tester', password=u'tester'),
            model.User(name=u'joeadmin', password=u'joeadmin'),
            model.User(name=u'annafan', about=u'I love reading Annakarenina. My site: http://anna.com', password=u'annafan'),
            model.User(name=u'russianfan', password=u'russianfan'),
            sysadmin,
            ])
        cls.user_refs.extend([u'tester', u'joeadmin', u'annafan', u'russianfan', u'testsysadmin'])
        model.repo.commit_and_remove()

        visitor = model.User.by_name(model.PSEUDO_USER__VISITOR)
        anna = model.Package.by_name(u'annakarenina')
        war = model.Package.by_name(u'warandpeace')
        annafan = model.User.by_name(u'annafan')
        russianfan = model.User.by_name(u'russianfan')
        model.setup_default_user_roles(anna, [annafan])
        model.setup_default_user_roles(war, [russianfan])
        model.add_user_to_role(visitor, model.Role.ADMIN, war)
        david = model.Group.by_name(u'david')
        roger = model.Group.by_name(u'roger')
        model.setup_default_user_roles(david, [russianfan])
        model.setup_default_user_roles(roger, [russianfan])

        # in new_authz you can't give a visitor permissions to a
        # group it seems, so this is a bit meaningless
        model.add_user_to_role(visitor, model.Role.ADMIN, roger)
        model.repo.commit_and_remove()

    # method used in DGU and all good tests elsewhere
    @classmethod
    def create_users(cls, user_dicts):
        needs_commit = False
        for user_dict in user_dicts:
            user = cls._create_user_without_commit(**user_dict)
            if user:
                needs_commit = True
        if needs_commit:
            model.repo.commit_and_remove()

    @classmethod
    def _create_user_without_commit(cls, name='', **user_dict):
        if model.User.by_name(name) or \
                (user_dict.get('open_id') and
                 model.User.by_openid(user_dict.get('openid'))):
            log.warning('Cannot create user "%s" as it already exists.' %
                        name or user_dict['name'])
            return
        # User objects are not revisioned so no need to create a revision
        user_ref = name or user_dict['openid']
        assert user_ref
        for k, v in user_dict.items():
            if v:
                # avoid unicode warnings
                user_dict[k] = unicode(v)
        user = model.User(name=unicode(name), **user_dict)
        model.Session.add(user)
        cls.user_refs.append(user_ref)
        return user

    @classmethod
    def create_user(cls, name='', **kwargs):
        user = cls._create_user_without_commit(name, **kwargs)
        model.Session.commit()
        return user

    @classmethod
    def flag_for_deletion(cls, pkg_names=[], tag_names=[], group_names=[],
                          user_names=[]):
        '''If you create a domain object manually in your test then you
        can name it here (flag it up) and it will be deleted when you next
        call CreateTestData.delete().'''
        if isinstance(pkg_names, basestring):
            pkg_names = [pkg_names]
        cls.pkg_names.extend(pkg_names)
        cls.tag_names.extend(tag_names)
        cls.group_names = cls.group_names.union(set(group_names))
        cls.user_refs.extend(user_names)

    @classmethod
    def delete(cls):
        '''Purges packages etc. that were created by this class.'''
        for pkg_name in cls.pkg_names:
            model.Session().autoflush = False
            pkg = model.Package.by_name(unicode(pkg_name))
            if pkg:
                pkg.purge()
        for tag_name in cls.tag_names:
            tag = model.Tag.by_name(unicode(tag_name))
            if tag:
                tag.purge()
        for group_name in cls.group_names:
            group = model.Group.by_name(unicode(group_name))
            if group:
                model.Session.delete(group)
        revs = model.Session.query(model.Revision).filter_by(author=cls.author)
        for rev in revs:
            for pkg in rev.packages:
                pkg.purge()
            for grp in rev.groups:
                grp.purge()
            model.Session.commit()
            model.Session.delete(rev)
        for user_name in cls.user_refs:
            user = model.User.get(unicode(user_name))
            if user:
                user.purge()
        model.Session.commit()
        model.Session.remove()
        cls.reset()

    @classmethod
    def reset(cls):
        cls.pkg_names = []
        cls.group_names = set()
        cls.tag_names = []
        cls.user_refs = []

    @classmethod
    def get_all_data(cls):
        return cls.pkg_names + list(cls.group_names) + cls.tag_names + cls.user_refs

    @classmethod
    def make_some_vocab_tags(cls):
        model.repo.new_revision()

        # Create a couple of vocabularies.
        genre_vocab = model.Vocabulary(u'genre')
        model.Session.add(genre_vocab)
        composers_vocab = model.Vocabulary(u'composers')
        model.Session.add(composers_vocab)

        # Create some additional free tags for tag search tests.
        tolkien_tag = model.Tag(name="tolkien")
        model.Session.add(tolkien_tag)
        toledo_tag = model.Tag(name="toledo")
        model.Session.add(toledo_tag)
        tolerance_tag = model.Tag(name="tolerance")
        model.Session.add(tolerance_tag)
        tollbooth_tag = model.Tag(name="tollbooth")
        model.Session.add(tollbooth_tag)
        # We have to add free tags to a package or they won't show up in tag results.
        model.Package.get('warandpeace').add_tags((tolkien_tag, toledo_tag,
            tolerance_tag, tollbooth_tag))

        # Create some tags that belong to vocabularies.
        sonata_tag = model.Tag(name=u'sonata', vocabulary_id=genre_vocab.id)
        model.Session.add(sonata_tag)

        bach_tag = model.Tag(name=u'Bach', vocabulary_id=composers_vocab.id)
        model.Session.add(bach_tag)

        neoclassical_tag = model.Tag(name='neoclassical',
                vocabulary_id=genre_vocab.id)
        model.Session.add(neoclassical_tag)

        neofolk_tag = model.Tag(name='neofolk', vocabulary_id=genre_vocab.id)
        model.Session.add(neofolk_tag)

        neomedieval_tag = model.Tag(name='neomedieval',
                vocabulary_id=genre_vocab.id)
        model.Session.add(neomedieval_tag)

        neoprog_tag = model.Tag(name='neoprog',
                vocabulary_id=genre_vocab.id)
        model.Session.add(neoprog_tag)

        neopsychedelia_tag = model.Tag(name='neopsychedelia',
                vocabulary_id=genre_vocab.id)
        model.Session.add(neopsychedelia_tag)

        neosoul_tag = model.Tag(name='neosoul', vocabulary_id=genre_vocab.id)
        model.Session.add(neosoul_tag)

        nerdcore_tag = model.Tag(name='nerdcore', vocabulary_id=genre_vocab.id)
        model.Session.add(nerdcore_tag)

        model.Package.get('warandpeace').add_tag(bach_tag)
        model.Package.get('annakarenina').add_tag(sonata_tag)

        model.Session.commit()



search_items = [{'name':'gils',
              'title':'Government Information Locator Service',
              'url':'',
              'tags':'registry,country-usa,government,federal,gov,workshop-20081101,penguin'.split(','),
              'resources':[{'url':'http://www.dcsf.gov.uk/rsgateway/DB/SFR/s000859/SFR17_2009_tables.xls',
                          'format':'XLS',
                          'last_modified': datetime.datetime(2005,10,01),
                          'description':'December 2009 | http://www.statistics.gov.uk/hub/id/119-36345'},
                          {'url':'http://www.dcsf.gov.uk/rsgateway/DB/SFR/s000860/SFR17_2009_key.doc',
                          'format':'DOC',
                          'description':'http://www.statistics.gov.uk/hub/id/119-34565'}],
              'groups':'ukgov test1 test2 penguin',
              'license':'odc-by',
              'notes':u'''From <http://www.gpoaccess.gov/gils/about.html>

> The Government Information Locator Service (GILS) is an effort to identify, locate, and describe publicly available Federal
> Because this collection is decentralized, the GPO

Foreign word:
u with umlaut th\xfcmb
''',
              'extras':{'date_released':'2008'},
              },
             {'name':'us-gov-images',
              'title':'U.S. Government Photos and Graphics',
              'url':'http://www.usa.gov/Topics/Graphics.shtml',
              'download_url':'http://www.usa.gov/Topics/Graphics.shtml',
              'tags':'images,graphics,photographs,photos,pictures,us,usa,america,history,wildlife,nature,war,military,todo split,gov,penguin'.split(','),
              'groups':'ukgov test1 penguin',
              'license':'other-open',
              'notes':'''## About

Collection of links to different US image collections in the public domain.

## Openness

> Most of these images and graphics are available for use in the public domain, and''',
              'extras':{'date_released':'2009'},
              },
             {'name':'usa-courts-gov',
              'title':'Text of US Federal Cases',
              'url':'http://bulk.resource.org/courts.gov/',
              'download_url':'http://bulk.resource.org/courts.gov/',
              'tags':'us,courts,case-law,us,courts,case-law,gov,legal,law,access-bulk,penguins,penguin'.split(','),
              'groups':'ukgov test2 penguin',
              'license':'cc-zero',
              'notes':'''### Description

1.8 million pages of U.S. case law available with no restrictions. From the [README](http://bulk.resource.org/courts.gov/0_README.html):

> This file is  http://bulk.resource.org/courts.gov/0_README.html and was last revised.

penguin
''',
              'extras':{'date_released':'2007-06'},
              },
             {'name':'uk-government-expenditure',
              'title':'UK Government Expenditure',
              'tags':'workshop-20081101,uk,gov,expenditure,finance,public,funding,penguin'.split(','),
              'groups':'ukgov penguin',
              'notes':'''Discussed at [Workshop on Public Information, 2008-11-02](http://okfn.org/wiki/PublicInformation).

Overview is available in Red Book, or Financial Statement and Budget Report (FSBR), [published by the Treasury](http://www.hm-treasury.gov.uk/budget.htm).''',
              'extras':{'date_released':'2007-10'},
              },
             {'name':'se-publications',
              'title':'Sweden - Government Offices of Sweden - Publications',
              'url':'http://www.sweden.gov.se/sb/d/574',
              'groups':'penguin',
              'tags':u'country-sweden,format-pdf,access-www,documents,publications,government,eutransparency,penguin,CAPITALS,surprise.,greek omega \u03a9,japanese katakana \u30a1'.split(','),
              'license':'',
              'notes':'''### About

Official documents including "government bills and reports, information material and other publications".

### Reuse

Not clear.''',
              'extras':{'date_released':'2009-10-27'},
              },
             {'name':'se-opengov',
              'title':'Opengov.se',
              'groups':'penguin',
              'url':'http://www.opengov.se/',
              'download_url':'http://www.opengov.se/data/open/',
              'tags':'country-sweden,government,data,penguin'.split(','),
              'license':'cc-by-sa',
              'notes':'''### About

From [website](http://www.opengov.se/sidor/english/):

> Opengov.se is an initiative to highlight available public datasets in Sweden. It contains a commentable catalog of government datasets, their formats and usage restrictions.

> The goal is to highlight the benefits of open access to government data and explain how this is done in practice.

### Openness

It appears that the website is under a CC-BY-SA license. Legal status of the data varies. Data that is fully open can be viewed at:

 * <http://www.opengov.se/data/open/>'''
              },
             ]

family_items = [{'name':u'abraham', 'title':u'Abraham'},
                {'name':u'homer', 'title':u'Homer'},
                {'name':u'homer_derived', 'title':u'Homer Derived'},
                {'name':u'beer', 'title':u'Beer'},
                {'name':u'bart', 'title':u'Bart'},
                {'name':u'lisa', 'title':u'Lisa'},
                {'name':u'marge', 'title':u'Marge'},
                ]
family_relationships = [('abraham', 'parent_of', 'homer'),
                        ('homer', 'parent_of', 'bart'),
                        ('homer', 'parent_of', 'lisa'),
                        ('marge', 'parent_of', 'lisa'),
                        ('marge', 'parent_of', 'bart'),
                        ('homer_derived', 'derives_from', 'homer'),
                        ('homer', 'depends_on', 'beer'),
                        ]

gov_items = [
    {'name':'private-fostering-england-2009',
     'title':'Private Fostering',
     'notes':'Figures on children cared for and accommodated in private fostering arrangements, England, Year ending 31 March 2009',
     'resources':[{'url':'http://www.dcsf.gov.uk/rsgateway/DB/SFR/s000859/SFR17_2009_tables.xls',
                  'format':'XLS',
                  'description':'December 2009 | http://www.statistics.gov.uk/hub/id/119-36345'},
                  {'url':'http://www.dcsf.gov.uk/rsgateway/DB/SFR/s000860/SFR17_2009_key.doc',
                  'format':'DOC',
                  'description':'http://www.statistics.gov.uk/hub/id/119-34565'}],
     'url':'http://www.dcsf.gov.uk/rsgateway/DB/SFR/s000859/index.shtml',
     'author':'DCSF Data Services Group',
     'author_email':'statistics@dcsf.gsi.gov.uk',
     'license':'ukcrown',
     'tags':'children fostering',
     'extras':{
        'external_reference':'DCSF-DCSF-0024',
        'date_released':'2009-07-30',
        'date_updated':'2009-07-30',
        'update_frequency':'annually',
        'geographic_granularity':'regional',
        'geographic_coverage':'100000: England',
        'department':'Department for Education',
        'published_by':'Department for Education [3]',
        'published_via':'',
        'temporal_granularity':'years',
        'temporal_coverage-from':'2008-6',
        'temporal_coverage-to':'2009-6',
        'mandate':'',
        'national_statistic':'yes',
        'precision':'Numbers to nearest 10, percentage to nearest whole number',
        'taxonomy_url':'',
        'agency':'',
        'import_source':'ONS-Jan-09',
        }
     },
    {'name':'weekly-fuel-prices',
     'title':'Weekly fuel prices',
     'notes':'Latest price as at start of week of unleaded petrol and diesel.',
     'resources':[{'url':'http://www.decc.gov.uk/assets/decc/statistics/source/prices/qep211.xls', 'format':'XLS', 'description':'Quarterly 23/2/12'}],
     'url':'http://www.decc.gov.uk/en/content/cms/statistics/source/prices/prices.aspx',
     'author':'DECC Energy Statistics Team',
     'author_email':'energy.stats@decc.gsi.gov.uk',
     'license':'ukcrown',
     'tags':'fuel prices',
     'extras':{
        'external_reference':'DECC-DECC-0001',
        'date_released':'2009-11-24',
        'date_updated':'2009-11-24',
        'update_frequency':'weekly',
        'geographic_granularity':'national',
        'geographic_coverage':'111100: United Kingdom (England, Scotland, Wales, Northern Ireland)',
        'department':'Department of Energy and Climate Change',
        'published_by':'Department of Energy and Climate Change [4]',
        'published_via':'',
         'mandate':'',
        'temporal_granularity':'weeks',
        'temporal_coverage-from':'2008-11-24',
        'temporal_coverage-to':'2009-11-24',
        'national_statistic':'no',
        'import_source':'DECC-Jan-09',
        }
     }
    ]

group_hierarchy_groups = [
    {'name': 'department-of-health',
     'title': 'Department of Health',
     'contact-email': 'contact@doh.gov.uk',
     'type': 'organization',
     'is_organization': True
     },
    {'name': 'food-standards-agency',
     'title': 'Food Standards Agency',
     'contact-email': 'contact@fsa.gov.uk',
     'parent': 'department-of-health',
     'type': 'organization',
     'is_organization': True},
    {'name': 'national-health-service',
     'title': 'National Health Service',
     'contact-email': 'contact@nhs.gov.uk',
     'parent': 'department-of-health',
     'type': 'organization',
     'is_organization': True,
     'editors': ['nhseditor'],
     'admins': ['nhsadmin']},
    {'name': 'nhs-wirral-ccg',
     'title': 'NHS Wirral CCG',
     'contact-email': 'contact@wirral.nhs.gov.uk',
     'parent': 'national-health-service',
     'type': 'organization',
     'is_organization': True,
     'editors': ['wirraleditor'],
     'admins': ['wirraladmin']},
    {'name': 'nhs-southwark-ccg',
     'title': 'NHS Southwark CCG',
     'contact-email': 'contact@southwark.nhs.gov.uk',
     'parent': 'national-health-service',
     'type': 'organization',
     'is_organization': True},
    {'name': 'cabinet-office',
     'title': 'Cabinet Office',
     'contact-email': 'contact@cabinet-office.gov.uk',
     'type': 'organization',
     'is_organization': True},
    ]

group_hierarchy_datasets = [
    {'name': 'doh-spend', 'title': 'Department of Health Spend Data',
     'groups': ['department-of-health']},
    {'name': 'nhs-spend', 'title': 'NHS Spend Data',
     'groups': ['national-health-service']},
    {'name': 'wirral-spend', 'title': 'Wirral Spend Data',
     'groups': ['nhs-wirral-ccg']},
    {'name': 'southwark-spend', 'title': 'Southwark Spend Data',
     'groups': ['nhs-southwark-ccg']},
    ]

group_hierarchy_users = [{'name': 'nhsadmin', 'password': 'pass'},
                         {'name': 'nhseditor', 'password': 'pass'},
                         {'name': 'wirraladmin', 'password': 'pass'},
                         {'name': 'wirraleditor', 'password': 'pass'},
                         ]

# Some test terms and translations.
terms = ('A Novel By Tolstoy',
    'Index of the novel',
    'russian',
    'tolstoy',
    "Dave's books",
    "Roger's books",
    'romantic novel',
    'book',
    '123',
    '456',
    '789',
    'plain text',
    'Roger likes these books.',
)
english_translations = {
    '123': 'jealousy',
    '456': 'realism',
    '789': 'hypocrisy',
}
german_translations = {
    'A Novel By Tolstoy': 'Roman von Tolstoi',
    'Index of the novel': 'Index des Romans',
    'russian': 'Russisch',
    'tolstoy': 'Tolstoi',
    "Dave's books": 'Daves Bucher',
    "Roger's books": 'Rogers Bucher',
    'romantic novel': 'Liebesroman',
    'book': 'Buch',
    '456': 'Realismus',
    '789': 'Heuchelei',
    'plain text': 'Klartext',
    'Roger likes these books.': 'Roger mag diese Bucher.'
}
french_translations = {
    'A Novel By Tolstoy': 'A Novel par Tolstoi',
    'Index of the novel': 'Indice du roman',
    'russian': 'russe',
    'romantic novel': 'roman romantique',
    'book': 'livre',
    '123': 'jalousie',
    '789': 'hypocrisie',
}

########NEW FILE########
__FILENAME__ = datapreview
# coding=UTF-8

"""Data previewer functions

Functions and data structures that are needed for the ckan data preview.
"""

import urlparse
import logging

import pylons.config as config

import ckan.plugins as p

DEFAULT_DIRECT_EMBED = ['png', 'jpg', 'jpeg', 'gif']
DEFAULT_LOADABLE_IFRAME = ['html', 'htm', 'rdf+xml', 'owl+xml', 'xml',
                           'n3', 'n-triples', 'turtle', 'plain',
                           'atom', 'rss', 'txt']

log = logging.getLogger(__name__)


def direct():
    ''' Directly embeddable formats.'''
    direct_embed = config.get('ckan.preview.direct', '').split()
    return direct_embed or DEFAULT_DIRECT_EMBED


def loadable():
    ''' Iframe loadable formats. '''
    loadable_in_iframe = config.get('ckan.preview.loadable', '').split()
    return loadable_in_iframe or DEFAULT_LOADABLE_IFRAME


def res_format(resource):
    ''' The assumed resource format in lower case. '''
    if not resource['url']:
        return None
    return (resource['format'] or resource['url'].split('.')[-1]).lower()


def compare_domains(urls):
    ''' Return True if the domains of the provided urls are the same.
    '''
    first_domain = None
    for url in urls:
        # all urls are interpreted as absolute urls,
        # except for urls that start with a /
        try:
            if not urlparse.urlparse(url).scheme and not url.startswith('/'):
                url = '//' + url
            parsed = urlparse.urlparse(url.lower(), 'http')
            domain = (parsed.scheme, parsed.hostname, parsed.port)
        except ValueError:
            # URL is so messed up that even urlparse can't stand it
            return False

        if not first_domain:
            first_domain = domain
            continue
        if first_domain != domain:
            return False
    return True


def _on_same_domain(data_dict):
    # compare CKAN domain and resource URL
    ckan_url = config.get('ckan.site_url', '//localhost:5000')
    resource_url = data_dict['resource']['url']

    return compare_domains([ckan_url, resource_url])


def get_preview_plugin(data_dict, return_first=False):
    '''Determines whether there is an extension that can preview the resource.

    :param data_dict: contains a resource and package dict.
        The resource dict has to have a value for ``on_same_domain``
    :type data_dict: dictionary

    :param return_first: If True return the first plugin that can preview
    :type return_first: bool

    Returns a dict of plugins that can preview or ones that are fixable'''

    data_dict['resource']['on_same_domain'] = _on_same_domain(data_dict)

    plugins_that_can_preview = []
    plugins_fixable = []
    for plugin in p.PluginImplementations(p.IResourcePreview):
        p_info = {'plugin': plugin, 'quality': 1}
        data = plugin.can_preview(data_dict)
        # old school plugins return true/False
        if isinstance(data, bool):
            p_info['can_preview'] = data
        else:
            # new school provide a dict
            p_info.update(data)
        # if we can preview
        if p_info['can_preview']:
            if return_first:
                plugin
            plugins_that_can_preview.append(p_info)
        elif p_info.get('fixable'):
            plugins_fixable.append(p_info)

    num_plugins = len(plugins_that_can_preview)
    if num_plugins == 0:
        # we didn't find any.  see if any could be made to work
        for plug in plugins_fixable:
            log.info('%s would allow previews to fix: %s' % (
                plug['plugin'], plug['fixable']))
        preview_plugin = None
    elif num_plugins == 1:
        # just one available
        preview_plugin = plugins_that_can_preview[0]['plugin']
    else:
        # multiple plugins so get the best one
        plugs = [pl['plugin'] for pl in plugins_that_can_preview]
        log.warn('Multiple previews are possible. {0}'.format(plugs))
        preview_plugin = max(plugins_that_can_preview,
                             key=lambda x: x['quality'])['plugin']
    return preview_plugin

########NEW FILE########
__FILENAME__ = model_dictize
import datetime
import urlparse

from pylons import config
from sqlalchemy.sql import select

import ckan.logic as logic
import ckan.plugins as plugins
import ckan.lib.helpers as h
import ckan.lib.dictization as d
import ckan.new_authz as new_authz
import ckan.lib.search as search
import ckan.lib.munge as munge

## package save

def group_list_dictize(obj_list, context,
                       sort_key=lambda x:x['display_name'], reverse=False,
                       with_package_counts=True):

    active = context.get('active', True)
    with_private = context.get('include_private_packages', False)

    if with_package_counts:
        query = search.PackageSearchQuery()
        q = {'q': '+capacity:public' if not with_private else '*:*',
             'fl': 'groups', 'facet.field': ['groups', 'owner_org'],
             'facet.limit': -1, 'rows': 1}
        query.run(q)

    result_list = []

    for obj in obj_list:
        if context.get('with_capacity'):
            obj, capacity = obj
            group_dict = d.table_dictize(obj, context, capacity=capacity)
        else:
            group_dict = d.table_dictize(obj, context)
        group_dict.pop('created')
        if active and obj.state not in ('active', 'pending'):
            continue

        group_dict['display_name'] = (group_dict.get('title') or
                                      group_dict.get('name'))

        image_url = group_dict.get('image_url')
        group_dict['image_display_url'] = image_url
        if image_url and not image_url.startswith('http'):
            #munge here should not have an effect only doing it incase
            #of potential vulnerability of dodgy api input
            image_url = munge.munge_filename(image_url)
            group_dict['image_display_url'] = h.url_for_static(
                'uploads/group/%s' % group_dict.get('image_url'),
                qualified=True
            )

        if with_package_counts:
            facets = query.facets
            if obj.is_organization:
                group_dict['packages'] = facets['owner_org'].get(obj.id, 0)
            else:
                group_dict['packages'] = facets['groups'].get(obj.name, 0)

        if context.get('for_view'):
            if group_dict['is_organization']:
                plugin = plugins.IOrganizationController
            else:
                plugin = plugins.IGroupController
            for item in plugins.PluginImplementations(plugin):
                group_dict = item.before_view(group_dict)

        result_list.append(group_dict)
    return sorted(result_list, key=sort_key, reverse=reverse)

def resource_list_dictize(res_list, context):

    active = context.get('active', True)
    result_list = []
    for res in res_list:
        resource_dict = resource_dictize(res, context)
        if active and res.state not in ('active', 'pending'):
            continue

        result_list.append(resource_dict)

    return sorted(result_list, key=lambda x: x["position"])

def related_list_dictize(related_list, context):
    result_list = []
    for res in related_list:
        related_dict = related_dictize(res, context)
        result_list.append(related_dict)
    if context.get('sorted'):
        return result_list
    return sorted(result_list, key=lambda x: x["created"], reverse=True)


def extras_dict_dictize(extras_dict, context):
    result_list = []
    for name, extra in extras_dict.iteritems():
        dictized = d.table_dictize(extra, context)
        if not extra.state == 'active':
            continue
        value = dictized["value"]
        result_list.append(dictized)

    return sorted(result_list, key=lambda x: x["key"])

def extras_list_dictize(extras_list, context):
    result_list = []
    active = context.get('active', True)
    for extra in extras_list:
        dictized = d.table_dictize(extra, context)
        if active and extra.state not in ('active', 'pending'):
            continue
        value = dictized["value"]
        result_list.append(dictized)

    return sorted(result_list, key=lambda x: x["key"])


def resource_dictize(res, context):
    model = context['model']
    resource = d.table_dictize(res, context)
    resource_group_id = resource['resource_group_id']
    extras = resource.pop("extras", None)
    if extras:
        resource.update(extras)
    # some urls do not have the protocol this adds http:// to these
    url = resource['url']
    ## for_edit is only called at the times when the dataset is to be edited
    ## in the frontend. Without for_edit the whole qualified url is returned.
    if resource.get('url_type') == 'upload' and not context.get('for_edit'):
        resource_group = model.Session.query(
            model.ResourceGroup).get(resource_group_id)
        last_part = url.split('/')[-1]
        cleaned_name = munge.munge_filename(last_part)
        resource['url'] = h.url_for(controller='package',
                                    action='resource_download',
                                    id=resource_group.package_id,
                                    resource_id=res.id,
                                    filename=cleaned_name,
                                    qualified=True)
    elif not urlparse.urlsplit(url).scheme and not context.get('for_edit'):
        resource['url'] = u'http://' + url.lstrip('/')
    return resource

def related_dictize(rel, context):
    return d.table_dictize(rel, context)

def _execute_with_revision(q, rev_table, context):
    '''
    Takes an SqlAlchemy query (q) that is (at its base) a Select on an
    object revision table (rev_table), and normally it filters to the
    'current' object revision (latest which has been moderated) and
    returns that.

    But you can provide revision_id, revision_date or pending in the
    context and it will filter to an earlier time or the latest unmoderated
    object revision.

    Raises NotFound if context['revision_id'] is provided, but the revision
    ID does not exist.

    Returns [] if there are no results.

    '''
    model = context['model']
    meta = model.meta
    session = model.Session
    revision_id = context.get('revision_id')
    revision_date = context.get('revision_date')
    pending = context.get('pending')

    if revision_id:
        revision = session.query(context['model'].Revision).filter_by(
            id=revision_id).first()
        if not revision:
            raise logic.NotFound
        revision_date = revision.timestamp

    if revision_date:
        q = q.where(rev_table.c.revision_timestamp <= revision_date)
        q = q.where(rev_table.c.expired_timestamp > revision_date)
    elif pending:
        q = q.where(rev_table.c.expired_timestamp == datetime.datetime(9999, 12, 31))
    else:
        q = q.where(rev_table.c.current == True)

    return session.execute(q)


def package_dictize(pkg, context):
    '''
    Given a Package object, returns an equivalent dictionary.

    Normally this is the current revision (most recent moderated version),
    but you can provide revision_id, revision_date or pending in the
    context and it will filter to an earlier time or the latest unmoderated
    object revision.

    May raise NotFound. TODO: understand what the specific set of
    circumstances are that cause this.
    '''
    model = context['model']
    #package
    package_rev = model.package_revision_table
    q = select([package_rev]).where(package_rev.c.id == pkg.id)
    result = _execute_with_revision(q, package_rev, context).first()
    if not result:
        raise logic.NotFound
    result_dict = d.table_dictize(result, context)
    #strip whitespace from title
    if result_dict.get('title'):
        result_dict['title'] = result_dict['title'].strip()
    #resources
    res_rev = model.resource_revision_table
    resource_group = model.resource_group_table
    q = select([res_rev], from_obj = res_rev.join(resource_group,
               resource_group.c.id == res_rev.c.resource_group_id))
    q = q.where(resource_group.c.package_id == pkg.id)
    result = _execute_with_revision(q, res_rev, context)
    result_dict["resources"] = resource_list_dictize(result, context)
    result_dict['num_resources'] = len(result_dict.get('resources', []))

    #tags
    tag_rev = model.package_tag_revision_table
    tag = model.tag_table
    q = select([tag, tag_rev.c.state, tag_rev.c.revision_timestamp],
        from_obj=tag_rev.join(tag, tag.c.id == tag_rev.c.tag_id)
        ).where(tag_rev.c.package_id == pkg.id)
    result = _execute_with_revision(q, tag_rev, context)
    result_dict["tags"] = d.obj_list_dictize(result, context, lambda x: x["name"])
    result_dict['num_tags'] = len(result_dict.get('tags', []))

    # Add display_names to tags. At first a tag's display_name is just the
    # same as its name, but the display_name might get changed later (e.g.
    # translated into another language by the multilingual extension).
    for tag in result_dict['tags']:
        assert not tag.has_key('display_name')
        tag['display_name'] = tag['name']

    #extras
    extra_rev = model.extra_revision_table
    q = select([extra_rev]).where(extra_rev.c.package_id == pkg.id)
    result = _execute_with_revision(q, extra_rev, context)
    result_dict["extras"] = extras_list_dictize(result, context)
    #groups
    member_rev = model.member_revision_table
    group = model.group_table
    q = select([group, member_rev.c.capacity],
               from_obj=member_rev.join(group, group.c.id == member_rev.c.group_id)
               ).where(member_rev.c.table_id == pkg.id)\
                .where(member_rev.c.state == 'active') \
                .where(group.c.is_organization == False)
    result = _execute_with_revision(q, member_rev, context)
    context['with_capacity'] = False
    ## no package counts as cannot fetch from search index at the same
    ## time as indexing to it.
    result_dict["groups"] = group_list_dictize(result, context,
                                               with_package_counts=False)
    #owning organization
    group_rev = model.group_revision_table
    q = select([group_rev]
               ).where(group_rev.c.id == pkg.owner_org) \
                .where(group_rev.c.state == 'active')
    result = _execute_with_revision(q, group_rev, context)
    organizations = d.obj_list_dictize(result, context)
    if organizations:
        result_dict["organization"] = organizations[0]
    else:
        result_dict["organization"] = None
    #relations
    rel_rev = model.package_relationship_revision_table
    q = select([rel_rev]).where(rel_rev.c.subject_package_id == pkg.id)
    result = _execute_with_revision(q, rel_rev, context)
    result_dict["relationships_as_subject"] = d.obj_list_dictize(result, context)
    q = select([rel_rev]).where(rel_rev.c.object_package_id == pkg.id)
    result = _execute_with_revision(q, rel_rev, context)
    result_dict["relationships_as_object"] = d.obj_list_dictize(result, context)

    # Extra properties from the domain object
    # We need an actual Package object for this, not a PackageRevision
    if isinstance(pkg, model.PackageRevision):
        pkg = model.Package.get(pkg.id)

    # isopen
    result_dict['isopen'] = pkg.isopen if isinstance(pkg.isopen,bool) else pkg.isopen()

    # type
    # if null assign the default value to make searching easier
    result_dict['type']= pkg.type or u'dataset'

    # license
    if pkg.license and pkg.license.url:
        result_dict['license_url']= pkg.license.url
        result_dict['license_title']= pkg.license.title.split('::')[-1]
    elif pkg.license:
        result_dict['license_title']= pkg.license.title
    else:
        result_dict['license_title']= pkg.license_id

    # creation and modification date
    result_dict['metadata_modified'] = pkg.metadata_modified.isoformat()
    result_dict['metadata_created'] = pkg.metadata_created.isoformat() \
        if pkg.metadata_created else None

    return result_dict

def _get_members(context, group, member_type):

    model = context['model']
    Entity = getattr(model, member_type[:-1].capitalize())
    q = model.Session.query(Entity, model.Member.capacity).\
               join(model.Member, model.Member.table_id == Entity.id).\
               filter(model.Member.group_id == group.id).\
               filter(model.Member.state == 'active').\
               filter(model.Member.table_name == member_type[:-1])
    if member_type == 'packages':
        q = q.filter(Entity.private==False)
    if 'limits' in context and member_type in context['limits']:
        return q[:context['limits'][member_type]]
    return q.all()


def group_dictize(group, context):
    result_dict = d.table_dictize(group, context)

    result_dict['display_name'] = group.display_name

    result_dict['extras'] = extras_dict_dictize(
        group._extras, context)

    include_datasets = context.get('include_datasets', True)

    q = {
        'facet': 'false',
        'rows': 0,
    }

    if group.is_organization:
        q['fq'] = 'owner_org:"{0}"'.format(group.id)
    else:
        q['fq'] = 'groups:"{0}"'.format(group.name)

    is_group_member = (context.get('user') and
         new_authz.has_user_permission_for_group_or_org(group.id, context.get('user'), 'read'))
    if is_group_member:
        context['ignore_capacity_check'] = True

    if include_datasets:
        q['rows'] = 1000    # Only the first 1000 datasets are returned

    context_ = dict((k, v) for (k, v) in context.items() if k != 'schema')
    search_results = logic.get_action('package_search')(context_, q)

    if include_datasets:
        result_dict['packages'] = search_results['results']

    result_dict['package_count'] = search_results['count']

    context['with_capacity'] = True
    result_dict['tags'] = tag_list_dictize(
        _get_members(context, group, 'tags'),
        context)

    result_dict['groups'] = group_list_dictize(
        _get_members(context, group, 'groups'),
        context)

    result_dict['users'] = user_list_dictize(
        _get_members(context, group, 'users'),
        context)

    context['with_capacity'] = False

    if context.get('for_view'):
        if result_dict['is_organization']:
            plugin = plugins.IOrganizationController
        else:
            plugin = plugins.IGroupController
        for item in plugins.PluginImplementations(plugin):
            result_dict = item.before_view(result_dict)

    image_url = result_dict.get('image_url')
    result_dict['image_display_url'] = image_url
    if image_url and not image_url.startswith('http'):
        #munge here should not have an effect only doing it incase
        #of potential vulnerability of dodgy api input
        image_url = munge.munge_filename(image_url)
        result_dict['image_display_url'] = h.url_for_static(
            'uploads/group/%s' % result_dict.get('image_url'),
            qualified = True
        )
    return result_dict

def tag_list_dictize(tag_list, context):

    result_list = []
    for tag in tag_list:
        if context.get('with_capacity'):
            tag, capacity = tag
            dictized = d.table_dictize(tag, context, capacity=capacity)
        else:
            dictized = d.table_dictize(tag, context)

        # Add display_names to tag dicts. At first a tag's display_name is just
        # the same as its name, but the display_name might get changed later
        # (e.g.  translated into another language by the multilingual
        # extension).
        assert not dictized.has_key('display_name')
        dictized['display_name'] = dictized['name']

        if context.get('for_view'):
            for item in plugins.PluginImplementations(
                    plugins.ITagController):
                dictized = item.before_view(dictized)

        result_list.append(dictized)

    return result_list

def tag_dictize(tag, context):
    tag_dict = d.table_dictize(tag, context)
    query = search.PackageSearchQuery()

    tag_query = u'+capacity:public '
    vocab_id = tag_dict.get('vocabulary_id')

    if vocab_id:
        model = context['model']
        vocab = model.Vocabulary.get(vocab_id)
        tag_query += u'+vocab_{0}:"{1}"'.format(vocab.name, tag.name)
    else:
        tag_query += u'+tags:"{0}"'.format(tag.name)

    q = {'q': tag_query, 'fl': 'data_dict', 'wt': 'json', 'rows': 1000}

    package_dicts = [h.json.loads(result['data_dict'])
                     for result in query.run(q)['results']]

    # Add display_names to tags. At first a tag's display_name is just the
    # same as its name, but the display_name might get changed later (e.g.
    # translated into another language by the multilingual extension).
    assert 'display_name' not in tag_dict
    tag_dict['display_name'] = tag_dict['name']

    if context.get('for_view'):
        for item in plugins.PluginImplementations(plugins.ITagController):
            tag_dict = item.before_view(tag_dict)

        tag_dict['packages'] = []
        for package_dict in package_dicts:
            for item in plugins.PluginImplementations(plugins.IPackageController):
                package_dict = item.before_view(package_dict)
            tag_dict['packages'].append(package_dict)
    else:
        tag_dict['packages'] = package_dicts

    return tag_dict

def user_list_dictize(obj_list, context,
                      sort_key=lambda x:x['name'], reverse=False):

    result_list = []

    for obj in obj_list:
        user_dict = user_dictize(obj, context)
        user_dict.pop('reset_key', None)
        user_dict.pop('apikey', None)
        user_dict.pop('email', None)
        result_list.append(user_dict)
    return sorted(result_list, key=sort_key, reverse=reverse)

def member_dictize(member, context):
    return d.table_dictize(member, context)

def user_dictize(user, context):

    if context.get('with_capacity'):
        user, capacity = user
        result_dict = d.table_dictize(user, context, capacity=capacity)
    else:
        result_dict = d.table_dictize(user, context)

    del result_dict['password']
    del result_dict['reset_key']

    result_dict['display_name'] = user.display_name
    result_dict['email_hash'] = user.email_hash
    result_dict['number_of_edits'] = user.number_of_edits()
    result_dict['number_administered_packages'] = user.number_administered_packages()

    requester = context.get('user')

    reset_key = result_dict.pop('reset_key', None)
    apikey = result_dict.pop('apikey', None)
    email = result_dict.pop('email', None)

    if context.get('keep_email', False):
        result_dict['email'] = email

    if context.get('keep_apikey', False):
        result_dict['apikey'] = apikey

    if requester == user.name:
        result_dict['apikey'] = apikey
        result_dict['email'] = email

    ## this should not really really be needed but tests need it
    if new_authz.is_sysadmin(requester):
        result_dict['apikey'] = apikey
        result_dict['email'] = email

    model = context['model']
    session = model.Session

    if context.get('with_related'):
        related_items = session.query(model.Related).\
                        filter(model.Related.owner_id==user.id).all()
        result_dict['related_items'] = related_list_dictize(related_items,
                                                            context)

    return result_dict

def task_status_dictize(task_status, context):
    return d.table_dictize(task_status, context)

## conversion to api

def group_to_api(group, context):
    api_version = context.get('api_version')
    assert api_version, 'No api_version supplied in context'
    dictized = group_dictize(group, context)
    dictized["extras"] = dict((extra["key"], extra["value"])
                              for extra in dictized["extras"])
    if api_version == 1:
        dictized["packages"] = sorted([pkg["name"] for pkg in dictized["packages"]])
    else:
        dictized["packages"] = sorted([pkg["id"] for pkg in dictized["packages"]])
    return dictized

def tag_to_api(tag, context):
    api_version = context.get('api_version')
    assert api_version, 'No api_version supplied in context'
    dictized = tag_dictize(tag, context)
    if api_version == 1:
        return sorted([package["name"] for package in dictized["packages"]])
    else:
        return sorted([package["id"] for package in dictized["packages"]])


def resource_dict_to_api(res_dict, package_id, context):
    res_dict.pop("revision_id")
    res_dict.pop("state")
    res_dict.pop("revision_timestamp")
    res_dict["package_id"] = package_id


def package_to_api(pkg, context):
    api_version = context.get('api_version')
    assert api_version, 'No api_version supplied in context'
    dictized = package_dictize(pkg, context)
    dictized.pop("revision_timestamp")

    dictized["tags"] = [tag["name"] for tag in dictized["tags"] \
                        if not tag.get('vocabulary_id')]
    dictized["extras"] = dict((extra["key"], extra["value"])
                              for extra in dictized["extras"])
    dictized['license'] = pkg.license.title if pkg.license else None
    dictized['ratings_average'] = pkg.get_average_rating()
    dictized['ratings_count'] = len(pkg.ratings)
    dictized['notes_rendered'] = h.render_markdown(pkg.notes)

    site_url = config.get('ckan.site_url', None)
    if site_url:
        dictized['ckan_url'] = '%s/dataset/%s' % (site_url, pkg.name)

    for resource in dictized["resources"]:
        resource_dict_to_api(resource, pkg.id, context)

    def make_api_1(package_id):
        return pkg.get(package_id).name

    def make_api_2(package_id):
        return package_id

    if api_version == 1:
        api_fn = make_api_1
        dictized["groups"] = [group["name"] for group in dictized["groups"]]
        # FIXME why is this just for version 1?
        if pkg.resources:
            dictized['download_url'] = pkg.resources[0].url
    else:
        api_fn = make_api_2
        dictized["groups"] = [group["id"] for group in dictized["groups"]]

    subjects = dictized.pop("relationships_as_subject")
    objects = dictized.pop("relationships_as_object")

    relationships = []
    for rel in objects:
        model = context['model']
        swap_types = model.PackageRelationship.forward_to_reverse_type
        type = swap_types(rel['type'])
        relationships.append({'subject': api_fn(rel['object_package_id']),
                              'type': type,
                              'object': api_fn(rel['subject_package_id']),
                              'comment': rel["comment"]})
    for rel in subjects:
        relationships.append({'subject': api_fn(rel['subject_package_id']),
                              'type': rel['type'],
                              'object': api_fn(rel['object_package_id']),
                              'comment': rel["comment"]})

    dictized['relationships'] = relationships

    return dictized

def vocabulary_dictize(vocabulary, context):
    vocabulary_dict = d.table_dictize(vocabulary, context)
    assert not vocabulary_dict.has_key('tags')
    vocabulary_dict['tags'] = [tag_dictize(tag, context) for tag
            in vocabulary.tags]
    return vocabulary_dict

def vocabulary_list_dictize(vocabulary_list, context):
    return [vocabulary_dictize(vocabulary, context)
            for vocabulary in vocabulary_list]

def activity_dictize(activity, context):
    activity_dict = d.table_dictize(activity, context)
    return activity_dict

def activity_list_dictize(activity_list, context):
    return [activity_dictize(activity, context) for activity in activity_list]

def activity_detail_dictize(activity_detail, context):
    return d.table_dictize(activity_detail, context)

def activity_detail_list_dictize(activity_detail_list, context):
    return [activity_detail_dictize(activity_detail, context)
            for activity_detail in activity_detail_list]


def package_to_api1(pkg, context):
    # DEPRICIATED set api_version in context and use package_to_api()
    context['api_version'] = 1
    return package_to_api(pkg, context)

def package_to_api2(pkg, context):
    # DEPRICIATED set api_version in context and use package_to_api()
    context['api_version'] = 2
    return package_to_api(pkg, context)

def group_to_api1(group, context):
    # DEPRICIATED set api_version in context and use group_to_api()
    context['api_version'] = 1
    return group_to_api(group, context)

def group_to_api2(group, context):
    # DEPRICIATED set api_version in context and use group_to_api()
    context['api_version'] = 2
    return group_to_api(group, context)

def tag_to_api1(tag, context):
    # DEPRICIATED set api_version in context and use tag_to_api()
    context['api_version'] = 1
    return tag_to_api(tag, context)

def tag_to_api2(tag, context):
    # DEPRICIATED set api_version in context and use tag_to_api()
    context['api_version'] = 2
    return tag_to_api(tag, context)

def user_following_user_dictize(follower, context):
    return d.table_dictize(follower, context)

def user_following_dataset_dictize(follower, context):
    return d.table_dictize(follower, context)

def user_following_group_dictize(follower, context):
    return d.table_dictize(follower, context)

    base_columns = set(['id', 'resource_id', 'title', 'description',
                        'view_type', 'order', 'config'])

########NEW FILE########
__FILENAME__ = model_save
import datetime
import uuid
import logging

from sqlalchemy.orm import class_mapper

import ckan.lib.dictization as d
import ckan.lib.helpers as h
import ckan.new_authz as new_authz

log = logging.getLogger(__name__)

def resource_dict_save(res_dict, context):
    model = context["model"]
    session = context["session"]

    id = res_dict.get("id")
    obj = None
    if id:
        obj = session.query(model.Resource).get(id)
    if not obj:
        new = True
        obj = model.Resource()
    else:
        new = False

    table = class_mapper(model.Resource).mapped_table
    fields = [field.name for field in table.c]

    for key, value in res_dict.iteritems():
        if isinstance(value, list):
            continue
        if key in ('extras', 'revision_timestamp', 'tracking_summary'):
            continue
        if key in fields:
            if isinstance(getattr(obj, key), datetime.datetime):
                if getattr(obj, key).isoformat() == value:
                    continue
            if key == 'url' and not new and obj.url <> value:
                obj.url_changed = True
            setattr(obj, key, value)
        else:
            # resources save extras directly onto the object, instead
            # of in a separate extras field like packages and groups
            obj.extras[key] = value

    # Resource extras not submitted should be removed from the extras dict
    extras_to_delete = set(obj.extras.keys()) - set(res_dict.keys())
    for delete_me in extras_to_delete:
        del obj.extras[delete_me]

    if context.get('pending'):
        if session.is_modified(obj, include_collections=False, passive=True):
            obj.state = u'pending'
    else:
        obj.state = u'active'

    session.add(obj)
    return obj

def package_resource_list_save(res_dicts, package, context):
    allow_partial_update = context.get("allow_partial_update", False)
    if res_dicts is None and allow_partial_update:
        return

    pending = context.get('pending')

    resource_list = package.resource_groups_all[0].resources_all
    old_list = package.resource_groups_all[0].resources_all[:]

    obj_list = []
    for res_dict in res_dicts or []:
        obj = resource_dict_save(res_dict, context)
        obj_list.append(obj)

    resource_list[:] = obj_list

    for resource in set(old_list) - set(obj_list):
        if pending and resource.state != 'deleted':
            resource.state = 'pending-deleted'
        else:
            resource.state = 'deleted'
        resource_list.append(resource)


def package_extras_save(extra_dicts, obj, context):
    allow_partial_update = context.get("allow_partial_update", False)
    if extra_dicts is None and allow_partial_update:
        return

    model = context["model"]
    session = context["session"]

    extras_list = obj.extras_list
    old_extras = dict((extra.key, extra) for extra in extras_list)

    new_extras = {}
    for extra_dict in extra_dicts or []:
        if extra_dict.get("deleted"):
            continue

        if extra_dict['value'] is None:
            pass
        else:
            new_extras[extra_dict["key"]] = extra_dict["value"]
    #new
    for key in set(new_extras.keys()) - set(old_extras.keys()):
        state = 'pending' if context.get('pending') else 'active'
        extra = model.PackageExtra(state=state, key=key, value=new_extras[key])
        session.add(extra)
        extras_list.append(extra)
    #changed
    for key in set(new_extras.keys()) & set(old_extras.keys()):
        extra = old_extras[key]
        #dont change state to pending if nothing has changed
        if new_extras[key] == extra.value and extra.state != 'deleted':
            continue
        state = 'pending' if context.get('pending') else 'active'
        extra.value = new_extras[key]
        extra.state = state
        session.add(extra)
    #deleted
    for key in set(old_extras.keys()) - set(new_extras.keys()):
        extra = old_extras[key]
        if extra.state == 'deleted':
            continue
        state = 'pending-deleted' if context.get('pending') else 'deleted'
        extra.state = state

def group_extras_save(extras_dicts, context):

    model = context["model"]
    session = context["session"]

    result_dict = {}
    for extra_dict in extras_dicts:
        if extra_dict.get("deleted"):
            continue
        result_dict[extra_dict["key"]] = extra_dict["value"]

    return result_dict

def package_tag_list_save(tag_dicts, package, context):
    allow_partial_update = context.get("allow_partial_update", False)
    if tag_dicts is None and allow_partial_update:
        return

    model = context["model"]
    session = context["session"]
    pending = context.get('pending')

    tag_package_tag = dict((package_tag.tag, package_tag)
                            for package_tag in
                            package.package_tag_all)

    tag_package_tag_inactive = dict(
        [ (tag,pt) for tag,pt in tag_package_tag.items() if
            pt.state in ['deleted', 'pending-deleted'] ]
        )

    tag_name_vocab = set()
    tags = set()
    for tag_dict in tag_dicts or []:
        if (tag_dict.get('name'), tag_dict.get('vocabulary_id')) not in tag_name_vocab:
            tag_obj = d.table_dict_save(tag_dict, model.Tag, context)
            tags.add(tag_obj)
            tag_name_vocab.add((tag_obj.name, tag_obj.vocabulary_id))

    # 3 cases
    # case 1: currently active but not in new list
    for tag in set(tag_package_tag.keys()) - tags:
        package_tag = tag_package_tag[tag]
        if pending and package_tag.state != 'deleted':
            package_tag.state = 'pending-deleted'
        else:
            package_tag.state = 'deleted'

    # case 2: in new list but never used before
    for tag in tags - set(tag_package_tag.keys()):
        state = 'pending' if pending else 'active'
        package_tag_obj = model.PackageTag(package, tag, state)
        session.add(package_tag_obj)
        tag_package_tag[tag] = package_tag_obj

    # case 3: in new list and already used but in deleted state
    for tag in tags.intersection(set(tag_package_tag_inactive.keys())):
        state = 'pending' if pending else 'active'
        package_tag = tag_package_tag[tag]
        package_tag.state = state

    package.package_tag_all[:] = tag_package_tag.values()

def package_membership_list_save(group_dicts, package, context):

    allow_partial_update = context.get("allow_partial_update", False)
    if group_dicts is None and allow_partial_update:
        return

    capacity = 'public'
    model = context["model"]
    session = context["session"]
    pending = context.get('pending')
    user = context.get('user')

    members = session.query(model.Member) \
            .filter(model.Member.table_id == package.id) \
            .filter(model.Member.capacity != 'organization')

    group_member = dict((member.group, member)
                         for member in
                         members)
    groups = set()
    for group_dict in group_dicts or []:
        id = group_dict.get("id")
        name = group_dict.get("name")
        capacity = group_dict.get("capacity", "public")
        if capacity == 'organization':
            continue
        if id:
            group = session.query(model.Group).get(id)
        else:
            group = session.query(model.Group).filter_by(name=name).first()
        if group:
            groups.add(group)

    ## need to flush so we can get out the package id
    model.Session.flush()

    # Remove any groups we are no longer in
    for group in set(group_member.keys()) - groups:
        member_obj = group_member[group]
        if member_obj and member_obj.state == 'deleted':
            continue
        if new_authz.has_user_permission_for_group_or_org(
                member_obj.group_id, user, 'read'):
            member_obj.capacity = capacity
            member_obj.state = 'deleted'
            session.add(member_obj)

    # Add any new groups
    for group in groups:
        member_obj = group_member.get(group)
        if member_obj and member_obj.state == 'active':
            continue
        if new_authz.has_user_permission_for_group_or_org(
                group.id, user, 'read'):
            member_obj = group_member.get(group)
            if member_obj:
                member_obj.capacity = capacity
                member_obj.state = 'active'
            else:
                member_obj = model.Member(table_id=package.id,
                                          table_name='package',
                                          group=group,
                                          capacity=capacity,
                                          group_id=group.id,
                                          state = 'active')
            session.add(member_obj)


def relationship_list_save(relationship_dicts, package, attr, context):

    allow_partial_update = context.get("allow_partial_update", False)
    if relationship_dicts is None and allow_partial_update:
        return

    model = context["model"]
    session = context["session"]
    pending = context.get('pending')

    relationship_list = getattr(package, attr)
    old_list = relationship_list[:]

    relationships = []
    for relationship_dict in relationship_dicts or []:
        obj = d.table_dict_save(relationship_dict,
                              model.PackageRelationship, context)
        relationships.append(obj)

    relationship_list[:] = relationships

    for relationship in set(old_list) - set(relationship_list):
        if pending and relationship.state <> 'deleted':
            relationship.state = 'pending-deleted'
        else:
            relationship.state = 'deleted'
        relationship_list.append(relationship)

def package_dict_save(pkg_dict, context):
    model = context["model"]
    package = context.get("package")
    allow_partial_update = context.get("allow_partial_update", False)
    if package:
        pkg_dict["id"] = package.id
    Package = model.Package

    if 'metadata_created' in pkg_dict:
        del pkg_dict['metadata_created']
    if 'metadata_modified' in pkg_dict:
        del pkg_dict['metadata_modified']

    pkg = d.table_dict_save(pkg_dict, Package, context)

    if not pkg.id:
        pkg.id = str(uuid.uuid4())

    package_resource_list_save(pkg_dict.get("resources"), pkg, context)
    package_tag_list_save(pkg_dict.get("tags"), pkg, context)
    package_membership_list_save(pkg_dict.get("groups"), pkg, context)

    # relationships are not considered 'part' of the package, so only
    # process this if the key is provided
    if 'relationships_as_subject' in pkg_dict:
        subjects = pkg_dict.get('relationships_as_subject')
        relationship_list_save(subjects, pkg, 'relationships_as_subject', context)
    if 'relationships_as_object' in pkg_dict:
        objects = pkg_dict.get('relationships_as_object')
        relationship_list_save(objects, pkg, 'relationships_as_object', context)

    extras = package_extras_save(pkg_dict.get("extras"), pkg, context)

    return pkg

def group_member_save(context, group_dict, member_table_name):
    model = context["model"]
    session = context["session"]
    group = context['group']
    entity_list = group_dict.get(member_table_name, None)

    if entity_list is None:
        if context.get('allow_partial_update', False):
            return {'added': [], 'removed': []}
        else:
            entity_list = []

    entities = {}
    Member = model.Member

    classname = member_table_name[:-1].capitalize()
    if classname == 'Organization':
        # Organizations use the model.Group class
        classname = 'Group'
    ModelClass = getattr(model, classname)

    for entity_dict in entity_list:
        name_or_id = entity_dict.get('id') or entity_dict.get('name')
        obj = ModelClass.get(name_or_id)
        if obj and obj not in entities.values():
            entities[(obj.id, entity_dict.get('capacity', 'public'))] = obj

    members = session.query(Member).filter_by(
        table_name=member_table_name[:-1],
        group_id=group.id,
    ).all()

    processed = {
        'added': [],
        'removed': []
    }

    entity_member = dict(((member.table_id, member.capacity), member) for member in members)
    for entity_id in set(entity_member.keys()) - set(entities.keys()):
        if entity_member[entity_id].state != 'deleted':
            processed['removed'].append(entity_id[0])
        entity_member[entity_id].state = 'deleted'
        session.add(entity_member[entity_id])

    for entity_id in set(entity_member.keys()) & set(entities.keys()):
        if entity_member[entity_id].state != 'active':
            processed['added'].append(entity_id[0])
        entity_member[entity_id].state = 'active'
        session.add(entity_member[entity_id])

    for entity_id in set(entities.keys()) - set(entity_member.keys()):
        member = Member(group=group, group_id=group.id, table_id=entity_id[0],
                        table_name=member_table_name[:-1],
                        capacity=entity_id[1])
        processed['added'].append(entity_id[0])
        session.add(member)

    return processed


def group_dict_save(group_dict, context, prevent_packages_update=False):
    from ckan.lib.search import rebuild

    model = context["model"]
    session = context["session"]
    group = context.get("group")
    allow_partial_update = context.get("allow_partial_update", False)

    Group = model.Group
    if group:
        group_dict["id"] = group.id

    group = d.table_dict_save(group_dict, Group, context)
    if not group.id:
        group.id = str(uuid.uuid4())

    context['group'] = group

    # Under the new org rules we do not want to be able to update datasets
    # via group edit so we need a way to prevent this.  It may be more
    # sensible in future to send a list of allowed/disallowed updates for
    # groups, users, tabs etc.
    if not prevent_packages_update:
        pkgs_edited = group_member_save(context, group_dict, 'packages')
    else:
        pkgs_edited = {
            'added': [],
            'removed': []
        }
    group_users_changed = group_member_save(context, group_dict, 'users')
    group_groups_changed = group_member_save(context, group_dict, 'groups')
    group_tags_changed = group_member_save(context, group_dict, 'tags')
    log.debug('Group save membership changes - Packages: %r  Users: %r  '
            'Groups: %r  Tags: %r', pkgs_edited, group_users_changed,
            group_groups_changed, group_tags_changed)

    extras = group_extras_save(group_dict.get("extras", {}), context)
    if extras or not allow_partial_update:
        old_extras = set(group.extras.keys())
        new_extras = set(extras.keys())
        for key in old_extras - new_extras:
            del group.extras[key]
        for key in new_extras:
            group.extras[key] = extras[key]

    # We will get a list of packages that we have either added or
    # removed from the group, and trigger a re-index.
    package_ids = pkgs_edited['removed']
    package_ids.extend( pkgs_edited['added'] )
    if package_ids:
        session.commit()
        map( rebuild, package_ids )

    return group


def user_dict_save(user_dict, context):

    model = context['model']
    session = context['session']
    user = context.get('user_obj')

    User = model.User
    if user:
        user_dict['id'] = user.id

    if 'password' in user_dict and not len(user_dict['password']):
        del user_dict['password']

    user = d.table_dict_save(user_dict, User, context)

    return user


def related_dict_save(related_dict, context):
    model = context['model']
    session = context['session']

    return d.table_dict_save(related_dict,model.Related, context)


def package_api_to_dict(api1_dict, context):

    package = context.get("package")
    api_version = context.get('api_version')
    assert api_version, 'No api_version supplied in context'

    dictized = {}

    for key, value in api1_dict.iteritems():
        new_value = value
        if key == 'tags':
            if isinstance(value, basestring):
                new_value = [{"name": item} for item in value.split()]
            else:
                new_value = [{"name": item} for item in value]
        if key == 'extras':
            updated_extras = {}
            if package:
                updated_extras.update(package.extras)
            updated_extras.update(value)

            new_value = []

            for extras_key, extras_value in updated_extras.iteritems():
                new_value.append({"key": extras_key,
                                  "value": extras_value})

        if key == 'groups' and len(value):
            if api_version == 1:
                new_value = [{'name': item} for item in value]
            else:
                new_value = [{'id': item} for item in value]

        dictized[key] = new_value

    download_url = dictized.pop('download_url', None)
    if download_url and not dictized.get('resources'):
        dictized["resources"] = [{'url': download_url}]

    download_url = dictized.pop('download_url', None)

    return dictized

def group_api_to_dict(api1_dict, context):

    dictized = {}

    for key, value in api1_dict.iteritems():
        new_value = value
        if key == 'packages':
            new_value = [{"id": item} for item in value]
        if key == 'extras':
            new_value = [{"key": extra_key, "value": value[extra_key]}
                         for extra_key in value]
        dictized[key] = new_value

    return dictized

def task_status_dict_save(task_status_dict, context):
    model = context["model"]
    task_status = context.get("task_status")
    allow_partial_update = context.get("allow_partial_update", False)
    if task_status:
        task_status_dict["id"] = task_status.id

    task_status = d.table_dict_save(task_status_dict, model.TaskStatus, context)
    return task_status

def activity_dict_save(activity_dict, context):

    model = context['model']
    session = context['session']
    user_id = activity_dict['user_id']
    object_id = activity_dict['object_id']
    revision_id = activity_dict['revision_id']
    activity_type = activity_dict['activity_type']
    if activity_dict.has_key('data'):
        data = activity_dict['data']
    else:
        data = None
    activity_obj = model.Activity(user_id, object_id, revision_id,
            activity_type, data)
    session.add(activity_obj)

    # TODO: Handle activity details.

    return activity_obj

def vocabulary_tag_list_save(new_tag_dicts, vocabulary_obj, context):
    model = context['model']
    session = context['session']

    # First delete any tags not in new_tag_dicts.
    for tag in vocabulary_obj.tags:
        if tag.name not in [t['name'] for t in new_tag_dicts]:
            tag.delete()
    # Now add any new tags.
    for tag_dict in new_tag_dicts:
        current_tag_names = [tag.name for tag in vocabulary_obj.tags]
        if tag_dict['name'] not in current_tag_names:
            # Make sure the tag belongs to this vocab..
            tag_dict['vocabulary_id'] = vocabulary_obj.id
            # then add it.
            tag_dict_save(tag_dict, {'model': model, 'session': session})

def vocabulary_dict_save(vocabulary_dict, context):
    model = context['model']
    session = context['session']
    vocabulary_name = vocabulary_dict['name']

    vocabulary_obj = model.Vocabulary(vocabulary_name)
    session.add(vocabulary_obj)

    if vocabulary_dict.has_key('tags'):
        vocabulary_tag_list_save(vocabulary_dict['tags'], vocabulary_obj,
            context)

    return vocabulary_obj

def vocabulary_dict_update(vocabulary_dict, context):

    model = context['model']
    session = context['session']

    vocabulary_obj = model.vocabulary.Vocabulary.get(vocabulary_dict['id'])

    if vocabulary_dict.has_key('name'):
        vocabulary_obj.name = vocabulary_dict['name']

    if vocabulary_dict.has_key('tags'):
        vocabulary_tag_list_save(vocabulary_dict['tags'], vocabulary_obj,
            context)

    return vocabulary_obj

def tag_dict_save(tag_dict, context):
    model = context['model']
    tag = context.get('tag')
    if tag:
        tag_dict['id'] = tag.id
    tag = d.table_dict_save(tag_dict, model.Tag, context)
    return tag

def follower_dict_save(data_dict, context, FollowerClass):
    model = context['model']
    session = context['session']
    follower_obj = FollowerClass(
            follower_id=model.User.get(context['user']).id,
            object_id=data_dict['id'])
    session.add(follower_obj)
    return follower_obj

########NEW FILE########
__FILENAME__ = dumper
import csv
import datetime
from sqlalchemy import orm

import ckan.model as model
import ckan.model
from ckan.common import json, OrderedDict

class SimpleDumper(object):
    '''Dumps just package data but including tags, groups, license text etc'''
    def dump(self, dump_file_obj, format='json', query=None):
        if query is None:
            query = model.Session.query(model.Package)
            active = model.State.ACTIVE
            query = query.filter_by(state=active)
        if format == 'csv':
            self.dump_csv(dump_file_obj, query)
        elif format == 'json':
            self.dump_json(dump_file_obj, query)
        else:
            raise Exception('Unknown format: %s' % format)

    def dump_csv(self, dump_file_obj, query):
        row_dicts = []
        for pkg in query:
            pkg_dict = pkg.as_dict()
            # flatten dict
            for name, value in pkg_dict.items()[:]:
                if isinstance(value, (list, tuple)):
                    if value and isinstance(value[0], dict) and name == 'resources':
                        for i, res in enumerate(value):
                            prefix = 'resource-%i' % i
                            pkg_dict[prefix + '-url'] = res['url']
                            pkg_dict[prefix + '-format'] = res['format']
                            pkg_dict[prefix + '-description'] = res['description']
                    else:
                        pkg_dict[name] = ' '.join(value)
                if isinstance(value, dict):
                    for name_, value_ in value.items():
                        pkg_dict[name_] = value_
                    del pkg_dict[name]
            row_dicts.append(pkg_dict)
        writer = CsvWriter(row_dicts)
        writer.save(dump_file_obj)

    def dump_json(self, dump_file_obj, query):
        pkgs = []
        for pkg in query:
            pkg_dict = pkg.as_dict()
            pkgs.append(pkg_dict)
        json.dump(pkgs, dump_file_obj, indent=4)

class Dumper(object):
    '''Dumps the database in same structure as it appears in the database'''
    model_classes = [
#        ckan.model.State,
        ckan.model.Revision,
        ckan.model.Package,
        ckan.model.Tag,
        ckan.model.PackageTag,
        ckan.model.PackageRevision,
        ckan.model.PackageTagRevision,
        ckan.model.Group,
        ckan.model.Member,
        ckan.model.PackageExtra,
        ]
    # TODO Bring this list of classes up to date. In the meantime,
    # disabling this functionality in cli.
    
    def get_table(self, model_class):
        table = orm.class_mapper(model_class).mapped_table
        return table

    def dump_json(self, dump_path, verbose=False, ):
        dump_struct = { 'version' : ckan.__version__ }

        if verbose:
            print "\n\nStarting...........................\n\n\n"

        for model_class in self.model_classes:
            table = self.get_table(model_class)
            model_class_name = model_class.__name__
            dump_struct[model_class_name] = {}
            if verbose:
                print model_class_name, '--------------------------------'
            q = table.select()
            for record in q.execute():
                if verbose:
                    print '--- ', 'id', record.id
                recorddict = self.cvt_record_to_dict(record, table)
                dump_struct[model_class_name][record.id] = recorddict
        if verbose:
            print '---------------------------------'
            print 'Dumping to %s' % dump_path
        json.dump(dump_struct, file(dump_path, 'w'), indent=4, sort_keys=True)

    def cvt_record_to_dict(self, record, table):
        out = {}
        for key in table.c.keys():
            val  = getattr(record, key)
            if isinstance(val, datetime.date):
                val = str(val)
            out[key] = val
            # print "--- ", modelAttrName, unicode(modelAttrValue).encode('ascii', 'ignore')
        return out

    def load_json(self, dump_path, verbose=False):
        dump_struct = json.load(open(dump_path))

        if verbose:
            print 'Building table...'
        # Protect against writing into created database.
        ckan.model.metadata.create_all()
        for model_class in self.model_classes:
            if model.Session.query(model_class).count():
                raise Exception, "Existing '%s' records in database" % model_class

        records = {}
        for model_class in self.model_classes:
            table = self.get_table(model_class)
            collection_objects = {}
            model_class_name = model_class.__name__
            records[model_class_name] = collection_objects
            if verbose:
                print model_class_name, '--------------------------------'
            collectionStruct = dump_struct[model_class_name]
            if verbose:
                print collectionStruct.keys()
            recordIds = collectionStruct.keys()
            recordIds.sort()
            for recordId in recordIds:
                record_struct = collectionStruct[recordId]
                record_struct = self.switch_names(record_struct)
                if verbose:
                    print record_struct
                q = table.insert(values=record_struct)
                result = q.execute()
        self.fix_sequences()
        if verbose:
            print 'OK'

    def switch_names(self, record_struct):
        '''Alter SQLObject and v0.6 names.

        Can be run safely on data post 0.6.
        '''
        out = {}
        for k,v in record_struct.items():
            # convert from v0.6 to v0.7
            k = k.replace('ID', '_id')
            if k == 'base_id':
                k = 'continuity_id'
            if k == 'log_message':
                k = 'message'
            # generic
            if v == 'None':
                v = None
            if '_id' in k and v is not None:
                v = int(v)
            out[k] = v
        return out

    def fix_sequences(self):
        for model_class in self.model_classes:
            if model_class == ckan.model.User: # ApiKey does not have idseq
                continue
            table = self.get_table(model_class)
            seqname = '%s_id_seq' % table.name 
            q = table.select()
            print model_class
            maxid = q.order_by(table.c.id.desc()).execute().fetchone().id
            print seqname, maxid+1
            sql = "SELECT setval('%s', %s);" % (seqname, maxid+1)
            engine = ckan.model.metadata.bind
            engine.execute(sql)

    def migrate_06_to_07(self):
        '''Fix up continuity objects and put names in revision objects.'''
        print 'Migrating 0.6 data to 0.7'
        pkg_table = self.get_table(ckan.model.Package)
        pkg_rev_table = self.get_table(ckan.model.PackageRevision)
        for record in pkg_table.select().execute():
            print 'Current:', record
            q = pkg_rev_table.select()
            q = q.where(pkg_rev_table.c.continuity_id==record.id)
            mostrecent = q.order_by(pkg_rev_table.c.revision_id.desc()).limit(1)
            pkg_rev_record = mostrecent.execute().fetchall()[0]
            print 'Object Revision:', pkg_rev_record
            newrecord = {}
            for k in [ 'download_url', 'license_id', 'notes', 'revision_id',
                    'state_id', 'title', 'url' ]:
                if k != 'id': 
                    newrecord[k] = getattr(pkg_rev_record, k)
            print 'New:', newrecord
            update = pkg_table.update(pkg_table.c.id==record.id, values=newrecord)
            update.execute()

            # now put names in package_revisions
            for rev in q.execute():
                update = pkg_rev_table.update(pkg_rev_table.c.id==rev.id,
                        values={'name': record.name})
                update.execute()

class CsvWriter:
    def __init__(self, package_dict_list=None):
        self._rows = []
        self._col_titles = []
        titles_set = set()
        for row_dict in package_dict_list:
            for key in row_dict.keys():
                if key not in self._col_titles:
                    self._col_titles.append(key)
        for row_dict in package_dict_list:
            self._add_row_dict(row_dict)
        
    def _add_row_dict(self, row_dict):
        row = []
        for title in self._col_titles:
            if row_dict.has_key(title):
                if isinstance(row_dict[title], int):
                    row.append(row_dict[title])
                elif isinstance(row_dict[title], unicode):
                    row.append(row_dict[title].encode('utf8'))
                else:
                    row.append(row_dict[title])
            else:
                row.append(None)
        self._rows.append(row)

    def save(self, file_obj):        
        writer = csv.writer(file_obj, quotechar='"', quoting=csv.QUOTE_NONNUMERIC)
        writer.writerow(self._col_titles)
        for row in self._rows:
            writer.writerow(row)

class PackagesXlWriter:
    def __init__(self, package_dict_list=None):
        import xlwt
        self._workbook = xlwt.Workbook(encoding='utf8')
        self._sheet = self._workbook.add_sheet('test')
        self._col_titles = {} # title:col_index
        self._row = 1
        self.add_col_titles(['name', 'title'])
        if package_dict_list:
            for row_dict in package_dict_list:
                self.add_row_dict(row_dict)
                self._row += 1

    def add_row_dict(self, row_dict):
        for key, value in row_dict.items():
            if value is not None:
                if key not in self._col_titles.keys():
                    self._add_col_title(key)
                col_index = self._col_titles[key]
                self._sheet.write(self._row, col_index, value)

    def get_serialized(self):
        strm = StringIO.StringIO()
        self._workbook.save(strm)
        workbook_serialized = strm.getvalue()
        strm.close()
        return workbook_serialized

    def save(self, filepath):
        self._workbook.save(filepath)

    def add_col_titles(self, titles):
        # use initially to specify the order of column titles
        for title in titles:
            self._add_col_title(title)
                    
    def _add_col_title(self, title):
        if self._col_titles.has_key(title):
            return
        col_index = len(self._col_titles)
        self._sheet.write(0, col_index, title)
        self._col_titles[title] = col_index

    @staticmethod
    def pkg_to_xl_dict(pkg):
        '''Convert a Package object to a dictionary suitable for XL format'''
        dict_ = pkg.as_dict()

        for key, value in dict_.items():
            # Not interested in dumping IDs - for internal use only really
            if (key.endswith('_id') or key == 'id'
                or key.startswith('rating')):
                del dict_[key]
            if key=='resources':
                for i, res in enumerate(value):
                    prefix = 'resource-%i' % i
                    keys = model.Resource.get_columns()
                    keys += [key_ for key_ in pkg.resources[i].extras.keys() if key_ not in keys]
                    for field in keys:
                        dict_['%s-%s' % (prefix, field)] = res[field]
                del dict_[key]
            elif isinstance(value, (list, tuple)):
                dict_[key] = ' '.join(value)
            elif key=='extras':
                for key_, value_ in value.items():
                    dict_[key_] = value_
                del dict_[key]
        return dict_

class UserDumper(object):
    def dump(self, dump_file_obj):
        query = model.Session.query(model.User)
        query = query.order_by(model.User.created.asc())

        columns = (('id', 'name', 'openid', 'fullname', 'email', 'created', 'about'))
        row_dicts = []
        for user in query:
            row = OrderedDict()
            for col in columns:
                value = getattr(user, col)
                if not value:
                    value = ''
                if col == 'created':
                    value = str(value) # or maybe dd/mm/yyyy?
                row[col] = value
            row_dicts.append(row)

        writer = CsvWriter(row_dicts)
        writer.save(dump_file_obj)
        dump_file_obj.close()

########NEW FILE########
__FILENAME__ = email_notifications
'''
Code for generating email notifications for users (e.g. email notifications for
new activities in your dashboard activity stream) and emailing them to the
users.

'''
import datetime
import re

import pylons

import ckan.model as model
import ckan.logic as logic
import ckan.lib.base as base

from ckan.common import ungettext


def string_to_timedelta(s):
    '''Parse a string s and return a standard datetime.timedelta object.

    Handles days, hours, minutes, seconds, and microseconds.

    Accepts strings in these formats:

    2 days
    14 days
    4:35:00 (hours, minutes and seconds)
    4:35:12.087465 (hours, minutes, seconds and microseconds)
    7 days, 3:23:34
    7 days, 3:23:34.087465
    .087465 (microseconds only)

    :raises ckan.logic.ValidationError: if the given string does not match any
        of the recognised formats

    '''
    patterns = []
    days_only_pattern = '(?P<days>\d+)\s+day(s)?'
    patterns.append(days_only_pattern)
    hms_only_pattern = '(?P<hours>\d?\d):(?P<minutes>\d\d):(?P<seconds>\d\d)'
    patterns.append(hms_only_pattern)
    ms_only_pattern = '.(?P<milliseconds>\d\d\d)(?P<microseconds>\d\d\d)'
    patterns.append(ms_only_pattern)
    hms_and_ms_pattern = hms_only_pattern + ms_only_pattern
    patterns.append(hms_and_ms_pattern)
    days_and_hms_pattern = '{0},\s+{1}'.format(days_only_pattern,
            hms_only_pattern)
    patterns.append(days_and_hms_pattern)
    days_and_hms_and_ms_pattern = days_and_hms_pattern + ms_only_pattern
    patterns.append(days_and_hms_and_ms_pattern)

    for pattern in patterns:
        match = re.match('^{0}$'.format(pattern), s)
        if match:
            break

    if not match:
        raise logic.ValidationError('Not a valid time: {0}'.format(s))

    gd = match.groupdict()
    days = int(gd.get('days', '0'))
    hours = int(gd.get('hours', '0'))
    minutes = int(gd.get('minutes', '0'))
    seconds = int(gd.get('seconds', '0'))
    milliseconds = int(gd.get('milliseconds', '0'))
    microseconds = int(gd.get('microseconds', '0'))
    delta = datetime.timedelta(days=days, hours=hours, minutes=minutes,
            seconds=seconds, milliseconds=milliseconds,
            microseconds=microseconds)
    return delta


def _notifications_for_activities(activities, user_dict):
    '''Return one or more email notifications covering the given activities.

    This function handles grouping multiple activities into a single digest
    email.

    :param activities: the activities to consider
    :type activities: list of activity dicts like those returned by
        ckan.logic.action.get.dashboard_activity_list()

    :returns: a list of email notifications
    :rtype: list of dicts each with keys 'subject' and 'body'

    '''
    if not activities:
        return []

    if not user_dict.get('activity_streams_email_notifications'):
        return []

    # We just group all activities into a single "new activity" email that
    # doesn't say anything about _what_ new activities they are.
    # TODO: Here we could generate some smarter content for the emails e.g.
    # say something about the contents of the activities, or single out
    # certain types of activity to be sent in their own individual emails,
    # etc.
    subject = ungettext(
        "1 new activity from {site_title}",
        "{n} new activities from {site_title}",
        len(activities)).format(
                site_title=pylons.config.get('ckan.site_title'),
                n=len(activities))
    body = base.render(
            'activity_streams/activity_stream_email_notifications.text',
            extra_vars={'activities': activities})
    notifications = [{
        'subject': subject,
        'body': body
        }]

    return notifications


def _notifications_from_dashboard_activity_list(user_dict, since):
    '''Return any email notifications from the given user's dashboard activity
    list since `since`.

    '''
    # Get the user's dashboard activity stream.
    context = {'model': model, 'session': model.Session,
            'user': user_dict['id']}
    activity_list = logic.get_action('dashboard_activity_list')(context, {})

    # Filter out the user's own activities., so they don't get an email every
    # time they themselves do something (we are not Trac).
    activity_list = [activity for activity in activity_list
            if activity['user_id'] != user_dict['id']]

    # Filter out the old activities.
    strptime = datetime.datetime.strptime
    fmt = '%Y-%m-%dT%H:%M:%S.%f'
    activity_list = [activity for activity in activity_list
            if strptime(activity['timestamp'], fmt) > since]

    return _notifications_for_activities(activity_list, user_dict)


# A list of functions that provide email notifications for users from different
# sources. Add to this list if you want to implement a new source of email
# notifications.
_notifications_functions = [
    _notifications_from_dashboard_activity_list,
    ]


def get_notifications(user_dict, since):
    '''Return any email notifications for the given user since `since`.

    For example email notifications about activity streams will be returned for
    any activities the occurred since `since`.

    :param user_dict: a dictionary representing the user, should contain 'id'
        and 'name'
    :type user_dict: dictionary

    :param since: datetime after which to return notifications from
    :rtype since: datetime.datetime

    :returns: a list of email notifications
    :rtype: list of dicts with keys 'subject' and 'body'

    '''
    notifications = []
    for function in _notifications_functions:
        notifications.extend(function(user_dict, since))
    return notifications


def send_notification(user, email_dict):
    '''Email `email_dict` to `user`.'''
    import ckan.lib.mailer

    if not user.get('email'):
        # FIXME: Raise an exception.
        return

    try:
        ckan.lib.mailer.mail_recipient(user['display_name'], user['email'],
                email_dict['subject'], email_dict['body'])
    except ckan.lib.mailer.MailerException:
        raise


def get_and_send_notifications_for_user(user):

    # Parse the email_notifications_since config setting, email notifications
    # from longer ago than this time will not be sent.
    email_notifications_since = pylons.config.get(
            'ckan.email_notifications_since', '2 days')
    email_notifications_since = string_to_timedelta(
            email_notifications_since)
    email_notifications_since = (datetime.datetime.now()
            - email_notifications_since)

    # FIXME: We are accessing model from lib here but I'm not sure what
    # else to do unless we add a get_email_last_sent() logic function which
    # would only be needed by this lib.
    email_last_sent = model.Dashboard.get(user['id']).email_last_sent
    activity_stream_last_viewed = (
            model.Dashboard.get(user['id']).activity_stream_last_viewed)

    since = max(email_notifications_since, email_last_sent,
            activity_stream_last_viewed)

    notifications = get_notifications(user, since)

    # TODO: Handle failures from send_email_notification.
    for notification in notifications:
        send_notification(user, notification)

    # FIXME: We are accessing model from lib here but I'm not sure what
    # else to do unless we add a update_email_last_sent()
    # logic function which would only be needed by this lib.
    dash = model.Dashboard.get(user['id'])
    dash.email_last_sent = datetime.datetime.now()
    model.repo.commit()


def get_and_send_notifications_for_all_users():
    context = {'model': model, 'session': model.Session, 'ignore_auth': True,
            'keep_email': True}
    users = logic.get_action('user_list')(context, {})
    for user in users:
        get_and_send_notifications_for_user(user)

########NEW FILE########
__FILENAME__ = extract
import re
from genshi.filters.i18n import extract as extract_genshi
from jinja2.ext import babel_extract as extract_jinja2
import lib.jinja_extensions

jinja_extensions = '''
                    jinja2.ext.do, jinja2.ext.with_,
                    ckan.lib.jinja_extensions.SnippetExtension,
                    ckan.lib.jinja_extensions.CkanExtend,
                    ckan.lib.jinja_extensions.LinkForExtension,
                    ckan.lib.jinja_extensions.ResourceExtension,
                    ckan.lib.jinja_extensions.UrlForStaticExtension,
                    ckan.lib.jinja_extensions.UrlForExtension
                   '''

def jinja2_cleaner(fileobj, *args, **kw):
    # We want to format the messages correctly and intercepting here seems
    # the best location
    # add our custom tags
    kw['options']['extensions'] = jinja_extensions

    raw_extract = extract_jinja2(fileobj, *args, **kw)

    for lineno, func, message, finder in raw_extract:

        if isinstance(message, basestring):
            message = lib.jinja_extensions.regularise_html(message)
        elif message is not None:
            message = (lib.jinja_extensions.regularise_html(message[0])
                       ,lib.jinja_extensions.regularise_html(message[1]))

        yield lineno, func, message, finder


def extract_ckan(fileobj, *args, **kw):
    ''' Determine the type of file (Genshi or Jinja2) and then call the
    correct extractor function.

    Basically we just look for genshi.edgewall.org which all genshi XML
    templates should contain. '''

    source = fileobj.read()
    if re.search('genshi\.edgewall\.org', source):
        # genshi
        output = extract_genshi(fileobj, *args, **kw)
    else:
        # jinja2
        output = jinja2_cleaner(fileobj, *args, **kw)
    # we've eaten the file so we need to get back to the start
    fileobj.seek(0)
    return output

########NEW FILE########
__FILENAME__ = fanstatic_extensions
import fanstatic.core as core


class CkanCustomRenderer(object):
    ''' Allows for in-line js and IE conditionals via fanstatic. '''
    def __init__(self, script=None, renderer=None, condition=None,
                 other_browsers=False):
        self.script = script
        self.other_browsers = other_browsers
        self.renderer = renderer
        start = ''
        end = ''
        # IE conditionals
        if condition:
            start = '<!--[if %s]>' % condition
            end = '<![endif]-->'
            if other_browsers:
                start += '<!-->'
                end = '<!--' + end
        self.start = start
        self.end = end

    def __call__(self, url):
        if self.script:
            return '%s<script>%s</script>%s' % (self.start,
                               self.script,
                               self.end)
        return '%s%s%s' % (self.start,
                           self.renderer(url),
                           self.end)


def render_js(url):
    return '<script src="%s"></script>' % (url,)

#    __  __             _                ____       _       _
#   |  \/  | ___  _ __ | | _____ _   _  |  _ \ __ _| |_ ___| |__
#   | |\/| |/ _ \| '_ \| |/ / _ \ | | | | |_) / _` | __/ __| '_ \
#   | |  | | (_) | | | |   <  __/ |_| | |  __/ (_| | || (__| | | |
#   |_|  |_|\___/|_| |_|_|\_\___|\__, | |_|   \__,_|\__\___|_| |_|
#                                |___/

def render(self, library_url):

    paths = [resource.relpath for resource in self._resources]

    # MONKEY PATCH
    # We have changed the relpath to just use the bundle path as we don't
    # care about the dir name of the resource as that is now part of the
    # resource name.  We need this so that we can actually get to all the
    # resources regardless of the actual directory they are in.

    # relpath = ''.join([self.dirname, BUNDLE_PREFIX, ';'.join(paths)])
    relpath = ''.join([core.BUNDLE_PREFIX, ';'.join(paths)])

    return self.renderer('%s/%s' % (library_url, relpath))

core.Bundle.render = render


def fits(self, resource):
    if resource.dont_bundle:
        return False
    # an empty resource fits anything
    if not self._resources:
        return True
    # a resource fits if it's like the resources already inside
    bundle_resource = self._resources[0]
    return (resource.library is bundle_resource.library and
            resource.renderer is bundle_resource.renderer and

            # MONKEY PATCH
            # We allow .js files to be bundled even if they are in different
            # directories as the directory location doesn't actually matter
            # to javascript files just css files.
            (resource.ext == '.js' or
             resource.dirname == bundle_resource.dirname))

core.Bundle.fits = fits


def sort_resources(resources):
    """Sort resources for inclusion on web page.

    A number of rules are followed:

    * resources are always grouped per renderer (.js, .css, etc)
    * resources that depend on other resources are sorted later
    * resources are grouped by library, if the dependencies allow it
    * libraries are sorted by name, if dependencies allow it
    * resources are sorted by resource path if they both would be
      sorted the same otherwise.

    The only purpose of sorting on library is so we can
    group resources per library, so that bundles can later be created
    of them if bundling support is enabled.

    Note this sorting algorithm guarantees a consistent ordering, no
    matter in what order resources were needed.
    """
    for resource in resources:
        resource.library.init_library_nr()

    def key(resource):
        return (
            resource.order,
            resource.library.library_nr,
            resource.library.name,
            resource.custom_order,  # Added in MONKEY PATCH
            resource.dependency_nr,
            resource.relpath)
    return sorted(resources, key=key)

core.sort_resources = sort_resources

########NEW FILE########
__FILENAME__ = fanstatic_resources
import os.path
import sys
import logging
import ConfigParser

from fanstatic import Library, Resource, Group, get_library_registry
import fanstatic.core as core

# This imports patches fanstatic
import ckan.lib.fanstatic_extensions as fanstatic_extensions

log = logging.getLogger(__name__)


def min_path(path):
    '''Return the .min.* filename for the given .js or .css file.

    For example moo.js -> moo.min.js

    '''
    path, ext = os.path.splitext(path)
    return path + '.min' + ext


def create_library(name, path, depend_base=True):
    ''' Creates a fanstatic library `name` with the contents of a
    directory `path` using resource.config if found.'''

    def get_resource(lib_name, resource_name):
        ''' Attempt to get the resource from the current lib or if not try
        assume it is a fully qualified resource name. '''
        try:
            res = getattr(module, '%s/%s' % (lib_name, resource_name))
        except AttributeError:
            res = getattr(module, '%s' % resource_name)
        return res

    def create_resource(path, lib_name, count, inline=False):
        ''' create the fanstatic Resource '''
        renderer = None
        kw = {}
        if not inline:
            # resource_name is name of the file without the .js/.css
            rel_path, filename = os.path.split(path)
            filename = os.path.join(rel_path, filename)
            path_min = min_path(os.path.join(resource_path, filename))
            if os.path.exists(path_min):
                kw['minified'] = min_path(filename)
            if filename.endswith('.js'):
                renderer = core.render_js
                if path not in force_top:
                    kw['bottom'] = True
            if filename.endswith('.css'):
                renderer = core.render_css
            core.set_resource_file_existence_checking(True)
        else:
            # This doesn't exist so stop fanstatic checking the filesystem
            if path not in force_top:
                kw['bottom'] = True
            core.set_resource_file_existence_checking(False)
        dependencies = []
        if path in depends:
            for dependency in depends[path]:
                dependencies.append(get_resource(name, dependency))
        if depend_base:
            dependencies.append(getattr(module, 'base/main'))
        if dependencies:
            kw['depends'] = dependencies
        if path in dont_bundle:
            kw['dont_bundle'] = True
        # IE conditionals
        condition = None
        other_browsers = False
        if path in IE_conditionals:
            other_browsers = ('others' in IE_conditionals[path])
            condition = IE_conditionals[path][0]
        if inline or condition:
            kw['renderer'] = fanstatic_extensions.CkanCustomRenderer(
                                        condition=condition,
                                        script=inline,
                                        renderer=renderer,
                                        other_browsers=other_browsers)
        resource = Resource(library, path, **kw)

        # Add our customised ordering
        if path in custom_render_order:
            resource.order = custom_render_order[path]
        resource.custom_order = count
        # Update the attributes of the minified version of the resource to
        # that of the parents as fanstatic does not pass these on.
        update_attributes = ['custom_order', 'order', 'bottom', 'depends',
                             'dont_bundle', 'renderer']
        if 'minified' in resource.modes:
            min_res = resource.modes['minified']
            for attribute in update_attributes:
                setattr(min_res, attribute, getattr(resource, attribute))

        # add the resource to this module
        fanstatic_name = '%s/%s' % (lib_name, path)
        log.debug('create resource %s' % fanstatic_name)
        setattr(module, fanstatic_name, resource)
        return resource

    resource_path = os.path.join(os.path.dirname(__file__), path)
    library = Library(name, path)
    module = sys.modules[__name__]

    # config options
    order = []
    dont_bundle = []
    force_top = []
    depends = {}
    groups = {}
    IE_conditionals = {}
    custom_render_order = {}
    inline_scripts = {}

    # parse the resource.config file if it exists
    config_path = os.path.join(resource_path, 'resource.config')
    if os.path.exists(config_path):
        config = ConfigParser.RawConfigParser()
        config.read(config_path)

        if config.has_option('main', 'order'):
            order = config.get('main', 'order').split()
        if config.has_option('main', 'dont_bundle'):
            dont_bundle = config.get('main', 'dont_bundle').split()
        if config.has_option('main', 'force_top'):
            force_top = config.get('main', 'force_top').split()

        if config.has_section('depends'):
            items = config.items('depends')
            depends = dict((n, v.split()) for (n, v) in items)
        if config.has_section('groups'):
            items = config.items('groups')
            groups = dict((n, v.split()) for (n, v) in items)
        if config.has_section('custom render order'):
            items = config.items('custom render order')
            custom_render_order = dict((n, int(v)) for (n, v) in items)
        if config.has_section('inline scripts'):
            items = config.items('inline scripts')
            inline_scripts = dict((n, v) for (n, v) in items)
        if config.has_section('IE conditional'):
            items = config.items('IE conditional')
            for (n, v) in items:
                files = v.split()
                for f in files:
                    if f not in IE_conditionals:
                        IE_conditionals[f] = []
                    IE_conditionals[f].append(n)

    # add dependencies for resources in groups
    for group in groups:
        if group in depends:
            for resource in groups[group]:
                if resource not in depends:
                    depends[resource] = []
                for dep in depends[group]:
                    if dep not in depends[resource]:
                        depends[resource].append(dep)

    # process each .js/.css file found
    resource_list = []
    for dirname, dirnames, filenames in os.walk(resource_path):
        for f in filenames:
            rel_path = dirname[len(path):]
            if rel_path:
                rel_path = rel_path[1:]
            filepath = os.path.join(rel_path, f)
            filename_only, extension = os.path.splitext(f)
            if extension in ('.css', '.js') and (
                not filename_only.endswith('.min')):
              resource_list.append(filepath)

    # if groups are defined make sure the order supplied there is honored
    for group in groups:
        for resource in groups[group]:
            if resource not in order:
                # make sure any dependencies are met when we get to creating
                # the resource
                if resource in depends:
                    for dep in depends[resource]:
                        if dep not in order:
                            order.append(dep)
                order.append(resource)

    # add inline scripts
    for inline in inline_scripts:
        resource_list.append(inline)
        if inline not in custom_render_order:
            custom_render_order[inline] = 20

    # order resource_list so that resources are created in the correct order
    for resource_name in reversed(order):
        if resource_name in resource_list:
            resource_list.remove(resource_name)
            resource_list.insert(0, resource_name)

    # create the resources and keep them ordered as we define them.
    count = 0
    for resource_name in resource_list:
        if resource_name in inline_scripts:
            inline = inline_scripts[resource_name].strip()
        else:
            inline = None
        create_resource(resource_name, name, count, inline=inline)
        count += 1

    # add groups
    for group_name in groups:
        members = []
        for member in groups[group_name]:
            fanstatic_name = '%s/%s' % (name, member)
            members.append(getattr(module, fanstatic_name))
        group = Group(members)
        fanstatic_name = '%s/%s' % (name, group_name)
        setattr(module, fanstatic_name, group)

    # finally add the library to this module
    setattr(module, name, library)
    # add to fanstatic
    registry = get_library_registry()
    registry.add(library)

base_path = os.path.abspath(os.path.join(os.path.dirname(__file__),
                                         '..', 'public', 'base'))

create_library('vendor', os.path.join(base_path, 'vendor'), depend_base=False)

create_library('base', os.path.join(base_path, 'javascript'),
               depend_base=False)

create_library('datapreview', os.path.join(base_path, 'datapreview'),
               depend_base=False)

create_library('css', os.path.join(base_path, 'css'), depend_base=False)

########NEW FILE########
__FILENAME__ = field_types
import re
import time
import datetime
import warnings

with warnings.catch_warnings():
    warnings.filterwarnings('ignore', '.*compile_mappers.*')
    import formalchemy

from ckan.common import OrderedDict

months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']

class DateConvertError(Exception):
    pass

class DateType(object):
    '''Utils for handling dates in forms.
    * Full or partial dates
    * User inputs in form DD/MM/YYYY and it is stored in db as YYYY-MM-DD.
    '''
    format_types = ('form', 'db')
    datetime_fields = OrderedDict([('year', (1000, 2100, 4, 'YYYY')),
                                   ('month', (1, 12, 2, 'MM')),
                                   ('day', (1, 31, 2, 'DD')),
                                   ('hour', (0, 23, 2, 'HH')),
                                   ('minute', (0, 59, 2, 'MM')),
                                   ])
    datetime_fields_indexes = {'min':0, 'max':1, 'digits':2, 'format_code':3}
    date_fields_order = {'db':('year', 'month', 'day'),
                         'form':('day', 'month', 'year')}
    parsing_separators = {'date':'-/',
                          'time':':\.'}
    default_separators = {'db':{'date':'-',
                                'time':':'},
                          'form':{'date':'/',
                                  'time':':'},}
    field_code_map = {'year':'YYYY', 'month':'MM', 'day':'DD',
                      'hour':'HH', 'minute':'MM'}
    word_match = re.compile('[A-Za-z]+')
    timezone_match = re.compile('(\s[A-Z]{3})|(\s[+-]\d\d:?\d\d)')
    months_abbreviated = [month[:3] for month in months]

    @classmethod
    def parse_timedate(cls, timedate_str, format_type):
        '''Takes a timedate and returns a dictionary of the fields.
        * Little validation is done.
        * If it can\'t understand the layout it raises DateConvertError
        '''
        assert format_type in cls.format_types
        if not hasattr(cls, 'matchers'):
            # build up a list of re matches for the different
            # acceptable ways of expressing the time and date
            cls.matchers = {}
            cls.readable_formats = {}
            for format_type_ in cls.format_types:
                finished_regexps = []
                readable_formats = [] # analogous to the regexps,
                                      # but human readable
                year_re = '(?P<%s>\d{2,4})'
                month_re = '(?P<%s>\w+)'
                two_digit_decimal_re = '(?P<%s>\d{1,2})'
                time_re = '%s[%s]%s' % (
                    two_digit_decimal_re % 'hour',
                    cls.parsing_separators['time'],
                    two_digit_decimal_re % 'minute')
                time_readable = '%s%s%s' % (
                    cls.datetime_fields['hour'][cls.datetime_fields_indexes['format_code']],
                    cls.default_separators[format_type_]['time'],
                    cls.datetime_fields['minute'][cls.datetime_fields_indexes['format_code']])
                date_field_re = {'year':year_re % 'year',
                                 'month':month_re % 'month',
                                 'day':two_digit_decimal_re % 'day'}
                date_fields = list(cls.date_fields_order[format_type_])
                for how_specific in ('day', 'month', 'year'):
                    date_sep_re = '[%s]' % cls.parsing_separators['date']
                    date_sep_readable = cls.default_separators[format_type_]['date']
                    date_field_regexps = [date_field_re[field] for field in date_fields]
                    date_field_readable = [cls.datetime_fields[field][cls.datetime_fields_indexes['format_code']] for field in date_fields]
                    date_re = date_sep_re.join(date_field_regexps)
                    date_readable = date_sep_readable.join(date_field_readable)
                    finished_regexps.append(date_re)
                    readable_formats.append(date_readable)
                    date_fields.remove(how_specific)
                full_date_re = finished_regexps[0]
                full_date_readable = readable_formats[0]
                # Allow time to be before or after the date
                for format_ in ('%(time_re)s%(sep)s%(full_date_re)s',
                                '%(full_date_re)s%(sep)s%(time_re)s'):
                    finished_regexps.insert(0, format_ % {
                        'time_re':time_re,
                        'sep':'\s',
                        'full_date_re':full_date_re})
                    readable_formats.insert(0, format_ % {
                        'time_re':time_readable,
                        'sep':' ',
                        'full_date_re':full_date_readable})
                cls.matchers[format_type_] = [re.compile('^%s$' % regexp) for regexp in finished_regexps]
                cls.readable_formats[format_type_] = readable_formats
                #print format_type_, finished_regexps, readable_formats
        for index, matcher in enumerate(cls.matchers[format_type]):
            match = matcher.match(timedate_str)
            if match:
                timedate_dict = match.groupdict()
                timedate_dict = cls.int_timedate(timedate_dict)
                timedate_dict['readable_format'] = cls.readable_formats[format_type][index]
                return timedate_dict
        else:
            acceptable_formats = ', '.join(["'%s'" % format_ for format_ in cls.readable_formats[format_type]])
            raise DateConvertError("Cannot parse %s date '%s'. Acceptable formats: %s" % (format_type, timedate_str, acceptable_formats))

    @classmethod
    def int_timedate(cls, timedate_dict):
        # Convert timedate string values to integers
        int_timedate_dict = timedate_dict.copy()
        for field in cls.datetime_fields.keys():
            if timedate_dict.has_key(field):
                val = timedate_dict[field]
                if field == 'year':
                    if len(val) == 2:
                        # Deal with 2 digit dates
                        try:
                            int_val = int(val)
                        except ValueError:
                            raise DateConvertError('Expecting integer for %s value: %s' % (field, val))
                        val = cls.add_centurys_to_two_digit_year(int_val)
                    elif len(val) == 3:
                        raise DateConvertError('Expecting 2 or 4 digit year: "%s"' % (val))
                if field == 'month':
                    # Deal with months expressed as words
                    if val in months:
                        val = months.index(val) + 1
                    if val in cls.months_abbreviated:
                        val = cls.months_abbreviated.index(val) + 1
                try:
                    int_timedate_dict[field] = int(val)
                except ValueError:
                    raise DateConvertError('Expecting integer for %s value: %s' % (field, val))
        return int_timedate_dict

    @classmethod
    def iso_to_db(cls, iso_date, format):
        # e.g. 'Wed, 06 Jan 2010 09:30:00'
        #      '%a, %d %b %Y %H:%M:%S'
        assert isinstance(iso_date, (unicode, str))
        try:
            date_tuple = time.strptime(iso_date, format)
        except ValueError, e:
            raise DateConvertError('Could not read date as ISO format "%s". Date provided: "%s"' % (format, iso_date))
        date_obj = datetime.datetime(*date_tuple[:4])
        date_str = cls.date_to_db(date_obj)
        return date_str

    @classmethod
    def strip_iso_timezone(cls, iso_date):
        return cls.timezone_match.sub('', iso_date)

    @classmethod
    def form_to_db(cls, form_str, may_except=True):
        '''
        27/2/2005 -> 2005-02-27
        27/Feb/2005 -> 2005-02-27
        2/2005 -> 2005-02
        Feb/2005 -> 2005-02
        2005 -> 2005
        '''
        try:
            # Allow blank input or None
            if not form_str:
                return u''
            form_str = form_str.strip()
            if not form_str:
                return u''

            # Parse form value
            timedate_dict = cls.parse_timedate(form_str, 'form')
                    
            # Check range of dates and format as standard string
            try:
                db_datetime = cls.format(timedate_dict, 'db')
            except DateConvertError, e:
                msg = 'Date error reading in format \'%s\': %s' % (timedate_dict['readable_format'], ' '.join(e.args))
                raise DateConvertError(msg)
            return db_datetime

        except DateConvertError, e:
            if may_except:
                raise e
            else:
                return form_str

    @classmethod
    def date_to_db(cls, date):
        '''
        datetime.date(2005, 2, 27) -> 2005-02-27
        '''
        assert isinstance(date, datetime.date)
        date_str = date.strftime('%Y-%m-%d')
        return date_str

    @classmethod
    def format(cls, datetime_dict, format_type):
        '''Takes datetime_dict and formats them either for
        the form or the database. If it encounters an out
        of range value, it raises an exception.
        '''
        assert isinstance(datetime_dict, dict)
        assert format_type in ('form', 'db')

        # convert each field to a string
        str_datetime_dict = {} # strings by field
        for field in cls.datetime_fields:
            if not datetime_dict.has_key(field):
                break
            val = datetime_dict[field]
            min_, max_ = cls.datetime_fields[field][cls.datetime_fields_indexes['min']:cls.datetime_fields_indexes['max'] + 1]
            if val < min_ or val > max_:
                raise DateConvertError('%s value of "%s" is out of range.' % (field.capitalize(), val))
            if format_type == 'form':
                int_format_string = '%d'
            elif format_type == 'db':
                num_digits = cls.datetime_fields['hour'][cls.datetime_fields_indexes['digits']]
                int_format_string = '%%0%sd' % num_digits                
            str_datetime_dict[field] = int_format_string % val

        # assemble the date
        date_fields = []
        for field in cls.date_fields_order[format_type]:
            if str_datetime_dict.has_key(field):
                date_fields.append(str_datetime_dict[field])
        formatted_datetime = unicode(cls.default_separators[format_type]['date'].join(date_fields))

        # add in the time if specified
        if str_datetime_dict.has_key('hour'):
            if format_type == 'form':
                datetime_format_string = '%(hour)s%(time_separator)s%(minute)s %(date)s'
            elif format_type == 'db':
                datetime_format_string = '%(date)s %(hour)s%(time_separator)s%(minute)s'
            format_dict = str_datetime_dict.copy()
            format_dict['date'] = formatted_datetime
            format_dict['time_separator'] = cls.default_separators[format_type]['time']
            formatted_datetime = datetime_format_string % format_dict
        return formatted_datetime

    @staticmethod
    def form_validator(form_date_str, field=None):
        try:
            DateType.form_to_db(form_date_str)
        except DateConvertError, e:
            raise formalchemy.ValidationError(e)

    @classmethod
    def db_to_form(cls, db_str):
        '2005-02-27 -> 27/2/2005 if correct format, otherwise, display as is.'
        db_str = db_str.strip()
        if not db_str:
            return db_str
        try:
            timedate_dict = cls.parse_timedate(db_str, 'db')
        except DateConvertError, e:
            # cannot parse - simply display as-is
            return db_str
        try:
            datetime_form = cls.format(timedate_dict, 'form')
        except DateConvertError, e:
            # values out of range - simply display as-is
            return db_str
        return datetime_form

    @classmethod
    def add_centurys_to_two_digit_year(cls, year, near_year=2010):
        assert isinstance(year, int)
        assert isinstance(near_year, int)
        assert year < 1000, repr(year)
        assert near_year > 1000 and near_year < 2200, repr(near_year)
        year += 1000
        while abs(year - near_year) > 50:
            year += 100
        return year

########NEW FILE########
__FILENAME__ = formatters
import datetime

from babel import numbers

import ckan.lib.i18n as i18n

from ckan.common import _, ungettext


##################################################
#                                                #
#              Month translations                #
#                                                #
##################################################

def _month_jan():
    return _('January')


def _month_feb():
    return _('February')


def _month_mar():
    return _('March')


def _month_apr():
    return _('April')


def _month_may():
    return _('May')


def _month_june():
    return _('June')


def _month_july():
    return _('July')


def _month_aug():
    return _('August')


def _month_sept():
    return _('September')


def _month_oct():
    return _('October')


def _month_nov():
    return _('November')


def _month_dec():
    return _('December')


# _MONTH_FUNCTIONS provides an easy way to get a localised month via
# _MONTH_FUNCTIONS[month]() where months are zero based ie jan = 0, dec = 11
_MONTH_FUNCTIONS = [_month_jan, _month_feb, _month_mar, _month_apr,
                   _month_may, _month_june, _month_july, _month_aug,
                   _month_sept, _month_oct, _month_nov, _month_dec]


def localised_nice_date(datetime_, show_date=False, with_hours=False):
    ''' Returns a friendly localised unicode representation of a datetime.

    :param datetime_: The date to format
    :type datetime_: datetime
    :param show_date: Show date not 2 days ago etc
    :type show_date: bool
    :param with_hours: should the `hours:mins` be shown for dates
    :type with_hours: bool

    :rtype: sting
    '''

    def months_between(date1, date2):
        if date1 > date2:
            date1, date2 = date2, date1
        m1 = date1.year * 12 + date1.month
        m2 = date2.year * 12 + date2.month
        months = m2 - m1
        if date1.day > date2.day:
            months -= 1
        elif date1.day == date2.day:
            seconds1 = date1.hour * 3600 + date1.minute + date1.second
            seconds2 = date2.hour * 3600 + date2.minute + date2.second
            if seconds1 > seconds2:
                months -= 1
        return months

    if not show_date:
        now = datetime.datetime.now()
        date_diff = now - datetime_
        days = date_diff.days
        if days < 1 and now > datetime_:
            # less than one day
            seconds = date_diff.seconds
            if seconds < 3600:
                # less than one hour
                if seconds < 60:
                    return _('Just now')
                else:
                    return ungettext('{mins} minute ago', '{mins} minutes ago',
                                     seconds / 60).format(mins=seconds / 60)
            else:
                return ungettext('{hours} hour ago', '{hours} hours ago',
                                 seconds / 3600).format(hours=seconds / 3600)
        # more than one day
        months = months_between(datetime_, now)

        if months < 1:
            return ungettext('{days} day ago', '{days} days ago',
                             days).format(days=days)
        if months < 13:
            return ungettext('{months} month ago', '{months} months ago',
                             months).format(months=months)
        return ungettext('over {years} year ago', 'over {years} years ago',
                         months / 12).format(years=months / 12)
    # actual date
    details = {
        'min': datetime_.minute,
        'hour': datetime_.hour,
        'day': datetime_.day,
        'year': datetime_.year,
        'month': _MONTH_FUNCTIONS[datetime_.month - 1](),
    }
    if with_hours:
        return (
            # NOTE: This is for translating dates like `April 24, 2013, 10:45`
            _('{month} {day}, {year}, {hour:02}:{min:02}').format(**details))
    else:
        return (
            # NOTE: This is for translating dates like `April 24, 2013`
            _('{month} {day}, {year}').format(**details))


def localised_number(number):
    ''' Returns a localised unicode representation of number '''
    return numbers.format_number(number, locale=i18n.get_lang())


def localised_filesize(number):
    ''' Returns a localised unicode representation of a number in bytes, MiB
    etc '''
    def rnd(number, divisor):
        # round to 1 decimal place
        return localised_number(float(number * 10 / divisor) / 10)

    if number < 1024:
        return _('{bytes} bytes').format(bytes=localised_number(number))
    elif number < 1024 ** 2:
        return _('{kibibytes} KiB').format(kibibytes=rnd(number, 1024))
    elif number < 1024 ** 3:
        return _('{mebibytes} MiB').format(mebibytes=rnd(number, 1024 ** 2))
    elif number < 1024 ** 4:
        return _('{gibibytes} GiB').format(gibibytes=rnd(number, 1024 ** 3))
    else:
        return _('{tebibytes} TiB').format(tebibytes=rnd(number, 1024 ** 4))


def localised_SI_number(number):
    ''' Returns a localised unicode representation of a number in SI format
    eg 14700 becomes 14.7k '''

    def rnd(number, divisor):
        # round to 1 decimal place
        return localised_number(float(number * 10 / divisor) / 10)

    if number < 1000:
        return _('{n}').format(n=localised_number(number))
    elif number < 1000 ** 2:
        return _('{k}k').format(k=rnd(number, 1000))
    elif number < 1000 ** 3:
        return _('{m}M').format(m=rnd(number, 1000 ** 2))
    elif number < 1000 ** 4:
        return _('{g}G').format(g=rnd(number, 1000 ** 3))
    elif number < 1000 ** 5:
        return _('{t}T').format(t=rnd(number, 1000 ** 4))
    elif number < 1000 ** 6:
        return _('{p}P').format(p=rnd(number, 1000 ** 5))
    elif number < 1000 ** 7:
        return _('{e}E').format(e=rnd(number, 1000 ** 6))
    elif number < 1000 ** 8:
        return _('{z}Z').format(z=rnd(number, 1000 ** 7))
    else:
        return _('{y}Y').format(y=rnd(number, 1000 ** 8))

########NEW FILE########
__FILENAME__ = hash
import hmac
import hashlib

from pylons import config, request

secret = None

def get_message_hash(value):
    global secret
    if not secret:
        # avoid getting config value at module scope since config may
        # not be read in yet
        secret = config['beaker.session.secret']
    return hmac.new(secret, value.encode('utf8'), hashlib.sha1).hexdigest()

def get_redirect():
    '''Checks the return_to value against the hash, and if it
    is valid then returns the return_to for redirect. Otherwise
    it returns None.'''
    return_to = request.params.get('return_to')
    hash_given = request.params.get('hash', '')
    if not (return_to and hash_given):
        return None
    hash_expected = get_message_hash(return_to)
    if hash_given == hash_expected:
        return return_to.encode('utf-8')
    return None

########NEW FILE########
__FILENAME__ = helpers
# coding=UTF-8

'''Helper functions

Consists of functions to typically be used within templates, but also
available to Controllers. This module is available to templates as 'h'.
'''
import email.utils
import datetime
import logging
import re
import os
import urllib
import urlparse
import pprint
import copy
import urlparse
from urllib import urlencode

from paste.deploy.converters import asbool
from webhelpers.html import escape, HTML, literal, url_escape
from webhelpers.html.tools import mail_to
from webhelpers.html.tags import *
from webhelpers.markdown import markdown
from webhelpers import paginate
from webhelpers.text import truncate
import webhelpers.date as date
from pylons import url as _pylons_default_url
from pylons.decorators.cache import beaker_cache
from pylons import config
from routes import redirect_to as _redirect_to
from routes import url_for as _routes_default_url_for
from alphabet_paginate import AlphaPage
import i18n
import ckan.exceptions

import ckan.lib.fanstatic_resources as fanstatic_resources
import ckan.model as model
import ckan.lib.formatters as formatters
import ckan.lib.maintain as maintain
import ckan.lib.datapreview as datapreview
import ckan.logic as logic
import ckan.lib.uploader as uploader
import ckan.new_authz as new_authz

from ckan.common import (
    _, ungettext, g, c, request, session, json, OrderedDict
)

get_available_locales = i18n.get_available_locales
get_locales_dict = i18n.get_locales_dict

log = logging.getLogger(__name__)


def _datestamp_to_datetime(datetime_):
    ''' Converts a datestamp to a datetime.  If a datetime is provided it
    just gets returned.

    :param datetime_: the timestamp
    :type datetime_: string or datetime

    :rtype: datetime
    '''
    if isinstance(datetime_, basestring):
        try:
            datetime_ = date_str_to_datetime(datetime_)
        except TypeError:
            return None
        except ValueError:
            return None
    # check we are now a datetime
    if not isinstance(datetime_, datetime.datetime):
        return None
    return datetime_


def redirect_to(*args, **kw):
    '''Issue a redirect: return an HTTP response with a ``302 Moved`` header.

    This is a wrapper for :py:func:`routes.redirect_to` that maintains the
    user's selected language when redirecting.

    The arguments to this function identify the route to redirect to, they're
    the same arguments as :py:func:`ckan.plugins.toolkit.url_for` accepts,
    for example::

        import ckan.plugins.toolkit as toolkit

        # Redirect to /dataset/my_dataset.
        toolkit.redirect_to(controller='package', action='read',
                            id='my_dataset')

    Or, using a named route::

        toolkit.redirect_to('dataset_read', id='changed')

    '''
    kw['__ckan_no_root'] = True
    if are_there_flash_messages():
        kw['__no_cache__'] = True
    return _redirect_to(url_for(*args, **kw))


def url(*args, **kw):
    '''Create url adding i18n information if selected
    wrapper for pylons.url'''
    locale = kw.pop('locale', None)
    my_url = _pylons_default_url(*args, **kw)
    return _add_i18n_to_url(my_url, locale=locale, **kw)


def url_for(*args, **kw):
    '''Return the URL for the given controller, action, id, etc.

    Usage::

        import ckan.plugins.toolkit as toolkit

        url = toolkit.url_for(controller='package', action='read',
                              id='my_dataset')
        => returns '/dataset/my_dataset'

    Or, using a named route::

        toolkit.url_for('dataset_read', id='changed')

    This is a wrapper for :py:func:`routes.url_for` that adds some extra
    features that CKAN needs.

    '''
    locale = kw.pop('locale', None)
    # remove __ckan_no_root and add after to not pollute url
    no_root = kw.pop('__ckan_no_root', False)
    # routes will get the wrong url for APIs if the ver is not provided
    if kw.get('controller') == 'api':
        ver = kw.get('ver')
        if not ver:
            raise Exception('api calls must specify the version! e.g. ver=3')
        # fix ver to include the slash
        kw['ver'] = '/%s' % ver
    my_url = _routes_default_url_for(*args, **kw)
    kw['__ckan_no_root'] = no_root
    return _add_i18n_to_url(my_url, locale=locale, **kw)


def url_for_static(*args, **kw):
    '''Returns the URL for static content that doesn't get translated (eg CSS)

    It'll raise CkanUrlException if called with an external URL

    This is a wrapper for :py:func:`routes.url_for`
    '''
    if args:
        url = urlparse.urlparse(args[0])
        url_is_external = (url.scheme != '' or url.netloc != '')
        if url_is_external:
            CkanUrlException = ckan.exceptions.CkanUrlException
            raise CkanUrlException('External URL passed to url_for_static()')
    return url_for_static_or_external(*args, **kw)


def url_for_static_or_external(*args, **kw):
    '''Returns the URL for static content that doesn't get translated (eg CSS),
    or external URLs

    This is a wrapper for :py:func:`routes.url_for`
    '''
    def fix_arg(arg):
        url = urlparse.urlparse(str(arg))
        url_is_relative = (url.scheme == '' and url.netloc == '' and
                           not url.path.startswith('/'))
        if url_is_relative:
            return '/' + url.geturl()
        return url.geturl()

    if args:
        args = (fix_arg(args[0]), ) + args[1:]
    my_url = _routes_default_url_for(*args, **kw)
    return my_url


def _add_i18n_to_url(url_to_amend, **kw):
    # If the locale keyword param is provided then the url is rewritten
    # using that locale .If return_to is provided this is used as the url
    # (as part of the language changing feature).
    # A locale of default will not add locale info to the url.

    default_locale = False
    locale = kw.pop('locale', None)
    no_root = kw.pop('__ckan_no_root', False)
    allowed_locales = ['default'] + i18n.get_locales()
    if locale and locale not in allowed_locales:
        locale = None
    if locale:
        if locale == 'default':
            default_locale = True
    else:
        try:
            locale = request.environ.get('CKAN_LANG')
            default_locale = request.environ.get('CKAN_LANG_IS_DEFAULT', True)
        except TypeError:
            default_locale = True
    try:
        root = request.environ.get('SCRIPT_NAME', '')
    except TypeError:
        root = ''
    if kw.get('qualified', False):
        # if qualified is given we want the full url ie http://...
        root = _routes_default_url_for('/', qualified=True)[:-1]
    # ckan.root_path is defined when we have none standard language
    # position in the url
    root_path = config.get('ckan.root_path', None)
    if root_path:
        # FIXME this can be written better once the merge
        # into the ecportal core is done - Toby
        # we have a special root specified so use that
        if default_locale:
            root = re.sub('/{{LANG}}', '', root_path)
        else:
            root = re.sub('{{LANG}}', locale, root_path)
        # make sure we don't have a trailing / on the root
        if root[-1] == '/':
            root = root[:-1]
        url = url_to_amend[len(re.sub('/{{LANG}}', '', root_path)):]
        url = '%s%s' % (root, url)
        root = re.sub('/{{LANG}}', '', root_path)
    else:
        if default_locale:
            url = url_to_amend
        else:
            # we need to strip the root from the url and the add it before
            # the language specification.
            url = url_to_amend[len(root):]
            url = '%s/%s%s' % (root, locale, url)

    # stop the root being added twice in redirects
    if no_root:
        url = url_to_amend[len(root):]
        if not default_locale:
            url = '/%s%s' % (locale, url)

    if url == '/packages':
        error = 'There is a broken url being created %s' % kw
        raise ckan.exceptions.CkanUrlException(error)

    return url


def url_is_local(url):
    '''Returns True if url is local'''
    if not url or url.startswith('//'):
        return False
    parsed = urlparse.urlparse(url)
    if parsed.scheme:
        domain = urlparse.urlparse(url_for('/', qualified=True)).netloc
        if domain != parsed.netloc:
            return False
    return True


def full_current_url():
    ''' Returns the fully qualified current url (eg http://...) useful
    for sharing etc '''
    return (url_for(request.environ['CKAN_CURRENT_URL'], qualified=True))


def lang():
    ''' Return the language code for the current locale eg `en` '''
    return request.environ.get('CKAN_LANG')


def lang_native_name(lang=None):
    ''' Return the langage name currently used in it's localised form
        either from parameter or current environ setting'''
    lang = lang or lang()
    locale = get_locales_dict().get(lang)
    if locale:
        return locale.display_name or locale.english_name
    return lang


class Message(object):
    '''A message returned by ``Flash.pop_messages()``.

    Converting the message to a string returns the message text. Instances
    also have the following attributes:

    * ``message``: the message text.
    * ``category``: the category specified when the message was created.
    '''

    def __init__(self, category, message, allow_html):
        self.category = category
        self.message = message
        self.allow_html = allow_html

    def __str__(self):
        return self.message

    __unicode__ = __str__

    def __html__(self):
        if self.allow_html:
            return self.message
        else:
            return escape(self.message)


class _Flash(object):

    # List of allowed categories.  If None, allow any category.
    categories = ["", "alert-info", "alert-error", "alert-success"]

    # Default category if none is specified.
    default_category = ""

    def __init__(self, session_key="flash", categories=None,
                 default_category=None):
        self.session_key = session_key
        if categories is not None:
            self.categories = categories
        if default_category is not None:
            self.default_category = default_category
        if self.categories and self.default_category not in self.categories:
            raise ValueError("unrecognized default category %r"
                             % (self.default_category, ))

    def __call__(self, message, category=None, ignore_duplicate=False,
                 allow_html=False):
        if not category:
            category = self.default_category
        elif self.categories and category not in self.categories:
            raise ValueError("unrecognized category %r" % (category, ))
        # Don't store Message objects in the session, to avoid unpickling
        # errors in edge cases.
        new_message_tuple = (category, message, allow_html)
        messages = session.setdefault(self.session_key, [])
        # ``messages`` is a mutable list, so changes to the local variable are
        # reflected in the session.
        if ignore_duplicate:
            for i, m in enumerate(messages):
                if m[1] == message:
                    if m[0] != category:
                        messages[i] = new_message_tuple
                        session.save()
                    return  # Original message found, so exit early.
        messages.append(new_message_tuple)
        session.save()

    def pop_messages(self):
        messages = session.pop(self.session_key, [])
        # only save session if it has changed
        if messages:
            session.save()
        return [Message(*m) for m in messages]

    def are_there_messages(self):
        return bool(session.get(self.session_key))

flash = _Flash()
# this is here for backwards compatability
_flash = flash


def flash_notice(message, allow_html=False):
    ''' Show a flash message of type notice '''
    flash(message, category='alert-info', allow_html=allow_html)


def flash_error(message, allow_html=False):
    ''' Show a flash message of type error '''
    flash(message, category='alert-error', allow_html=allow_html)


def flash_success(message, allow_html=False):
    ''' Show a flash message of type success '''
    flash(message, category='alert-success', allow_html=allow_html)


def are_there_flash_messages():
    ''' Returns True if there are flash messages for the current user '''
    return flash.are_there_messages()


def _link_active(kwargs):
    ''' creates classes for the link_to calls '''
    highlight_actions = kwargs.get('highlight_actions',
                                   kwargs.get('action', '')).split(' ')
    return (c.controller == kwargs.get('controller')
            and c.action in highlight_actions)


def _link_to(text, *args, **kwargs):
    '''Common link making code for several helper functions'''
    assert len(args) < 2, 'Too many unnamed arguments'

    def _link_class(kwargs):
        ''' creates classes for the link_to calls '''
        suppress_active_class = kwargs.pop('suppress_active_class', False)
        if not suppress_active_class and _link_active(kwargs):
            active = ' active'
        else:
            active = ''
        kwargs.pop('highlight_actions', '')
        return kwargs.pop('class_', '') + active or None

    def _create_link_text(text, **kwargs):
        ''' Update link text to add a icon or span if specified in the
        kwargs '''
        if kwargs.pop('inner_span', None):
            text = literal('<span>') + text + literal('</span>')
        if icon:
            text = literal('<i class="icon-%s"></i> ' % icon) + text
        return text

    icon = kwargs.pop('icon', None)
    class_ = _link_class(kwargs)
    return link_to(
        _create_link_text(text, **kwargs),
        url_for(*args, **kwargs),
        class_=class_
    )


def nav_link(text, *args, **kwargs):
    '''
    :param class_: pass extra class(es) to add to the ``<a>`` tag
    :param icon: name of ckan icon to use within the link
    :param condition: if ``False`` then no link is returned

    '''
    if len(args) > 1:
        raise Exception('Too many unnamed parameters supplied')
    if args:
        kwargs['controller'] = controller
        log.warning('h.nav_link() please supply controller as a named '
                    'parameter not a positional one')
    named_route = kwargs.pop('named_route', '')
    if kwargs.pop('condition', True):
        if named_route:
            link = _link_to(text, named_route, **kwargs)
        else:
            link = _link_to(text, **kwargs)
    else:
        link = ''
    return link


@maintain.deprecated('h.nav_named_link is deprecated please '
                     'use h.nav_link\nNOTE: you will need to pass the '
                     'route_name as a named parameter')
def nav_named_link(text, named_route, **kwargs):
    '''Create a link for a named route.
    Deprecated in ckan 2.0 '''
    return nav_link(text, named_route=named_route, **kwargs)


@maintain.deprecated('h.subnav_link is deprecated please '
                     'use h.nav_link\nNOTE: if action is passed as the second '
                     'parameter make sure it is passed as a named parameter '
                     'eg. `action=\'my_action\'')
def subnav_link(text, action, **kwargs):
    '''Create a link for a named route.
    Deprecated in ckan 2.0 '''
    kwargs['action'] = action
    return nav_link(text, **kwargs)


@maintain.deprecated('h.subnav_named_route is deprecated please '
                     'use h.nav_link\nNOTE: you will need to pass the '
                     'route_name as a named parameter')
def subnav_named_route(text, named_route, **kwargs):
    '''Generate a subnav element based on a named route
    Deprecated in ckan 2.0 '''
    return nav_link(text, named_route=named_route, **kwargs)


def build_nav_main(*args):
    ''' build a set of menu items.

    args: tuples of (menu type, title) eg ('login', _('Login'))
    outputs <li><a href="...">title</a></li>
    '''
    output = ''
    for item in args:
        menu_item, title = item[:2]
        if len(item) == 3 and not check_access(item[2]):
            continue
        output += _make_menu_item(menu_item, title)
    return output


def build_nav_icon(menu_item, title, **kw):
    '''Build a navigation item used for example in ``user/read_base.html``.

    Outputs ``<li><a href="..."><i class="icon.."></i> title</a></li>``.

    :param menu_item: the name of the defined menu item defined in
      config/routing as the named route of the same name
    :type menu_item: string
    :param title: text used for the link
    :type title: string
    :param kw: additional keywords needed for creating url eg ``id=...``

    :rtype: HTML literal

    '''
    return _make_menu_item(menu_item, title, **kw)


def build_nav(menu_item, title, **kw):
    '''Build a navigation item used for example breadcrumbs.

    Outputs ``<li><a href="..."></i> title</a></li>``.

    :param menu_item: the name of the defined menu item defined in
      config/routing as the named route of the same name
    :type menu_item: string
    :param title: text used for the link
    :type title: string
    :param  kw: additional keywords needed for creating url eg ``id=...``

    :rtype: HTML literal

    '''
    return _make_menu_item(menu_item, title, icon=None, **kw)


def _make_menu_item(menu_item, title, **kw):
    ''' build a navigation item used for example breadcrumbs

    outputs <li><a href="..."></i> title</a></li>

    :param menu_item: the name of the defined menu item defined in
    config/routing as the named route of the same name
    :type menu_item: string
    :param title: text used for the link
    :type title: string
    :param **kw: additional keywords needed for creating url eg id=...

    :rtype: HTML literal

    This function is called by wrapper functions.
    '''
    _menu_items = config['routes.named_routes']
    if menu_item not in _menu_items:
        raise Exception('menu item `%s` cannot be found' % menu_item)
    item = copy.copy(_menu_items[menu_item])
    item.update(kw)
    active = _link_active(item)
    needed = item.pop('needed')
    for need in needed:
        if need not in kw:
            raise Exception('menu item `%s` need parameter `%s`'
                            % (menu_item, need))
    link = _link_to(title, menu_item, suppress_active_class=True, **item)
    if active:
        return literal('<li class="active">') + link + literal('</li>')
    return literal('<li>') + link + literal('</li>')


def default_group_type():
    return str(config.get('ckan.default.group_type', 'group'))


def get_facet_items_dict(facet, limit=None, exclude_active=False):
    '''Return the list of unselected facet items for the given facet, sorted
    by count.

    Returns the list of unselected facet contraints or facet items (e.g. tag
    names like "russian" or "tolstoy") for the given search facet (e.g.
    "tags"), sorted by facet item count (i.e. the number of search results that
    match each facet item).

    Reads the complete list of facet items for the given facet from
    c.search_facets, and filters out the facet items that the user has already
    selected.

    Arguments:
    facet -- the name of the facet to filter.
    limit -- the max. number of facet items to return.
    exclude_active -- only return unselected facets.

    '''
    if not c.search_facets or \
            not c.search_facets.get(facet) or \
            not c.search_facets.get(facet).get('items'):
        return []
    facets = []
    for facet_item in c.search_facets.get(facet)['items']:
        if not len(facet_item['name'].strip()):
            continue
        if not (facet, facet_item['name']) in request.params.items():
            facets.append(dict(active=False, **facet_item))
        elif not exclude_active:
            facets.append(dict(active=True, **facet_item))
    facets = sorted(facets, key=lambda item: item['count'], reverse=True)
    if c.search_facets_limits and limit is None:
        limit = c.search_facets_limits.get(facet)
    if limit is not None:
        return facets[:limit]
    return facets


def has_more_facets(facet, limit=None, exclude_active=False):
    '''
    Returns True if there are more facet items for the given facet than the
    limit.

    Reads the complete list of facet items for the given facet from
    c.search_facets, and filters out the facet items that the user has already
    selected.

    Arguments:
    facet -- the name of the facet to filter.
    limit -- the max. number of facet items.
    exclude_active -- only return unselected facets.

    '''
    facets = []
    for facet_item in c.search_facets.get(facet)['items']:
        if not len(facet_item['name'].strip()):
            continue
        if not (facet, facet_item['name']) in request.params.items():
            facets.append(dict(active=False, **facet_item))
        elif not exclude_active:
            facets.append(dict(active=True, **facet_item))
    if c.search_facets_limits and limit is None:
        limit = c.search_facets_limits.get(facet)
    if limit is not None and len(facets) > limit:
        return True
    return False


def unselected_facet_items(facet, limit=10):
    '''Return the list of unselected facet items for the given facet, sorted
    by count.

    Returns the list of unselected facet contraints or facet items (e.g. tag
    names like "russian" or "tolstoy") for the given search facet (e.g.
    "tags"), sorted by facet item count (i.e. the number of search results that
    match each facet item).

    Reads the complete list of facet items for the given facet from
    c.search_facets, and filters out the facet items that the user has already
    selected.

    Arguments:
    facet -- the name of the facet to filter.
    limit -- the max. number of facet items to return.

    '''
    return get_facet_items_dict(facet, limit=limit, exclude_active=True)


@maintain.deprecated('h.get_facet_title is deprecated in 2.0 and will be removed.')
def get_facet_title(name):
    '''Deprecated in ckan 2.0 '''
    # if this is set in the config use this
    config_title = config.get('search.facets.%s.title' % name)
    if config_title:
        return config_title

    facet_titles = {'organization': _('Organizations'),
                    'groups': _('Groups'),
                    'tags': _('Tags'),
                    'res_format': _('Formats'),
                    'license': _('Licenses'), }
    return facet_titles.get(name, name.capitalize())


def get_param_int(name, default=10):
    try:
        return int(request.params.get(name, default))
    except ValueError:
        return default


def _url_with_params(url, params):
    if not params:
        return url
    params = [(k, v.encode('utf-8') if isinstance(v, basestring) else str(v))
              for k, v in params]
    return url + u'?' + urlencode(params)


def _search_url(params):
    url = url_for(controller='package', action='search')
    return _url_with_params(url, params)


def sorted_extras(package_extras, auto_clean=False, subs=None, exclude=None):
    ''' Used for outputting package extras

    :param package_extras: the package extras
    :type package_extras: dict
    :param auto_clean: If true capitalize and replace -_ with spaces
    :type auto_clean: bool
    :param subs: substitutes to use instead of given keys
    :type subs: dict {'key': 'replacement'}
    :param exclude: keys to exclude
    :type exclude: list of strings
    '''

    # If exclude is not supplied use values defined in the config
    if not exclude:
        exclude = g.package_hide_extras
    output = []
    for extra in sorted(package_extras, key=lambda x: x['key']):
        if extra.get('state') == 'deleted':
            continue
        k, v = extra['key'], extra['value']
        if k in exclude:
            continue
        if subs and k in subs:
            k = subs[k]
        elif auto_clean:
            k = k.replace('_', ' ').replace('-', ' ').title()
        if isinstance(v, (list, tuple)):
            v = ", ".join(map(unicode, v))
        output.append((k, v))
    return output


def check_access(action, data_dict=None):
    context = {'model': model,
               'user': c.user or c.author}
    if not data_dict:
        data_dict = {}
    try:
        logic.check_access(action, context, data_dict)
        authorized = True
    except logic.NotAuthorized:
        authorized = False

    return authorized


def get_action(action_name, data_dict=None):
    '''Calls an action function from a template.'''
    if data_dict is None:
        data_dict = {}
    return logic.get_action(action_name)({}, data_dict)


def linked_user(user, maxlength=0, avatar=20):
    if user in [model.PSEUDO_USER__LOGGED_IN, model.PSEUDO_USER__VISITOR]:
        return user
    if not isinstance(user, model.User):
        user_name = unicode(user)
        user = model.User.get(user_name)
        if not user:
            return user_name
    if user:
        name = user.name if model.User.VALID_NAME.match(user.name) else user.id
        icon = gravatar(email_hash=user.email_hash, size=avatar)
        displayname = user.display_name
        if maxlength and len(user.display_name) > maxlength:
            displayname = displayname[:maxlength] + '...'
        return icon + u' ' + link_to(displayname,
                                     url_for(controller='user', action='read', id=name))


def group_name_to_title(name):
    group = model.Group.by_name(name)
    if group is not None:
        return group.display_name
    return name


def markdown_extract(text, extract_length=190):
    ''' return the plain text representation of markdown encoded text.  That
    is the texted without any html tags.  If extract_length is 0 then it
    will not be truncated.'''
    if (text is None) or (text.strip() == ''):
        return ''
    plain = RE_MD_HTML_TAGS.sub('', markdown(text))
    if not extract_length or len(plain) < extract_length:
        return literal(plain)
    return literal(unicode(truncate(plain, length=extract_length, indicator='...', whole_word=True)))


def icon_url(name):
    return url_for_static('/images/icons/%s.png' % name)


def icon_html(url, alt=None, inline=True):
    classes = ''
    if inline:
        classes += 'inline-icon '
    return literal(('<img src="%s" height="16px" width="16px" alt="%s" ' +
                    'class="%s" /> ') % (url, alt, classes))


def icon(name, alt=None, inline=True):
    return icon_html(icon_url(name), alt, inline)


def resource_icon(res):
    if False:
        icon_name = 'page_white'
        # if (res.is_404?): icon_name = 'page_white_error'
        # also: 'page_white_gear'
        # also: 'page_white_link'
        return icon(icon_name)
    else:
        return icon(format_icon(res.get('format', '')))


def format_icon(_format):
    _format = _format.lower()
    if ('json' in _format): return 'page_white_cup'
    if ('csv' in _format): return 'page_white_gear'
    if ('xls' in _format): return 'page_white_excel'
    if ('zip' in _format): return 'page_white_compressed'
    if ('api' in _format): return 'page_white_database'
    if ('plain text' in _format): return 'page_white_text'
    if ('xml' in _format): return 'page_white_code'
    return 'page_white'


def dict_list_reduce(list_, key, unique=True):
    ''' Take a list of dicts and create a new one containing just the
    values for the key with unique values if requested. '''
    new_list = []
    for item in list_:
        value = item.get(key)
        if not value or (unique and value in new_list):
            continue
        new_list.append(value)
    return new_list


def linked_gravatar(email_hash, size=100, default=None):
    return literal(
        '<a href="https://gravatar.com/" target="_blank" ' +
        'title="%s">' % _('Update your avatar at gravatar.com') +
        '%s</a>' % gravatar(email_hash, size, default)
    )

_VALID_GRAVATAR_DEFAULTS = ['404', 'mm', 'identicon', 'monsterid',
                            'wavatar', 'retro']


def gravatar(email_hash, size=100, default=None):
    if default is None:
        default = config.get('ckan.gravatar_default', 'identicon')

    if not default in _VALID_GRAVATAR_DEFAULTS:
        # treat the default as a url
        default = urllib.quote(default, safe='')

    return literal('''<img src="//gravatar.com/avatar/%s?s=%d&amp;d=%s"
        class="gravatar" width="%s" height="%s" />'''
                   % (email_hash, size, default, size, size)
                   )


def pager_url(page, partial=None, **kwargs):
    routes_dict = _pylons_default_url.environ['pylons.routes_dict']
    kwargs['controller'] = routes_dict['controller']
    kwargs['action'] = routes_dict['action']
    if routes_dict.get('id'):
        kwargs['id'] = routes_dict['id']
    kwargs['page'] = page
    return url(**kwargs)


class Page(paginate.Page):
    # Curry the pager method of the webhelpers.paginate.Page class, so we have
    # our custom layout set as default.

    def pager(self, *args, **kwargs):
        kwargs.update(
            format=u"<div class='pagination pagination-centered'><ul>$link_previous ~2~ $link_next</ul></div>",
            symbol_previous=u'«', symbol_next=u'»',
            curpage_attr={'class': 'active'}, link_attr={}
        )
        return super(Page, self).pager(*args, **kwargs)

    # Put each page link into a <li> (for Bootstrap to style it)

    def _pagerlink(self, page, text, extra_attributes=None):
        anchor = super(Page, self)._pagerlink(page, text)
        extra_attributes = extra_attributes or {}
        return HTML.li(anchor, **extra_attributes)

    # Change 'current page' link from <span> to <li><a>
    # and '..' into '<li><a>..'
    # (for Bootstrap to style them properly)

    def _range(self, regexp_match):
        html = super(Page, self)._range(regexp_match)
        # Convert ..
        dotdot = '<span class="pager_dotdot">..</span>'
        dotdot_link = HTML.li(HTML.a('...', href='#'), class_='disabled')
        html = re.sub(dotdot, dotdot_link, html)

        # Convert current page
        text = '%s' % self.page
        current_page_span = str(HTML.span(c=text, **self.curpage_attr))
        current_page_link = self._pagerlink(self.page, text,
                                            extra_attributes=self.curpage_attr)
        return re.sub(current_page_span, current_page_link, html)


def render_datetime(datetime_, date_format=None, with_hours=False):
    '''Render a datetime object or timestamp string as a localised date or
    in the requested format.
    If timestamp is badly formatted, then a blank string is returned.

    :param datetime_: the date
    :type datetime_: datetime or ISO string format
    :param date_format: a date format
    :type date_format: string
    :param with_hours: should the `hours:mins` be shown
    :type with_hours: bool

    :rtype: string
    '''
    datetime_ = _datestamp_to_datetime(datetime_)
    if not datetime_:
        return ''
    # if date_format was supplied we use it
    if date_format:
        return datetime_.strftime(date_format)
    # the localised date
    return formatters.localised_nice_date(datetime_, show_date=True,
                                          with_hours=with_hours)


def date_str_to_datetime(date_str):
    '''Convert ISO-like formatted datestring to datetime object.

    This function converts ISO format date- and datetime-strings into
    datetime objects.  Times may be specified down to the microsecond.  UTC
    offset or timezone information may **not** be included in the string.

    Note - Although originally documented as parsing ISO date(-times), this
           function doesn't fully adhere to the format.  This function will
           throw a ValueError if the string contains UTC offset information.
           So in that sense, it is less liberal than ISO format.  On the
           other hand, it is more liberal of the accepted delimiters between
           the values in the string.  Also, it allows microsecond precision,
           despite that not being part of the ISO format.
    '''

    time_tuple = re.split('[^\d]+', date_str, maxsplit=5)

    # Extract seconds and microseconds
    if len(time_tuple) >= 6:
        m = re.match('(?P<seconds>\d{2})(\.(?P<microseconds>\d{6}))?$',
                     time_tuple[5])
        if not m:
            raise ValueError('Unable to parse %s as seconds.microseconds' %
                             time_tuple[5])
        seconds = int(m.groupdict().get('seconds'))
        microseconds = int(m.groupdict(0).get('microseconds'))
        time_tuple = time_tuple[:5] + [seconds, microseconds]

    return datetime.datetime(*map(int, time_tuple))


def parse_rfc_2822_date(date_str, assume_utc=True):
    '''
    Parse a date string of the form specified in RFC 2822, and return a
    datetime.

    RFC 2822 is the date format used in HTTP headers.  It should contain
    timezone information, but that cannot be relied upon.

    If date_str doesn't contain timezone information, then the 'assume_utc'
    flag determines whether we assume this string is local (with respect to the
    server running this code), or UTC.  In practice, what this means is that if
    assume_utc is True, then the returned datetime is 'aware', with an
    associated tzinfo of offset zero.  Otherwise, the returned datetime is
    'naive'.

    If timezone information is available in date_str, then the returned
    datetime is 'aware', ie - it has an associated tz_info object.

    Returns None if the string cannot be parsed as a valid datetime.
    '''
    time_tuple = email.utils.parsedate_tz(date_str)

    # Not parsable
    if not time_tuple:
        return None

    # No timezone information available in the string
    if time_tuple[-1] is None and not assume_utc:
        return datetime.datetime.fromtimestamp(
            email.utils.mktime_tz(time_tuple))
    else:
        offset = 0 if time_tuple[-1] is None else time_tuple[-1]
        tz_info = _RFC2282TzInfo(offset)
    return datetime.datetime(*time_tuple[:6], microsecond=0, tzinfo=tz_info)


class _RFC2282TzInfo(datetime.tzinfo):
    '''
    A datetime.tzinfo implementation used by parse_rfc_2822_date() function.

    In order to return timezone information, a concrete implementation of
    datetime.tzinfo is required.  This class represents tzinfo that knows
    about it's offset from UTC, has no knowledge of daylight savings time, and
    no knowledge of the timezone name.

    '''

    def __init__(self, offset):
        '''
        offset from UTC in seconds.
        '''
        self.offset = datetime.timedelta(seconds=offset)

    def utcoffset(self, dt):
        return self.offset

    def dst(self, dt):
        '''
        Dates parsed from an RFC 2822 string conflate timezone and dst, and so
        it's not possible to determine whether we're in DST or not, hence
        returning None.
        '''
        return None

    def tzname(self, dt):
        return None

@maintain.deprecated('h.time_ago_in_words_from_str is deprecated in 2.2 '
                     'and will be removed.  Please use '
                     'h.time_ago_from_timestamp instead')
def time_ago_in_words_from_str(date_str, granularity='month'):
    '''Deprecated in 2.2 use time_ago_from_timestamp'''
    if date_str:
        return date.time_ago_in_words(date_str_to_datetime(date_str),
                                      granularity=granularity)
    else:
        return _('Unknown')


def time_ago_from_timestamp(timestamp):
    ''' Returns a string like `5 months ago` for a datetime relative to now
    :param timestamp: the timestamp or datetime
    :type timestamp: string or datetime

    :rtype: string
    '''
    datetime_ = _datestamp_to_datetime(timestamp)
    if not datetime_:
        return _('Unknown')

    # the localised date
    return formatters.localised_nice_date(datetime_, show_date=False)


def button_attr(enable, type='primary'):
    if enable:
        return 'class="btn %s"' % type
    return 'disabled class="btn disabled"'


def dataset_display_name(package_or_package_dict):
    if isinstance(package_or_package_dict, dict):
        return package_or_package_dict.get('title', '') or \
            package_or_package_dict.get('name', '')
    else:
        return package_or_package_dict.title or package_or_package_dict.name


def dataset_link(package_or_package_dict):
    if isinstance(package_or_package_dict, dict):
        name = package_or_package_dict['name']
    else:
        name = package_or_package_dict.name
    text = dataset_display_name(package_or_package_dict)
    return link_to(
        text,
        url_for(controller='package', action='read', id=name)
    )

# TODO: (?) support resource objects as well
def resource_display_name(resource_dict):
    name = resource_dict.get('name', None)
    description = resource_dict.get('description', None)
    if name:
        return name
    elif description:
        description = description.split('.')[0]
        max_len = 60
        if len(description) > max_len:
            description = description[:max_len] + '...'
        return description
    else:
        return _("Unnamed resource")


def resource_link(resource_dict, package_id):
    text = resource_display_name(resource_dict)
    url = url_for(controller='package',
                  action='resource_read',
                  id=package_id,
                  resource_id=resource_dict['id'])
    return link_to(text, url)


def related_item_link(related_item_dict):
    text = related_item_dict.get('title', '')
    url = url_for(controller='related',
                  action='read',
                  id=related_item_dict['id'])
    return link_to(text, url)


def tag_link(tag):
    url = url_for(controller='tag', action='read', id=tag['name'])
    return link_to(tag.get('title', tag['name']), url)


def group_link(group):
    url = url_for(controller='group', action='read', id=group['name'])
    return link_to(group['title'], url)


def organization_link(organization):
    url = url_for(controller='organization', action='read', id=organization['name'])
    return link_to(organization['name'], url)


def dump_json(obj, **kw):
    return json.dumps(obj, **kw)


def _get_template_name():
    #FIX ME THIS IS BROKEN
    ''' helper function to get the currently/last rendered template name '''
    return c.__debug_info[-1]['template_name']


def auto_log_message():
    if (c.action == 'new'):
        return _('Created new dataset.')
    elif (c.action == 'editresources'):
        return _('Edited resources.')
    elif (c.action == 'edit'):
        return _('Edited settings.')
    return ''


def activity_div(template, activity, actor, object=None, target=None):
    actor = '<span class="actor">%s</span>' % actor
    if object:
        object = '<span class="object">%s</span>' % object
    if target:
        target = '<span class="target">%s</span>' % target
    rendered_datetime = render_datetime(activity['timestamp'])
    date = '<span class="date">%s</span>' % rendered_datetime
    template = template.format(actor=actor, date=date,
                               object=object, target=target)
    template = '<div class="activity">%s %s</div>' % (template, date)
    return literal(template)


def snippet(template_name, **kw):
    ''' This function is used to load html snippets into pages. keywords
    can be used to pass parameters into the snippet rendering '''
    import ckan.lib.base as base
    return base.render_snippet(template_name, **kw)


def convert_to_dict(object_type, objs):
    ''' This is a helper function for converting lists of objects into
    lists of dicts. It is for backwards compatability only. '''

    def dictize_revision_list(revision, context):
        # conversionof revision lists

        def process_names(items):
            array = []
            for item in items:
                array.append(item.name)
            return array

        rev = {'id': revision.id,
               'state': revision.state,
               'timestamp': revision.timestamp,
               'author': revision.author,
               'packages': process_names(revision.packages),
               'groups': process_names(revision.groups),
               'message': revision.message, }
        return rev
    import ckan.lib.dictization.model_dictize as md
    converters = {'package': md.package_dictize,
                  'revisions': dictize_revision_list}
    converter = converters[object_type]
    items = []
    context = {'model': model}
    for obj in objs:
        item = converter(obj, context)
        items.append(item)
    return items

# these are the types of objects that can be followed
_follow_objects = ['dataset', 'user', 'group']


def follow_button(obj_type, obj_id):
    '''Return a follow button for the given object type and id.

    If the user is not logged in return an empty string instead.

    :param obj_type: the type of the object to be followed when the follow
        button is clicked, e.g. 'user' or 'dataset'
    :type obj_type: string
    :param obj_id: the id of the object to be followed when the follow button
        is clicked
    :type obj_id: string

    :returns: a follow button as an HTML snippet
    :rtype: string

    '''
    obj_type = obj_type.lower()
    assert obj_type in _follow_objects
    # If the user is logged in show the follow/unfollow button
    if c.user:
        context = {'model': model, 'session': model.Session, 'user': c.user}
        action = 'am_following_%s' % obj_type
        following = logic.get_action(action)(context, {'id': obj_id})
        return snippet('snippets/follow_button.html',
                       following=following,
                       obj_id=obj_id,
                       obj_type=obj_type)
    return ''


def follow_count(obj_type, obj_id):
    '''Return the number of followers of an object.

    :param obj_type: the type of the object, e.g. 'user' or 'dataset'
    :type obj_type: string
    :param obj_id: the id of the object
    :type obj_id: string

    :returns: the number of followers of the object
    :rtype: int

    '''
    obj_type = obj_type.lower()
    assert obj_type in _follow_objects
    action = '%s_follower_count' % obj_type
    context = {'model': model, 'session': model.Session, 'user': c.user}
    return logic.get_action(action)(context, {'id': obj_id})


def _create_url_with_params(params=None, controller=None, action=None,
                            extras=None):
    ''' internal function for building urls with parameters. '''

    if not controller:
        controller = c.controller
    if not action:
        action = c.action
    if not extras:
        extras = {}

    url = url_for(controller=controller, action=action, **extras)
    return _url_with_params(url, params)


def add_url_param(alternative_url=None, controller=None, action=None,
                  extras=None, new_params=None):
    '''
    Adds extra parameters to existing ones

    controller action & extras (dict) are used to create the base url via
    :py:func:`~ckan.lib.helpers.url_for` controller & action default to the
    current ones

    This can be overriden providing an alternative_url, which will be used
    instead.
    '''

    params_nopage = [(k, v) for k, v in request.params.items() if k != 'page']
    params = set(params_nopage)
    if new_params:
        params |= set(new_params.items())
    if alternative_url:
        return _url_with_params(alternative_url, params)
    return _create_url_with_params(params=params, controller=controller,
                                   action=action, extras=extras)


def remove_url_param(key, value=None, replace=None, controller=None,
                     action=None, extras=None, alternative_url=None):
    ''' Remove one or multiple keys from the current parameters.
    The first parameter can be either a string with the name of the key to
    remove or a list of keys to remove.
    A specific key/value pair can be removed by passing a second value
    argument otherwise all pairs matching the key will be removed. If replace
    is given then a new param key=replace will be added.
    Note that the value and replace parameters only apply to the first key
    provided (or the only one provided if key is a string).

    controller action & extras (dict) are used to create the base url
    via :py:func:`~ckan.lib.helpers.url_for`
    controller & action default to the current ones

    This can be overriden providing an alternative_url, which will be used
    instead.

    '''
    if isinstance(key, basestring):
        keys = [key]
    else:
        keys = key

    params_nopage = [(k, v) for k, v in request.params.items() if k != 'page']
    params = list(params_nopage)
    if value:
        params.remove((keys[0], value))
    else:
        for key in keys:
            [params.remove((k, v)) for (k, v) in params[:] if k == key]
    if replace is not None:
        params.append((keys[0], replace))

    if alternative_url:
        return _url_with_params(alternative_url, params)

    return _create_url_with_params(params=params, controller=controller,
                                   action=action, extras=extras)


def include_resource(resource):
    r = getattr(fanstatic_resources, resource)
    r.need()


def urls_for_resource(resource):
    ''' Returns a list of urls for the resource specified.  If the resource
    is a group or has dependencies then there can be multiple urls.

    NOTE: This is for special situations only and is not the way to generally
    include resources.  It is advised not to use this function.'''
    r = getattr(fanstatic_resources, resource)
    resources = list(r.resources)
    core = fanstatic_resources.fanstatic_extensions.core
    f = core.get_needed()
    lib = r.library
    root_path = f.library_url(lib)

    resources = core.sort_resources(resources)
    if f._bundle:
        resources = core.bundle_resources(resources)
    out = []
    for resource in resources:
        if isinstance(resource, core.Bundle):
            paths = [resource.relpath for resource in resource.resources()]
            relpath = ';'.join(paths)
            relpath = core.BUNDLE_PREFIX + relpath
        else:
            relpath = resource.relpath

        out.append('%s/%s' % (root_path, relpath))
    return out


def debug_inspect(arg):
    ''' Output pprint.pformat view of supplied arg '''
    return literal('<pre>') + pprint.pformat(arg) + literal('</pre>')


def debug_full_info_as_list(debug_info):
    ''' This dumps the template variables for debugging purposes only. '''
    out = []
    ignored_keys = ['c', 'app_globals', 'g', 'h', 'request', 'tmpl_context',
                    'actions', 'translator', 'session', 'N_', 'ungettext',
                    'config', 'response', '_']
    ignored_context_keys = ['__class__', '__context', '__delattr__', '__dict__',
                            '__doc__', '__format__', '__getattr__',
                            '__getattribute__', '__hash__', '__init__',
                            '__module__', '__new__', '__reduce__',
                            '__reduce_ex__', '__repr__', '__setattr__',
                            '__sizeof__', '__str__', '__subclasshook__',
                            '__weakref__', 'action', 'environ', 'pylons',
                            'start_response']
    debug_vars = debug_info['vars']
    for key in debug_vars.keys():
        if not key in ignored_keys:
            data = pprint.pformat(debug_vars.get(key))
            data = data.decode('utf-8')
            out.append((key, data))

    if 'tmpl_context' in debug_vars:
        for key in debug_info['c_vars']:

            if not key in ignored_context_keys:
                data = pprint.pformat(getattr(debug_vars['tmpl_context'], key))
                data = data.decode('utf-8')
                out.append(('c.%s' % key, data))

    return out


def popular(type_, number, min=1, title=None):
    ''' display a popular icon. '''
    if type_ == 'views':
        title = ungettext('{number} view', '{number} views', number)
    elif type_ == 'recent views':
        title = ungettext('{number} recent view', '{number} recent views', number)
    elif not title:
        raise Exception('popular() did not recieve a valid type_ or title')
    return snippet('snippets/popular.html', title=title, number=number, min=min)


def groups_available(am_member=False):
    '''Return a list of the groups that the user is authorized to edit.

    :param am_member: if True return only the groups the logged-in user is a
      member of, otherwise return all groups that the user is authorized to
      edit (for example, sysadmin users are authorized to edit all groups)
      (optional, default: False)
    :type am-member: boolean

    '''
    context = {}
    data_dict = {'available_only': True, 'am_member': am_member}
    return logic.get_action('group_list_authz')(context, data_dict)


def organizations_available(permission='edit_group'):
    ''' return a list of available organizations '''
    context = {'user': c.user}
    data_dict = {'permission': permission}
    return logic.get_action('organization_list_for_user')(context, data_dict)


def user_in_org_or_group(group_id):
    ''' Check if user is in a group or organization '''
    # we need a user
    if not c.userobj:
        return False
    # sysadmins can do anything
    if c.userobj.sysadmin:
        return True
    query = model.Session.query(model.Member) \
        .filter(model.Member.state == 'active') \
        .filter(model.Member.table_name == 'user') \
        .filter(model.Member.group_id == group_id) \
        .filter(model.Member.table_id == c.userobj.id)
    return len(query.all()) != 0


def dashboard_activity_stream(user_id, filter_type=None, filter_id=None,
                              offset=0):
    '''Return the dashboard activity stream of the current user.

    :param user_id: the id of the user
    :type user_id: string

    :param filter_type: the type of thing to filter by
    :type filter_type: string

    :param filter_id: the id of item to filter by
    :type filter_id: string

    :returns: an activity stream as an HTML snippet
    :rtype: string

    '''
    context = {'model': model, 'session': model.Session, 'user': c.user}

    if filter_type:
        action_functions = {
            'dataset': 'package_activity_list_html',
            'user': 'user_activity_list_html',
            'group': 'group_activity_list_html',
            'organization': 'organization_activity_list_html',
        }
        action_function = logic.get_action(action_functions.get(filter_type))
        return action_function(context, {'id': filter_id, 'offset': offset})
    else:
        return logic.get_action('dashboard_activity_list_html')(
            context, {'offset': offset})


def recently_changed_packages_activity_stream(limit=None):
    if limit:
        data_dict = {'limit': limit}
    else:
        data_dict = {}
    context = {'model': model, 'session': model.Session, 'user': c.user}
    return logic.get_action('recently_changed_packages_activity_list_html')(
        context, data_dict)


def escape_js(str_to_escape):
    '''Escapes special characters from a JS string.

       Useful e.g. when you need to pass JSON to the templates

       :param str_to_escape: string to be escaped
       :rtype: string
    '''
    return str_to_escape.replace('\\', '\\\\') \
        .replace('\'', '\\\'') \
        .replace('"', '\\\"')


def get_pkg_dict_extra(pkg_dict, key, default=None):
    '''Returns the value for the dataset extra with the provided key.

    If the key is not found, it returns a default value, which is None by
    default.

    :param pkg_dict: dictized dataset
    :key: extra key to lookup
    :default: default value returned if not found
    '''

    extras = pkg_dict['extras'] if 'extras' in pkg_dict else []

    for extra in extras:
        if extra['key'] == key:
            return extra['value']

    return default


def get_request_param(parameter_name, default=None):
    ''' This function allows templates to access query string parameters
    from the request. This is useful for things like sort order in
    searches. '''
    return request.params.get(parameter_name, default)

# find all inner text of html eg `<b>moo</b>` gets `moo` but not of <a> tags
# as this would lead to linkifying links if they are urls.
RE_MD_GET_INNER_HTML = re.compile(
    r'(^|(?:<(?!a\b)[^>]*>))([^<]+)(?=<|$)',
    flags=re.UNICODE
)

# find all `internal links` eg. tag:moo, dataset:1234, tag:"my tag"
RE_MD_INTERNAL_LINK = re.compile(
    r'\b(tag|package|dataset|group):((")?(?(3)[ \w\-.]+|[\w\-.]+)(?(3)"))',
    flags=re.UNICODE
)

# find external links eg http://foo.com, https://bar.org/foobar.html
RE_MD_EXTERNAL_LINK = re.compile(
    r'(\bhttps?:\/\/[\w\-\.,@?^=%&;:\/~\\+#]*)',
    flags=re.UNICODE
)

# find all tags but ignore < in the strings so that we can use it correctly
# in markdown
RE_MD_HTML_TAGS = re.compile('<[^><]*>')


def html_auto_link(data):
    '''Linkifies HTML

    tag:... converted to a tag link
    dataset:... converted to a dataset link
    group:... converted to a group link
    http://... converted to a link
    '''

    LINK_FNS = {
        'tag': tag_link,
        'group': group_link,
        'dataset': dataset_link,
        'package': dataset_link,
    }

    def makelink(matchobj):
        obj = matchobj.group(1)
        name = matchobj.group(2)
        title = '%s:%s' % (obj, name)
        return LINK_FNS[obj]({'name': name.strip('"'), 'title': title})

    def link(matchobj):
        return '<a href="%s" target="_blank" rel="nofollow">%s</a>' \
            % (matchobj.group(1), matchobj.group(1))

    def process(matchobj):
        data = matchobj.group(2)
        data = RE_MD_INTERNAL_LINK.sub(makelink, data)
        data = RE_MD_EXTERNAL_LINK.sub(link, data)
        return matchobj.group(1) + data

    data = RE_MD_GET_INNER_HTML.sub(process, data)
    return data


def render_markdown(data, auto_link=True):
    ''' returns the data as rendered markdown '''
    if not data:
        return ''
    data = RE_MD_HTML_TAGS.sub('', data.strip())
    data = markdown(data, safe_mode=True)
    # tags can be added by tag:... or tag:"...." and a link will be made
    # from it
    if auto_link:
        data = html_auto_link(data)
    return literal(data)


def format_resource_items(items):
    ''' Take a resource item list and format nicely with blacklisting etc. '''
    blacklist = ['name', 'description', 'url', 'tracking_summary']
    output = []
    # regular expressions for detecting types in strings
    reg_ex_datetime = '^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(\.\d{6})?$'
    reg_ex_int = '^-?\d{1,}$'
    reg_ex_float = '^-?\d{1,}\.\d{1,}$'
    for key, value in items:
        if not value or key in blacklist:
            continue
        # size is treated specially as we want to show in MiB etc
        if key == 'size':
            try:
                value = formatters.localised_filesize(int(value))
            except ValueError:
                # Sometimes values that can't be converted to ints can sneak
                # into the db. In this case, just leave them as they are.
                pass
        elif isinstance(value, basestring):
            # check if strings are actually datetime/number etc
            if re.search(reg_ex_datetime, value):
                datetime_ = date_str_to_datetime(value)
                value = formatters.localised_nice_date(datetime_)
            elif re.search(reg_ex_float, value):
                value = formatters.localised_number(float(value))
            elif re.search(reg_ex_int, value):
                value = formatters.localised_number(int(value))
        elif isinstance(value, int) or isinstance(value, float):
            value = formatters.localised_number(value)
        key = key.replace('_', ' ')
        output.append((key, value))
    return sorted(output, key=lambda x: x[0])


def resource_preview(resource, package):
    '''
    Returns a rendered snippet for a embedded resource preview.

    Depending on the type, different previews are loaded.
    This could be an img tag where the image is loaded directly or an iframe
    that embeds a web page, recline or a pdf preview.
    '''

    if not resource['url']:
        return snippet("dataviewer/snippets/no_preview.html",
                       resource_type=format_lower,
                       reason=_(u'The resource url is not specified.'))

    format_lower = datapreview.res_format(resource)
    directly = False
    data_dict = {'resource': resource, 'package': package}

    if datapreview.get_preview_plugin(data_dict, return_first=True):
        url = url_for(controller='package', action='resource_datapreview',
                      resource_id=resource['id'], id=package['id'], qualified=True)
    elif format_lower in datapreview.direct():
        directly = True
        url = resource['url']
    elif format_lower in datapreview.loadable():
        url = resource['url']
    else:
        reason = None
        if format_lower:
            log.info(
                _(u'No preview handler for resource of type {0}'.format(
                    format_lower))
            )
        else:
            reason = _(u'The resource format is not specified.')
        return snippet("dataviewer/snippets/no_preview.html",
                       reason=reason,
                       resource_type=format_lower)

    return snippet("dataviewer/snippets/data_preview.html",
                   embed=directly,
                   resource_url=url,
                   raw_resource_url=resource.get('url'))


def list_dict_filter(list_, search_field, output_field, value):
    ''' Takes a list of dicts and returns the value of a given key if the
    item has a matching value for a supplied key

    :param list_: the list to search through for matching items
    :type list_: list of dicts

    :param search_field: the key to use to find matching items
    :type search_field: string

    :param output_field: the key to use to output the value
    :type output_field: string

    :param value: the value to search for
    '''

    for item in list_:
        if item.get(search_field) == value:
            return item.get(output_field, value)
    return value


def SI_number_span(number):
    ''' outputs a span with the number in SI unit eg 14700 -> 14.7k '''
    number = int(number)
    if number < 1000:
        output = literal('<span>')
    else:
        output = literal('<span title="' + formatters.localised_number(number) + '">')
    return output + formatters.localised_SI_number(number) + literal('</span>')

# add some formatter functions
localised_number = formatters.localised_number
localised_SI_number = formatters.localised_SI_number
localised_nice_date = formatters.localised_nice_date
localised_filesize = formatters.localised_filesize

def new_activities():
    '''Return the number of activities for the current user.

    See :func:`logic.action.get.dashboard_new_activities_count` for more
    details.

    '''
    if not c.userobj:
        return None
    action = logic.get_action('dashboard_new_activities_count')
    return action({}, {})

def uploads_enabled():
    if uploader.get_storage_path():
        return True
    return False

def get_featured_organizations(count=1):
    '''Returns a list of favourite organization in the form
    of organization_list action function
    '''
    config_orgs = config.get('ckan.featured_orgs', '').split()
    orgs = featured_group_org(get_action='organization_show',
                              list_action='organization_list',
                              count=count,
                              items=config_orgs)
    return orgs


def get_featured_groups(count=1):
    '''Returns a list of favourite group the form
    of organization_list action function
    '''
    config_groups = config.get('ckan.featured_groups', '').split()
    groups = featured_group_org(get_action='group_show',
                                list_action='group_list',
                                count=count,
                                items=config_groups)
    return groups


def featured_group_org(items, get_action, list_action, count):
    def get_group(id):
        context = {'ignore_auth': True,
                   'limits': {'packages': 2},
                   'for_view': True}
        data_dict = {'id': id}

        try:
            out = logic.get_action(get_action)(context, data_dict)
        except logic.NotFound:
            return None
        return out

    groups_data = []

    extras = logic.get_action(list_action)({}, {})

    # list of found ids to prevent duplicates
    found = []
    for group_name in items + extras:
        group = get_group(group_name)
        if not group:
            continue
        # check if duplicate
        if group['id'] in found:
            continue
        found.append(group['id'])
        groups_data.append(group)
        if len(groups_data) == count:
            break

    return groups_data


def get_site_statistics():
    stats = {}
    stats['dataset_count'] = logic.get_action('package_search')(
        {}, {"rows": 1})['count']
    stats['group_count'] = len(logic.get_action('group_list')({}, {}))
    stats['organization_count'] = len(
        logic.get_action('organization_list')({}, {}))
    result = model.Session.execute(
        '''select count(*) from related r
           left join related_dataset rd on r.id = rd.related_id
           where rd.status = 'active' or rd.id is null''').first()[0]
    stats['related_count'] = result

    return stats

_RESOURCE_FORMATS = None

def resource_formats():
    ''' Returns the resource formats as a dict, sourced from the resource format JSON file.
    key:  potential user input value
    value:  [canonical mimetype lowercased, canonical format (lowercase), human readable form]
    Fuller description of the fields are described in
    `ckan/config/resource_formats.json`.
    '''
    global _RESOURCE_FORMATS
    if not _RESOURCE_FORMATS:
        _RESOURCE_FORMATS = {}
        format_file_path = config.get('ckan.resource_formats')
        if not format_file_path:
            format_file_path = os.path.join(
                os.path.dirname(os.path.realpath(ckan.config.__file__)),
                'resource_formats.json'
            )
        with open(format_file_path) as format_file:
            try:
                file_resource_formats = json.loads(format_file.read())
            except ValueError, e:  # includes simplejson.decoder.JSONDecodeError
                raise ValueError('Invalid JSON syntax in %s: %s' % (format_file_path, e))

            for format_line in file_resource_formats:
                if format_line[0] == '_comment':
                    continue
                line = [format_line[2], format_line[0], format_line[1]]
                alternatives = format_line[3] if len(format_line) == 4 else []
                for item in line + alternatives:
                    if item:
                        item = item.lower()
                        if item in _RESOURCE_FORMATS \
                                and _RESOURCE_FORMATS[item] != line:
                            raise ValueError('Duplicate resource format '
                                             'identifier in %s: %s' %
                                             (format_file_path, item))
                        _RESOURCE_FORMATS[item] = line

    return _RESOURCE_FORMATS


def unified_resource_format(format):
    formats = resource_formats()
    format_clean = format.lower()
    if format_clean in formats:
        format_new = formats[format_clean][1]
    else:
        format_new = format
    return format_new

def check_config_permission(permission):
    return new_authz.check_config_permission(permission)


def get_organization(org=None):
    if org is None:
        return {}
    try:
        return logic.get_action('organization_show')({}, {'id': org})
    except (NotFound, ValidationError, NotAuthorized):
        return {}

# these are the functions that will end up in `h` template helpers
__allowed_functions__ = [
    # functions defined in ckan.lib.helpers
    'redirect_to',
    'url',
    'url_for',
    'url_for_static',
    'url_for_static_or_external',
    'lang',
    'flash',
    'flash_error',
    'flash_notice',
    'flash_success',
    'nav_link',
    'nav_named_link',
    'subnav_link',
    'subnav_named_route',
    'default_group_type',
    'check_access',
    'get_action',
    'linked_user',
    'group_name_to_title',
    'markdown_extract',
    'icon',
    'icon_html',
    'icon_url',
    'resource_icon',
    'format_icon',
    'linked_gravatar',
    'gravatar',
    'pager_url',
    'render_datetime',
    'date_str_to_datetime',
    'parse_rfc_2822_date',
    'time_ago_in_words_from_str',
    'button_attr',
    'dataset_display_name',
    'dataset_link',
    'resource_display_name',
    'resource_link',
    'related_item_link',
    'tag_link',
    'group_link',
    'dump_json',
    'auto_log_message',
    'snippet',
    'convert_to_dict',
    'activity_div',
    'lang_native_name',
    'get_facet_items_dict',
    'unselected_facet_items',
    'include_resource',
    'urls_for_resource',
    'build_nav_main',
    'build_nav_icon',
    'build_nav',
    'debug_inspect',
    'dict_list_reduce',
    'full_current_url',
    'popular',
    'debug_full_info_as_list',
    'get_facet_title',
    'get_param_int',
    'sorted_extras',
    'follow_button',
    'follow_count',
    'remove_url_param',
    'add_url_param',
    'groups_available',
    'organizations_available',
    'user_in_org_or_group',
    'dashboard_activity_stream',
    'recently_changed_packages_activity_stream',
    'escape_js',
    'get_pkg_dict_extra',
    'get_request_param',
    'render_markdown',
    'format_resource_items',
    'resource_preview',
    'SI_number_span',
    'localised_number',
    'localised_SI_number',
    'localised_nice_date',
    'localised_filesize',
    'list_dict_filter',
    'new_activities',
    'time_ago_from_timestamp',
    'get_organization',
    'has_more_facets',
    # imported into ckan.lib.helpers
    'literal',
    'link_to',
    'get_available_locales',
    'get_locales_dict',
    'truncate',
    'file',
    'mail_to',
    'radio',
    'submit',
    'asbool',
    'uploads_enabled',
    'get_featured_organizations',
    'get_featured_groups',
    'get_site_statistics',
    'check_config_permission',
]

########NEW FILE########
__FILENAME__ = i18n
import os

from babel import Locale, localedata
from babel.core import LOCALE_ALIASES
from pylons import config
from pylons import i18n

import ckan.i18n

LOCALE_ALIASES['pt'] = 'pt_BR' # Default Portuguese language to
                               # Brazilian territory, since
                               # we don't have a Portuguese territory
                               # translation currently.

def get_locales_from_config():
    ''' despite the name of this function it gets the locales defined by
    the config AND also the locals available subject to the config. '''
    locales_offered = config.get('ckan.locales_offered', '').split()
    filtered_out = config.get('ckan.locales_filtered_out', '').split()
    locale_default = config.get('ckan.locale_default', 'en')
    locale_order = config.get('ckan.locale_order', '').split()
    known_locales = get_locales()
    all_locales = set(known_locales) | set(locales_offered) | set(locale_order) | set(locale_default)
    all_locales -= set(filtered_out)
    return all_locales

def _get_locales():
    # FIXME this wants cleaning up and merging with get_locales_from_config()
    assert not config.get('lang'), \
            '"lang" config option not supported - please use ckan.locale_default instead.'
    locales_offered = config.get('ckan.locales_offered', '').split()
    filtered_out = config.get('ckan.locales_filtered_out', '').split()
    locale_default = config.get('ckan.locale_default', 'en')
    locale_order = config.get('ckan.locale_order', '').split()

    locales = ['en']
    if config.get('ckan.i18n_directory'):
        i18n_path = os.path.join(config.get('ckan.i18n_directory'), 'i18n')
    else:
        i18n_path = os.path.dirname(ckan.i18n.__file__)
    locales += [l for l in os.listdir(i18n_path) if localedata.exists(l)]

    assert locale_default in locales, \
            'default language "%s" not available' % locale_default

    locale_list = []
    for locale in locales:
        # no duplicates
        if locale in locale_list:
            continue
        # if offered locales then check locale is offered
        if locales_offered and locale not in locales_offered:
            continue
        # remove if filtered out
        if locale in filtered_out:
            continue
        # ignore the default as it will be added first
        if locale == locale_default:
            continue
        locale_list.append(locale)
    # order the list if specified
    ordered_list = [locale_default]
    for locale in locale_order:
        if locale in locale_list:
            ordered_list.append(locale)
            # added so remove from our list
            locale_list.remove(locale)
    # add any remaining locales not ordered
    ordered_list += locale_list

    return ordered_list

available_locales = None
locales = None
locales_dict = None
_non_translated_locals = None

def get_locales():
    ''' Get list of available locales
    e.g. [ 'en', 'de', ... ]
    '''
    global locales
    if not locales:
        locales = _get_locales()
    return locales

def non_translated_locals():
    ''' These are the locales that are available but for which there are
    no translations. returns a list like ['en', 'de', ...] '''
    global _non_translated_locals
    if not _non_translated_locals:
        locales = config.get('ckan.locale_order', '').split()
        _non_translated_locals = [x for x in locales if x not in get_locales()]
    return _non_translated_locals

def get_locales_dict():
    ''' Get a dict of the available locales
    e.g.  { 'en' : Locale('en'), 'de' : Locale('de'), ... } '''
    global locales_dict
    if not locales_dict:
        locales = _get_locales()
        locales_dict = {}
        for locale in locales:
            locales_dict[str(locale)] = Locale.parse(locale)
    return locales_dict

def get_available_locales():
    ''' Get a list of the available locales
    e.g.  [ Locale('en'), Locale('de'), ... ] '''
    global available_locales
    if not available_locales:
        available_locales = map(Locale.parse, get_locales())
    return available_locales

def _set_lang(lang):
    ''' Allows a custom i18n directory to be specified.
    Creates a fake config file to pass to pylons.i18n.set_lang, which
    sets the Pylons root path to desired i18n_directory.
    This is needed as Pylons will only look for an i18n directory in
    the application root.'''
    if config.get('ckan.i18n_directory'):
        fake_config = {'pylons.paths': {'root': config['ckan.i18n_directory']},
                       'pylons.package': config['pylons.package']}
        i18n.set_lang(lang, pylons_config=fake_config)
    else:
        i18n.set_lang(lang)

def handle_request(request, tmpl_context):
    ''' Set the language for the request '''
    lang = request.environ.get('CKAN_LANG') or \
        config.get('ckan.locale_default', 'en')
    if lang != 'en':
        set_lang(lang)
    tmpl_context.language = lang
    return lang

def get_lang():
    ''' Returns the current language. Based on babel.i18n.get_lang but
    works when set_lang has not been run (i.e. still in English). '''
    langs = i18n.get_lang()
    if langs:
        return langs[0]
    else:
        return 'en'

def set_lang(language_code):
    ''' Wrapper to pylons call '''
    if language_code in non_translated_locals():
        language_code = config.get('ckan.locale_default', 'en')
    if language_code != 'en':
        _set_lang(language_code)

########NEW FILE########
__FILENAME__ = jinja_extensions
import re
from os import path
import logging

from jinja2 import nodes
from jinja2 import loaders
from jinja2 import ext
from jinja2.exceptions import TemplateNotFound
from jinja2.utils import open_if_exists, escape
from jinja2.filters import do_truncate
from jinja2 import Environment

import ckan.lib.base as base
import ckan.lib.helpers as h


log = logging.getLogger(__name__)
### Filters

def empty_and_escape(value):
    ''' returns '' for a None value else escapes the content useful for form
    elements. '''
    if value is None:
        return ''
    else:
        return escape(value)

def truncate(value, length=255, killwords=None, end='...'):
    ''' A more clever truncate. If killwords is supplied we use the default
    truncate.  Otherwise we try to truncate using killwords=False, if this
    truncates the whole value we try again with killwords=True '''
    if value is None:
        return None
    if killwords is not None:
        return do_truncate(value, length=length, killwords=killwords, end=end)
    result = do_truncate(value, length=length, killwords=False, end=end)
    if result != end:
        return result
    return do_truncate(value, length=length, killwords=True, end=end)

### Tags

def regularise_html(html):
    ''' Take badly formatted html with strings etc and make it beautiful
    generally remove surlus whitespace and kill \n this will break <code><pre>
    tags but they should not be being translated '''
    if html is None:
        return
    html = re.sub('\n', ' ', html)
    matches = re.findall('(<[^>]*>|%[^%]\([^)]*\)\w|[^<%]+|%)', html)
    for i in xrange(len(matches)):
        match = matches[i]
        if match.startswith('<') or match.startswith('%'):
            continue
        matches[i] = re.sub('\s{2,}', ' ', match)
    html = ''.join(matches)
    return html


class CkanInternationalizationExtension(ext.InternationalizationExtension):
    ''' Custom translation to allow cleaned up html '''

    def parse(self, parser):
        node = ext.InternationalizationExtension.parse(self, parser)
        args = getattr(node.nodes[0], 'args', None)
        if args:
            for arg in args:
                if isinstance(arg, nodes.Const):
                    value = arg.value
                    if isinstance(value, unicode):
                        arg.value = regularise_html(value)
        return node


class CkanExtend(ext.Extension):
    ''' Custom {% ckan_extends <template> %} tag that allows templates
    to inherit from the ckan template futher down the template search path
    if no template provided we assume the same template name. '''

    tags = set(['ckan_extends'])

    def __init__(self, environment):
        ext.Extension.__init__(self, environment)
        try:
            self.searchpath = environment.loader.searchpath[:]
        except AttributeError:
            # this isn't available on message extraction
            pass

    def parse(self, parser):
        lineno = next(parser.stream).lineno
        node = nodes.Extends(lineno)
        template_path = parser.filename
        # find where in the search path this template is from
        index = 0
        if not hasattr(self, 'searchpath'):
            return node
        for searchpath in self.searchpath:
            if template_path.startswith(searchpath):
                break
            index += 1

        # get filename from full path
        filename = template_path[len(searchpath) + 1:]

        # Providing template path violently deprecated
        if parser.stream.current.type != 'block_end':
            provided_template = parser.parse_expression().value
            if provided_template != filename:
                raise Exception('ckan_extends tag wrong path %s in %s'
                                % (provided_template, template_path))
            else:
                log.critical('Remove path from ckan_extend tag in %s'
                             % template_path)

        # provide our magic format
        # format is *<search path parent index>*<template name>
        magic_filename = '*' + str(index) + '*' + filename
        # set template
        node.template = nodes.Const(magic_filename)
        return node


class CkanFileSystemLoader(loaders.FileSystemLoader):
    ''' This is a variant of the jinja2 FileSystemLoader. It allows
    functionality for the ckan_extends tag. When we use the ckan_extends
    tag we only want to look in the ckan/templates directory rather than
    looking thropugh all the template paths. This allows a none base
    template to be able to extend a base ckan template of the same name.
    This functionality allows easy customisation of ckan via template
    inheritance.

    This class is based on jinja2 code which is licensed as follows
======================================================================
    Copyright (c) 2009 by the Jinja Team, see AUTHORS for more details.

Some rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

    * Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.

    * Redistributions in binary form must reproduce the above
      copyright notice, this list of conditions and the following
      disclaimer in the documentation and/or other materials provided
      with the distribution.

    * The names of the contributors may not be used to endorse or
      promote products derived from this software without specific
      prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
=====================================================================
    '''

    def get_source(self, environment, template):
        # if the template name starts with * then this should be
        # treated specially.
        # format is *<search path parent index>*<template name>
        # so we only search from then downwards.  This allows recursive
        # ckan_extends tags
        if template.startswith('*'):
            parts = template.split('*')
            template = parts[2]
            searchpaths = self.searchpath[int(parts[1]) + 1:]
        else:
            searchpaths = self.searchpath
        # end of ckan changes
        pieces = loaders.split_template_path(template)
        for searchpath in searchpaths:
            filename = path.join(searchpath, *pieces)
            f = open_if_exists(filename)
            if f is None:
                continue
            try:
                contents = f.read().decode(self.encoding)
            except UnicodeDecodeError, e:
                log.critical(
                    'Template corruption in `%s` unicode decode errors'
                    % filename
                )
                raise e
            finally:
                f.close()

            mtime = path.getmtime(filename)

            def uptodate():
                try:
                    return path.getmtime(filename) == mtime
                except OSError:
                    return False
            return contents, filename, uptodate
        raise TemplateNotFound(template)


class BaseExtension(ext.Extension):
    ''' Base class for creating custom jinja2 tags.
    parse expects a tag of the format
    {% tag_name args, kw %}
    after parsing it will call _call(args, kw) which must be defined. '''

    def parse(self, parser):
        stream = parser.stream
        tag = stream.next()
        # get arguments
        args = []
        kwargs = []
        while not stream.current.test_any('block_end'):
            if args or kwargs:
                stream.expect('comma')
            if stream.current.test('name') and stream.look().test('assign'):
                key = nodes.Const(stream.next().value)
                stream.skip()
                value = parser.parse_expression()
                kwargs.append(nodes.Pair(key, value, lineno=key.lineno))
            else:
                args.append(parser.parse_expression())

        def make_call_node(*kw):
            return self.call_method('_call', args=[
                nodes.List(args),
                nodes.Dict(kwargs),
            ], kwargs=kw)

        return nodes.Output([make_call_node()]).set_lineno(tag.lineno)


class SnippetExtension(BaseExtension):
    ''' Custom snippet tag

    {% snippet <template_name> [, <keyword>=<value>].. %}

    see lib.helpers.snippet() for more details.
    '''

    tags = set(['snippet'])

    @classmethod
    def _call(cls, args, kwargs):
        assert len(args) == 1
        return base.render_snippet(args[0], **kwargs)

class UrlForStaticExtension(BaseExtension):
    ''' Custom url_for_static tag for getting a path for static assets.

    {% url_for_static <path> %}

    see lib.helpers.url_for_static() for more details.
    '''

    tags = set(['url_for_static'])

    @classmethod
    def _call(cls, args, kwargs):
        assert len(args) == 1
        return h.url_for_static(args[0], **kwargs)

class UrlForExtension(BaseExtension):
    ''' Custom url_for tag

    {% url_for <params> %}

    see lib.helpers.url_for() for more details.
    '''

    tags = set(['url_for'])

    @classmethod
    def _call(cls, args, kwargs):
        return h.url_for(*args, **kwargs)


class LinkForExtension(BaseExtension):
    ''' Custom link_for tag

    {% link_for <params> %}

    see lib.helpers.nav_link() for more details.
    '''

    tags = set(['link_for'])

    @classmethod
    def _call(cls, args, kwargs):
        return h.nav_link(*args, **kwargs)

class ResourceExtension(BaseExtension):
    ''' Custom include_resource tag

    {% resource <resource_name> %}

    see lib.helpers.include_resource() for more details.
    '''

    tags = set(['resource'])

    @classmethod
    def _call(cls, args, kwargs):
        assert len(args) == 1
        assert len(kwargs) == 0
        h.include_resource(args[0], **kwargs)
        return ''



'''
The following function is based on jinja2 code

Provides a class that holds runtime and parsing time options.

:copyright: (c) 2010 by the Jinja Team.
:license: BSD, see LICENSE for more details.
'''

def jinja2_getattr(self, obj, attribute):
    """Get an item or attribute of an object but prefer the attribute.
    Unlike :meth:`getitem` the attribute *must* be a bytestring.

    This is a customised version to work with properties
    """
    try:
        value = getattr(obj, attribute)
        if isinstance(value, property):
            value = value.fget()
        return value
    except AttributeError:
        pass
    try:
        value = obj[attribute]
        if isinstance(value, property):
            value = value.fget()
        return value
    except (TypeError, LookupError, AttributeError):
        return self.undefined(obj=obj, name=attribute)

setattr(Environment, 'get_attr', jinja2_getattr)
del jinja2_getattr

########NEW FILE########
__FILENAME__ = jsonp
import decorator

from ckan.common import json, request, response


def to_jsonp(data):
    content_type = 'application/json;charset=utf-8'
    result = json.dumps(data, sort_keys=True)
    if 'callback' in request.params:
        response.headers['Content-Type'] = content_type
        cbname = request.params['callback']
        result = '%s(%s);' % (cbname, result)
    else:
        response.headers['Content-Type'] = content_type
    return result


def jsonpify(func, *args, **kwargs):
    """A decorator that reformats the output as JSON; or, if the
    *callback* parameter is specified (in the HTTP request), as JSONP.
    
    Very much modelled after pylons.decorators.jsonify .
    """
    data = func(*args, **kwargs)
    return to_jsonp(data)

jsonpify = decorator.decorator(jsonpify)


########NEW FILE########
__FILENAME__ = mailer
import smtplib
import logging
import uuid
from time import time
from email.mime.text import MIMEText
from email.header import Header
from email import Utils
from urlparse import urljoin

from pylons import config
import paste.deploy.converters

import ckan
import ckan.model as model
import ckan.lib.helpers as h

from ckan.common import _, g

log = logging.getLogger(__name__)

class MailerException(Exception):
    pass

def add_msg_niceties(recipient_name, body, sender_name, sender_url):
    return _(u"Dear %s,") % recipient_name \
           + u"\r\n\r\n%s\r\n\r\n" % body \
           + u"--\r\n%s (%s)" % (sender_name, sender_url)

def _mail_recipient(recipient_name, recipient_email,
        sender_name, sender_url, subject,
        body, headers={}):
    mail_from = config.get('smtp.mail_from')
    body = add_msg_niceties(recipient_name, body, sender_name, sender_url)
    msg = MIMEText(body.encode('utf-8'), 'plain', 'utf-8')
    for k, v in headers.items(): msg[k] = v
    subject = Header(subject.encode('utf-8'), 'utf-8')
    msg['Subject'] = subject
    msg['From'] = _("%s <%s>") % (sender_name, mail_from)
    recipient = u"%s <%s>" % (recipient_name, recipient_email)
    msg['To'] = Header(recipient, 'utf-8')
    msg['Date'] = Utils.formatdate(time())
    msg['X-Mailer'] = "CKAN %s" % ckan.__version__

    # Send the email using Python's smtplib.
    smtp_connection = smtplib.SMTP()
    if 'smtp.test_server' in config:
        # If 'smtp.test_server' is configured we assume we're running tests,
        # and don't use the smtp.server, starttls, user, password etc. options.
        smtp_server = config['smtp.test_server']
        smtp_starttls = False
        smtp_user = None
        smtp_password = None
    else:
        smtp_server = config.get('smtp.server', 'localhost')
        smtp_starttls = paste.deploy.converters.asbool(
                config.get('smtp.starttls'))
        smtp_user = config.get('smtp.user')
        smtp_password = config.get('smtp.password')
    smtp_connection.connect(smtp_server)
    try:
        #smtp_connection.set_debuglevel(True)

        # Identify ourselves and prompt the server for supported features.
        smtp_connection.ehlo()

        # If 'smtp.starttls' is on in CKAN config, try to put the SMTP
        # connection into TLS mode.
        if smtp_starttls:
            if smtp_connection.has_extn('STARTTLS'):
                smtp_connection.starttls()
                # Re-identify ourselves over TLS connection.
                smtp_connection.ehlo()
            else:
                raise MailerException("SMTP server does not support STARTTLS")

        # If 'smtp.user' is in CKAN config, try to login to SMTP server.
        if smtp_user:
            assert smtp_password, ("If smtp.user is configured then "
                    "smtp.password must be configured as well.")
            smtp_connection.login(smtp_user, smtp_password)

        smtp_connection.sendmail(mail_from, [recipient_email], msg.as_string())
        log.info("Sent email to {0}".format(recipient_email))

    except smtplib.SMTPException, e:
        msg = '%r' % e
        log.exception(msg)
        raise MailerException(msg)
    finally:
        smtp_connection.quit()

def mail_recipient(recipient_name, recipient_email, subject,
        body, headers={}):
    return _mail_recipient(recipient_name, recipient_email,
            g.site_title, g.site_url, subject, body, headers=headers)

def mail_user(recipient, subject, body, headers={}):
    if (recipient.email is None) or not len(recipient.email):
        raise MailerException(_("No recipient email address available!"))
    mail_recipient(recipient.display_name, recipient.email, subject,
            body, headers=headers)

def get_reset_link_body(user):
    reset_link_message = _(
    "You have requested your password on {site_title} to be reset.\n"
    "\n"
    "Please click the following link to confirm this request:\n"
    "\n"
    "   {reset_link}\n"
    )

    d = {
        'reset_link': get_reset_link(user),
        'site_title': g.site_title
        }
    return reset_link_message.format(**d)

def get_invite_body(user):
    invite_message = _(
    "You have been invited to {site_title}. A user has already been created"
    "to you with the username {user_name}. You can change it later.\n"
    "\n"
    "To accept this invite, please reset your password at:\n"
    "\n"
    "   {reset_link}\n"
    )

    d = {
        'reset_link': get_reset_link(user),
        'site_title': g.site_title,
        'user_name': user.name,
        }
    return invite_message.format(**d)

def get_reset_link(user):
    return urljoin(g.site_url,
                   h.url_for(controller='user',
                           action='perform_reset',
                           id=user.id,
                           key=user.reset_key))

def send_reset_link(user):
    create_reset_key(user)
    body = get_reset_link_body(user)
    subject = _('Reset your password')
    mail_user(user, subject, body)

def send_invite(user):
    create_reset_key(user)
    body = get_invite_body(user)
    subject = _('Invite for {site_title}'.format(site_title=g.site_title))
    mail_user(user, subject, body)

def create_reset_key(user):
    user.reset_key = unicode(make_key())
    model.repo.commit_and_remove()

def make_key():
    return uuid.uuid4().hex[:10]

def verify_reset_link(user, key):
    if not key:
        return False
    if not user.reset_key or len(user.reset_key) < 5:
        return False
    return key.strip() == user.reset_key




########NEW FILE########
__FILENAME__ = maintain
''' This module contains code that helps in maintaining the Ckan codebase. '''

import inspect
import time
import logging
import re

from pylons import c

log = logging.getLogger(__name__)


def deprecated(message=''):
    ''' This is a decorator used to mark functions as deprecated.

    It logs a warning when the function is called. If a message is
    passed it is also logged, this can be useful to indicate for example
    that a different function should be used instead.

    Additionally an exception is raised if the functions docstring does
    not contain the word `deprecated`.'''
    def decorator(fn):
        # When decorating a function check that the docstring is correct.
        if not fn.__doc__ or not re.search(r'\bdeprecated\b',
                                           fn.__doc__, re.IGNORECASE):
            raise Exception('Function %s() in module %s has been deprecated '
                            'but this is not mentioned in the docstring. '
                            'Please update the docstring for the function. '
                            'It must include the word `deprecated`.'
                            % (fn.__name__, fn.__module__))
        # Log deprecated functions
        log.debug('Function %s() in module %s has been deprecated. %s'
                            % (fn.__name__, fn.__module__, message))

        def wrapped(*args, **kw):
            log.warning('Function %s() in module %s has been deprecated '
                         'and will be removed in a later release of ckan. %s'
                         % (fn.__name__, fn.__module__, message))
            return fn(*args, **kw)
        return wrapped
    return decorator

def deprecate_context_item(item_name, message=''):
    ''' Deprecate a named item in the global context object.

    It logs a warning when the item is accessed.  If a mesage is passed, it is
    also logged.  This can be useful to indicate for example that a different
    function should be used instead.

    No warnings are given when an attempt to change or delete the named item
    from the context object.

    Example usage:

    >>> c.facets = "Foobar"
    >>> deprecate_context_item('facets', 'Use `c.search_facets` instead')
    >>> print c.facets
    2012-07-12 13:27:06,294 WARNI [ckan.lib.maintain] c.facets has been deprecated [...]
    Foobar

    This function works by attaching a property to the underlying
    `pylons.util.AttribSafeContextObj` object which provides the storage of the
    context object.  ie - it adds a class-level attribute to the
    `pylons.util.AttribSafeContextObj` at runtime.
    '''

    # we need to store the origional __getattr__ and replace with our own one
    if not hasattr(c.__class__, '__old_getattr__'):
        def custom__getattr__(self, name):
            # get the origional __getattr__ so we can access things
            __old_getattr__ = self.__class__.__dict__['__old_getattr__']
            # see if we have a __depricated_properties__ for this name and
            # if so log a warning
            try:
                depricated = __old_getattr__(self, '__depricated_properties__')
                if name in depricated:
                    log.warn(depricated[name])
            except AttributeError:
                pass
            # return the requested value
            return __old_getattr__(self, name)

        # get store the old __getattr__ method and then replace it
        __old_getattr__ =  getattr(c.__class__, '__getattr__')
        setattr(c.__class__, '__old_getattr__', __old_getattr__)
        setattr(c.__class__, '__getattr__', custom__getattr__)

    # if c.__depricated_properties__ is not set it returns ''
    if not c.__depricated_properties__:
        c.__depricated_properties__ = {}
    c.__depricated_properties__[item_name] = message


def defer_context_item(item_name, function):
    ''' Allows a function to be passed that will be appended to c as a property
    so that it is only called if actually used. '''

    assert hasattr(function, '__call__'), 'must pass a function'
    setattr(c, item_name, property(function))


def timer(params):
    ''' Decorator function for basic performance testing. It logs the time
    taken to call a function.  It can either be used as a basic decorator or an
    array of parameter names can be passed. If parameter names are passed then
    the logging will include the value of the parameter if it is passed to the
    function. '''

    if hasattr(params, '__call__'):
        # this is being used as a simple decorator
        fn = params
        fn_name = '%s.%s' % (fn.__module__, fn.__name__)
        def wrapped(*args, **kw):
            start = time.time()
            result = fn(*args, **kw)
            log.info('Timer: %s %.4f' % (fn_name, time.time() - start))
            return result
        return wrapped

    assert isinstance(params, list)

    def decorator(fn):
        # we have a list of parameter names so we want to find if the parameter
        # is a named one and if so store its position
        args_info = inspect.getargspec(fn)
        params_data = []
        for param in params:
            if param in args_info.args:
                params_data.append((param, args_info.args.index(param)))
            else:
                # it could be passed in keywords
                params_data.append((param))
        fn_name = '%s.%s' % (fn.__module__, fn.__name__)
        def wrapped(*args, **kw):
            # store parameters being used in the call that we want to record
            params = []
            for param in  params_data:
                value = None
                if param[0] in kw:
                    value = kw[param[0]]
                elif len(param) != 1 and len(args) >= param[1]:
                    value = args[param[1]]
                else:
                    continue
                params.append(u'%s=%r' % (param[0], value))
            p = ', '.join(params)
            start = time.time()
            # call the function
            result = fn(*args, **kw)
            log.info('Timer: %s %.4f %s' % (fn_name, time.time() - start, p))
            return result
        return wrapped
    return decorator

########NEW FILE########
__FILENAME__ = munge
# Note these functions are similar to, but separate from name/title mungers
# found in the ckanext importer. That one needs to be stable to prevent
# packages changing name on reimport, but these ones can be changed and
# improved.

import re

from ckan import model

def munge_name(name):
    '''Munges the package name field in case it is not to spec.
    '''
    # remove foreign accents
    if isinstance(name, unicode):
        name = substitute_ascii_equivalents(name)
    # separators become dashes
    name = re.sub('[ .:/]', '-', name)
    # take out not-allowed characters
    name = re.sub('[^a-zA-Z0-9-_]', '', name).lower()
    # keep it within the length spec
    name = _munge_to_length(name, model.PACKAGE_NAME_MIN_LENGTH, model.PACKAGE_NAME_MAX_LENGTH)
    return name

def munge_title_to_name(name):
    '''Munge a package title into a package name.
    '''
    # remove foreign accents
    if isinstance(name, unicode):
        name = substitute_ascii_equivalents(name)
    # convert spaces and separators
    name = re.sub('[ .:/]', '-', name)
    # take out not-allowed characters
    name = re.sub('[^a-zA-Z0-9-_]', '', name).lower()
    # remove doubles
    name = re.sub('--', '-', name)
    # remove leading or trailing hyphens
    name = name.strip('-')
    # if longer than max_length, keep last word if a year
    max_length = model.PACKAGE_NAME_MAX_LENGTH - 5
    # (make length less than max, in case we need a few for '_' chars
    # to de-clash names.)
    if len(name) > max_length:
        year_match = re.match('.*?[_-]((?:\d{2,4}[-/])?\d{2,4})$', name)
        if year_match:
            year = year_match.groups()[0]
            name = '%s-%s' % (name[:(max_length-len(year)-1)], year)
        else:
            name = name[:max_length]
    name = _munge_to_length(name, model.PACKAGE_NAME_MIN_LENGTH, model.PACKAGE_NAME_MAX_LENGTH)
    return name

def substitute_ascii_equivalents(text_unicode):
    # Method taken from: http://code.activestate.com/recipes/251871/
    """This takes a UNICODE string and replaces Latin-1 characters with
        something equivalent in 7-bit ASCII. It returns a plain ASCII string. 
        This function makes a best effort to convert Latin-1 characters into 
        ASCII equivalents. It does not just strip out the Latin-1 characters.
        All characters in the standard 7-bit ASCII range are preserved. 
        In the 8th bit range all the Latin-1 accented letters are converted 
        to unaccented equivalents. Most symbol characters are converted to 
        something meaningful. Anything not converted is deleted.
    """
    char_mapping={0xc0:'A', 0xc1:'A', 0xc2:'A', 0xc3:'A', 0xc4:'A', 0xc5:'A',
        0xc6:'Ae', 0xc7:'C',
        0xc8:'E', 0xc9:'E', 0xca:'E', 0xcb:'E',
        0xcc:'I', 0xcd:'I', 0xce:'I', 0xcf:'I',
        0xd0:'Th', 0xd1:'N',
        0xd2:'O', 0xd3:'O', 0xd4:'O', 0xd5:'O', 0xd6:'O', 0xd8:'O',
        0xd9:'U', 0xda:'U', 0xdb:'U', 0xdc:'U',
        0xdd:'Y', 0xde:'th', 0xdf:'ss',
        0xe0:'a', 0xe1:'a', 0xe2:'a', 0xe3:'a', 0xe4:'a', 0xe5:'a',
        0xe6:'ae', 0xe7:'c',
        0xe8:'e', 0xe9:'e', 0xea:'e', 0xeb:'e',
        0xec:'i', 0xed:'i', 0xee:'i', 0xef:'i',
        0xf0:'th', 0xf1:'n',
        0xf2:'o', 0xf3:'o', 0xf4:'o', 0xf5:'o', 0xf6:'o', 0xf8:'o',
        0xf9:'u', 0xfa:'u', 0xfb:'u', 0xfc:'u',
        0xfd:'y', 0xfe:'th', 0xff:'y',
        #0xa1:'!', 0xa2:'{cent}', 0xa3:'{pound}', 0xa4:'{currency}',
        #0xa5:'{yen}', 0xa6:'|', 0xa7:'{section}', 0xa8:'{umlaut}',
        #0xa9:'{C}', 0xaa:'{^a}', 0xab:'<<', 0xac:'{not}',
        #0xad:'-', 0xae:'{R}', 0xaf:'_', 0xb0:'{degrees}',
        #0xb1:'{+/-}', 0xb2:'{^2}', 0xb3:'{^3}', 0xb4:"'",
        #0xb5:'{micro}', 0xb6:'{paragraph}', 0xb7:'*', 0xb8:'{cedilla}',
        #0xb9:'{^1}', 0xba:'{^o}', 0xbb:'>>', 
        #0xbc:'{1/4}', 0xbd:'{1/2}', 0xbe:'{3/4}', 0xbf:'?',
        #0xd7:'*', 0xf7:'/'
        }

    r = ''
    for char in text_unicode:
        if char_mapping.has_key(ord(char)):
            r += char_mapping[ord(char)]
        elif ord(char) >= 0x80:
            pass
        else:
            r += str(char)
    return r


def munge_tag(tag):
    tag = substitute_ascii_equivalents(tag)
    tag = tag.lower().strip()
    tag = re.sub(r'[^a-zA-Z0-9 ]', '', tag).replace(' ', '-')
    tag = _munge_to_length(tag, model.MIN_TAG_LENGTH, model.MAX_TAG_LENGTH)
    return tag

def munge_filename(filename):
    filename = substitute_ascii_equivalents(filename)
    filename = filename.strip()
    filename = re.sub(r'[^a-zA-Z0-9. ]', '', filename).replace(' ', '-')
    filename = _munge_to_length(filename, 3, 100)
    return filename

def _munge_to_length(string, min_length, max_length):
    '''Pad/truncates a string'''
    if len(string) < min_length:
        string += '_' * (min_length - len(string))
    if len(string) > max_length:
        string = string[:max_length]
    return string
    

########NEW FILE########
__FILENAME__ = dictization_functions
import copy
import formencode as fe
import inspect
import json
from pylons import config

from ckan.common import _

class Missing(object):
    def __unicode__(self):
        raise Invalid(_('Missing value'))
    def __str__(self):
        raise Invalid(_('Missing value'))
    def __int__(self):
        raise Invalid(_('Missing value'))
    def __complex__(self):
        raise Invalid(_('Missing value'))
    def __long__(self):
        raise Invalid(_('Missing value'))
    def __float__(self):
        raise Invalid(_('Missing value'))
    def __oct__(self):
        raise Invalid(_('Missing value'))
    def __hex__(self):
        raise Invalid(_('Missing value'))
    def __nonzero__(self):
        return False

missing = Missing()

class State(object):
    pass

class DictizationError(Exception):
    def __str__(self):
        if hasattr(self, 'error') and self.error:
            return repr(self.error)
        return ''

class Invalid(DictizationError):
    '''Exception raised by some validator, converter and dictization functions
    when the given value is invalid.

    '''
    def __init__(self, error, key=None):
        self.error = error

class DataError(DictizationError):
    def __init__(self, error):
        self.error = error

class StopOnError(DictizationError):
    '''error to stop validations for a particualar key'''
    pass

def flattened_order_key(key):
    '''order by key length first then values'''

    return tuple([len(key)] + list(key))

def flatten_schema(schema, flattened=None, key=None):
    '''convert schema into flat dict where the keys are tuples'''

    flattened = flattened or {}
    old_key = key or []

    for key, value in schema.iteritems():
        new_key = old_key + [key]
        if isinstance(value, dict):
            flattened = flatten_schema(value, flattened, new_key)
        else:
            flattened[tuple(new_key)] = value

    return flattened

def get_all_key_combinations(data, flattented_schema):
    '''Compare the schema against the given data and get all valid tuples that
    match the schema ignoring the last value in the tuple.

    '''
    schema_prefixes = set([key[:-1] for key in flattented_schema])
    combinations = set([()])

    for key in sorted(data.keys(), key=flattened_order_key):
        ## make sure the tuple key is a valid one in the schema
        key_prefix = key[:-1:2]
        if key_prefix not in schema_prefixes:
            continue
        ## make sure the parent key exists, this is assured by sorting the keys
        ## first
        if tuple(tuple(key[:-3])) not in combinations:
            continue
        combinations.add(tuple(key[:-1]))

    return combinations

def make_full_schema(data, schema):
    '''make schema by getting all valid combinations and making sure that all keys
    are available'''

    flattented_schema = flatten_schema(schema)

    key_combinations = get_all_key_combinations(data, flattented_schema)

    full_schema = {}

    for combination in key_combinations:
        sub_schema = schema
        for key in combination[::2]:
            sub_schema = sub_schema[key]

        for key, value in sub_schema.iteritems():
            if isinstance(value, list):
                full_schema[combination + (key,)] = value

    return full_schema

def augment_data(data, schema):
    '''add missing, extras and junk data'''
    flattented_schema = flatten_schema(schema)
    key_combinations = get_all_key_combinations(data, flattented_schema)

    full_schema = make_full_schema(data, schema)

    new_data = copy.copy(data)

    ## fill junk and extras

    for key, value in new_data.items():
        if key in full_schema:
            continue

        ## check if any thing naugthy is placed against subschemas
        initial_tuple = key[::2]
        if initial_tuple in [initial_key[:len(initial_tuple)]
                             for initial_key in flattented_schema]:
            if data[key] <> []:
                raise DataError('Only lists of dicts can be placed against '
                                'subschema %s, not %s' % (key,type(data[key])))

        if key[:-1] in key_combinations:
            extras_key = key[:-1] + ('__extras',)
            extras = new_data.get(extras_key, {})
            extras[key[-1]] = value
            new_data[extras_key] = extras
        else:
            junk = new_data.get(("__junk",), {})
            junk[key] = value
            new_data[("__junk",)] = junk
        new_data.pop(key)

    ## add missing

    for key, value in full_schema.items():
        if key not in new_data and not key[-1].startswith("__"):
            new_data[key] = missing

    return new_data

def convert(converter, key, converted_data, errors, context):

    if inspect.isclass(converter) and issubclass(converter, fe.Validator):
        try:
            value = converted_data.get(key)
            value = converter().to_python(value, state=context)
        except fe.Invalid, e:
            errors[key].append(e.msg)
        return

    if isinstance(converter, fe.Validator):
        try:
            value = converted_data.get(key)
            value = converter.to_python(value, state=context)
        except fe.Invalid, e:
            errors[key].append(e.msg)
        return

    try:
        value = converter(converted_data.get(key))
        converted_data[key] = value
        return
    except TypeError, e:
        ## hack to make sure the type error was caused by the wrong
        ## number of arguments given.
        if not converter.__name__ in str(e):
            raise
    except Invalid, e:
        errors[key].append(e.error)
        return

    try:
        converter(key, converted_data, errors, context)
        return
    except Invalid, e:
        errors[key].append(e.error)
        return
    except TypeError, e:
        ## hack to make sure the type error was caused by the wrong
        ## number of arguments given.
        if not converter.__name__ in str(e):
            raise

    try:
        value = converter(converted_data.get(key), context)
        converted_data[key] = value
        return
    except Invalid, e:
        errors[key].append(e.error)
        return

def _remove_blank_keys(schema):

    for key, value in schema.items():
        if isinstance(value[0], dict):
            for item in value:
                _remove_blank_keys(item)
            if not any(value):
                schema.pop(key)

    return schema

def validate(data, schema, context=None):
    '''Validate an unflattened nested dict against a schema.'''
    context = context or {}

    assert isinstance(data, dict)

    # store any empty lists in the data as they will get stripped out by
    # the _validate function. We do this so we can differentiate between
    # empty fields and missing fields when doing partial updates.
    empty_lists = [key for key, value in data.items() if value == []]

    flattened = flatten_dict(data)
    converted_data, errors = _validate(flattened, schema, context)
    converted_data = unflatten(converted_data)

    # check config for partial update fix option
    if config.get('ckan.fix_partial_updates', True):
        # repopulate the empty lists
        for key in empty_lists:
            if key not in converted_data:
                converted_data[key] = []

    errors_unflattened = unflatten(errors)

    ##remove validators that passed
    dicts_to_process = [errors_unflattened]
    while dicts_to_process:
        dict_to_process = dicts_to_process.pop()
        for key, value in dict_to_process.items():
            if not value:
                dict_to_process.pop(key)
                continue
            if isinstance(value[0], dict):
                dicts_to_process.extend(value)

    _remove_blank_keys(errors_unflattened)

    return converted_data, errors_unflattened

def validate_flattened(data, schema, context=None):

    context = context or {}
    assert isinstance(data, dict)
    converted_data, errors = _validate(data, schema, context)

    for key, value in errors.items():
        if not value:
            errors.pop(key)

    return converted_data, errors


def _validate(data, schema, context):
    '''validate a flattened dict against a schema'''
    converted_data = augment_data(data, schema)
    full_schema = make_full_schema(data, schema)

    errors = dict((key, []) for key in full_schema)

    ## before run
    for key in sorted(full_schema, key=flattened_order_key):
        if key[-1] == '__before':
            for converter in full_schema[key]:
                try:
                    convert(converter, key, converted_data, errors, context)
                except StopOnError:
                    break

    ## main run
    for key in sorted(full_schema, key=flattened_order_key):
        if not key[-1].startswith('__'):
            for converter in full_schema[key]:
                try:
                    convert(converter, key, converted_data, errors, context)
                except StopOnError:
                    break

    ## extras run
    for key in sorted(full_schema, key=flattened_order_key):
        if key[-1] == '__extras':
            for converter in full_schema[key]:
                try:
                    convert(converter, key, converted_data, errors, context)
                except StopOnError:
                    break

    ## after run
    for key in reversed(sorted(full_schema, key=flattened_order_key)):
        if key[-1] == '__after':
            for converter in full_schema[key]:
                try:
                    convert(converter, key, converted_data, errors, context)
                except StopOnError:
                    break

    ## junk
    if ('__junk',) in full_schema:
        for converter in full_schema[('__junk',)]:
            try:
                convert(converter, ('__junk',), converted_data, errors, context)
            except StopOnError:
                break

    return converted_data, errors


def flatten_list(data, flattened=None, old_key=None):
    '''flatten a list of dicts'''

    flattened = flattened or {}
    old_key = old_key or []

    for num, value in enumerate(data):
        if not isinstance(value, dict):
            raise DataError('Values in lists need to be dicts')
        new_key = old_key + [num]
        flattened = flatten_dict(value, flattened, new_key)

    return flattened

def flatten_dict(data, flattened=None, old_key=None):
    '''flatten a dict'''

    flattened = flattened or {}
    old_key = old_key or []

    for key, value in data.iteritems():
        new_key = old_key + [key]
        if isinstance(value, list) and value and isinstance(value[0], dict):
            flattened = flatten_list(value, flattened, new_key)
        else:
            flattened[tuple(new_key)] = value

    return flattened


def unflatten(data):
    '''Unflatten a simple dict whose keys are tuples.

    e.g.
    >>> unflatten(
      {('name',): u'testgrp4',
       ('title',): u'',
       ('description',): u'',
       ('packages', 0, 'name'): u'testpkg',
       ('packages', 1, 'name'): u'testpkg',
       ('extras', 0, 'key'): u'packages',
       ('extras', 0, 'value'): u'["testpkg"]',
       ('extras', 1, 'key'): u'',
       ('extras', 1, 'value'): u'',
       ('state',): u'active'
       ('save',): u'Save Changes',
       ('cancel',): u'Cancel'})
    {'name': u'testgrp4',
     'title': u'',
     'description': u'',
     'packages': [{'name': u'testpkg'}, {'name': u'testpkg'}],
     'extras': [{'key': u'packages', 'value': u'["testpkg"]'},
                {'key': u'', 'value': u''}],
     'state': u'active',
     'save': u'Save Changes',
     'cancel': u'Cancel'}
    '''

    unflattened = {}
    convert_to_list = []

    for flattend_key in sorted(data.keys(), key=flattened_order_key):
        current_pos = unflattened

        if (len(flattend_key) > 1
            and not flattend_key[0] in convert_to_list
            and not flattend_key[0] in unflattened):
            convert_to_list.append(flattend_key[0])

        for key in flattend_key[:-1]:
            try:
                current_pos = current_pos[key]
            except KeyError:
                new_pos = {}
                current_pos[key] = new_pos
                current_pos = new_pos
        current_pos[flattend_key[-1]] = data[flattend_key]

    for key in convert_to_list:
        unflattened[key] = [unflattened[key][s] for s in sorted(unflattened[key])]

    return unflattened


class MissingNullEncoder(json.JSONEncoder):
    '''json encoder that treats missing objects as null'''
    def default(self, obj):
        if isinstance(obj, Missing):
            return None
        return json.JSONEncoder.default(self, obj)

########NEW FILE########
__FILENAME__ = validators
import ckan.lib.navl.dictization_functions as df

from ckan.common import _

missing = df.missing
StopOnError = df.StopOnError
Invalid = df.Invalid


def identity_converter(key, data, errors, context):
    return

def keep_extras(key, data, errors, context):

    extras = data.pop(key, {})
    for extras_key, value in extras.iteritems():
        data[key[:-1] + (extras_key,)] = value

def not_missing(key, data, errors, context):

    value = data.get(key)
    if value is missing:
        errors[key].append(_('Missing value'))
        raise StopOnError

def not_empty(key, data, errors, context):

    value = data.get(key)
    if not value or value is missing:
        errors[key].append(_('Missing value'))
        raise StopOnError

def if_empty_same_as(other_key):

    def callable(key, data, errors, context):
        value = data.get(key)
        if not value or value is missing:
            data[key] = data[key[:-1] + (other_key,)]

    return callable


def both_not_empty(other_key):

    def callable(key, data, errors, context):
        value = data.get(key)
        other_value = data.get(key[:-1] + (other_key,))
        if (not value or value is missing and
            not other_value or other_value is missing):
            errors[key].append(_('Missing value'))
            raise StopOnError

    return callable

def empty(key, data, errors, context):

    value = data.pop(key, None)
    
    if value and value is not missing:
        errors[key].append(_(
            'The input field %(name)s was not expected.') % {"name": key[-1]})

def ignore(key, data, errors, context):

    value = data.pop(key, None)
    raise StopOnError

def default(default_value):

    def callable(key, data, errors, context):

        value = data.get(key)
        if not value or value is missing:
            data[key] = default_value

    return callable

def ignore_missing(key, data, errors, context):
    '''If the key is missing from the data, ignore the rest of the key's
    schema.

    By putting ignore_missing at the start of the schema list for a key,
    you can allow users to post a dict without the key and the dict will pass
    validation. But if they post a dict that does contain the key, then any
    validators after ignore_missing in the key's schema list will be applied.

    :raises ckan.lib.navl.dictization_functions.StopOnError: if ``data[key]``
        is :py:data:`ckan.lib.navl.dictization_functions.missing` or ``None``

    :returns: ``None``

    '''
    value = data.get(key)

    if value is missing or value is None:
        data.pop(key, None)
        raise StopOnError

def ignore_empty(key, data, errors, context):

    value = data.get(key)

    if value is missing or not value:
        data.pop(key, None)
        raise StopOnError

def convert_int(value, context):

    try:
        return int(value)
    except ValueError:
        raise Invalid(_('Please enter an integer value'))


########NEW FILE########
__FILENAME__ = package_saver
import ckan.lib.helpers as h
import ckan.lib.base as base
import ckan.model as model
import ckan.rating

from ckan.common import g, c, _

# Todo: Factor out unused original_name argument.

class PackageSaver(object):
    '''Use this to validate and save packages to the db.
    @param log_message: optional - only supply this if you want it validated
    @param author: optional - only supply this if you want it validated
    '''

    # TODO: rename to something more correct like prepare_for_render
    @classmethod
    def render_package(cls, pkg, context):
        '''Prepares for rendering a package. Takes a Package object and
        formats it for the various context variables required to call
        render. 
        Note that the actual calling of render('package/read') is left
        to the caller.'''
        c.pkg_notes_formatted = h.render_markdown(pkg.get('notes'))

        c.current_rating, c.num_ratings = ckan.rating.get_rating(context['package'])
        url = pkg.get('url', '')
        c.pkg_url_link = h.link_to(url, url, rel='foaf:homepage', target='_blank') \
                if url else _("No web page given")

        c.pkg_author_link = cls._person_email_link(
                name=pkg.get('author'), email=pkg.get('author_email'),
                fallback=_("Author not given"))
        c.pkg_maintainer_link = cls._person_email_link(
                name=pkg.get('maintainer'), email=pkg.get('maintainer_email'),
                fallback=_("Maintainer not given"))

        c.package_relationships = context['package'].get_relationships_printable()
        c.pkg_extras = []
        for extra in sorted(pkg.get('extras',[]), key=lambda x:x['key']):
            if extra.get('state') == 'deleted':
                continue
            k, v = extra['key'], extra['value']
            if k in g.package_hide_extras:
                continue
            if isinstance(v, (list, tuple)):
                v = ", ".join(map(unicode, v))
            c.pkg_extras.append((k, v))
        if context.get('revision_id') or context.get('revision_date'):
            # request was for a specific revision id or date
            c.pkg_revision_id = c.pkg_dict[u'revision_id']
            c.pkg_revision_timestamp = c.pkg_dict[u'revision_timestamp']
            c.pkg_revision_not_latest = c.pkg_dict[u'revision_id'] != c.pkg.revision.id

    @classmethod
    def commit_pkg(cls, fs, log_message, author, client=None):
        '''Writes the POST data (associated with a package edit) to the
        database
        @input c.error
        @input fs      FieldSet with the param data bound to it
        '''
        cls._update(fs, log_message, author, client=client)

    @classmethod
    def _update(cls, fs, log_message, author, client=None):
        # Todo: Consolidate log message field (and validation).
        rev = None
        # validation
        errors = cls._revision_validation(log_message)
        if client:
            client.errors = errors
        fs.validate()
        validates = not (errors or fs.errors)
        if not validates:
            raise base.ValidationException(fs)
        # sync
        try:
            rev = model.repo.new_revision()
            rev.author = author
            rev.message = log_message
            fs.sync()
        except Exception:
            model.Session.rollback()
            raise
        else:
            # only commit if it validates ok
            if validates:
                model.Session.commit()

    @classmethod
    def _revision_validation(cls, log_message):
        errors = []
        if log_message and 'http:' in log_message:
            errors.append(_('No links are allowed in the log_message.'))
        return errors

    @classmethod
    def _person_email_link(cls, name, email, fallback):
        if email:
            return h.mail_to(email_address=email, name=name or email,
                    encode='hex')
        else:
            return name or fallback

class WritePackageFromBoundFieldset(object):

    def __init__(self, fieldset, log_message='', author='', client=None):
        self.fieldset = fieldset
        self.log_message = log_message
        self.author = author
        self.client = None
        self.write_package()

    def write_package(self):
        PackageSaver().commit_pkg(self.fieldset, self.log_message, self.author, self.client)


########NEW FILE########
__FILENAME__ = plugins
import logging

from pylons import c
from ckan.lib import base
import ckan.lib.maintain as maintain
from ckan import logic
import logic.schema
from ckan import plugins
import ckan.new_authz
import ckan.plugins.toolkit as toolkit

log = logging.getLogger(__name__)

# Mapping from package-type strings to IDatasetForm instances
_package_plugins = {}
# The fallback behaviour
_default_package_plugin = None

# Mapping from group-type strings to IDatasetForm instances
_group_plugins = {}
# The fallback behaviour
_default_group_plugin = None


def reset_package_plugins():
    global _default_package_plugin
    _default_package_plugin = None
    global _package_plugins
    _package_plugins = {}
    global _default_group_plugin
    _default_group_plugin = None
    global _group_plugins
    _group_plugins = {}


def lookup_package_plugin(package_type=None):
    """
    Returns the plugin controller associoated with the given package type.

    If the package type is None or cannot be found in the mapping, then the
    fallback behaviour is used.
    """
    if package_type is None:
        return _default_package_plugin
    return _package_plugins.get(package_type, _default_package_plugin)


def lookup_group_plugin(group_type=None):
    """
    Returns the plugin controller associoated with the given group type.

    If the group type is None or cannot be found in the mapping, then the
    fallback behaviour is used.
    """
    if group_type is None:
        return _default_group_plugin
    return _group_plugins.get(group_type, _default_organization_plugin
        if group_type == 'organization' else _default_group_plugin)


def register_package_plugins(map):
    """
    Register the various IDatasetForm instances.

    This method will setup the mappings between package types and the
    registered IDatasetForm instances. If it's called more than once an
    exception will be raised.
    """
    global _default_package_plugin

    # This function should have not effect if called more than once.
    # This should not occur in normal deployment, but it may happen when
    # running unit tests.
    if _default_package_plugin is not None:
        return

    # Create the mappings and register the fallback behaviour if one is found.
    for plugin in plugins.PluginImplementations(plugins.IDatasetForm):
        if plugin.is_fallback():
            if _default_package_plugin is not None:
                raise ValueError, "More than one fallback "\
                                  "IDatasetForm has been registered"
            _default_package_plugin = plugin

        for package_type in plugin.package_types():
            # Create a connection between the newly named type and the
            # package controller

            map.connect('%s_search' % package_type, '/%s' % package_type,
                        controller='package', action='search')

            map.connect('%s_new' % package_type, '/%s/new' % package_type,
                        controller='package', action='new')
            map.connect('%s_read' % package_type, '/%s/{id}' % package_type,
                        controller='package', action='read')

            for action in ['edit', 'authz', 'history']:
                map.connect('%s_%s' % (package_type, action),
                        '/%s/%s/{id}' % (package_type, action),
                        controller='package',
                        action=action
                )

            if package_type in _package_plugins:
                raise ValueError, "An existing IDatasetForm is "\
                                  "already associated with the package type "\
                                  "'%s'" % package_type
            _package_plugins[package_type] = plugin

    # Setup the fallback behaviour if one hasn't been defined.
    if _default_package_plugin is None:
        _default_package_plugin = DefaultDatasetForm()


def register_group_plugins(map):
    """
    Register the various IGroupForm instances.

    This method will setup the mappings between group types and the
    registered IGroupForm instances. If it's called more than once an
    exception will be raised.
    """
    global _default_group_plugin

    # This function should have not effect if called more than once.
    # This should not occur in normal deployment, but it may happen when
    # running unit tests.
    if _default_group_plugin is not None:
        return

    # Create the mappings and register the fallback behaviour if one is found.
    for plugin in plugins.PluginImplementations(plugins.IGroupForm):
        if plugin.is_fallback():
            if _default_group_plugin is not None:
                raise ValueError, "More than one fallback "\
                                  "IGroupForm has been registered"
            _default_group_plugin = plugin

        for group_type in plugin.group_types():
            # Create the routes based on group_type here, this will
            # allow us to have top level objects that are actually
            # Groups, but first we need to make sure we are not
            # clobbering an existing domain

            # Our version of routes doesn't allow the environ to be
            # passed into the match call and so we have to set it on the
            # map instead. This looks like a threading problem waiting
            # to happen but it is executed sequentially from inside the
            # routing setup

            map.connect('%s_index' % group_type, '/%s' % group_type,
                        controller='group', action='index')
            map.connect('%s_new' % group_type, '/%s/new' % group_type,
                        controller='group', action='new')
            map.connect('%s_read' % group_type, '/%s/{id}' % group_type,
                        controller='group', action='read')
            map.connect('%s_action' % group_type,
                        '/%s/{action}/{id}' % group_type, controller='group',
                requirements=dict(action='|'.join(['edit', 'authz', 'history']))
            )

            if group_type in _group_plugins:
                raise ValueError, "An existing IGroupForm is "\
                                  "already associated with the group type "\
                                  "'%s'" % group_type
            _group_plugins[group_type] = plugin

    # Setup the fallback behaviour if one hasn't been defined.
    if _default_group_plugin is None:
        _default_group_plugin = DefaultGroupForm()


def plugin_validate(plugin, context, data_dict, schema, action):
    """
    Backwards compatibility with 2.x dataset group and org plugins:
    return a default validate method if one has not been provided.
    """
    if hasattr(plugin, 'validate'):
        result = plugin.validate(context, data_dict, schema, action)
        if result is not None:
            return result

    return toolkit.navl_validate(data_dict, schema, context)


class DefaultDatasetForm(object):
    '''The default implementation of
    :py:class:`~ckan.plugins.interfaces.IDatasetForm`.

    This class serves two purposes:

    1. It provides a base class for plugin classes that implement
       :py:class:`~ckan.plugins.interfaces.IDatasetForm` to inherit from, so
       they can inherit the default behavior and just modify the bits they
       need to.

    2. It is used as the default fallback plugin when no registered
       :py:class:`~ckan.plugins.interfaces.IDatasetForm` plugin handles the
       given dataset type and no other plugin has registered itself as the
       fallback plugin.

    .. note::

       :py:class:`~ckan.plugins.toolkit.DefaultDatasetForm` doesn't call
       :py:func:`~ckan.plugins.core.implements`, because we don't want it
       being registered.

    '''
    def create_package_schema(self):
        return ckan.logic.schema.default_create_package_schema()

    def update_package_schema(self):
        return ckan.logic.schema.default_update_package_schema()

    def show_package_schema(self):
        return ckan.logic.schema.default_show_package_schema()

    def setup_template_variables(self, context, data_dict):
        authz_fn = logic.get_action('group_list_authz')
        c.groups_authz = authz_fn(context, data_dict)
        data_dict.update({'available_only': True})

        c.groups_available = authz_fn(context, data_dict)

        c.licenses = [('', '')] + base.model.Package.get_license_options()
        # CS: bad_spelling ignore 2 lines
        c.licences = c.licenses
        maintain.deprecate_context_item('licences', 'Use `c.licenses` instead')
        c.is_sysadmin = ckan.new_authz.is_sysadmin(c.user)

        if c.pkg:
            c.related_count = c.pkg.related_count

        ## This is messy as auths take domain object not data_dict
        context_pkg = context.get('package', None)
        pkg = context_pkg or c.pkg
        if pkg:
            try:
                if not context_pkg:
                    context['package'] = pkg
                logic.check_access('package_change_state', context)
                c.auth_for_change_state = True
            except logic.NotAuthorized:
                c.auth_for_change_state = False

    def new_template(self):
        return 'package/new.html'

    def read_template(self):
        return 'package/read.html'

    def edit_template(self):
        return 'package/edit.html'

    def search_template(self):
        return 'package/search.html'

    def history_template(self):
        return 'package/history.html'

    def package_form(self):
        return 'package/new_package_form.html'


class DefaultGroupForm(object):
    """
    Provides a default implementation of the pluggable Group controller
    behaviour.

    This class has 2 purposes:

     - it provides a base class for IGroupForm implementations to use if
       only a subset of the method hooks need to be customised.

     - it provides the fallback behaviour if no plugin is setup to
       provide the fallback behaviour.

    Note - this isn't a plugin implementation. This is deliberate, as we
           don't want this being registered.
    """
    def new_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the 'new' page
        """
        return 'group/new.html'

    def index_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the index page
        """
        return 'group/index.html'

    def read_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the read page
        """
        return 'group/read.html'

    def about_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the about page
        """
        return 'group/about.html'

    def history_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the history page
        """
        return 'group/history.html'

    def edit_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the edit page
        """
        return 'group/edit.html'

    def activity_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the activity stream page
        """
        return 'group/activity_stream.html'

    def admins_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the admins page
        """
        return 'group/admins.html'

    def bulk_process_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the bulk_process page
        """
        return 'group/bulk_process.html'

    def about_template(self):
        '''Return the path to the template for the group's 'about' page.

        :rtype: string

        '''
        return 'group/about.html'

    def group_form(self):
        return 'group/new_group_form.html'

    def form_to_db_schema_options(self, options):
        ''' This allows us to select different schemas for different
        purpose eg via the web interface or via the api or creation vs
        updating. It is optional and if not available form_to_db_schema
        should be used.
        If a context is provided, and it contains a schema, it will be
        returned.
        '''
        schema = options.get('context', {}).get('schema', None)
        if schema:
            return schema

        if options.get('api'):
            if options.get('type') == 'create':
                return self.form_to_db_schema_api_create()
            else:
                return self.form_to_db_schema_api_update()
        else:
            return self.form_to_db_schema()

    def form_to_db_schema_api_create(self):
        return logic.schema.default_group_schema()

    def form_to_db_schema_api_update(self):
        return logic.schema.default_update_group_schema()

    def form_to_db_schema(self):
        return logic.schema.group_form_schema()

    def db_to_form_schema(self):
        '''This is an interface to manipulate data from the database
        into a format suitable for the form (optional)'''

    def db_to_form_schema_options(self, options):
        '''This allows the selectino of different schemas for different
        purposes.  It is optional and if not available, ``db_to_form_schema``
        should be used.
        If a context is provided, and it contains a schema, it will be
        returned.
        '''
        schema = options.get('context', {}).get('schema', None)
        if schema:
            return schema
        return self.db_to_form_schema()

    def check_data_dict(self, data_dict):
        '''Check if the return data is correct, mostly for checking out
        if spammers are submitting only part of the form

        # Resources might not exist yet (eg. Add Dataset)
        surplus_keys_schema = ['__extras', '__junk', 'state', 'groups',
                               'extras_validation', 'save', 'return_to',
                               'resources']

        schema_keys = form_to_db_package_schema().keys()
        keys_in_schema = set(schema_keys) - set(surplus_keys_schema)

        missing_keys = keys_in_schema - set(data_dict.keys())

        if missing_keys:
            #print data_dict
            #print missing_keys
            log.info('incorrect form fields posted')
            raise DataError(data_dict)
        '''
        pass

    def setup_template_variables(self, context, data_dict):
        c.is_sysadmin = ckan.new_authz.is_sysadmin(c.user)

        ## This is messy as auths take domain object not data_dict
        context_group = context.get('group', None)
        group = context_group or c.group
        if group:
            try:
                if not context_group:
                    context['group'] = group
                logic.check_access('group_change_state', context)
                c.auth_for_change_state = True
            except logic.NotAuthorized:
                c.auth_for_change_state = False


class DefaultOrganizationForm(DefaultGroupForm):
    def group_form(self):
        return 'organization/new_organization_form.html'

    def setup_template_variables(self, context, data_dict):
        pass

    def new_template(self):
        return 'organization/new.html'

    def about_template(self):
        return 'organization/about.html'

    def index_template(self):
        return 'organization/index.html'

    def admins_template(self):
        return 'organization/admins.html'

    def bulk_process_template(self):
        return 'organization/bulk_process.html'

    def read_template(self):
        return 'organization/read.html'

    # don't override history_template - use group template for history

    def edit_template(self):
        return 'organization/edit.html'

    def activity_template(self):
        return 'organization/activity_stream.html'

_default_organization_plugin = DefaultOrganizationForm()

########NEW FILE########
__FILENAME__ = render
import os
import re

from pylons import config

_template_info_cache = {}

def reset_template_info_cache():
    '''Reset the template cache'''
    _template_info_cache.clear()

def find_template(template_name):
    ''' looks through the possible template paths to find a template
    returns the full path is it exists. '''
    template_paths = config['pylons.app_globals'].template_paths
    for path in template_paths:
        if os.path.exists(os.path.join(path, template_name.encode('utf-8'))):
            return os.path.join(path, template_name)

def template_type(template_path):
    ''' returns best guess for template type
    returns 'jinja2', 'genshi', 'genshi-text' '''
    if template_path.endswith('.txt'):
        return 'genshi-text'
    try:
        f = open(template_path, 'r')
    except IOError:
        # do the import here due to circular import hell functions like
        # abort should be in a none circular importing file but that
        # refactor has not yet happened
        import ckan.lib.base as base
        base.abort(404)
    source = f.read()
    f.close()
    if re.search('genshi\.edgewall\.org', source):
        return 'genshi'
    return 'jinja2'

class TemplateNotFound(Exception):
    pass

def template_info(template_name):
    ''' Returns the path and type for a template '''

    if template_name in _template_info_cache:
        t_data = _template_info_cache[template_name]
        return t_data['template_path'], t_data['template_type']

    template_path = find_template(template_name)
    if not template_path:
        raise TemplateNotFound('Template %s cannot be found' % template_name)
    t_type = template_type(template_path)

    # if in debug mode we always want to search for templates so we
    # don't want to store it.
    if not config.get('debug', False):
        t_data = {'template_path' : template_path,
                  'template_type' : t_type,}
        _template_info_cache[template_name] = t_data
    return template_path, t_type

########NEW FILE########
__FILENAME__ = repoze_patch
from webob import Request, Response
from openid.consumer import consumer
from openid.extensions import sreg, ax

# #1659 fix - logged_out_url prefixed with mount point
def get_full_path(path, environ):
    if path.startswith('/'):
        path = environ.get('SCRIPT_NAME', '') + path
    return path

def identify(self, environ):
    """this method is called when a request is incoming.

    After the challenge has been called we might get here a response
    from an openid provider.

    """

    request = Request(environ)
    logger = environ['repoze.who.logger']
    # #1659 fix - Use PATH_INFO rather than request.path as the former
    #             strips off the mount point.
    path = environ['PATH_INFO']

    # first test for logout as we then don't need the rest
    if path == self.logout_handler_path:
        res = Response()
        # set forget headers
        for a,v in self.forget(environ,{}):
            res.headers.add(a,v)
        res.status = 302
        url = self.logged_out_url + '?came_from=' + environ.get('came_from')
        res.location = get_full_path(url, environ)

        environ['repoze.who.application'] = res
        return {}

    identity = {}

    # first we check we are actually on the URL which is supposed to be the
    # url to return to (login_handler_path in configuration)
    # this URL is used for both: the answer for the login form and
    # when the openid provider redirects the user back.
    if path == self.login_handler_path:

    # in the case we are coming from the login form we should have
    # an openid in here the user entered
        open_id = request.params.get(self.openid_field, None)
        if logger:
            logger.debug('checking openid results for : %s ' %open_id)

        if open_id is not None:
            open_id = open_id.strip()

        # we don't do anything with the openid we found ourselves but we put it in here
        # to tell the challenge plugin to initiate the challenge
        identity['repoze.whoplugins.openid.openid'] = open_id
        environ['repoze.whoplugins.openid.openid'] = open_id

        # this part now is for the case when the openid provider redirects
        # the user back. We should find some openid specific fields in the request.
        mode=request.params.get("openid.mode", None)
        if mode=="id_res":
            oidconsumer = self.get_consumer(environ)
            info = oidconsumer.complete(request.params, request.url)
            if info.status == consumer.SUCCESS:

                fr = ax.FetchResponse.fromSuccessResponse(info)
                if fr is not None:
                    items = chain(self.ax_require.items(), self.ax_optional.items())
                    for key, value in items:
                        try:
                            identity['repoze.who.plugins.openid.' + key] = fr.get(value)
                        except KeyError:
                            pass

                fr = sreg.SRegResponse.fromSuccessResponse(info)
                if fr is not None:
                    items = chain(self.sreg_require, self.sreg_optional)
                    for key in items:
                        try:
                            identity['repoze.who.plugins.openid.' + key] = fr.get(key)
                        except KeyError:
                            pass

                if logger:
                    logger.info('openid request successful for : %s ' %open_id)

                display_identifier = info.identity_url

                # remove this so that the challenger is not triggered again
                del environ['repoze.whoplugins.openid.openid']

                # store the id for the authenticator
                identity['repoze.who.plugins.openid.userid'] = display_identifier

                # now redirect to came_from or the success page
                self.redirect_to_logged_in(environ)
                return identity

            # TODO: Do we have to check for more failures and such?
            #
        elif mode=="cancel":
            # cancel is a negative assertion in the OpenID protocol,
            # which means the user did not authorize correctly.
            environ['repoze.whoplugins.openid.error'] = 'OpenID authentication failed.'
            pass
    return identity

def redirect_to_logged_in(self, environ):
    """redirect to came_from or standard page if login was successful"""
    request = Request(environ)
    came_from = request.params.get(self.came_from_field,'')
    if came_from!='':
        url = came_from
    else:
        url = get_full_path(self.logged_in_url, environ)
    res = Response()
    res.status = 302
    res.location = url
    environ['repoze.who.application'] = res

def challenge(self, environ, status, app_headers, forget_headers):
    """the challenge method is called when the ``IChallengeDecider``
    in ``classifiers.py`` returns ``True``. This is the case for either a
    ``401`` response from the client or if the key
    ``repoze.whoplugins.openid.openidrepoze.whoplugins.openid.openid``
    is present in the WSGI environment.
    The name of this key can be adjusted via the ``openid_field`` configuration
    directive.

    The latter is the case when we are coming from the login page where the
    user entered the openid to use.

    ``401`` can come back in any case and then we simply redirect to the login
    form which is configured in the who configuration as ``login_form_url``.

    TODO: make the environment key to check also configurable in the challenge_decider.

    For the OpenID flow check `the OpenID library documentation
    <http://openidenabled.com/files/python-openid/docs/2.2.1/openid.consumer.consumer-module.html>`_

    """
    request = Request(environ)
    logger = environ['repoze.who.logger']

    # check for the field present, if not redirect to login_form
    if not request.params.has_key(self.openid_field):
        # redirect to login_form
        res = Response()
        res.status = 302
        res.location = get_full_path(self.login_form_url, environ)+"?%s=%s" %(self.came_from_field, request.url)
        return res

    # now we have an openid from the user in the request
    openid_url = request.params[self.openid_field]
    if logger:
        logger.debug('starting openid request for : %s ' %openid_url)

    try:
    # we create a new Consumer and start the discovery process for the URL given
    # in the library openid_request is called auth_req btw.
        openid_request = self.get_consumer(environ).begin(openid_url)

        if len(self.ax_require.values()) or len(self.ax_optional.values()):
            fetch_request = ax.FetchRequest()
            for value in self.ax_require.values():
                fetch_request.add(ax.AttrInfo(value, required=True))
            for value in self.ax_optional.values():
                fetch_request.add(ax.AttrInfo(value, required=False))
            openid_request.addExtension(fetch_request)

        if len(self.sreg_require) or len(self.sreg_optional):
            sreq = sreg.SRegRequest(required=self.sreg_require, optional=self.sreg_optional)
            openid_request.addExtension(sreq)


    except consumer.DiscoveryFailure, exc:
        # eventually no openid server could be found
        environ[self.error_field] = 'Error in discovery: %s' %exc[0]
        if logger:
            logger.info('Error in discovery: %s ' %exc[0])
        return self._redirect_to_loginform(environ)
    except KeyError, exc:
        # TODO: when does that happen, why does plone.openid use "pass" here?
        environ[self.error_field] = 'Error in discovery: %s' %exc[0]
        if logger:
            logger.info('Error in discovery: %s ' %exc[0])
        return self._redirect_to_loginform(environ)
        return None

    # not sure this can still happen but we are making sure.
    # should actually been handled by the DiscoveryFailure exception above
    if openid_request is None:
        environ[self.error_field] = 'No OpenID services found for %s' %openid_url
        if logger:
            logger.info('No OpenID services found for: %s ' %openid_url)
        return self._redirect_to_loginform(environ)

    # we have to tell the openid provider where to send the user after login
    # so we need to compute this from our path and application URL
    # we simply use the URL we are at right now (which is the form)
    # this will be captured by the repoze.who identification plugin later on
    # it will check if some valid openid response is coming back
    # trust_root is the URL (realm) which will be presented to the user
    # in the login process and should be your applications url
    # TODO: make this configurable?
    # return_to is the actual URL to be used for returning to this app
    return_to = request.path_url # we return to this URL here
    trust_root = request.application_url
    if logger:
        logger.debug('setting return_to URL to : %s ' %return_to)

    # TODO: usually you should check openid_request.shouldSendRedirect()
    # but this might say you have to use a form redirect and I don't get why
    # so we do the same as plone.openid and ignore it.

    # TODO: we might also want to give the application some way of adding
    # extensions to this message.
    redirect_url = openid_request.redirectURL(trust_root, return_to)
    # # , immediate=False)
    res = Response()
    res.status = 302
    res.location = redirect_url
    if logger:
        logger.debug('redirecting to : %s ' %redirect_url)

    # now it's redirecting and might come back via the identify() method
    # from the openid provider once the user logged in there.
    return res


def _redirect_to_loginform(self, environ={}):
    """redirect the user to the login form"""
    res = Response()
    res.status = 302
    q=''
    ef = environ.get(self.error_field, None)
    if ef is not None:
            q='?%s=%s' %(self.error_field, ef)
    res.location = get_full_path(self.login_form_url, environ)+q
    return res

########NEW FILE########
__FILENAME__ = common
from pylons import config
import logging
log = logging.getLogger(__name__)


class SearchIndexError(Exception):
    pass


class SearchError(Exception):
    pass


class SearchQueryError(SearchError):
    pass

DEFAULT_SOLR_URL = 'http://127.0.0.1:8983/solr'


class SolrSettings(object):
    _is_initialised = False
    _url = None
    _user = None
    _password = None

    @classmethod
    def init(cls, url, user=None, password=None):
        if url is not None:
            cls._url = url
            cls._user = user
            cls._password = password
        else:
            cls._url = DEFAULT_SOLR_URL
        cls._is_initialised = True

    @classmethod
    def get(cls):
        if not cls._is_initialised:
            raise SearchIndexError('SOLR URL not initialised')
        if not cls._url:
            raise SearchIndexError('SOLR URL is blank')
        return (cls._url, cls._user, cls._password)


def is_available():
    """
    Return true if we can successfully connect to Solr.
    """
    try:
        conn = make_connection()
        conn.query("*:*", rows=1)
    except Exception, e:
        log.exception(e)
        return False
    finally:
        if 'conn' in dir():
            conn.close()

    return True


def make_connection():
    from solr import SolrConnection
    solr_url, solr_user, solr_password = SolrSettings.get()
    assert solr_url is not None
    if solr_user is not None and solr_password is not None:
        return SolrConnection(solr_url, http_user=solr_user,
                              http_pass=solr_password)
    else:
        return SolrConnection(solr_url)

########NEW FILE########
__FILENAME__ = index
import socket
import string
import logging
import collections
import json
from dateutil.parser import parse

import re

import solr

from pylons import config
from paste.deploy.converters import asbool

from common import SearchIndexError, make_connection
from ckan.model import PackageRelationship
import ckan.model as model
from ckan.plugins import (PluginImplementations,
                          IPackageController)
import ckan.logic as logic
import ckan.lib.plugins as lib_plugins
import ckan.lib.navl.dictization_functions

log = logging.getLogger(__name__)

_validate = ckan.lib.navl.dictization_functions.validate

TYPE_FIELD = "entity_type"
PACKAGE_TYPE = "package"
KEY_CHARS = string.digits + string.letters + "_-"
SOLR_FIELDS = [TYPE_FIELD, "res_url", "text", "urls", "indexed_ts", "site_id"]
RESERVED_FIELDS = SOLR_FIELDS + ["tags", "groups", "res_description",
                                 "res_format", "res_url"]
RELATIONSHIP_TYPES = PackageRelationship.types

# Regular expression used to strip invalid XML characters
_illegal_xml_chars_re = re.compile(u'[\x00-\x08\x0b\x0c\x0e-\x1F\uD800-\uDFFF\uFFFE\uFFFF]')

def escape_xml_illegal_chars(val, replacement=''):
    '''
        Replaces any character not supported by XML with
        a replacement string (default is an empty string)
        Thanks to http://goo.gl/ZziIz
    '''
    return _illegal_xml_chars_re.sub(replacement, val)


def clear_index():
    import solr.core
    conn = make_connection()
    query = "+site_id:\"%s\"" % (config.get('ckan.site_id'))
    try:
        conn.delete_query(query)
        conn.commit()
    except socket.error, e:
        err = 'Could not connect to SOLR %r: %r' % (conn.url, e)
        log.error(err)
        raise SearchIndexError(err)
    except solr.core.SolrException, e:
        err = 'SOLR %r exception: %r' % (conn.url, e)
        log.error(err)
        raise SearchIndexError(err)
    finally:
        conn.close()

class SearchIndex(object):
    """
    A search index handles the management of documents of a specific type in the
    index, but no queries.
    The default implementation maps many of the methods, so most subclasses will
    only have to implement ``update_dict`` and ``remove_dict``.
    """

    def __init__(self):
        pass

    def insert_dict(self, data):
        """ Insert new data from a dictionary. """
        return self.update_dict(data)

    def update_dict(self, data):
        """ Update data from a dictionary. """
        log.debug("NOOP Index: %s" % ",".join(data.keys()))

    def remove_dict(self, data):
        """ Delete an index entry uniquely identified by ``data``. """
        log.debug("NOOP Delete: %s" % ",".join(data.keys()))

    def clear(self):
        """ Delete the complete index. """
        clear_index()

    def get_all_entity_ids(self):
        """ Return a list of entity IDs in the index. """
        raise NotImplemented

class NoopSearchIndex(SearchIndex): pass

class PackageSearchIndex(SearchIndex):
    def remove_dict(self, pkg_dict):
        self.delete_package(pkg_dict)

    def update_dict(self, pkg_dict, defer_commit=False):
        self.index_package(pkg_dict, defer_commit)

    def index_package(self, pkg_dict, defer_commit=False):
        if pkg_dict is None:
            return

        pkg_dict['data_dict'] = json.dumps(pkg_dict)

        if config.get('ckan.cache_validated_datasets', True):
            package_plugin = lib_plugins.lookup_package_plugin(
                pkg_dict.get('type'))

            schema = package_plugin.show_package_schema()
            validated_pkg_dict, errors = _validate(pkg_dict, schema, {
                'model': model, 'session': model.Session})
            pkg_dict['validated_data_dict'] = json.dumps(validated_pkg_dict,
                cls=ckan.lib.navl.dictization_functions.MissingNullEncoder)

        # add to string field for sorting
        title = pkg_dict.get('title')
        if title:
            pkg_dict['title_string'] = title

        if (not pkg_dict.get('state')) or ('active' not in pkg_dict.get('state')):
            return self.delete_package(pkg_dict)

        index_fields = RESERVED_FIELDS + pkg_dict.keys()

        # include the extras in the main namespace
        extras = pkg_dict.get('extras', [])
        for extra in extras:
            key, value = extra['key'], extra['value']
            if isinstance(value, (tuple, list)):
                value = " ".join(map(unicode, value))
            key = ''.join([c for c in key if c in KEY_CHARS])
            pkg_dict['extras_' + key] = value
            if key not in index_fields:
                pkg_dict[key] = value
        pkg_dict.pop('extras', None)

        # add tags, removing vocab tags from 'tags' list and adding them as
        # vocab_<tag name> so that they can be used in facets
        non_vocab_tag_names = []
        tags = pkg_dict.pop('tags', [])
        context = {'model': model}

        for tag in tags:
            if tag.get('vocabulary_id'):
                data = {'id': tag['vocabulary_id']}
                vocab = logic.get_action('vocabulary_show')(context, data)
                key = u'vocab_%s' % vocab['name']
                if key in pkg_dict:
                    pkg_dict[key].append(tag['name'])
                else:
                    pkg_dict[key] = [tag['name']]
            else:
                non_vocab_tag_names.append(tag['name'])

        pkg_dict['tags'] = non_vocab_tag_names

        # add groups
        groups = pkg_dict.pop('groups', [])

        # we use the capacity to make things private in the search index
        if pkg_dict['private']:
            pkg_dict['capacity'] = 'private'
        else:
            pkg_dict['capacity'] = 'public'

        pkg_dict['groups'] = [group['name'] for group in groups]

        # if there is an owner_org we want to add this to groups for index
        # purposes
        if pkg_dict.get('organization'):
           pkg_dict['organization'] = pkg_dict['organization']['name']
        else:
           pkg_dict['organization'] = None

        # tracking
        tracking_summary = pkg_dict.pop('tracking_summary', None)
        if tracking_summary:
            pkg_dict['views_total'] = tracking_summary['total']
            pkg_dict['views_recent'] = tracking_summary['recent']

        # flatten the structure for indexing:
        for resource in pkg_dict.get('resources', []):
            for (okey, nkey) in [('description', 'res_description'),
                                 ('format', 'res_format'),
                                 ('url', 'res_url')]:
                pkg_dict[nkey] = pkg_dict.get(nkey, []) + [resource.get(okey, u'')]
        pkg_dict.pop('resources', None)

        rel_dict = collections.defaultdict(list)
        subjects = pkg_dict.pop("relationships_as_subject", [])
        objects = pkg_dict.pop("relationships_as_object", [])
        for rel in objects:
            type = model.PackageRelationship.forward_to_reverse_type(rel['type'])
            rel_dict[type].append(model.Package.get(rel['subject_package_id']).name)
        for rel in subjects:
            type = rel['type']
            rel_dict[type].append(model.Package.get(rel['object_package_id']).name)
        for key, value in rel_dict.iteritems():
            if key not in pkg_dict:
                pkg_dict[key] = value

        pkg_dict[TYPE_FIELD] = PACKAGE_TYPE

        # Save dataset type
        pkg_dict['dataset_type'] = pkg_dict['type']

        # clean the dict fixing keys and dates
        # FIXME where are we getting these dirty keys from?  can we not just
        # fix them in the correct place or is this something that always will
        # be needed?  For my data not changing the keys seems to not cause a
        # problem.
        new_dict = {}
        for key, value in pkg_dict.items():
            key = key.encode('ascii', 'ignore')
            if key.endswith('_date'):
                try:
                    value = parse(value).isoformat() + 'Z'
                except ValueError:
                    continue
            new_dict[key] = value
        pkg_dict = new_dict

        for k in ('title', 'notes', 'title_string'):
            if k in pkg_dict and pkg_dict[k]:
                pkg_dict[k] = escape_xml_illegal_chars(pkg_dict[k])

        # modify dates (SOLR is quite picky with dates, and only accepts ISO dates
        # with UTC time (i.e trailing Z)
        # See http://lucene.apache.org/solr/api/org/apache/solr/schema/DateField.html
        pkg_dict['metadata_created'] += 'Z'
        pkg_dict['metadata_modified'] += 'Z'

        # mark this CKAN instance as data source:
        pkg_dict['site_id'] = config.get('ckan.site_id')

        # Strip a selection of the fields.
        # These fields are possible candidates for sorting search results on,
        # so we strip leading spaces because solr will sort " " before "a" or "A".
        for field_name in ['title']:
            try:
                value = pkg_dict.get(field_name)
                if value:
                    pkg_dict[field_name] = value.lstrip()
            except KeyError:
                pass

        # add a unique index_id to avoid conflicts
        import hashlib
        pkg_dict['index_id'] = hashlib.md5('%s%s' % (pkg_dict['id'],config.get('ckan.site_id'))).hexdigest()

        for item in PluginImplementations(IPackageController):
            pkg_dict = item.before_index(pkg_dict)

        assert pkg_dict, 'Plugin must return non empty package dict on index'

        # send to solr:
        try:
            conn = make_connection()
            commit = not defer_commit
            if not asbool(config.get('ckan.search.solr_commit', 'true')):
                commit = False
            conn.add_many([pkg_dict], _commit=commit)
        except solr.core.SolrException, e:
            msg = 'Solr returned an error: {0} {1} - {2}'.format(
                e.httpcode, e.reason, e.body[:1000] # limit huge responses
            )
            raise SearchIndexError(msg)
        except socket.error, e:
            err = 'Could not connect to Solr using {0}: {1}'.format(conn.url, str(e))
            log.error(err)
            raise SearchIndexError(err)
        finally:
            conn.close()

        commit_debug_msg = 'Not commited yet' if defer_commit else 'Commited'
        log.debug('Updated index for %s [%s]' % (pkg_dict.get('name'), commit_debug_msg))

    def commit(self):
        try:
            conn = make_connection()
            conn.commit(wait_searcher=False)
        except Exception, e:
            log.exception(e)
            raise SearchIndexError(e)
        finally:
            conn.close()


    def delete_package(self, pkg_dict):
        conn = make_connection()
        query = "+%s:%s (+id:\"%s\" OR +name:\"%s\") +site_id:\"%s\"" % (TYPE_FIELD, PACKAGE_TYPE,
                                                       pkg_dict.get('id'), pkg_dict.get('id'),
                                                       config.get('ckan.site_id'))
        try:
            conn.delete_query(query)
            if asbool(config.get('ckan.search.solr_commit', 'true')):
                conn.commit()
        except Exception, e:
            log.exception(e)
            raise SearchIndexError(e)
        finally:
            conn.close()

########NEW FILE########
__FILENAME__ = query
import re
import logging

from pylons import config
from solr import SolrException
from paste.deploy.converters import asbool
from paste.util.multidict import MultiDict

from ckan.common import json
from ckan.lib.search.common import make_connection, SearchError, SearchQueryError
import ckan.logic as logic
import ckan.model as model

log = logging.getLogger(__name__)

_open_licenses = None

VALID_SOLR_PARAMETERS = set([
    'q', 'fl', 'fq', 'rows', 'sort', 'start', 'wt', 'qf', 'bf', 'boost',
    'facet', 'facet.mincount', 'facet.limit', 'facet.field',
    'extras', 'fq_list', 'tie', 'defType', 'mm'
])

# for (solr) package searches, this specifies the fields that are searched
# and their relative weighting
QUERY_FIELDS = "name^4 title^4 tags^2 groups^2 text"

solr_regex = re.compile(r'([\\+\-&|!(){}\[\]^"~*?:])')

def escape_legacy_argument(val):
    # escape special chars \+-&|!(){}[]^"~*?:
    return solr_regex.sub(r'\\\1', val)

def convert_legacy_parameters_to_solr(legacy_params):
    '''API v1 and v2 allowed search params that the SOLR syntax does not
    support, so use this function to convert those to SOLR syntax.
    See tests for examples.

    raises SearchQueryError on invalid params.
    '''
    options = QueryOptions(**legacy_params)
    options.validate()
    solr_params = legacy_params.copy()
    solr_q_list = []
    if solr_params.get('q'):
        solr_q_list.append(solr_params['q'].replace('+', ' '))
    non_solr_params = set(legacy_params.keys()) - VALID_SOLR_PARAMETERS
    for search_key in non_solr_params:
        value_obj = legacy_params[search_key]
        value = value_obj.replace('+', ' ') if isinstance(value_obj, basestring) else value_obj
        if search_key == 'all_fields':
            if value:
                solr_params['fl'] = '*'
        elif search_key == 'offset':
            solr_params['start'] = value
        elif search_key == 'limit':
            solr_params['rows'] = value
        elif search_key == 'order_by':
            solr_params['sort'] = '%s asc' % value
        elif search_key == 'tags':
            if isinstance(value_obj, list):
                tag_list = value_obj
            elif isinstance(value_obj, basestring):
                tag_list = [value_obj]
            else:
                raise SearchQueryError('Was expecting either a string or JSON list for the tags parameter: %r' % value)
            solr_q_list.extend(['tags:"%s"' % escape_legacy_argument(tag) for tag in tag_list])
        else:
            if len(value.strip()):
                value = escape_legacy_argument(value)
                if ' ' in value:
                    value = '"%s"' % value
                solr_q_list.append('%s:%s' % (search_key, value))
        del solr_params[search_key]
    solr_params['q'] = ' '.join(solr_q_list)
    if non_solr_params:
        log.debug('Converted legacy search params from %r to %r',
                 legacy_params, solr_params)
    return solr_params


class QueryOptions(dict):
    """
    Options specify aspects of the search query which are only tangentially related
    to the query terms (such as limits, etc.).
    NB This is used only by legacy package search and current resource & tag search.
       Modern SOLR package search leaves this to SOLR syntax.
    """

    BOOLEAN_OPTIONS = ['all_fields']
    INTEGER_OPTIONS = ['offset', 'limit']
    UNSUPPORTED_OPTIONS = ['filter_by_downloadable', 'filter_by_openness']

    def __init__(self, **kwargs):
        from ckan.lib.search import DEFAULT_OPTIONS

        # set values according to the defaults
        for option_name, default_value in DEFAULT_OPTIONS.items():
            if not option_name in self:
                self[option_name] = default_value

        super(QueryOptions, self).__init__(**kwargs)

    def validate(self):
        for key, value in self.items():
            if key in self.BOOLEAN_OPTIONS:
                try:
                    value = asbool(value)
                except ValueError:
                    raise SearchQueryError('Value for search option %r must be True or False (1 or 0) but received %r' % (key, value))
            elif key in self.INTEGER_OPTIONS:
                try:
                    value = int(value)
                except ValueError:
                    raise SearchQueryError('Value for search option %r must be an integer but received %r' % (key, value))
            elif key in self.UNSUPPORTED_OPTIONS:
                    raise SearchQueryError('Search option %r is not supported' % key)
            self[key] = value

    def __getattr__(self, name):
        return self.get(name)

    def __setattr__(self, name, value):
        self[name] = value


class SearchQuery(object):
    """
    A query is ... when you ask the search engine things. SearchQuery is intended
    to be used for only one query, i.e. it sets state. Definitely not thread-safe.
    """

    def __init__(self):
        self.results = []
        self.count = 0

    @property
    def open_licenses(self):
        # this isn't exactly the very best place to put these, but they stay
        # there persistently.
        # TODO: figure out if they change during run-time.
        global _open_licenses
        if not isinstance(_open_licenses, list):
            _open_licenses = []
            for license in model.Package.get_license_register().values():
                if license and license.isopen():
                    _open_licenses.append(license.id)
        return _open_licenses

    def get_all_entity_ids(self, max_results=1000):
        """
        Return a list of the IDs of all indexed packages.
        """
        return []

    def run(self, query=None, terms=[], fields={}, facet_by=[], options=None, **kwargs):
        raise SearchError("SearchQuery.run() not implemented!")

    # convenience, allows to query(..)
    __call__ = run


class TagSearchQuery(SearchQuery):
    """Search for tags."""
    def run(self, query=None, fields=None, options=None, **kwargs):
        query = [] if query is None else query
        fields = {} if fields is None else fields

        if options is None:
            options = QueryOptions(**kwargs)
        else:
            options.update(kwargs)

        if isinstance(query, basestring):
            query = [query]

        query = query[:] # don't alter caller's query list.
        for field, value in fields.items():
            if field in ('tag', 'tags'):
                query.append(value)

        context = {'model': model, 'session': model.Session}
        data_dict = {
            'query': query,
            'offset': options.get('offset'),
            'limit': options.get('limit')
        }
        results = logic.get_action('tag_search')(context, data_dict)

        if not options.return_objects:
            # if options.all_fields is set, return a dict
            # if not, return a list of resource IDs
            if options.all_fields:
                results['results'] = [r.as_dict() for r in results['results']]
            else:
                results['results'] = [r['name'] for r in results['results']]

        self.count = results['count']
        self.results = results['results']
        return results


class ResourceSearchQuery(SearchQuery):
    """Search for resources."""
    def run(self, fields={}, options=None, **kwargs):
        if options is None:
            options = QueryOptions(**kwargs)
        else:
            options.update(kwargs)

        context = {
            'model':model,
            'session': model.Session,
            'search_query': True,
        }

        # Transform fields into structure required by the resource_search
        # action.
        query = []
        for field, terms in fields.items():
            if isinstance(terms, basestring):
                terms = terms.split()
            for term in terms:
                query.append(':'.join([field, term]))

        data_dict = {
            'query': query,
            'offset': options.get('offset'),
            'limit': options.get('limit'),
            'order_by': options.get('order_by')
        }
        results = logic.get_action('resource_search')(context, data_dict)

        if not options.return_objects:
            # if options.all_fields is set, return a dict
            # if not, return a list of resource IDs
            if options.all_fields:
                results['results'] = [r.as_dict() for r in results['results']]
            else:
                results['results'] = [r.id for r in results['results']]

        self.count = results['count']
        self.results = results['results']
        return results


class PackageSearchQuery(SearchQuery):
    def get_all_entity_ids(self, max_results=1000):
        """
        Return a list of the IDs of all indexed packages.
        """
        query = "*:*"
        fq = "+site_id:\"%s\" " % config.get('ckan.site_id')
        fq += "+state:active "

        conn = make_connection()
        try:
            data = conn.query(query, fq=fq, rows=max_results, fields='id')
        finally:
            conn.close()

        return [r.get('id') for r in data.results]

    def get_index(self,reference):
        query = {
            'rows': 1,
            'q': 'name:%s OR id:%s' % (reference,reference),
            'wt': 'json',
            'fq': 'site_id:"%s"' % config.get('ckan.site_id')}

        conn = make_connection()
        log.debug('Package query: %r' % query)
        try:
            solr_response = conn.raw_query(**query)
        except SolrException, e:
            raise SearchError('SOLR returned an error running query: %r Error: %r' %
                              (query, e.reason))
        try:
            data = json.loads(solr_response)

            if data['response']['numFound'] == 0:
                raise SearchError('Dataset not found in the search index: %s' % reference)
            else:
                return data['response']['docs'][0]
        except Exception, e:
            if not isinstance(e, SearchError):
                log.exception(e)
            raise SearchError(e)
        finally:
            conn.close()


    def run(self, query):
        '''
        Performs a dataset search using the given query.

        @param query - dictionary with keys like: q, fq, sort, rows, facet
        @return - dictionary with keys results and count

        May raise SearchQueryError or SearchError.
        '''
        assert isinstance(query, (dict, MultiDict))
        # check that query keys are valid
        if not set(query.keys()) <= VALID_SOLR_PARAMETERS:
            invalid_params = [s for s in set(query.keys()) - VALID_SOLR_PARAMETERS]
            raise SearchQueryError("Invalid search parameters: %s" % invalid_params)

        # default query is to return all documents
        q = query.get('q')
        if not q or q == '""' or q == "''":
            query['q'] = "*:*"

        # number of results
        rows_to_return = min(1000, int(query.get('rows', 10)))
        if rows_to_return > 0:
            # #1683 Work around problem of last result being out of order
            #       in SOLR 1.4
            rows_to_query = rows_to_return + 1
        else:
            rows_to_query = rows_to_return
        query['rows'] = rows_to_query

        # show only results from this CKAN instance
        fq = query.get('fq', '')
        if not '+site_id:' in fq:
            fq += ' +site_id:"%s"' % config.get('ckan.site_id')

        # filter for package status
        if not '+state:' in fq:
            fq += " +state:active"
        query['fq'] = [fq]

        fq_list = query.get('fq_list', [])
        query['fq'].extend(fq_list)

        # faceting
        query['facet'] = query.get('facet', 'true')
        query['facet.limit'] = query.get('facet.limit', config.get('search.facets.limit', '50'))
        query['facet.mincount'] = query.get('facet.mincount', 1)

        # return the package ID and search scores
        query['fl'] = query.get('fl', 'name')

        # return results as json encoded string
        query['wt'] = query.get('wt', 'json')

        # If the query has a colon in it then consider it a fielded search and do use dismax.
        defType = query.get('defType', 'dismax')
        if ':' not in query['q'] or defType == 'edismax':
            query['defType'] = defType
            query['tie'] = query.get('tie', '0.1')
            # this minimum match is explained
            # http://wiki.apache.org/solr/DisMaxQParserPlugin#mm_.28Minimum_.27Should.27_Match.29
            query['mm'] = query.get('mm', '2<-1 5<80%')
            query['qf'] = query.get('qf', QUERY_FIELDS)


        conn = make_connection()
        log.debug('Package query: %r' % query)
        try:
            solr_response = conn.raw_query(**query)
        except SolrException, e:
            raise SearchError('SOLR returned an error running query: %r Error: %r' %
                              (query, e.reason))
        try:
            data = json.loads(solr_response)
            response = data['response']
            self.count = response.get('numFound', 0)
            self.results = response.get('docs', [])

            # #1683 Filter out the last row that is sometimes out of order
            self.results = self.results[:rows_to_return]

            # get any extras and add to 'extras' dict
            for result in self.results:
                extra_keys = filter(lambda x: x.startswith('extras_'), result.keys())
                extras = {}
                for extra_key in extra_keys:
                    value = result.pop(extra_key)
                    extras[extra_key[len('extras_'):]] = value
                if extra_keys:
                    result['extras'] = extras

            # if just fetching the id or name, return a list instead of a dict
            if query.get('fl') in ['id', 'name']:
                self.results = [r.get(query.get('fl')) for r in self.results]

            # get facets and convert facets list to a dict
            self.facets = data.get('facet_counts', {}).get('facet_fields', {})
            for field, values in self.facets.iteritems():
                self.facets[field] = dict(zip(values[0::2], values[1::2]))
        except Exception, e:
            log.exception(e)
            raise SearchError(e)
        finally:
            conn.close()

        return {'results': self.results, 'count': self.count}

########NEW FILE########
__FILENAME__ = sql
from sqlalchemy import or_
from ckan.lib.search.query import SearchQuery
import ckan.model as model

class PackageSearchQuery(SearchQuery):
    def get_all_entity_ids(self, max_results=100):
        """
        Return a list of the IDs of all indexed packages.
        """
        # could make this a pure sql query which would be much more efficient!
        q = model.Session.query(model.Package).filter_by(state='active').limit(max_results)

        return [r.id for r in q]

    def run(self, query):
        assert isinstance(query, dict)
        # no support for faceting atm
        self.facets = {}
        limit = min(1000, int(query.get('rows', 10)))

        q = query.get('q')
        ourq = model.Session.query(model.Package.id).filter_by(state='active')

        def makelike(field):
            _attr = getattr(model.Package, field)
            return _attr.ilike('%' + term + '%')
        if q and q not in ('""', "''", '*:*'):
            terms = q.split()
            # TODO: tags ...?
            fields = ['name', 'title', 'notes']
            for term in terms:
                args = [makelike(field) for field in fields]
                subq = or_(*args)
                ourq = ourq.filter(subq)
        self.count = ourq.count()
        ourq = ourq.limit(limit)
        self.results = [{'id': r[0]} for r in ourq.all()]

        return {'results': self.results, 'count': self.count}


########NEW FILE########
__FILENAME__ = uploader
import os
import cgi
import pylons
import datetime
import ckan.lib.munge as munge
import logging
import ckan.logic as logic


config = pylons.config
log = logging.getLogger(__name__)

_storage_path = None
_max_resource_size = None
_max_image_size = None


def get_storage_path():
    '''Function to cache storage path'''
    global _storage_path

    #None means it has not been set. False means not in config.
    if _storage_path is None:
        storage_path = config.get('ckan.storage_path')
        ofs_impl = config.get('ofs.impl')
        ofs_storage_dir = config.get('ofs.storage_dir')
        if storage_path:
            _storage_path = storage_path
        elif ofs_impl == 'pairtree' and ofs_storage_dir:
            log.warn('''Please use config option ckan.storage_path instaed of
                     ofs.storage_path''')
            _storage_path = ofs_storage_dir
            return _storage_path
        elif ofs_impl:
            log.critical('''We only support local file storage form version 2.2
                         of ckan please specify ckan.storage_path in your
                         config for your uploads''')
            _storage_path = False
        else:
            log.critical('''Please specify a ckan.storage_path in your config
                         for your uploads''')
            _storage_path = False

    return _storage_path


def get_max_image_size():
    global _max_image_size
    if _max_image_size is None:
        _max_image_size = int(config.get('ckan.max_image_size', 2))
    return _max_image_size


def get_max_resource_size():
    global _max_resource_size
    if _max_resource_size is None:
        _max_resource_size = int(config.get('ckan.max_resource_size', 10))
    return _max_resource_size


class Upload(object):
    def __init__(self, object_type, old_filename=None):
        ''' Setup upload by creating  a subdirectory of the storage directory
        of name object_type. old_filename is the name of the file in the url
        field last time'''

        self.storage_path = None
        self.filename = None
        self.filepath = None
        path = get_storage_path()
        if not path:
            return
        self.storage_path = os.path.join(path, 'storage',
                                         'uploads', object_type)
        try:
            os.makedirs(self.storage_path)
        except OSError, e:
            ## errno 17 is file already exists
            if e.errno != 17:
                raise
        self.object_type = object_type
        self.old_filename = old_filename
        if old_filename:
            self.old_filepath = os.path.join(self.storage_path, old_filename)

    def update_data_dict(self, data_dict, url_field, file_field, clear_field):
        ''' Manipulate data from the data_dict.  url_field is the name of the
        field where the upload is going to be. file_field is name of the key
        where the FieldStorage is kept (i.e the field where the file data
        actually is). clear_field is the name of a boolean field which
        requests the upload to be deleted.  This needs to be called before
        it reaches any validators'''

        self.url = data_dict.get(url_field, '')
        self.clear = data_dict.pop(clear_field, None)
        self.file_field = file_field
        self.upload_field_storage = data_dict.pop(file_field, None)

        if not self.storage_path:
            return

        if isinstance(self.upload_field_storage, cgi.FieldStorage):
            self.filename = self.upload_field_storage.filename
            self.filename = str(datetime.datetime.utcnow()) + self.filename
            self.filename = munge.munge_filename(self.filename)
            self.filepath = os.path.join(self.storage_path, self.filename)
            data_dict[url_field] = self.filename
            self.upload_file = self.upload_field_storage.file
            self.tmp_filepath = self.filepath + '~'
        ### keep the file if there has been no change
        elif self.old_filename and not self.old_filename.startswith('http'):
            if not self.clear:
                data_dict[url_field] = self.old_filename
            if self.clear and self.url == self.old_filename:
                data_dict[url_field] = ''

    def upload(self, max_size=2):
        ''' Actually upload the file.
        This should happen just before a commit but after the data has
        been validated and flushed to the db. This is so we do not store
        anything unless the request is actually good.
        max_size is size in MB maximum of the file'''

        if self.filename:
            output_file = open(self.tmp_filepath, 'wb')
            self.upload_file.seek(0)
            current_size = 0
            while True:
                current_size = current_size + 1
                # MB chuncks
                data = self.upload_file.read(2 ** 20)
                if not data:
                    break
                output_file.write(data)
                if current_size > max_size:
                    os.remove(self.tmp_filepath)
                    raise logic.ValidationError(
                        {self.file_field: ['File upload too large']}
                    )
            output_file.close()
            os.rename(self.tmp_filepath, self.filepath)
            self.clear = True

        if (self.clear and self.old_filename
                and not self.old_filename.startswith('http')):
            try:
                os.remove(self.old_filepath)
            except OSError, e:
                pass


class ResourceUpload(object):
    def __init__(self, resource):
        path = get_storage_path()
        if not path:
            self.storage_path = None
            return
        self.storage_path = os.path.join(path, 'resources')
        try:
            os.makedirs(self.storage_path)
        except OSError, e:
            ## errno 17 is file already exists
            if e.errno != 17:
                raise
        self.filename = None

        url = resource.get('url')
        upload_field_storage = resource.pop('upload', None)
        self.clear = resource.pop('clear_upload', None)

        if isinstance(upload_field_storage, cgi.FieldStorage):
            self.filename = upload_field_storage.filename
            self.filename = munge.munge_filename(self.filename)
            resource['url'] = self.filename
            resource['url_type'] = 'upload'
            self.upload_file = upload_field_storage.file
        elif self.clear:
            resource['url_type'] = ''

    def get_directory(self, id):
        directory = os.path.join(self.storage_path,
                                 id[0:3], id[3:6])
        return directory

    def get_path(self, id):
        directory = self.get_directory(id)
        filepath = os.path.join(directory, id[6:])
        return filepath

    def upload(self, id, max_size=10):
        if not self.storage_path:
            return
        directory = self.get_directory(id)
        filepath = self.get_path(id)
        if self.filename:
            try:
                os.makedirs(directory)
            except OSError, e:
                ## errno 17 is file already exists
                if e.errno != 17:
                    raise
            tmp_filepath = filepath + '~'
            output_file = open(tmp_filepath, 'wb+')
            self.upload_file.seek(0)
            current_size = 0
            while True:
                current_size = current_size + 1
                #MB chunks
                data = self.upload_file.read(2 ** 20)
                if not data:
                    break
                output_file.write(data)
                if current_size > max_size:
                    os.remove(tmp_filepath)
                    raise logic.ValidationError(
                        {'upload': ['File upload too large']}
                    )
            output_file.close()
            os.rename(tmp_filepath, filepath)

        if self.clear:
            try:
                os.remove(filepath)
            except OSError, e:
                pass

########NEW FILE########
__FILENAME__ = create
'''API functions for adding data to CKAN.'''

import logging
import random
import re

from pylons import config
import paste.deploy.converters

import ckan.lib.plugins as lib_plugins
import ckan.logic as logic
import ckan.rating as ratings
import ckan.plugins as plugins
import ckan.lib.dictization
import ckan.logic.action
import ckan.logic.schema
import ckan.lib.dictization.model_dictize as model_dictize
import ckan.lib.dictization.model_save as model_save
import ckan.lib.navl.dictization_functions
import ckan.lib.uploader as uploader
import ckan.lib.navl.validators as validators
import ckan.lib.mailer as mailer

from ckan.common import _

# FIXME this looks nasty and should be shared better
from ckan.logic.action.update import _update_package_relationship

log = logging.getLogger(__name__)

# Define some shortcuts
# Ensure they are module-private so that they don't get loaded as available
# actions in the action API.
_validate = ckan.lib.navl.dictization_functions.validate
_check_access = logic.check_access
_get_action = logic.get_action
ValidationError = logic.ValidationError
NotFound = logic.NotFound
_get_or_bust = logic.get_or_bust


def package_create(context, data_dict):
    '''Create a new dataset (package).

    You must be authorized to create new datasets. If you specify any groups
    for the new dataset, you must also be authorized to edit these groups.

    Plugins may change the parameters of this function depending on the value
    of the ``type`` parameter, see the
    :py:class:`~ckan.plugins.interfaces.IDatasetForm` plugin interface.

    :param name: the name of the new dataset, must be between 2 and 100
        characters long and contain only lowercase alphanumeric characters,
        ``-`` and ``_``, e.g. ``'warandpeace'``
    :type name: string
    :param title: the title of the dataset (optional, default: same as
        ``name``)
    :type title: string
    :param author: the name of the dataset's author (optional)
    :type author: string
    :param author_email: the email address of the dataset's author (optional)
    :type author_email: string
    :param maintainer: the name of the dataset's maintainer (optional)
    :type maintainer: string
    :param maintainer_email: the email address of the dataset's maintainer
        (optional)
    :type maintainer_email: string
    :param license_id: the id of the dataset's license, see
        :py:func:`~ckan.logic.action.get.license_list` for available values
        (optional)
    :type license_id: license id string
    :param notes: a description of the dataset (optional)
    :type notes: string
    :param url: a URL for the dataset's source (optional)
    :type url: string
    :param version: (optional)
    :type version: string, no longer than 100 characters
    :param state: the current state of the dataset, e.g. ``'active'`` or
        ``'deleted'``, only active datasets show up in search results and
        other lists of datasets, this parameter will be ignored if you are not
        authorized to change the state of the dataset (optional, default:
        ``'active'``)
    :type state: string
    :param type: the type of the dataset (optional),
        :py:class:`~ckan.plugins.interfaces.IDatasetForm` plugins
        associate themselves with different dataset types and provide custom
        dataset handling behaviour for these types
    :type type: string
    :param resources: the dataset's resources, see
        :py:func:`resource_create` for the format of resource dictionaries
        (optional)
    :type resources: list of resource dictionaries
    :param tags: the dataset's tags, see :py:func:`tag_create` for the format
        of tag dictionaries (optional)
    :type tags: list of tag dictionaries
    :param extras: the dataset's extras (optional), extras are arbitrary
        (key: value) metadata items that can be added to datasets, each extra
        dictionary should have keys ``'key'`` (a string), ``'value'`` (a
        string)
    :type extras: list of dataset extra dictionaries
    :param relationships_as_object: see :py:func:`package_relationship_create`
        for the format of relationship dictionaries (optional)
    :type relationships_as_object: list of relationship dictionaries
    :param relationships_as_subject: see :py:func:`package_relationship_create`
        for the format of relationship dictionaries (optional)
    :type relationships_as_subject: list of relationship dictionaries
    :param groups: the groups to which the dataset belongs (optional), each
        group dictionary should have one or more of the following keys which
        identify an existing group:
        ``'id'`` (the id of the group, string), ``'name'`` (the name of the
        group, string), ``'title'`` (the title of the group, string), to see
        which groups exist call :py:func:`~ckan.logic.action.get.group_list`
    :type groups: list of dictionaries
    :param owner_org: the id of the dataset's owning organization, see
        :py:func:`~ckan.logic.action.get.organization_list` or
        :py:func:`~ckan.logic.action.get.organization_list_for_user` for
        available values (optional)
    :type owner_org: string

    :returns: the newly created dataset (unless 'return_id_only' is set to True
              in the context, in which case just the dataset id will
              be returned)
    :rtype: dictionary

    '''
    model = context['model']
    user = context['user']

    package_type = data_dict.get('type')
    package_plugin = lib_plugins.lookup_package_plugin(package_type)
    if 'schema' in context:
        schema = context['schema']
    else:
        schema = package_plugin.create_package_schema()

    _check_access('package_create', context, data_dict)

    if 'api_version' not in context:
        # check_data_dict() is deprecated. If the package_plugin has a
        # check_data_dict() we'll call it, if it doesn't have the method we'll
        # do nothing.
        check_data_dict = getattr(package_plugin, 'check_data_dict', None)
        if check_data_dict:
            try:
                check_data_dict(data_dict, schema)
            except TypeError:
                # Old plugins do not support passing the schema so we need
                # to ensure they still work
                package_plugin.check_data_dict(data_dict)

    data, errors = lib_plugins.plugin_validate(
        package_plugin, context, data_dict, schema, 'package_create')
    log.debug('package_create validate_errs=%r user=%s package=%s data=%r',
              errors, context.get('user'),
              data.get('name'), data_dict)

    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    rev = model.repo.new_revision()
    rev.author = user
    if 'message' in context:
        rev.message = context['message']
    else:
        rev.message = _(u'REST API: Create object %s') % data.get("name")

    admins = []
    if user:
        user_obj = model.User.by_name(user.decode('utf8'))
        if user_obj:
            admins = [user_obj]
            data['creator_user_id'] = user_obj.id

    pkg = model_save.package_dict_save(data, context)

    model.setup_default_user_roles(pkg, admins)
    # Needed to let extensions know the package id
    model.Session.flush()
    data['id'] = pkg.id

    context_org_update = context.copy()
    context_org_update['ignore_auth'] = True
    context_org_update['defer_commit'] = True
    _get_action('package_owner_org_update')(context_org_update,
                                            {'id': pkg.id,
                                             'organization_id': pkg.owner_org})

    for item in plugins.PluginImplementations(plugins.IPackageController):
        item.create(pkg)

        item.after_create(context, data)

    if not context.get('defer_commit'):
        model.repo.commit()

    ## need to let rest api create
    context["package"] = pkg
    ## this is added so that the rest controller can make a new location
    context["id"] = pkg.id
    log.debug('Created object %s' % pkg.name)

    # Make sure that a user provided schema is not used on package_show
    context.pop('schema', None)

    return_id_only = context.get('return_id_only', False)

    output = context['id'] if return_id_only \
        else _get_action('package_show')(context, {'id': context['id']})

    return output


def resource_create(context, data_dict):
    '''Appends a new resource to a datasets list of resources.

    :param package_id: id of package that the resource should be added to.
    :type package_id: string
    :param url: url of resource
    :type url: string
    :param revision_id: (optional)
    :type revision_id: string
    :param description: (optional)
    :type description: string
    :param format: (optional)
    :type format: string
    :param hash: (optional)
    :type hash: string
    :param name: (optional)
    :type name: string
    :param resource_type: (optional)
    :type resource_type: string
    :param mimetype: (optional)
    :type mimetype: string
    :param mimetype_inner: (optional)
    :type mimetype_inner: string
    :param webstore_url: (optional)
    :type webstore_url: string
    :param cache_url: (optional)
    :type cache_url: string
    :param size: (optional)
    :type size: int
    :param created: (optional)
    :type created: iso date string
    :param last_modified: (optional)
    :type last_modified: iso date string
    :param cache_last_updated: (optional)
    :type cache_last_updated: iso date string
    :param webstore_last_updated: (optional)
    :type webstore_last_updated: iso date string
    :param upload: (optional)
    :type upload: FieldStorage (optional) needs multipart/form-data

    :returns: the newly created resource
    :rtype: dictionary

    '''
    model = context['model']
    user = context['user']

    package_id = _get_or_bust(data_dict, 'package_id')
    data_dict.pop('package_id')
    _get_or_bust(data_dict, 'url')

    pkg_dict = _get_action('package_show')(context, {'id': package_id})

    _check_access('resource_create', context, data_dict)

    if not 'resources' in pkg_dict:
        pkg_dict['resources'] = []

    upload = uploader.ResourceUpload(data_dict)

    pkg_dict['resources'].append(data_dict)

    try:
        context['defer_commit'] = True
        context['use_cache'] = False
        _get_action('package_update')(context, pkg_dict)
        context.pop('defer_commit')
    except ValidationError, e:
        errors = e.error_dict['resources'][-1]
        raise ValidationError(errors)

    ## Get out resource_id resource from model as it will not appear in
    ## package_show until after commit
    upload.upload(context['package'].resources[-1].id,
                  uploader.get_max_resource_size())
    model.repo.commit()

    ##  Run package show again to get out actual last_resource
    pkg_dict = _get_action('package_show')(context, {'id': package_id})
    resource = pkg_dict['resources'][-1]

    return resource


def related_create(context, data_dict):
    '''Add a new related item to a dataset.

    You must provide your API key in the Authorization header.

    :param title: the title of the related item
    :type title: string
    :param type: the type of the related item, e.g. ``'Application'``,
        ``'Idea'`` or ``'Visualisation'``
    :type type: string
    :param id: the id of the related item (optional)
    :type id: string
    :param description: the description of the related item (optional)
    :type description: string
    :param url: the URL to the related item (optional)
    :type url: string
    :param image_url: the URL to the image for the related item (optional)
    :type image_url: string
    :param dataset_id: the name or id of the dataset that the related item
        belongs to (optional)
    :type dataset_id: string

    :returns: the newly created related item
    :rtype: dictionary

    '''
    model = context['model']
    session = context['session']
    user = context['user']
    userobj = model.User.get(user)

    _check_access('related_create', context, data_dict)

    data_dict["owner_id"] = userobj.id
    data, errors = _validate(
        data_dict, ckan.logic.schema.default_related_schema(), context)
    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    related = model_save.related_dict_save(data, context)
    if not context.get('defer_commit'):
        model.repo.commit_and_remove()

    dataset_dict = None
    if 'dataset_id' in data_dict:
        dataset = model.Package.get(data_dict['dataset_id'])
        dataset.related.append(related)
        model.repo.commit_and_remove()
        dataset_dict = ckan.lib.dictization.table_dictize(dataset, context)

    session.flush()

    related_dict = model_dictize.related_dictize(related, context)
    activity_dict = {
        'user_id': userobj.id,
        'object_id': related.id,
        'activity_type': 'new related item',
    }
    activity_dict['data'] = {
        'related': related_dict,
        'dataset': dataset_dict,
    }
    activity_create_context = {
        'model': model,
        'user': user,
        'defer_commit': True,
        'ignore_auth': True,
        'session': session
    }
    logic.get_action('activity_create')(activity_create_context,
                                        activity_dict)
    session.commit()

    context["related"] = related
    context["id"] = related.id
    log.debug('Created object %s' % related.title)
    return related_dict


def package_relationship_create(context, data_dict):
    '''Create a relationship between two datasets (packages).

    You must be authorized to edit both the subject and the object datasets.

    :param subject: the id or name of the dataset that is the subject of the
        relationship
    :type subject: string
    :param object: the id or name of the dataset that is the object of the
        relationship
    :param type: the type of the relationship, one of ``'depends_on'``,
        ``'dependency_of'``, ``'derives_from'``, ``'has_derivation'``,
        ``'links_to'``, ``'linked_from'``, ``'child_of'`` or ``'parent_of'``
    :type type: string
    :param comment: a comment about the relationship (optional)
    :type comment: string

    :returns: the newly created package relationship
    :rtype: dictionary

    '''
    model = context['model']
    user = context['user']
    schema = context.get('schema') \
        or ckan.logic.schema.default_create_relationship_schema()
    api = context.get('api_version')
    ref_package_by = 'id' if api == 2 else 'name'

    id, id2, rel_type = _get_or_bust(data_dict, ['subject', 'object', 'type'])
    comment = data_dict.get('comment', u'')

    pkg1 = model.Package.get(id)
    pkg2 = model.Package.get(id2)
    if not pkg1:
        raise NotFound('Subject package %r was not found.' % id)
    if not pkg2:
        return NotFound('Object package %r was not found.' % id2)

    data, errors = _validate(data_dict, schema, context)
    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    _check_access('package_relationship_create', context, data_dict)

    # Create a Package Relationship.
    existing_rels = pkg1.get_relationships_with(pkg2, rel_type)
    if existing_rels:
        return _update_package_relationship(existing_rels[0],
                                            comment, context)
    rev = model.repo.new_revision()
    rev.author = user
    rev.message = _(u'REST API: Create package relationship: %s %s %s') \
        % (pkg1, rel_type, pkg2)
    rel = pkg1.add_relationship(rel_type, pkg2, comment=comment)
    if not context.get('defer_commit'):
        model.repo.commit_and_remove()
    context['relationship'] = rel

    relationship_dicts = rel.as_dict(ref_package_by=ref_package_by)
    return relationship_dicts


def member_create(context, data_dict=None):
    '''Make an object (e.g. a user, dataset or group) a member of a group.

    If the object is already a member of the group then the capacity of the
    membership will be updated.

    You must be authorized to edit the group.

    :param id: the id or name of the group to add the object to
    :type id: string
    :param object: the id or name of the object to add
    :type object: string
    :param object_type: the type of the object being added, e.g. ``'package'``
        or ``'user'``
    :type object_type: string
    :param capacity: the capacity of the membership
    :type capacity: string

    :returns: the newly created (or updated) membership
    :rtype: dictionary

    '''
    model = context['model']
    user = context['user']

    rev = model.repo.new_revision()
    rev.author = user
    if 'message' in context:
        rev.message = context['message']
    else:
        rev.message = _(u'REST API: Create member object %s') \
            % data_dict.get('name', '')

    group_id, obj_id, obj_type, capacity = \
        _get_or_bust(data_dict, ['id', 'object', 'object_type', 'capacity'])

    group = model.Group.get(group_id)
    if not group:
        raise NotFound('Group was not found.')

    obj_class = ckan.logic.model_name_to_class(model, obj_type)
    obj = obj_class.get(obj_id)
    if not obj:
        raise NotFound('%s was not found.' % obj_type.title())

    _check_access('member_create', context, data_dict)

    # Look up existing, in case it exists
    member = model.Session.query(model.Member).\
        filter(model.Member.table_name == obj_type).\
        filter(model.Member.table_id == obj.id).\
        filter(model.Member.group_id == group.id).\
        filter(model.Member.state == 'active').first()
    if not member:
        member = model.Member(table_name=obj_type,
                              table_id=obj.id,
                              group_id=group.id,
                              state='active')

    member.capacity = capacity

    model.Session.add(member)
    model.repo.commit()

    return model_dictize.member_dictize(member, context)


def _group_or_org_create(context, data_dict, is_org=False):
    model = context['model']
    user = context['user']
    session = context['session']
    data_dict['is_organization'] = is_org

    upload = uploader.Upload('group')
    upload.update_data_dict(data_dict, 'image_url',
                            'image_upload', 'clear_upload')
    # get the schema
    group_plugin = lib_plugins.lookup_group_plugin(
        group_type=data_dict.get('type'))
    try:
        schema = group_plugin.form_to_db_schema_options({
            'type': 'create', 'api': 'api_version' in context,
            'context': context})
    except AttributeError:
        schema = group_plugin.form_to_db_schema()

    if 'api_version' not in context:
        # old plugins do not support passing the schema so we need
        # to ensure they still work
        try:
            group_plugin.check_data_dict(data_dict, schema)
        except TypeError:
            group_plugin.check_data_dict(data_dict)

    data, errors = lib_plugins.plugin_validate(
        group_plugin, context, data_dict, schema,
        'organization_create' if is_org else 'group_create')
    log.debug('group_create validate_errs=%r user=%s group=%s data_dict=%r',
              errors, context.get('user'), data_dict.get('name'), data_dict)

    if errors:
        session.rollback()
        raise ValidationError(errors)

    rev = model.repo.new_revision()
    rev.author = user

    if 'message' in context:
        rev.message = context['message']
    else:
        rev.message = _(u'REST API: Create object %s') % data.get("name")

    group = model_save.group_dict_save(data, context)

    if user:
        admins = [model.User.by_name(user.decode('utf8'))]
    else:
        admins = []
    model.setup_default_user_roles(group, admins)
    # Needed to let extensions know the group id
    session.flush()

    if is_org:
        plugin_type = plugins.IOrganizationController
    else:
        plugin_type = plugins.IGroupController

    for item in plugins.PluginImplementations(plugin_type):
        item.create(group)

    if is_org:
        activity_type = 'new organization'
    else:
        activity_type = 'new group'

    user_id = model.User.by_name(user.decode('utf8')).id

    activity_dict = {
        'user_id': user_id,
        'object_id': group.id,
        'activity_type': activity_type,
    }
    activity_dict['data'] = {
        'group': ckan.lib.dictization.table_dictize(group, context)
    }
    activity_create_context = {
        'model': model,
        'user': user,
        'defer_commit': True,
        'ignore_auth': True,
        'session': session
    }
    logic.get_action('activity_create')(activity_create_context, activity_dict)

    upload.upload(uploader.get_max_image_size())
    if not context.get('defer_commit'):
        model.repo.commit()
    context["group"] = group
    context["id"] = group.id

    # creator of group/org becomes an admin
    # this needs to be after the repo.commit or else revisions break
    member_dict = {
        'id': group.id,
        'object': user_id,
        'object_type': 'user',
        'capacity': 'admin',
    }
    member_create_context = {
        'model': model,
        'user': user,
        'ignore_auth': True,  # we are not a member of the group at this point
        'session': session
    }
    logic.get_action('member_create')(member_create_context, member_dict)

    log.debug('Created object %s' % group.name)
    return model_dictize.group_dictize(group, context)


def group_create(context, data_dict):
    '''Create a new group.

    You must be authorized to create groups.

    Plugins may change the parameters of this function depending on the value
    of the ``type`` parameter, see the
    :py:class:`~ckan.plugins.interfaces.IGroupForm` plugin interface.

    :param name: the name of the group, a string between 2 and 100 characters
        long, containing only lowercase alphanumeric characters, ``-`` and
        ``_``
    :type name: string
    :param id: the id of the group (optional)
    :type id: string
    :param title: the title of the group (optional)
    :type title: string
    :param description: the description of the group (optional)
    :type description: string
    :param image_url: the URL to an image to be displayed on the group's page
        (optional)
    :type image_url: string
    :param type: the type of the group (optional),
        :py:class:`~ckan.plugins.interfaces.IGroupForm` plugins
        associate themselves with different group types and provide custom
        group handling behaviour for these types
        Cannot be 'organization'
    :type type: string
    :param state: the current state of the group, e.g. ``'active'`` or
        ``'deleted'``, only active groups show up in search results and
        other lists of groups, this parameter will be ignored if you are not
        authorized to change the state of the group (optional, default:
        ``'active'``)
    :type state: string
    :param approval_status: (optional)
    :type approval_status: string
    :param extras: the group's extras (optional), extras are arbitrary
        (key: value) metadata items that can be added to groups, each extra
        dictionary should have keys ``'key'`` (a string), ``'value'`` (a
        string), and optionally ``'deleted'``
    :type extras: list of dataset extra dictionaries
    :param packages: the datasets (packages) that belong to the group, a list
        of dictionaries each with keys ``'name'`` (string, the id or name of
        the dataset) and optionally ``'title'`` (string, the title of the
        dataset)
    :type packages: list of dictionaries
    :param groups: the groups that belong to the group, a list of dictionaries
        each with key ``'name'`` (string, the id or name of the group) and
        optionally ``'capacity'`` (string, the capacity in which the group is
        a member of the group)
    :type groups: list of dictionaries
    :param users: the users that belong to the group, a list of dictionaries
        each with key ``'name'`` (string, the id or name of the user) and
        optionally ``'capacity'`` (string, the capacity in which the user is
        a member of the group)
    :type users: list of dictionaries

    :returns: the newly created group
    :rtype: dictionary

    '''
    # wrapper for creating groups
    if data_dict.get('type') == 'organization':
        # FIXME better exception?
        raise Exception(_('Trying to create an organization as a group'))
    _check_access('group_create', context, data_dict)
    return _group_or_org_create(context, data_dict)


def organization_create(context, data_dict):
    '''Create a new organization.

    You must be authorized to create organizations.

    Plugins may change the parameters of this function depending on the value
    of the ``type`` parameter, see the
    :py:class:`~ckan.plugins.interfaces.IGroupForm` plugin interface.

    :param name: the name of the organization, a string between 2 and
        100 characters long, containing only lowercase alphanumeric
        characters, ``-`` and ``_``
    :type name: string
    :param id: the id of the organization (optional)
    :type id: string
    :param title: the title of the organization (optional)
    :type title: string
    :param description: the description of the organization (optional)
    :type description: string
    :param image_url: the URL to an image to be displayed on the
        organization's page (optional)
    :type image_url: string
    :param state: the current state of the organization, e.g. ``'active'`` or
        ``'deleted'``, only active organizations show up in search results and
        other lists of organizations, this parameter will be ignored if you
        are not authorized to change the state of the organization
        (optional, default: ``'active'``)
    :type state: string
    :param approval_status: (optional)
    :type approval_status: string
    :param extras: the organization's extras (optional), extras are arbitrary
        (key: value) metadata items that can be added to organizations,
        each extra
        dictionary should have keys ``'key'`` (a string), ``'value'`` (a
        string), and optionally ``'deleted'``
    :type extras: list of dataset extra dictionaries
    :param packages: the datasets (packages) that belong to the organization,
        a list of dictionaries each with keys ``'name'`` (string, the id
        or name of the dataset) and optionally ``'title'`` (string, the
        title of the dataset)
    :type packages: list of dictionaries
    :param users: the users that belong to the organization, a list
        of dictionaries each with key ``'name'`` (string, the id or name
        of the user) and optionally ``'capacity'`` (string, the capacity
        in which the user is a member of the organization)
    :type users: list of dictionaries

    :returns: the newly created organization
    :rtype: dictionary

    '''
    # wrapper for creating organizations
    data_dict['type'] = 'organization'
    _check_access('organization_create', context, data_dict)
    return _group_or_org_create(context, data_dict, is_org=True)


@logic.auth_audit_exempt
def rating_create(context, data_dict):
    '''Rate a dataset (package).

    You must provide your API key in the Authorization header.

    :param package: the name or id of the dataset to rate
    :type package: string
    :param rating: the rating to give to the dataset, an integer between 1 and
        5
    :type rating: int

    :returns: a dictionary with two keys: ``'rating average'`` (the average
        rating of the dataset you rated) and ``'rating count'`` (the number of
        times the dataset has been rated)
    :rtype: dictionary

    '''
    model = context['model']
    user = context.get("user")

    package_ref = data_dict.get('package')
    rating = data_dict.get('rating')
    opts_err = None
    if not package_ref:
        opts_err = _('You must supply a package id or name '
                     '(parameter "package").')
    elif not rating:
        opts_err = _('You must supply a rating (parameter "rating").')
    else:
        try:
            rating_int = int(rating)
        except ValueError:
            opts_err = _('Rating must be an integer value.')
        else:
            package = model.Package.get(package_ref)
            if rating < ratings.MIN_RATING or rating > ratings.MAX_RATING:
                opts_err = _('Rating must be between %i and %i.') \
                    % (ratings.MIN_RATING, ratings.MAX_RATING)
            elif not package:
                opts_err = _('Not found') + ': %r' % package_ref
    if opts_err:
        raise ValidationError(opts_err)

    user = model.User.by_name(user)
    ratings.set_rating(user, package, rating_int)

    package = model.Package.get(package_ref)
    ret_dict = {'rating average': package.get_average_rating(),
                'rating count': len(package.ratings)}
    return ret_dict


def user_create(context, data_dict):
    '''Create a new user.

    You must be authorized to create users.

    :param name: the name of the new user, a string between 2 and 100
        characters in length, containing only lowercase alphanumeric
        characters, ``-`` and ``_``
    :type name: string
    :param email: the email address for the new user
    :type email: string
    :param password: the password of the new user, a string of at least 4
        characters
    :type password: string
    :param id: the id of the new user (optional)
    :type id: string
    :param fullname: the full name of the new user (optional)
    :type fullname: string
    :param about: a description of the new user (optional)
    :type about: string
    :param openid: (optional)
    :type openid: string

    :returns: the newly created yser
    :rtype: dictionary

    '''
    model = context['model']
    schema = context.get('schema') or ckan.logic.schema.default_user_schema()
    session = context['session']

    _check_access('user_create', context, data_dict)

    data, errors = _validate(data_dict, schema, context)

    if errors:
        session.rollback()
        raise ValidationError(errors)

    user = model_save.user_dict_save(data, context)

    # Flush the session to cause user.id to be initialised, because
    # activity_create() (below) needs it.
    session.flush()

    activity_create_context = {
        'model': model,
        'user': context['user'],
        'defer_commit': True,
        'ignore_auth': True,
        'session': session
    }
    activity_dict = {
        'user_id': user.id,
        'object_id': user.id,
        'activity_type': 'new user',
    }
    logic.get_action('activity_create')(activity_create_context, activity_dict)

    if not context.get('defer_commit'):
        model.repo.commit()

    # A new context is required for dictizing the newly constructed user in
    # order that all the new user's data is returned, in particular, the
    # api_key.
    #
    # The context is copied so as not to clobber the caller's context dict.
    user_dictize_context = context.copy()
    user_dictize_context['keep_apikey'] = True
    user_dictize_context['keep_email'] = True
    user_dict = model_dictize.user_dictize(user, user_dictize_context)

    context['user_obj'] = user
    context['id'] = user.id

    model.Dashboard.get(user.id)  # Create dashboard for user.

    log.debug('Created user {name}'.format(name=user.name))
    return user_dict


def user_invite(context, data_dict):
    '''Invite a new user.

    You must be authorized to create group members.

    :param email: the email of the user to be invited to the group
    :type email: string
    :param group_id: the id or name of the group
    :type group_id: string
    :param role: role of the user in the group. One of ``member``, ``editor``,
        or ``admin``
    :type role: string

    :returns: the newly created yser
    :rtype: dictionary
    '''
    _check_access('user_invite', context, data_dict)

    schema = context.get('schema',
                         ckan.logic.schema.default_user_invite_schema())
    data, errors = _validate(data_dict, schema, context)
    if errors:
        raise ValidationError(errors)

    name = _get_random_username_from_email(data['email'])
    password = str(random.SystemRandom().random())
    data['name'] = name
    data['password'] = password
    data['state'] = ckan.model.State.PENDING
    user_dict = _get_action('user_create')(context, data)
    user = ckan.model.User.get(user_dict['id'])
    member_dict = {
        'username': user.id,
        'id': data['group_id'],
        'role': data['role']
    }
    _get_action('group_member_create')(context, member_dict)
    mailer.send_invite(user)
    return model_dictize.user_dictize(user, context)


def _get_random_username_from_email(email):
    localpart = email.split('@')[0]
    cleaned_localpart = re.sub(r'[^\w]', '-', localpart)

    # if we can't create a unique user name within this many attempts
    # then something else is probably wrong and we should give up
    max_name_creation_attempts = 100

    for i in range(max_name_creation_attempts):
        random_number = random.SystemRandom().random() * 10000
        name = '%s-%d' % (cleaned_localpart, random_number)
        if not ckan.model.User.get(name):
            return name

    return cleaned_localpart


## Modifications for rest api

def package_create_rest(context, data_dict):
    _check_access('package_create_rest', context, data_dict)
    dictized_package = model_save.package_api_to_dict(data_dict, context)
    dictized_after = _get_action('package_create')(context, dictized_package)
    pkg = context['package']
    package_dict = model_dictize.package_to_api(pkg, context)
    data_dict['id'] = pkg.id
    return package_dict


def group_create_rest(context, data_dict):
    _check_access('group_create_rest', context, data_dict)
    dictized_group = model_save.group_api_to_dict(data_dict, context)
    dictized_after = _get_action('group_create')(context, dictized_group)
    group = context['group']
    group_dict = model_dictize.group_to_api(group, context)
    data_dict['id'] = group.id
    return group_dict


def vocabulary_create(context, data_dict):
    '''Create a new tag vocabulary.

    You must be a sysadmin to create vocabularies.

    :param name: the name of the new vocabulary, e.g. ``'Genre'``
    :type name: string
    :param tags: the new tags to add to the new vocabulary, for the format of
        tag dictionaries see :py:func:`tag_create`
    :type tags: list of tag dictionaries

    :returns: the newly-created vocabulary
    :rtype: dictionary

    '''
    model = context['model']
    schema = context.get('schema') or \
        ckan.logic.schema.default_create_vocabulary_schema()

    _check_access('vocabulary_create', context, data_dict)

    data, errors = _validate(data_dict, schema, context)

    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    vocabulary = model_save.vocabulary_dict_save(data, context)

    if not context.get('defer_commit'):
        model.repo.commit()

    log.debug('Created Vocabulary %s' % vocabulary.name)

    return model_dictize.vocabulary_dictize(vocabulary, context)


def activity_create(context, activity_dict, **kw):
    '''Create a new activity stream activity.

    You must be a sysadmin to create new activities.

    :param user_id: the name or id of the user who carried out the activity,
        e.g. ``'seanh'``
    :type user_id: string
    :param object_id: the name or id of the object of the activity, e.g.
        ``'my_dataset'``
    :param activity_type: the type of the activity, this must be an activity
        type that CKAN knows how to render, e.g. ``'new package'``,
        ``'changed user'``, ``'deleted group'`` etc.
    :type activity_type: string
    :param data: any additional data about the activity
    :type data: dictionary

    :returns: the newly created activity
    :rtype: dictionary

    '''

    _check_access('activity_create', context, activity_dict)

    # this action had a ignore_auth param which has been removed
    # removed in 2.2
    if 'ignore_auth' in kw:
        raise Exception('Activity Stream calling parameters have changed '
                        'ignore_auth must be passed in the context not as '
                        'a param')

    if not paste.deploy.converters.asbool(
            config.get('ckan.activity_streams_enabled', 'true')):
        return

    model = context['model']

    # Any revision_id that the caller attempts to pass in the activity_dict is
    # ignored and overwritten here.
    if getattr(model.Session, 'revision', None):
        activity_dict['revision_id'] = model.Session.revision.id
    else:
        activity_dict['revision_id'] = None

    schema = context.get('schema') or \
        ckan.logic.schema.default_create_activity_schema()

    data, errors = _validate(activity_dict, schema, context)
    if errors:
        raise ValidationError(errors)

    activity = model_save.activity_dict_save(data, context)

    if not context.get('defer_commit'):
        model.repo.commit()

    log.debug("Created '%s' activity" % activity.activity_type)
    return model_dictize.activity_dictize(activity, context)


def package_relationship_create_rest(context, data_dict):
    # rename keys
    key_map = {'id': 'subject',
               'id2': 'object',
               'rel': 'type'}
    # Don't be destructive to enable parameter values for
    # object and type to override the URL parameters.
    data_dict = ckan.logic.action.rename_keys(data_dict, key_map,
                                              destructive=False)

    relationship_dict = _get_action('package_relationship_create')(
        context, data_dict)
    return relationship_dict


def tag_create(context, data_dict):
    '''Create a new vocabulary tag.

    You must be a sysadmin to create vocabulary tags.

    You can only use this function to create tags that belong to a vocabulary,
    not to create free tags. (To create a new free tag simply add the tag to
    a package, e.g. using the
    :py:func:`~ckan.logic.action.update.package_update` function.)

    :param name: the name for the new tag, a string between 2 and 100
        characters long containing only alphanumeric characters and ``-``,
        ``_`` and ``.``, e.g. ``'Jazz'``
    :type name: string
    :param vocabulary_id: the name or id of the vocabulary that the new tag
        should be added to, e.g. ``'Genre'``
    :type vocabulary_id: string

    :returns: the newly-created tag
    :rtype: dictionary

    '''
    model = context['model']

    _check_access('tag_create', context, data_dict)

    schema = context.get('schema') or \
        ckan.logic.schema.default_create_tag_schema()
    data, errors = _validate(data_dict, schema, context)
    if errors:
        raise ValidationError(errors)

    tag = model_save.tag_dict_save(data_dict, context)

    if not context.get('defer_commit'):
        model.repo.commit()

    log.debug("Created tag '%s' " % tag)
    return model_dictize.tag_dictize(tag, context)


def follow_user(context, data_dict):
    '''Start following another user.

    You must provide your API key in the Authorization header.

    :param id: the id or name of the user to follow, e.g. ``'joeuser'``
    :type id: string

    :returns: a representation of the 'follower' relationship between yourself
        and the other user
    :rtype: dictionary

    '''
    if 'user' not in context:
        raise logic.NotAuthorized(_("You must be logged in to follow users"))

    model = context['model']
    session = context['session']

    userobj = model.User.get(context['user'])
    if not userobj:
        raise logic.NotAuthorized(_("You must be logged in to follow users"))

    schema = (context.get('schema')
              or ckan.logic.schema.default_follow_user_schema())

    validated_data_dict, errors = _validate(data_dict, schema, context)

    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    # Don't let a user follow herself.
    if userobj.id == validated_data_dict['id']:
        message = _('You cannot follow yourself')
        raise ValidationError({'message': message}, error_summary=message)

    # Don't let a user follow someone she is already following.
    if model.UserFollowingUser.is_following(userobj.id,
                                            validated_data_dict['id']):
        followeduserobj = model.User.get(validated_data_dict['id'])
        name = followeduserobj.display_name
        message = _('You are already following {0}').format(name)
        raise ValidationError({'message': message}, error_summary=message)

    follower = model_save.follower_dict_save(
        validated_data_dict, context, model.UserFollowingUser)

    if not context.get('defer_commit'):
        model.repo.commit()

    log.debug(u'User {follower} started following user {object}'.format(
        follower=follower.follower_id, object=follower.object_id))

    return model_dictize.user_following_user_dictize(follower, context)


def follow_dataset(context, data_dict):
    '''Start following a dataset.

    You must provide your API key in the Authorization header.

    :param id: the id or name of the dataset to follow, e.g. ``'warandpeace'``
    :type id: string

    :returns: a representation of the 'follower' relationship between yourself
        and the dataset
    :rtype: dictionary

    '''

    if not 'user' in context:
        raise logic.NotAuthorized(
            _("You must be logged in to follow a dataset."))

    model = context['model']
    session = context['session']

    userobj = model.User.get(context['user'])
    if not userobj:
        raise logic.NotAuthorized(
            _("You must be logged in to follow a dataset."))

    schema = (context.get('schema')
              or ckan.logic.schema.default_follow_dataset_schema())

    validated_data_dict, errors = _validate(data_dict, schema, context)

    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    # Don't let a user follow a dataset she is already following.
    if model.UserFollowingDataset.is_following(userobj.id,
                                               validated_data_dict['id']):
        # FIXME really package model should have this logic and provide
        # 'display_name' like users and groups
        pkgobj = model.Package.get(validated_data_dict['id'])
        name = pkgobj.title or pkgobj.name or pkgobj.id
        message = _(
            'You are already following {0}').format(name)
        raise ValidationError({'message': message}, error_summary=message)

    follower = model_save.follower_dict_save(validated_data_dict, context,
                                             model.UserFollowingDataset)

    if not context.get('defer_commit'):
        model.repo.commit()

    log.debug(u'User {follower} started following dataset {object}'.format(
        follower=follower.follower_id, object=follower.object_id))

    return model_dictize.user_following_dataset_dictize(follower, context)


def _group_or_org_member_create(context, data_dict, is_org=False):
    # creator of group/org becomes an admin
    # this needs to be after the repo.commit or else revisions break
    model = context['model']
    user = context['user']
    session = context['session']

    schema = ckan.logic.schema.member_schema()
    data, errors = _validate(data_dict, schema, context)

    username = _get_or_bust(data_dict, 'username')
    role = data_dict.get('role')
    group_id = data_dict.get('id')
    group = model.Group.get(group_id)
    result = model.User.get(username)
    if result:
        user_id = result.id
    else:
        message = _(u'User {username} does not exist.').format(
            username=username)
        raise ValidationError({'message': message}, error_summary=message)
    member_dict = {
        'id': group.id,
        'object': user_id,
        'object_type': 'user',
        'capacity': role,
    }
    member_create_context = {
        'model': model,
        'user': user,
        'session': session
    }
    logic.get_action('member_create')(member_create_context, member_dict)


def group_member_create(context, data_dict):
    '''Make a user a member of a group.

    You must be authorized to edit the group.

    :param id: the id or name of the group
    :type id: string
    :param username: name or id of the user to be made member of the group
    :type username: string
    :param role: role of the user in the group. One of ``member``, ``editor``,
        or ``admin``
    :type role: string

    :returns: the newly created (or updated) membership
    :rtype: dictionary
    '''
    _check_access('group_member_create', context, data_dict)
    return _group_or_org_member_create(context, data_dict)


def organization_member_create(context, data_dict):
    '''Make a user a member of an organization.

    You must be authorized to edit the organization.

    :param id: the id or name of the organization
    :type id: string
    :param username: name or id of the user to be made member of the
        organization
    :type username: string
    :param role: role of the user in the organization. One of ``member``,
        ``editor``, or ``admin``
    :type role: string

    :returns: the newly created (or updated) membership
    :rtype: dictionary
    '''
    _check_access('organization_member_create', context, data_dict)
    return _group_or_org_member_create(context, data_dict, is_org=True)


def follow_group(context, data_dict):
    '''Start following a group.

    You must provide your API key in the Authorization header.

    :param id: the id or name of the group to follow, e.g. ``'roger'``
    :type id: string

    :returns: a representation of the 'follower' relationship between yourself
        and the group
    :rtype: dictionary

    '''
    if 'user' not in context:
        raise logic.NotAuthorized(
            _("You must be logged in to follow a group."))

    model = context['model']
    session = context['session']

    userobj = model.User.get(context['user'])
    if not userobj:
        raise logic.NotAuthorized(
            _("You must be logged in to follow a group."))

    schema = context.get('schema',
                         ckan.logic.schema.default_follow_group_schema())

    validated_data_dict, errors = _validate(data_dict, schema, context)

    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    # Don't let a user follow a group she is already following.
    if model.UserFollowingGroup.is_following(userobj.id,
                                             validated_data_dict['id']):
        groupobj = model.Group.get(validated_data_dict['id'])
        name = groupobj.display_name
        message = _(
            'You are already following {0}').format(name)
        raise ValidationError({'message': message}, error_summary=message)

    follower = model_save.follower_dict_save(validated_data_dict, context,
                                             model.UserFollowingGroup)

    if not context.get('defer_commit'):
        model.repo.commit()

    log.debug(u'User {follower} started following group {object}'.format(
        follower=follower.follower_id, object=follower.object_id))

    return model_dictize.user_following_group_dictize(follower, context)

########NEW FILE########
__FILENAME__ = delete
'''API functions for deleting data from CKAN.'''

from sqlalchemy import or_

import ckan.logic
import ckan.logic.action
import ckan.plugins as plugins
import ckan.lib.dictization.model_dictize as model_dictize

from ckan.common import _

validate = ckan.lib.navl.dictization_functions.validate

# Define some shortcuts
# Ensure they are module-private so that they don't get loaded as available
# actions in the action API.
ValidationError = ckan.logic.ValidationError
NotFound = ckan.logic.NotFound
_check_access = ckan.logic.check_access
_get_or_bust = ckan.logic.get_or_bust
_get_action = ckan.logic.get_action


def user_delete(context, data_dict):
    '''Delete a user.

    Only sysadmins can delete users.

    :param id: the id or usernamename of the user to delete
    :type id: string
    '''

    _check_access('user_delete', context, data_dict)

    model = context['model']
    user_id = _get_or_bust(data_dict, 'id')
    user = model.User.get(user_id)

    if user is None:
        raise NotFound('User "{id}" was not found.'.format(id=user_id))

    user.delete()
    model.repo.commit()


def package_delete(context, data_dict):
    '''Delete a dataset (package).

    You must be authorized to delete the dataset.

    :param id: the id or name of the dataset to delete
    :type id: string

    '''
    model = context['model']
    user = context['user']
    id = _get_or_bust(data_dict, 'id')

    entity = model.Package.get(id)

    if entity is None:
        raise NotFound

    _check_access('package_delete',context, data_dict)

    rev = model.repo.new_revision()
    rev.author = user
    rev.message = _(u'REST API: Delete Package: %s') % entity.name

    for item in plugins.PluginImplementations(plugins.IPackageController):
        item.delete(entity)

        item.after_delete(context, data_dict)

    entity.delete()
    model.repo.commit()

def resource_delete(context, data_dict):
    '''Delete a resource from a dataset.

    You must be a sysadmin or the owner of the resource to delete it.

    :param id: the id of the resource
    :type id: string

    '''
    model = context['model']
    id = _get_or_bust(data_dict, 'id')

    entity = model.Resource.get(id)

    if entity is None:
        raise NotFound

    _check_access('resource_delete',context, data_dict)

    package_id = entity.get_package_id()

    pkg_dict = _get_action('package_show')(context, {'id': package_id})

    if pkg_dict.get('resources'):
        pkg_dict['resources'] = [r for r in pkg_dict['resources'] if not
                r['id'] == id]
    try:
        pkg_dict = _get_action('package_update')(context, pkg_dict)
    except ValidationError, e:
        errors = e.error_dict['resources'][-1]
        raise ValidationError(errors)

    model.repo.commit()


def package_relationship_delete(context, data_dict):
    '''Delete a dataset (package) relationship.

    You must be authorised to delete dataset relationships, and to edit both
    the subject and the object datasets.

    :param subject: the id or name of the dataset that is the subject of the
        relationship
    :type subject: string
    :param object: the id or name of the dataset that is the object of the
        relationship
    :type object: string
    :param type: the type of the relationship
    :type type: string

    '''
    model = context['model']
    user = context['user']
    id, id2, rel = _get_or_bust(data_dict, ['subject', 'object', 'type'])

    pkg1 = model.Package.get(id)
    pkg2 = model.Package.get(id2)
    if not pkg1:
        raise NotFound('Subject package %r was not found.' % id)
    if not pkg2:
        return NotFound('Object package %r was not found.' % id2)

    existing_rels = pkg1.get_relationships_with(pkg2, rel)
    if not existing_rels:
        raise NotFound

    relationship = existing_rels[0]
    revisioned_details = 'Package Relationship: %s %s %s' % (id, rel, id2)

    context['relationship'] = relationship
    _check_access('package_relationship_delete', context, data_dict)

    rev = model.repo.new_revision()
    rev.author = user
    rev.message = _(u'REST API: Delete %s') % revisioned_details

    relationship.delete()
    model.repo.commit()

def related_delete(context, data_dict):
    '''Delete a related item from a dataset.

    You must be a sysadmin or the owner of the related item to delete it.

    :param id: the id of the related item
    :type id: string

    '''
    model = context['model']
    session = context['session']
    user = context['user']
    userobj = model.User.get(user)

    id = _get_or_bust(data_dict, 'id')

    entity = model.Related.get(id)

    if entity is None:
        raise NotFound

    _check_access('related_delete',context, data_dict)

    related_dict = model_dictize.related_dictize(entity, context)
    activity_dict = {
        'user_id': userobj.id,
        'object_id': entity.id,
        'activity_type': 'deleted related item',
    }
    activity_dict['data'] = {
        'related': related_dict
    }
    activity_create_context = {
        'model': model,
        'user': user,
        'defer_commit': True,
        'ignore_auth': True,
        'session': session
    }

    _get_action('activity_create')(activity_create_context, activity_dict)
    session.commit()

    entity.delete()
    model.repo.commit()


def member_delete(context, data_dict=None):
    '''Remove an object (e.g. a user, dataset or group) from a group.

    You must be authorized to edit a group to remove objects from it.

    :param id: the id of the group
    :type id: string
    :param object: the id or name of the object to be removed
    :type object: string
    :param object_type: the type of the object to be removed, e.g. ``package``
        or ``user``
    :type object_type: string

    '''
    model = context['model']

    group_id, obj_id, obj_type = _get_or_bust(data_dict, ['id', 'object', 'object_type'])

    group = model.Group.get(group_id)
    if not group:
        raise NotFound('Group was not found.')

    obj_class = ckan.logic.model_name_to_class(model, obj_type)
    obj = obj_class.get(obj_id)
    if not obj:
        raise NotFound('%s was not found.' % obj_type.title())

    _check_access('member_delete', context, data_dict)

    member = model.Session.query(model.Member).\
            filter(model.Member.table_name == obj_type).\
            filter(model.Member.table_id == obj.id).\
            filter(model.Member.group_id == group.id).\
            filter(model.Member.state    == 'active').first()
    if member:
        rev = model.repo.new_revision()
        rev.author = context.get('user')
        rev.message = _(u'REST API: Delete Member: %s') % obj_id
        member.delete()
        model.repo.commit()

def _group_or_org_delete(context, data_dict, is_org=False):
    '''Delete a group.

    You must be authorized to delete the group.

    :param id: the name or id of the group
    :type id: string

    '''
    model = context['model']
    user = context['user']
    id = _get_or_bust(data_dict, 'id')

    group = model.Group.get(id)
    context['group'] = group
    if group is None:
        raise NotFound('Group was not found.')

    revisioned_details = 'Group: %s' % group.name

    if is_org:
        _check_access('organization_delete', context, data_dict)
    else:
        _check_access('group_delete', context, data_dict)

    # organization delete will delete all datasets for that org
    # FIXME this gets all the packages the user can see which generally will
    # be all but this is only a fluke so we should fix this properly
    if is_org:
        for pkg in group.packages(with_private=True):
            _get_action('package_delete')(context, {'id': pkg.id})

    rev = model.repo.new_revision()
    rev.author = user
    rev.message = _(u'REST API: Delete %s') % revisioned_details

    # The group's Member objects are deleted
    # (including hierarchy connections to parent and children groups)
    for member in model.Session.query(model.Member).\
            filter(or_(model.Member.table_id == id,
                       model.Member.group_id == id)).\
            filter(model.Member.state == 'active').all():
        member.delete()

    group.delete()

    if is_org:
        plugin_type = plugins.IOrganizationController
    else:
        plugin_type = plugins.IGroupController

    for item in plugins.PluginImplementations(plugin_type):
        item.delete(group)

    model.repo.commit()

def group_delete(context, data_dict):
    '''Delete a group.

    You must be authorized to delete the group.

    :param id: the name or id of the group
    :type id: string

    '''
    return _group_or_org_delete(context, data_dict)

def organization_delete(context, data_dict):
    '''Delete an organization.

    You must be authorized to delete the organization.

    :param id: the name or id of the organization
    :type id: string

    '''
    return _group_or_org_delete(context, data_dict, is_org=True)

def _group_or_org_purge(context, data_dict, is_org=False):
    '''Purge a group or organization.

    The group or organization will be completely removed from the database.
    This cannot be undone!

    Only sysadmins can purge groups or organizations.

    :param id: the name or id of the group or organization to be purged
    :type id: string

    :param is_org: you should pass is_org=True if purging an organization,
        otherwise False (optional, default: False)
    :type is_org: boolean

    '''
    model = context['model']
    id = _get_or_bust(data_dict, 'id')

    group = model.Group.get(id)
    context['group'] = group
    if group is None:
        if is_org:
            raise NotFound('Organization was not found')
        else:
            raise NotFound('Group was not found')

    if is_org:
        _check_access('organization_purge', context, data_dict)
    else:
        _check_access('group_purge', context, data_dict)

    members = model.Session.query(model.Member)
    members = members.filter(model.Member.group_id == group.id)
    if members.count() > 0:
        model.repo.new_revision()
        for m in members.all():
            m.delete()
        model.repo.commit_and_remove()

    group = model.Group.get(id)
    model.repo.new_revision()
    group.purge()
    model.repo.commit_and_remove()

def group_purge(context, data_dict):
    '''Purge a group.

    .. warning:: Purging a group cannot be undone!

    Purging a group completely removes the group from the CKAN database,
    whereas deleting a group simply marks the group as deleted (it will no
    longer show up in the frontend, but is still in the db).

    You must be authorized to purge the group.

    :param id: the name or id of the group to be purged
    :type id: string

    '''
    return _group_or_org_purge(context, data_dict, is_org=False)

def organization_purge(context, data_dict):
    '''Purge an organization.

    .. warning:: Purging an organization cannot be undone!

    Purging an organization completely removes the organization from the CKAN
    database, whereas deleting an organization simply marks the organization as
    deleted (it will no longer show up in the frontend, but is still in the
    db).

    You must be authorized to purge the organization.

    :param id: the name or id of the organization to be purged
    :type id: string

    '''
    return _group_or_org_purge(context, data_dict, is_org=True)

def task_status_delete(context, data_dict):
    '''Delete a task status.

    You must be a sysadmin to delete task statuses.

    :param id: the id of the task status to delete
    :type id: string

    '''
    model = context['model']
    id = _get_or_bust(data_dict, 'id')

    entity = model.TaskStatus.get(id)

    if entity is None:
        raise NotFound

    _check_access('task_status_delete', context, data_dict)

    entity.delete()
    model.Session.commit()

def vocabulary_delete(context, data_dict):
    '''Delete a tag vocabulary.

    You must be a sysadmin to delete vocabularies.

    :param id: the id of the vocabulary
    :type id: string

    '''
    model = context['model']

    vocab_id = data_dict.get('id')
    if not vocab_id:
        raise ValidationError({'id': _('id not in data')})

    vocab_obj = model.vocabulary.Vocabulary.get(vocab_id)
    if vocab_obj is None:
        raise NotFound(_('Could not find vocabulary "%s"') % vocab_id)

    _check_access('vocabulary_delete', context, data_dict)

    vocab_obj.delete()
    model.repo.commit()

def tag_delete(context, data_dict):
    '''Delete a tag.

    You must be a sysadmin to delete tags.

    :param id: the id or name of the tag
    :type id: string
    :param vocabulary_id: the id or name of the vocabulary that the tag belongs
        to (optional, default: None)
    :type vocabulary_id: string

    '''
    model = context['model']

    if not data_dict.has_key('id') or not data_dict['id']:
        raise ValidationError({'id': _('id not in data')})
    tag_id_or_name = _get_or_bust(data_dict, 'id')

    vocab_id_or_name = data_dict.get('vocabulary_id')

    tag_obj = model.tag.Tag.get(tag_id_or_name, vocab_id_or_name)

    if tag_obj is None:
        raise NotFound(_('Could not find tag "%s"') % tag_id_or_name)

    _check_access('tag_delete', context, data_dict)

    tag_obj.delete()
    model.repo.commit()

def package_relationship_delete_rest(context, data_dict):

    # rename keys
    key_map = {'id': 'subject',
               'id2': 'object',
               'rel': 'type'}
    # We want 'destructive', so that the value of the subject,
    # object and rel in the URI overwrite any values for these
    # in params. This is because you are not allowed to change
    # these values.
    data_dict = ckan.logic.action.rename_keys(data_dict, key_map, destructive=True)

    package_relationship_delete(context, data_dict)

def _unfollow(context, data_dict, schema, FollowerClass):
    model = context['model']

    if not context.has_key('user'):
        raise ckan.logic.NotAuthorized(
                _("You must be logged in to unfollow something."))
    userobj = model.User.get(context['user'])
    if not userobj:
        raise ckan.logic.NotAuthorized(
                _("You must be logged in to unfollow something."))
    follower_id = userobj.id

    validated_data_dict, errors = validate(data_dict, schema, context)
    if errors:
        raise ValidationError(errors)
    object_id = validated_data_dict.get('id')

    follower_obj = FollowerClass.get(follower_id, object_id)
    if follower_obj is None:
        raise NotFound(
                _('You are not following {0}.').format(data_dict.get('id')))

    follower_obj.delete()
    model.repo.commit()

def unfollow_user(context, data_dict):
    '''Stop following a user.

    :param id: the id or name of the user to stop following
    :type id: string

    '''
    schema = context.get('schema') or (
            ckan.logic.schema.default_follow_user_schema())
    _unfollow(context, data_dict, schema, context['model'].UserFollowingUser)

def unfollow_dataset(context, data_dict):
    '''Stop following a dataset.

    :param id: the id or name of the dataset to stop following
    :type id: string

    '''
    schema = context.get('schema') or (
            ckan.logic.schema.default_follow_dataset_schema())
    _unfollow(context, data_dict, schema,
            context['model'].UserFollowingDataset)


def _group_or_org_member_delete(context, data_dict=None):
    model = context['model']
    user = context['user']
    session = context['session']

    group_id = data_dict.get('id')
    group = model.Group.get(group_id)
    user_id = data_dict.get('username')
    user_id = data_dict.get('user_id') if user_id is None else user_id
    member_dict = {
        'id': group.id,
        'object': user_id,
        'object_type': 'user',
    }
    member_context = {
        'model': model,
        'user': user,
        'session': session
    }
    _get_action('member_delete')(member_context, member_dict)


def group_member_delete(context, data_dict=None):
    '''Remove a user from a group.

    You must be authorized to edit the group.

    :param id: the id or name of the group
    :type id: string
    :param username: name or id of the user to be removed
    :type username: string

    '''
    _check_access('group_member_delete',context, data_dict)
    return _group_or_org_member_delete(context, data_dict)

def organization_member_delete(context, data_dict=None):
    '''Remove a user from an organization.

    You must be authorized to edit the organization.

    :param id: the id or name of the organization
    :type id: string
    :param username: name or id of the user to be removed
    :type username: string

    '''
    _check_access('organization_member_delete',context, data_dict)
    return _group_or_org_member_delete(context, data_dict)


def unfollow_group(context, data_dict):
    '''Stop following a group.

    :param id: the id or name of the group to stop following
    :type id: string

    '''
    schema = context.get('schema',
            ckan.logic.schema.default_follow_group_schema())
    _unfollow(context, data_dict, schema,
            context['model'].UserFollowingGroup)

########NEW FILE########
__FILENAME__ = get
'''API functions for searching for and getting data from CKAN.'''

import uuid
import logging
import json
import datetime
import socket

from pylons import config
import sqlalchemy

import ckan.lib.dictization
import ckan.logic as logic
import ckan.logic.action
import ckan.logic.schema
import ckan.lib.dictization.model_dictize as model_dictize
import ckan.lib.navl.dictization_functions
import ckan.model as model
import ckan.model.misc as misc
import ckan.plugins as plugins
import ckan.lib.search as search
import ckan.lib.plugins as lib_plugins
import ckan.lib.activity_streams as activity_streams
import ckan.new_authz as new_authz

from ckan.common import _

log = logging.getLogger('ckan.logic')

# Define some shortcuts
# Ensure they are module-private so that they don't get loaded as available
# actions in the action API.
_validate = ckan.lib.navl.dictization_functions.validate
_table_dictize = ckan.lib.dictization.table_dictize
_check_access = logic.check_access
NotFound = logic.NotFound
ValidationError = logic.ValidationError
_get_or_bust = logic.get_or_bust

_select = sqlalchemy.sql.select
_aliased = sqlalchemy.orm.aliased
_or_ = sqlalchemy.or_
_and_ = sqlalchemy.and_
_func = sqlalchemy.func
_desc = sqlalchemy.desc
_case = sqlalchemy.case
_text = sqlalchemy.text


def _filter_activity_by_user(activity_list, users=[]):
    '''
    Return the given ``activity_list`` with activities from the specified
    users removed. The users parameters should be a list of ids.

    A *new* filtered list is returned, the given ``activity_list`` itself is
    not modified.
    '''
    if not len(users):
        return activity_list
    new_list = []
    for activity in activity_list:
        if activity.user_id not in users:
            new_list.append(activity)
    return new_list


def _activity_stream_get_filtered_users():
    '''
    Get the list of users from the :ref:`ckan.hide_activity_from_users` config
    option and return a list of their ids. If the config is not specified,
    returns the id of the site user.
    '''
    users = config.get('ckan.hide_activity_from_users')
    if users:
        users_list = users.split()
    else:
        context = {'model': model, 'ignore_auth': True}
        site_user = logic.get_action('get_site_user')(context)
        users_list = [site_user.get('name')]

    return model.User.user_ids_for_name_or_id(users_list)


def _package_list_with_resources(context, package_revision_list):
    package_list = []
    for package in package_revision_list:
        result_dict = model_dictize.package_dictize(package,context)
        package_list.append(result_dict)
    return package_list


def site_read(context, data_dict=None):
    '''Return ``True``.

    :rtype: boolean
    '''
    _check_access('site_read', context, data_dict)
    return True


@logic.validate(logic.schema.default_pagination_schema)
def package_list(context, data_dict):
    '''Return a list of the names of the site's datasets (packages).

    :param limit: if given, the list of datasets will be broken into pages of
        at most ``limit`` datasets per page and only one page will be returned
        at a time (optional)
    :type limit: int
    :param offset: when ``limit`` is given, the offset to start
        returning packages from
    :type offset: int

    :rtype: list of strings

    '''
    model = context["model"]
    api = context.get("api_version", 1)

    _check_access('package_list', context, data_dict)

    package_revision_table = model.package_revision_table
    col = (package_revision_table.c.id
           if api == 2 else package_revision_table.c.name)
    query = _select([col])
    query = query.where(_and_(
        package_revision_table.c.state == 'active',
        package_revision_table.c.current == True,
        package_revision_table.c.private == False,
    ))
    query = query.order_by(col)

    limit = data_dict.get('limit')
    if limit:
        query = query.limit(limit)

    offset = data_dict.get('offset')
    if offset:
        query = query.offset(offset)

    ## Returns the first field in each result record
    return [r[0] for r in query.execute()]


@logic.validate(logic.schema.default_package_list_schema)
def current_package_list_with_resources(context, data_dict):
    '''Return a list of the site's datasets (packages) and their resources.

    The list is sorted most-recently-modified first.

    :param limit: if given, the list of datasets will be broken into pages of
        at most ``limit`` datasets per page and only one page will be returned
        at a time (optional)
    :type limit: int
    :param offset: when ``limit`` is given, the offset to start
        returning packages from
    :type offset: int
    :param page: when ``limit`` is given, which page to return,
        Deprecated: use ``offset``
    :type page: int

    :rtype: list of dictionaries

    '''
    model = context["model"]
    limit = data_dict.get('limit')
    offset = data_dict.get('offset', 0)
    user = context['user']

    if not 'offset' in data_dict and 'page' in data_dict:
        log.warning('"page" parameter is deprecated.  '
                    'Use the "offset" parameter instead')
        page = data_dict['page']
        if limit:
            offset = (page - 1) * limit
        else:
            offset = 0

    _check_access('current_package_list_with_resources', context, data_dict)

    is_sysadmin = new_authz.is_sysadmin(user)
    q = '+capacity:public' if not is_sysadmin else '*:*'
    context['ignore_capacity_check'] = True
    search = package_search(context, {'q': q, 'rows': limit, 'start': offset})
    return search.get('results', [])


def revision_list(context, data_dict):
    '''Return a list of the IDs of the site's revisions.

    :rtype: list of strings

    '''
    model = context['model']

    _check_access('revision_list', context, data_dict)

    revs = model.Session.query(model.Revision).all()
    return [rev.id for rev in revs]


def package_revision_list(context, data_dict):
    '''Return a dataset (package)'s revisions as a list of dictionaries.

    :param id: the id or name of the dataset
    :type id: string

    '''
    model = context["model"]
    id = _get_or_bust(data_dict, "id")
    pkg = model.Package.get(id)
    if pkg is None:
        raise NotFound

    _check_access('package_revision_list', context, data_dict)

    revision_dicts = []
    for revision, object_revisions in pkg.all_related_revisions:
        revision_dicts.append(model.revision_as_dict(revision,
                                                     include_packages=False,
                                                     include_groups=False))
    return revision_dicts


def related_show(context, data_dict=None):
    '''Return a single related item.

    :param id: the id of the related item to show
    :type id: string

    :rtype: dictionary

    '''
    model = context['model']
    id = _get_or_bust(data_dict, 'id')

    related = model.Related.get(id)
    context['related'] = related

    if related is None:
        raise NotFound

    _check_access('related_show', context, data_dict)
    schema = context.get('schema') \
        or ckan.logic.schema.default_related_schema()
    related_dict = model_dictize.related_dictize(related, context)
    related_dict, errors = _validate(related_dict, schema, context=context)

    return related_dict


def related_list(context, data_dict=None):
    '''Return a dataset's related items.

    :param id: id or name of the dataset (optional)
    :type id: string
    :param dataset: dataset dictionary of the dataset (optional)
    :type dataset: dictionary
    :param type_filter: the type of related item to show (optional,
      default: None, show all items)
    :type type_filter: string
    :param sort: the order to sort the related items in, possible values are
      'view_count_asc', 'view_count_desc', 'created_asc' or 'created_desc'
      (optional)
    :type sort: string
    :param featured: whether or not to restrict the results to only featured
      related items (optional, default: False)
    :type featured: bool

    :rtype: list of dictionaries

    '''
    model = context['model']
    dataset = data_dict.get('dataset', None)
    if not dataset:
        dataset = model.Package.get(data_dict.get('id'))
    _check_access('related_show', context, data_dict)
    related_list = []
    if not dataset:
        related_list = model.Session.query(model.Related)

        filter_on_type = data_dict.get('type_filter', None)
        if filter_on_type:
            related_list = related_list.filter(
                model.Related.type == filter_on_type)

        sort = data_dict.get('sort', None)
        if sort:
            sortables = {
                'view_count_asc': model.Related.view_count.asc,
                'view_count_desc': model.Related.view_count.desc,
                'created_asc': model.Related.created.asc,
                'created_desc': model.Related.created.desc,
            }
            s = sortables.get(sort, None)
            if s:
                related_list = related_list.order_by(s())

        if data_dict.get('featured', False):
            related_list = related_list.filter(model.Related.featured == 1)
        related_items = related_list.all()
        context['sorted'] = True
    else:
        relateds = model.Related.get_for_dataset(dataset, status='active')
        related_items = (r.related for r in relateds)
    related_list = model_dictize.related_list_dictize(
        related_items, context)
    return related_list


def member_list(context, data_dict=None):
    '''Return the members of a group.

    The user must have permission to 'get' the group.

    :param id: the id or name of the group
    :type id: string
    :param object_type: restrict the members returned to those of a given type,
      e.g. ``'user'`` or ``'package'`` (optional, default: ``None``)
    :type object_type: string
    :param capacity: restrict the members returned to those with a given
      capacity, e.g. ``'member'``, ``'editor'``, ``'admin'``, ``'public'``,
      ``'private'`` (optional, default: ``None``)
    :type capacity: string

    :rtype: list of (id, type, capacity) tuples

    :raises: :class:`ckan.logic.NotFound`: if the group doesn't exist

    '''
    model = context['model']

    group = model.Group.get(_get_or_bust(data_dict, 'id'))
    if not group:
        raise NotFound

    obj_type = data_dict.get('object_type', None)
    capacity = data_dict.get('capacity', None)

    # User must be able to update the group to remove a member from it
    _check_access('group_show', context, data_dict)

    q = model.Session.query(model.Member).\
        filter(model.Member.group_id == group.id).\
        filter(model.Member.state == "active")

    if obj_type:
        q = q.filter(model.Member.table_name == obj_type)
    if capacity:
        q = q.filter(model.Member.capacity == capacity)

    trans = new_authz.roles_trans()

    def translated_capacity(capacity):
        try:
            return trans[capacity]
        except KeyError:
            return capacity

    return [(m.table_id, m.table_name, translated_capacity(m.capacity))
            for m in q.all()]


def _group_or_org_list(context, data_dict, is_org=False):
    model = context['model']
    user = context['user']
    api = context.get('api_version')
    groups = data_dict.get('groups')
    ref_group_by = 'id' if api == 2 else 'name'

    sort = data_dict.get('sort', 'name')
    q = data_dict.get('q')

    # order_by deprecated in ckan 1.8
    # if it is supplied and sort isn't use order_by and raise a warning
    order_by = data_dict.get('order_by', '')
    if order_by:
        log.warn('`order_by` deprecated please use `sort`')
        if not data_dict.get('sort'):
            sort = order_by
    # if the sort is packages and no sort direction is supplied we want to do a
    # reverse sort to maintain compatibility.
    if sort.strip() == 'packages':
        sort = 'packages desc'

    sort_info = _unpick_search(sort,
                               allowed_fields=['name', 'packages'],
                               total=1)

    all_fields = data_dict.get('all_fields', None)

    query = model.Session.query(model.Group).join(model.GroupRevision)
    query = query.filter(model.GroupRevision.state == 'active')
    query = query.filter(model.GroupRevision.current == True)
    if groups:
        query = query.filter(model.GroupRevision.name.in_(groups))
    if q:
        q = u'%{0}%'.format(q)
        query = query.filter(_or_(
            model.GroupRevision.name.ilike(q),
            model.GroupRevision.title.ilike(q),
            model.GroupRevision.description.ilike(q),
        ))

    query = query.filter(model.GroupRevision.is_organization == is_org)

    groups = query.all()
    group_list = model_dictize.group_list_dictize(groups, context,
                                                  lambda x: x[sort_info[0][0]],
                                                  sort_info[0][1] == 'desc')

    if not all_fields:
        group_list = [group[ref_group_by] for group in group_list]

    return group_list


def group_list(context, data_dict):
    '''Return a list of the names of the site's groups.

    :param order_by: the field to sort the list by, must be ``'name'`` or
      ``'packages'`` (optional, default: ``'name'``) Deprecated use sort.
    :type order_by: string
    :param sort: sorting of the search results.  Optional.  Default:
        "name asc" string of field name and sort-order. The allowed fields are
        'name' and 'packages'
    :type sort: string
    :param groups: a list of names of the groups to return, if given only
        groups whose names are in this list will be returned (optional)
    :type groups: list of strings
    :param all_fields: return full group dictionaries instead of  just names
        (optional, default: ``False``)
    :type all_fields: boolean

    :rtype: list of strings

    '''
    _check_access('group_list', context, data_dict)
    data_dict['type'] = 'group'
    return _group_or_org_list(context, data_dict)


def organization_list(context, data_dict):
    '''Return a list of the names of the site's organizations.

    :param order_by: the field to sort the list by, must be ``'name'`` or
      ``'packages'`` (optional, default: ``'name'``) Deprecated use sort.
    :type order_by: string
    :param sort: sorting of the search results.  Optional.  Default:
        "name asc" string of field name and sort-order. The allowed fields are
        'name' and 'packages'
    :type sort: string
    :param organizations: a list of names of the groups to return,
        if given only groups whose names are in this list will be
        returned (optional)
    :type organizations: list of strings
    :param all_fields: return full group dictionaries instead of  just names
        (optional, default: ``False``)
    :type all_fields: boolean

    :rtype: list of strings

    '''
    _check_access('organization_list', context, data_dict)
    data_dict['groups'] = data_dict.pop('organizations', [])
    data_dict['type'] = 'organization'
    return _group_or_org_list(context, data_dict, is_org=True)


def group_list_authz(context, data_dict):
    '''Return the list of groups that the user is authorized to edit.

    :param available_only: remove the existing groups in the package
      (optional, default: ``False``)
    :type available_only: boolean

    :param am_member: if ``True`` return only the groups the logged-in user is
      a member of, otherwise return all groups that the user is authorized to
      edit (for example, sysadmin users are authorized to edit all groups)
      (optional, default: ``False``)
    :type am-member: boolean

    :returns: list of dictized groups that the user is authorized to edit
    :rtype: list of dicts

    '''
    model = context['model']
    user = context['user']
    available_only = data_dict.get('available_only', False)
    am_member = data_dict.get('am_member', False)

    _check_access('group_list_authz', context, data_dict)

    sysadmin = new_authz.is_sysadmin(user)
    roles = ckan.new_authz.get_roles_with_permission('manage_group')
    if not roles:
        return []
    user_id = new_authz.get_user_id_for_username(user, allow_none=True)
    if not user_id:
        return []

    if not sysadmin or am_member:
        q = model.Session.query(model.Member) \
            .filter(model.Member.table_name == 'user') \
            .filter(model.Member.capacity.in_(roles)) \
            .filter(model.Member.table_id == user_id)
        group_ids = []
        for row in q.all():
            group_ids.append(row.group_id)

        if not group_ids:
            return []

    q = model.Session.query(model.Group) \
        .filter(model.Group.is_organization == False) \
        .filter(model.Group.state == 'active')

    if not sysadmin or am_member:
        q = q.filter(model.Group.id.in_(group_ids))

    groups = q.all()

    if available_only:
        package = context.get('package')
        if package:
            groups = set(groups) - set(package.get_groups())

    group_list = model_dictize.group_list_dictize(groups, context)
    return group_list


def organization_list_for_user(context, data_dict):
    '''Return the list of organizations that the user is a member of.

    :param permission: the permission the user has against the
        returned organizations (optional, default: ``edit_group``)
    :type permission: string

    :returns: list of dictized organizations that the user is
        authorized to edit
    :rtype: list of dicts
    '''
    model = context['model']
    user = context['user']

    _check_access('organization_list_for_user', context, data_dict)
    sysadmin = new_authz.is_sysadmin(user)

    orgs_q = model.Session.query(model.Group) \
        .filter(model.Group.is_organization == True) \
        .filter(model.Group.state == 'active')

    if not sysadmin:
        # for non-Sysadmins check they have the required permission

        permission = data_dict.get('permission', 'edit_group')

        roles = ckan.new_authz.get_roles_with_permission(permission)

        if not roles:
            return []
        user_id = new_authz.get_user_id_for_username(user, allow_none=True)
        if not user_id:
            return []

        q = model.Session.query(model.Member) \
            .filter(model.Member.table_name == 'user') \
            .filter(model.Member.capacity.in_(roles)) \
            .filter(model.Member.table_id == user_id)

        group_ids = []
        for row in q.all():
            group_ids.append(row.group_id)

        if not group_ids:
            return []

        orgs_q = orgs_q.filter(model.Group.id.in_(group_ids))

    orgs_list = model_dictize.group_list_dictize(orgs_q.all(), context)
    return orgs_list


def _group_or_org_revision_list(context, data_dict):
    '''Return a group's revisions.

    :param id: the name or id of the group
    :type id: string

    :rtype: list of dictionaries

    '''
    model = context['model']
    id = _get_or_bust(data_dict, 'id')
    group = model.Group.get(id)
    if group is None:
        raise NotFound

    revision_dicts = []
    for revision, object_revisions in group.all_related_revisions:
        revision_dicts.append(model.revision_as_dict(revision,
                                                     include_packages=False,
                                                     include_groups=False))
    return revision_dicts


def group_revision_list(context, data_dict):
    '''Return a group's revisions.

    :param id: the name or id of the group
    :type id: string

    :rtype: list of dictionaries

    '''

    _check_access('group_revision_list', context, data_dict)
    return _group_or_org_revision_list(context, data_dict)


def organization_revision_list(context, data_dict):
    '''Return an organization's revisions.

    :param id: the name or id of the organization
    :type id: string

    :rtype: list of dictionaries

    '''

    _check_access('organization_revision_list', context, data_dict)
    return _group_or_org_revision_list(context, data_dict)


def license_list(context, data_dict):
    '''Return the list of licenses available for datasets on the site.

    :rtype: list of dictionaries

    '''
    model = context["model"]

    _check_access('license_list', context, data_dict)

    license_register = model.Package.get_license_register()
    licenses = license_register.values()
    licenses = [l.as_dict() for l in licenses]
    return licenses


def tag_list(context, data_dict):
    '''Return a list of the site's tags.

    By default only free tags (tags that don't belong to a vocabulary) are
    returned. If the ``vocabulary_id`` argument is given then only tags
    belonging to that vocabulary will be returned instead.

    :param query: a tag name query to search for, if given only tags whose
        names contain this string will be returned (optional)
    :type query: string
    :param vocabulary_id: the id or name of a vocabulary, if give only tags
        that belong to this vocabulary will be returned (optional)
    :type vocabulary_id: string
    :param all_fields: return full tag dictionaries instead of just names
        (optional, default: ``False``)
    :type all_fields: boolean

    :rtype: list of dictionaries

    '''
    model = context['model']

    vocab_id_or_name = data_dict.get('vocabulary_id')
    query = data_dict.get('query') or data_dict.get('q')
    if query:
        query = query.strip()
    all_fields = data_dict.get('all_fields', None)

    _check_access('tag_list', context, data_dict)

    if query:
        tags, count = _tag_search(context, data_dict)
    else:
        tags = model.Tag.all(vocab_id_or_name)

    if tags:
        if all_fields:
            tag_list = model_dictize.tag_list_dictize(tags, context)
        else:
            tag_list = [tag.name for tag in tags]
    else:
        tag_list = []

    return tag_list


def user_list(context, data_dict):
    '''Return a list of the site's user accounts.

    :param q: restrict the users returned to those whose names contain a string
      (optional)
    :type q: string
    :param order_by: which field to sort the list by (optional, default:
      ``'name'``)
    :type order_by: string

    :rtype: list of dictionaries

    '''
    model = context['model']

    _check_access('user_list', context, data_dict)

    q = data_dict.get('q', '')
    order_by = data_dict.get('order_by', 'name')

    query = model.Session.query(
        model.User,
        model.User.name.label('name'),
        model.User.fullname.label('fullname'),
        model.User.about.label('about'),
        model.User.about.label('email'),
        model.User.created.label('created'),
        _select([_func.count(model.Revision.id)],
                _or_(
                    model.Revision.author == model.User.name,
                    model.Revision.author == model.User.openid
                )).label('number_of_edits'),
        _select([_func.count(model.UserObjectRole.id)],
                _and_(
                    model.UserObjectRole.user_id == model.User.id,
                    model.UserObjectRole.context == 'Package',
                    model.UserObjectRole.role == 'admin'
                )).label('number_administered_packages')
    )

    if q:
        query = model.User.search(q, query, user_name=context.get('user'))

    if order_by == 'edits':
        query = query.order_by(_desc(
            _select([_func.count(model.Revision.id)],
                    _or_(
                        model.Revision.author == model.User.name,
                        model.Revision.author == model.User.openid))))

    else:
        query = query.order_by(
            _case([(
                _or_(model.User.fullname == None,
                     model.User.fullname == ''),
                model.User.name)],
                else_=model.User.fullname))

    # Filter deleted users
    query = query.filter(model.User.state != model.State.DELETED)

    ## hack for pagination
    if context.get('return_query'):
        return query

    users_list = []

    for user in query.all():
        result_dict = model_dictize.user_dictize(user[0], context)
        users_list.append(result_dict)

    return users_list


def package_relationships_list(context, data_dict):
    '''Return a dataset (package)'s relationships.

    :param id: the id or name of the first package
    :type id: string
    :param id2: the id or name of the second package
    :type id: string
    :param rel: relationship as string see
        :py:func:`~ckan.logic.action.create.package_relationship_create` for
        the relationship types (optional)

    :rtype: list of dictionaries

    '''
    ##TODO needs to work with dictization layer
    model = context['model']
    api = context.get('api_version')

    id = _get_or_bust(data_dict, "id")
    id2 = data_dict.get("id2")
    rel = data_dict.get("rel")
    ref_package_by = 'id' if api == 2 else 'name'
    pkg1 = model.Package.get(id)
    pkg2 = None
    if not pkg1:
        raise NotFound('First package named in request was not found.')
    if id2:
        pkg2 = model.Package.get(id2)
        if not pkg2:
            raise NotFound('Second package named in address was not found.')

    if rel == 'relationships':
        rel = None

    _check_access('package_relationships_list', context, data_dict)

    # TODO: How to handle this object level authz?
    # Currently we don't care
    relationships = pkg1.get_relationships(with_package=pkg2, type=rel)

    if rel and not relationships:
        raise NotFound('Relationship "%s %s %s" not found.'
                       % (id, rel, id2))

    relationship_dicts = [
        rel.as_dict(pkg1, ref_package_by=ref_package_by)
        for rel in relationships]

    return relationship_dicts


def package_show(context, data_dict):
    '''Return the metadata of a dataset (package) and its resources.

    :param id: the id or name of the dataset
    :type id: string
    :param use_default_schema: use default package schema instead of
        a custom schema defined with an IDatasetForm plugin (default: False)
    :type use_default_schema: bool

    :rtype: dictionary

    '''
    model = context['model']
    context['session'] = model.Session
    name_or_id = data_dict.get("id") or _get_or_bust(data_dict, 'name_or_id')

    pkg = model.Package.get(name_or_id)

    if pkg is None:
        raise NotFound

    context['package'] = pkg

    _check_access('package_show', context, data_dict)

    if data_dict.get('use_default_schema', False):
        context['schema'] = ckan.logic.schema.default_show_package_schema()

    package_dict = None
    use_cache = (context.get('use_cache', True)
                 and not 'revision_id' in context
                 and not 'revision_date' in context)
    if use_cache:
        try:
            search_result = search.show(name_or_id)
        except (search.SearchError, socket.error):
            pass
        else:
            use_validated_cache = 'schema' not in context
            if use_validated_cache and 'validated_data_dict' in search_result:
                package_dict = json.loads(search_result['validated_data_dict'])
                package_dict_validated = True
            else:
                package_dict = json.loads(search_result['data_dict'])
                package_dict_validated = False
            metadata_modified = pkg.metadata_modified.isoformat()
            search_metadata_modified = search_result['metadata_modified']
            # solr stores less precice datetime,
            # truncate to 22 charactors to get good enough match
            if metadata_modified[:22] != search_metadata_modified[:22]:
                package_dict = None

    if not package_dict:
        package_dict = model_dictize.package_dictize(pkg, context)
        package_dict_validated = False

    # Add page-view tracking summary data to the package dict.
    # If the package_dict came from the Solr cache then it will already have a
    # potentially outdated tracking_summary, this will overwrite it with a
    # current one.
    package_dict['tracking_summary'] = model.TrackingSummary.get_for_package(
        package_dict['id'])

    # Add page-view tracking summary data to the package's resource dicts.
    # If the package_dict came from the Solr cache then each resource dict will
    # already have a potentially outdated tracking_summary, this will overwrite
    # it with a current one.
    for resource_dict in package_dict['resources']:
        _add_tracking_summary_to_resource_dict(resource_dict, model)

    if context.get('for_view'):
        for item in plugins.PluginImplementations(plugins.IPackageController):
            package_dict = item.before_view(package_dict)

    for item in plugins.PluginImplementations(plugins.IPackageController):
        item.read(pkg)

    for resource_dict in package_dict['resources']:
        for item in plugins.PluginImplementations(plugins.IResourceController):
            resource_dict = item.before_show(resource_dict)

    if not package_dict_validated:
        package_plugin = lib_plugins.lookup_package_plugin(
            package_dict['type'])
        if 'schema' in context:
            schema = context['schema']
        else:
            schema = package_plugin.show_package_schema()
            if schema and context.get('validate', True):
                package_dict, errors = lib_plugins.plugin_validate(
                    package_plugin, context, package_dict, schema,
                    'package_show')

    for item in plugins.PluginImplementations(plugins.IPackageController):
        item.after_show(context, package_dict)

    return package_dict


def _add_tracking_summary_to_resource_dict(resource_dict, model):
    '''Add page-view tracking summary data to the given resource dict.

    '''
    tracking_summary = model.TrackingSummary.get_for_resource(
        resource_dict['url'])
    resource_dict['tracking_summary'] = tracking_summary


def resource_show(context, data_dict):
    '''Return the metadata of a resource.

    :param id: the id of the resource
    :type id: string

    :rtype: dictionary

    '''
    model = context['model']
    id = _get_or_bust(data_dict, 'id')

    resource = model.Resource.get(id)
    context['resource'] = resource

    if not resource:
        raise NotFound

    _check_access('resource_show', context, data_dict)
    resource_dict = model_dictize.resource_dictize(resource, context)

    _add_tracking_summary_to_resource_dict(resource_dict, model)

    for item in plugins.PluginImplementations(plugins.IResourceController):
        resource_dict = item.before_show(resource_dict)

    return resource_dict


def resource_status_show(context, data_dict):
    '''Return the statuses of a resource's tasks.

    :param id: the id of the resource
    :type id: string

    :rtype: list of (status, date_done, traceback, task_status) dictionaries

    '''
    try:
        import ckan.lib.celery_app as celery_app
    except ImportError:
        return {'message': 'queue is not installed on this instance'}

    model = context['model']
    id = _get_or_bust(data_dict, 'id')

    _check_access('resource_status_show', context, data_dict)

    # needs to be text query as celery tables are not in our model
    q = _text("""
        select status, date_done, traceback, task_status.*
        from task_status left join celery_taskmeta
        on task_status.value = celery_taskmeta.task_id
           and key = 'celery_task_id'
        where entity_id = :entity_id
    """)
    result = model.Session.connection().execute(q, entity_id=id)
    result_list = [_table_dictize(row, context) for row in result]
    return result_list


@logic.auth_audit_exempt
def revision_show(context, data_dict):
    '''Return the details of a revision.

    :param id: the id of the revision
    :type id: string

    :rtype: dictionary
    '''
    model = context['model']
    api = context.get('api_version')
    id = _get_or_bust(data_dict, 'id')
    ref_package_by = 'id' if api == 2 else 'name'

    rev = model.Session.query(model.Revision).get(id)
    if rev is None:
        raise NotFound
    rev_dict = model.revision_as_dict(rev, include_packages=True,
                                      ref_package_by=ref_package_by)
    return rev_dict


def _group_or_org_show(context, data_dict, is_org=False):
    model = context['model']
    id = _get_or_bust(data_dict, 'id')

    group = model.Group.get(id)
    context['group'] = group

    include_datasets = data_dict.get('include_datasets', True)
    if isinstance(include_datasets, basestring):
        include_datasets = (include_datasets.lower() in ('true', '1'))
    context['include_datasets'] = include_datasets

    if group is None:
        raise NotFound
    if is_org and not group.is_organization:
        raise NotFound
    if not is_org and group.is_organization:
        raise NotFound

    if is_org:
        _check_access('organization_show', context, data_dict)
    else:
        _check_access('group_show', context, data_dict)

    group_dict = model_dictize.group_dictize(group, context)

    if is_org:
        plugin_type = plugins.IOrganizationController
    else:
        plugin_type = plugins.IGroupController

    for item in plugins.PluginImplementations(plugin_type):
        item.read(group)

    group_plugin = lib_plugins.lookup_group_plugin(group_dict['type'])
    try:
        schema = group_plugin.db_to_form_schema_options({
            'type': 'show',
            'api': 'api_version' in context,
            'context': context})
    except AttributeError:
        schema = group_plugin.db_to_form_schema()

    group_dict['num_followers'] = logic.get_action('group_follower_count')(
        {'model': model, 'session': model.Session},
        {'id': group_dict['id']})

    if schema is None:
        schema = logic.schema.default_show_group_schema()
    group_dict, errors = lib_plugins.plugin_validate(
        group_plugin, context, group_dict, schema,
        'organization_show' if is_org else 'group_show')
    return group_dict


def group_show(context, data_dict):
    '''Return the details of a group.

    :param id: the id or name of the group
    :type id: string
    :param include_datasets: include a list of the group's datasets
         (optional, default: ``True``)
    :type id: boolean

    :rtype: dictionary

    .. note:: Only its first 1000 datasets are returned

    '''
    return _group_or_org_show(context, data_dict)


def organization_show(context, data_dict):
    '''Return the details of a organization.

    :param id: the id or name of the organization
    :type id: string
    :param include_datasets: include a list of the organization's datasets
         (optional, default: ``True``)
    :type id: boolean

    :rtype: dictionary

    .. note:: Only its first 1000 datasets are returned
    '''
    return _group_or_org_show(context, data_dict, is_org=True)


def group_package_show(context, data_dict):
    '''Return the datasets (packages) of a group.

    :param id: the id or name of the group
    :type id: string
    :param limit: the maximum number of datasets to return (optional)
    :type limit: int

    :rtype: list of dictionaries

    '''
    model = context['model']
    group_id = _get_or_bust(data_dict, 'id')

    # FIXME: What if limit is not an int? Schema and validation needed.
    limit = data_dict.get('limit')

    group = model.Group.get(group_id)
    context['group'] = group
    if group is None:
        raise NotFound

    _check_access('group_show', context, data_dict)

    result = []
    for pkg_rev in group.packages(
            limit=limit,
            return_query=context.get('return_query')):
        result.append(model_dictize.package_dictize(pkg_rev, context))

    return result


def tag_show(context, data_dict):
    '''Return the details of a tag and all its datasets.

    :param id: the name or id of the tag
    :type id: string

    :returns: the details of the tag, including a list of all of the tag's
        datasets and their details
    :rtype: dictionary
    '''

    model = context['model']
    id = _get_or_bust(data_dict, 'id')

    tag = model.Tag.get(id)
    context['tag'] = tag

    if tag is None:
        raise NotFound

    _check_access('tag_show', context, data_dict)
    return model_dictize.tag_dictize(tag, context)


def user_show(context, data_dict):
    '''Return a user account.

    Either the ``id`` or the ``user_obj`` parameter must be given.

    :param id: the id or name of the user (optional)
    :type id: string
    :param user_obj: the user dictionary of the user (optional)
    :type user_obj: user dictionary

    :rtype: dictionary

    '''
    model = context['model']

    id = data_dict.get('id', None)
    provided_user = data_dict.get('user_obj', None)
    if id:
        user_obj = model.User.get(id)
        context['user_obj'] = user_obj
        if user_obj is None:
            raise NotFound
    elif provided_user:
        context['user_obj'] = user_obj = provided_user
    else:
        raise NotFound

    _check_access('user_show', context, data_dict)

    user_dict = model_dictize.user_dictize(user_obj, context)

    if context.get('return_minimal'):
        return user_dict

    revisions_q = model.Session.query(model.Revision).filter_by(
        author=user_obj.name)

    revisions_list = []
    for revision in revisions_q.limit(20).all():
        revision_dict = logic.get_action('revision_show')(
            context, {'id': revision.id})
        revision_dict['state'] = revision.state
        revisions_list.append(revision_dict)
    user_dict['activity'] = revisions_list

    user_dict['datasets'] = []
    dataset_q = (model.Session.query(model.Package)
                 .join(model.PackageRole)
                 .filter_by(user=user_obj, role=model.Role.ADMIN)
                 .limit(50))

    for dataset in dataset_q:
        try:
            dataset_dict = logic.get_action('package_show')(
                context, {'id': dataset.id})
        except logic.NotAuthorized:
            continue
        user_dict['datasets'].append(dataset_dict)

    user_dict['num_followers'] = logic.get_action('user_follower_count')(
        {'model': model, 'session': model.Session},
        {'id': user_dict['id']})

    return user_dict


def package_show_rest(context, data_dict):
    _check_access('package_show_rest', context, data_dict)

    logic.get_action('package_show')(context, data_dict)

    pkg = context['package']

    package_dict = model_dictize.package_to_api(pkg, context)

    return package_dict


def group_show_rest(context, data_dict):
    _check_access('group_show_rest', context, data_dict)

    logic.get_action('group_show')(context, data_dict)
    group = context['group']

    group_dict = model_dictize.group_to_api(group, context)

    return group_dict


def tag_show_rest(context, data_dict):
    _check_access('tag_show_rest', context, data_dict)

    logic.get_action('tag_show')(context, data_dict)
    tag = context['tag']

    tag_dict = model_dictize.tag_to_api(tag, context)

    return tag_dict


@logic.validate(logic.schema.default_autocomplete_schema)
def package_autocomplete(context, data_dict):
    '''Return a list of datasets (packages) that match a string.

    Datasets with names or titles that contain the query string will be
    returned.

    :param q: the string to search for
    :type q: string
    :param limit: the maximum number of resource formats to return (optional,
        default: 10)
    :type limit: int

    :rtype: list of dictionaries

    '''
    model = context['model']

    _check_access('package_autocomplete', context, data_dict)

    limit = data_dict.get('limit', 10)
    q = data_dict['q']

    like_q = u"%s%%" % q

    query = model.Session.query(model.PackageRevision)
    query = query.filter(model.PackageRevision.state == 'active')
    query = query.filter(model.PackageRevision.current == True)
    query = query.filter(_or_(model.PackageRevision.name.ilike(like_q),
                              model.PackageRevision.title.ilike(like_q)))
    query = query.limit(limit)

    q_lower = q.lower()
    pkg_list = []
    for package in query:
        if package.name.startswith(q_lower):
            match_field = 'name'
            match_displayed = package.name
        else:
            match_field = 'title'
            match_displayed = '%s (%s)' % (package.title, package.name)
        result_dict = {
            'name': package.name,
            'title': package.title,
            'match_field': match_field,
            'match_displayed': match_displayed}
        pkg_list.append(result_dict)

    return pkg_list


@logic.validate(logic.schema.default_autocomplete_schema)
def format_autocomplete(context, data_dict):
    '''Return a list of resource formats whose names contain a string.

    :param q: the string to search for
    :type q: string
    :param limit: the maximum number of resource formats to return (optional,
        default: 5)
    :type limit: int

    :rtype: list of strings

    '''
    model = context['model']
    session = context['session']

    _check_access('format_autocomplete', context, data_dict)

    q = data_dict['q']
    limit = data_dict.get('limit', 5)

    like_q = u'%' + q + u'%'

    query = (session.query(
        model.ResourceRevision.format,
        _func.count(model.ResourceRevision.format).label('total'))
        .filter(_and_(
            model.ResourceRevision.state == 'active',
            model.ResourceRevision.current == True
        ))
        .filter(model.ResourceRevision.format.ilike(like_q))
        .group_by(model.ResourceRevision.format)
        .order_by('total DESC')
        .limit(limit))

    return [resource.format.lower() for resource in query]


@logic.validate(logic.schema.default_autocomplete_schema)
def user_autocomplete(context, data_dict):
    '''Return a list of user names that contain a string.

    :param q: the string to search for
    :type q: string
    :param limit: the maximum number of user names to return (optional,
        default: 20)
    :type limit: int

    :rtype: a list of user dictionaries each with keys ``'name'``,
        ``'fullname'``, and ``'id'``

    '''
    model = context['model']
    user = context['user']

    _check_access('user_autocomplete', context, data_dict)

    q = data_dict['q']
    limit = data_dict.get('limit', 20)

    query = model.User.search(q)
    query = query.filter(model.User.state != model.State.DELETED)
    query = query.limit(limit)

    user_list = []
    for user in query.all():
        result_dict = {}
        for k in ['id', 'name', 'fullname']:
            result_dict[k] = getattr(user, k)

        user_list.append(result_dict)

    return user_list


def package_search(context, data_dict):
    '''
    Searches for packages satisfying a given search criteria.

    This action accepts solr search query parameters (details below), and
    returns a dictionary of results, including dictized datasets that match
    the search criteria, a search count and also facet information.

    **Solr Parameters:**

    For more in depth treatment of each paramter, please read the `Solr
    Documentation <http://wiki.apache.org/solr/CommonQueryParameters>`_.

    This action accepts a *subset* of solr's search query parameters:


    :param q: the solr query.  Optional.  Default: ``"*:*"``
    :type q: string
    :param fq: any filter queries to apply.  Note: ``+site_id:{ckan_site_id}``
        is added to this string prior to the query being executed.
    :type fq: string
    :param sort: sorting of the search results.  Optional.  Default:
        ``'relevance asc, metadata_modified desc'``.  As per the solr
        documentation, this is a comma-separated string of field names and
        sort-orderings.
    :type sort: string
    :param rows: the number of matching rows to return.
    :type rows: int
    :param start: the offset in the complete result for where the set of
        returned datasets should begin.
    :type start: int
    :param facet: whether to enable faceted results.  Default: ``True``.
    :type facet: string
    :param facet.mincount: the minimum counts for facet fields should be
        included in the results.
    :type facet.mincount: int
    :param facet.limit: the maximum number of values the facet fields return.
        A negative value means unlimited. This can be set instance-wide with
        the :ref:`search.facets.limit` config option. Default is 50.
    :type facet.limit: int
    :param facet.field: the fields to facet upon.  Default empty.  If empty,
        then the returned facet information is empty.
    :type facet.field: list of strings


    The following advanced Solr parameters are supported as well. Note that
    some of these are only available on particular Solr versions. See Solr's
    `dismax`_ and `edismax`_ documentation for further details on them:

    ``qf``, ``wt``, ``bf``, ``boost``, ``tie``, ``defType``, ``mm``


    .. _dismax: http://wiki.apache.org/solr/DisMaxQParserPlugin
    .. _edismax: http://wiki.apache.org/solr/ExtendedDisMax


    **Results:**

    The result of this action is a dict with the following keys:

    :rtype: A dictionary with the following keys
    :param count: the number of results found.  Note, this is the total number
        of results found, not the total number of results returned (which is
        affected by limit and row parameters used in the input).
    :type count: int
    :param results: ordered list of datasets matching the query, where the
        ordering defined by the sort parameter used in the query.
    :type results: list of dictized datasets.
    :param facets: DEPRECATED.  Aggregated information about facet counts.
    :type facets: DEPRECATED dict
    :param search_facets: aggregated information about facet counts.  The outer
        dict is keyed by the facet field name (as used in the search query).
        Each entry of the outer dict is itself a dict, with a "title" key, and
        an "items" key.  The "items" key's value is a list of dicts, each with
        "count", "display_name" and "name" entries.  The display_name is a
        form of the name that can be used in titles.
    :type search_facets: nested dict of dicts.
    :param use_default_schema: use default package schema instead of
        a custom schema defined with an IDatasetForm plugin (default: False)
    :type use_default_schema: bool

    An example result: ::

     {'count': 2,
      'results': [ { <snip> }, { <snip> }],
      'search_facets': {u'tags': {'items': [{'count': 1,
                                             'display_name': u'tolstoy',
                                             'name': u'tolstoy'},
                                            {'count': 2,
                                             'display_name': u'russian',
                                             'name': u'russian'}
                                           ]
                                 }
                       }
     }

    **Limitations:**

    The full solr query language is not exposed, including.

    fl
        The parameter that controls which fields are returned in the solr
        query cannot be changed.  CKAN always returns the matched datasets as
        dictionary objects.
    '''
    # sometimes context['schema'] is None
    schema = (context.get('schema') or
              logic.schema.default_package_search_schema())
    data_dict, errors = _validate(data_dict, schema, context)
    # put the extras back into the data_dict so that the search can
    # report needless parameters
    data_dict.update(data_dict.get('__extras', {}))
    data_dict.pop('__extras', None)
    if errors:
        raise ValidationError(errors)

    model = context['model']
    session = context['session']

    _check_access('package_search', context, data_dict)

    # Move ext_ params to extras and remove them from the root of the search
    # params, so they don't cause and error
    data_dict['extras'] = data_dict.get('extras', {})
    for key in [key for key in data_dict.keys() if key.startswith('ext_')]:
        data_dict['extras'][key] = data_dict.pop(key)

    # check if some extension needs to modify the search params
    for item in plugins.PluginImplementations(plugins.IPackageController):
        data_dict = item.before_search(data_dict)

    # the extension may have decided that it is not necessary to perform
    # the query
    abort = data_dict.get('abort_search', False)

    if data_dict.get('sort') in (None, 'rank'):
        data_dict['sort'] = 'score desc, metadata_modified desc'

    results = []
    if not abort:
        data_source = 'data_dict' if data_dict.get('use_default_schema') else 'validated_data_dict'
        # return a list of package ids
        data_dict['fl'] = 'id {0}'.format(data_source)

        # If this query hasn't come from a controller that has set this flag
        # then we should remove any mention of capacity from the fq and
        # instead set it to only retrieve public datasets
        fq = data_dict.get('fq', '')
        if not context.get('ignore_capacity_check', False):
            fq = ' '.join(p for p in fq.split(' ')
                          if not 'capacity:' in p)
            data_dict['fq'] = fq + ' capacity:"public"'

        # Pop these ones as Solr does not need them
        extras = data_dict.pop('extras', None)

        query = search.query_for(model.Package)
        query.run(data_dict)

        # Add them back so extensions can use them on after_search
        data_dict['extras'] = extras

        for package in query.results:
            # get the package object
            package, package_dict = package['id'], package.get(data_source)
            pkg_query = session.query(model.PackageRevision)\
                .filter(model.PackageRevision.id == package)\
                .filter(_and_(
                    model.PackageRevision.state == u'active',
                    model.PackageRevision.current == True
                ))
            pkg = pkg_query.first()

            ## if the index has got a package that is not in ckan then
            ## ignore it.
            if not pkg:
                log.warning('package %s in index but not in database'
                            % package)
                continue
            ## use data in search index if there
            if package_dict:
                ## the package_dict still needs translating when being viewed
                package_dict = json.loads(package_dict)
                if context.get('for_view'):
                    for item in plugins.PluginImplementations(
                            plugins.IPackageController):
                        package_dict = item.before_view(package_dict)
                results.append(package_dict)
            else:
                results.append(model_dictize.package_dictize(pkg, context))

        count = query.count
        facets = query.facets
    else:
        count = 0
        facets = {}
        results = []

    search_results = {
        'count': count,
        'facets': facets,
        'results': results,
        'sort': data_dict['sort']
    }

    # Transform facets into a more useful data structure.
    restructured_facets = {}
    for key, value in facets.items():
        restructured_facets[key] = {
            'title': key,
            'items': []
        }
        for key_, value_ in value.items():
            new_facet_dict = {}
            new_facet_dict['name'] = key_
            if key in ('groups', 'organization'):
                group = model.Group.get(key_)
                if group:
                    new_facet_dict['display_name'] = group.display_name
                else:
                    new_facet_dict['display_name'] = key_
            elif key == 'license_id':
                license = model.Package.get_license_register().get(key_)
                if license:
                    new_facet_dict['display_name'] = license.title
                else:
                    new_facet_dict['display_name'] = key_
            else:
                new_facet_dict['display_name'] = key_
            new_facet_dict['count'] = value_
            restructured_facets[key]['items'].append(new_facet_dict)
    search_results['search_facets'] = restructured_facets

    # check if some extension needs to modify the search results
    for item in plugins.PluginImplementations(plugins.IPackageController):
        search_results = item.after_search(search_results, data_dict)

    # After extensions have had a chance to modify the facets, sort them by
    # display name.
    for facet in search_results['search_facets']:
        search_results['search_facets'][facet]['items'] = sorted(
            search_results['search_facets'][facet]['items'],
            key=lambda facet: facet['display_name'], reverse=True)

    return search_results


@logic.validate(logic.schema.default_resource_search_schema)
def resource_search(context, data_dict):
    '''
    Searches for resources satisfying a given search criteria.

    It returns a dictionary with 2 fields: ``count`` and ``results``.  The
    ``count`` field contains the total number of Resources found without the
    limit or query parameters having an effect.  The ``results`` field is a
    list of dictized Resource objects.

    The 'query' parameter is a required field.  It is a string of the form
    ``{field}:{term}`` or a list of strings, each of the same form.  Within
    each string, ``{field}`` is a field or extra field on the Resource domain
    object.

    If ``{field}`` is ``"hash"``, then an attempt is made to match the
    `{term}` as a *prefix* of the ``Resource.hash`` field.

    If ``{field}`` is an extra field, then an attempt is made to match against
    the extra fields stored against the Resource.

    Note: The search is limited to search against extra fields declared in
    the config setting ``ckan.extra_resource_fields``.

    Note: Due to a Resource's extra fields being stored as a json blob, the
    match is made against the json string representation.  As such, false
    positives may occur:

    If the search criteria is: ::

        query = "field1:term1"

    Then a json blob with the string representation of: ::

        {"field1": "foo", "field2": "term1"}

    will match the search criteria!  This is a known short-coming of this
    approach.

    All matches are made ignoring case; and apart from the ``"hash"`` field,
    a term matches if it is a substring of the field's value.

    Finally, when specifying more than one search criteria, the criteria are
    AND-ed together.

    The ``order`` parameter is used to control the ordering of the results.
    Currently only ordering one field is available, and in ascending order
    only.

    The ``fields`` parameter is deprecated as it is not compatible with calling
    this action with a GET request to the action API.

    The context may contain a flag, `search_query`, which if True will make
    this action behave as if being used by the internal search api.  ie - the
    results will not be dictized, and SearchErrors are thrown for bad search
    queries (rather than ValidationErrors).

    :param query: The search criteria.  See above for description.
    :type query: string or list of strings of the form ``{field}:{term1}``
    :param fields: Deprecated
    :type fields: dict of fields to search terms.
    :param order_by: A field on the Resource model that orders the results.
    :type order_by: string
    :param offset: Apply an offset to the query.
    :type offset: int
    :param limit: Apply a limit to the query.
    :type limit: int

    :returns:  A dictionary with a ``count`` field, and a ``results`` field.
    :rtype: dict

    '''
    model = context['model']

    # Allow either the `query` or `fields` parameter to be given, but not both.
    # Once `fields` parameter is dropped, this can be made simpler.
    # The result of all this gumpf is to populate the local `fields` variable
    # with mappings from field names to list of search terms, or a single
    # search-term string.
    query = data_dict.get('query')
    fields = data_dict.get('fields')

    if query is None and fields is None:
        raise ValidationError({'query': _('Missing value')})

    elif query is not None and fields is not None:
        raise ValidationError(
            {'fields': _('Do not specify if using "query" parameter')})

    elif query is not None:
        if isinstance(query, basestring):
            query = [query]
        try:
            fields = dict(pair.split(":", 1) for pair in query)
        except ValueError:
            raise ValidationError(
                {'query': _('Must be <field>:<value> pair(s)')})

    else:
        log.warning('Use of the "fields" parameter in resource_search is '
                    'deprecated.  Use the "query" parameter instead')

        # The legacy fields paramter splits string terms.
        # So maintain that behaviour
        split_terms = {}
        for field, terms in fields.items():
            if isinstance(terms, basestring):
                terms = terms.split()
            split_terms[field] = terms
        fields = split_terms

    order_by = data_dict.get('order_by')
    offset = data_dict.get('offset')
    limit = data_dict.get('limit')

    q = (model.Session.query(model.Resource)
         .join(model.ResourceGroup)
         .join(model.Package))
    q = q.filter(model.Package.state == 'active')
    q = q.filter(model.Package.private == False)
    q = q.filter(model.Resource.state == 'active')

    resource_fields = model.Resource.get_columns()
    for field, terms in fields.items():

        if isinstance(terms, basestring):
            terms = [terms]

        if field not in resource_fields:
            msg = _('Field "{field}" not recognised in resource_search.')\
                .format(field=field)

            # Running in the context of the internal search api.
            if context.get('search_query', False):
                raise search.SearchError(msg)

            # Otherwise, assume we're in the context of an external api
            # and need to provide meaningful external error messages.
            raise ValidationError({'query': msg})

        for term in terms:

            # prevent pattern injection
            term = misc.escape_sql_like_special_characters(term)

            model_attr = getattr(model.Resource, field)

            # Treat the has field separately, see docstring.
            if field == 'hash':
                q = q.filter(model_attr.ilike(unicode(term) + '%'))

            # Resource extras are stored in a json blob.  So searching for
            # matching fields is a bit trickier.  See the docstring.
            elif field in model.Resource.get_extra_columns():
                model_attr = getattr(model.Resource, 'extras')

                like = _or_(
                    model_attr.ilike(
                        u'''%%"%s": "%%%s%%",%%''' % (field, term)),
                    model_attr.ilike(
                        u'''%%"%s": "%%%s%%"}''' % (field, term))
                )
                q = q.filter(like)

            # Just a regular field
            else:
                q = q.filter(model_attr.ilike('%' + unicode(term) + '%'))

    if order_by is not None:
        if hasattr(model.Resource, order_by):
            q = q.order_by(getattr(model.Resource, order_by))

    count = q.count()
    q = q.offset(offset)
    q = q.limit(limit)

    results = []
    for result in q:
        if isinstance(result, tuple) \
                and isinstance(result[0], model.DomainObject):
            # This is the case for order_by rank due to the add_column.
            results.append(result[0])
        else:
            results.append(result)

    # If run in the context of a search query, then don't dictize the results.
    if not context.get('search_query', False):
        results = model_dictize.resource_list_dictize(results, context)

    return {'count': count,
            'results': results}


def _tag_search(context, data_dict):
    model = context['model']

    terms = data_dict.get('query') or data_dict.get('q') or []
    if isinstance(terms, basestring):
        terms = [terms]
    terms = [t.strip() for t in terms if t.strip()]

    if 'fields' in data_dict:
        log.warning('"fields" parameter is deprecated.  '
                    'Use the "query" parameter instead')

    fields = data_dict.get('fields', {})
    offset = data_dict.get('offset')
    limit = data_dict.get('limit')

    # TODO: should we check for user authentication first?
    q = model.Session.query(model.Tag)

    if 'vocabulary_id' in data_dict:
        # Filter by vocabulary.
        vocab = model.Vocabulary.get(_get_or_bust(data_dict, 'vocabulary_id'))
        if not vocab:
            raise NotFound
        q = q.filter(model.Tag.vocabulary_id == vocab.id)
    else:
        # If no vocabulary_name in data dict then show free tags only.
        q = q.filter(model.Tag.vocabulary_id == None)
        # If we're searching free tags, limit results to tags that are
        # currently applied to a package.
        q = q.distinct().join(model.Tag.package_tags)

    for field, value in fields.items():
        if field in ('tag', 'tags'):
            terms.append(value)

    if not len(terms):
        return [], 0

    for term in terms:
        escaped_term = misc.escape_sql_like_special_characters(
            term, escape='\\')
        q = q.filter(model.Tag.name.ilike('%' + escaped_term + '%'))

    count = q.count()
    q = q.offset(offset)
    q = q.limit(limit)
    return q.all(), count


def tag_search(context, data_dict):
    '''Return a list of tags whose names contain a given string.

    By default only free tags (tags that don't belong to any vocabulary) are
    searched. If the ``vocabulary_id`` argument is given then only tags
    belonging to that vocabulary will be searched instead.

    :param query: the string(s) to search for
    :type query: string or list of strings
    :param vocabulary_id: the id or name of the tag vocabulary to search in
      (optional)
    :type vocabulary_id: string
    :param fields: deprecated
    :type fields: dictionary
    :param limit: the maximum number of tags to return
    :type limit: int
    :param offset: when ``limit`` is given, the offset to start returning tags
        from
    :type offset: int

    :returns: A dictionary with the following keys:

      ``'count'``
        The number of tags in the result.

      ``'results'``
        The list of tags whose names contain the given string, a list of
        dictionaries.

    :rtype: dictionary

    '''
    tags, count = _tag_search(context, data_dict)
    return {'count': count,
            'results': [_table_dictize(tag, context) for tag in tags]}


def tag_autocomplete(context, data_dict):
    '''Return a list of tag names that contain a given string.

    By default only free tags (tags that don't belong to any vocabulary) are
    searched. If the ``vocabulary_id`` argument is given then only tags
    belonging to that vocabulary will be searched instead.

    :param query: the string to search for
    :type query: string
    :param vocabulary_id: the id or name of the tag vocabulary to search in
      (optional)
    :type vocabulary_id: string
    :param fields: deprecated
    :type fields: dictionary
    :param limit: the maximum number of tags to return
    :type limit: int
    :param offset: when ``limit`` is given, the offset to start returning tags
        from
    :type offset: int

    :rtype: list of strings

    '''
    _check_access('tag_autocomplete', context, data_dict)
    matching_tags, count = _tag_search(context, data_dict)
    if matching_tags:
        return [tag.name for tag in matching_tags]
    else:
        return []


def task_status_show(context, data_dict):
    '''Return a task status.

    Either the ``id`` parameter *or* the ``entity_id``, ``task_type`` *and*
    ``key`` parameters must be given.

    :param id: the id of the task status (optional)
    :type id: string
    :param entity_id: the entity_id of the task status (optional)
    :type entity_id: string
    :param task_type: the task_type of the task status (optional)
    :type tast_type: string
    :param key: the key of the task status (optional)
    :type key: string

    :rtype: dictionary
    '''
    model = context['model']
    id = data_dict.get('id')

    if id:
        task_status = model.TaskStatus.get(id)
    else:
        query = model.Session.query(model.TaskStatus)\
            .filter(_and_(
                model.TaskStatus.entity_id
                == _get_or_bust(data_dict, 'entity_id'),
                model.TaskStatus.task_type
                == _get_or_bust(data_dict, 'task_type'),
                model.TaskStatus.key
                == _get_or_bust(data_dict, 'key')
            ))
        task_status = query.first()

    context['task_status'] = task_status

    _check_access('task_status_show', context, data_dict)

    if task_status is None:
        raise NotFound

    task_status_dict = model_dictize.task_status_dictize(task_status, context)
    return task_status_dict


def term_translation_show(context, data_dict):
    '''Return the translations for the given term(s) and language(s).

    :param terms: the terms to search for translations of, e.g. ``'Russian'``,
        ``'romantic novel'``
    :type terms: list of strings
    :param lang_codes: the language codes of the languages to search for
        translations into, e.g. ``'en'``, ``'de'`` (optional, default is to
        search for translations into any language)
    :type lang_codes: list of language code strings

    :rtype: a list of term translation dictionaries each with keys ``'term'``
        (the term searched for, in the source language), ``'term_translation'``
        (the translation of the term into the target language) and
        ``'lang_code'`` (the language code of the target language)
    '''
    model = context['model']

    trans_table = model.term_translation_table

    q = _select([trans_table])

    if 'terms' not in data_dict:
        raise ValidationError({'terms': 'terms not in data'})

    # This action accepts `terms` as either a list of strings, or a single
    # string.
    terms = _get_or_bust(data_dict, 'terms')
    if isinstance(terms, basestring):
        terms = [terms]
    if terms:
        q = q.where(trans_table.c.term.in_(terms))

    # This action accepts `lang_codes` as either a list of strings, or a single
    # string.
    if 'lang_codes' in data_dict:
        lang_codes = _get_or_bust(data_dict, 'lang_codes')
        if isinstance(lang_codes, basestring):
            lang_codes = [lang_codes]
        q = q.where(trans_table.c.lang_code.in_(lang_codes))

    conn = model.Session.connection()
    cursor = conn.execute(q)

    results = []

    for row in cursor:
        results.append(_table_dictize(row, context))

    return results


# Only internal services are allowed to call get_site_user.
def get_site_user(context, data_dict):
    '''Return the ckan site user

    :param defer_commit: by default (or if set to false) get_site_user will
        commit and clean up the current transaction, it will also close and
        discard the current session in the context. If set to true, caller
        is responsible for commiting transaction after get_site_user is
        called. Leaving open connections can cause cli commands to hang!
        (optional, default: False)
    :type defer_commit: boolean
    '''
    _check_access('get_site_user', context, data_dict)
    model = context['model']
    site_id = config.get('ckan.site_id', 'ckan_site_user')
    user = model.User.get(site_id)
    if not user:
        apikey = str(uuid.uuid4())
        user = model.User(name=site_id,
                          password=apikey,
                          apikey=apikey)
        # make sysadmin
        user.sysadmin = True
        model.Session.add(user)
        model.Session.flush()
    if not context.get('defer_commit'):
        model.repo.commit_and_remove()

    return {'name': user.name,
            'apikey': user.apikey}


def roles_show(context, data_dict):
    '''Return the roles of all users and authorization groups for an object.

    :param domain_object: a package or group name or id
        to filter the results by
    :type domain_object: string
    :param user: a user name or id
    :type user: string

    :rtype: list of dictionaries

    '''
    model = context['model']
    session = context['session']
    domain_object_ref = _get_or_bust(data_dict, 'domain_object')
    user_ref = data_dict.get('user')

    domain_object = ckan.logic.action.get_domain_object(
        model, domain_object_ref)
    if isinstance(domain_object, model.Package):
        query = session.query(model.PackageRole).join('package')
    elif isinstance(domain_object, model.Group):
        query = session.query(model.GroupRole).join('group')
    elif domain_object is model.System:
        query = session.query(model.SystemRole)
    else:
        raise NotFound(_('Cannot list entity of this type: %s')
                       % type(domain_object).__name__)
    # Filter by the domain_obj (apart from if it is the system object)
    if not isinstance(domain_object, type):
        query = query.filter_by(id=domain_object.id)

    # Filter by the user
    if user_ref:
        user = model.User.get(user_ref)
        if not user:
            raise NotFound(_('unknown user:') + repr(user_ref))
        query = query.join('user').filter_by(id=user.id)

    uors = query.all()

    uors_dictized = [_table_dictize(uor, context) for uor in uors]

    result = {
        'domain_object_type': type(domain_object).__name__,
        'domain_object_id':
        domain_object.id if domain_object != model.System else None,
        'roles': uors_dictized}
    if user_ref:
        result['user'] = user.id

    return result


def status_show(context, data_dict):
    '''Return a dictionary with information about the site's configuration.

    :rtype: dictionary

    '''
    return {
        'site_title': config.get('ckan.site_title'),
        'site_description': config.get('ckan.site_description'),
        'site_url': config.get('ckan.site_url'),
        'ckan_version': ckan.__version__,
        'error_emails_to': config.get('email_to'),
        'locale_default': config.get('ckan.locale_default'),
        'extensions': config.get('ckan.plugins').split(),
    }


def vocabulary_list(context, data_dict):
    '''Return a list of all the site's tag vocabularies.

    :rtype: list of dictionaries

    '''
    model = context['model']
    vocabulary_objects = model.Session.query(model.Vocabulary).all()
    return model_dictize.vocabulary_list_dictize(vocabulary_objects, context)


def vocabulary_show(context, data_dict):
    '''Return a single tag vocabulary.

    :param id: the id or name of the vocabulary
    :type id: string
    :return: the vocabulary.
    :rtype: dictionary

    '''
    model = context['model']
    vocab_id = data_dict.get('id')
    if not vocab_id:
        raise ValidationError({'id': _('id not in data')})
    vocabulary = model.vocabulary.Vocabulary.get(vocab_id)
    if vocabulary is None:
        raise NotFound(_('Could not find vocabulary "%s"') % vocab_id)
    vocabulary_dict = model_dictize.vocabulary_dictize(vocabulary, context)
    return vocabulary_dict


@logic.validate(logic.schema.default_activity_list_schema)
def user_activity_list(context, data_dict):
    '''Return a user's public activity stream.

    You must be authorized to view the user's profile.


    :param id: the id or name of the user
    :type id: string
    :param offset: where to start getting activity items from
        (optional, default: 0)
    :type offset: int
    :param limit: the maximum number of activities to return
        (optional, default: 31, the default value is configurable via the
        ckan.activity_list_limit setting)
    :type limit: int

    :rtype: list of dictionaries

    '''
    # FIXME: Filter out activities whose subject or object the user is not
    # authorized to read.
    _check_access('user_show', context, data_dict)

    model = context['model']

    user_ref = data_dict.get('id')  # May be user name or id.
    user = model.User.get(user_ref)
    if user is None:
        raise logic.NotFound

    offset = data_dict.get('offset', 0)
    limit = int(
        data_dict.get('limit', config.get('ckan.activity_list_limit', 31)))

    _activity_objects = model.activity.user_activity_list(user.id, limit=limit,
            offset=offset)
    activity_objects = _filter_activity_by_user(_activity_objects,
            _activity_stream_get_filtered_users())

    return model_dictize.activity_list_dictize(activity_objects, context)


@logic.validate(logic.schema.default_activity_list_schema)
def package_activity_list(context, data_dict):
    '''Return a package's activity stream.

    You must be authorized to view the package.

    :param id: the id or name of the package
    :type id: string
    :param offset: where to start getting activity items from
        (optional, default: 0)
    :type offset: int
    :param limit: the maximum number of activities to return
        (optional, default: 31, the default value is configurable via the
        ckan.activity_list_limit setting)
    :type limit: int

    :rtype: list of dictionaries

    '''
    # FIXME: Filter out activities whose subject or object the user is not
    # authorized to read.
    _check_access('package_show', context, data_dict)

    model = context['model']

    package_ref = data_dict.get('id')  # May be name or ID.
    package = model.Package.get(package_ref)
    if package is None:
        raise logic.NotFound

    offset = int(data_dict.get('offset', 0))
    limit = int(
        data_dict.get('limit', config.get('ckan.activity_list_limit', 31)))

    _activity_objects = model.activity.package_activity_list(package.id,
            limit=limit, offset=offset)
    activity_objects = _filter_activity_by_user(_activity_objects,
            _activity_stream_get_filtered_users())

    return model_dictize.activity_list_dictize(activity_objects, context)


@logic.validate(logic.schema.default_activity_list_schema)
def group_activity_list(context, data_dict):
    '''Return a group's activity stream.

    You must be authorized to view the group.

    :param id: the id or name of the group
    :type id: string
    :param offset: where to start getting activity items from
        (optional, default: 0)
    :type offset: int
    :param limit: the maximum number of activities to return
        (optional, default: 31, the default value is configurable via the
        ckan.activity_list_limit setting)
    :type limit: int

    :rtype: list of dictionaries

    '''
    # FIXME: Filter out activities whose subject or object the user is not
    # authorized to read.
    _check_access('group_show', context, data_dict)

    model = context['model']
    group_id = data_dict.get('id')
    offset = data_dict.get('offset', 0)
    limit = int(
        data_dict.get('limit', config.get('ckan.activity_list_limit', 31)))

    # Convert group_id (could be id or name) into id.
    group_show = logic.get_action('group_show')
    group_id = group_show(context, {'id': group_id})['id']

    _activity_objects = model.activity.group_activity_list(group_id,
            limit=limit, offset=offset)
    activity_objects = _filter_activity_by_user(_activity_objects,
            _activity_stream_get_filtered_users())

    return model_dictize.activity_list_dictize(activity_objects, context)


@logic.validate(logic.schema.default_activity_list_schema)
def organization_activity_list(context, data_dict):
    '''Return a organization's activity stream.

    :param id: the id or name of the organization
    :type id: string

    :rtype: list of dictionaries

    '''
    # FIXME: Filter out activities whose subject or object the user is not
    # authorized to read.
    _check_access('organization_show', context, data_dict)

    model = context['model']
    org_id = data_dict.get('id')
    offset = data_dict.get('offset', 0)
    limit = int(
        data_dict.get('limit', config.get('ckan.activity_list_limit', 31)))

    # Convert org_id (could be id or name) into id.
    org_show = logic.get_action('organization_show')
    org_id = org_show(context, {'id': org_id})['id']

    _activity_objects = model.activity.group_activity_list(org_id,
            limit=limit, offset=offset)
    activity_objects = _filter_activity_by_user(_activity_objects,
            _activity_stream_get_filtered_users())

    return model_dictize.activity_list_dictize(activity_objects, context)


@logic.validate(logic.schema.default_pagination_schema)
def recently_changed_packages_activity_list(context, data_dict):
    '''Return the activity stream of all recently added or changed packages.

    :param offset: where to start getting activity items from
        (optional, default: 0)
    :type offset: int
    :param limit: the maximum number of activities to return
        (optional, default: 31, the default value is configurable via the
        ckan.activity_list_limit setting)
    :type limit: int

    :rtype: list of dictionaries

    '''
    # FIXME: Filter out activities whose subject or object the user is not
    # authorized to read.
    model = context['model']
    offset = data_dict.get('offset', 0)
    limit = int(
        data_dict.get('limit', config.get('ckan.activity_list_limit', 31)))

    _activity_objects = model.activity.recently_changed_packages_activity_list(
            limit=limit, offset=offset)
    activity_objects = _filter_activity_by_user(_activity_objects,
            _activity_stream_get_filtered_users())

    return model_dictize.activity_list_dictize(activity_objects, context)


def activity_detail_list(context, data_dict):
    '''Return an activity's list of activity detail items.

    :param id: the id of the activity
    :type id: string
    :rtype: list of dictionaries.

    '''
    # FIXME: Filter out activities whose subject or object the user is not
    # authorized to read.
    model = context['model']
    activity_id = _get_or_bust(data_dict, 'id')
    activity_detail_objects = model.ActivityDetail.by_activity_id(activity_id)
    return model_dictize.activity_detail_list_dictize(
        activity_detail_objects, context)


def user_activity_list_html(context, data_dict):
    '''Return a user's public activity stream as HTML.

    The activity stream is rendered as a snippet of HTML meant to be included
    in an HTML page, i.e. it doesn't have any HTML header or footer.

    :param id: The id or name of the user.
    :type id: string
    :param offset: where to start getting activity items from
        (optional, default: 0)
    :type offset: int
    :param limit: the maximum number of activities to return
        (optional, default: 31, the default value is configurable via the
        ckan.activity_list_limit setting)
    :type limit: int

    :rtype: string

    '''
    activity_stream = user_activity_list(context, data_dict)
    offset = int(data_dict.get('offset', 0))
    extra_vars = {
        'controller': 'user',
        'action': 'activity',
        'id': data_dict['id'],
        'offset': offset,
    }
    return activity_streams.activity_list_to_html(
        context, activity_stream, extra_vars)


def package_activity_list_html(context, data_dict):
    '''Return a package's activity stream as HTML.

    The activity stream is rendered as a snippet of HTML meant to be included
    in an HTML page, i.e. it doesn't have any HTML header or footer.

    :param id: the id or name of the package
    :type id: string
    :param offset: where to start getting activity items from
        (optional, default: 0)
    :type offset: int
    :param limit: the maximum number of activities to return
        (optional, default: 31, the default value is configurable via the
        ckan.activity_list_limit setting)
    :type limit: int

    :rtype: string

    '''
    activity_stream = package_activity_list(context, data_dict)
    offset = int(data_dict.get('offset', 0))
    extra_vars = {
        'controller': 'package',
        'action': 'activity',
        'id': data_dict['id'],
        'offset': offset,
    }
    return activity_streams.activity_list_to_html(
        context, activity_stream, extra_vars)


def group_activity_list_html(context, data_dict):
    '''Return a group's activity stream as HTML.

    The activity stream is rendered as a snippet of HTML meant to be included
    in an HTML page, i.e. it doesn't have any HTML header or footer.

    :param id: the id or name of the group
    :type id: string
    :param offset: where to start getting activity items from
        (optional, default: 0)
    :type offset: int
    :param limit: the maximum number of activities to return
        (optional, default: 31, the default value is configurable via the
        ckan.activity_list_limit setting)
    :type limit: int

    :rtype: string

    '''
    activity_stream = group_activity_list(context, data_dict)
    offset = int(data_dict.get('offset', 0))
    extra_vars = {
        'controller': 'group',
        'action': 'activity',
        'id': data_dict['id'],
        'offset': offset,
    }
    return activity_streams.activity_list_to_html(
        context, activity_stream, extra_vars)


def organization_activity_list_html(context, data_dict):
    '''Return a organization's activity stream as HTML.

    The activity stream is rendered as a snippet of HTML meant to be included
    in an HTML page, i.e. it doesn't have any HTML header or footer.

    :param id: the id or name of the organization
    :type id: string

    :rtype: string

    '''
    activity_stream = organization_activity_list(context, data_dict)
    offset = int(data_dict.get('offset', 0))
    extra_vars = {
        'controller': 'organization',
        'action': 'activity',
        'id': data_dict['id'],
        'offset': offset,
    }

    return activity_streams.activity_list_to_html(
        context, activity_stream, extra_vars)


def recently_changed_packages_activity_list_html(context, data_dict):
    '''Return the activity stream of all recently changed packages as HTML.

    The activity stream includes all recently added or changed packages. It is
    rendered as a snippet of HTML meant to be included in an HTML page, i.e. it
    doesn't have any HTML header or footer.

    :param offset: where to start getting activity items from
        (optional, default: 0)
    :type offset: int
    :param limit: the maximum number of activities to return
        (optional, default: 31, the default value is configurable via the
        ckan.activity_list_limit setting)
    :type limit: int

    :rtype: string

    '''
    activity_stream = recently_changed_packages_activity_list(
        context, data_dict)
    offset = int(data_dict.get('offset', 0))
    extra_vars = {
        'controller': 'package',
        'action': 'activity',
        'offset': offset,
    }
    return activity_streams.activity_list_to_html(
        context, activity_stream, extra_vars)


def _follower_count(context, data_dict, default_schema, ModelClass):
    schema = context.get('schema', default_schema)
    data_dict, errors = _validate(data_dict, schema, context)
    if errors:
        raise ValidationError(errors)
    return ModelClass.follower_count(data_dict['id'])


def user_follower_count(context, data_dict):
    '''Return the number of followers of a user.

    :param id: the id or name of the user
    :type id: string

    :rtype: int

    '''
    return _follower_count(
        context, data_dict,
        ckan.logic.schema.default_follow_user_schema(),
        context['model'].UserFollowingUser)


def dataset_follower_count(context, data_dict):
    '''Return the number of followers of a dataset.

    :param id: the id or name of the dataset
    :type id: string

    :rtype: int

    '''
    return _follower_count(
        context, data_dict,
        ckan.logic.schema.default_follow_dataset_schema(),
        context['model'].UserFollowingDataset)


def group_follower_count(context, data_dict):
    '''Return the number of followers of a group.

    :param id: the id or name of the group
    :type id: string

    :rtype: int

    '''
    return _follower_count(
        context, data_dict,
        ckan.logic.schema.default_follow_group_schema(),
        context['model'].UserFollowingGroup)


def organization_follower_count(context, data_dict):
    '''Return the number of followers of an organization.

    :param id: the id or name of the organization
    :type id: string

    :rtype: int

    '''
    return group_follower_count(context, data_dict)


def _follower_list(context, data_dict, default_schema, FollowerClass):
    schema = context.get('schema', default_schema)
    data_dict, errors = _validate(data_dict, schema, context)
    if errors:
        raise ValidationError(errors)

    # Get the list of Follower objects.
    model = context['model']
    object_id = data_dict.get('id')
    followers = FollowerClass.follower_list(object_id)

    # Convert the list of Follower objects to a list of User objects.
    users = [model.User.get(follower.follower_id) for follower in followers]
    users = [user for user in users if user is not None]

    # Dictize the list of User objects.
    return model_dictize.user_list_dictize(users, context)


def user_follower_list(context, data_dict):
    '''Return the list of users that are following the given user.

    :param id: the id or name of the user
    :type id: string

    :rtype: list of dictionaries

    '''
    _check_access('user_follower_list', context, data_dict)
    return _follower_list(
        context, data_dict,
        ckan.logic.schema.default_follow_user_schema(),
        context['model'].UserFollowingUser)


def dataset_follower_list(context, data_dict):
    '''Return the list of users that are following the given dataset.

    :param id: the id or name of the dataset
    :type id: string

    :rtype: list of dictionaries

    '''
    _check_access('dataset_follower_list', context, data_dict)
    return _follower_list(
        context, data_dict,
        ckan.logic.schema.default_follow_dataset_schema(),
        context['model'].UserFollowingDataset)


def group_follower_list(context, data_dict):
    '''Return the list of users that are following the given group.

    :param id: the id or name of the group
    :type id: string

    :rtype: list of dictionaries

    '''
    _check_access('group_follower_list', context, data_dict)
    return _follower_list(
        context, data_dict,
        ckan.logic.schema.default_follow_group_schema(),
        context['model'].UserFollowingGroup)


def organization_follower_list(context, data_dict):
    '''Return the list of users that are following the given organization.

    :param id: the id or name of the organization
    :type id: string

    :rtype: list of dictionaries

    '''
    _check_access('organization_follower_list', context, data_dict)
    return _follower_list(
        context, data_dict,
        ckan.logic.schema.default_follow_group_schema(),
        context['model'].UserFollowingGroup)

def _am_following(context, data_dict, default_schema, FollowerClass):
    schema = context.get('schema', default_schema)
    data_dict, errors = _validate(data_dict, schema, context)
    if errors:
        raise ValidationError(errors)

    if 'user' not in context:
        raise logic.NotAuthorized

    model = context['model']

    userobj = model.User.get(context['user'])
    if not userobj:
        raise logic.NotAuthorized

    object_id = data_dict.get('id')

    return FollowerClass.is_following(userobj.id, object_id)


def am_following_user(context, data_dict):
    '''Return ``True`` if you're following the given user, ``False`` if not.

    :param id: the id or name of the user
    :type id: string

    :rtype: boolean

    '''
    return _am_following(
        context, data_dict,
        ckan.logic.schema.default_follow_user_schema(),
        context['model'].UserFollowingUser)


def am_following_dataset(context, data_dict):
    '''Return ``True`` if you're following the given dataset, ``False`` if not.

    :param id: the id or name of the dataset
    :type id: string

    :rtype: boolean

    '''
    return _am_following(
        context, data_dict,
        ckan.logic.schema.default_follow_dataset_schema(),
        context['model'].UserFollowingDataset)


def am_following_group(context, data_dict):
    '''Return ``True`` if you're following the given group, ``False`` if not.

    :param id: the id or name of the group
    :type id: string

    :rtype: boolean

    '''
    return _am_following(
        context, data_dict,
        ckan.logic.schema.default_follow_group_schema(),
        context['model'].UserFollowingGroup)


def _followee_count(context, data_dict, FollowerClass):
    if not context.get('skip_validation'):
        schema = context.get('schema',
                             ckan.logic.schema.default_follow_user_schema())
        data_dict, errors = _validate(data_dict, schema, context)
        if errors:
            raise ValidationError(errors)
    return FollowerClass.followee_count(data_dict['id'])


def followee_count(context, data_dict):
    '''Return the number of objects that are followed by the given user.

    Counts all objects, of any type, that the given user is following
    (e.g. followed users, followed datasets, followed groups).

    :param id: the id of the user
    :type id: string

    :rtype: int

    '''
    model = context['model']
    followee_users = _followee_count(context, data_dict,
                                     model.UserFollowingUser)

    # followee_users has validated data_dict so the following functions don't
    # need to validate it again.
    context['skip_validation'] = True

    followee_datasets = _followee_count(context, data_dict,
                                        model.UserFollowingDataset)
    followee_groups = _followee_count(context, data_dict,
                                      model.UserFollowingGroup)

    return sum((followee_users, followee_datasets, followee_groups))


def user_followee_count(context, data_dict):
    '''Return the number of users that are followed by the given user.

    :param id: the id of the user
    :type id: string

    :rtype: int

    '''
    return _followee_count(
        context, data_dict,
        context['model'].UserFollowingUser)


def dataset_followee_count(context, data_dict):
    '''Return the number of datasets that are followed by the given user.

    :param id: the id of the user
    :type id: string

    :rtype: int

    '''
    return _followee_count(
        context, data_dict,
        context['model'].UserFollowingDataset)


def group_followee_count(context, data_dict):
    '''Return the number of groups that are followed by the given user.

    :param id: the id of the user
    :type id: string

    :rtype: int

    '''
    return _followee_count(
        context, data_dict,
        context['model'].UserFollowingGroup)


@logic.validate(logic.schema.default_follow_user_schema)
def followee_list(context, data_dict):
    '''Return the list of objects that are followed by the given user.

    Returns all objects, of any type, that the given user is following
    (e.g. followed users, followed datasets, followed groups.. ).

    :param id: the id of the user
    :type id: string

    :param q: a query string to limit results by, only objects whose display
        name begins with the given string (case-insensitive) wil be returned
        (optional)
    :type q: string

    :rtype: list of dictionaries, each with keys ``'type'`` (e.g. ``'user'``,
        ``'dataset'`` or ``'group'``), ``'display_name'`` (e.g. a user's
        display name, or a package's title) and ``'dict'`` (e.g. a dict
        representing the followed user, package or group, the same as the dict
        that would be returned by :py:func:`user_show`,
        :py:func:`package_show` or :py:func:`group_show`)

    '''
    _check_access('followee_list', context, data_dict)

    def display_name(followee):
        '''Return a display name for the given user, group or dataset dict.'''
        display_name = followee.get('display_name')
        fullname = followee.get('fullname')
        title = followee.get('title')
        name = followee.get('name')
        return display_name or fullname or title or name

    # Get the followed objects.
    # TODO: Catch exceptions raised by these *_followee_list() functions?
    # FIXME should we be changing the context like this it seems dangerous
    followee_dicts = []
    context['skip_validation'] = True
    context['ignore_auth'] = True
    for followee_list_function, followee_type in (
            (user_followee_list, 'user'),
            (dataset_followee_list, 'dataset'),
            (group_followee_list, 'group'),
            (organization_followee_list, 'organization')):
        dicts = followee_list_function(context, data_dict)
        for d in dicts:
            followee_dicts.append(
                {'type': followee_type,
                 'display_name': display_name(d),
                 'dict': d})

    followee_dicts.sort(key=lambda d: d['display_name'])

    q = data_dict.get('q')
    if q:
        q = q.strip().lower()
        matching_followee_dicts = []
        for followee_dict in followee_dicts:
            if followee_dict['display_name'].strip().lower().startswith(q):
                matching_followee_dicts.append(followee_dict)
        followee_dicts = matching_followee_dicts

    return followee_dicts


def user_followee_list(context, data_dict):
    '''Return the list of users that are followed by the given user.

    :param id: the id of the user
    :type id: string

    :rtype: list of dictionaries

    '''
    _check_access('user_followee_list', context, data_dict)

    if not context.get('skip_validation'):
        schema = context.get('schema') or (
            ckan.logic.schema.default_follow_user_schema())
        data_dict, errors = _validate(data_dict, schema, context)
        if errors:
            raise ValidationError(errors)

    # Get the list of Follower objects.
    model = context['model']
    user_id = _get_or_bust(data_dict, 'id')
    followees = model.UserFollowingUser.followee_list(user_id)

    # Convert the list of Follower objects to a list of User objects.
    users = [model.User.get(followee.object_id) for followee in followees]
    users = [user for user in users if user is not None]

    # Dictize the list of User objects.
    return model_dictize.user_list_dictize(users, context)


def dataset_followee_list(context, data_dict):
    '''Return the list of datasets that are followed by the given user.

    :param id: the id or name of the user
    :type id: string

    :rtype: list of dictionaries

    '''
    _check_access('dataset_followee_list', context, data_dict)

    if not context.get('skip_validation'):
        schema = context.get('schema') or (
            ckan.logic.schema.default_follow_user_schema())
        data_dict, errors = _validate(data_dict, schema, context)
        if errors:
            raise ValidationError(errors)

    # Get the list of Follower objects.
    model = context['model']
    user_id = _get_or_bust(data_dict, 'id')
    followees = model.UserFollowingDataset.followee_list(user_id)

    # Convert the list of Follower objects to a list of Package objects.
    datasets = [model.Package.get(followee.object_id)
                for followee in followees]
    datasets = [dataset for dataset in datasets if dataset is not None]

    # Dictize the list of Package objects.
    return [model_dictize.package_dictize(dataset, context)
            for dataset in datasets]


def group_followee_list(context, data_dict):
    '''Return the list of groups that are followed by the given user.

    :param id: the id or name of the user
    :type id: string

    :rtype: list of dictionaries

    '''
    _check_access('group_followee_list', context, data_dict)

    return _group_or_org_followee_list(context, data_dict, is_org=False)


def organization_followee_list(context, data_dict):
    '''Return the list of organizations that are followed by the given user.

    :param id: the id or name of the user
    :type id: string

    :rtype: list of dictionaries

    '''

    _check_access('organization_followee_list', context, data_dict)

    return _group_or_org_followee_list(context, data_dict, is_org=True)


def _group_or_org_followee_list(context, data_dict, is_org=False):

    if not context.get('skip_validation'):
        schema = context.get('schema',
                             ckan.logic.schema.default_follow_user_schema())
        data_dict, errors = _validate(data_dict, schema, context)
        if errors:
            raise ValidationError(errors)

    # Get the list of UserFollowingGroup objects.
    model = context['model']
    user_id = _get_or_bust(data_dict, 'id')
    followees = model.UserFollowingGroup.followee_list(user_id)

    # Convert the UserFollowingGroup objects to a list of Group objects.
    groups = [model.Group.get(followee.object_id) for followee in followees]
    groups = [group for group in groups
              if group is not None and group.is_organization == is_org]

    # Dictize the list of Group objects.
    return [model_dictize.group_dictize(group, context) for group in groups]


@logic.validate(logic.schema.default_pagination_schema)
def dashboard_activity_list(context, data_dict):
    '''Return the authorized user's dashboard activity stream.

    Unlike the activity dictionaries returned by other ``*_activity_list``
    actions, these activity dictionaries have an extra boolean value with key
    ``is_new`` that tells you whether the activity happened since the user last
    viewed her dashboard (``'is_new': True``) or not (``'is_new': False``).

    The user's own activities are always marked ``'is_new': False``.

    :param offset: where to start getting activity items from
        (optional, default: 0)
    :type offset: int
    :param limit: the maximum number of activities to return
        (optional, default: 31, the default value is configurable via the
        :ref:`ckan.activity_list_limit` setting)

    :rtype: list of activity dictionaries

    '''
    _check_access('dashboard_activity_list', context, data_dict)

    model = context['model']
    user_id = model.User.get(context['user']).id
    offset = data_dict.get('offset', 0)
    limit = int(
        data_dict.get('limit', config.get('ckan.activity_list_limit', 31)))

    # FIXME: Filter out activities whose subject or object the user is not
    # authorized to read.
    _activity_objects = model.activity.dashboard_activity_list(user_id,
            limit=limit, offset=offset)

    activity_objects = _filter_activity_by_user(_activity_objects,
            _activity_stream_get_filtered_users())
    activity_dicts = model_dictize.activity_list_dictize(
        activity_objects, context)

    # Mark the new (not yet seen by user) activities.
    strptime = datetime.datetime.strptime
    fmt = '%Y-%m-%dT%H:%M:%S.%f'
    last_viewed = model.Dashboard.get(user_id).activity_stream_last_viewed
    for activity in activity_dicts:
        if activity['user_id'] == user_id:
            # Never mark the user's own activities as new.
            activity['is_new'] = False
        else:
            activity['is_new'] = (
                strptime(activity['timestamp'], fmt) > last_viewed)

    return activity_dicts


@logic.validate(ckan.logic.schema.default_pagination_schema)
def dashboard_activity_list_html(context, data_dict):
    '''Return the authorized user's dashboard activity stream as HTML.

    The activity stream is rendered as a snippet of HTML meant to be included
    in an HTML page, i.e. it doesn't have any HTML header or footer.

    :param id: the id or name of the user
    :type id: string
    :param offset: where to start getting activity items from
        (optional, default: 0)
    :type offset: int
    :param limit: the maximum number of activities to return
        (optional, default: 31, the default value is configurable via the
        ckan.activity_list_limit setting)
    :type limit: int

    :rtype: string

    '''
    activity_stream = dashboard_activity_list(context, data_dict)
    model = context['model']
    offset = data_dict.get('offset', 0)
    extra_vars = {
        'controller': 'user',
        'action': 'dashboard',
        'offset': offset,
    }
    return activity_streams.activity_list_to_html(context, activity_stream,
                                                  extra_vars)


def dashboard_new_activities_count(context, data_dict):
    '''Return the number of new activities in the user's dashboard.

    Return the number of new activities in the authorized user's dashboard
    activity stream.

    Activities from the user herself are not counted by this function even
    though they appear in the dashboard (users don't want to be notified about
    things they did themselves).

    :rtype: int

    '''
    _check_access('dashboard_new_activities_count', context, data_dict)
    activities = logic.get_action('dashboard_activity_list')(
        context, data_dict)
    return len([activity for activity in activities if activity['is_new']])


def _unpick_search(sort, allowed_fields=None, total=None):
    ''' This is a helper function that takes a sort string
    eg 'name asc, last_modified desc' and returns a list of
    split field order eg [('name', 'asc'), ('last_modified', 'desc')]
    allowed_fields can limit which field names are ok.
    total controls how many sorts can be specifed '''
    sorts = []
    split_sort = sort.split(',')
    for part in split_sort:
        split_part = part.strip().split()
        field = split_part[0]
        if len(split_part) > 1:
            order = split_part[1].lower()
        else:
            order = 'asc'
        if allowed_fields:
            if field not in allowed_fields:
                raise ValidationError('Cannot sort by field `%s`' % field)
        if order not in ['asc', 'desc']:
            raise ValidationError('Invalid sort direction `%s`' % order)
        sorts.append((field, order))
    if total and len(sorts) > total:
        raise ValidationError(
            'Too many sort criteria provided only %s allowed' % total)
    return sorts


def member_roles_list(context, data_dict):
    '''Return the possible roles for members of groups and organizations.

    :param group_type: the group type, either ``"group"`` or ``"organization"``
        (optional, default ``"organization"``)
    :type id: string
    :returns: a list of dictionaries each with two keys: ``"text"`` (the
        display name of the role, e.g. ``"Admin"``) and ``"value"`` (the
        internal name of the role, e.g. ``"admin"``)
    :rtype: list of dictionaries

    '''
    group_type = data_dict.get('group_type', 'organization')
    roles_list = new_authz.roles_list()
    if group_type == 'group':
        roles_list = [role for role in roles_list
                      if role['value'] != 'editor']

    _check_access('member_roles_list', context, data_dict)
    return roles_list

########NEW FILE########
__FILENAME__ = update
'''API functions for updating existing data in CKAN.'''

import logging
import datetime
import json

from pylons import config
from vdm.sqlalchemy.base import SQLAlchemySession
import paste.deploy.converters as converters

import ckan.plugins as plugins
import ckan.logic as logic
import ckan.logic.schema as schema_
import ckan.lib.dictization as dictization
import ckan.lib.dictization.model_dictize as model_dictize
import ckan.lib.dictization.model_save as model_save
import ckan.lib.navl.dictization_functions
import ckan.lib.navl.validators as validators
import ckan.lib.plugins as lib_plugins
import ckan.lib.email_notifications as email_notifications
import ckan.lib.search as search
import ckan.lib.uploader as uploader

from ckan.common import _, request

log = logging.getLogger(__name__)

# Define some shortcuts
# Ensure they are module-private so that they don't get loaded as available
# actions in the action API.
_validate = ckan.lib.navl.dictization_functions.validate
_get_action = logic.get_action
_check_access = logic.check_access
NotFound = logic.NotFound
ValidationError = logic.ValidationError
_get_or_bust = logic.get_or_bust

def _make_latest_rev_active(context, q):

    session = context['model'].Session

    old_current = q.filter_by(current=True).first()
    if old_current:
        old_current.current = False
        session.add(old_current)

    latest_rev = q.filter_by(expired_timestamp=datetime.datetime(9999, 12, 31)).one()
    latest_rev.current = True
    if latest_rev.state in ('pending-deleted', 'deleted'):
        latest_rev.state = 'deleted'
        latest_rev.continuity.state = 'deleted'
    else:
        latest_rev.continuity.state = 'active'
        latest_rev.state = 'active'

    session.add(latest_rev)

    ##this is just a way to get the latest revision that changed
    ##in order to timestamp
    old_latest = context.get('latest_revision_date')
    if old_latest:
        if latest_rev.revision_timestamp > old_latest:
            context['latest_revision_date'] = latest_rev.revision_timestamp
            context['latest_revision'] = latest_rev.revision_id
    else:
        context['latest_revision_date'] = latest_rev.revision_timestamp
        context['latest_revision'] = latest_rev.revision_id

def make_latest_pending_package_active(context, data_dict):
    '''

    .. todo:: What does this function do?

    You must be authorized to update the dataset.

    :param id: the name or id of the dataset, e.g. ``'warandpeace'``
    :type id: string

    '''
    model = context['model']
    session = model.Session
    SQLAlchemySession.setattr(session, 'revisioning_disabled', True)
    id = _get_or_bust(data_dict, "id")
    pkg = model.Package.get(id)

    _check_access('make_latest_pending_package_active', context, data_dict)

    #packages
    q = session.query(model.PackageRevision).filter_by(id=pkg.id)
    _make_latest_rev_active(context, q)

    #resources
    for resource in pkg.resource_groups_all[0].resources_all:
        q = session.query(model.ResourceRevision).filter_by(id=resource.id)
        _make_latest_rev_active(context, q)

    #tags
    for tag in pkg.package_tag_all:
        q = session.query(model.PackageTagRevision).filter_by(id=tag.id)
        _make_latest_rev_active(context, q)

    #extras
    for extra in pkg.extras_list:
        q = session.query(model.PackageExtraRevision).filter_by(id=extra.id)
        _make_latest_rev_active(context, q)

    latest_revision = context.get('latest_revision')
    if not latest_revision:
        return

    q = session.query(model.Revision).filter_by(id=latest_revision)
    revision = q.first()
    revision.approved_timestamp = datetime.datetime.now()
    session.add(revision)

    if not context.get('defer_commit'):
        session.commit()


def related_update(context, data_dict):
    '''Update a related item.

    You must be the owner of a related item to update it.

    For further parameters see
    :py:func:`~ckan.logic.action.create.related_create`.

    :param id: the id of the related item to update
    :type id: string

    :returns: the updated related item
    :rtype: dictionary

    '''
    model = context['model']
    id = _get_or_bust(data_dict, "id")

    session = context['session']
    schema = context.get('schema') or schema_.default_update_related_schema()

    related = model.Related.get(id)
    context["related"] = related

    if not related:
        logging.error('Could not find related ' + id)
        raise NotFound(_('Item was not found.'))

    _check_access('related_update', context, data_dict)
    data, errors = _validate(data_dict, schema, context)
    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    related = model_save.related_dict_save(data, context)

    dataset_dict = None
    if 'package' in context:
        dataset = context['package']
        dataset_dict = ckan.lib.dictization.table_dictize(dataset, context)

    related_dict = model_dictize.related_dictize(related, context)
    activity_dict = {
        'user_id': context['user'],
        'object_id': related.id,
        'activity_type': 'changed related item',
    }
    activity_dict['data'] = {
        'related': related_dict,
        'dataset': dataset_dict,
    }
    activity_create_context = {
        'model': model,
        'user': context['user'],
        'defer_commit': True,
        'ignore_auth': True,
        'session': session
    }

    _get_action('activity_create')(activity_create_context, activity_dict)

    if not context.get('defer_commit'):
        model.repo.commit()
    return model_dictize.related_dictize(related, context)



def resource_update(context, data_dict):
    '''Update a resource.

    To update a resource you must be authorized to update the dataset that the
    resource belongs to.

    For further parameters see
    :py:func:`~ckan.logic.action.create.resource_create`.

    :param id: the id of the resource to update
    :type id: string

    :returns: the updated resource
    :rtype: string

    '''
    model = context['model']
    user = context['user']
    id = _get_or_bust(data_dict, "id")

    resource = model.Resource.get(id)
    context["resource"] = resource

    if not resource:
        logging.error('Could not find resource ' + id)
        raise NotFound(_('Resource was not found.'))

    _check_access('resource_update', context, data_dict)
    del context["resource"]

    package_id = resource.resource_group.package.id
    pkg_dict = _get_action('package_show')(context, {'id': package_id})

    for n, p in enumerate(pkg_dict['resources']):
        if p['id'] == id:
            break
    else:
        logging.error('Could not find resource ' + id)
        raise NotFound(_('Resource was not found.'))

    upload = uploader.ResourceUpload(data_dict)

    pkg_dict['resources'][n] = data_dict

    try:
        context['defer_commit'] = True
        context['use_cache'] = False
        pkg_dict = _get_action('package_update')(context, pkg_dict)
        context.pop('defer_commit')
    except ValidationError, e:
        errors = e.error_dict['resources'][n]
        raise ValidationError(errors)

    upload.upload(id, uploader.get_max_resource_size())
    model.repo.commit()
    return _get_action('resource_show')(context, {'id': id})


def package_update(context, data_dict):
    '''Update a dataset (package).

    You must be authorized to edit the dataset and the groups that it belongs
    to.
    
    It is recommended to call
    :py:func:`ckan.logic.action.get.package_show`, make the desired changes to
    the result, and then call ``package_update()`` with it.

    Plugins may change the parameters of this function depending on the value
    of the dataset's ``type`` attribute, see the
    :py:class:`~ckan.plugins.interfaces.IDatasetForm` plugin interface.

    For further parameters see
    :py:func:`~ckan.logic.action.create.package_create`.

    :param id: the name or id of the dataset to update
    :type id: string

    :returns: the updated dataset (if ``'return_package_dict'`` is ``True`` in
              the context, which is the default. Otherwise returns just the
              dataset id)
    :rtype: dictionary

    '''
    model = context['model']
    user = context['user']
    name_or_id = data_dict.get("id") or data_dict['name']

    pkg = model.Package.get(name_or_id)
    if pkg is None:
        raise NotFound(_('Package was not found.'))
    context["package"] = pkg
    data_dict["id"] = pkg.id

    _check_access('package_update', context, data_dict)

    # get the schema
    package_plugin = lib_plugins.lookup_package_plugin(pkg.type)
    if 'schema' in context:
        schema = context['schema']
    else:
        schema = package_plugin.update_package_schema()

    if 'api_version' not in context:
        # check_data_dict() is deprecated. If the package_plugin has a
        # check_data_dict() we'll call it, if it doesn't have the method we'll
        # do nothing.
        check_data_dict = getattr(package_plugin, 'check_data_dict', None)
        if check_data_dict:
            try:
                package_plugin.check_data_dict(data_dict, schema)
            except TypeError:
                # Old plugins do not support passing the schema so we need
                # to ensure they still work.
                package_plugin.check_data_dict(data_dict)

    data, errors = lib_plugins.plugin_validate(
        package_plugin, context, data_dict, schema, 'package_update')
    log.debug('package_update validate_errs=%r user=%s package=%s data=%r',
              errors, context.get('user'),
              context.get('package').name if context.get('package') else '',
              data)

    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    rev = model.repo.new_revision()
    rev.author = user
    if 'message' in context:
        rev.message = context['message']
    else:
        rev.message = _(u'REST API: Update object %s') % data.get("name")

    #avoid revisioning by updating directly
    model.Session.query(model.Package).filter_by(id=pkg.id).update(
        {"metadata_modified": datetime.datetime.utcnow()})
    model.Session.refresh(pkg)

    pkg = model_save.package_dict_save(data, context)

    context_org_update = context.copy()
    context_org_update['ignore_auth'] = True
    context_org_update['defer_commit'] = True
    _get_action('package_owner_org_update')(context_org_update,
                                            {'id': pkg.id,
                                             'organization_id': pkg.owner_org})

    for item in plugins.PluginImplementations(plugins.IPackageController):
        item.edit(pkg)

        item.after_update(context, data)

    if not context.get('defer_commit'):
        model.repo.commit()

    log.debug('Updated object %s' % pkg.name)

    return_id_only = context.get('return_id_only', False)

    # Make sure that a user provided schema is not used on package_show
    context.pop('schema', None)

    # we could update the dataset so we should still be able to read it.
    context['ignore_auth'] = True
    output = data_dict['id'] if return_id_only \
            else _get_action('package_show')(context, {'id': data_dict['id']})

    return output

def package_resource_reorder(context, data_dict):
    '''Reorder resources against datasets.  If only partial resource ids are
    supplied then these are assumed to be first and the other resources will
    stay in their original order

    :param id: the id or name of the package to update
    :type id: string
    :param order: a list of resource ids in the order needed
    :type list: list
    '''

    id = _get_or_bust(data_dict, "id")
    order = _get_or_bust(data_dict, "order")
    if not isinstance(order, list):
        raise ValidationError({'order': 'Must be a list of resource'})

    if len(set(order)) != len(order):
        raise ValidationError({'order': 'Must supply unique resource_ids'})

    package_dict = _get_action('package_show')(context, {'id': id})
    existing_resources = package_dict.get('resources', [])
    ordered_resources = []

    for resource_id in order:
        for i in range(0, len(existing_resources)):
            if existing_resources[i]['id'] == resource_id:
                resource = existing_resources.pop(i)
                ordered_resources.append(resource)
                break
        else:
            raise ValidationError(
                {'order':
                 'resource_id {id} can not be found'.format(id=resource_id)}
            )

    new_resources = ordered_resources + existing_resources
    package_dict['resources'] = new_resources

    _check_access('package_resource_reorder', context, package_dict)
    _get_action('package_update')(context, package_dict)

    return {'id': id, 'order': [resource['id'] for resource in new_resources]}


def _update_package_relationship(relationship, comment, context):
    model = context['model']
    api = context.get('api_version')
    ref_package_by = 'id' if api == 2 else 'name'
    is_changed = relationship.comment != comment
    if is_changed:
        rev = model.repo.new_revision()
        rev.author = context["user"]
        rev.message = (_(u'REST API: Update package relationship: %s %s %s') %
            (relationship.subject, relationship.type, relationship.object))
        relationship.comment = comment
        if not context.get('defer_commit'):
            model.repo.commit_and_remove()
    rel_dict = relationship.as_dict(package=relationship.subject,
                                    ref_package_by=ref_package_by)
    return rel_dict

def package_relationship_update(context, data_dict):
    '''Update a relationship between two datasets (packages).

    You must be authorized to edit both the subject and the object datasets.

    :param id: the id of the package relationship to update
    :type id: string
    :param subject: the name or id of the dataset that is the subject of the
        relationship (optional)
    :type subject: string
    :param object: the name or id of the dataset that is the object of the
        relationship (optional)
    :param type: the type of the relationship, one of ``'depends_on'``,
        ``'dependency_of'``, ``'derives_from'``, ``'has_derivation'``,
        ``'links_to'``, ``'linked_from'``, ``'child_of'`` or ``'parent_of'``
        (optional)
    :type type: string
    :param comment: a comment about the relationship (optional)
    :type comment: string

    :returns: the updated relationship
    :rtype: dictionary

    '''
    model = context['model']
    schema = context.get('schema') or schema_.default_update_relationship_schema()

    id, id2, rel = _get_or_bust(data_dict, ['subject', 'object', 'type'])

    pkg1 = model.Package.get(id)
    pkg2 = model.Package.get(id2)
    if not pkg1:
        raise NotFound('Subject package %r was not found.' % id)
    if not pkg2:
        return NotFound('Object package %r was not found.' % id2)

    data, errors = _validate(data_dict, schema, context)
    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    _check_access('package_relationship_update', context, data_dict)

    existing_rels = pkg1.get_relationships_with(pkg2, rel)
    if not existing_rels:
        raise NotFound('This relationship between the packages was not found.')
    entity = existing_rels[0]
    comment = data_dict.get('comment', u'')
    context['relationship'] = entity
    return _update_package_relationship(entity, comment, context)

def _group_or_org_update(context, data_dict, is_org=False):
    model = context['model']
    user = context['user']
    session = context['session']
    id = _get_or_bust(data_dict, 'id')

    group = model.Group.get(id)
    context["group"] = group
    if group is None:
        raise NotFound('Group was not found.')

    # get the schema
    group_plugin = lib_plugins.lookup_group_plugin(group.type)
    try:
        schema = group_plugin.form_to_db_schema_options({'type':'update',
                                               'api':'api_version' in context,
                                               'context': context})
    except AttributeError:
        schema = group_plugin.form_to_db_schema()

    upload = uploader.Upload('group', group.image_url)
    upload.update_data_dict(data_dict, 'image_url',
                           'image_upload', 'clear_upload')

    if is_org:
        _check_access('organization_update', context, data_dict)
    else:
        _check_access('group_update', context, data_dict)

    if 'api_version' not in context:
        # old plugins do not support passing the schema so we need
        # to ensure they still work
        try:
            group_plugin.check_data_dict(data_dict, schema)
        except TypeError:
            group_plugin.check_data_dict(data_dict)

    data, errors = lib_plugins.plugin_validate(
        group_plugin, context, data_dict, schema,
        'organization_update' if is_org else 'group_update')
    log.debug('group_update validate_errs=%r user=%s group=%s data_dict=%r',
              errors, context.get('user'),
              context.get('group').name if context.get('group') else '',
              data_dict)

    if errors:
        session.rollback()
        raise ValidationError(errors)

    rev = model.repo.new_revision()
    rev.author = user

    if 'message' in context:
        rev.message = context['message']
    else:
        rev.message = _(u'REST API: Update object %s') % data.get("name")

    group = model_save.group_dict_save(data, context,
        prevent_packages_update=is_org)

    if is_org:
        plugin_type = plugins.IOrganizationController
    else:
        plugin_type = plugins.IGroupController

    for item in plugins.PluginImplementations(plugin_type):
        item.edit(group)

    if is_org:
        activity_type = 'changed organization'
    else:
        activity_type = 'changed group'

    activity_dict = {
            'user_id': model.User.by_name(user.decode('utf8')).id,
            'object_id': group.id,
            'activity_type': activity_type,
            }
    # Handle 'deleted' groups.
    # When the user marks a group as deleted this comes through here as
    # a 'changed' group activity. We detect this and change it to a 'deleted'
    # activity.
    if group.state == u'deleted':
        if session.query(ckan.model.Activity).filter_by(
                object_id=group.id, activity_type='deleted').all():
            # A 'deleted group' activity for this group has already been
            # emitted.
            # FIXME: What if the group was deleted and then activated again?
            activity_dict = None
        else:
            # We will emit a 'deleted group' activity.
            activity_dict['activity_type'] = 'deleted group'
    if activity_dict is not None:
        activity_dict['data'] = {
                'group': dictization.table_dictize(group, context)
                }
        activity_create_context = {
            'model': model,
            'user': user,
            'defer_commit': True,
            'ignore_auth': True,
            'session': session
        }
        _get_action('activity_create')(activity_create_context, activity_dict)
        # TODO: Also create an activity detail recording what exactly changed
        # in the group.

    upload.upload(uploader.get_max_image_size())
    if not context.get('defer_commit'):
        model.repo.commit()


    return model_dictize.group_dictize(group, context)

def group_update(context, data_dict):
    '''Update a group.

    You must be authorized to edit the group.

    Plugins may change the parameters of this function depending on the value
    of the group's ``type`` attribute, see the
    :py:class:`~ckan.plugins.interfaces.IGroupForm` plugin interface.

    For further parameters see
    :py:func:`~ckan.logic.action.create.group_create`.

    :param id: the name or id of the group to update
    :type id: string

    :returns: the updated group
    :rtype: dictionary

    '''
    return _group_or_org_update(context, data_dict)

def organization_update(context, data_dict):
    '''Update a organization.

    You must be authorized to edit the organization.

    For further parameters see
    :py:func:`~ckan.logic.action.create.organization_create`.

    :param id: the name or id of the organization to update
    :type id: string
    :param packages: ignored. use
        :py:func:`~ckan.logic.action.update.package_owner_org_update`
        to change package ownership

    :returns: the updated organization
    :rtype: dictionary

    '''
    return _group_or_org_update(context, data_dict, is_org=True)

def user_update(context, data_dict):
    '''Update a user account.

    Normal users can only update their own user accounts. Sysadmins can update
    any user account.

    For further parameters see
    :py:func:`~ckan.logic.action.create.user_create`.

    :param id: the name or id of the user to update
    :type id: string

    :returns: the updated user account
    :rtype: dictionary

    '''
    model = context['model']
    user = context['user']
    session = context['session']
    schema = context.get('schema') or schema_.default_update_user_schema()
    id = _get_or_bust(data_dict, 'id')

    user_obj = model.User.get(id)
    context['user_obj'] = user_obj
    if user_obj is None:
        raise NotFound('User was not found.')

    _check_access('user_update', context, data_dict)

    data, errors = _validate(data_dict, schema, context)
    if errors:
        session.rollback()
        raise ValidationError(errors)

    user = model_save.user_dict_save(data, context)

    activity_dict = {
            'user_id': user.id,
            'object_id': user.id,
            'activity_type': 'changed user',
            }
    activity_create_context = {
        'model': model,
        'user': user,
        'defer_commit': True,
        'ignore_auth': True,
        'session': session
    }
    _get_action('activity_create')(activity_create_context, activity_dict)
    # TODO: Also create an activity detail recording what exactly changed in
    # the user.

    if not context.get('defer_commit'):
        model.repo.commit()
    return model_dictize.user_dictize(user, context)

def task_status_update(context, data_dict):
    '''Update a task status.

    :param id: the id of the task status to update
    :type id: string
    :param entity_id:
    :type entity_id: string
    :param entity_type:
    :type entity_type: string
    :param task_type:
    :type task_type: string
    :param key:
    :type key: string
    :param value: (optional)
    :type value:
    :param state: (optional)
    :type state:
    :param last_updated: (optional)
    :type last_updated:
    :param error: (optional)
    :type error:

    :returns: the updated task status
    :rtype: dictionary

    '''
    model = context['model']
    session = model.meta.create_local_session()
    context['session'] = session

    user = context['user']
    id = data_dict.get("id")
    schema = context.get('schema') or schema_.default_task_status_schema()

    if id:
        task_status = model.TaskStatus.get(id)
        context["task_status"] = task_status

        if task_status is None:
            raise NotFound(_('TaskStatus was not found.'))

    _check_access('task_status_update', context, data_dict)

    data, errors = _validate(data_dict, schema, context)
    if errors:
        session.rollback()
        raise ValidationError(errors)

    task_status = model_save.task_status_dict_save(data, context)

    session.commit()
    session.close()
    return model_dictize.task_status_dictize(task_status, context)

def task_status_update_many(context, data_dict):
    '''Update many task statuses at once.

    :param data: the task_status dictionaries to update, for the format of task
        status dictionaries see 
        :py:func:`~task_status_update`
    :type data: list of dictionaries

    :returns: the updated task statuses
    :rtype: list of dictionaries

    '''
    results = []
    model = context['model']
    deferred = context.get('defer_commit')
    context['defer_commit'] = True
    for data in data_dict['data']:
        results.append(_get_action('task_status_update')(context, data))
    if not deferred:
        context.pop('defer_commit')
    if not context.get('defer_commit'):
        model.Session.commit()
    return {'results': results}

def term_translation_update(context, data_dict):
    '''Create or update a term translation.

    You must be a sysadmin to create or update term translations.

    :param term: the term to be translated, in the original language, e.g.
        ``'romantic novel'``
    :type term: string
    :param term_translation: the translation of the term, e.g.
        ``'Liebesroman'``
    :type term_translation: string
    :param lang_code: the language code of the translation, e.g. ``'de'``
    :type lang_code: string

    :returns: the newly created or updated term translation
    :rtype: dictionary

    '''
    model = context['model']

    _check_access('term_translation_update', context, data_dict)

    schema = {'term': [validators.not_empty, unicode],
              'term_translation': [validators.not_empty, unicode],
              'lang_code': [validators.not_empty, unicode]}

    data, errors = _validate(data_dict, schema, context)
    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    trans_table = model.term_translation_table

    update = trans_table.update()
    update = update.where(trans_table.c.term == data['term'])
    update = update.where(trans_table.c.lang_code == data['lang_code'])
    update = update.values(term_translation = data['term_translation'])

    conn = model.Session.connection()
    result = conn.execute(update)

    # insert if not updated
    if not result.rowcount:
        conn.execute(trans_table.insert().values(**data))

    if not context.get('defer_commit'):
        model.Session.commit()

    return data

def term_translation_update_many(context, data_dict):
    '''Create or update many term translations at once.

    :param data: the term translation dictionaries to create or update,
        for the format of term translation dictionaries see
        :py:func:`~term_translation_update`
    :type data: list of dictionaries

    :returns: a dictionary with key ``'success'`` whose value is a string
        stating how many term translations were updated
    :rtype: string

    '''
    model = context['model']

    if not (data_dict.get('data') and isinstance(data_dict.get('data'), list)):
        raise ValidationError(
            {'error': 'term_translation_update_many needs to have a '
                      'list of dicts in field data'}
        )

    context['defer_commit'] = True

    action = _get_action('term_translation_update')
    for num, row in enumerate(data_dict['data']):
        action(context, row)

    model.Session.commit()

    return {'success': '%s rows updated' % (num + 1)}


## Modifications for rest api

def package_update_rest(context, data_dict):

    model = context['model']
    id = data_dict.get("id")
    request_id = context['id']
    pkg = model.Package.get(request_id)

    if not pkg:
        raise NotFound

    if id and id != pkg.id:
        pkg_from_data = model.Package.get(id)
        if pkg_from_data != pkg:
            error_dict = {id:('Cannot change value of key from %s to %s. '
                'This key is read-only') % (pkg.id, id)}
            raise ValidationError(error_dict)

    context["package"] = pkg
    context["allow_partial_update"] = False
    dictized_package = model_save.package_api_to_dict(data_dict, context)

    _check_access('package_update_rest', context, dictized_package)

    dictized_after = _get_action('package_update')(context, dictized_package)

    pkg = context['package']

    package_dict = model_dictize.package_to_api(pkg, context)

    return package_dict

def group_update_rest(context, data_dict):

    model = context['model']
    id = _get_or_bust(data_dict, "id")
    group = model.Group.get(id)
    context["group"] = group
    context["allow_partial_update"] = True
    dictized_group = model_save.group_api_to_dict(data_dict, context)

    _check_access('group_update_rest', context, dictized_group)

    dictized_after = _get_action('group_update')(context, dictized_group)

    group = context['group']

    group_dict = model_dictize.group_to_api(group, context)

    return group_dict

def vocabulary_update(context, data_dict):
    '''Update a tag vocabulary.

    You must be a sysadmin to update vocabularies.

    For further parameters see
    :py:func:`~ckan.logic.action.create.vocabulary_create`.

    :param id: the id of the vocabulary to update
    :type id: string

    :returns: the updated vocabulary
    :rtype: dictionary

    '''
    model = context['model']

    vocab_id = data_dict.get('id')
    if not vocab_id:
        raise ValidationError({'id': _('id not in data')})

    vocab = model.vocabulary.Vocabulary.get(vocab_id)
    if vocab is None:
        raise NotFound(_('Could not find vocabulary "%s"') % vocab_id)

    data_dict['id'] = vocab.id
    if data_dict.has_key('name'):
        if data_dict['name'] == vocab.name:
            del data_dict['name']

    _check_access('vocabulary_update', context, data_dict)

    schema = context.get('schema') or schema_.default_update_vocabulary_schema()
    data, errors = _validate(data_dict, schema, context)
    if errors:
        model.Session.rollback()
        raise ValidationError(errors)

    updated_vocab = model_save.vocabulary_dict_update(data, context)

    if not context.get('defer_commit'):
        model.repo.commit()

    return model_dictize.vocabulary_dictize(updated_vocab, context)

def package_relationship_update_rest(context, data_dict):

    # rename keys
    key_map = {'id': 'subject',
               'id2': 'object',
               'rel': 'type'}

    # We want 'destructive', so that the value of the subject,
    # object and rel in the URI overwrite any values for these
    # in params. This is because you are not allowed to change
    # these values.
    data_dict = logic.action.rename_keys(data_dict, key_map, destructive=True)

    relationship_dict = _get_action('package_relationship_update')(context, data_dict)

    return relationship_dict

def user_role_update(context, data_dict):
    '''Update a user or authorization group's roles for a domain object.

    The ``user`` parameter must be given.

    You must be authorized to update the domain object.

    To delete all of a user or authorization group's roles for domain object,
    pass an empty list ``[]`` to the ``roles`` parameter.

    :param user: the name or id of the user
    :type user: string
    :param domain_object: the name or id of the domain object (e.g. a package,
        group or authorization group)
    :type domain_object: string
    :param roles: the new roles, e.g. ``['editor']``
    :type roles: list of strings

    :returns: the updated roles of all users for the
        domain object
    :rtype: dictionary

    '''
    model = context['model']

    new_user_ref = data_dict.get('user') # the user who is being given the new role
    if not bool(new_user_ref):
        raise ValidationError('You must provide the "user" parameter.')
    domain_object_ref = _get_or_bust(data_dict, 'domain_object')
    if not isinstance(data_dict['roles'], (list, tuple)):
        raise ValidationError('Parameter "%s" must be of type: "%s"' % ('role', 'list'))
    desired_roles = set(data_dict['roles'])

    if new_user_ref:
        user_object = model.User.get(new_user_ref)
        if not user_object:
            raise NotFound('Cannot find user %r' % new_user_ref)
        data_dict['user'] = user_object.id
        add_user_to_role_func = model.add_user_to_role
        remove_user_from_role_func = model.remove_user_from_role

    domain_object = logic.action.get_domain_object(model, domain_object_ref)
    data_dict['id'] = domain_object.id

    # current_uors: in order to avoid either creating a role twice or
    # deleting one which is non-existent, we need to get the users\'
    # current roles (if any)
    current_role_dicts = _get_action('roles_show')(context, data_dict)['roles']
    current_roles = set([role_dict['role'] for role_dict in current_role_dicts])

    # Whenever our desired state is different from our current state,
    # change it.
    for role in (desired_roles - current_roles):
        add_user_to_role_func(user_object, role, domain_object)
    for role in (current_roles - desired_roles):
        remove_user_from_role_func(user_object, role, domain_object)

    # and finally commit all these changes to the database
    if not (current_roles == desired_roles):
        model.repo.commit_and_remove()

    return _get_action('roles_show')(context, data_dict)

def user_role_bulk_update(context, data_dict):
    '''Update the roles of many users or authorization groups for an object.

    You must be authorized to update the domain object.

    :param user_roles: the updated user roles, for the format of user role
        dictionaries see :py:func:`~user_role_update`
    :type user_roles: list of dictionaries

    :returns: the updated roles of all users and authorization groups for the
        domain object
    :rtype: dictionary

    '''
    # Collate all the roles for each user
    roles_by_user = {} # user:roles
    for user_role_dict in data_dict['user_roles']:
        user = user_role_dict.get('user')
        if user:
            roles = user_role_dict['roles']
            if user not in roles_by_user:
                roles_by_user[user] = []
            roles_by_user[user].extend(roles)
    # For each user, update its roles
    for user in roles_by_user:
        uro_data_dict = {'user': user,
                         'roles': roles_by_user[user],
                         'domain_object': data_dict['domain_object']}
        user_role_update(context, uro_data_dict)
    return _get_action('roles_show')(context, data_dict)


def dashboard_mark_activities_old(context, data_dict):
    '''Mark all the authorized user's new dashboard activities as old.

    This will reset
    :py:func:`~ckan.logic.action.get.dashboard_new_activities_count` to 0.

    '''
    _check_access('dashboard_mark_activities_old', context,
            data_dict)
    model = context['model']
    user_id = model.User.get(context['user']).id
    model.Dashboard.get(user_id).activity_stream_last_viewed = (
            datetime.datetime.now())
    if not context.get('defer_commit'):
        model.repo.commit()


def send_email_notifications(context, data_dict):
    '''Send any pending activity stream notification emails to users.

    You must provide a sysadmin's API key in the Authorization header of the
    request, or call this action from the command-line via a `paster post ...`
    command.

    '''
    # If paste.command_request is True then this function has been called
    # by a `paster post ...` command not a real HTTP request, so skip the
    # authorization.
    if not request.environ.get('paste.command_request'):
        _check_access('send_email_notifications', context, data_dict)

    if not converters.asbool(
            config.get('ckan.activity_streams_email_notifications')):
        raise ValidationError('ckan.activity_streams_email_notifications'
                              ' is not enabled in config')

    email_notifications.get_and_send_notifications_for_all_users()


def package_owner_org_update(context, data_dict):
    '''Update the owning organization of a dataset

    :param id: the name or id of the dataset to update
    :type id: string

    :param organization_id: the name or id of the owning organization
    :type id: string
    '''
    model = context['model']
    name_or_id = data_dict.get('id')
    organization_id = data_dict.get('organization_id')

    _check_access('package_owner_org_update', context, data_dict)

    pkg = model.Package.get(name_or_id)
    if pkg is None:
        raise NotFound(_('Package was not found.'))
    if organization_id:
        org = model.Group.get(organization_id)
        if org is None or not org.is_organization:
            raise NotFound(_('Organization was not found.'))

        # FIXME check we are in that org
        pkg.owner_org = org.id
    else:
        org = None
        pkg.owner_org = None


    members = model.Session.query(model.Member) \
            .filter(model.Member.table_id == pkg.id) \
            .filter(model.Member.capacity == 'organization')

    need_update = True
    for member_obj in members:
        if org and member_obj.group_id == org.id:
            need_update = False
        else:
            member_obj.state = 'deleted'
            member_obj.save()

    # add the organization to member table
    if org and need_update:
        member_obj = model.Member(table_id=pkg.id,
                                  table_name='package',
                                  group=org,
                                  capacity='organization',
                                  group_id=org.id,
                                  state='active')
        model.Session.add(member_obj)

    if not context.get('defer_commit'):
        model.Session.commit()


def _bulk_update_dataset(context, data_dict, update_dict):
    ''' Bulk update shared code for organizations'''

    datasets = data_dict.get('datasets', [])
    org_id = data_dict.get('org_id')

    model = context['model']

    model.Session.query(model.package_table) \
        .filter(model.Package.id.in_(datasets)) \
        .filter(model.Package.owner_org == org_id) \
        .update(update_dict, synchronize_session=False)

    # revisions
    model.Session.query(model.package_revision_table) \
        .filter(model.PackageRevision.id.in_(datasets)) \
        .filter(model.PackageRevision.owner_org == org_id) \
        .filter(model.PackageRevision.current == True) \
        .update(update_dict, synchronize_session=False)

    model.Session.commit()

    # solr update here
    psi = search.PackageSearchIndex()

    # update the solr index in batches
    BATCH_SIZE = 50

    def process_solr(q):
        # update the solr index for the query
        query = search.PackageSearchQuery()
        q = {
            'q': q,
            'fl': 'data_dict',
            'wt': 'json',
            'fq': 'site_id:"%s"' % config.get('ckan.site_id'),
            'rows': BATCH_SIZE
        }

        for result in query.run(q)['results']:
            data_dict = json.loads(result['data_dict'])
            if data_dict['owner_org'] == org_id:
                data_dict.update(update_dict)
                psi.index_package(data_dict, defer_commit=True)

    count = 0
    q = []
    for id in datasets:
        q.append('id:%s' % (id))
        count += 1
        if count % BATCH_SIZE == 0:
            process_solr(' OR '.join(q))
            q = []
    if len(q):
        process_solr(' OR '.join(q))
    # finally commit the changes
    psi.commit()


def bulk_update_private(context, data_dict):
    ''' Make a list of datasets private

    :param datasets: list of ids of the datasets to update
    :type datasets: list of strings

    :param org_id: id of the owning organization
    :type org_id: int
    '''

    _check_access('bulk_update_private', context, data_dict)
    _bulk_update_dataset(context, data_dict, {'private': True})

def bulk_update_public(context, data_dict):
    ''' Make a list of datasets public

    :param datasets: list of ids of the datasets to update
    :type datasets: list of strings

    :param org_id: id of the owning organization
    :type org_id: int
    '''

    _check_access('bulk_update_public', context, data_dict)
    _bulk_update_dataset(context, data_dict, {'private': False})

def bulk_update_delete(context, data_dict):
    ''' Make a list of datasets deleted

    :param datasets: list of ids of the datasets to update
    :type datasets: list of strings

    :param org_id: id of the owning organization
    :type org_id: int
    '''

    _check_access('bulk_update_delete', context, data_dict)
    _bulk_update_dataset(context, data_dict, {'state': 'deleted'})

########NEW FILE########
__FILENAME__ = create
import ckan.logic as logic
import ckan.new_authz as new_authz
import ckan.logic.auth as logic_auth

from ckan.common import _

@logic.auth_allow_anonymous_access
def package_create(context, data_dict=None):
    user = context['user']

    if new_authz.auth_is_anon_user(context):
        check1 = new_authz.check_config_permission('anon_create_dataset')
    else:
        check1 = new_authz.check_config_permission('create_dataset_if_not_in_organization') \
            or new_authz.check_config_permission('create_unowned_dataset') \
            or new_authz.has_user_permission_for_some_org(user, 'create_dataset')

    if not check1:
        return {'success': False, 'msg': _('User %s not authorized to create packages') % user}

    check2 = _check_group_auth(context,data_dict)
    if not check2:
        return {'success': False, 'msg': _('User %s not authorized to edit these groups') % user}

    # If an organization is given are we able to add a dataset to it?
    data_dict = data_dict or {}
    org_id = data_dict.get('owner_org')
    if org_id and not new_authz.has_user_permission_for_group_or_org(
            org_id, user, 'create_dataset'):
        return {'success': False, 'msg': _('User %s not authorized to add dataset to this organization') % user}
    return {'success': True}


def file_upload(context, data_dict=None):
    user = context['user']
    if new_authz.auth_is_anon_user(context):
        return {'success': False, 'msg': _('User %s not authorized to create packages') % user}
    return {'success': True}

def related_create(context, data_dict=None):
    '''Users must be logged-in to create related items.

    To create a featured item the user must be a sysadmin.
    '''
    model = context['model']
    user = context['user']
    userobj = model.User.get( user )

    if userobj:
        if data_dict.get('featured', 0) != 0:
            return {'success': False,
                    'msg': _('You must be a sysadmin to create a featured '
                             'related item')}
        return {'success': True}

    return {'success': False, 'msg': _('You must be logged in to add a related item')}

def resource_create(context, data_dict):
    # resource_create runs through package_update, no need to
    # check users eligibility to add resource to package here.

    # FIXME This is identical behaviour to what existed but feels like we
    # should be using package_update permissions and have better errors.  I
    # am also not sure about the need for the group issue
    return new_authz.is_authorized('package_create', context, data_dict)

def package_relationship_create(context, data_dict):
    user = context['user']

    id = data_dict['subject']
    id2 = data_dict['object']

    # If we can update each package we can see the relationships
    authorized1 = new_authz.is_authorized_boolean(
        'package_update', context, {'id': id})
    authorized2 = new_authz.is_authorized_boolean(
        'package_update', context, {'id': id2})

    if not authorized1 and authorized2:
        return {'success': False, 'msg': _('User %s not authorized to edit these packages') % user}
    else:
        return {'success': True}

def group_create(context, data_dict=None):
    user = context['user']
    user = new_authz.get_user_id_for_username(user, allow_none=True)

    if user and new_authz.check_config_permission('user_create_groups'):
        return {'success': True}
    return {'success': False,
            'msg': _('User %s not authorized to create groups') % user}


def organization_create(context, data_dict=None):
    user = context['user']
    user = new_authz.get_user_id_for_username(user, allow_none=True)

    if user and new_authz.check_config_permission('user_create_organizations'):
        return {'success': True}
    return {'success': False,
            'msg': _('User %s not authorized to create organizations') % user}

def rating_create(context, data_dict):
    # No authz check in the logic function
    return {'success': True}


@logic.auth_allow_anonymous_access
def user_create(context, data_dict=None):
    using_api = 'api_version' in context
    create_user_via_api = new_authz.check_config_permission(
            'create_user_via_api')
    create_user_via_web = new_authz.check_config_permission(
            'create_user_via_web')

    if using_api and not create_user_via_api:
        return {'success': False, 'msg': _('User {user} not authorized to '
            'create users via the API').format(user=context.get('user'))}
    if not using_api and not create_user_via_web:
        return {'success': False, 'msg': _('Not authorized to '
            'create users')}
    return {'success': True}

def user_invite(context, data_dict):
    data_dict['id'] = data_dict['group_id']
    return group_member_create(context, data_dict)

def _check_group_auth(context, data_dict):
    '''Has this user got update permission for all of the given groups?
    If there is a package in the context then ignore that package's groups.
    (owner_org is checked elsewhere.)
    :returns: False if not allowed to update one (or more) of the given groups.
              True otherwise. i.e. True is the default. A blank data_dict
              mentions no groups, so it returns True.

    '''
    # FIXME This code is shared amoung other logic.auth files and should be
    # somewhere better
    if not data_dict:
        return True

    model = context['model']
    user = context['user']
    pkg = context.get("package")

    api_version = context.get('api_version') or '1'

    group_blobs = data_dict.get('groups', [])
    groups = set()
    for group_blob in group_blobs:
        # group_blob might be a dict or a group_ref
        if isinstance(group_blob, dict):
            if api_version == '1':
                id = group_blob.get('name')
            else:
                id = group_blob.get('id')
            if not id:
                continue
        else:
            id = group_blob
        grp = model.Group.get(id)
        if grp is None:
            raise logic.NotFound(_('Group was not found.'))
        groups.add(grp)

    if pkg:
        pkg_groups = pkg.get_groups()

        groups = groups - set(pkg_groups)

    for group in groups:
        if not new_authz.has_user_permission_for_group_or_org(group.id, user, 'update'):
            return False

    return True

## Modifications for rest api

def package_create_rest(context, data_dict):
    model = context['model']
    user = context['user']
    if user in (model.PSEUDO_USER__VISITOR, ''):
        return {'success': False, 'msg': _('Valid API key needed to create a package')}

    return package_create(context, data_dict)

def group_create_rest(context, data_dict):
    model = context['model']
    user = context['user']
    if user in (model.PSEUDO_USER__VISITOR, ''):
        return {'success': False, 'msg': _('Valid API key needed to create a group')}

    return group_create(context, data_dict)

def vocabulary_create(context, data_dict):
    # sysadmins only
    return {'success': False}

def activity_create(context, data_dict):
    # sysadmins only
    return {'success': False}

def tag_create(context, data_dict):
    # sysadmins only
    return {'success': False}

def _group_or_org_member_create(context, data_dict):
    user = context['user']
    group_id = data_dict['id']
    if not new_authz.has_user_permission_for_group_or_org(group_id, user, 'membership'):
        return {'success': False, 'msg': _('User %s not authorized to add members') % user}
    return {'success': True}

def organization_member_create(context, data_dict):
    return _group_or_org_member_create(context, data_dict)

def group_member_create(context, data_dict):
    return _group_or_org_member_create(context, data_dict)

def member_create(context, data_dict):
    group = logic_auth.get_group_object(context, data_dict)
    user = context['user']

    # User must be able to update the group to add a member to it
    permission = 'update'
    # However if the user is member of group then they can add/remove datasets
    if not group.is_organization and data_dict.get('object_type') == 'package':
        permission = 'manage_group'

    authorized = new_authz.has_user_permission_for_group_or_org(group.id,
                                                                user,
                                                                permission)
    if not authorized:
        return {'success': False,
                'msg': _('User %s not authorized to edit group %s') %
                        (str(user), group.id)}
    else:
        return {'success': True}

########NEW FILE########
__FILENAME__ = delete
import ckan.logic as logic
import ckan.new_authz as new_authz
from ckan.logic.auth import get_group_object, get_related_object
from ckan.logic.auth import get_resource_object
import ckan.logic.auth.create as _auth_create
import ckan.logic.auth.update as _auth_update
from ckan.lib.base import _


def user_delete(context, data_dict):
    # sysadmins only
    return {'success': False}


def package_delete(context, data_dict):
    # Defer auhtorization for package_delete to package_update, as deletions
    # are essentially changing the state field
    return _auth_update.package_update(context, data_dict)

def resource_delete(context, data_dict):
    model = context['model']
    user = context.get('user')
    resource = get_resource_object(context, data_dict)

    # check authentication against package
    query = model.Session.query(model.Package)\
        .join(model.ResourceGroup)\
        .join(model.Resource)\
        .filter(model.ResourceGroup.id == resource.resource_group_id)
    pkg = query.first()
    if not pkg:
        raise logic.NotFound(_('No package found for this resource, cannot check auth.'))

    pkg_dict = {'id': pkg.id}
    authorized = package_delete(context, pkg_dict).get('success')

    if not authorized:
        return {'success': False, 'msg': _('User %s not authorized to delete resource %s') % (user, resource.id)}
    else:
        return {'success': True}


def related_delete(context, data_dict):
    model = context['model']
    user = context['user']
    if not user:
        return {'success': False, 'msg': _('Only the owner can delete a related item')}

    related = get_related_object(context, data_dict)
    userobj = model.User.get( user )

    if related.datasets:
        package = related.datasets[0]

        pkg_dict = { 'id': package.id }
        authorized = package_delete(context, pkg_dict).get('success')
        if authorized:
            return {'success': True}

    if not userobj or userobj.id != related.owner_id:
        return {'success': False, 'msg': _('Only the owner can delete a related item')}

    return {'success': True}


def package_relationship_delete(context, data_dict):
    user = context['user']
    relationship = context['relationship']

    # If you can create this relationship the you can also delete it
    authorized = new_authz.is_authorized_boolean('package_relationship_create', context, data_dict)
    if not authorized:
        return {'success': False, 'msg': _('User %s not authorized to delete relationship %s') % (user ,relationship.id)}
    else:
        return {'success': True}

def group_delete(context, data_dict):
    group = get_group_object(context, data_dict)
    user = context['user']
    if not new_authz.check_config_permission('user_delete_groups'):
        return {'success': False,
            'msg': _('User %s not authorized to delete groups') % user}
    authorized = new_authz.has_user_permission_for_group_or_org(
        group.id, user, 'delete')
    if not authorized:
        return {'success': False, 'msg': _('User %s not authorized to delete group %s') % (user ,group.id)}
    else:
        return {'success': True}

def group_purge(context, data_dict):
    # Only sysadmins are authorized to purge groups.
    return {'success': False}

def organization_purge(context, data_dict):
    # Only sysadmins are authorized to purge organizations.
    return {'success': False}

def organization_delete(context, data_dict):
    group = get_group_object(context, data_dict)
    user = context['user']
    if not new_authz.check_config_permission('user_delete_organizations'):
        return {'success': False,
            'msg': _('User %s not authorized to delete organizations') % user}
    authorized = new_authz.has_user_permission_for_group_or_org(
        group.id, user, 'delete')
    if not authorized:
        return {'success': False, 'msg': _('User %s not authorized to delete organization %s') % (user ,group.id)}
    else:
        return {'success': True}

def revision_undelete(context, data_dict):
    return {'success': False, 'msg': 'Not implemented yet in the auth refactor'}

def revision_delete(context, data_dict):
    return {'success': False, 'msg': 'Not implemented yet in the auth refactor'}

def task_status_delete(context, data_dict):
    # sysadmins only
    user = context['user']
    return {'success': False, 'msg': _('User %s not authorized to delete task_status') % user}

def vocabulary_delete(context, data_dict):
    # sysadmins only
    return {'success': False}

def tag_delete(context, data_dict):
    # sysadmins only
    return {'success': False}

def group_member_delete(context, data_dict):
    ## just return true as logic runs through member_delete
    return {'success': True}

def organization_member_delete(context, data_dict):
    ## just return true as logic runs through member_delete
    return {'success': True}

def member_delete(context, data_dict):
    return _auth_create.member_create(context, data_dict)

########NEW FILE########
__FILENAME__ = get
import ckan.logic as logic
import ckan.new_authz as new_authz
from ckan.lib.base import _
from ckan.logic.auth import (get_package_object, get_group_object,
                            get_resource_object, get_related_object)


def sysadmin(context, data_dict):
    ''' This is a pseudo check if we are a sysadmin all checks are true '''
    return {'success': False, 'msg': _('Not authorized')}


def site_read(context, data_dict):
    """\
    This function should be deprecated. It is only here because we couldn't
    get hold of Friedrich to ask what it was for.

    ./ckan/controllers/api.py
    """

    # FIXME we need to remove this for now we allow site read
    return {'success': True}

def package_search(context, data_dict):
    # Everyone can search by default
    return {'success': True}

def package_list(context, data_dict):
    # List of all active packages are visible by default
    return {'success': True}

def current_package_list_with_resources(context, data_dict):
    return package_list(context, data_dict)

def revision_list(context, data_dict):
    # In our new model everyone can read the revison list
    return {'success': True}

def group_revision_list(context, data_dict):
    return group_show(context, data_dict)

def organization_revision_list(context, data_dict):
    return group_show(context, data_dict)

def package_revision_list(context, data_dict):
    return package_show(context, data_dict)

def group_list(context, data_dict):
    # List of all active groups is visible by default
    return {'success': True}

def group_list_authz(context, data_dict):
    return group_list(context, data_dict)

def group_list_available(context, data_dict):
    return group_list(context, data_dict)

def organization_list(context, data_dict):
    # List of all active organizations are visible by default
    return {'success': True}

def organization_list_for_user(context, data_dict):
    return {'success': True}

def license_list(context, data_dict):
    # Licenses list is visible by default
    return {'success': True}

def tag_list(context, data_dict):
    # Tags list is visible by default
    return {'success': True}

def user_list(context, data_dict):
    # Users list is visible by default
    return {'success': True}

def package_relationships_list(context, data_dict):
    user = context.get('user')

    id = data_dict['id']
    id2 = data_dict.get('id2')

    # If we can see each package we can see the relationships
    authorized1 = new_authz.is_authorized_boolean(
        'package_show', context, {'id': id})
    if id2:
        authorized2 = new_authz.is_authorized_boolean(
            'package_show', context, {'id': id2})
    else:
        authorized2 = True

    if not (authorized1 and authorized2):
        return {'success': False, 'msg': _('User %s not authorized to read these packages') % user}
    else:
        return {'success': True}

def package_show(context, data_dict):
    user = context.get('user')
    package = get_package_object(context, data_dict)
    # draft state indicates package is still in the creation process
    # so we need to check we have creation rights.
    if package.state.startswith('draft'):
        auth = new_authz.is_authorized('package_update',
                                       context, data_dict)
        authorized = auth.get('success')
    elif package.owner_org is None and package.state == 'active':
        return {'success': True}
    else:
        # anyone can see a public package
        if not package.private and package.state == 'active':
            return {'success': True}
        authorized = new_authz.has_user_permission_for_group_or_org(
            package.owner_org, user, 'read')
    if not authorized:
        return {'success': False, 'msg': _('User %s not authorized to read package %s') % (user, package.id)}
    else:
        return {'success': True}

def related_show(context, data_dict=None):
    return {'success': True}


def resource_show(context, data_dict):
    model = context['model']
    user = context.get('user')
    resource = get_resource_object(context, data_dict)

    # check authentication against package
    query = model.Session.query(model.Package)\
        .join(model.ResourceGroup)\
        .join(model.Resource)\
        .filter(model.ResourceGroup.id == resource.resource_group_id)
    pkg = query.first()
    if not pkg:
        raise logic.NotFound(_('No package found for this resource, cannot check auth.'))

    pkg_dict = {'id': pkg.id}
    authorized = package_show(context, pkg_dict).get('success')

    if not authorized:
        return {'success': False, 'msg': _('User %s not authorized to read resource %s') % (user, resource.id)}
    else:
        return {'success': True}

def revision_show(context, data_dict):
    # No authz check in the logic function
    return {'success': True}

def group_show(context, data_dict):
    # anyone can see a group
    return {'success': True}

def organization_show(context, data_dict):
    # anyone can see a organization
    return {'success': True}

def tag_show(context, data_dict):
    # No authz check in the logic function
    return {'success': True}

def user_show(context, data_dict):
    # By default, user details can be read by anyone, but some properties like
    # the API key are stripped at the action level if not not logged in.
    return {'success': True}

def package_autocomplete(context, data_dict):
    return package_list(context, data_dict)

def group_autocomplete(context, data_dict):
    return group_list(context, data_dict)

def tag_autocomplete(context, data_dict):
    return tag_list(context, data_dict)

def user_autocomplete(context, data_dict):
    return user_list(context, data_dict)

def format_autocomplete(context, data_dict):
    return {'success': True}

def task_status_show(context, data_dict):
    return {'success': True}

def resource_status_show(context, data_dict):
    return {'success': True}

## Modifications for rest api

def package_show_rest(context, data_dict):
    return package_show(context, data_dict)

def group_show_rest(context, data_dict):
    return group_show(context, data_dict)

def tag_show_rest(context, data_dict):
    return tag_show(context, data_dict)

def get_site_user(context, data_dict):
    # FIXME this is available to sysadmins currently till
    # @auth_sysadmins_check decorator is added
    return {'success': False,
            'msg': 'Only internal services allowed to use this action'}


def member_roles_list(context, data_dict):
    return {'success': True}


def dashboard_activity_list(context, data_dict):
    # FIXME: context['user'] could be an IP address but that case is not
    # handled here. Maybe add an auth helper function like is_logged_in().
    if context.get('user'):
        return {'success': True}
    else:
        return {'success': False,
                'msg': _("You must be logged in to access your dashboard.")}


def dashboard_new_activities_count(context, data_dict):
    # FIXME: This should go through check_access() not call is_authorized()
    # directly, but wait until 2939-orgs is merged before fixing this.
    # This is so a better not authourized message can be sent.
    return new_authz.is_authorized('dashboard_activity_list',
            context, data_dict)


def user_follower_list(context, data_dict):
    return sysadmin(context, data_dict)


def dataset_follower_list(context, data_dict):
    return sysadmin(context, data_dict)


def group_follower_list(context, data_dict):
    return sysadmin(context, data_dict)


def organization_follower_list(context, data_dict):
    return sysadmin(context, data_dict)


def _followee_list(context, data_dict):
    model = context['model']

    # Visitors cannot see what users are following.
    authorized_user = model.User.get(context.get('user'))
    if not authorized_user:
        return {'success': False, 'msg': _('Not authorized')}

    # Any user is authorized to see what she herself is following.
    requested_user = model.User.get(data_dict.get('id'))
    if authorized_user == requested_user:
        return {'success': True}

    # Sysadmins are authorized to see what anyone is following.
    return sysadmin(context, data_dict)


def followee_list(context, data_dict):
    return _followee_list(context, data_dict)


@logic.auth_audit_exempt
def user_followee_list(context, data_dict):
    return _followee_list(context, data_dict)


@logic.auth_audit_exempt
def dataset_followee_list(context, data_dict):
    return _followee_list(context, data_dict)


@logic.auth_audit_exempt
def group_followee_list(context, data_dict):
    return _followee_list(context, data_dict)

@logic.auth_audit_exempt
def organization_followee_list(context, data_dict):
    return _followee_list(context, data_dict)

def user_reset(context, data_dict):
    return {'success': True}


def request_reset(context, data_dict):
    return {'success': True}

########NEW FILE########
__FILENAME__ = update
import ckan.logic as logic
import ckan.new_authz as new_authz
import ckan.logic.auth as logic_auth
from ckan.common import _

# FIXME this import is evil and should be refactored
from ckan.logic.auth.create import _check_group_auth


def make_latest_pending_package_active(context, data_dict):
    return new_authz.is_authorized('package_update', context, data_dict)

@logic.auth_allow_anonymous_access
def package_update(context, data_dict):
    user = context.get('user')
    package = logic_auth.get_package_object(context, data_dict)

    if package.owner_org:
        # if there is an owner org then we must have update_dataset
        # permission for that organization
        check1 = new_authz.has_user_permission_for_group_or_org(
            package.owner_org, user, 'update_dataset'
        )
    else:
        # If dataset is not owned then we can edit if config permissions allow
        if not new_authz.auth_is_anon_user(context):
            check1 = new_authz.check_config_permission(
                'create_dataset_if_not_in_organization')
        else:
            check1 = new_authz.check_config_permission('anon_create_dataset')
    if not check1:
        return {'success': False,
                'msg': _('User %s not authorized to edit package %s') %
                        (str(user), package.id)}
    else:
        check2 = _check_group_auth(context, data_dict)
        if not check2:
            return {'success': False,
                    'msg': _('User %s not authorized to edit these groups') %
                            (str(user))}

    return {'success': True}

def package_resource_reorder(context, data_dict):
    ## the action function runs package update so no need to run it twice
    return {'success': True}

def resource_update(context, data_dict):
    model = context['model']
    user = context.get('user')
    resource = logic_auth.get_resource_object(context, data_dict)

    # check authentication against package
    query = model.Session.query(model.Package)\
        .join(model.ResourceGroup)\
        .join(model.Resource)\
        .filter(model.ResourceGroup.id == resource.resource_group_id)
    pkg = query.first()
    if not pkg:
        raise logic.NotFound(
            _('No package found for this resource, cannot check auth.')
        )

    pkg_dict = {'id': pkg.id}
    authorized = new_authz.is_authorized('package_update', context, pkg_dict).get('success')

    if not authorized:
        return {'success': False,
                'msg': _('User %s not authorized to edit resource %s') %
                        (str(user), resource.id)}
    else:
        return {'success': True}


def package_relationship_update(context, data_dict):
    return new_authz.is_authorized('package_relationship_create',
                                   context,
                                   data_dict)


def package_change_state(context, data_dict):
    user = context['user']
    package = logic_auth.get_package_object(context, data_dict)

    # use the logic for package_update
    authorized = new_authz.is_authorized_boolean('package_update',
                                                 context,
                                                 data_dict)
    if not authorized:
        return {
            'success': False,
            'msg': _('User %s not authorized to change state of package %s') %
                    (str(user), package.id)
        }
    else:
        return {'success': True}


def group_update(context, data_dict):
    group = logic_auth.get_group_object(context, data_dict)
    user = context['user']
    authorized = new_authz.has_user_permission_for_group_or_org(group.id,
                                                                user,
                                                                'update')
    if not authorized:
        return {'success': False,
                'msg': _('User %s not authorized to edit group %s') %
                        (str(user), group.id)}
    else:
        return {'success': True}


def organization_update(context, data_dict):
    group = logic_auth.get_group_object(context, data_dict)
    user = context['user']
    authorized = new_authz.has_user_permission_for_group_or_org(
        group.id, user, 'update')
    if not authorized:
        return {'success': False,
                'msg': _('User %s not authorized to edit organization %s') %
                        (user, group.id)}
    else:
        return {'success': True}


def related_update(context, data_dict):
    model = context['model']
    user = context['user']
    if not user:
        return {'success': False,
                'msg': _('Only the owner can update a related item')}

    related = logic_auth.get_related_object(context, data_dict)
    userobj = model.User.get(user)
    if not userobj or userobj.id != related.owner_id:
        return {'success': False,
                'msg': _('Only the owner can update a related item')}

    # Only sysadmins can change the featured field.
    if ('featured' in data_dict and data_dict['featured'] != related.featured):
        return {'success': False,
                'msg': _('You must be a sysadmin to change a related item\'s '
                         'featured field.')}

    return {'success': True}


def group_change_state(context, data_dict):
    user = context['user']
    group = logic_auth.get_group_object(context, data_dict)

    # use logic for group_update
    authorized = new_authz.is_authorized_boolean('group_update',
                                                 context,
                                                 data_dict)
    if not authorized:
        return {
            'success': False,
            'msg': _('User %s not authorized to change state of group %s') %
                    (str(user), group.id)
        }
    else:
        return {'success': True}


def group_edit_permissions(context, data_dict):
    user = context['user']
    group = logic_auth.get_group_object(context, data_dict)

    authorized = new_authz.has_user_permission_for_group_or_org(group.id,
                                                                user,
                                                                'update')

    if not authorized:
        return {'success': False,
                'msg': _('User %s not authorized to edit permissions of group %s') %
                        (str(user), group.id)}
    else:
        return {'success': True}


@logic.auth_allow_anonymous_access
def user_update(context, data_dict):
    user = context['user']

    # FIXME: We shouldn't have to do a try ... except here, validation should
    # have ensured that the data_dict contains a valid user id before we get to
    # authorization.
    try:
        user_obj = logic_auth.get_user_object(context, data_dict)
    except logic.NotFound:
        return {'success': False, 'msg': _('User not found')}

    # If the user has a valid reset_key in the db, and that same reset key
    # has been posted in the data_dict, we allow the user to update
    # her account without using her password or API key.
    if user_obj.reset_key and 'reset_key' in data_dict:
        if user_obj.reset_key == data_dict['reset_key']:
            return {'success': True}

    if not user:
        return {'success': False,
                'msg': _('Have to be logged in to edit user')}

    if user == user_obj.name:
        # Allow users to update their own user accounts.
        return {'success': True}
    else:
        # Don't allow users to update other users' accounts.
        return {'success': False,
                'msg': _('User %s not authorized to edit user %s') %
                        (user, user_obj.id)}


def revision_change_state(context, data_dict):
    # FIXME currently only sysadmins can change state
    user = context['user']
    return {
        'success': False,
        'msg': _('User %s not authorized to change state of revision') % user
    }


def task_status_update(context, data_dict):
    # sysadmins only
    user = context['user']
    return {
        'success': False,
        'msg': _('User %s not authorized to update task_status table') % user
    }


def vocabulary_update(context, data_dict):
    # sysadmins only
    return {'success': False}


def term_translation_update(context, data_dict):
    # sysadmins only
    user = context['user']
    return {
        'success': False,
        'msg': _('User %s not authorized to update term_translation table') % user
    }


def dashboard_mark_activities_old(context, data_dict):
    return new_authz.is_authorized('dashboard_activity_list',
                                   context,
                                   data_dict)


def send_email_notifications(context, data_dict):
    # Only sysadmins are authorized to send email notifications.
    return {'success': False}


## Modifications for rest api

def package_update_rest(context, data_dict):
    model = context['model']
    user = context['user']
    if user in (model.PSEUDO_USER__VISITOR, ''):
        return {'success': False,
                'msg': _('Valid API key needed to edit a package')}

    return new_authz.is_authorized('package_update', context, data_dict)


def group_update_rest(context, data_dict):
    model = context['model']
    user = context['user']
    if user in (model.PSEUDO_USER__VISITOR, ''):
        return {'success': False,
                'msg': _('Valid API key needed to edit a group')}

    return group_update(context, data_dict)


def package_owner_org_update(context, data_dict):
    # sysadmins only
    return {'success': False}


def bulk_update_private(context, data_dict):
    org_id = data_dict.get('org_id')
    user = context['user']
    authorized = new_authz.has_user_permission_for_group_or_org(
        org_id, user, 'update')
    if not authorized:
        return {'success': False}
    return {'success': True}


def bulk_update_public(context, data_dict):
    org_id = data_dict.get('org_id')
    user = context['user']
    authorized = new_authz.has_user_permission_for_group_or_org(
        org_id, user, 'update')
    if not authorized:
        return {'success': False}
    return {'success': True}


def bulk_update_delete(context, data_dict):
    org_id = data_dict.get('org_id')
    user = context['user']
    authorized = new_authz.has_user_permission_for_group_or_org(
        org_id, user, 'update')
    if not authorized:
        return {'success': False}
    return {'success': True}

########NEW FILE########
__FILENAME__ = converters
import json

import ckan.model as model
import ckan.lib.navl.dictization_functions as df
import ckan.lib.field_types as field_types
import ckan.logic.validators as validators

from ckan.common import _

def convert_to_extras(key, data, errors, context):
    extras = data.get(('extras',), [])
    if not extras:
        data[('extras',)] = extras
    extras.append({'key': key[-1], 'value': data[key]})

def convert_from_extras(key, data, errors, context):

    def remove_from_extras(data, key):
        to_remove = []
        for data_key, data_value in data.iteritems():
            if (data_key[0] == 'extras'
                and data_key[1] == key):
                to_remove.append(data_key)
        for item in to_remove:
            del data[item]

    for data_key, data_value in data.iteritems():
        if (data_key[0] == 'extras'
            and data_key[-1] == 'key'
            and data_value == key[-1]):
            data[key] = data[('extras', data_key[1], 'value')]
            break
    else:
        return
    remove_from_extras(data, data_key[1])

def date_to_db(value, context):
    try:
        value = field_types.DateType.form_to_db(value)
    except field_types.DateConvertError, e:
        raise df.Invalid(str(e))
    return value

def date_to_form(value, context):
    try:
        value = field_types.DateType.db_to_form(value)
    except field_types.DateConvertError, e:
        raise df.Invalid(str(e))
    return value

def free_tags_only(key, data, errors, context):
    tag_number = key[1]
    if not data.get(('tags', tag_number, 'vocabulary_id')):
        return
    for k in data.keys():
        if k[0] == 'tags' and k[1] == tag_number:
            del data[k]

def convert_to_tags(vocab):
    def callable(key, data, errors, context):
        new_tags = data.get(key)
        if not new_tags:
            return
        if isinstance(new_tags, basestring):
            new_tags = [new_tags]

        # get current number of tags
        n = 0
        for k in data.keys():
            if k[0] == 'tags':
                n = max(n, k[1] + 1)

        v = model.Vocabulary.get(vocab)
        if not v:
            raise df.Invalid(_('Tag vocabulary "%s" does not exist') % vocab)
        context['vocabulary'] = v

        for tag in new_tags:
            validators.tag_in_vocabulary_validator(tag, context)

        for num, tag in enumerate(new_tags):
            data[('tags', num + n, 'name')] = tag
            data[('tags', num + n, 'vocabulary_id')] = v.id
    return callable

def convert_from_tags(vocab):
    def callable(key, data, errors, context):
        v = model.Vocabulary.get(vocab)
        if not v:
            raise df.Invalid(_('Tag vocabulary "%s" does not exist') % vocab)

        tags = []
        for k in data.keys():
            if k[0] == 'tags':
                if data[k].get('vocabulary_id') == v.id:
                    name = data[k].get('display_name', data[k]['name'])
                    tags.append(name)
        data[key] = tags
    return callable

def convert_user_name_or_id_to_id(user_name_or_id, context):
    '''Return the user id for the given user name or id.

    The point of this function is to convert user names to ids. If you have
    something that may be a user name or a user id you can pass it into this
    function and get the user id out either way.

    Also validates that a user with the given name or id exists.

    :returns: the id of the user with the given user name or id
    :rtype: string
    :raises: ckan.lib.navl.dictization_functions.Invalid if no user can be
        found with the given id or user name

    '''
    session = context['session']
    result = session.query(model.User).filter_by(id=user_name_or_id).first()
    if not result:
        result = session.query(model.User).filter_by(
                name=user_name_or_id).first()
    if not result:
        raise df.Invalid('%s: %s' % (_('Not found'), _('User')))
    return result.id

def convert_package_name_or_id_to_id(package_name_or_id, context):
    '''Return the package id for the given package name or id.

    The point of this function is to convert package names to ids. If you have
    something that may be a package name or id you can pass it into this
    function and get the id out either way.

    Also validates that a package with the given name or id exists.

    :returns: the id of the package with the given name or id
    :rtype: string
    :raises: ckan.lib.navl.dictization_functions.Invalid if there is no
        package with the given name or id

    '''
    session = context['session']
    result = session.query(model.Package).filter_by(
            id=package_name_or_id).first()
    if not result:
        result = session.query(model.Package).filter_by(
                name=package_name_or_id).first()
    if not result:
        raise df.Invalid('%s: %s' % (_('Not found'), _('Dataset')))
    return result.id

def convert_group_name_or_id_to_id(group_name_or_id, context):
    '''Return the group id for the given group name or id.

    The point of this function is to convert group names to ids. If you have
    something that may be a group name or id you can pass it into this
    function and get the id out either way.

    Also validates that a group with the given name or id exists.

    :returns: the id of the group with the given name or id
    :rtype: string
    :raises: ckan.lib.navl.dictization_functions.Invalid if there is no
        group with the given name or id

    '''
    session = context['session']
    result = session.query(model.Group).filter_by(
            id=group_name_or_id).first()
    if not result:
        result = session.query(model.Group).filter_by(
                name=group_name_or_id).first()
    if not result:
        raise df.Invalid('%s: %s' % (_('Not found'), _('Group')))
    return result.id


def convert_to_json_if_string(value, context):
    if isinstance(value, basestring):
        try:
            return json.loads(value)
        except ValueError:
            raise df.Invalid(_('Could not parse as valid JSON'))
    else:
        return value


def remove_whitespace(value, context):
    if isinstance(value, basestring):
        return value.strip()
    return value

########NEW FILE########
__FILENAME__ = schema
from ckan.lib.navl.validators import (ignore_missing,
                                      keep_extras,
                                      not_empty,
                                      empty,
                                      ignore,
                                      if_empty_same_as,
                                      not_missing,
                                      ignore_empty
                                     )
from ckan.logic.validators import (package_id_not_changed,
                                   package_id_exists,
                                   package_id_or_name_exists,
                                   extras_unicode_convert,
                                   name_validator,
                                   package_name_validator,
                                   package_version_validator,
                                   group_name_validator,
                                   tag_length_validator,
                                   tag_name_validator,
                                   tag_string_convert,
                                   duplicate_extras_key,
                                   ignore_not_package_admin,
                                   ignore_not_group_admin,
                                   ignore_not_sysadmin,
                                   no_http,
                                   tag_not_uppercase,
                                   user_name_validator,
                                   user_password_validator,
                                   user_both_passwords_entered,
                                   user_passwords_match,
                                   user_password_not_empty,
                                   isodate,
                                   int_validator,
                                   natural_number_validator,
                                   is_positive_integer,
                                   boolean_validator,
                                   user_about_validator,
                                   vocabulary_name_validator,
                                   vocabulary_id_not_changed,
                                   vocabulary_id_exists,
                                   user_id_exists,
                                   user_id_or_name_exists,
                                   object_id_validator,
                                   activity_type_exists,
                                   resource_id_exists,
                                   tag_not_in_vocabulary,
                                   group_id_exists,
                                   owner_org_validator,
                                   user_name_exists,
                                   role_exists,
                                   url_validator,
                                   datasets_with_no_organization_cannot_be_private,
                                   list_of_strings,
                                   if_empty_guess_format,
                                   clean_format,
                                   no_loops_in_hierarchy,
                                   )
from ckan.logic.converters import (convert_user_name_or_id_to_id,
                                   convert_package_name_or_id_to_id,
                                   convert_group_name_or_id_to_id,
                                   convert_to_json_if_string,
                                   remove_whitespace,
                                   )
from formencode.validators import OneOf
import ckan.model
import ckan.lib.maintain as maintain

def default_resource_schema():

    schema = {
        'id': [ignore_empty, unicode],
        'revision_id': [ignore],
        'resource_group_id': [ignore],
        'package_id': [ignore],
        'url': [not_empty, unicode, remove_whitespace],
        'description': [ignore_missing, unicode],
        'format': [if_empty_guess_format, ignore_missing, clean_format, unicode],
        'hash': [ignore_missing, unicode],
        'state': [ignore],
        'position': [ignore],
        'revision_timestamp': [ignore],
        'name': [ignore_missing, unicode],
        'resource_type': [ignore_missing, unicode],
        'url_type': [ignore_missing, unicode],
        'mimetype': [ignore_missing, unicode],
        'mimetype_inner': [ignore_missing, unicode],
        'webstore_url': [ignore_missing, unicode],
        'cache_url': [ignore_missing, unicode],
        'size': [ignore_missing, int_validator],
        'created': [ignore_missing, isodate],
        'last_modified': [ignore_missing, isodate],
        'cache_last_updated': [ignore_missing, isodate],
        'webstore_last_updated': [ignore_missing, isodate],
        'tracking_summary': [ignore_missing],
        'datastore_active': [ignore],
        '__extras': [ignore_missing, extras_unicode_convert, keep_extras],
    }

    return schema

def default_update_resource_schema():
    schema = default_resource_schema()
    return schema

def default_tags_schema():
    schema = {
        'name': [not_missing,
                 not_empty,
                 unicode,
                 tag_length_validator,
                 tag_name_validator,
                ],
        'vocabulary_id': [ignore_missing, unicode, vocabulary_id_exists],
        'revision_timestamp': [ignore],
        'state': [ignore],
        'display_name': [ignore],
    }
    return schema

def default_create_tag_schema():
    schema = default_tags_schema()
    # When creating a tag via the tag_create() logic action function, a
    # vocabulary_id _must_ be given (you cannot create free tags via this
    # function).
    schema['vocabulary_id'] = [not_missing, not_empty, unicode,
            vocabulary_id_exists, tag_not_in_vocabulary]
    # You're not allowed to specify your own ID when creating a tag.
    schema['id'] = [empty]
    return schema


def default_create_package_schema():
    schema = {
        '__before': [duplicate_extras_key, ignore],
        'id': [empty],
        'revision_id': [ignore],
        'name': [not_empty, unicode, name_validator, package_name_validator],
        'title': [if_empty_same_as("name"), unicode],
        'author': [ignore_missing, unicode],
        'author_email': [ignore_missing, unicode],
        'maintainer': [ignore_missing, unicode],
        'maintainer_email': [ignore_missing, unicode],
        'license_id': [ignore_missing, unicode],
        'notes': [ignore_missing, unicode],
        'url': [ignore_missing, unicode],#, URL(add_http=False)],
        'version': [ignore_missing, unicode, package_version_validator],
        'state': [ignore_not_package_admin, ignore_missing],
        'type': [ignore_missing, unicode],
        'owner_org': [owner_org_validator, unicode],
        'log_message': [ignore_missing, unicode, no_http],
        'private': [ignore_missing, boolean_validator,
            datasets_with_no_organization_cannot_be_private],
        '__extras': [ignore],
        '__junk': [empty],
        'resources': default_resource_schema(),
        'tags': default_tags_schema(),
        'tag_string': [ignore_missing, tag_string_convert],
        'extras': default_extras_schema(),
        'save': [ignore],
        'return_to': [ignore],
        'relationships_as_object': default_relationship_schema(),
        'relationships_as_subject': default_relationship_schema(),
        'groups': {
            'id': [ignore_missing, unicode],
            'name': [ignore_missing, unicode],
            'title': [ignore_missing, unicode],
            '__extras': [ignore],
        }
    }
    return schema

def default_update_package_schema():
    schema = default_create_package_schema()

    schema['resources'] = default_update_resource_schema()

    # Users can (optionally) supply the package id when updating a package, but
    # only to identify the package to be updated, they cannot change the id.
    schema['id'] = [ignore_missing, package_id_not_changed]

    # Supplying the package name when updating a package is optional (you can
    # supply the id to identify the package instead).
    schema['name'] = [ignore_missing, name_validator, package_name_validator,
            unicode]

    # Supplying the package title when updating a package is optional, if it's
    # not supplied the title will not be changed.
    schema['title'] = [ignore_missing, unicode]

    schema['owner_org'] = [ignore_missing, owner_org_validator, unicode]

    return schema

def default_show_package_schema():
    schema = default_create_package_schema()

    # Don't strip ids from package dicts when validating them.
    schema['id'] = []

    schema.update({
        'tags': {'__extras': [ckan.lib.navl.validators.keep_extras]}})

    # Add several keys to the 'resources' subschema so they don't get stripped
    # from the resource dicts by validation.
    schema['resources'].update({
        'format': [ignore_missing, clean_format, unicode],
        'created': [ckan.lib.navl.validators.ignore_missing],
        'position': [not_empty],
        'last_modified': [ckan.lib.navl.validators.ignore_missing],
        'cache_last_updated': [ckan.lib.navl.validators.ignore_missing],
        'webstore_last_updated': [ckan.lib.navl.validators.ignore_missing],
        'revision_timestamp': [],
        'revision_id': [],
        'resource_group_id': [],
        'cache_last_updated': [],
        'webstore_last_updated': [],
        'size': [],
        'state': [],
        'last_modified': [],
        'mimetype': [],
        'cache_url': [],
        'name': [],
        'webstore_url': [],
        'mimetype_inner': [],
        'resource_type': [],
        'url_type': [],
    })

    schema.update({
        'state': [ckan.lib.navl.validators.ignore_missing],
        'isopen': [ignore_missing],
        'license_url': [ignore_missing],
        'revision_id': [],
        })

    schema['groups'].update({
        'description': [ignore_missing],
        'display_name': [ignore_missing],
        'image_display_url': [ignore_missing],
        })

    # Remove validators for several keys from the schema so validation doesn't
    # strip the keys from the package dicts if the values are 'missing' (i.e.
    # None).
    schema['author'] = []
    schema['author_email'] = []
    schema['maintainer'] = []
    schema['maintainer_email'] = []
    schema['license_id'] = []
    schema['notes'] = []
    schema['url'] = []
    schema['version'] = []

    # Add several keys that are missing from default_create_package_schema(), so
    # validation doesn't strip the keys from the package dicts.
    schema['metadata_created'] = []
    schema['metadata_modified'] = []
    schema['creator_user_id'] = []
    schema['num_resources'] = []
    schema['num_tags'] = []
    schema['organization'] = []
    schema['owner_org'] = []
    schema['private'] = []
    schema['revision_id'] = []
    schema['revision_timestamp'] = []
    schema['tracking_summary'] = []
    schema['license_title'] = []

    return schema

def default_group_schema():

    schema = {
        'id': [ignore_missing, unicode],
        'revision_id': [ignore],
        'name': [not_empty, unicode, name_validator, group_name_validator],
        'title': [ignore_missing, unicode],
        'description': [ignore_missing, unicode],
        'image_url': [ignore_missing, unicode],
        'image_display_url': [ignore_missing, unicode],
        'type': [ignore_missing, unicode],
        'state': [ignore_not_group_admin, ignore_missing],
        'created': [ignore],
        'is_organization': [ignore_missing],
        'approval_status': [ignore_missing, unicode],
        'extras': default_extras_schema(),
        '__extras': [ignore],
        '__junk': [ignore],
        'packages': {
            "id": [not_empty, unicode, package_id_or_name_exists],
            "title":[ignore_missing, unicode],
            "name":[ignore_missing, unicode],
            "__extras": [ignore]
        },
        'users': {
            "name": [not_empty, unicode],
            "capacity": [ignore_missing],
            "__extras": [ignore]
        },
        'groups': {
            "name": [not_empty, no_loops_in_hierarchy, unicode],
            "capacity": [ignore_missing],
            "__extras": [ignore]
        }
    }
    return schema

def group_form_schema():
    schema = default_group_schema()
    #schema['extras_validation'] = [duplicate_extras_key, ignore]
    schema['packages'] = {
        "name": [not_empty, unicode],
        "title": [ignore_missing],
        "__extras": [ignore]
    }
    schema['users'] = {
        "name": [not_empty, unicode],
        "capacity": [ignore_missing],
        "__extras": [ignore]
    }
    schema['display_name'] = [ignore_missing]
    return schema


def default_update_group_schema():
    schema = default_group_schema()
    schema["name"] = [ignore_missing, group_name_validator, unicode]
    return schema

def default_show_group_schema():
    schema = default_group_schema()

    # make default show schema behave like when run with no validation
    schema['num_followers'] = []
    schema['created'] = []
    schema['display_name'] = []
    schema['extras'] = {'__extras': [ckan.lib.navl.validators.keep_extras]}
    schema['package_count'] = []
    schema['packages'] = {'__extras': [ckan.lib.navl.validators.keep_extras]}
    schema['revision_id'] = []
    schema['state'] = []
    schema['users'] = {'__extras': [ckan.lib.navl.validators.keep_extras]}

    return schema


def default_related_schema():
    schema = {
        'id': [ignore_missing, unicode],
        'title': [not_empty, unicode],
        'description': [ignore_missing, unicode],
        'type': [not_empty, unicode],
        'image_url': [ignore_missing, unicode, url_validator],
        'url': [ignore_missing, unicode, url_validator],
        'owner_id': [not_empty, unicode],
        'created': [ignore],
        'featured': [ignore_missing, int],
    }
    return schema


def default_update_related_schema():
    schema = default_related_schema()
    schema['id'] = [not_empty, unicode]
    schema['title'] = [ignore_missing, unicode]
    schema['type'] = [ignore_missing, unicode]
    schema['owner_id'] = [ignore_missing, unicode]
    return schema


def default_extras_schema():

    schema = {
        'id': [ignore],
        'key': [not_empty, unicode],
        'value': [not_missing],
        'state': [ignore],
        'deleted': [ignore_missing],
        'revision_timestamp': [ignore],
        '__extras': [ignore],
    }
    return schema

def default_relationship_schema():

    schema = {
         'id': [ignore_missing, unicode],
         'subject': [ignore_missing, unicode],
         'object': [ignore_missing, unicode],
         'type': [not_empty, OneOf(ckan.model.PackageRelationship.get_all_types())],
         'comment': [ignore_missing, unicode],
         'state': [ignore],
    }
    return schema

def default_create_relationship_schema():

    schema = default_relationship_schema()
    schema['id'] = [empty]
    schema['subject'] = [not_empty, unicode, package_id_or_name_exists]
    schema['object'] = [not_empty, unicode, package_id_or_name_exists]

    return schema

def default_update_relationship_schema():

    schema = default_relationship_schema()
    schema['id'] = [ignore_missing, package_id_not_changed]

    # Todo: would like to check subject, object & type haven't changed, but
    # no way to do this in schema
    schema['subject'] = [ignore_missing]
    schema['object'] = [ignore_missing]
    schema['type'] = [ignore_missing]

    return schema




def default_user_schema():

    schema = {
        'id': [ignore_missing, unicode],
        'name': [not_empty, name_validator, user_name_validator, unicode],
        'fullname': [ignore_missing, unicode],
        'password': [user_password_validator, user_password_not_empty, ignore_missing, unicode],
        'email': [not_empty, unicode],
        'about': [ignore_missing, user_about_validator, unicode],
        'created': [ignore],
        'openid': [ignore_missing],
        'sysadmin': [ignore_missing, ignore_not_sysadmin],
        'apikey': [ignore],
        'reset_key': [ignore],
        'activity_streams_email_notifications': [ignore_missing],
        'state': [ignore_missing],
    }
    return schema

def user_new_form_schema():
    schema = default_user_schema()

    schema['password1'] = [unicode,user_both_passwords_entered,user_password_validator,user_passwords_match]
    schema['password2'] = [unicode]

    return schema

def user_edit_form_schema():
    schema = default_user_schema()

    schema['password'] = [ignore_missing]
    schema['password1'] = [ignore_missing,unicode,user_password_validator,user_passwords_match]
    schema['password2'] = [ignore_missing,unicode]

    return schema

def default_update_user_schema():
    schema = default_user_schema()

    schema['name'] = [ignore_missing, name_validator, user_name_validator, unicode]
    schema['password'] = [user_password_validator,ignore_missing, unicode]

    return schema

def default_user_invite_schema():
    schema = {
        'email': [not_empty, unicode],
        'group_id': [not_empty],
        'role': [not_empty],
    }
    return schema

def default_task_status_schema():
    schema = {
        'id': [ignore],
        'entity_id': [not_empty, unicode],
        'entity_type': [not_empty, unicode],
        'task_type': [not_empty, unicode],
        'key': [not_empty, unicode],
        'value': [ignore_missing],
        'state': [ignore_missing],
        'last_updated': [ignore_missing],
        'error': [ignore_missing]
    }
    return schema

def default_vocabulary_schema():
    schema = {
        'id': [ignore_missing, unicode, vocabulary_id_exists],
        'name': [not_empty, unicode, vocabulary_name_validator],
        'tags': default_tags_schema(),
    }
    return schema

def default_create_vocabulary_schema():
    schema = default_vocabulary_schema()
    schema['id'] = [empty]
    return schema

def default_update_vocabulary_schema():
    schema = default_vocabulary_schema()
    schema['id'] = [ignore_missing, vocabulary_id_not_changed]
    schema['name'] = [ignore_missing, vocabulary_name_validator]
    return schema

def default_create_activity_schema():
    schema = {
        'id': [ignore],
        'timestamp': [ignore],
        'user_id': [not_missing, not_empty, unicode,
            convert_user_name_or_id_to_id],
        'object_id': [not_missing, not_empty, unicode, object_id_validator],
        # We don't bother to validate revision ID, since it's always created
        # internally by the activity_create() logic action function.
        'revision_id': [],
        'activity_type': [not_missing, not_empty, unicode,
            activity_type_exists],
        'data': [ignore_empty, ignore_missing],
    }
    return schema

def default_follow_user_schema():
    schema = {'id': [not_missing, not_empty, unicode,
        convert_user_name_or_id_to_id]}
    return schema

def default_follow_dataset_schema():
    schema = {'id': [not_missing, not_empty, unicode,
        convert_package_name_or_id_to_id]}
    return schema


def member_schema():
    schema = {
        'id': [group_id_exists, unicode],
        'username': [user_name_exists, unicode],
        'role': [role_exists, unicode],
    }
    return schema


def default_follow_group_schema():
    schema = {'id': [not_missing, not_empty, unicode,
        convert_group_name_or_id_to_id]}
    return schema


def default_package_list_schema():
    schema = {
        'limit': [ignore_missing, natural_number_validator],
        'offset': [ignore_missing, natural_number_validator],
        'page': [ignore_missing, is_positive_integer]
    }
    return schema


def default_pagination_schema():
    schema = {
        'limit': [ignore_missing, natural_number_validator],
        'offset': [ignore_missing, natural_number_validator]
    }
    return schema


def default_dashboard_activity_list_schema():
    schema = default_pagination_schema()
    schema['id'] = [unicode]
    return schema


def default_activity_list_schema():
    schema = default_pagination_schema()
    schema['id'] = [not_missing, unicode]
    return schema


def default_autocomplete_schema():
    schema = {
        'q': [not_missing, unicode],
        'limit': [ignore_missing, natural_number_validator]
    }
    return schema


def default_package_search_schema():
    schema = {
        'q': [ignore_missing, unicode],
        'fq': [ignore_missing, unicode],
        'rows': [ignore_missing, natural_number_validator],
        'sort': [ignore_missing, unicode],
        'start': [ignore_missing, natural_number_validator],
        'qf': [ignore_missing, unicode],
        'facet': [ignore_missing, unicode],
        'facet.mincount': [ignore_missing, natural_number_validator],
        'facet.limit': [ignore_missing, int_validator],
        'facet.field': [ignore_missing, convert_to_json_if_string,
            list_of_strings],
        'extras': [ignore_missing]  # Not used by Solr, but useful for extensions
    }
    return schema


def default_resource_search_schema():
    schema = {
        'query': [ignore_missing],  # string or list of strings
        'fields': [ignore_missing],  # dict of fields
        'order_by': [ignore_missing, unicode],
        'offset': [ignore_missing, natural_number_validator],
        'limit': [ignore_missing, natural_number_validator]
    }
    return schema


def create_schema_for_required_keys(keys):
    ''' helper function that creates a schema definition where
    each key from keys is validated against ``not_missing``.
    '''
    schema = dict([(x, [not_missing]) for x in keys])
    return schema

########NEW FILE########
__FILENAME__ = validators
import datetime
from itertools import count
import re
import mimetypes

import ckan.lib.navl.dictization_functions as df
import ckan.logic as logic
import ckan.lib.helpers as h
from ckan.model import (MAX_TAG_LENGTH, MIN_TAG_LENGTH,
                        PACKAGE_NAME_MIN_LENGTH, PACKAGE_NAME_MAX_LENGTH,
                        PACKAGE_VERSION_MAX_LENGTH,
                        VOCABULARY_NAME_MAX_LENGTH,
                        VOCABULARY_NAME_MIN_LENGTH)
import ckan.new_authz as new_authz

from ckan.common import _

Invalid = df.Invalid
StopOnError = df.StopOnError
Missing = df.Missing
missing = df.missing

def owner_org_validator(key, data, errors, context):

    value = data.get(key)

    if value is missing or value is None:
        if not new_authz.check_config_permission('create_unowned_dataset'):
            raise Invalid(_('A organization must be supplied'))
        data.pop(key, None)
        raise df.StopOnError

    model = context['model']
    user = context['user']
    user = model.User.get(user)
    if value == '' :
        if not new_authz.check_config_permission('create_unowned_dataset'):
            raise Invalid(_('A organization must be supplied'))
        package = context.get('package')
        # only sysadmins can remove datasets from org
        if package and package.owner_org and not user.sysadmin:
            raise Invalid(_('You cannot remove a dataset from an existing organization'))
        return

    group = model.Group.get(value)
    if not group:
        raise Invalid(_('Organization does not exist'))
    group_id = group.id
    if not(user.sysadmin or
           new_authz.has_user_permission_for_group_or_org(
               group_id, user.name, 'create_dataset')):
        raise Invalid(_('You cannot add a dataset to this organization'))
    data[key] = group_id


def package_id_not_changed(value, context):

    package = context.get('package')
    if package and value != package.id:
        raise Invalid('Cannot change value of key from %s to %s. '
                      'This key is read-only' % (package.id, value))
    return value

def int_validator(value, context):
    '''
    Return an integer for value, which may be a string in base 10 or
    a numeric type (e.g. int, long, float, Decimal, Fraction). Return
    None for None or empty/all-whitespace string values.

    :raises: ckan.lib.navl.dictization_functions.Invalid for other
        inputs or non-whole values
    '''
    if value is None:
        return None
    if hasattr(value, 'strip') and not value.strip():
        return None

    try:
        whole, part = divmod(value, 1)
    except TypeError:
        try:
            return int(value)
        except ValueError:
            pass
    else:
        if not part:
            try:
                return int(whole)
            except TypeError:
                pass  # complex number: fail like int(complex) does

    raise Invalid(_('Invalid integer'))

def natural_number_validator(value, context):
    value = int_validator(value, context)
    if value < 0:
        raise Invalid(_('Must be a natural number'))
    return value

def is_positive_integer(value, context):
    value = int_validator(value, context)
    if value < 1:
        raise Invalid(_('Must be a postive integer'))
    return value

def boolean_validator(value, context):
    if isinstance(value, bool):
        return value
    if value.lower() in ['true', 'yes', 't', 'y', '1']:
        return True
    return False

def isodate(value, context):
    if isinstance(value, datetime.datetime):
        return value
    if value == '':
        return None
    try:
        date = h.date_str_to_datetime(value)
    except (TypeError, ValueError), e:
        raise Invalid(_('Date format incorrect'))
    return date

def no_http(value, context):

    model = context['model']
    session = context['session']

    if 'http:' in value:
        raise Invalid(_('No links are allowed in the log_message.'))
    return value

def package_id_exists(value, context):

    model = context['model']
    session = context['session']

    result = session.query(model.Package).get(value)
    if not result:
        raise Invalid('%s: %s' % (_('Not found'), _('Dataset')))
    return value

def package_name_exists(value, context):

    model = context['model']
    session = context['session']

    result = session.query(model.Package).filter_by(name=value).first()

    if not result:
        raise Invalid(_('Not found') + ': %s' % value)
    return value

def package_id_or_name_exists(package_id_or_name, context):
    '''Return the given package_id_or_name if such a package exists.

    :raises: ckan.lib.navl.dictization_functions.Invalid if there is no
        package with the given id or name

    '''
    model = context['model']
    session = context['session']

    result = session.query(model.Package).get(package_id_or_name)
    if result:
        return package_id_or_name

    result = session.query(model.Package).filter_by(
            name=package_id_or_name).first()

    if not result:
        raise Invalid('%s: %s' % (_('Not found'), _('Dataset')))

    return package_id_or_name

def user_id_exists(user_id, context):
    '''Raises Invalid if the given user_id does not exist in the model given
    in the context, otherwise returns the given user_id.

    '''
    model = context['model']
    session = context['session']

    result = session.query(model.User).get(user_id)
    if not result:
        raise Invalid('%s: %s' % (_('Not found'), _('User')))
    return user_id

def user_id_or_name_exists(user_id_or_name, context):
    '''Return the given user_id_or_name if such a user exists.

    :raises: ckan.lib.navl.dictization_functions.Invalid if no user can be
        found with the given id or user name

    '''
    model = context['model']
    session = context['session']
    result = session.query(model.User).get(user_id_or_name)
    if result:
        return user_id_or_name
    result = session.query(model.User).filter_by(name=user_id_or_name).first()
    if not result:
        raise Invalid('%s: %s' % (_('Not found'), _('User')))
    return user_id_or_name

def group_id_exists(group_id, context):
    '''Raises Invalid if the given group_id does not exist in the model given
    in the context, otherwise returns the given group_id.

    '''
    model = context['model']
    session = context['session']

    result = session.query(model.Group).get(group_id)
    if not result:
        raise Invalid('%s: %s' % (_('Not found'), _('Group')))
    return group_id


def related_id_exists(related_id, context):
    '''Raises Invalid if the given related_id does not exist in the model
    given in the context, otherwise returns the given related_id.

    '''
    model = context['model']
    session = context['session']

    result = session.query(model.Related).get(related_id)
    if not result:
        raise Invalid('%s: %s' % (_('Not found'), _('Related')))
    return related_id

def group_id_or_name_exists(reference, context):
    '''
    Raises Invalid if a group identified by the name or id cannot be found.
    '''
    model = context['model']
    result = model.Group.get(reference)
    if not result:
        raise Invalid(_('That group name or ID does not exist.'))
    return reference

def activity_type_exists(activity_type):
    '''Raises Invalid if there is no registered activity renderer for the
    given activity_type. Otherwise returns the given activity_type.

    This just uses object_id_validators as a lookup.
    very safe.

    '''
    if activity_type in object_id_validators:
        return activity_type
    else:
        raise Invalid('%s: %s' % (_('Not found'), _('Activity type')))

def resource_id_exists(value, context):

    model = context['model']
    session = context['session']

    result = session.query(model.Resource).get(value)
    if not result:
        raise Invalid('%s: %s' % (_('Not found'), _('Resource')))
    return value

# A dictionary mapping activity_type values from activity dicts to functions
# for validating the object_id values from those same activity dicts.
object_id_validators = {
    'new package' : package_id_exists,
    'changed package' : package_id_exists,
    'deleted package' : package_id_exists,
    'follow dataset' : package_id_exists,
    'new user' : user_id_exists,
    'changed user' : user_id_exists,
    'follow user' : user_id_exists,
    'new group' : group_id_exists,
    'changed group' : group_id_exists,
    'deleted group' : group_id_exists,
    'new organization' : group_id_exists,
    'changed organization' : group_id_exists,
    'deleted organization' : group_id_exists,
    'follow group' : group_id_exists,
    'new related item': related_id_exists,
    'deleted related item': related_id_exists,
    'changed related item': related_id_exists,
    }

def object_id_validator(key, activity_dict, errors, context):
    '''Validate the 'object_id' value of an activity_dict.

    Uses the object_id_validators dict (above) to find and call an 'object_id'
    validator function for the given activity_dict's 'activity_type' value.

    Raises Invalid if the model given in context contains no object of the
    correct type (according to the 'activity_type' value of the activity_dict)
    with the given ID.

    Raises Invalid if there is no object_id_validator for the activity_dict's
    'activity_type' value.

    '''
    activity_type = activity_dict[('activity_type',)]
    if object_id_validators.has_key(activity_type):
        object_id = activity_dict[('object_id',)]
        return object_id_validators[activity_type](object_id, context)
    else:
        raise Invalid('There is no object_id validator for '
            'activity type "%s"' % activity_type)

def extras_unicode_convert(extras, context):
    for extra in extras:
        extras[extra] = unicode(extras[extra])
    return extras

name_match = re.compile('[a-z0-9_\-]*$')
def name_validator(value, context):
    '''Return the given value if it's a valid name, otherwise raise Invalid.

    If it's a valid name, the given value will be returned unmodified.

    This function applies general validation rules for names of packages,
    groups, users, etc.

    Most schemas also have their own custom name validator function to apply
    custom validation rules after this function, for example a
    ``package_name_validator()`` to check that no package with the given name
    already exists.

    :raises ckan.lib.navl.dictization_functions.Invalid: if ``value`` is not
        a valid name

    '''
    if not isinstance(value, basestring):
        raise Invalid(_('Names must be strings'))

    # check basic textual rules
    if value in ['new', 'edit', 'search']:
        raise Invalid(_('That name cannot be used'))

    if len(value) < 2:
        raise Invalid(_('Name must be at least %s characters long') % 2)
    if len(value) > PACKAGE_NAME_MAX_LENGTH:
        raise Invalid(_('Name must be a maximum of %i characters long') % \
                      PACKAGE_NAME_MAX_LENGTH)
    if not name_match.match(value):
        raise Invalid(_('Url must be purely lowercase alphanumeric '
                        '(ascii) characters and these symbols: -_'))
    return value

def package_name_validator(key, data, errors, context):
    model = context['model']
    session = context['session']
    package = context.get('package')

    query = session.query(model.Package.name).filter_by(name=data[key])
    if package:
        package_id = package.id
    else:
        package_id = data.get(key[:-1] + ('id',))
    if package_id and package_id is not missing:
        query = query.filter(model.Package.id <> package_id)
    result = query.first()
    if result:
        errors[key].append(_('That URL is already in use.'))

    value = data[key]
    if len(value) < PACKAGE_NAME_MIN_LENGTH:
        raise Invalid(
            _('Name "%s" length is less than minimum %s') % (value, PACKAGE_NAME_MIN_LENGTH)
        )
    if len(value) > PACKAGE_NAME_MAX_LENGTH:
        raise Invalid(
            _('Name "%s" length is more than maximum %s') % (value, PACKAGE_NAME_MAX_LENGTH)
        )

def package_version_validator(value, context):

    if len(value) > PACKAGE_VERSION_MAX_LENGTH:
        raise Invalid(_('Version must be a maximum of %i characters long') % \
                      PACKAGE_VERSION_MAX_LENGTH)
    return value

def duplicate_extras_key(key, data, errors, context):

    unflattened = df.unflatten(data)
    extras = unflattened.get('extras', [])
    extras_keys = []
    for extra in extras:
        if not extra.get('deleted'):
            extras_keys.append(extra['key'])

    for extra_key in set(extras_keys):
        extras_keys.remove(extra_key)
    if extras_keys:
        key_ = ('extras_validation',)
        assert key_ not in errors
        errors[key_] = [_('Duplicate key "%s"') % extras_keys[0]]

def group_name_validator(key, data, errors, context):
    model = context['model']
    session = context['session']
    group = context.get('group')

    query = session.query(model.Group.name).filter_by(name=data[key])
    if group:
        group_id = group.id
    else:
        group_id = data.get(key[:-1] + ('id',))
    if group_id and group_id is not missing:
        query = query.filter(model.Group.id <> group_id)
    result = query.first()
    if result:
        errors[key].append(_('Group name already exists in database'))

def tag_length_validator(value, context):

    if len(value) < MIN_TAG_LENGTH:
        raise Invalid(
            _('Tag "%s" length is less than minimum %s') % (value, MIN_TAG_LENGTH)
        )
    if len(value) > MAX_TAG_LENGTH:
        raise Invalid(
            _('Tag "%s" length is more than maximum %i') % (value, MAX_TAG_LENGTH)
        )
    return value

def tag_name_validator(value, context):

    tagname_match = re.compile('[\w \-.]*$', re.UNICODE)
    if not tagname_match.match(value):
        raise Invalid(_('Tag "%s" must be alphanumeric '
                        'characters or symbols: -_.') % (value))
    return value

def tag_not_uppercase(value, context):

    tagname_uppercase = re.compile('[A-Z]')
    if tagname_uppercase.search(value):
        raise Invalid(_('Tag "%s" must not be uppercase' % (value)))
    return value

def tag_string_convert(key, data, errors, context):
    '''Takes a list of tags that is a comma-separated string (in data[key])
    and parses tag names. These are added to the data dict, enumerated. They
    are also validated.'''

    if isinstance(data[key], basestring):
        tags = [tag.strip() \
                for tag in data[key].split(',') \
                if tag.strip()]
    else:
        tags = data[key]

    current_index = max( [int(k[1]) for k in data.keys() if len(k) == 3 and k[0] == 'tags'] + [-1] )

    for num, tag in zip(count(current_index+1), tags):
        data[('tags', num, 'name')] = tag

    for tag in tags:
        tag_length_validator(tag, context)
        tag_name_validator(tag, context)

def ignore_not_admin(key, data, errors, context):
    # Deprecated in favour of ignore_not_package_admin
    return ignore_not_package_admin(key, data, errors, context)

def ignore_not_package_admin(key, data, errors, context):
    '''Ignore if the user is not allowed to administer the package specified.'''

    model = context['model']
    user = context.get('user')

    if 'ignore_auth' in context:
        return

    if user and new_authz.is_sysadmin(user):
        return

    authorized = False
    pkg = context.get('package')
    if pkg:
        try:
            logic.check_access('package_change_state',context)
            authorized = True
        except logic.NotAuthorized:
            authorized = False

    if (user and pkg and authorized):
        return

    # allow_state_change in the context will allow the state to be changed
    # FIXME is this the best way to cjeck for state only?
    if key == ('state',) and context.get('allow_state_change'):
        return
    data.pop(key)


def ignore_not_sysadmin(key, data, errors, context):
    '''Ignore the field if user not sysadmin or ignore_auth in context.'''

    user = context.get('user')
    ignore_auth = context.get('ignore_auth')

    if ignore_auth or (user and new_authz.is_sysadmin(user)):
        return

    data.pop(key)


def ignore_not_group_admin(key, data, errors, context):
    '''Ignore if the user is not allowed to administer for the group specified.'''

    model = context['model']
    user = context.get('user')

    if user and new_authz.is_sysadmin(user):
        return

    authorized = False
    group = context.get('group')
    if group:
        try:
            logic.check_access('group_change_state',context)
            authorized = True
        except logic.NotAuthorized:
            authorized = False

    if (user and group and authorized):
        return

    data.pop(key)

def user_name_validator(key, data, errors, context):
    '''Validate a new user name.

    Append an error message to ``errors[key]`` if a user named ``data[key]``
    already exists. Otherwise, do nothing.

    :raises ckan.lib.navl.dictization_functions.Invalid: if ``data[key]`` is
        not a string
    :rtype: None

    '''
    model = context['model']
    new_user_name = data[key]

    if not isinstance(new_user_name, basestring):
        raise Invalid(_('User names must be strings'))

    user = model.User.get(new_user_name)
    if user is not None:
        # A user with new_user_name already exists in the database.

        user_obj_from_context = context.get('user_obj')
        if user_obj_from_context and user_obj_from_context.id == user.id:
            # If there's a user_obj in context with the same id as the user
            # found in the db, then we must be doing a user_update and not
            # updating the user name, so don't return an error.
            return
        else:
            # Otherwise return an error: there's already another user with that
            # name, so you can create a new user with that name or update an
            # existing user's name to that name.
            errors[key].append(_('That login name is not available.'))

def user_both_passwords_entered(key, data, errors, context):

    password1 = data.get(('password1',),None)
    password2 = data.get(('password2',),None)

    if password1 is None or password1 == '' or \
       password2 is None or password2 == '':
        errors[('password',)].append(_('Please enter both passwords'))

def user_password_validator(key, data, errors, context):
    value = data[key]

    if isinstance(value, Missing):
        pass
    elif not isinstance(value, basestring):
        errors[('password',)].append(_('Passwords must be strings'))
    elif value == '':
        pass
    elif len(value) < 4:
        errors[('password',)].append(_('Your password must be 4 characters or longer'))

def user_passwords_match(key, data, errors, context):

    password1 = data.get(('password1',),None)
    password2 = data.get(('password2',),None)

    if not password1 == password2:
        errors[key].append(_('The passwords you entered do not match'))
    else:
        #Set correct password
        data[('password',)] = password1

def user_password_not_empty(key, data, errors, context):
    '''Only check if password is present if the user is created via action API.
       If not, user_both_passwords_entered will handle the validation'''

    if not ('password1',) in data and not ('password2',) in data:
        password = data.get(('password',),None)
        if not password:
            errors[key].append(_('Missing value'))

def user_about_validator(value,context):
    if 'http://' in value or 'https://' in value:
        raise Invalid(_('Edit not allowed as it looks like spam. Please avoid links in your description.'))

    return value

def vocabulary_name_validator(name, context):
    model = context['model']
    session = context['session']

    if len(name) < VOCABULARY_NAME_MIN_LENGTH:
        raise Invalid(_('Name must be at least %s characters long') %
            VOCABULARY_NAME_MIN_LENGTH)
    if len(name) > VOCABULARY_NAME_MAX_LENGTH:
        raise Invalid(_('Name must be a maximum of %i characters long') %
                      VOCABULARY_NAME_MAX_LENGTH)
    query = session.query(model.Vocabulary.name).filter_by(name=name)
    result = query.first()
    if result:
        raise Invalid(_('That vocabulary name is already in use.'))
    return name

def vocabulary_id_not_changed(value, context):
    vocabulary = context.get('vocabulary')
    if vocabulary and value != vocabulary.id:
        raise Invalid(_('Cannot change value of key from %s to %s. '
                        'This key is read-only') % (vocabulary.id, value))
    return value

def vocabulary_id_exists(value, context):
    model = context['model']
    session = context['session']
    result = session.query(model.Vocabulary).get(value)
    if not result:
        raise Invalid(_('Tag vocabulary was not found.'))
    return value

def tag_in_vocabulary_validator(value, context):
    model = context['model']
    session = context['session']
    vocabulary = context.get('vocabulary')
    if vocabulary:
        query = session.query(model.Tag)\
            .filter(model.Tag.vocabulary_id==vocabulary.id)\
            .filter(model.Tag.name==value)\
            .count()
        if not query:
            raise Invalid(_('Tag %s does not belong to vocabulary %s') % (value, vocabulary.name))
    return value

def tag_not_in_vocabulary(key, tag_dict, errors, context):
    tag_name = tag_dict[('name',)]
    if not tag_name:
        raise Invalid(_('No tag name'))
    if tag_dict.has_key(('vocabulary_id',)):
        vocabulary_id = tag_dict[('vocabulary_id',)]
    else:
        vocabulary_id = None
    model = context['model']
    session = context['session']

    query = session.query(model.Tag)
    query = query.filter(model.Tag.vocabulary_id==vocabulary_id)
    query = query.filter(model.Tag.name==tag_name)
    count = query.count()
    if count > 0:
        raise Invalid(_('Tag %s already belongs to vocabulary %s') %
                (tag_name, vocabulary_id))
    else:
        return

def url_validator(key, data, errors, context):
    ''' Checks that the provided value (if it is present) is a valid URL '''
    import urlparse
    import string

    model = context['model']
    session = context['session']

    url = data.get(key, None)
    if not url:
        return

    pieces = urlparse.urlparse(url)
    if all([pieces.scheme, pieces.netloc]) and \
       set(pieces.netloc) <= set(string.letters + string.digits + '-.') and \
       pieces.scheme in ['http', 'https']:
       return

    errors[key].append(_('Please provide a valid URL'))


def user_name_exists(user_name, context):
    model = context['model']
    session = context['session']
    result = session.query(model.User).filter_by(name=user_name).first()
    if not result:
        raise Invalid('%s: %s' % (_('Not found'), _('User')))
    return result.name


def role_exists(role, context):
    if role not in new_authz.ROLE_PERMISSIONS:
        raise Invalid(_('role does not exist.'))
    return role


def datasets_with_no_organization_cannot_be_private(key, data, errors,
        context):

    dataset_id = data.get(('id',))
    owner_org = data.get(('owner_org',))
    private = data[key] is True

    check_passed = True

    if not dataset_id and private and not owner_org:
        # When creating a dataset, enforce it directly
        check_passed = False
    elif dataset_id and private and not owner_org:
        # Check if the dataset actually has an owner_org, even if not provided
        try:
            dataset_dict = logic.get_action('package_show')({},
                            {'id': dataset_id})
            if not dataset_dict.get('owner_org'):
                check_passed = False

        except logic.NotFound:
            check_passed = False

    if not check_passed:
        errors[key].append(
                _("Datasets with no organization can't be private."))


def list_of_strings(key, data, errors, context):
    value = data.get(key)
    if not isinstance(value, list):
        raise Invalid(_('Not a list'))
    for x in value:
        if not isinstance(x, basestring):
            raise Invalid('%s: %s' % (_('Not a string'), x))

def if_empty_guess_format(key, data, errors, context):
    value = data[key]
    resource_id = data.get(key[:-1] + ('id',))

    # if resource_id then an update
    if (not value or value is Missing) and not resource_id:
        url = data.get(key[:-1] + ('url',), '')
        mimetype, encoding = mimetypes.guess_type(url)
        if mimetype:
            data[key] = mimetype

def clean_format(format):
    return h.unified_resource_format(format)

def no_loops_in_hierarchy(key, data, errors, context):
    '''Checks that the parent groups specified in the data would not cause
    a loop in the group hierarchy, and therefore cause the recursion up/down
    the hierarchy to get into an infinite loop.
    '''
    if not 'id' in data:
        # Must be a new group - has no children, so no chance of loops
        return
    group = context['model'].Group.get(data['id'])
    allowable_parents = group.\
                        groups_allowed_to_be_its_parent(type=group.type)
    for parent in data['groups']:
        parent_name = parent['name']
        # a blank name signifies top level, which is always allowed
        if parent_name and context['model'].Group.get(parent_name) \
                not in allowable_parents:
            raise Invalid(_('This parent would create a loop in the '
                            'hierarchy'))


########NEW FILE########
__FILENAME__ = manage
#!/usr/bin/env python
from migrate.versioning.shell import main

main(repository='ckan/migration')

########NEW FILE########
__FILENAME__ = 001_add_existing_tables
from sqlalchemy import *
from migrate import *


def upgrade(migrate_engine):
    meta = MetaData()

    state = Table('state', meta,
      Column('id', Integer() ,  primary_key=True, nullable=False),
      Column('name', Unicode(100)),
    )

    revision = Table('revision', meta,
      Column('id', Integer() ,  primary_key=True, nullable=False),
      Column('timestamp', DateTime(timezone=False)   ),
      Column('author', Unicode(200)),
      Column('message', UnicodeText()),
      Column('state_id', Integer()   ),
    )

    apikey = Table('apikey', meta,
      Column('id', Integer() ,  primary_key=True, nullable=False),
      Column('name', UnicodeText()),
      Column('key', UnicodeText()),
    )

    license = Table('license', meta,
      Column('id', Integer() ,  primary_key=True, nullable=False),
      Column('name', Unicode(100)),
      # Column('state_id', Integer(), ForeignKey('state.id')),
      Column('state_id', Integer())
    )

    package = Table('package', meta,
      Column('id', Integer() ,  primary_key=True, nullable=False),
      Column('name', Unicode(100) ,  nullable=False, unique=True),
      Column('title', UnicodeText()),
      Column('version', Unicode(100)),
      Column('url', UnicodeText()),
      Column('download_url', UnicodeText()),
      Column('notes', UnicodeText()),
      Column('license_id', Integer(), ForeignKey('license.id') ),
      Column('state_id', Integer(), ForeignKey('state.id') ),
      Column('revision_id', Integer(), ForeignKey('revision.id') ),
    )

    package_revision = Table('package_revision', meta,
      Column('id', Integer(), primary_key=True, nullable=False),
      Column('name', Unicode(100), nullable=False),
      Column('title', UnicodeText()),
      Column('version', Unicode(100)),
      Column('url', UnicodeText()),
      Column('download_url', UnicodeText()),
      Column('notes', UnicodeText()),
      Column('license_id', Integer(), ForeignKey('license.id')  ),
      Column('state_id', Integer(), ForeignKey('state.id')   ),
      Column('revision_id', Integer() , ForeignKey('revision.id'), primary_key=True),
      Column('continuity_id', Integer(), ForeignKey('package.id') ),
    )

    tag = Table('tag', meta,
      Column('id', Integer() ,  primary_key=True, nullable=False),
      Column('name', Unicode(100), nullable=False, unique=True),
    )

    package_tag = Table('package_tag', meta,
      Column('id', Integer() ,  primary_key=True, nullable=False),
      Column('package_id', Integer(), ForeignKey('package.id') ),
      Column('tag_id', Integer(), ForeignKey('tag.id') ),
      Column('state_id', Integer(), ForeignKey('state.id') ),
      Column('revision_id', Integer(), ForeignKey('revision.id')  ),
    )

    package_tag_revision = Table('package_tag_revision', meta,
      Column('id', Integer() ,  primary_key=True, nullable=False),
      Column('package_id', Integer(), ForeignKey('package.id') ),
      Column('tag_id', Integer(), ForeignKey('tag.id') ),
      Column('state_id', Integer(), ForeignKey('state.id') ),
      Column('revision_id', Integer() , ForeignKey('revision.id'), primary_key=True),
      Column('continuity_id', Integer(), ForeignKey('package_tag.id') ),
    )

    package_extra = Table('package_extra', meta,
      Column('id', Integer() ,  primary_key=True, nullable=False),
      Column('package_id', Integer(), ForeignKey('package.id') ),
      Column('key', UnicodeText()),
      Column('value', UnicodeText()),
      Column('state_id', Integer(), ForeignKey('state.id') ),
      Column('revision_id', Integer(), ForeignKey('revision.id')  ),
    )

    package_extra_revision = Table('package_extra_revision', meta,
      Column('id', Integer() ,  primary_key=True, nullable=False),
      Column('package_id', Integer(), ForeignKey('package.id') ),
      Column('key', UnicodeText()),
      Column('value', UnicodeText()),
      Column('state_id', Integer(), ForeignKey('state.id') ),
      Column('revision_id', Integer(), ForeignKey('revision.id'), primary_key=True),
      Column('continuity_id', Integer(), ForeignKey('package_extra.id') ),
    )

    meta.bind = migrate_engine
    meta.create_all()

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 002_add_author_and_maintainer
from sqlalchemy import *
from migrate import *
import migrate.changeset


def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    # Upgrade operations go here. Don't create your own engine; use the engine
    # named 'migrate_engine' imported from migrate.
    package = Table('package', metadata, autoload=True)
    package_revision = Table('package_revision', metadata, autoload=True)

    columns = [Column('author', UnicodeText),
               Column('author_email', UnicodeText),
               Column('maintainer', UnicodeText),
               Column('maintainer_email', UnicodeText),
               ]
    columns2 = [Column('author', UnicodeText),
               Column('author_email', UnicodeText),
               Column('maintainer', UnicodeText),
               Column('maintainer_email', UnicodeText),
               ]

    for col in columns:
        col.create(package)
    for col in columns2:
        col.create(package_revision)

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 003_add_user_object
from sqlalchemy import *
from migrate import *
import uuid


def make_uuid():
    return unicode(uuid.uuid4())


def upgrade(migrate_engine):
    metadata = MetaData()
    user_table = Table('user', metadata,
            Column('id', UnicodeText, primary_key=True, default=make_uuid),
            Column('name', UnicodeText),
            Column('apikey', UnicodeText, default=make_uuid)
            )
    metadata.bind = migrate_engine
    apikey_table = Table('apikey', metadata, autoload=True)

    user_table.create()
    apikey_table.drop()

def downgrade(migrate_engine):
    raise NotImplementedError()


########NEW FILE########
__FILENAME__ = 004_add_group_object
from sqlalchemy import *
from migrate import *
import uuid


def make_uuid():
    return unicode(uuid.uuid4())


def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    # you need to load this for foreign keys to work in package_group_table
    package_table = Table('package', metadata, autoload=True)

    group_table = Table('group', metadata,
            Column('id', UnicodeText, primary_key=True, default=make_uuid),
            Column('name', UnicodeText, unique=True, nullable=False),
            Column('title', UnicodeText),
            Column('description', UnicodeText),
    )

    package_group_table = Table('package_group', metadata,
            Column('id', UnicodeText, primary_key=True, default=make_uuid),
            Column('package_id', Integer, ForeignKey('package.id')),
            Column('group_id', UnicodeText, ForeignKey('group.id')),
            )


    group_table.create()
    package_group_table.create()

def downgrade(migrate_engine):
    raise NotImplementedError()


########NEW FILE########
__FILENAME__ = 005_add_authorization_tables
from sqlalchemy import *
from migrate import *
import uuid


def make_uuid():
    return unicode(uuid.uuid4())

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    # you need to load these two for foreign keys to work 
    package_table = Table('package', metadata, autoload=True)
    group_table = Table('group', metadata, autoload=True)
    user_table = Table('user', metadata, autoload=True)

    # authorization tables
    role_action_table = Table('role_action', metadata,
               Column('id', UnicodeText, primary_key=True, default=make_uuid),
               Column('role', UnicodeText),
               Column('context', UnicodeText, nullable=False),
               Column('action', UnicodeText),
               )

    user_object_role_table = Table('user_object_role', metadata,
               Column('id', UnicodeText, primary_key=True, default=make_uuid),
               Column('user_id', UnicodeText, ForeignKey('user.id')),
               Column('context', UnicodeText, nullable=False),
               Column('role', UnicodeText)
               )

    package_role_table = Table('package_role', metadata,
               Column('user_object_role_id', UnicodeText, ForeignKey('user_object_role.id'), primary_key=True),
               Column('package_id', Integer, ForeignKey('package.id')),
               )

    group_role_table = Table('group_role', metadata,
               Column('user_object_role_id', UnicodeText, ForeignKey('user_object_role.id'), primary_key=True),
               Column('group_id', UnicodeText, ForeignKey('group.id')),
               )
    
    role_action_table.create()
    user_object_role_table.create()
    package_role_table.create()
    group_role_table.create()

    # Not Good to use model here. TODO: refactor this.
    # import ckan.model as model
    # model.repo.init_db()
    # call this explicitly elsewhere
    # model.give_all_packages_default_user_roles()

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 006_add_ratings
from sqlalchemy import *
from migrate import *
import uuid


def make_uuid():
    return unicode(uuid.uuid4())

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    # you need to load these two for foreign keys to work 
    package_table = Table('package', metadata, autoload=True)
    user_table = Table('user', metadata, autoload=True)

    rating_table = Table('rating', metadata,
                         Column('id', UnicodeText, primary_key=True, default=make_uuid),
                         Column('user_id', UnicodeText, ForeignKey('user.id')),
                         Column('user_ip_address', UnicodeText), # alternative to user_id if not logged in
                         Column('package_id', Integer, ForeignKey('package.id')),
                         Column('rating', Float)
                         )

    rating_table.create()

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 007_add_system_roles
from sqlalchemy import *
from migrate import *
import uuid




def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    user_object_role_table = Table('user_object_role', metadata, autoload=True)

    # authorization tables
    system_role_table = Table('system_role', metadata,
               Column('user_object_role_id', UnicodeText, ForeignKey('user_object_role.id'), primary_key=True),
               )
        
    system_role_table.create()

    # you can now add system administrators
    # e.g. paster create-sysadmin http://bgates.openid.com/

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 008_update_vdm_ids
from sqlalchemy import *
import sqlalchemy.schema
import uuid

from migrate import *
import migrate.changeset
from migrate.changeset.constraint import ForeignKeyConstraint, PrimaryKeyConstraint

metadata = None

def make_uuid():
    return unicode(uuid.uuid4())

# 1 drop all foreign key constraints
# 2 alter type of revision id and foreign keys
# 3 create foreign key constraints (using cascade!)
# 4 create uuids for revisions (auto cascades elsewhere!)
def upgrade(migrate_engine):
    global metadata
    metadata = MetaData()
    metadata.bind = migrate_engine
    dropped_fk_constraints = drop_constraints_and_alter_types()
    upgrade2(migrate_engine, dropped_fk_constraints)

def drop_constraints_and_alter_types():
    # 1 drop all foreign key constraints
    dropped_fk_constraints = []
    revision_table = Table('revision', metadata, autoload=True)
    foreign_tables = ['package', 'package_tag', 'package_revision', 'package_tag_revision', 'package_extra', 'package_extra_revision', ]
    for table_name in foreign_tables:
        table = Table(table_name, metadata, autoload=True)
        for constraint in table.constraints.copy():
            if isinstance(constraint, sqlalchemy.schema.ForeignKeyConstraint):
                foreign_key_cols = [key.column for key in constraint.elements]
                fk_col = foreign_key_cols[0]
                if fk_col.table == revision_table:
                    orig_fk = ForeignKeyConstraint(constraint.columns, foreign_key_cols, name=constraint.name, table=table)
                    orig_fk.drop()
                    dropped_fk_constraints.append((constraint.columns, foreign_key_cols, constraint.name, table.name))

    # 2 alter type of revision id and foreign keys
                    id_col = constraint.table.columns[constraint.columns[0]]
                    id_col.alter(type=UnicodeText)

    revision_table = Table('revision', metadata, autoload=True)
    id_col = revision_table.c['id']
    id_col.alter(type=UnicodeText,
                 )

    return dropped_fk_constraints

def upgrade2(migrate_engine, dropped_fk_constraints):
    # have changed type of cols so recreate metadata
    metadata = MetaData(migrate_engine)

    # 3 create foreign key constraints
    for fk_constraint in dropped_fk_constraints:
        # cascade doesn't work
        # see http://code.google.com/p/sqlalchemy-migrate/issues/detail?id=48
        # new_fk = ForeignKeyConstraint(*fk_constraint, onupdate='CASCADE')
        # new_fk = ForeignKeyConstraint(*fk_constraint)
        # new_fk.create()

        # So we create via hand ...
        constraint_columns, foreign_key_cols, constraint_name, table_name = fk_constraint
        oursql = '''ALTER TABLE %(table)s
            ADD CONSTRAINT %(fkeyname)s
            FOREIGN KEY (%(col_name)s)
            REFERENCES revision (id)
            ''' % {'table':table_name, 'fkeyname':constraint_name,
                    'col_name':constraint_columns[0] }
        migrate_engine.execute(oursql)

    # 4 create uuids for revisions and in related tables
    revision_table = Table('revision', metadata, autoload=True)
    from sqlalchemy.sql import select
    for row in migrate_engine.execute(select([revision_table])):
        update = revision_table.update().where(revision_table.c.id==row.id).values(id=make_uuid())
        migrate_engine.execute(update)

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 009_add_creation_timestamps
from datetime import datetime

from sqlalchemy import *
from migrate import *
import migrate.changeset


domain_obj_names = ['rating', 'group', 'user']

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    # Use sql instead of migrate.changeset because user and group are sql
    # reserved words and migrate doesn't quote them.
    for domain_obj_name in domain_obj_names:
        sql = 'ALTER TABLE "%s" ADD created TIMESTAMP WITHOUT TIME ZONE' % domain_obj_name
        migrate_engine.execute(sql)

    now = datetime.now()
    for domain_obj_name in domain_obj_names[::-1]:
        table = Table(domain_obj_name, metadata, autoload=True)
        migrate_engine.execute(table.update(values={table.c.created:now}))

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 010_add_user_about
from sqlalchemy import *
from migrate import *
import migrate.changeset


def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    # Using sql because migrate doesn't quote reserved word 'user'
    user_sql = 'ALTER TABLE "user" ADD about TEXT'
    migrate_engine.execute(user_sql)

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 011_add_package_search_vector
from sqlalchemy import *
from migrate import *
import migrate.changeset


def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    package_table = Table('package', metadata, autoload=True)
    package_search_table = Table('package_search', metadata,
            Column('package_id', Integer, ForeignKey('package.id'), primary_key=True),
            )
    
    package_search_table.create()
    sql = 'ALTER TABLE package_search ADD COLUMN search_vector tsvector'
    migrate_engine.execute(sql)

    # This is not so important now and annoying to read when testing
    #print 'IMPORTANT! Now run:\n  paster create-search-index'

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 012_add_resources
from sqlalchemy import *
from migrate import *
import migrate.changeset
import vdm.sqlalchemy



def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    package_table = Table('package', metadata, autoload=True)
    package_revision_table = Table('package_revision', metadata, autoload=True)
    package_resource_table = Table('package_resource', metadata,
        Column('id', Integer, primary_key=True),
        Column('package_id', Integer, ForeignKey('package.id')),
        Column('url', UnicodeText, nullable=False),
        Column('format', UnicodeText),
        Column('description', UnicodeText),
        Column('position', Integer),
        Column('state_id', Integer),
        Column('revision_id', UnicodeText, ForeignKey('revision.id'))
        )

    package_resource_revision_table = Table('package_resource_revision', metadata,
        Column('id', Integer, primary_key=True),
        Column('package_id', Integer, ForeignKey('package.id')),
        Column('url', UnicodeText, nullable=False),
        Column('format', UnicodeText),
        Column('description', UnicodeText),
        Column('position', Integer),
        Column('state_id', Integer),
        Column('revision_id', UnicodeText, ForeignKey('revision.id'), primary_key=True),
        Column('continuity_id', Integer, ForeignKey('package_resource.id'))
        )

    
    package_resource_table.create()
    package_resource_revision_table.create()
    
    # Move download_urls across to resources
    # NB: strictly we should check each package_revision to check whether
    # download_url changed (and if only change) and then create
    # package_resource_revision for each such revision (and delete every
    # package_revision where only change is download_url)
    # However, we adopt a cruder approach in which we just create 
    engine = migrate_engine
    select_sql = select([package_table])
    for pkg in engine.execute(select_sql):
        download_url = pkg['download_url']
        if download_url:
            # what about revision_id?
            res_values = {'package_id':pkg.id,
                          'url':download_url,
                          'format':u'',
                          'description':u'',
                          'position':0,
                          'state_id':1,
                          'revision_id': pkg.revision_id,
                          }
            insert_sql = package_resource_table.insert(values=res_values)
            engine.execute(insert_sql)
            # get id of just inserted resource
            getid_sql = select([package_resource_table]).where(
                    package_resource_table.c.package_id==pkg.id)
            resource_id = getid_sql.execute().fetchone().id
            # now we need to update revision table ...
            res_rev_values = dict(res_values)
            res_rev_values['continuity_id'] = resource_id
            res_rev_values['id'] = resource_id
            insert_sql = package_resource_revision_table.insert(values=res_rev_values)
            engine.execute(insert_sql)

    package_table.c.download_url.drop()
    package_revision_table.c.download_url.drop()

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 013_add_hash
from sqlalchemy import *
from migrate import *
import migrate.changeset


def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    package_resource = Table('package_resource', metadata, autoload=True)
    column = Column('hash', UnicodeText)
    column.create(package_resource)

def downgrade(migrate_engine):
    raise NotImplementedError()


########NEW FILE########
__FILENAME__ = 014_hash_2
from sqlalchemy import *
from migrate import *
import migrate.changeset


def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    # When adding a column to a revisioned object, need to add it to it's
    # counterpart revision object too. Here is the counter-part for that in
    # 013_add_hash.py
    package_resource_revision = Table('package_resource_revision', metadata, autoload=True)
    column = Column('hash', UnicodeText)
    column.create(package_resource_revision)

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 015_remove_state_object
from sqlalchemy import *
import sqlalchemy.sql as sql

from migrate import *
import migrate.changeset


def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    stateful_tables = [
            'license',
            'package', 'package_revision',
            'package_tag', 'package_tag_revision',
            'package_extra', 'package_extra_revision',
            'package_resource', 'package_resource_revision',
            'revision'
            ]
    for table_name in stateful_tables:
        # print '***** Processing table: %s' % table_name
        table = Table(table_name, metadata, autoload=True)
        column = Column('state', UnicodeText)
        column.create(table)
        for (name,id) in [ ('active',1), ('deleted',2), ('pending',3) ]:
            sqlcmd = '''UPDATE %s SET state = '%s' WHERE state_id = %s''' % (table.name, name, id)
            migrate_engine.execute(sqlcmd)
        stateid = table.c['state_id']
        stateid.drop()
    table = Table('state', metadata, autoload=True)
    table.drop()

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 016_uuids_everywhere
from sqlalchemy import *
import sqlalchemy.schema
import uuid
from sqlalchemy.sql import select

from migrate import *
import migrate.changeset
from migrate.changeset.constraint import ForeignKeyConstraint, PrimaryKeyConstraint

metadata = MetaData()

def make_uuid():
    return unicode(uuid.uuid4())

## Tables and columns changed in the model
##     Versioned:
##        ('package', 'id'),
##        ('package_tag', ('id', 'package_id', 'tag_id')),
##        ('package_extra', ('id', 'package_id')),
##        ('package_resource', ('id', 'package_id')),
##     Versions:  
##        ('package_revision', 'id'),
##        ('package_tag_revision', ('id', 'package_id', 'tag_id')),
##        ('package_extra_revision', ('id', 'package_id')),
##        ('package_resource_revision', ('id', 'package_id')),
##     Non-versioned:
##        ('tag', 'id'),
##        ('rating', 'package_id'),
##        ('package_search', 'package_id'),
##        ('package_role', 'package_id'),
##        ('package_group', 'package_id'),

def upgrade(migrate_engine):
    global metadata
    metadata = MetaData()
    metadata.bind = migrate_engine
    primary_table_name = 'package'
    foreign_tables = ['package_revision',
                      'package_tag', 'package_tag_revision',
                      'package_extra', 'package_extra_revision',
                      'package_resource', 'package_resource_revision',
                      'rating', 'package_search',
                      'package_role', 'package_group']
    revision_table_name = 'package_revision'
    convert_to_uuids(migrate_engine, primary_table_name, foreign_tables, revision_table_name)

    primary_table_name = 'package_resource'
    foreign_tables = ['package_resource_revision']
    revision_table_name = 'package_resource_revision'
    convert_to_uuids(migrate_engine, primary_table_name, foreign_tables, revision_table_name)

    primary_table_name = 'package_tag'
    foreign_tables = ['package_tag_revision']
    revision_table_name = 'package_tag_revision'
    convert_to_uuids(migrate_engine, primary_table_name, foreign_tables, revision_table_name)

    primary_table_name = 'package_extra'
    foreign_tables = ['package_extra_revision']
    revision_table_name = 'package_extra_revision'
    convert_to_uuids(migrate_engine, primary_table_name, foreign_tables, revision_table_name)

    primary_table_name = 'tag'
    foreign_tables = ['package_tag', 'package_tag_revision']
    revision_table_name = None
    convert_to_uuids(migrate_engine, primary_table_name, foreign_tables, revision_table_name)

    drop_sequencies(migrate_engine)

def convert_to_uuids(migrate_engine, primary_table_name, foreign_tables, revision_table_name=None):
    '''Convert an id column in Primary Table to string type UUIDs.
    How it works:
       1 drop all foreign key constraints
       2 alter type of revision id and foreign keys
       3 create foreign key constraints (using cascade!)
       4 create uuids for revisions (auto cascades elsewhere!)

    @param primary_table_name - table containing the primary key id column
    @param foreign_tables - names of tables which have this same key as a
                            foreign key constraint
    @param revision_table_name - if primary_table is versioned, supply the name
          of its related revision table, so that it can be updated at the same
          time.
          '''
    #print('** Processing %s' % primary_table_name)
    #print('*** Dropping fk constraints')
    dropped_fk_constraints = drop_constraints_and_alter_types(primary_table_name, foreign_tables, revision_table_name)
    #print('*** Adding fk constraints (with cascade)')
    add_fk_constraints(migrate_engine, dropped_fk_constraints, primary_table_name)
    #print('*** Creating UUIDs')
    create_uuids(migrate_engine, primary_table_name, revision_table_name)

def drop_constraints_and_alter_types(primary_table_name, foreign_tables, revision_table_name):
    # 1 drop all foreign key constraints
    dropped_fk_constraints = []
    primary_table = Table(primary_table_name, metadata, autoload=True)
    for table_name in foreign_tables:
        table = Table(table_name, metadata, autoload=True)
        for constraint in table.constraints.copy():
            if isinstance(constraint, sqlalchemy.schema.ForeignKeyConstraint):
                foreign_key_cols = [key.column for key in constraint.elements]
                fk_col = foreign_key_cols[0]
                if fk_col.table == primary_table:
                    orig_fk = ForeignKeyConstraint(constraint.columns, foreign_key_cols, name=constraint.name, table=table)
                    orig_fk.drop()
                    dropped_fk_constraints.append((constraint.columns, foreign_key_cols, constraint.name, table.name))
                    #print 'CON', dropped_fk_constraints[-1]

    # 2 alter type of primary table id and foreign keys
                    id_col = constraint.table.columns[constraint.columns[0]]
                    id_col.alter(type=UnicodeText)

    primary_table = Table(primary_table_name, metadata, autoload=True)
    id_col = primary_table.c['id']
    id_col.alter(type=UnicodeText)

    if revision_table_name:
        # Revision table id column type changed as well
        revision_table = Table(revision_table_name, metadata, autoload=True)
        id_col = revision_table.c['id']
        id_col.alter(type=UnicodeText)

    return dropped_fk_constraints

def add_fk_constraints(migrate_engine, dropped_fk_constraints, primary_table_name):
    # 3 create foreign key constraints
    for fk_constraint in dropped_fk_constraints:
        # cascade doesn't work
        # see http://code.google.com/p/sqlalchemy-migrate/issues/detail?id=48
        # new_fk = ForeignKeyConstraint(*fk_constraint, onupdate='CASCADE')
        # new_fk = ForeignKeyConstraint(*fk_constraint)
        # new_fk.create()

        # So we create via hand ...
        constraint_columns, foreign_key_cols, constraint_name, table_name = fk_constraint
        oursql = '''ALTER TABLE %(table)s
            ADD CONSTRAINT %(fkeyname)s
            FOREIGN KEY (%(col_name)s)
            REFERENCES %(primary_table_name)s (id)
            ''' % {'table':table_name, 'fkeyname':constraint_name,
                   'col_name':constraint_columns[0],
                   'primary_table_name':primary_table_name}
        migrate_engine.execute(oursql)

def create_uuids(migrate_engine, primary_table_name, revision_table_name):
    # have changed type of cols so recreate metadata
    metadata = MetaData(migrate_engine)

    # 4 create uuids for primary entities and in related tables
    primary_table = Table(primary_table_name, metadata, autoload=True)
    if revision_table_name:
        revision_table = Table(revision_table_name, metadata, autoload=True)
    # fetchall wouldn't be optimal with really large sets of data but here <20k
    ids = [ res[0] for res in
            migrate_engine.execute(select([primary_table.c.id])).fetchall() ]
    for count,id in enumerate(ids):
        # if count % 100 == 0: print(count, id)
        myuuid = make_uuid()
        update = primary_table.update().where(primary_table.c.id==id).values(id=myuuid)
        migrate_engine.execute(update)
    if revision_table_name:
        # ensure each id in revision table match its continuity id.
        q = revision_table.update().values(id=revision_table.c.continuity_id)
        migrate_engine.execute(q)

def drop_sequencies(migrate_engine):

    sequencies = ['package_extra', 'package_extra_revision', 'package',
                  'package_resource', 'package_resource_revision',
                  'package_revision',' package_tag', 'package_tag_revision',
                  'revision', 'tag']


    for sequence in sequencies:
        migrate_engine.execute('ALTER TABLE %s ALTER COLUMN id DROP DEFAULT;' % sequence)

    for sequence in sequencies:
        migrate_engine.execute('drop sequence %s_id_seq;' % sequence)


            
def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 017_add_pkg_relationships
from sqlalchemy import *
from migrate import *
import uuid


def make_uuid():
    return unicode(uuid.uuid4())


def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    package_table = Table('package', metadata, autoload=True)

    package_relationship_table = Table('package_relationship', metadata,
         Column('id', UnicodeText, primary_key=True, default=make_uuid),
         Column('subject_package_id', UnicodeText, ForeignKey('package.id')),
         Column('object_package_id', UnicodeText, ForeignKey('package.id')),
         Column('type', UnicodeText),
         Column('comment', UnicodeText),
         Column('revision_id', UnicodeText, ForeignKey('revision.id'))
         )

    package_relationship_revision_table = Table('package_relationship_revision', metadata,
         Column('id', UnicodeText, primary_key=True, default=make_uuid),
         Column('subject_package_id', UnicodeText, ForeignKey('package.id')),
         Column('object_package_id', UnicodeText, ForeignKey('package.id')),
         Column('type', UnicodeText),
         Column('comment', UnicodeText),
         Column('revision_id', UnicodeText, ForeignKey('revision.id'), primary_key=True),
         Column('continuity_id', UnicodeText, ForeignKey('package_relationship.id'))
        )
    
    package_relationship_table.create()
    package_relationship_revision_table.create()

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 018_adjust_licenses
from sqlalchemy import *
from migrate import *
import uuid


map = {
    u'OSI Approved::Mozilla Public License 1.1 (MPL)': 'mozilla1.1', 
    u'OKD Compliant::Creative Commons Attribution-ShareAlike': 'cc-by-sa', 
    u'OSI Approved::Nokia Open Source License': 'nokia', 
    u'OSI Approved::Computer Associates Trusted Open Source License 1.1': 'ca-tosl1.1', 
    u'OKD Compliant::Higher Education Statistics Agency Copyright with data.gov.uk rights': 'hesa-withrights', 
    u'OSI Approved::Lucent Public License Version 1.02': 'lucent1.02', 
    u'OSI Approved::Open Software License': 'osl-3.0', 
    u'OSI Approved::Motosoto License': 'motosoto', 
    u'OSI Approved::MIT license': 'mit-license', 
    u'OSI Approved::Mozilla Public License 1.0 (MPL)': 'mozilla', 
    u'OSI Approved::GNU General Public License v3 (GPLv3)': 'gpl-3.0', 
    u'OKD Compliant::UK Click Use PSI': 'ukclickusepsi', 
    u'OSI Approved::Eiffel Forum License': 'eiffel', 
    u'OSI Approved::Jabber Open Source License': 'jabber-osl', 
    u'OSI Approved::Open Group Test Suite License': 'opengroup', 
    u'OSI Approved::Entessa Public License': 'entessa', 
    u'OKD Compliant::Other': 'other-open', 
    u'OSI Approved::EU DataGrid Software License': 'eudatagrid', 
    u'OSI Approved::Zope Public License': 'zpl', 
    u'OSI Approved::Naumen Public License': 'naumen', 
    u'OSI Approved::wxWindows Library License': 'wxwindows', 
    u'OKD Compliant::GNU Free Documentation License (GFDL)': 'gfdl', 
    u'Non-OKD Compliant::Non-Commercial Other': 'other-nc', 
    u'OKD Compliant::Open Data Commons Public Domain Dedication and License (PDDL)': 'odc-pddl', 
    u'OSI Approved::NASA Open Source Agreement 1.3': 'nasa1.3', 
    u'OSI Approved::X.Net License': 'xnet', 
    u'OSI Approved::W3C License': 'W3C', 
    u'OSI Approved::Academic Free License': 'afl-3.0', 
    u'Non-OKD Compliant::Crown Copyright': 'ukcrown', 
    u'OSI Approved::RealNetworks Public Source License V1.0': 'real', 
    u'OSI Approved::Common Development and Distribution License': 'cddl1', 
    u'OSI Approved::Intel Open Source License': 'intel-osl', 
    u'OSI Approved::GNU General Public License (GPL)': 'gpl-2.0', 
    u'Non-OKD Compliant::Creative Commons Non-Commercial (Any)': 'cc-nc', 
    u'Non-OKD Compliant::Other': 'other-closed', 
    u'Other::License Not Specified': 'notspecified', 
    u'OSI Approved::Sybase Open Watcom Public License 1.0': 'sybase', 
    u'OSI Approved::Educational Community License': 'ecl2', 
    u'OSI Approved::Sun Industry Standards Source License (SISSL)': 'sun-issl', 
    u'OKD Compliant::Other (Public Domain)': 'other-pd', 
    u'OKD Compliant::Public Domain': 'other-pd', 
    u'OKD Compliant::Creative Commons Attribution': 'cc-by', 
    u'OSI Approved::OCLC Research Public License 2.0': 'oclc2', 
    u'OSI Approved::Artistic license': 'artistic-license-2.0', 
    u'OKD Compliant::Other (Attribution)': 'other-at', 
    u'OSI Approved::Sleepycat License': 'sleepycat', 
    u'OSI Approved::PHP License': 'php', 
    u'OKD Compliant::Creative Commons CCZero': 'cc-zero', 
    u'OSI Approved::University of Illinois/NCSA Open Source License': 'UoI-NCSA', 
    u'OSI Approved::Adaptive Public License': 'apl1.0', 
    u'OSI Approved::Ricoh Source Code Public License': 'ricohpl', 
    u'OSI Approved::Eiffel Forum License V2.0': 'ver2_eiffel', 
    u'OSI Approved::Python license (CNRI Python License)': 'pythonpl', 
    u'OSI Approved::Frameworx License': 'frameworx', 
    u'OSI Approved::IBM Public License': 'ibmpl', 
    u'OSI Approved::Fair License': 'fair', 
    u'OSI Approved::Lucent Public License (Plan9)': 'lucent-plan9', 
    u'OSI Approved::Nethack General Public License': 'nethack', 
    u'OSI Approved::Common Public License 1.0': 'cpal_1.0', 
    u'OSI Approved::Attribution Assurance Licenses': 'attribution', 
    u'OSI Approved::Reciprocal Public License': 'rpl1.5', 
    u'OSI Approved::Eclipse Public License': 'eclipse-1.0', 
    u'OSI Approved::CUA Office Public License Version 1.0': 'cuaoffice', 
    u'OSI Approved::Vovida Software License v. 1.0': 'vovidapl', 
    u'OSI Approved::Apple Public Source License': 'apsl-2.0', 
    u'OKD Compliant::UK Crown Copyright with data.gov.uk rights': 'ukcrown-withrights', 
    u'OKD Compliant::Local Authority Copyright with data.gov.uk rights': 'localauth-withrights', 
    u'OKD Compliant::Open Data Commons Open Database License (ODbL)': 'odc-odbl', 
    u'OSI Approved::New BSD license': 'bsd-license', 
    u'OSI Approved::Qt Public License (QPL)': 'qtpl', 
    u'OSI Approved::GNU Library or "Lesser" General Public License (LGPL)': 'lgpl-2.1', 
    u'OSI Approved::MITRE Collaborative Virtual Workspace License (CVW License)': 'mitre', 
    u'OSI Approved::Apache License, 2.0': 'apache2.0', 
    u'OSI Approved::Apache Software License': 'apache', 
    u'OSI Approved::Python Software Foundation License': 'PythonSoftFoundation', 
    u'OSI Approved::Sun Public License': 'sunpublic', 
    u'OSI Approved::zlib/libpng license': 'zlib-license'
}

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    #print "Changing package license_ids to strings."

    # Get licenses, package license ids, and package revision license ids.
    old_license_titles = _get_old_license_titles(migrate_engine)
    old_package_license_ids = _get_old_package_license_ids(migrate_engine)
    old_package_revision_license_ids = _get_old_package_revision_license_ids(migrate_engine)
    _check_map_has_old_license_titles(old_license_titles, map)
    
    # Upgrade database scheme.
    drop_fk_constraint_on_package_table = "ALTER TABLE package DROP CONSTRAINT package_license_id_fkey;"
    drop_fk_constraint_on_package_revision_table = "ALTER TABLE package_revision DROP CONSTRAINT package_revision_license_id_fkey;"
    change_license_id_type_on_package_table = "ALTER TABLE package ALTER COLUMN license_id TYPE text;"
    change_license_id_type_on_package_revision_table = "ALTER TABLE package_revision ALTER COLUMN license_id TYPE text;"
    drop_licenses_table = "DROP TABLE license CASCADE;"
    
    migrate_engine.execute(drop_fk_constraint_on_package_table)
    migrate_engine.execute(drop_fk_constraint_on_package_revision_table)
    migrate_engine.execute(change_license_id_type_on_package_table)
    migrate_engine.execute(change_license_id_type_on_package_revision_table)
    migrate_engine.execute(drop_licenses_table)

    # Set package license ids, and package revision license ids.    
    new_package_license_ids = _switch_package_license_ids(
            old_package_license_ids, old_license_titles, map)
    new_package_revision_license_ids = _switch_package_license_ids(
            old_package_revision_license_ids, old_license_titles, map)
    _set_new_package_license_ids(migrate_engine, new_package_license_ids)
    _set_new_package_revision_license_ids(migrate_engine, new_package_revision_license_ids)

def downgrade(migrate_engine):
    raise NotImplementedError()

def _check_map_has_old_license_titles(old_license_titles, map):
    for title in old_license_titles.values():
        if title not in map:
            raise Exception, "The old license title '%s' wasn't found in the upgrade map. Decide which new license id should be substituted for this license and add an entry to the map (in ckan/migration/versions/018_adjust_licenses.py)." % title

def _get_old_license_titles(migrate_engine):
    "Returns a dict of old license titles, keyed by old license id."
    titles = {}
    select_licenses = "SELECT id, name FROM license;"
    q = migrate_engine.execute(select_licenses)
    for id, title in q:
        titles[id] = title
    return titles

def _get_old_package_license_ids(migrate_engine):
    "Returns a dict of old license ids, keyed by package id."
    old_ids = {}
    select_licenses = "SELECT id, license_id FROM package;"
    q = migrate_engine.execute(select_licenses)
    for id, license_id in q:
        old_ids[id] = license_id
    return old_ids

def _get_old_package_revision_license_ids(migrate_engine):
    "Returns a dict of old license ids, keyed by package_revision id."
    old_ids = {}
    select_licenses = "SELECT id, license_id FROM package_revision;"
    q = migrate_engine.execute(select_licenses)
    for id, license_id in q:
        old_ids[id] = license_id
    return old_ids

def _switch_package_license_ids(old_ids, old_license_titles, map):
    "Returns a dict of new license ids, keyed by package id."
    new_ids = {}
    for (package_id, old_license_id) in old_ids.items():
        if old_license_id != None:
            old_license_title = old_license_titles[old_license_id]
            new_license_id = map[old_license_title]
            new_ids[package_id] = new_license_id
            print "Switched license_id %s to %s" % (old_license_id, new_license_id)
    return new_ids

def _set_new_package_license_ids(migrate_engine, new_ids):
    for (package_id, license_id) in new_ids.items():
        _set_package_license_id(migrate_engine, package_id, license_id)

def _set_package_license_id(migrate_engine, package_id, license_id):
    set_package_license_id = """UPDATE package SET license_id ='%s' where id = '%s';""" % (license_id, package_id)
    migrate_engine.execute(set_package_license_id)

def _set_new_package_revision_license_ids(migrate_engine, new_ids):
    for (package_id, license_id) in new_ids.items():
        _set_package_revision_license_id(migrate_engine, package_id, license_id)

def _set_package_revision_license_id(migrate_engine, package_id, license_id):
    set_package_license_id = """UPDATE package_revision SET license_id ='%s' where id = '%s';""" % (license_id, package_id)
    migrate_engine.execute(set_package_license_id)



########NEW FILE########
__FILENAME__ = 019_pkg_relationships_state
from sqlalchemy import *
from migrate import *
import migrate.changeset


def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    package_relationship_table = Table('package_relationship',
                                       metadata, autoload=True)
    package_relationship_revision_table = Table('package_relationship_revision',
                                                metadata, autoload=True)

    state_column = Column('state', UnicodeText)
    state_column.create(package_relationship_table)
    state_column = Column('state', UnicodeText)
    state_column.create(package_relationship_revision_table)
    # No package relationship objects exist to migrate, so no
    # need to populate state column

def downgrade(migrate_engine):
    raise NotImplementedError()
    

########NEW FILE########
__FILENAME__ = 020_add_changeset
from sqlalchemy import *
from migrate import *
import datetime
from migrate.changeset.constraint import PrimaryKeyConstraint



def upgrade(migrate_engine):
    metadata = MetaData()

    revision_table = Table('revision', metadata,
            Column('id', UnicodeText, primary_key=True),
    )

    changeset_table = Table('changeset', metadata,
            Column('id', UnicodeText, primary_key=True),
            Column('closes_id', UnicodeText, nullable=True),
            Column('follows_id', UnicodeText, nullable=True),
            Column('meta', UnicodeText, nullable=True),
            Column('branch', UnicodeText, nullable=True),
            Column('timestamp', DateTime, default=datetime.datetime.utcnow),
            Column('is_working', Boolean, default=False),
            Column('revision_id', UnicodeText, ForeignKey('revision.id'), nullable=True),
            Column('added_here', DateTime, default=datetime.datetime.utcnow),
    )

    change_table = Table('change', metadata,
            Column('ref', UnicodeText, nullable=True),
            Column('diff', UnicodeText, nullable=True),
            Column('changeset_id', UnicodeText, ForeignKey('changeset.id')),
    )

    changemask_table = Table('changemask', metadata,
            Column('ref', UnicodeText, primary_key=True),
            Column('timestamp', DateTime, default=datetime.datetime.utcnow),
    )
    metadata.bind = migrate_engine
    changeset_table.create()
    change_table.create()
    changemask_table.create()

def downgrade(migrate_engine):
    change_table.drop()
    changeset_table.drop()


########NEW FILE########
__FILENAME__ = 022_add_group_extras
from sqlalchemy import *
from migrate import *
import migrate.changeset
import vdm.sqlalchemy
import uuid
from sqlalchemy import types

from ckan.common import json

class JsonType(types.TypeDecorator):
    '''Store data as JSON serializing on save and unserializing on use.
    '''
    impl = types.UnicodeText

    def process_bind_param(self, value, engine):
        if value is None or value == {}: # ensure we stores nulls in db not json "null"
            return None
        else:
            # ensure_ascii=False => allow unicode but still need to convert
            return unicode(json.dumps(value, ensure_ascii=False))

    def process_result_value(self, value, engine):
        if value is None:
            return None
        else:
            return json.loads(value)

    def copy(self):
        return JsonType(self.impl.length)

def make_uuid():
    return unicode(uuid.uuid4())



def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    group_table = Table('group', metadata, autoload=True)
    group_extra_table = Table('group_extra', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('group_id', UnicodeText, ForeignKey('group.id')),
        Column('key', UnicodeText),
        Column('value', JsonType),
    )
    
    group_extra_table.create()

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 023_add_harvesting
from sqlalchemy import *
from migrate import *
import datetime
import uuid
from migrate.changeset.constraint import PrimaryKeyConstraint


def make_uuid():
    return unicode(uuid.uuid4())

def upgrade(migrate_engine):
    metadata = MetaData()
    harvest_source_table = Table('harvest_source', metadata,
            Column('id', UnicodeText, primary_key=True, default=make_uuid),
            Column('status', UnicodeText, default=u'New'),
            Column('url', UnicodeText, unique=True, nullable=False),
            Column('description', UnicodeText, default=u''),                      
            Column('user_ref', UnicodeText, default=u''),
            Column('publisher_ref', UnicodeText, default=u''),
            Column('created', DateTime, default=datetime.datetime.utcnow),
    )

    harvesting_job_table = Table('harvesting_job', metadata,
            Column('id', UnicodeText, primary_key=True, default=make_uuid),
            Column('status', UnicodeText, default=u'', nullable=False),
            Column('created', DateTime, default=datetime.datetime.utcnow),
            Column('user_ref', UnicodeText, nullable=False),
            Column('report', UnicodeText, default=u''),                     
            Column('source_id', UnicodeText, ForeignKey('harvest_source.id')), 
    )

    metadata.bind = migrate_engine
    harvest_source_table.create()
    harvesting_job_table.create()

def downgrade(migrate_engine):
    metadata.bind = migrate_engine
    harvesting_job_table.drop()
    harvest_source_table.drop()


########NEW FILE########
__FILENAME__ = 024_add_harvested_document
from sqlalchemy import *
from migrate import *
import datetime


def upgrade(migrate_engine):
    metadata = MetaData()
    harvested_document_table = Table('harvested_document', metadata,
            Column('id', UnicodeText, primary_key=True),
            Column('created', DateTime),
            Column('url', UnicodeText, nullable=False),
            Column('content', UnicodeText, nullable=False),
    )
    metadata.bind = migrate_engine
    harvested_document_table.create()

def downgrade(migrate_engine):
    metadata.bind = migrate_engine
    harvested_document_table.drop()


########NEW FILE########
__FILENAME__ = 025_add_authorization_groups
from sqlalchemy import *
from migrate import *
from datetime import datetime
import migrate.changeset
import vdm.sqlalchemy
import uuid
from sqlalchemy import types

def make_uuid():
    return unicode(uuid.uuid4())



def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    user_table = Table('user', metadata, autoload=True)

    authorization_group_table = Table('authorization_group', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('name', UnicodeText),
        Column('created', DateTime, default=datetime.now),
        )

    authorization_group_user_table = Table('authorization_group_user', metadata,
        Column('authorization_group_id', UnicodeText, ForeignKey('authorization_group.id'), nullable=False),
        Column('user_id', UnicodeText, ForeignKey('user.id'), nullable=False)
        )

    # make user nullable:
    user_object_role_table = Table('user_object_role', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('user_id', UnicodeText, ForeignKey('user.id'), nullable=True),
        Column('context', UnicodeText, nullable=False),
        Column('role', UnicodeText)
        )

    authorization_group_role_table = Table('authorization_group_role', metadata,
        Column('user_object_role_id', UnicodeText, ForeignKey('user_object_role.id'), primary_key=True),
        Column('authorization_group_id', UnicodeText, ForeignKey('authorization_group.id')),
        )

    authorization_group_table.create()
    authorization_group_user_table.create()
    authorization_group_role_table.create()
    authorization_group_id = Column('authorized_group_id', UnicodeText,
                                    ForeignKey('authorization_group.id'), nullable=True)
    authorization_group_id.create(user_object_role_table)

def downgrade(migrate_engine):
    raise NotImplementedError()





########NEW FILE########
__FILENAME__ = 026_authorization_group_user_pk
from sqlalchemy import *
from migrate import *
from datetime import datetime
import migrate.changeset
import vdm.sqlalchemy
import uuid
from sqlalchemy import types

def make_uuid():
    return unicode(uuid.uuid4())

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    user_table = Table('user', metadata, autoload=True)

    authorization_group_table = Table('authorization_group', metadata, autoload=True)

    authorization_group_role_table = Table('authorization_group_role', metadata,
        Column('user_object_role_id', UnicodeText, ForeignKey('user_object_role.id'), primary_key=True),
        Column('authorization_group_id', UnicodeText, ForeignKey('authorization_group.id')),
        )
##    id = Column('id', UnicodeText, primary_key=True, default=make_uuid)
##    id.create(table=authorization_group_role_table,
##              primary_key_name='blum'
###              unique_name='id'
##              )
    
def downgrade(migrate_engine):
    raise NotImplementedError()





########NEW FILE########
__FILENAME__ = 027_adjust_harvester
import warnings

from sqlalchemy import exc as sa_exc
from sqlalchemy import *
from migrate import *
import migrate.changeset

def upgrade(migrate_engine):
    # ignore reflection warnings
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=sa_exc.SAWarning)
        metadata = MetaData()
        metadata.bind = migrate_engine

        harvest_source_table = Table('harvest_source', metadata, autoload=True)
        package_table = Table('package', metadata, autoload=True)

        harvested_document_table = Table('harvested_document', metadata,
            Column('url', UnicodeText, nullable=False),
            Column('guid', UnicodeText, default=u''),
            Column('source_id', UnicodeText, ForeignKey('harvest_source.id')),
            Column('package_id', UnicodeText, ForeignKey('package.id')),
        )

        harvested_document_table.c.url.drop()
        harvested_document_table.c.guid.create(harvested_document_table)
        harvested_document_table.c.source_id.create(harvested_document_table)
        harvested_document_table.c.package_id.create(harvested_document_table)

def downgrade(migrate_engine):
    raise NotImplementedError()


########NEW FILE########
__FILENAME__ = 028_drop_harvest_source_status
from sqlalchemy import *
from migrate import *
import migrate.changeset

    
def upgrade(migrate_engine):
    metadata = MetaData()
    harvested_source_table = Table('harvest_source', metadata,
        Column('status', UnicodeText, nullable=False),
        )
    metadata.bind = migrate_engine
    harvested_source_table.c.status.drop()

def downgrade():
    raise NotImplementedError()


########NEW FILE########
__FILENAME__ = 029_version_groups
import uuid

from sqlalchemy import *
from sqlalchemy import types
from migrate import *
from datetime import datetime
import migrate.changeset
from migrate.changeset.constraint import ForeignKeyConstraint

from ckan.common import json

class JsonType(types.TypeDecorator):
    '''Store data as JSON serializing on save and unserializing on use.
    '''
    impl = types.UnicodeText

    def process_bind_param(self, value, engine):
        if value is None or value == {}: # ensure we stores nulls in db not json "null"
            return None
        else:
            # ensure_ascii=False => allow unicode but still need to convert
            return unicode(json.dumps(value, ensure_ascii=False))

    def process_result_value(self, value, engine):
        if value is None:
            return None
        else:
            return json.loads(value)

    def copy(self):
        return JsonType(self.impl.length)

def make_uuid():
    return unicode(uuid.uuid4())



def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine

    group_table = Table('group', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('name', UnicodeText, unique=True, nullable=False),
        Column('title', UnicodeText),
        Column('description', UnicodeText),
        Column('created', DateTime, default=datetime.now),
        )

    group_revision_table = Table('group_revision', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('name', UnicodeText, nullable=False),
        Column('title', UnicodeText),
        Column('description', UnicodeText),
        Column('created', DateTime, default=datetime.now),
        Column('state', UnicodeText),
        Column('revision_id', UnicodeText, ForeignKey('revision.id'), primary_key=True),
        Column('continuity_id', UnicodeText, ForeignKey('group.id'))
        )

    package_group_table = Table('package_group', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('package_id', UnicodeText, ForeignKey('package.id')),
        Column('group_id', UnicodeText, ForeignKey('group.id')),
        )

    package_group_revision_table = Table('package_group_revision', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('package_id', UnicodeText, ForeignKey('package.id')),
        Column('group_id', UnicodeText, ForeignKey('group.id')),
        Column('state', UnicodeText),
        Column('revision_id', UnicodeText, ForeignKey('revision.id'), primary_key=True),
        Column('continuity_id', UnicodeText, ForeignKey('package_group.id'))
        )

    group_extra_table = Table('group_extra', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('group_id', UnicodeText, ForeignKey('group.id')),
        Column('key', UnicodeText),
        Column('value', JsonType),
        )
        
    group_extra_revision_table = Table('group_extra_revision', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('group_id', UnicodeText, ForeignKey('group.id')),
        Column('key', UnicodeText),
        Column('value', JsonType),
        Column('state', UnicodeText),
        Column('revision_id', UnicodeText, ForeignKey('revision.id'), primary_key=True),
        Column('continuity_id', UnicodeText, ForeignKey('group_extra.id'))
        )

    revision_table = Table('revision', metadata, autoload=True)
    package_table = Table('package', metadata, autoload=True)

    rev_id = make_uuid()
    q = revision_table.insert(values={'id': rev_id, 
                                      'author': u'system',
                                      'message': u"Add versioning to groups, group_extras and package_groups",
                                      'timestamp': datetime.utcnow(),
                                      'state': u'active'})
    r = migrate_engine.execute(q)
    
    # handle groups: 
    
    # BUG in sqlalchemy-migrate 0.4/0.5.4: "group" isn't escaped properly when sent to 
    # postgres. 
    # cf http://code.google.com/p/sqlalchemy-migrate/issues/detail?id=32
    
    #state = Column('state', UnicodeText)
    #revision_id = Column('revision_id', UnicodeText)
    #state.create(group_table)
    #revision_id.create(group_table)
    migrate_engine.execute('ALTER TABLE "group" ADD COLUMN state TEXT')
    migrate_engine.execute('ALTER TABLE "group" ADD COLUMN revision_id TEXT')
    #q = group_table.update(values={'state': 'active',
    #                               'revision_id': rev_id})
    #migrate_engine.execute(q)
    migrate_engine.execute('UPDATE "group" SET revision_id = \'%s\', state=\'active\'' % rev_id)
    #fk = ForeignKeyConstraint(['revision_id'], [revision_table.c.id], table=group_table)
    #fk.create(migrate_engine)
    migrate_engine.execute('ALTER TABLE "group" ADD CONSTRAINT "group_revision_id_fkey" ' + \
            'FOREIGN KEY (revision_id) REFERENCES revision(id)')
    
    group_revision_table.create()
    for row in migrate_engine.execute(group_table.select()):
        group_rev = dict(row.items())
        group_rev['continuity_id'] = group_rev['id']
        
        # otherwise, this doesn't get mapped due to the bug above:
        group_rev['state'] = u'active'
        group_rev['revision_id'] = rev_id
        
        q = group_revision_table.insert(values=group_rev)
        migrate_engine.execute(q)
    
    
    state = Column('state', UnicodeText)
    revision_id = Column('revision_id', UnicodeText)
    state.create(package_group_table)
    revision_id.create(package_group_table)
    q = package_group_table.update(values={'state': u'active',
                                           'revision_id': rev_id})
    migrate_engine.execute(q)
    fk = ForeignKeyConstraint(['revision_id'], [revision_table.c.id], table=package_group_table, name = 'package_group_revision_id_fkey')
    fk.create(migrate_engine)
    package_group_revision_table.create()
    for row in migrate_engine.execute(package_group_table.select()):
        pkg_group_rev = dict(row.items())
        pkg_group_rev['continuity_id'] = pkg_group_rev['id']
        q = package_group_revision_table.insert(values=pkg_group_rev)
        migrate_engine.execute(q)
    
    state = Column('state', UnicodeText)
    revision_id = Column('revision_id', UnicodeText)
    state.create(group_extra_table)
    revision_id.create(group_extra_table)
    q = group_extra_table.update(values={'state': u'active',
                                         'revision_id': rev_id})
    migrate_engine.execute(q)
    fk = ForeignKeyConstraint(['revision_id'], [revision_table.c.id], table=group_extra_table, name='group_extra_revision_id_fkey')
    fk.create(migrate_engine)
    group_extra_revision_table.create()
    for row in migrate_engine.execute(group_extra_table.select()):
        group_extra_rev = dict(row.items())
        group_extra_rev['continuity_id'] = group_rev['id']
        q = group_extra_revision_table.insert(values=group_extra_rev)
        migrate_engine.execute(q)


def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 030_additional_user_attributes
from sqlalchemy import *
from sqlalchemy import types
from migrate import *
from datetime import datetime
import migrate.changeset
import uuid

    
def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    user_sql = 'ALTER TABLE "user" ADD openid TEXT'
    migrate_engine.execute(user_sql)
    user_sql = 'ALTER TABLE "user" ADD password TEXT'
    migrate_engine.execute(user_sql)
    user_sql = 'ALTER TABLE "user" ADD fullname TEXT'
    migrate_engine.execute(user_sql)
    user_sql = 'ALTER TABLE "user" ADD email TEXT'
    migrate_engine.execute(user_sql)
    
def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 031_move_openid_to_new_field
from sqlalchemy import *
from sqlalchemy import types
from migrate import *
from datetime import datetime
import migrate.changeset
import uuid


def make_uuid():
    return unicode(uuid.uuid4())

    
def upgrade(migrate_engine):
    metadata = MetaData()
    user_table = Table('user', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('name', UnicodeText),
        Column('openid', UnicodeText),
        Column('password', UnicodeText),
        Column('fullname', UnicodeText),
        Column('email', UnicodeText),
        Column('apikey', UnicodeText, default=make_uuid),
        Column('created', DateTime, default=datetime.now),
        Column('about', UnicodeText),
        )
    metadata.bind = migrate_engine
    for row in migrate_engine.execute(user_table.select()):
        user = dict(row.items())
        name = user.get('name').lower().strip()
        if name.startswith('http://') or name.startswith('https://'):
            user['openid'] = name
        q = user_table.update(user_table.c.id==user.get('id'), 
                              values=user)
        migrate_engine.execute(q)
    
def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 032_add_extra_info_field_to_resources
from sqlalchemy import *
from sqlalchemy import types
from migrate import *
from datetime import datetime
import migrate.changeset
import uuid

    
def upgrade(migrate_engine):
    metadata = MetaData(migrate_engine)
    user_sql = 'ALTER TABLE package_resource ADD COLUMN extras text'
    migrate_engine.execute(user_sql)
    user_sql = 'ALTER TABLE package_resource_revision ADD COLUMN extras text'
    migrate_engine.execute(user_sql)

def downgrade():
    raise NotImplementedError()


########NEW FILE########
__FILENAME__ = 033_auth_group_user_id_add_conditional
from sqlalchemy import *
from migrate import *
import datetime
import uuid
from migrate.changeset.constraint import PrimaryKeyConstraint


def make_uuid():
    return unicode(uuid.uuid4())

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    authorization_group_user_table = Table('authorization_group_user',
                                           metadata, autoload=True)

    try:
        ##check if id column already exists
        authorization_group_user_table.c["id"]
        return
    except KeyError:
        pass


    id_col = Column('id', UnicodeText, primary_key=True, default=make_uuid)
    id_col.create(authorization_group_user_table,
                  primary_key_name='authorization_group_user_pkey')

def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 034_resource_group_table
from sqlalchemy import *
from migrate import *
import datetime
import uuid
import migrate.changeset
from migrate.changeset.constraint import PrimaryKeyConstraint
from ckan.model.types import JsonDictType

def make_uuid():
    return unicode(uuid.uuid4())

def upgrade(migrate_engine):

    metadata = MetaData(migrate_engine)

    package = Table('package', metadata, autoload=True)

    resource = Table(
        'package_resource', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('package_id', UnicodeText, ForeignKey('package.id')),
        Column('url', UnicodeText, nullable=False),
        Column('format', UnicodeText),
        Column('description', UnicodeText),
        Column('hash', UnicodeText),
        Column('position', Integer),
        Column('extras', JsonDictType),
        Column('state', UnicodeText),
        Column('revision_id', UnicodeText, ForeignKey('revision.id'), primary_key=True),
        )

    resource_revision = Table(
        'package_resource_revision', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('package_id', UnicodeText),
        Column('url', UnicodeText, nullable=False),
        Column('format', UnicodeText),
        Column('description', UnicodeText),
        Column('hash', UnicodeText),
        Column('position', Integer),
        Column('extras', JsonDictType),
        Column('state', UnicodeText),
        Column('revision_id', UnicodeText, ForeignKey('revision.id'), primary_key=True),
        Column('continuity_id', UnicodeText, ForeignKey('package_resource.id'))
        )

    resource_group = Table(
        'resource_group', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('package_id', UnicodeText, ForeignKey('package.id')),
        Column('label', UnicodeText),
        Column('sort_order', UnicodeText),
        Column('extras', JsonDictType),
        Column('state', UnicodeText),
        Column('revision_id', UnicodeText, ForeignKey('revision.id')),
        )

    resource_group_revision = Table(
        'resource_group_revision', metadata,
        Column('id', UnicodeText, primary_key=True, default=make_uuid),
        Column('package_id', UnicodeText, ForeignKey('package.id')),
        Column('label', UnicodeText),
        Column('sort_order', UnicodeText),
        Column('extras', JsonDictType),
        Column('state', UnicodeText),
        Column('revision_id', UnicodeText, ForeignKey('revision.id'), primary_key=True),
        Column('continuity_id', UnicodeText, ForeignKey('resource_group.id'))
        )
    
    resource_count = migrate_engine.execute('''select count(*) from package_resource''').first()[0]
    package_count = migrate_engine.execute('''select count(*) from package''').first()[0]


    # change field names
    resource.c.package_id.alter(name = 'resource_group_id')
    resource_revision.c.package_id.alter(name = 'resource_group_id')

    # rename tables
    resource.rename('resource')
    resource_revision.rename('resource_revision')

    # make new tables
    metadata.create_all(migrate_engine)

    # drop all constaints
    migrate_engine.execute('''
ALTER TABLE resource_revision
	DROP CONSTRAINT package_resource_revision_pkey;

ALTER TABLE resource
	DROP CONSTRAINT package_resource_revision_id_fkey;

ALTER TABLE resource_revision
	DROP CONSTRAINT package_resource_revision_continuity_id_fkey;

ALTER TABLE resource_revision
	DROP CONSTRAINT package_resource_revision_package_id_fkey;

ALTER TABLE resource_revision
	DROP CONSTRAINT package_resource_revision_revision_id_fkey;

ALTER TABLE resource
	DROP CONSTRAINT package_resource_pkey;

ALTER TABLE resource
	DROP CONSTRAINT package_resource_package_id_fkey;
''')


    # do data transfer
    # give resource group a hashed version of package uuid 
    # so that we can use the same hash calculation on  
    # the resource and resource revision table
    migrate_engine.execute('''
insert into resource_group 
    select 
        %s, id, 'default', null, null, state, revision_id
    from
        package;
''' %  make_new_uuid("id")
)

    migrate_engine.execute('''
insert into resource_group_revision
    select 
        id, package_id, 'default', null, null, state, revision_id, id
    from
        resource_group;
'''
)

    ## update resource table with new ids generated from the
    migrate_engine.execute('update resource set resource_group_id = %s' 
                           % make_new_uuid('resource_group_id'))

    migrate_engine.execute('update resource_revision set resource_group_id = %s' 
                           % make_new_uuid('resource_group_id'))

##add back contraints

    migrate_engine.execute('''
ALTER TABLE resource
	ADD CONSTRAINT resource_pkey PRIMARY KEY (id);

ALTER TABLE resource_revision
	ADD CONSTRAINT resource_revision_pkey PRIMARY KEY (id, revision_id);

ALTER TABLE resource
	ADD CONSTRAINT resource_resource_group_id_fkey FOREIGN KEY (resource_group_id) REFERENCES resource_group(id);

ALTER TABLE resource
	ADD CONSTRAINT resource_revision_id_fkey FOREIGN KEY (revision_id) REFERENCES revision(id);

ALTER TABLE resource_revision
	ADD CONSTRAINT resource_revision_continuity_id_fkey FOREIGN KEY (continuity_id) REFERENCES resource(id);

ALTER TABLE resource_revision
	ADD CONSTRAINT resource_revision_resource_group_id_fkey FOREIGN KEY (resource_group_id) REFERENCES resource_group(id);

ALTER TABLE resource_revision
	ADD CONSTRAINT resource_revision_revision_id_fkey FOREIGN KEY (revision_id) REFERENCES revision(id);
''')

    resource_count_after = migrate_engine.execute('''select count(*) from resource''').first()[0]
    resource_group_after = migrate_engine.execute('''select count(*) from resource_group''').first()[0]
    package_count_after = migrate_engine.execute('''select count(*) from package''').first()[0]

    all_joined = migrate_engine.execute('''select count(*) from package p 
                                           join resource_group rg on rg.package_id = p.id
                                           join resource r on r.resource_group_id = rg.id
                                        ''').first()[0]

    all_uuids = migrate_engine.execute('''
                                     select count(*) from 
                                     (select id from resource union 
                                     select id from resource_group union 
                                     select id from package) sub
                                     ''').first()[0]

    assert resource_count_after == resource_count 
    assert resource_group_after == package_count 
    assert package_count_after == package_count 

    ## this makes sure all uuids are unique (union dedupes)
    assert all_uuids == resource_count + package_count * 2 

    ## this makes sure all uuids are unique (union dedupes)
    assert all_joined == resource_count 



def make_new_uuid(column_name):

    out = '''substring(md5(%s), 1, 8)  || '-' ||
             substring(md5(%s), 9, 4)  || '-' ||
             substring(md5(%s), 13, 4)  || '-' ||        
             substring(md5(%s), 17, 4)  || '-' ||   
             substring(md5(%s), 21, 12)'''

    return out % tuple([column_name] * 5)





def downgrade(migrate_engine):
    raise NotImplementedError()

########NEW FILE########
__FILENAME__ = 035_harvesting_doc_versioning
from sqlalchemy import *
from migrate import *
import datetime
import uuid
import migrate.changeset
from migrate.changeset.constraint import PrimaryKeyConstraint
from ckan.model.types import JsonDictType

def upgrade(migrate_engine):
    metadata = MetaData(migrate_engine)

    migrate_engine.execute('''

    CREATE TABLE harvested_document_revision (
        id text NOT NULL,
        guid text,
        created timestamp without time zone,
        content text NOT NULL,
        source_id text,
        package_id text,
        state text,
        revision_id text NOT NULL,
        continuity_id text
    );

    ALTER TABLE harvested_document
        ADD COLUMN state text,
        ADD COLUMN revision_id text;

    ALTER TABLE harvested_document_revision
        ADD CONSTRAINT harvested_document_revision_pkey PRIMARY KEY (id, revision_id);

    ALTER TABLE harvested_document
        ADD CONSTRAINT harvested_document_revision_id_fkey FOREIGN KEY (revision_id) REFERENCES revision(id);

    ALTER TABLE harvested_document_revision
        ADD CONSTRAINT harvested_document_revision_continuity_id_fkey FOREIGN KEY (continuity_id) REFERENCES harvested_document(id);

    ALTER TABLE harvested_document_revision
        ADD CONSTRAINT harvested_document_revision_package_id_fkey FOREIGN KEY (package_id) REFERENCES package(id);

    ALTER TABLE harvested_document_revision
        ADD CONSTRAINT harvested_document_revision_revision_id_fkey FOREIGN KEY (revision_id) REFERENCES revision(id);

    ALTER TABLE harvested_document_revision
        ADD CONSTRAINT harvested_document_revision_source_id_fkey FOREIGN KEY (source_id) REFERENCES harvest_source(id);
    '''
    )

########NEW FILE########
__FILENAME__ = 036_lockdown_roles
from sqlalchemy import *
from migrate import *
import datetime
import uuid
from migrate.changeset.constraint import PrimaryKeyConstraint

def make_uuid():
    return unicode(uuid.uuid4())

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    role_action = Table('role_action', metadata, autoload=True)
    q = role_action.insert(values={'id': make_uuid(), 'role': 'editor', 
                           'action': 'read-site', 'context': ''})
    migrate_engine.execute(q)
    q = role_action.insert(values={'id': make_uuid(), 'role': 'editor', 
                                   'action': 'read-user', 'context': ''})
    migrate_engine.execute(q)
    q = role_action.insert(values={'id': make_uuid(), 'role': 'editor', 
                                   'action': 'create-user', 'context': ''})
    migrate_engine.execute(q)
    q = role_action.insert(values={'id': make_uuid(), 'role': 'reader', 
                                   'action': 'read-site', 'context': ''})
    migrate_engine.execute(q)
    q = role_action.insert(values={'id': make_uuid(), 'role': 'reader', 
                                   'action': 'read-user', 'context': ''})
    migrate_engine.execute(q)
    q = role_action.insert(values={'id': make_uuid(), 'role': 'reader', 
                                   'action': 'create-user', 'context': ''})
    migrate_engine.execute(q)

def downgrade(migrate_engine):
    raise NotImplementedError()


########NEW FILE########
__FILENAME__ = 037_role_anon_editor
from sqlalchemy import *
from sqlalchemy.sql import select, and_
from migrate import *
import logging

log = logging.getLogger(__name__)

def upgrade(migrate_engine):
    '''#1066 Change Visitor role on System from "reader" to "anon_editor".'''
    metadata = MetaData(migrate_engine)

    # get visitor ID
    user = Table('user', metadata, autoload=True)
    s = select([user.c.id, user.c.name],
               user.c.name == u'visitor')
    results = migrate_engine.execute(s).fetchall()
    if len(results) == 0:
        log.debug('No visitor on the system - obviously init hasn\'t been run yet' \
                  'and that will init visitor to an anon_editor')
        return

    visitor_id, visitor_name = results[0]

    # find visitor role as reader on system
    uor = Table('user_object_role', metadata, autoload=True)
    visitor_system_condition = and_(uor.c.context == u'System',
                                    uor.c.user_id == visitor_id)
    s = select([uor.c.context, uor.c.user_id, uor.c.role],
               visitor_system_condition)
    results = migrate_engine.execute(s).fetchall()
    if len(results) != 1:
        log.warn('Could not find a Right for a Visitor on the System')
        return
    context, user_id, role = results[0]
    if role != 'reader':
        log.info('Visitor right for the System is not "reader", so not upgrading it to anon_editor.')
        return

    # change visitor role to anon_editor
    log.info('Visitor is a "reader" on the System, so upgrading it to "anon_editor".')
    sql = uor.update().where(visitor_system_condition).\
          values(role=u'anon_editor')
    migrate_engine.execute(sql)


def downgrade(migrate_engine):
    raise NotImplementedError()


########NEW FILE########
__FILENAME__ = 038_delete_migration_tables
from migrate import *

def upgrade(migrate_engine):

    migrate_engine.execute('''
DROP TABLE harvested_document_revision, harvested_document, harvesting_job, harvest_source;
''')




########NEW FILE########
__FILENAME__ = 039_add_expired_id_and_dates
from migrate import *
import uuid
import datetime

def upgrade(migrate_engine):

    id = uuid.uuid4()

    make_missing_revisions = '''

-- make sure all tables have an entry in the revision_table

insert into revision values ('%(id)s' , '%(timestamp)s', 'admin', 'Admin: make sure every object has a row in a revision table', 'active');

insert into package_tag_revision (id,package_id,tag_id,revision_id,state,continuity_id) select id,package_id,tag_id, '%(id)s' ,state, id from package_tag where package_tag.id not in (select id from package_tag_revision);

insert into resource_revision (id,resource_group_id,url,format,description,position,revision_id,hash,state,extras,continuity_id) select id,resource_group_id,url,format,description,position, '%(id)s' ,hash,state,extras, id from resource where resource.id not in (select id from resource_revision);

insert into group_extra_revision (id,group_id,key,value,state,revision_id,continuity_id) select id,group_id,key,value,state, '%(id)s' , id from group_extra where group_extra.id not in (select id from group_extra_revision);

insert into resource_group_revision (id,package_id,label,sort_order,extras,state,revision_id,continuity_id) select id,package_id,label,sort_order,extras,state, '%(id)s', id from resource_group where resource_group.id not in (select id from resource_group_revision);

insert into package_extra_revision (id,package_id,key,value,revision_id,state,continuity_id) select id,package_id,key,value, '%(id)s',state, id from package_extra where package_extra.id not in (select id from package_extra_revision);

insert into package_relationship_revision (id,subject_package_id,object_package_id,type,comment,revision_id,state,continuity_id) select id,subject_package_id,object_package_id,type,comment, '%(id)s',state, id from package_relationship where package_relationship.id not in (select id from package_relationship_revision);
                           
insert into group_revision (id,name,title,description,created,state,revision_id,continuity_id) select id,name,title,description,created,state, '%(id)s', id from "group" where "group".id not in (select id from group_revision);

insert into package_revision (id,name,title,url,notes,license_id,revision_id,version,author,author_email,maintainer,maintainer_email,state,continuity_id) select id,name,title,url,notes,license_id, '%(id)s',version,author,author_email,maintainer,maintainer_email,state, id from package where package.id not in (select id from package_revision);

''' % dict(id=id, timestamp=datetime.datetime.utcnow().isoformat())


    update_schema = '''
ALTER TABLE package_revision
	ADD COLUMN expired_id text,
	ADD COLUMN revision_timestamp timestamp without time zone,
	ADD COLUMN expired_timestamp timestamp without time zone,
	ADD COLUMN current boolean;

ALTER TABLE package_extra_revision
	ADD COLUMN expired_id text,
	ADD COLUMN revision_timestamp timestamp without time zone,
	ADD COLUMN expired_timestamp timestamp without time zone,
	ADD COLUMN current boolean;

ALTER TABLE group_revision
	ADD COLUMN expired_id text,
	ADD COLUMN revision_timestamp timestamp without time zone,
	ADD COLUMN expired_timestamp timestamp without time zone,
	ADD COLUMN current boolean;

ALTER TABLE group_extra_revision
	ADD COLUMN expired_id text,
	ADD COLUMN revision_timestamp timestamp without time zone,
	ADD COLUMN expired_timestamp timestamp without time zone,
	ADD COLUMN current boolean;


ALTER TABLE package_group_revision
	ADD COLUMN expired_id text,
	ADD COLUMN revision_timestamp timestamp without time zone,
	ADD COLUMN expired_timestamp timestamp without time zone,
	ADD COLUMN current boolean;

ALTER TABLE package_tag_revision
	ADD COLUMN expired_id text,
	ADD COLUMN revision_timestamp timestamp without time zone,
	ADD COLUMN expired_timestamp timestamp without time zone,
	ADD COLUMN current boolean;

ALTER TABLE resource_group_revision
	ADD COLUMN expired_id text,
	ADD COLUMN revision_timestamp timestamp without time zone,
	ADD COLUMN expired_timestamp timestamp without time zone,
	ADD COLUMN current boolean;

ALTER TABLE resource_revision
	ADD COLUMN expired_id text,
	ADD COLUMN revision_timestamp timestamp without time zone,
	ADD COLUMN expired_timestamp timestamp without time zone,
	ADD COLUMN current boolean;

ALTER TABLE package_relationship_revision 
	ADD COLUMN expired_id text,
	ADD COLUMN revision_timestamp timestamp without time zone,
	ADD COLUMN expired_timestamp timestamp without time zone,
	ADD COLUMN current boolean;

ALTER TABLE revision
	ADD COLUMN approved_timestamp timestamp without time zone;

create table tmp_expired_id(id text, revision_id text, revision_timestamp timestamp, expired_timestamp timestamp, expired_id text);
create index id_exp on tmp_expired_id(id, revision_id);

--package revision
truncate tmp_expired_id;
insert into tmp_expired_id select pr.id, revision_id, timestamp, lead(timestamp, 1, '9999-12-31') over (partition by pr.id order by timestamp), lead(pr.revision_id) over (partition by pr.id order by timestamp) from package_revision pr join revision r on pr.revision_id = r.id;
update package_revision pr set revision_timestamp = (select revision_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_timestamp = (select expired_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_id = (select expired_id from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id);
update package_revision set current = '1' where expired_timestamp = '9999-12-31';

create index idx_package_period on package_revision(revision_timestamp, expired_timestamp, id);
create index idx_package_current on package_revision(current);

--package extra revision 
truncate tmp_expired_id;
insert into tmp_expired_id select pr.id, revision_id, timestamp, lead(timestamp, 1, '9999-12-31') over (partition by pr.id order by timestamp), lead(pr.revision_id) over (partition by pr.id order by timestamp) from package_extra_revision pr join revision r on pr.revision_id = r.id;
update package_extra_revision pr set revision_timestamp = (select revision_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_timestamp = (select expired_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_id = (select expired_id from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id);
update package_extra_revision set current = '1' where expired_timestamp = '9999-12-31';

create index idx_package_extra_period on package_extra_revision(revision_timestamp, expired_timestamp, id);
create index idx_package_extra_period_package on package_extra_revision(revision_timestamp, expired_timestamp, package_id);
create index idx_package_extra_current on package_extra_revision(current);

--package group revision
truncate tmp_expired_id;
insert into tmp_expired_id select pr.id, revision_id, timestamp, lead(timestamp, 1, '9999-12-31') over (partition by pr.id order by timestamp), lead(pr.revision_id) over (partition by pr.id order by timestamp) from package_group_revision pr join revision r on pr.revision_id = r.id;
update package_group_revision pr set revision_timestamp = (select revision_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_timestamp = (select expired_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_id = (select expired_id from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id);
update package_group_revision set current = '1' where expired_timestamp = '9999-12-31';

create index idx_package_group_period_package_group on package_group_revision(revision_timestamp, expired_timestamp, package_id, group_id);
create index idx_package_group_current on package_group_revision(current);


-- package_tags
truncate tmp_expired_id;
insert into tmp_expired_id select pr.id, revision_id, timestamp, lead(timestamp, 1, '9999-12-31') over (partition by pr.id order by timestamp), lead(pr.revision_id) over (partition by pr.id order by timestamp) from package_tag_revision pr join revision r on pr.revision_id = r.id;
update package_tag_revision pr set revision_timestamp = (select revision_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_timestamp = (select expired_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_id = (select expired_id from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id);
update package_tag_revision set current = '1' where expired_timestamp = '9999-12-31';

create index idx_period_package_tag on package_tag_revision(revision_timestamp, expired_timestamp, package_id, tag_id);
create index idx_package_tag_current on package_tag_revision(current);

-- package relationship
truncate tmp_expired_id;
insert into tmp_expired_id select pr.id, revision_id, timestamp, lead(timestamp, 1, '9999-12-31') over (partition by pr.id order by timestamp), lead(pr.revision_id) over (partition by pr.id order by timestamp) from package_relationship_revision pr join revision r on pr.revision_id = r.id;
update package_relationship_revision pr set revision_timestamp = (select revision_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_timestamp = (select expired_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_id = (select expired_id from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id);
update package_relationship_revision set current = '1' where expired_timestamp = '9999-12-31';

create index idx_period_package_relationship on package_relationship_revision(revision_timestamp, expired_timestamp, object_package_id, subject_package_id);
create index idx_package_relationship_current on package_relationship_revision(current);

-- resource revision
truncate tmp_expired_id;
insert into tmp_expired_id select pr.id, revision_id, timestamp, lead(timestamp, 1, '9999-12-31') over (partition by pr.id order by timestamp), lead(pr.revision_id) over (partition by pr.id order by timestamp) from resource_revision pr join revision r on pr.revision_id = r.id;
update resource_revision pr set revision_timestamp = (select revision_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_timestamp = (select expired_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_id = (select expired_id from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id);
update resource_revision set current = '1' where expired_timestamp = '9999-12-31';

create index idx_resource_period on resource_revision(revision_timestamp, expired_timestamp, id);
create index idx_resource_period_resource_group on resource_revision(revision_timestamp, expired_timestamp, resource_group_id);
create index idx_resource_current on resource_revision(current);

-- resource group revision;
truncate tmp_expired_id;
insert into tmp_expired_id select pr.id, revision_id, timestamp, lead(timestamp, 1, '9999-12-31') over (partition by pr.id order by timestamp), lead(pr.revision_id) over (partition by pr.id order by timestamp) from resource_group_revision pr join revision r on pr.revision_id = r.id;
update resource_group_revision pr set revision_timestamp = (select revision_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_timestamp = (select expired_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_id = (select expired_id from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id);
update resource_group_revision set current = '1' where expired_timestamp = '9999-12-31';

create index idx_resource_group_period on resource_group_revision(revision_timestamp, expired_timestamp, id);
create index idx_resource_group_period_package on resource_group_revision(revision_timestamp, expired_timestamp, package_id);
create index idx_resource_group_current on resource_group_revision(current);

--group revision;
truncate tmp_expired_id;
insert into tmp_expired_id select pr.id, revision_id, timestamp, lead(timestamp, 1, '9999-12-31') over (partition by pr.id order by timestamp), lead(pr.revision_id) over (partition by pr.id order by timestamp) from group_revision pr join revision r on pr.revision_id = r.id;
update group_revision pr set revision_timestamp = (select revision_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_timestamp = (select expired_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_id = (select expired_id from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id);
update group_revision set current = '1' where expired_timestamp = '9999-12-31';

create index idx_group_period on group_revision(revision_timestamp, expired_timestamp, id);
create index idx_group_current on group_revision(current);

--group extra revision 
truncate tmp_expired_id;
insert into tmp_expired_id select pr.id, revision_id, timestamp, lead(timestamp, 1, '9999-12-31') over (partition by pr.id order by timestamp), lead(pr.revision_id) over (partition by pr.id order by timestamp) from group_extra_revision pr join revision r on pr.revision_id = r.id;
update group_extra_revision pr set revision_timestamp = (select revision_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_timestamp = (select expired_timestamp from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id),
                               expired_id = (select expired_id from tmp_expired_id tmp where tmp.revision_id = pr.revision_id and tmp.id = pr.id);
update group_extra_revision set current = '1' where expired_timestamp = '9999-12-31';

create index idx_group_extra_period on group_extra_revision(revision_timestamp, expired_timestamp, id);
create index idx_group_extra_period_group on group_extra_revision(revision_timestamp, expired_timestamp, group_id);
create index idx_group_extra_current on group_extra_revision(current);

drop table tmp_expired_id;

-- change state of revision tables

update revision set approved_timestamp = timestamp;
'''
    
    migrate_engine.execute('begin;  ' + make_missing_revisions + update_schema + ' commit;')
    
    for table in ['package', 'resource', 'resource_group', 'package_extra', 
                  'package_tag', 'package_relationship', 'group', 'group_extra']:
        count = migrate_engine.execute('''select count(*) from "%s"''' % table).first()[0]
        revision_expired_id_count = migrate_engine.execute('''select count(*) from %s_revision where %s_revision.expired_id is null''' % (table, table)).first()[0]
        revision_expired_data_count = migrate_engine.execute('''select count(*) from %s_revision where %s_revision.expired_timestamp = '9999-12-31' ''' % (table, table)).first()[0]
        revision_current = migrate_engine.execute('''select count(*) from %s_revision where %s_revision.current = '1' ''' % (table, table)).first()[0]
        assert count == revision_expired_id_count
        assert count == revision_expired_data_count
        assert count == revision_current

    

########NEW FILE########
__FILENAME__ = 040_reset_key_on_user
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    user_table = Table('user', metadata, autoload=True)
    reset_key_col = Column('reset_key', UnicodeText)
    reset_key_col.create(user_table)

def downgrade(migrate_engine):
    raise NotImplementedError()


########NEW FILE########
__FILENAME__ = 041_resource_new_fields
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute(
    '''
    begin;
    ALTER TABLE resource
    ADD COLUMN name text,
    ADD COLUMN resource_type text,
    ADD COLUMN mimetype text,
    ADD COLUMN mimetype_inner text,
    ADD COLUMN "size" bigint,
    ADD COLUMN last_modified timestamp without time zone,
    ADD COLUMN cache_url text,
    ADD COLUMN cache_last_updated timestamp without time zone,
    ADD COLUMN webstore_url text,
    ADD COLUMN webstore_last_updated timestamp without time zone;

    ALTER TABLE resource_revision
    ADD COLUMN name text,
    ADD COLUMN resource_type text,
    ADD COLUMN mimetype text,
    ADD COLUMN mimetype_inner text,
    ADD COLUMN "size" bigint,
    ADD COLUMN last_modified timestamp without time zone,
    ADD COLUMN cache_url text,
    ADD COLUMN cache_last_updated timestamp without time zone,
    ADD COLUMN webstore_url text,
    ADD COLUMN webstore_last_updated timestamp without time zone;
    commit;
    '''
    )

########NEW FILE########
__FILENAME__ = 042_user_revision_indexes
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute('''
    BEGIN;
    CREATE INDEX idx_revision_author ON "revision" (author);
    CREATE INDEX idx_openid ON "user" (openid);
    CREATE INDEX "idx_user_name_index" on "user"((CASE WHEN ("user".fullname IS NULL OR "user".fullname = '') THEN "user".name ELSE "user".fullname END));
    COMMIT;
    '''
    )



########NEW FILE########
__FILENAME__ = 043_drop_postgres_search
from sqlalchemy import *
from migrate import *
import migrate.changeset

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    package_search_table = Table('package_search', metadata, autoload=True)
    package_search_table.drop()
##    migrate_engine.execute('''
##DROP TABLE package_search;
##''')

########NEW FILE########
__FILENAME__ = 044_add_task_status
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute('''
        CREATE TABLE task_status (
            id text NOT NULL,
            entity_id text NOT NULL,
            entity_type text NOT NULL,
            task_type text NOT NULL,
            "key" text NOT NULL,
            "value" text NOT NULL,
            "state" text,
            "error" text,
            last_updated timestamp without time zone
        );

        ALTER TABLE task_status
            ADD CONSTRAINT task_status_pkey PRIMARY KEY (id);

        ALTER TABLE task_status
            ADD CONSTRAINT task_status_entity_id_task_type_key_key UNIQUE (entity_id, task_type, key);
    '''
    )

########NEW FILE########
__FILENAME__ = 045_user_name_unique
import warnings

from sqlalchemy import exc as sa_exc
from sqlalchemy import *
from migrate import *
from migrate.changeset.constraint import UniqueConstraint

def upgrade(migrate_engine):
    # ignore reflection warnings
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=sa_exc.SAWarning)
        metadata = MetaData()
        metadata.bind = migrate_engine
        user_table = Table('user', metadata, autoload=True)
    #    name_column = user_table.c.name
        unique_name_constraint = UniqueConstraint('name', table=user_table)
        unique_name_constraint.create()

########NEW FILE########
__FILENAME__ = 046_drop_changesets
from sqlalchemy import *
from migrate import *
import migrate.changeset

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    for table_name in ['change', 'changemask', 'changeset']:
        table = Table(table_name, metadata, autoload=True)
        table.drop()

########NEW FILE########
__FILENAME__ = 047_rename_package_group_member
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute('''
BEGIN;
alter table package_group RENAME to member;
alter table package_group_revision RENAME to member_revision;
alter table member RENAME column package_id to table_id;
alter table member_revision RENAME column package_id to table_id;

alter table member ALTER column table_id set NOT NULL;
alter table member_revision ALTER column table_id set NOT NULL;

ALTER TABLE member_revision
	DROP CONSTRAINT package_group_revision_pkey;

ALTER TABLE member_revision
	DROP CONSTRAINT package_group_revision_continuity_id_fkey;

ALTER TABLE member_revision
	DROP CONSTRAINT package_group_revision_group_id_fkey;

ALTER TABLE member_revision
	DROP CONSTRAINT package_group_revision_package_id_fkey;

ALTER TABLE member_revision
	DROP CONSTRAINT package_group_revision_revision_id_fkey;

ALTER TABLE "member"
	DROP CONSTRAINT package_group_pkey;

ALTER TABLE "member"
	DROP CONSTRAINT package_group_group_id_fkey;

ALTER TABLE "member"
	DROP CONSTRAINT package_group_package_id_fkey;

ALTER TABLE "member"
	DROP CONSTRAINT package_group_revision_id_fkey;


ALTER TABLE "member"
	ADD COLUMN table_name text;
ALTER TABLE "member"
	ADD COLUMN capacity text;

ALTER TABLE "member_revision"
	ADD COLUMN table_name text;
ALTER TABLE "member_revision"
	ADD COLUMN capacity text;

ALTER TABLE "member"
	ADD CONSTRAINT member_pkey PRIMARY KEY (id);

ALTER TABLE member_revision
	ADD CONSTRAINT member_revision_pkey PRIMARY KEY (id, revision_id);

ALTER TABLE "member"
	ADD CONSTRAINT member_group_id_fkey FOREIGN KEY (group_id) REFERENCES "group"(id);

ALTER TABLE "member"
	ADD CONSTRAINT member_revision_id_fkey FOREIGN KEY (revision_id) REFERENCES revision(id);

ALTER TABLE member_revision
	ADD CONSTRAINT member_revision_continuity_id_fkey FOREIGN KEY (continuity_id) REFERENCES member(id);

ALTER TABLE member_revision
	ADD CONSTRAINT member_revision_group_id_fkey FOREIGN KEY (group_id) REFERENCES "group"(id);

ALTER TABLE member_revision
	ADD CONSTRAINT member_revision_revision_id_fkey FOREIGN KEY (revision_id) REFERENCES revision(id);

ALTER TABLE "group"
	ADD COLUMN "type" text;
ALTER TABLE "group_revision"
	ADD COLUMN "type" text;

update member set table_name = 'package', capacity = 'public';
update member_revision set table_name = 'package', capacity = 'public';

update "group" set type = 'group';
update group_revision set type = 'group';


ALTER TABLE "member"
	ALTER COLUMN  table_name set not null;
ALTER TABLE "member"
	ALTER COLUMN  capacity set not null;

ALTER TABLE member_revision
	ALTER COLUMN table_name set not null;
ALTER TABLE "member_revision"
	ALTER COLUMN capacity set not null;

ALTER TABLE "group"
	ALTER COLUMN "type" set not null;
ALTER TABLE "group_revision"
	ALTER COLUMN "type" set not null;

ALTER TABLE "package"
	ADD COLUMN "type" text;
ALTER TABLE "package_revision"
	ADD COLUMN "type" text;


COMMIT;
    '''
    )

########NEW FILE########
__FILENAME__ = 048_add_activity_streams_tables
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    migrate_engine.execute('''
CREATE TABLE activity (
	id text NOT NULL,
	timestamp timestamp without time zone,
	user_id text,
	object_id text,
	revision_id text,
	activity_type text,
	data text
);

CREATE TABLE activity_detail (
	id text NOT NULL,
	activity_id text NOT NULL,
	object_id text,
	object_type text,
	activity_type text,
	data text
);

ALTER TABLE activity
	ADD CONSTRAINT activity_pkey PRIMARY KEY (id);

ALTER TABLE activity_detail
	ADD CONSTRAINT activity_detail_pkey PRIMARY KEY (id);

ALTER TABLE activity_detail
	ADD CONSTRAINT activity_detail_activity_id_fkey FOREIGN KEY (activity_id) REFERENCES activity(id);
    ''')

########NEW FILE########
__FILENAME__ = 049_add_group_approval_status
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute('''
BEGIN;
ALTER TABLE "group"
	ADD COLUMN approval_status text;

ALTER TABLE group_revision
	ADD COLUMN approval_status text;

update "group" set approval_status = 'approved';
update group_revision set approval_status = 'approved';

COMMIT;
    '''
    )

########NEW FILE########
__FILENAME__ = 050_term_translation_table
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute('''
        CREATE TABLE term_translation (
            term text NOT NULL,
            term_translation text NOT NULL,
            lang_code text NOT NULL
        );

        create index term_lang on term_translation(term, lang_code);
        create index term on term_translation(term);
    '''
    )



  


########NEW FILE########
__FILENAME__ = 051_add_tag_vocabulary
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute('''
        ALTER TABLE tag
            DROP CONSTRAINT tag_name_key;

        CREATE TABLE vocabulary (
            id text NOT NULL,
            name character varying(100) NOT NULL
        );

        ALTER TABLE tag
            ADD COLUMN vocabulary_id character varying(100);

        ALTER TABLE vocabulary
            ADD CONSTRAINT vocabulary_pkey PRIMARY KEY (id);

        ALTER TABLE tag
            ADD CONSTRAINT tag_name_vocabulary_id_key UNIQUE (name, vocabulary_id);

        ALTER TABLE tag
            ADD CONSTRAINT tag_vocabulary_id_fkey FOREIGN KEY (vocabulary_id) REFERENCES vocabulary(id);

        ALTER TABLE vocabulary
            ADD CONSTRAINT vocabulary_name_key UNIQUE (name);
    '''
    )

########NEW FILE########
__FILENAME__ = 052_update_member_capacities
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute("""
    BEGIN;
        UPDATE member SET capacity='public' WHERE capacity='member'
                                            AND table_name='package';
        UPDATE member_revision SET capacity='public' WHERE capacity='member'
                                                     AND   table_name='package';
    COMMIT;
    """
    )

########NEW FILE########
__FILENAME__ = 053_add_group_logo
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute('''
        ALTER TABLE "group"
            ADD COLUMN image_url text;

        ALTER TABLE group_revision
            ADD COLUMN image_url text;
    '''
    )

########NEW FILE########
__FILENAME__ = 054_add_resource_created_date
def upgrade(migrate_engine):
    migrate_engine.execute('''
        ALTER TABLE resource
            ADD COLUMN created timestamp without time zone;

        ALTER TABLE resource_revision
            ADD COLUMN created timestamp without time zone;
    '''
    )

########NEW FILE########
__FILENAME__ = 055_update_user_and_activity_detail
def upgrade(migrate_engine):
    migrate_engine.execute('''
        ALTER TABLE activity_detail
            ALTER COLUMN activity_id DROP NOT NULL;

        ALTER TABLE "user"
            ALTER COLUMN name SET NOT NULL;
    '''
    )

########NEW FILE########
__FILENAME__ = 056_add_related_table
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    migrate_engine.execute('''
BEGIN;
CREATE TABLE related (
	id text NOT NULL,
	type text NOT NULL,
	title text,
	description text,
	image_url text,
	url text,
	created timestamp without time zone,
	owner_id text
);

CREATE TABLE related_dataset (
	id text NOT NULL,
	dataset_id text NOT NULL,
	related_id text NOT NULL,
	status text
);

ALTER TABLE related
	ADD CONSTRAINT related_pkey PRIMARY KEY (id);

ALTER TABLE related_dataset
	ADD CONSTRAINT related_dataset_pkey PRIMARY KEY (id);

ALTER TABLE related_dataset
	ADD CONSTRAINT related_dataset_dataset_id_fkey FOREIGN KEY (dataset_id) REFERENCES package(id);

ALTER TABLE related_dataset
	ADD CONSTRAINT related_dataset_related_id_fkey FOREIGN KEY (related_id) REFERENCES related(id);
COMMIT;
    '''
    )

########NEW FILE########
__FILENAME__ = 057_tracking
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute('''
        BEGIN;
        CREATE TABLE tracking_raw (
            user_key character varying(100) NOT NULL,
            url text NOT NULL,
            tracking_type character varying(10) NOT NULL,
            access_timestamp timestamp without time zone DEFAULT current_timestamp
        );
        CREATE INDEX tracking_raw_url ON tracking_raw(url);
        CREATE INDEX tracking_raw_user_key ON tracking_raw(user_key);
        CREATE INDEX tracking_raw_access_timestamp ON tracking_raw(access_timestamp);

        CREATE TABLE tracking_summary(
            url text NOT NULL,
            package_id text,
            tracking_type character varying(10) NOT NULL,
            count int NOT NULL,
            running_total int NOT NULL DEFAULT 0,
            recent_views int NOT NULL DEFAULT 0,
            tracking_date date
        );

        CREATE INDEX tracking_summary_url ON tracking_summary(url);
        CREATE INDEX tracking_summary_package_id ON tracking_summary(package_id);
        CREATE INDEX tracking_summary_date ON tracking_summary(tracking_date);

        COMMIT;
    '''
    )

########NEW FILE########
__FILENAME__ = 058_add_follower_tables
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    migrate_engine.execute('''
CREATE TABLE user_following_dataset (
    follower_id text NOT NULL,
    object_id text NOT NULL,
    datetime timestamp without time zone NOT NULL
);

CREATE TABLE user_following_user (
    follower_id text NOT NULL,
    object_id text NOT NULL,
    datetime timestamp without time zone NOT NULL
);

ALTER TABLE user_following_dataset
    ADD CONSTRAINT user_following_dataset_pkey PRIMARY KEY (follower_id, object_id);

ALTER TABLE user_following_user
    ADD CONSTRAINT user_following_user_pkey PRIMARY KEY (follower_id, object_id);

ALTER TABLE user_following_dataset
    ADD CONSTRAINT user_following_dataset_follower_id_fkey FOREIGN KEY (follower_id) REFERENCES "user"(id) ON UPDATE CASCADE ON DELETE CASCADE;

ALTER TABLE user_following_dataset
    ADD CONSTRAINT user_following_dataset_object_id_fkey FOREIGN KEY (object_id) REFERENCES package(id) ON UPDATE CASCADE ON DELETE CASCADE;

ALTER TABLE user_following_user
    ADD CONSTRAINT user_following_user_follower_id_fkey FOREIGN KEY (follower_id) REFERENCES "user"(id) ON UPDATE CASCADE ON DELETE CASCADE;

ALTER TABLE user_following_user
    ADD CONSTRAINT user_following_user_object_id_fkey FOREIGN KEY (object_id) REFERENCES "user"(id) ON UPDATE CASCADE ON DELETE CASCADE;
    ''')

########NEW FILE########
__FILENAME__ = 059_add_related_count_and_flag
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    migrate_engine.execute('''
        ALTER TABLE "related"
            ADD COLUMN view_count INT NOT NULL DEFAULT 0;

        ALTER TABLE "related"
            ADD COLUMN featured INT NOT NULL DEFAULT 0;

        UPDATE related SET view_count=0, featured=0 WHERE view_count IS NULL;
    '''
    )

########NEW FILE########
__FILENAME__ = 060_add_system_info_table
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    meta = MetaData()


    system_info_table = Table('system_info', meta,
            Column('id', Integer() ,  primary_key=True, nullable=False),
            Column('key', Unicode(100), unique=True, nullable=False),
            Column('value', UnicodeText),
            Column('revision_id', UnicodeText, ForeignKey('revision.id'))
        )

    system_info_revision_table = Table('system_info_revision', meta,
            Column('id', Integer() ,  primary_key=True, nullable=False),
            Column('key', Unicode(100), unique=True, nullable=False),
            Column('value', UnicodeText),
            Column('revision_id', UnicodeText, ForeignKey('revision.id'), primary_key=True),
            Column('continuity_id', Integer(), ForeignKey('system_info.id') ),
        )


    meta.bind = migrate_engine
    revision_table = Table('revision', meta, autoload=True)

    meta.create_all()

########NEW FILE########
__FILENAME__ = 061_add_follower__group_table
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    migrate_engine.execute('''
CREATE TABLE user_following_group (
    follower_id text NOT NULL,
    object_id text NOT NULL,
    datetime timestamp without time zone NOT NULL
);

ALTER TABLE user_following_group
    ADD CONSTRAINT user_following_group_pkey PRIMARY KEY (follower_id, object_id);

ALTER TABLE user_following_group
    ADD CONSTRAINT user_following_group_user_id_fkey FOREIGN KEY (follower_id) REFERENCES "user"(id) ON UPDATE CASCADE ON DELETE CASCADE;

ALTER TABLE user_following_group
    ADD CONSTRAINT user_following_group_group_id_fkey FOREIGN KEY (object_id) REFERENCES "group"(id) ON UPDATE CASCADE ON DELETE CASCADE;
    ''')

########NEW FILE########
__FILENAME__ = 062_add_dashboard_table
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    migrate_engine.execute('''
CREATE TABLE dashboard (
    user_id text NOT NULL,
    activity_stream_last_viewed timestamp without time zone NOT NULL
);
ALTER TABLE dashboard
    ADD CONSTRAINT dashboard_pkey PRIMARY KEY (user_id);
ALTER TABLE dashboard
    ADD CONSTRAINT dashboard_user_id_fkey FOREIGN KEY (user_id) REFERENCES "user"(id) ON UPDATE CASCADE ON DELETE CASCADE;
    ''')

########NEW FILE########
__FILENAME__ = 063_org_changes
from migrate import *

def upgrade(migrate_engine):

    update_schema = '''
BEGIN;

ALTER TABLE "user"
    ADD COLUMN sysadmin boolean DEFAULT FALSE;

ALTER TABLE package
    ADD COLUMN owner_org TEXT,
    ADD COLUMN private boolean DEFAULT FALSE;

ALTER TABLE package_revision
    ADD COLUMN owner_org TEXT,
    ADD COLUMN private boolean DEFAULT FALSE;


ALTER TABLE "group"
    ADD COLUMN is_organization boolean DEFAULT FALSE;

ALTER TABLE group_revision
    ADD COLUMN is_organization boolean DEFAULT FALSE;

UPDATE "user" SET sysadmin=true WHERE id in ( SELECT user_id FROM user_object_role WHERE role='admin' AND context='System');

COMMIT;

'''
    migrate_engine.execute(update_schema)

########NEW FILE########
__FILENAME__ = 064_add_email_last_sent_column
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    migrate_engine.execute('''
ALTER TABLE dashboard
    ADD COLUMN email_last_sent timestamp without time zone NOT NULL DEFAULT LOCALTIMESTAMP;
    ''')

########NEW FILE########
__FILENAME__ = 065_add_email_notifications_preference
from sqlalchemy import *
from migrate import *

def upgrade(migrate_engine):
    metadata = MetaData()
    metadata.bind = migrate_engine
    migrate_engine.execute('''
ALTER TABLE public.user
    ADD COLUMN activity_streams_email_notifications BOOLEAN DEFAULT FALSE;
    ''')

########NEW FILE########
__FILENAME__ = 066_default_package_type
def upgrade(migrate_engine):

    update_statement = '''
BEGIN;

UPDATE package SET type = 'dataset' WHERE type IS NULL;

COMMIT;

'''
    migrate_engine.execute(update_statement)

########NEW FILE########
__FILENAME__ = 067_turn_extras_to_strings
import json

def upgrade(migrate_engine):

    with migrate_engine.begin() as connection:
        tables = 'package_extra group_extra'
        revision_tables = 'package_extra_revision group_extra_revision'

        for table in tables.split():
            sql = """select id, value from {table} where substr(value,1,1) = '"' """.format(table=table)
            results = connection.execute(sql)
            for result in results:
                id, value = result
                update_sql = 'update {table} set value = %s where id = %s'
                connection.execute(update_sql.format(table=table),
                                   json.loads(value), id)

        for table in revision_tables.split():
            sql = """select id, revision_id, value from {table} where substr(value,1,1) = '"' """.format(table=table)

            results = connection.execute(sql)
            for result in results:
                id, revision_id, value = result
                update_sql = 'update {table} set value = %s where id = %s and revision_id = %s'
                connection.execute(update_sql.format(table=table),
                                   json.loads(value), id, revision_id)



########NEW FILE########
__FILENAME__ = 068_add_package_extras_index
def upgrade(migrate_engine):
    migrate_engine.execute(
        '''
        CREATE INDEX idx_package_extra_package_id ON package_extra_revision
        USING BTREE (package_id, current);
        '''
    )

########NEW FILE########
__FILENAME__ = 069_resource_url_and_metadata_modified
def upgrade(migrate_engine):

    update_schema = '''
BEGIN;

ALTER TABLE resource
    ADD COLUMN url_type TEXT;

ALTER TABLE resource_revision
    ADD COLUMN url_type TEXT;

ALTER TABLE package
    ADD COLUMN metadata_modified timestamp without time zone,
    ADD COLUMN creator_user_id TEXT;

ALTER TABLE package_revision
    ADD COLUMN metadata_modified timestamp without time zone,
    ADD COLUMN creator_user_id TEXT;


-- package
update package
set metadata_modified = greatest(max_revision, metadata_modified)
from
(
select id package_id, max(revision_timestamp) max_revision
from package_revision group by id
) max_rev
where max_rev.package_id = package.id;

-- package tag
update package
set metadata_modified = greatest(max_revision, metadata_modified)
from (select package_id, max(revision_timestamp) max_revision
from package_tag_revision group by package_id) max_rev
where max_rev.package_id = package.id;

-- package extra
update package
set metadata_modified = greatest(max_revision, metadata_modified)
from (select package_id, max(revision_timestamp) max_revision
from package_extra_revision group by package_id) max_rev
where max_rev.package_id = package.id;

--resource

update package
set metadata_modified = greatest(max_revision, metadata_modified)
from (select package_id, max(revision_timestamp) max_revision
      from resource_revision
      join resource_group
      on resource_revision.resource_group_id = resource_group.id
      group by package_id) max_rev
where max_rev.package_id = package.id
;

-- add as many creators as we can find
update package set creator_user_id = user_id from
(select
    package_revision.id as package_id,
    "user".id as user_id, revision_timestamp,
    row_number() over
    (partition by package_revision.id order by revision_timestamp) num
from package_revision
    join revision on package_revision.revision_id = revision.id join "user"
    on (revision.author = "user".name
        or revision.author = "user".openid)) first_rev
    where package_id = id and num = 1;

COMMIT;

'''
    migrate_engine.execute(update_schema)

########NEW FILE########
__FILENAME__ = 070_add_activity_and_resource_indexes
def upgrade(migrate_engine):
    migrate_engine.execute(
        '''
        CREATE INDEX idx_activity_user_id ON activity
        (user_id, timestamp);
        CREATE INDEX idx_activity_object_id ON activity
        (object_id, timestamp);
        CREATE INDEX idx_activity_detail_activity_id ON activity_detail
        (activity_id);
        CREATE INDEX idx_resource_resource_group_id ON resource_revision
        (resource_group_id, current);
        '''
    )

########NEW FILE########
__FILENAME__ = 071_add_state_column_to_user_table
import ckan.model


def upgrade(migrate_engine):
    migrate_engine.execute(
        '''
        ALTER TABLE "user" ADD COLUMN "state" text NOT NULL DEFAULT '%s'
        ''' % ckan.model.State.ACTIVE
    )

########NEW FILE########
__FILENAME__ = activity
import datetime

from sqlalchemy import orm, types, Column, Table, ForeignKey, desc, or_

import ckan.model
import meta
import types as _types
import domain_object

__all__ = ['Activity', 'activity_table',
           'ActivityDetail', 'activity_detail_table',
           ]

activity_table = Table(
    'activity', meta.metadata,
    Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
    Column('timestamp', types.DateTime),
    Column('user_id', types.UnicodeText),
    Column('object_id', types.UnicodeText),
    Column('revision_id', types.UnicodeText),
    Column('activity_type', types.UnicodeText),
    Column('data', _types.JsonDictType),
    )

activity_detail_table = Table(
    'activity_detail', meta.metadata,
    Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
    Column('activity_id', types.UnicodeText, ForeignKey('activity.id')),
    Column('object_id', types.UnicodeText),
    Column('object_type', types.UnicodeText),
    Column('activity_type', types.UnicodeText),
    Column('data', _types.JsonDictType),
    )

class Activity(domain_object.DomainObject):

    def __init__(self, user_id, object_id, revision_id, activity_type,
            data=None):
        self.id = _types.make_uuid()
        self.timestamp = datetime.datetime.now()
        self.user_id = user_id
        self.object_id = object_id
        self.revision_id = revision_id
        self.activity_type = activity_type
        if data is None:
            self.data = {}
        else:
            self.data = data

meta.mapper(Activity, activity_table)


class ActivityDetail(domain_object.DomainObject):

    def __init__(self, activity_id, object_id, object_type, activity_type,
            data=None):
        self.activity_id = activity_id
        self.object_id = object_id
        self.object_type = object_type
        self.activity_type = activity_type
        if data is None:
            self.data = {}
        else:
            self.data = data

    @classmethod
    def by_activity_id(cls, activity_id):
        return ckan.model.Session.query(cls) \
                .filter_by(activity_id = activity_id).all()


meta.mapper(ActivityDetail, activity_detail_table, properties = {
    'activity':orm.relation ( Activity, backref=orm.backref('activity_detail'))
    })


def _activities_at_offset(q, limit, offset):
    '''Return an SQLAlchemy query for all activities at an offset with a limit.

    '''
    import ckan.model as model
    q = q.order_by(desc(model.Activity.timestamp))
    if offset:
        q = q.offset(offset)
    if limit:
        q = q.limit(limit)
    return q.all()

def _activities_from_user_query(user_id):
    '''Return an SQLAlchemy query for all activities from user_id.'''
    import ckan.model as model
    q = model.Session.query(model.Activity)
    q = q.filter(model.Activity.user_id == user_id)
    return q


def _activities_about_user_query(user_id):
    '''Return an SQLAlchemy query for all activities about user_id.'''
    import ckan.model as model
    q = model.Session.query(model.Activity)
    q = q.filter(model.Activity.object_id == user_id)
    return q


def _user_activity_query(user_id):
    '''Return an SQLAlchemy query for all activities from or about user_id.'''
    q = _activities_from_user_query(user_id)
    q = q.union(_activities_about_user_query(user_id))
    return q


def user_activity_list(user_id, limit, offset):
    '''Return user_id's public activity stream.

    Return a list of all activities from or about the given user, i.e. where
    the given user is the subject or object of the activity, e.g.:

    "{USER} created the dataset {DATASET}"
    "{OTHER_USER} started following {USER}"
    etc.

    '''
    q = _user_activity_query(user_id)
    return _activities_at_offset(q, limit, offset)


def _package_activity_query(package_id):
    '''Return an SQLAlchemy query for all activities about package_id.

    '''
    import ckan.model as model
    q = model.Session.query(model.Activity)
    q = q.filter_by(object_id=package_id)
    return q


def package_activity_list(package_id, limit, offset):
    '''Return the given dataset (package)'s public activity stream.

    Returns all activities  about the given dataset, i.e. where the given
    dataset is the object of the activity, e.g.:

    "{USER} created the dataset {DATASET}"
    "{USER} updated the dataset {DATASET}"
    etc.

    '''
    q = _package_activity_query(package_id)
    return _activities_at_offset(q, limit, offset)


def _group_activity_query(group_id):
    '''Return an SQLAlchemy query for all activities about group_id.

    Returns a query for all activities whose object is either the group itself
    or one of the group's datasets.

    '''
    import ckan.model as model

    group = model.Group.get(group_id)
    if not group:
        # Return a query with no results.
        return model.Session.query(model.Activity).filter("0=1")

    dataset_ids = [dataset.id for dataset in group.packages()]

    q = model.Session.query(model.Activity)
    if dataset_ids:
        q = q.filter(or_(model.Activity.object_id == group_id,
            model.Activity.object_id.in_(dataset_ids)))
    else:
        q = q.filter(model.Activity.object_id == group_id)
    return q


def group_activity_list(group_id, limit, offset):
    '''Return the given group's public activity stream.

    Returns all activities where the given group or one of its datasets is the
    object of the activity, e.g.:

    "{USER} updated the group {GROUP}"
    "{USER} updated the dataset {DATASET}"
    etc.

    '''
    q = _group_activity_query(group_id)
    return _activities_at_offset(q, limit, offset)


def _activites_from_users_followed_by_user_query(user_id):
    '''Return a query for all activities from users that user_id follows.'''
    import ckan.model as model

    # Get a list of the users that the given user is following.
    follower_objects = model.UserFollowingUser.followee_list(user_id)
    if not follower_objects:
        # Return a query with no results.
        return model.Session.query(model.Activity).filter("0=1")

    q = _user_activity_query(follower_objects[0].object_id)
    q = q.union_all(*[_user_activity_query(follower.object_id)
        for follower in follower_objects[1:]])
    return q


def _activities_from_datasets_followed_by_user_query(user_id):
    '''Return a query for all activities from datasets that user_id follows.'''
    import ckan.model as model

    # Get a list of the datasets that the user is following.
    follower_objects = model.UserFollowingDataset.followee_list(user_id)
    if not follower_objects:
        # Return a query with no results.
        return model.Session.query(model.Activity).filter("0=1")

    q = _package_activity_query(follower_objects[0].object_id)
    q = q.union_all(*[_package_activity_query(follower.object_id)
        for follower in follower_objects[1:]])
    return q


def _activities_from_groups_followed_by_user_query(user_id):
    '''Return a query for all activities about groups the given user follows.

    Return a query for all activities about the groups the given user follows,
    or about any of the group's datasets. This is the union of
    _group_activity_query(group_id) for each of the groups the user follows.

    '''
    import ckan.model as model

    # Get a list of the group's that the user is following.
    follower_objects = model.UserFollowingGroup.followee_list(user_id)
    if not follower_objects:
        # Return a query with no results.
        return model.Session.query(model.Activity).filter("0=1")

    q = _group_activity_query(follower_objects[0].object_id)
    q = q.union_all(*[_group_activity_query(follower.object_id)
        for follower in follower_objects[1:]])
    return q


def _activities_from_everything_followed_by_user_query(user_id):
    '''Return a query for all activities from everything user_id follows.'''
    q = _activites_from_users_followed_by_user_query(user_id)
    q = q.union(_activities_from_datasets_followed_by_user_query(user_id))
    q = q.union(_activities_from_groups_followed_by_user_query(user_id))
    return q


def activities_from_everything_followed_by_user(user_id, limit, offset):
    '''Return activities from everything that the given user is following.

    Returns all activities where the object of the activity is anything
    (user, dataset, group...) that the given user is following.

    '''
    q = _activities_from_everything_followed_by_user_query(user_id)
    return _activities_at_offset(q, limit, offset)


def _dashboard_activity_query(user_id):
    '''Return an SQLAlchemy query for user_id's dashboard activity stream.'''
    q = _user_activity_query(user_id)
    q = q.union(_activities_from_everything_followed_by_user_query(user_id))
    return q


def dashboard_activity_list(user_id, limit, offset):
    '''Return the given user's dashboard activity stream.

    Returns activities from the user's public activity stream, plus
    activities from everything that the user is following.

    This is the union of user_activity_list(user_id) and
    activities_from_everything_followed_by_user(user_id).

    '''
    q = _dashboard_activity_query(user_id)
    return _activities_at_offset(q, limit, offset)

def _changed_packages_activity_query():
    '''Return an SQLAlchemyu query for all changed package activities.

    Return a query for all activities with activity_type '*package', e.g.
    'new_package', 'changed_package', 'deleted_package'.

    '''
    import ckan.model as model
    q = model.Session.query(model.Activity)
    q = q.filter(model.Activity.activity_type.endswith('package'))
    return q


def recently_changed_packages_activity_list(limit, offset):
    '''Return the site-wide stream of recently changed package activities.

    This activity stream includes recent 'new package', 'changed package' and
    'deleted package' activities for the whole site.

    '''
    q = _changed_packages_activity_query()
    return _activities_at_offset(q, limit, offset)

########NEW FILE########
__FILENAME__ = authz
'''For an overview of CKAN authorization system and model see
doc/authorization.rst.

'''
import simplejson as json
import weakref

from sqlalchemy import orm, types, Column, Table, ForeignKey
from pylons import config

import meta
import core
import domain_object
import package as _package
import group
import user as _user
import types as _types

__all__ = ['NotRealUserException', 'Enum', 'Action', 'Role', 'RoleAction',
           'UserObjectRole', 'PackageRole', 'GroupRole',
           'SystemRole', 'PSEUDO_USER__VISITOR',
           'PSEUDO_USER__LOGGED_IN', 'init_authz_const_data',
           'init_authz_configuration_data', 'add_user_to_role',
           'setup_user_roles', 'setup_default_user_roles',
           'give_all_packages_default_user_roles',
           'user_has_role', 'remove_user_from_role', 'clear_user_roles']

PSEUDO_USER__LOGGED_IN = u'logged_in'
PSEUDO_USER__VISITOR = u'visitor'

class NotRealUserException(Exception):
    pass

## ======================================
## Action and Role Enums

class Enum(object):
    @classmethod
    def is_valid(cls, val):
        return val in cls.get_all()

    @classmethod
    def get_all(cls):
        if not hasattr(cls, '_all_items'):
            vals = []
            for key, val in cls.__dict__.items():
                if not key.startswith('_'):
                    vals.append(val)
            cls._all_items = vals
        return cls._all_items

class Action(Enum):
    EDIT = u'edit'
    CHANGE_STATE = u'change-state'
    READ = u'read'
    PURGE = u'purge'
    EDIT_PERMISSIONS = u'edit-permissions'
    PACKAGE_CREATE = u'create-package'
    GROUP_CREATE = u'create-group'
    SITE_READ = u'read-site'
    USER_READ = u'read-user'
    USER_CREATE = u'create-user'
    UPLOAD_ACTION = u'file-upload'

class Role(Enum):
    ADMIN = u'admin'
    EDITOR = u'editor'
    ANON_EDITOR = u'anon_editor'
    READER = u'reader'

# These define what is meant by 'editor' and 'reader' for all ckan
# instances - locked down or otherwise. They get refreshed on every db_upgrade.
# So if you want to lock down an ckan instance, change Visitor and LoggedIn
# to have a new role which for which you can allow your customised actions.
default_role_actions = [
    (Role.EDITOR, Action.EDIT),
    (Role.EDITOR, Action.PACKAGE_CREATE),
    (Role.EDITOR, Action.GROUP_CREATE),
    (Role.EDITOR, Action.USER_CREATE),
    (Role.EDITOR, Action.USER_READ),
    (Role.EDITOR, Action.SITE_READ),
    (Role.EDITOR, Action.READ),
    (Role.EDITOR, Action.UPLOAD_ACTION),
    (Role.ANON_EDITOR, Action.EDIT),
    (Role.ANON_EDITOR, Action.PACKAGE_CREATE),
    (Role.ANON_EDITOR, Action.USER_CREATE),
    (Role.ANON_EDITOR, Action.USER_READ),
    (Role.ANON_EDITOR, Action.SITE_READ),
    (Role.ANON_EDITOR, Action.READ),
    (Role.ANON_EDITOR, Action.UPLOAD_ACTION),
    (Role.READER, Action.USER_CREATE),
    (Role.READER, Action.USER_READ),
    (Role.READER, Action.SITE_READ),
    (Role.READER, Action.READ),
    ]


## ======================================
## Table Definitions

role_action_table = Table('role_action', meta.metadata,
           Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
           Column('role', types.UnicodeText),
           Column('context', types.UnicodeText, nullable=False),
           Column('action', types.UnicodeText),
           )

user_object_role_table = Table('user_object_role', meta.metadata,
           Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
           Column('user_id', types.UnicodeText, ForeignKey('user.id'), nullable=True),
#           Column('authorized_group_id', types.UnicodeText, ForeignKey('authorization_group.id'), nullable=True),
           Column('context', types.UnicodeText, nullable=False), # stores subtype
           Column('role', types.UnicodeText)
           )

package_role_table = Table('package_role', meta.metadata,
           Column('user_object_role_id', types.UnicodeText, ForeignKey('user_object_role.id'), primary_key=True),
           Column('package_id', types.UnicodeText, ForeignKey('package.id')),
           )

group_role_table = Table('group_role', meta.metadata,
           Column('user_object_role_id', types.UnicodeText, ForeignKey('user_object_role.id'), primary_key=True),
           Column('group_id', types.UnicodeText, ForeignKey('group.id')),
           )

system_role_table = Table('system_role', meta.metadata,
           Column('user_object_role_id', types.UnicodeText, ForeignKey('user_object_role.id'), primary_key=True),
           )


class RoleAction(domain_object.DomainObject):
    def __repr__(self):
        return '<%s role="%s" action="%s" context="%s">' % \
               (self.__class__.__name__, self.role, self.action, self.context)


# dictionary mapping protected objects (e.g. Package) to related ObjectRole
protected_objects = {}

class UserObjectRole(domain_object.DomainObject):
    name = None
    protected_object = None

    def __repr__(self):
        if self.user:
            return '<%s user="%s" role="%s" context="%s">' % \
                (self.__class__.__name__, self.user.name, self.role, self.context)
        else:
            assert False, "UserObjectRole is not a user"

    @classmethod
    def get_object_role_class(cls, domain_obj):
        protected_object = protected_objects.get(domain_obj.__class__, None)
        if protected_object is None:
            # TODO: make into an authz exception
            msg = '%s is not a protected object, i.e. a subject of authorization' % domain_obj
            raise Exception(msg)
        else:
            return protected_object

    @classmethod
    def user_has_role(cls, user, role, domain_obj):
        assert isinstance(user, _user.User), user
        q = cls._user_query(user, role, domain_obj)
        return q.count() == 1


    @classmethod
    def _user_query(cls, user, role, domain_obj):
        q = meta.Session.query(cls).filter_by(role=role)
        # some protected objects are not "contextual"
        if cls.name is not None:
            # e.g. filter_by(package=domain_obj)
            q = q.filter_by(**dict({cls.name: domain_obj}))
        q = q.filter_by(user=user)
        return q


    @classmethod
    def add_user_to_role(cls, user, role, domain_obj):
        '''NB: Leaves the caller to commit the change. If called twice without a
        commit, will add the role to the database twice. Since some other
        functions count the number of occurrences, that leaves a fairly obvious
        bug. But adding a commit here seems to break various tests.
        So don't call this twice without committing, I guess...
        '''
        # Here we're trying to guard against adding the same role twice, but
        # that won't work if the transaction hasn't been committed yet, which allows a role to be added twice (you can do this from the interface)
        if cls.user_has_role(user, role, domain_obj):
            return
        objectrole = cls(role=role, user=user)
        if cls.name is not None:
            setattr(objectrole, cls.name, domain_obj)
        meta.Session.add(objectrole)


    @classmethod
    def remove_user_from_role(cls, user, role, domain_obj):
        q = cls._user_query(user, role, domain_obj)
        for uo_role in q.all():
            meta.Session.delete(uo_role)
        meta.Session.commit()
        meta.Session.remove()


class PackageRole(UserObjectRole):
    protected_object = _package.Package
    name = 'package'

    def __repr__(self):
        if self.user:
            return '<%s user="%s" role="%s" package="%s">' % \
                (self.__class__.__name__, self.user.name, self.role, self.package.name)
        else:
            assert False, "%s is not a user" % self.__class__.__name__

protected_objects[PackageRole.protected_object] = PackageRole

class GroupRole(UserObjectRole):
    protected_object = group.Group
    name = 'group'

    def __repr__(self):
        if self.user:
            return '<%s user="%s" role="%s" group="%s">' % \
                (self.__class__.__name__, self.user.name, self.role, self.group.name)
        else:
            assert False, "%s is not a user" % self.__class__.__name__

protected_objects[GroupRole.protected_object] = GroupRole


class SystemRole(UserObjectRole):
    protected_object = core.System
    name = None
protected_objects[SystemRole.protected_object] = SystemRole



## ======================================
## Helpers


def user_has_role(user, role, domain_obj):
    objectrole = UserObjectRole.get_object_role_class(domain_obj)
    return objectrole.user_has_role(user, role, domain_obj)

def add_user_to_role(user, role, domain_obj):
    objectrole = UserObjectRole.get_object_role_class(domain_obj)
    objectrole.add_user_to_role(user, role, domain_obj)

def remove_user_from_role(user, role, domain_obj):
    objectrole = UserObjectRole.get_object_role_class(domain_obj)
    objectrole.remove_user_from_role(user, role, domain_obj)


def init_authz_configuration_data():
    setup_default_user_roles(core.System())
    meta.Session.commit()
    meta.Session.remove()

def init_authz_const_data():
    '''Setup all default role-actions.

    These should be the same for all CKAN instances. Make custom roles if
    you want to divert from these.

    Note that Role.ADMIN can already do anything - hardcoded in.

    '''
    for role, action in default_role_actions:
        ra = meta.Session.query(RoleAction).filter_by(role=role, action=action).first()
        if ra is not None: continue
        ra = RoleAction(role=role, context=u'', action=action)
        meta.Session.add(ra)
    meta.Session.commit()
    meta.Session.remove()

## TODO: this should be removed
def setup_user_roles(_domain_object, visitor_roles, logged_in_roles, admins=[]):
    '''NB: leaves caller to commit change'''
    assert type(admins) == type([])
    admin_roles = [Role.ADMIN]
    visitor = _user.User.by_name(PSEUDO_USER__VISITOR)
    assert visitor
    for role in visitor_roles:
        add_user_to_role(visitor, role, _domain_object)
    logged_in = _user.User.by_name(PSEUDO_USER__LOGGED_IN)
    assert logged_in
    for role in logged_in_roles:
        add_user_to_role(logged_in, role, _domain_object)
    for admin in admins:
        # not sure if admin would reasonably by None
        if admin is not None:
            assert isinstance(admin, _user.User), admin
            if admin.name in (PSEUDO_USER__LOGGED_IN, PSEUDO_USER__VISITOR):
                raise NotRealUserException('Invalid user for domain object admin %r' % admin.name)
            for role in admin_roles:
                add_user_to_role(admin, role, _domain_object)

def give_all_packages_default_user_roles():
    # if this command gives an exception, you probably
    # forgot to do 'paster db init'
    pkgs = meta.Session.query(_package.Package).all()

    for pkg in pkgs:
        print pkg
        # weird - should already be in session but complains w/o this
        meta.Session.add(pkg)
        if len(pkg.roles) > 0:
            print 'Skipping (already has roles): %s' % pkg.name
            continue
        # work out the authors and make them admins
        admins = []
        revs = pkg.all_revisions
        for rev in revs:
            if rev.revision.author:
                # rev author is not Unicode!!
                user = _user.User.by_name(unicode(rev.revision.author))
                if user:
                    admins.append(user)
        # remove duplicates
        admins = list(set(admins))
        # gives default permissions
        print 'Creating default user for for %s with admins %s' % (pkg.name, admins)
        setup_default_user_roles(pkg, admins)

# default user roles - used when the config doesn\'t specify them
default_default_user_roles = {
    'Package': {"visitor": ["reader"], "logged_in": ["reader"]},
    'Group': {"visitor": ["reader"], "logged_in": ["reader"]},
    'System': {"visitor": ["reader"], "logged_in": ["editor"]},
    }

global _default_user_roles_cache
_default_user_roles_cache = weakref.WeakKeyDictionary()

def get_default_user_roles(_domain_object):
    # TODO: Should this func go in lib rather than model now?
    def _get_default_user_roles(_domain_object):
        config_key = 'ckan.default_roles.%s' % obj_type
        user_roles_json = config.get(config_key)
        if user_roles_json is None:
            user_roles_str = default_default_user_roles[obj_type]
        else:
            user_roles_str = json.loads(user_roles_json) if user_roles_json else {}
        unknown_keys = set(user_roles_str.keys()) - set(('visitor', 'logged_in'))
        assert not unknown_keys, 'Auth config for %r has unknown key %r' % \
               (_domain_object, unknown_keys)
        user_roles_ = {}
        for user in ('visitor', 'logged_in'):
            roles_str = user_roles_str.get(user, [])
            user_roles_[user] = [getattr(Role, role_str.upper()) for role_str in roles_str]
        return user_roles_
    obj_type = _domain_object.__class__.__name__
    global _default_user_roles_cache
    if not _default_user_roles_cache.has_key(_domain_object):
        _default_user_roles_cache[_domain_object] = _get_default_user_roles(_domain_object)
    return _default_user_roles_cache[_domain_object]

def setup_default_user_roles(_domain_object, admins=[]):
    ''' sets up roles for visitor, logged-in user and any admins provided
    @param admins - a list of User objects
    NB: leaves caller to commit change.
    '''
    assert isinstance(_domain_object, (_package.Package, group.Group, core.System)), _domain_object
    assert isinstance(admins, list)
    user_roles_ = get_default_user_roles(_domain_object)
    setup_user_roles(_domain_object,
                     user_roles_['visitor'],
                     user_roles_['logged_in'],
                     admins)

def clear_user_roles(_domain_object):
    assert isinstance(_domain_object, domain_object.DomainObject)
    if isinstance(_domain_object, _package.Package):
        q = meta.Session.query(PackageRole).filter_by(package=_domain_object)
    elif isinstance(_domain_object, group.Group):
        q = meta.Session.query(GroupRole).filter_by(group=_domain_object)
    else:
        raise NotImplementedError()
    user_roles = q.all()
    for user_role in user_roles:
        meta.Session.delete(user_role)


## ======================================
## Mappers

meta.mapper(RoleAction, role_action_table)

meta.mapper(UserObjectRole, user_object_role_table,
    polymorphic_on=user_object_role_table.c.context,
    polymorphic_identity=u'user_object',
    properties={
        'user': orm.relation(_user.User,
            backref=orm.backref('roles',
                cascade='all, delete, delete-orphan'
            )
        )
    },
    order_by=[user_object_role_table.c.id],
)

meta.mapper(PackageRole, package_role_table, inherits=UserObjectRole,
    polymorphic_identity=unicode(_package.Package.__name__),
    properties={
        'package': orm.relation(_package.Package,
             backref=orm.backref('roles',
             cascade='all, delete, delete-orphan'
             )
        ),
    },
    order_by=[package_role_table.c.user_object_role_id],
)

meta.mapper(GroupRole, group_role_table, inherits=UserObjectRole,
       polymorphic_identity=unicode(group.Group.__name__),
       properties={
            'group': orm.relation(group.Group,
                 backref=orm.backref('roles',
                 cascade='all, delete, delete-orphan'
                 ),
            )
    },
    order_by=[group_role_table.c.user_object_role_id],
)

meta.mapper(SystemRole, system_role_table, inherits=UserObjectRole,
       polymorphic_identity=unicode(core.System.__name__),
       order_by=[system_role_table.c.user_object_role_id],
)

########NEW FILE########
__FILENAME__ = core
import datetime

from sqlalchemy import Column, DateTime, Text, Boolean
import vdm.sqlalchemy

import meta
import domain_object


__all__ = ['System', 'Revision', 'State', 'revision_table']

## VDM-specific tables
revision_table = vdm.sqlalchemy.make_revision_table(meta.metadata)
revision_table.append_column(Column('approved_timestamp', DateTime))


class System(domain_object.DomainObject):

    name = 'system'

    def __unicode__(self):
        return u'<%s>' % self.__class__.__name__

    def purge(self):
        pass

    @classmethod
    def by_name(cls, name):
        return System()

# VDM-specific domain objects
State = vdm.sqlalchemy.State
State.all = [State.ACTIVE, State.DELETED]
Revision = vdm.sqlalchemy.make_Revision(meta.mapper, revision_table)


def make_revisioned_table(table):
    revision_table = vdm.sqlalchemy.make_revisioned_table(table)
    revision_table.append_column(Column('expired_id',
                                 Text))
    revision_table.append_column(Column('revision_timestamp', DateTime))
    revision_table.append_column(Column('expired_timestamp', DateTime,
                                 default=datetime.datetime(9999, 12, 31)))
    revision_table.append_column(Column('current', Boolean))
    return revision_table

########NEW FILE########
__FILENAME__ = dashboard
import datetime
import sqlalchemy
import meta

dashboard_table = sqlalchemy.Table('dashboard', meta.metadata,
    sqlalchemy.Column('user_id', sqlalchemy.types.UnicodeText,
            sqlalchemy.ForeignKey('user.id', onupdate='CASCADE',
                ondelete='CASCADE'),
            primary_key=True, nullable=False),
    sqlalchemy.Column('activity_stream_last_viewed', sqlalchemy.types.DateTime,
        nullable=False),
    sqlalchemy.Column('email_last_sent', sqlalchemy.types.DateTime,
        nullable=False)
)


class Dashboard(object):
    '''Saved data used for the user's dashboard.'''

    def __init__(self, user_id):
        self.user_id = user_id
        self.activity_stream_last_viewed = datetime.datetime.now()
        self.email_last_sent = datetime.datetime.now()

    @classmethod
    def get(cls, user_id):
        '''Return the Dashboard object for the given user_id.

        If there's no dashboard row in the database for this user_id, a fresh
        one will be created and returned.

        '''
        query = meta.Session.query(Dashboard)
        query = query.filter(Dashboard.user_id == user_id)
        try:
            row = query.one()
        except sqlalchemy.orm.exc.NoResultFound:
            row = Dashboard(user_id)
            meta.Session.add(row)
            meta.Session.commit()
        return row

meta.mapper(Dashboard, dashboard_table)

########NEW FILE########
__FILENAME__ = domain_object
import datetime

import sqlalchemy as sa
from sqlalchemy import orm
from sqlalchemy.util import OrderedDict

import meta
import core

__all__ = ['DomainObject', 'DomainObjectOperation']

class Enum(set):
    '''Simple enumeration
    e.g. Animal = Enum("dog", "cat", "horse")
    joey = Animal.DOG
    '''
    def __init__(self, *names):
        super(Enum, self).__init__(names)

    def __getattr__(self, name):
        if name in self:
            return name
        raise AttributeError

DomainObjectOperation = Enum('new', 'changed', 'deleted')

# TODO: replace this (or at least inherit from) standard SqlalchemyMixin in vdm
class DomainObject(object):

    text_search_fields = []
    Session = meta.Session

    def __init__(self, **kwargs):
        for k,v in kwargs.items():
            setattr(self, k, v)

    @classmethod
    def count(cls):
        cls.Session.query(cls).count()

    @classmethod
    def by_name(cls, name, autoflush=True):
        obj = meta.Session.query(cls).autoflush(autoflush)\
              .filter_by(name=name).first()
        return obj

    @classmethod
    def text_search(cls, query, term):
        register = cls
        make_like = lambda x,y: x.ilike('%' + y + '%')
        q = None
        for field in cls.text_search_fields:
            attr = getattr(register, field)
            q = sa.or_(q, make_like(attr, term))
        return query.filter(q)

    @classmethod
    def active(cls):
        return meta.Session.query(cls).filter_by(state=core.State.ACTIVE)

    def save(self):
        self.add()
        self.commit()

    def add(self):
        self.Session.add(self)

    def commit_remove(self):
        self.commit()
        self.remove()

    def commit(self):
        self.Session.commit()

    def remove(self):
        self.Session.remove()

    def delete(self):
        self.Session.delete(self)

    def purge(self):
        self.Session().autoflush = False
        if hasattr(self, '__revisioned__'): # only for versioned objects ...
            # this actually should auto occur due to cascade relationships but
            # ...
            for rev in self.all_revisions:
                self.Session.delete(rev)
        self.Session.delete(self)

    def as_dict(self):
        _dict = OrderedDict()
        table = orm.class_mapper(self.__class__).mapped_table
        for col in table.c:
            val = getattr(self, col.name)
            if isinstance(val, datetime.date):
                val = str(val)
            if isinstance(val, datetime.datetime):
                val = val.isoformat()
            _dict[col.name] = val
        return _dict

    def __str__(self):
        return self.__unicode__().encode('utf8')

    def __unicode__(self):
        repr = u'<%s' % self.__class__.__name__
        table = orm.class_mapper(self.__class__).mapped_table
        for col in table.c:
            try:
                repr += u' %s=%s' % (col.name, getattr(self, col.name))
            except Exception, inst:
                repr += u' %s=%s' % (col.name, inst)

        repr += '>'
        return repr

    def __repr__(self):
        return self.__unicode__().encode('utf-8')

########NEW FILE########
__FILENAME__ = extension
"""
Provides bridges between the model and plugin PluginImplementationss
"""
import logging

from sqlalchemy.orm.interfaces import MapperExtension
from sqlalchemy.orm.session import SessionExtension

import ckan.plugins as plugins

try:
    from operator import methodcaller
except ImportError:
    def methodcaller(name, *args, **kwargs):
        "Replaces stdlib operator.methodcaller in python <2.6"
        def caller(obj):
            return getattr(obj, name)(*args, **kwargs)
        return caller

log = logging.getLogger(__name__)

class ObserverNotifier(object):
    """
    Mixin for hooking into SQLAlchemy
    MapperExtension/SessionExtension
    """

    observers = None


class PluginMapperExtension(MapperExtension):
    """
    Extension that calls plugins implementing IMapper on SQLAlchemy
    MapperExtension events
    """

    def notify_observers(self, func):
        """
        Call func(observer) for all registered observers.

        :param func: Any callable, which will be called for each observer
        :returns: EXT_CONTINUE if no errors encountered, otherwise EXT_STOP
        """
        for observer in plugins.PluginImplementations(plugins.IMapper):
            func(observer)

    def before_insert(self, mapper, connection, instance):
        return self.notify_observers(
            methodcaller('before_insert', mapper, connection, instance)
        )

    def before_update(self, mapper, connection, instance):
        return self.notify_observers(
            methodcaller('before_update', mapper, connection, instance)
        )

    def before_delete(self, mapper, connection, instance):
        return self.notify_observers(
            methodcaller('before_delete', mapper, connection, instance)
        )

    def after_insert(self, mapper, connection, instance):
        return self.notify_observers(
            methodcaller('after_insert', mapper, connection, instance)
        )

    def after_update(self, mapper, connection, instance):
        return self.notify_observers(
            methodcaller('after_update', mapper, connection, instance)
        )

    def after_delete(self, mapper, connection, instance):
        return self.notify_observers(
            methodcaller('after_delete', mapper, connection, instance)
        )


class PluginSessionExtension(SessionExtension):
    """
    Class that calls plugins implementing ISession on SQLAlchemy
    SessionExtension events
    """

    def notify_observers(self, func):
        """
        Call func(observer) for all registered observers.

        :param func: Any callable, which will be called for each observer
        :returns: EXT_CONTINUE if no errors encountered, otherwise EXT_STOP
        """
        for observer in plugins.PluginImplementations(plugins.ISession):
            func(observer)


    def after_begin(self, session, transaction, connection):
        return self.notify_observers(
            methodcaller('after_begin', session, transaction, connection)
        )

    def before_flush(self, session, flush_context, instances):
        return self.notify_observers(
            methodcaller('before_flush', session, flush_context, instances)
        )

    def after_flush(self, session, flush_context):
        return self.notify_observers(
            methodcaller('after_flush', session, flush_context)
        )

    def before_commit(self, session):
        return self.notify_observers(
            methodcaller('before_commit', session)
        )

    def after_commit(self, session):
        return self.notify_observers(
            methodcaller('after_commit', session)
        )

    def after_rollback(self, session):
        return self.notify_observers(
            methodcaller('after_rollback', session)
        )


########NEW FILE########
__FILENAME__ = follower
import meta
import datetime
import sqlalchemy

import core
import ckan.model
import domain_object


class ModelFollowingModel(domain_object.DomainObject):
    def __init__(self, follower_id, object_id):
        self.follower_id = follower_id
        self.object_id = object_id
        self.datetime = datetime.datetime.now()

    @classmethod
    def get(cls, follower_id, object_id):
        '''Return a ModelFollowingModel object for the given follower_id and
        object_id, or None if no such follower exists.

        '''
        query = cls._get(follower_id, object_id)
        following = cls._filter_following_objects(query)
        if len(following) == 1:
            return following[0]

    @classmethod
    def is_following(cls, follower_id, object_id):
        '''Return True if follower_id is currently following object_id, False
        otherwise.

        '''
        return cls.get(follower_id, object_id) is not None

    @classmethod
    def followee_count(cls, follower_id):
        '''Return the number of objects followed by the follower.'''
        return cls._get_followees(follower_id).count()

    @classmethod
    def followee_list(cls, follower_id):
        '''Return a list of objects followed by the follower.'''
        query = cls._get_followees(follower_id).all()
        followees = cls._filter_following_objects(query)
        return followees

    @classmethod
    def follower_count(cls, object_id):
        '''Return the number of followers of the object.'''
        return cls._get_followers(object_id).count()

    @classmethod
    def follower_list(cls, object_id):
        '''Return a list of followers of the object.'''
        query = cls._get_followers(object_id).all()
        followers = cls._filter_following_objects(query)
        return followers

    @classmethod
    def _filter_following_objects(cls, query):
        return [q[0] for q in query]

    @classmethod
    def _get_followees(cls, follower_id):
        return cls._get(follower_id)

    @classmethod
    def _get_followers(cls, object_id):
        return cls._get(None, object_id)

    @classmethod
    def _get(cls, follower_id=None, object_id=None):
        follower_alias = sqlalchemy.orm.aliased(cls._follower_class())
        object_alias = sqlalchemy.orm.aliased(cls._object_class())

        follower_id = follower_id or cls.follower_id
        object_id = object_id or cls.object_id

        query = meta.Session.query(cls, follower_alias, object_alias)\
            .filter(sqlalchemy.and_(
                follower_alias.id == follower_id,
                cls.follower_id == follower_alias.id,
                cls.object_id == object_alias.id,
                follower_alias.state != core.State.DELETED,
                object_alias.state != core.State.DELETED,
                object_alias.id == object_id))

        return query


class UserFollowingUser(ModelFollowingModel):
    '''A many-many relationship between users.

    A relationship between one user (the follower) and another (the object),
    that means that the follower is currently following the object.

    '''
    @classmethod
    def _follower_class(cls):
        return ckan.model.User

    @classmethod
    def _object_class(cls):
        return ckan.model.User


user_following_user_table = sqlalchemy.Table('user_following_user',
        meta.metadata,
    sqlalchemy.Column('follower_id', sqlalchemy.types.UnicodeText,
        sqlalchemy.ForeignKey('user.id', onupdate='CASCADE',
            ondelete='CASCADE'),
        primary_key=True, nullable=False),
    sqlalchemy.Column('object_id', sqlalchemy.types.UnicodeText,
        sqlalchemy.ForeignKey('user.id', onupdate='CASCADE',
            ondelete='CASCADE'),
        primary_key=True, nullable=False),
    sqlalchemy.Column('datetime', sqlalchemy.types.DateTime, nullable=False),
)

meta.mapper(UserFollowingUser, user_following_user_table)

class UserFollowingDataset(ModelFollowingModel):
    '''A many-many relationship between users and datasets (packages).

    A relationship between a user (the follower) and a dataset (the object),
    that means that the user is currently following the dataset.

    '''
    @classmethod
    def _follower_class(cls):
        return ckan.model.User

    @classmethod
    def _object_class(cls):
        return ckan.model.Package


user_following_dataset_table = sqlalchemy.Table('user_following_dataset',
        meta.metadata,
    sqlalchemy.Column('follower_id', sqlalchemy.types.UnicodeText,
        sqlalchemy.ForeignKey('user.id', onupdate='CASCADE',
            ondelete='CASCADE'),
        primary_key=True, nullable=False),
    sqlalchemy.Column('object_id', sqlalchemy.types.UnicodeText,
        sqlalchemy.ForeignKey('package.id', onupdate='CASCADE',
            ondelete='CASCADE'),
        primary_key=True, nullable=False),
    sqlalchemy.Column('datetime', sqlalchemy.types.DateTime, nullable=False),
)

meta.mapper(UserFollowingDataset, user_following_dataset_table)


class UserFollowingGroup(ModelFollowingModel):
    '''A many-many relationship between users and groups.

    A relationship between a user (the follower) and a group (the object),
    that means that the user is currently following the group.

    '''
    @classmethod
    def _follower_class(cls):
        return ckan.model.User

    @classmethod
    def _object_class(cls):
        return ckan.model.Group

user_following_group_table = sqlalchemy.Table('user_following_group',
        meta.metadata,
    sqlalchemy.Column('follower_id', sqlalchemy.types.UnicodeText,
        sqlalchemy.ForeignKey('user.id', onupdate='CASCADE',
            ondelete='CASCADE'),
        primary_key=True, nullable=False),
    sqlalchemy.Column('object_id', sqlalchemy.types.UnicodeText,
        sqlalchemy.ForeignKey('group.id', onupdate='CASCADE',
            ondelete='CASCADE'),
        primary_key=True, nullable=False),
    sqlalchemy.Column('datetime', sqlalchemy.types.DateTime, nullable=False),
)

meta.mapper(UserFollowingGroup, user_following_group_table)

########NEW FILE########
__FILENAME__ = group
import datetime

from sqlalchemy import orm, types, Column, Table, ForeignKey, or_, and_
import vdm.sqlalchemy

import meta
import core
import package as _package
import types as _types
import domain_object
import user as _user

__all__ = ['group_table', 'Group',
           'Member', 'GroupRevision', 'MemberRevision',
           'member_revision_table', 'member_table']

member_table = Table('member', meta.metadata,
                     Column('id', types.UnicodeText,
                            primary_key=True,
                            default=_types.make_uuid),
                     Column('table_name', types.UnicodeText,
                            nullable=False),
                     Column('table_id', types.UnicodeText,
                            nullable=False),
                     Column('capacity', types.UnicodeText,
                            nullable=False),
                     Column('group_id', types.UnicodeText,
                            ForeignKey('group.id')),)

vdm.sqlalchemy.make_table_stateful(member_table)
member_revision_table = core.make_revisioned_table(member_table)

group_table = Table('group', meta.metadata,
                    Column('id', types.UnicodeText,
                           primary_key=True,
                           default=_types.make_uuid),
                    Column('name', types.UnicodeText,
                           nullable=False, unique=True),
                    Column('title', types.UnicodeText),
                    Column('type', types.UnicodeText,
                           nullable=False),
                    Column('description', types.UnicodeText),
                    Column('image_url', types.UnicodeText),
                    Column('created', types.DateTime,
                           default=datetime.datetime.now),
                    Column('is_organization', types.Boolean, default=False),
                    Column('approval_status', types.UnicodeText,
                           default=u"approved"))

vdm.sqlalchemy.make_table_stateful(group_table)
group_revision_table = core.make_revisioned_table(group_table)


class Member(vdm.sqlalchemy.RevisionedObjectMixin,
             vdm.sqlalchemy.StatefulObjectMixin,
             domain_object.DomainObject):
    '''A Member object represents any other object being a 'member' of a
    particular Group.

    Meanings:
    * Package - the Group is a collection of Packages
                 - capacity is 'public', 'private'
                   or 'organization' if the Group is an Organization
                   (see ckan.logic.action.package_owner_org_update)
    * User - the User is granted permissions for the Group
                 - capacity is 'admin', 'editor' or 'member'
    * Group - the Group (Member.group_id) is a parent of the Group (Member.id)
              in a hierarchy.
                 - capacity is 'parent'
    '''
    def __init__(self, group=None, table_id=None, group_id=None,
                 table_name=None, capacity='public', state='active'):
        self.group = group
        self.group_id = group_id
        self.table_id = table_id
        self.table_name = table_name
        self.capacity = capacity
        self.state = state

    @classmethod
    def get(cls, reference):
        '''Returns a group object referenced by its id or name.'''
        query = meta.Session.query(cls).filter(cls.id == reference)
        member = query.first()
        if member is None:
            member = cls.by_name(reference)
        return member

    def get_related(self, type):
        """ TODO: Determine if this is useful
            Get all objects that are members of the group of the specified
            type.

            Should the type be used to get table_name or should we use the
            one in the constructor
        """
        pass

    def related_packages(self):
        # TODO do we want to return all related packages or certain ones?
        return meta.Session.query(_package.Package).filter_by(
            id=self.table_id).all()

    def __unicode__(self):
        # refer to objects by name, not ID, to help debugging
        if self.table_name == 'package':
            table_info = 'package=%s' % meta.Session.query(_package.Package).\
                get(self.table_id).name
        elif self.table_name == 'group':
            table_info = 'group=%s' % meta.Session.query(Group).\
                get(self.table_id).name
        else:
            table_info = 'table_name=%s table_id=%s' % (self.table_name,
                                                        self.table_id)
        return u'<Member group=%s %s capacity=%s state=%s>' % \
               (self.group.name if self.group else repr(self.group),
                table_info, self.capacity, self.state)


class Group(vdm.sqlalchemy.RevisionedObjectMixin,
            vdm.sqlalchemy.StatefulObjectMixin,
            domain_object.DomainObject):

    def __init__(self, name=u'', title=u'', description=u'', image_url=u'',
                 type=u'group', approval_status=u'approved'):
        self.name = name
        self.title = title
        self.description = description
        self.image_url = image_url
        self.type = type
        self.approval_status = approval_status

    @property
    def display_name(self):
        if self.title is not None and len(self.title):
            return self.title
        else:
            return self.name

    @classmethod
    def get(cls, reference):
        '''Returns a group object referenced by its id or name.'''
        query = meta.Session.query(cls).filter(cls.id == reference)
        group = query.first()
        if group is None:
            group = cls.by_name(reference)
        return group
    # Todo: Make sure group names can't be changed to look like group IDs?

    @classmethod
    def all(cls, group_type=None, state=('active',)):
        """
        Returns all groups.
        """
        q = meta.Session.query(cls)
        if state:
            q = q.filter(cls.state.in_(state))

        if group_type:
            q = q.filter(cls.type == group_type)

        return q.order_by(cls.title)

    def set_approval_status(self, status):
        """
            Aproval status can be set on a group, where currently it does
            nothing other than act as an indication of whether it was
            approved or not. It may be that we want to tie the object
            status to the approval status
        """
        assert status in ["approved", "pending", "denied"]
        self.approval_status = status
        if status == "denied":
            pass

    def get_children_groups(self, type='group'):
        '''Returns the groups one level underneath this group in the hierarchy.
        '''
        # The original intention of this method was to provide the full depth
        # of the tree, but the CTE was incorrect. This new query does what that
        # old CTE actually did, but is now far simpler, and returns Group objects
        # instead of a dict.
        return meta.Session.query(Group).\
                     filter_by(type=type).\
                     filter_by(state='active').\
                     join(Member, Member.group_id == Group.id).\
                     filter_by(table_id=self.id).\
                     filter_by(table_name='group').\
                     filter_by(state='active').\
                     all()

    def get_children_group_hierarchy(self, type='group'):
        '''Returns the groups in all levels underneath this group in the
        hierarchy. The ordering is such that children always come after their
        parent.

        :rtype: a list of tuples, each one a Group ID, name and title and then
        the ID of its parent group.

        e.g. 
        >>> dept-health.get_children_group_hierarchy()
        [(u'8ac0...', u'national-health-service', u'National Health Service', u'e041...'), 
         (u'b468...', u'nhs-wirral-ccg', u'NHS Wirral CCG', u'8ac0...')]
        '''
        results = meta.Session.query(Group.id, Group.name, Group.title,
                                     'parent_id').\
            from_statement(HIERARCHY_DOWNWARDS_CTE).\
            params(id=self.id, type=type).all()
        return results

    def get_parent_groups(self, type='group'):
        '''Returns this group's parent groups.
        Returns a list. Will have max 1 value for organizations.

        '''
        return meta.Session.query(Group).\
            join(Member,
                 and_(Member.table_id == Group.id,
                      Member.table_name == 'group',
                      Member.state == 'active')).\
            filter(Member.group_id == self.id).\
            filter(Group.type == type).\
            filter(Group.state == 'active').\
            all()

    def get_parent_group_hierarchy(self, type='group'):
        '''Returns this group's parent, parent's parent, parent's parent's
        parent etc.. Sorted with the top level parent first.'''
        return meta.Session.query(Group).\
            from_statement(HIERARCHY_UPWARDS_CTE).\
            params(id=self.id, type=type).all()

    @classmethod
    def get_top_level_groups(cls, type='group'):
        '''Returns a list of the groups (of the specified type) which have
        no parent groups. Groups are sorted by title.
        '''
        return meta.Session.query(cls).\
            outerjoin(Member,
                      and_(Member.group_id == Group.id,
                           Member.table_name == 'group',
                           Member.state == 'active')).\
            filter(Member.id == None).\
            filter(Group.type == type).\
            filter(Group.state == 'active').\
            order_by(Group.title).all()

    def groups_allowed_to_be_its_parent(self, type='group'):
        '''Returns a list of the groups (of the specified type) which are
        allowed to be this group's parent. It excludes ones which would
        create a loop in the hierarchy, causing the recursive CTE to
        be in an infinite loop.

        :returns: A list of group objects ordered by group title

        '''
        all_groups = self.all(group_type=type)
        excluded_groups = set(group_name
                              for group_id, group_name, group_title, parent in
                              self.get_children_group_hierarchy(type=type))
        excluded_groups.add(self.name)
        return [group for group in all_groups
                if group.name not in excluded_groups]

    def packages(self, with_private=False, limit=None,
            return_query=False, context=None):
        '''Return this group's active and pending packages.

        Returns all packages in this group with VDM revision state ACTIVE or
        PENDING.

        :param with_private: if True, include the group's private packages
        :type with_private: boolean

        :param limit: the maximum number of packages to return
        :type limit: int

        :param return_query: if True, return the SQLAlchemy query object
            instead of the list of Packages resulting from the query
        :type return_query: boolean

        :returns: a list of this group's packages
        :rtype: list of ckan.model.package.Package objects

        '''
        user_is_org_member = False
        context = context or {}
        user_is_admin = context.get('user_is_admin', False)
        user_id = context.get('user_id')
        if user_is_admin:
            user_is_org_member = True

        elif self.is_organization and user_id:
            query = meta.Session.query(Member) \
                    .filter(Member.state == 'active') \
                    .filter(Member.table_name == 'user') \
                    .filter(Member.group_id == self.id) \
                    .filter(Member.table_id == user_id)
            user_is_org_member = len(query.all()) != 0

        query = meta.Session.query(_package.Package).\
            filter(
                or_(_package.Package.state == core.State.ACTIVE,
                    _package.Package.state == core.State.PENDING)). \
            filter(group_table.c.id == self.id).\
            filter(member_table.c.state == 'active')

        # orgs do not show private datasets unless the user is a member
        if self.is_organization and not user_is_org_member:
            query = query.filter(_package.Package.private == False)
        # groups (not orgs) never show private datasets
        if not self.is_organization:
            query = query.filter(_package.Package.private == False)

        query = query.join(member_table,
                member_table.c.table_id == _package.Package.id)
        query = query.join(group_table,
                group_table.c.id == member_table.c.group_id)

        if limit is not None:
            query = query.limit(limit)

        if return_query:
            return query
        else:
            return query.all()

    @classmethod
    def search_by_name_or_title(cls, text_query, group_type=None, is_org=False):
        text_query = text_query.strip().lower()
        q = meta.Session.query(cls) \
            .filter(or_(cls.name.contains(text_query),
                        cls.title.ilike('%' + text_query + '%')))
        if is_org:
            q = q.filter(cls.type == 'organization')
        else:
            q = q.filter(cls.type != 'organization')
            if group_type:
                q = q.filter(cls.type == group_type)
        q = q.filter(cls.state == 'active')
        return q.order_by(cls.title)

    def add_package_by_name(self, package_name):
        if not package_name:
            return
        package = _package.Package.by_name(package_name)
        assert package
        if not package in self.packages():
            member = Member(group=self, table_id=package.id,
                            table_name='package')
            meta.Session.add(member)

    @property
    def all_related_revisions(self):
        '''Returns chronological list of all object revisions related to
        this group. Ordered by most recent first.
        '''
        results = {}
        from group_extra import GroupExtra
        for grp_rev in self.all_revisions:
            if not grp_rev.revision in results:
                results[grp_rev.revision] = []
            results[grp_rev.revision].append(grp_rev)
        for class_ in [Member, GroupExtra]:
            rev_class = class_.__revision_class__
            obj_revisions = meta.Session.query(rev_class).\
                filter_by(group_id=self.id).all()
            for obj_rev in obj_revisions:
                if not obj_rev.revision in results:
                    results[obj_rev.revision] = []
                results[obj_rev.revision].append(obj_rev)
        result_list = results.items()
        ourcmp = lambda rev_tuple1, rev_tuple2: \
            cmp(rev_tuple2[0].timestamp, rev_tuple1[0].timestamp)
        return sorted(result_list, cmp=ourcmp)

    def __repr__(self):
        return '<Group %s>' % self.name

meta.mapper(Group, group_table,
            extension=[vdm.sqlalchemy.Revisioner(group_revision_table), ], )

vdm.sqlalchemy.modify_base_object_mapper(Group, core.Revision, core.State)
GroupRevision = vdm.sqlalchemy.create_object_version(meta.mapper, Group,
                                                     group_revision_table)

meta.mapper(Member, member_table, properties={
    'group': orm.relation(Group,
                          backref=orm.backref('member_all',
                                              cascade='all, delete-orphan')),
},
    extension=[vdm.sqlalchemy.Revisioner(member_revision_table), ],
)


vdm.sqlalchemy.modify_base_object_mapper(Member, core.Revision, core.State)
MemberRevision = vdm.sqlalchemy.create_object_version(meta.mapper, Member,
                                                      member_revision_table)

#TODO
MemberRevision.related_packages = lambda self: [self.continuity.package]

# Should there arise a bug that allows loops in the group hierarchy, then it
# will lead to infinite recursion, tieing up postgres processes at 100%, and
# the server will suffer. To avoid ever failing this badly, we put in this
# limit on recursion.
MAX_RECURSES = 8

HIERARCHY_DOWNWARDS_CTE = """WITH RECURSIVE child(depth) AS
(
    -- non-recursive term
    SELECT 0, * FROM member
    WHERE table_id = :id AND table_name = 'group' AND state = 'active'
    UNION ALL
    -- recursive term
    SELECT c.depth + 1, m.* FROM member AS m, child AS c
    WHERE m.table_id = c.group_id AND m.table_name = 'group'
          AND m.state = 'active' AND c.depth < {max_recurses}
)
SELECT G.id, G.name, G.title, child.depth, child.table_id as parent_id FROM child
    INNER JOIN public.group G ON G.id = child.group_id
    WHERE G.type = :type AND G.state='active'
    ORDER BY child.depth ASC;""".format(max_recurses=MAX_RECURSES)

HIERARCHY_UPWARDS_CTE = """WITH RECURSIVE parenttree(depth) AS (
    -- non-recursive term
    SELECT 0, M.* FROM public.member AS M
    WHERE group_id = :id AND M.table_name = 'group' AND M.state = 'active'
    UNION
    -- recursive term
    SELECT PG.depth + 1, M.* FROM parenttree PG, public.member M
    WHERE PG.table_id = M.group_id AND M.table_name = 'group'
          AND M.state = 'active' AND PG.depth < {max_recurses}
    )

SELECT G.*, PT.depth FROM parenttree AS PT
    INNER JOIN public.group G ON G.id = PT.table_id
    WHERE G.type = :type AND G.state='active'
    ORDER BY PT.depth DESC;""".format(max_recurses=MAX_RECURSES)


########NEW FILE########
__FILENAME__ = group_extra
import vdm.sqlalchemy
import vdm.sqlalchemy.stateful
from sqlalchemy import orm, types, Column, Table, ForeignKey

import group
import meta
import core
import types as _types
import domain_object


__all__ = ['GroupExtra', 'group_extra_table', 'GroupExtraRevision']

group_extra_table = Table('group_extra', meta.metadata,
    Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
    Column('group_id', types.UnicodeText, ForeignKey('group.id')),
    Column('key', types.UnicodeText),
    Column('value', types.UnicodeText),
)

vdm.sqlalchemy.make_table_stateful(group_extra_table)
group_extra_revision_table = core.make_revisioned_table(group_extra_table)


class GroupExtra(vdm.sqlalchemy.RevisionedObjectMixin,
        vdm.sqlalchemy.StatefulObjectMixin,
        domain_object.DomainObject):
    pass

meta.mapper(GroupExtra, group_extra_table, properties={
    'group': orm.relation(group.Group,
        backref=orm.backref('_extras',
            collection_class=orm.collections.attribute_mapped_collection(u'key'),
            cascade='all, delete, delete-orphan',
            ),
        )
    },
    order_by=[group_extra_table.c.group_id, group_extra_table.c.key],
    extension=[vdm.sqlalchemy.Revisioner(group_extra_revision_table),],
)

vdm.sqlalchemy.modify_base_object_mapper(GroupExtra, core.Revision, core.State)
GroupExtraRevision = vdm.sqlalchemy.create_object_version(meta.mapper, GroupExtra,
    group_extra_revision_table)

def _create_extra(key, value):
    return GroupExtra(key=unicode(key), value=value)

_extras_active = vdm.sqlalchemy.stateful.DeferredProperty('_extras',
        vdm.sqlalchemy.stateful.StatefulDict, base_modifier=lambda x: x.get_as_of()) 
setattr(group.Group, 'extras_active', _extras_active)
group.Group.extras = vdm.sqlalchemy.stateful.OurAssociationProxy('extras_active', 'value',
            creator=_create_extra)

########NEW FILE########
__FILENAME__ = license
import datetime
import urllib2
import re

from pylons import config

from ckan.common import _, json


class License(object):
    """Domain object for a license."""

    def __init__(self, data):
        self._data = data
        for (key, value) in self._data.items():
            if key == 'date_created':
                # Parse ISO formatted datetime.
                value = datetime.datetime(*map(int, re.split('[^\d]', value)))
                self._data[key] = value
            elif isinstance(value, str):
                # Convert str to unicode (keeps Pylons and SQLAlchemy happy).
                value = value.decode('utf8')
                self._data[key] = value

    def __getattr__(self, name):
        return self._data[name]

    def __getitem__(self, key):
        return self._data[key]

    def isopen(self):
        return self.is_okd_compliant or self.is_osi_compliant

    def as_dict(self):
        data = self._data.copy()
        if 'date_created' in data:
            value = data['date_created']
            value = value.isoformat()
            data['date_created'] = value
        return data


class LicenseRegister(object):
    """Dictionary-like interface to a group of licenses."""

    def __init__(self):
        group_url = config.get('licenses_group_url', None)
        if group_url:
            self.load_licenses(group_url)
        else:
            default_license_list = [
                LicenseNotSpecified(),
                LicenseOpenDataCommonsPDDL(),
                LicenseOpenDataCommonsOpenDatabase(),
                LicenseOpenDataAttribution(),
                LicenseCreativeCommonsZero(),
                LicenseCreativeCommonsAttribution(),
                LicenseCreativeCommonsAttributionShareAlike(),
                LicenseGNUFreeDocument(),
                LicenseOtherOpen(),
                LicenseOtherPublicDomain(),
                LicenseOtherAttribution(),
                LicenseOpenGovernment(),
                LicenseCreativeCommonsNonCommercial(),
                LicenseOtherNonCommercial(),
                LicenseOtherClosed(),
                ]
            self._create_license_list(default_license_list)

    def load_licenses(self, license_url):
        try:
            response = urllib2.urlopen(license_url)
            response_body = response.read()
        except Exception, inst:
            msg = "Couldn't connect to licenses service %r: %s" % (license_url, inst)
            raise Exception, msg
        try:
            license_data = json.loads(response_body)
        except Exception, inst:
            msg = "Couldn't read response from licenses service %r: %s" % (response_body, inst)
            raise Exception, inst
        self._create_license_list(license_data, license_url)

    def _create_license_list(self, license_data, license_url=''):
        if isinstance(license_data, dict):
            self.licenses = [License(entity) for entity in license_data.values()]
        elif isinstance(license_data, list):
            self.licenses = [License(entity) for entity in license_data]
        else:
            msg = "Licenses at %s must be dictionary or list" % license_url
            raise ValueError(msg)

    def __getitem__(self, key, default=Exception):
        for license in self.licenses:
            if key == license.id:
                return license
        if default != Exception:
            return default
        else:
            raise KeyError, "License not found: %s" % key

    def get(self, key, default=None):
        return self.__getitem__(key, default=default)

    def keys(self):
        return [license.id for license in self.licenses]

    def values(self):
        return self.licenses

    def items(self):
        return [(license.id, license) for license in self.licenses]

    def __iter__(self):
        return iter(self.keys())

    def __len__(self):
        return len(self.licenses)



class DefaultLicense(dict):
    ''' The license was a dict but this did not allow translation of the
    title.  This is a slightly changed dict that allows us to have the title
    as a property and so translated. '''

    domain_content = False
    domain_data = False
    domain_software = False
    family = ""
    is_generic = False
    is_okd_compliant = False
    is_osi_compliant = False
    maintainer = ""
    status = "active"
    url = ""
    title = ''
    id = ''

    keys = ['domain_content',
            'id',
            'domain_data',
            'domain_software',
            'family',
            'is_generic',
            'is_okd_compliant',
            'is_osi_compliant',
            'maintainer',
            'status',
            'url',
            'title']

    def __getitem__(self, key):
        ''' behave like a dict but get from attributes '''
        if key in self.keys:
            value = getattr(self, key)
            if isinstance(value, str):
                return unicode(value)
            else:
                return value
        else:
            raise KeyError()

    def copy(self):
        ''' create a dict of the license used by the licenses api '''
        out = {}
        for key in self.keys:
            out[key] = unicode(getattr(self, key))
        return out

class LicenseNotSpecified(DefaultLicense):
    id = "notspecified"
    is_generic = True

    @property
    def title(self):
        return _("License not specified")

class LicenseOpenDataCommonsPDDL(DefaultLicense):
    domain_data = True
    id = "odc-pddl"
    is_okd_compliant = True
    url = "http://www.opendefinition.org/licenses/odc-pddl"

    @property
    def title(self):
        return _("Open Data Commons Public Domain Dedication and License (PDDL)")

class LicenseOpenDataCommonsOpenDatabase(DefaultLicense):
    domain_data = True
    id = "odc-odbl"
    is_okd_compliant = True
    url = "http://www.opendefinition.org/licenses/odc-odbl"

    @property
    def title(self):
        return _("Open Data Commons Open Database License (ODbL)")

class LicenseOpenDataAttribution(DefaultLicense):
    domain_data = True
    id = "odc-by"
    is_okd_compliant = True
    url = "http://www.opendefinition.org/licenses/odc-by"

    @property
    def title(self):
        return _("Open Data Commons Attribution License")

class LicenseCreativeCommonsZero(DefaultLicense):
    domain_content = True
    domain_data = True
    id = "cc-zero"
    is_okd_compliant = True
    url = "http://www.opendefinition.org/licenses/cc-zero"

    @property
    def title(self):
        return _("Creative Commons CCZero")

class LicenseCreativeCommonsAttribution(DefaultLicense):
    id = "cc-by"
    is_okd_compliant = True
    url = "http://www.opendefinition.org/licenses/cc-by"

    @property
    def title(self):
        return _("Creative Commons Attribution")

class LicenseCreativeCommonsAttributionShareAlike(DefaultLicense):
    domain_content = True
    id = "cc-by-sa"
    is_okd_compliant = True
    url = "http://www.opendefinition.org/licenses/cc-by-sa"

    @property
    def title(self):
        return _("Creative Commons Attribution Share-Alike")

class LicenseGNUFreeDocument(DefaultLicense):
    domain_content = True
    id = "gfdl"
    is_okd_compliant = True
    url = "http://www.opendefinition.org/licenses/gfdl"
    @property
    def title(self):
        return _("GNU Free Documentation License")

class LicenseOtherOpen(DefaultLicense):
    domain_content = True
    id = "other-open"
    is_generic = True
    is_okd_compliant = True

    @property
    def title(self):
        return _("Other (Open)")

class LicenseOtherPublicDomain(DefaultLicense):
    domain_content = True
    id = "other-pd"
    is_generic = True
    is_okd_compliant = True

    @property
    def title(self):
        return _("Other (Public Domain)")

class LicenseOtherAttribution(DefaultLicense):
    domain_content = True
    id = "other-at"
    is_generic = True
    is_okd_compliant = True

    @property
    def title(self):
        return _("Other (Attribution)")

class LicenseOpenGovernment(DefaultLicense):
    domain_content = True
    id = "uk-ogl"
    is_okd_compliant = True
    # CS: bad_spelling ignore
    url = "http://reference.data.gov.uk/id/open-government-licence"

    @property
    def title(self):
        # CS: bad_spelling ignore
        return _("UK Open Government Licence (OGL)")

class LicenseCreativeCommonsNonCommercial(DefaultLicense):
    id = "cc-nc"
    url = "http://creativecommons.org/licenses/by-nc/2.0/"

    @property
    def title(self):
        return _("Creative Commons Non-Commercial (Any)")

class LicenseOtherNonCommercial(DefaultLicense):
    id = "other-nc"
    is_generic = True

    @property
    def title(self):
        return _("Other (Non-Commercial)")

class LicenseOtherClosed(DefaultLicense):
    id = "other-closed"
    is_generic = True

    @property
    def title(self):
        return _("Other (Not Open)")

########NEW FILE########
__FILENAME__ = meta
import datetime

from paste.deploy.converters import asbool
from pylons import config
"""SQLAlchemy Metadata and Session object"""
from sqlalchemy import MetaData, and_
import sqlalchemy.orm as orm
from sqlalchemy.orm.session import SessionExtension

import extension
import ckan.lib.activity_streams_session_extension as activity

__all__ = ['Session', 'engine_is_sqlite', 'engine_is_pg']


class CkanCacheExtension(SessionExtension):
    ''' This extension checks what tables have been affected by
    database access and allows us to act on them. Currently this is
    used by the page cache to flush the cache when data in the database
    is altered. '''

    def __init__(self, *args, **kw):
        super(CkanCacheExtension, self).__init__(*args, **kw)
        # Setup Redis support if needed.
        self.use_redis = asbool(config.get('ckan.page_cache_enabled'))
        if self.use_redis:
            import redis
            self.redis = redis
            self.redis_connection is None
            self.redis_exception = redis.exceptions.ConnectionError

    def after_commit(self, session):
        if hasattr(session, '_object_cache'):
            oc = session._object_cache
            oc_list = oc['new']
            oc_list.update(oc['changed'])
            oc_list.update(oc['deleted'])
            objs = set()
            for item in oc_list:
                objs.add(item.__class__.__name__)

        # Flush Redis
        if self.use_redis:
            if self.redis_connection is None:
                try:
                    self.redis_connection = self.redis.StrictRedis()
                except self.redis_exception:
                    pass
            try:
                self.redis_connection.flushdb()
            except self.redis_exception:
                pass

class CkanSessionExtension(SessionExtension):

    def before_flush(self, session, flush_context, instances):
        if not hasattr(session, '_object_cache'):
            session._object_cache= {'new': set(),
                                    'deleted': set(),
                                    'changed': set()}

        changed = [obj for obj in session.dirty if 
            session.is_modified(obj, include_collections=False, passive=True)]

        session._object_cache['new'].update(session.new)
        session._object_cache['deleted'].update(session.deleted)
        session._object_cache['changed'].update(changed)


    def before_commit(self, session):
        session.flush()
        try:
            obj_cache = session._object_cache
            revision = session.revision
        except AttributeError:
            return
        if getattr(session, 'revisioning_disabled', False):
            return
        new = obj_cache['new']
        changed = obj_cache['changed']
        deleted = obj_cache['deleted']
        for obj in new | changed | deleted:
            if not hasattr(obj, '__revision_class__'):
                continue
            revision_cls = obj.__revision_class__
            revision_table = orm.class_mapper(revision_cls).mapped_table
            ## when a normal active transaction happens
            if 'pending' not in obj.state:
                ### this is asql statement as we do not want it in object cache
                session.execute(
                    revision_table.update().where(
                        and_(revision_table.c.id == obj.id,
                             revision_table.c.current == '1')
                    ).values(current='0')
                )

            q = session.query(revision_cls)
            q = q.filter_by(expired_timestamp=datetime.datetime(9999, 12, 31), id=obj.id)
            results = q.all()
            for rev_obj in results:
                values = {}
                if rev_obj.revision_id == revision.id:
                    values['revision_timestamp'] = revision.timestamp
                    if 'pending' not in obj.state:
                        values['current'] = '1'
                else:
                    values['expired_id'] = revision.id
                    values['expired_timestamp'] = revision.timestamp
                session.execute(
                    revision_table.update().where(
                        and_(revision_table.c.id == rev_obj.id,
                             revision_table.c.revision_id == rev_obj.revision_id)
                    ).values(**values)
                )

    def after_commit(self, session):
        if hasattr(session, '_object_cache'):
            del session._object_cache

    def after_rollback(self, session):
        if hasattr(session, '_object_cache'):
            del session._object_cache

# __all__ = ['Session', 'engine', 'metadata', 'mapper']

# SQLAlchemy database engine. Updated by model.init_model()
engine = None

Session = orm.scoped_session(orm.sessionmaker(
    autoflush=False,
    autocommit=False,
    expire_on_commit=False,
    extension=[CkanCacheExtension(),
               CkanSessionExtension(),
               extension.PluginSessionExtension(),
               activity.DatasetActivitySessionExtension()],
))

create_local_session = orm.sessionmaker(
    autoflush=False,
    autocommit=False,
    expire_on_commit=False,
    extension=[CkanCacheExtension(),
               CkanSessionExtension(),
               extension.PluginSessionExtension(),
               activity.DatasetActivitySessionExtension()],
)

#mapper = Session.mapper
mapper = orm.mapper

# Global metadata. If you have multiple databases with overlapping table
# names, you'll need a metadata for each database
metadata = MetaData()


def engine_is_sqlite(sa_engine=None):
    # Returns true iff the engine is connected to a sqlite database.
    return (sa_engine or engine).url.drivername == 'sqlite'


def engine_is_pg(sa_engine=None):
    # Returns true iff the engine is connected to a postgresql database.
    # According to http://docs.sqlalchemy.org/en/latest/core/engines.html#postgresql
    # all Postgres driver names start with `postgres`
    return (sa_engine or engine).url.drivername.startswith('postgres')

########NEW FILE########
__FILENAME__ = misc
"""
Contains miscelaneous set of DB-related functions
"""


_special_characters = '%_'
def escape_sql_like_special_characters(term, escape='\\'):
    """
    Escapes characters that are special to the the sql LIKE expression.

    In particular, for both postgres and sqlite this means '%' and '_'.
    """
    for ch in escape + _special_characters:
        term = term.replace(ch, escape+ch)
    return term

########NEW FILE########
__FILENAME__ = modification
import logging

import ckan.plugins as plugins
import domain_object
import package as _package
import resource

log = logging.getLogger(__name__)

__all__ = ['DomainObjectModificationExtension']

class DomainObjectModificationExtension(plugins.SingletonPlugin):
    """
    A domain object level interface to change notifications

    Triggered by all edits to table and related tables, which we filter
    out with check_real_change.
    """

    plugins.implements(plugins.ISession, inherit=True)

    def notify_observers(self, func):
        """
        Call func(observer) for all registered observers.

        :param func: Any callable, which will be called for each observer
        :returns: EXT_CONTINUE if no errors encountered, otherwise EXT_STOP
        """
        for observer in plugins.PluginImplementations(
                plugins.IDomainObjectModification):
            func(observer)


    def before_commit(self, session):

        session.flush()
        if not hasattr(session, '_object_cache'):
            return

        obj_cache = session._object_cache
        new = obj_cache['new']
        changed = obj_cache['changed']
        deleted = obj_cache['deleted']

        for obj in set(new):
            if isinstance(obj, (_package.Package, resource.Resource)):
                self.notify(obj, domain_object.DomainObjectOperation.new)
        for obj in set(deleted):
            if isinstance(obj, (_package.Package, resource.Resource)):
                self.notify(obj, domain_object.DomainObjectOperation.deleted)
        for obj in set(changed):
            if isinstance(obj, resource.Resource):
                self.notify(obj, domain_object.DomainObjectOperation.changed)
            if getattr(obj, 'url_changed', False):
                for item in plugins.PluginImplementations(plugins.IResourceUrlChange):
                    item.notify(obj)

        changed_pkgs = set(obj for obj in changed if isinstance(obj, _package.Package))

        for obj in new | changed | deleted:
            if not isinstance(obj, _package.Package):
                try:
                    related_packages = obj.related_packages()
                except AttributeError:
                    continue
                # this is needed to sort out vdm bug where pkg.as_dict does not
                # work when the package is deleted.
                for package in related_packages:
                    if package and package not in deleted | new:
                        changed_pkgs.add(package)
        for obj in changed_pkgs:
            self.notify(obj, domain_object.DomainObjectOperation.changed)


    def notify(self, entity, operation):
        for observer in plugins.PluginImplementations(
                plugins.IDomainObjectModification):
            try:
                observer.notify(entity, operation)
            except Exception, ex:
                log.exception(ex)
                # We reraise all exceptions so they are obvious there
                # is something wrong
                raise

########NEW FILE########
__FILENAME__ = package
import datetime
from calendar import timegm
import logging
logger = logging.getLogger(__name__)

from sqlalchemy.sql import select, and_, union, or_
from sqlalchemy import orm
from sqlalchemy import types, Column, Table
from pylons import config
import vdm.sqlalchemy

import meta
import core
import license as _license
import types as _types
import domain_object
import activity
import extension

import ckan.lib.maintain as maintain
import ckan.lib.dictization as dictization

__all__ = ['Package', 'package_table', 'package_revision_table',
           'PACKAGE_NAME_MAX_LENGTH', 'PACKAGE_NAME_MIN_LENGTH',
           'PACKAGE_VERSION_MAX_LENGTH', 'PackageTagRevision', 'PackageRevision']

PACKAGE_NAME_MAX_LENGTH = 100
PACKAGE_NAME_MIN_LENGTH = 2
PACKAGE_VERSION_MAX_LENGTH = 100

## Our Domain Object Tables
package_table = Table('package', meta.metadata,
        Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
        Column('name', types.Unicode(PACKAGE_NAME_MAX_LENGTH),
               nullable=False, unique=True),
        Column('title', types.UnicodeText),
        Column('version', types.Unicode(PACKAGE_VERSION_MAX_LENGTH)),
        Column('url', types.UnicodeText),
        Column('author', types.UnicodeText),
        Column('author_email', types.UnicodeText),
        Column('maintainer', types.UnicodeText),
        Column('maintainer_email', types.UnicodeText),
        Column('notes', types.UnicodeText),
        Column('license_id', types.UnicodeText),
        Column('type', types.UnicodeText, default=u'dataset'),
        Column('owner_org', types.UnicodeText),
        Column('creator_user_id', types.UnicodeText),
        Column('metadata_modified', types.DateTime, default=datetime.datetime.utcnow),
        Column('private', types.Boolean, default=False),
)


vdm.sqlalchemy.make_table_stateful(package_table)
package_revision_table = core.make_revisioned_table(package_table)

## -------------------
## Mapped classes

class Package(vdm.sqlalchemy.RevisionedObjectMixin,
        vdm.sqlalchemy.StatefulObjectMixin,
        domain_object.DomainObject):

    text_search_fields = ['name', 'title']

    def __init__(self, **kw):
        from ckan import model
        super(Package, self).__init__(**kw)
        resource_group = model.ResourceGroup(label="default")
        self.resource_groups_all.append(resource_group)

    @classmethod
    def search_by_name(cls, text_query):
        text_query = text_query
        return meta.Session.query(cls).filter(cls.name.contains(text_query.lower()))

    @classmethod
    def get(cls, reference):
        '''Returns a package object referenced by its id or name.'''
        query = meta.Session.query(cls).filter(cls.id==reference)
        pkg = query.first()
        if pkg == None:
            pkg = cls.by_name(reference)
        return pkg
    # Todo: Make sure package names can't be changed to look like package IDs?

    @property
    def resources(self):
        if len(self.resource_groups_all) == 0:
            return []

        assert len(self.resource_groups_all) == 1, "can only use resources on packages if there is only one resource_group"
        return [resource for resource in 
                self.resource_groups_all[0].resources_all
                if resource.state <> 'deleted']

    def related_packages(self):
        return [self]

    def add_resource(self, url, format=u'', description=u'', hash=u'', **kw):
        import resource
        self.resource_groups_all[0].resources_all.append(resource.Resource(
            resource_group_id=self.resource_groups_all[0].id,
            url=url,
            format=format,
            description=description,
            hash=hash,
            **kw)
        )

    def add_tag(self, tag):
        import ckan.model as model
        if tag in self.get_tags(tag.vocabulary):
            return
        else:
            package_tag = model.PackageTag(self, tag)
            meta.Session.add(package_tag)


    def add_tags(self, tags):
        for tag in tags:
            self.add_tag(tag)

    def add_tag_by_name(self, tag_name, vocab=None, autoflush=True):
        """Add a tag with the given name to this package's tags.

        By default the given tag_name will be searched for among the free tags
        (tags which do not belong to any vocabulary) only. If the optional
        argument `vocab` is given then the named vocab will be searched for the
        tag name instead.

        If no tag with the given name is found, one will be created. If the
        optional argument vocab is given and there is no tag with the given
        name in the given vocabulary, then a new tag will be created and added
        to the vocabulary.

        """
        from tag import Tag
        if not tag_name:
            return
        # Get the named tag.
        tag = Tag.by_name(tag_name, vocab=vocab, autoflush=autoflush)
        if not tag:
            # Tag doesn't exist yet, make a new one.
            if vocab:
                tag = Tag(name=tag_name, vocabulary_id=vocab.id)
            else:
                tag = Tag(name=tag_name)
        assert tag is not None
        self.add_tag(tag)

    def get_tags(self, vocab=None):
        """Return a sorted list of this package's tags

        Tags are sorted by their names.

        """
        import ckan.model as model
        query = meta.Session.query(model.Tag)
        query = query.join(PackageTagRevision)
        query = query.filter(PackageTagRevision.tag_id == model.Tag.id)
        query = query.filter(PackageTagRevision.package_id == self.id)
        query = query.filter(and_(
            PackageTagRevision.state == 'active',
            PackageTagRevision.current == True))
        if vocab:
            query = query.filter(model.Tag.vocabulary_id == vocab.id)
        else:
            query = query.filter(model.Tag.vocabulary_id == None)
        query = query.order_by(model.Tag.name)
        tags = query.all()
        return tags

    def remove_tag(self, tag):
        import ckan.model as model
        query = meta.Session.query(model.PackageTag)
        query = query.filter(model.PackageTag.package_id == self.id)
        query = query.filter(model.PackageTag.tag_id == tag.id)
        package_tag = query.one()
        package_tag.delete()
        meta.Session.commit()

    def isopen(self):
        if self.license and self.license.isopen():
            return True
        return False

    def get_average_rating(self):
        total = 0
        for rating in self.ratings:
            total += rating.rating
        if total == 0:
            return None
        else:
            return total / len(self.ratings)

    def as_dict(self, ref_package_by='name', ref_group_by='name'):
        _dict = domain_object.DomainObject.as_dict(self)
        # Set 'license' in _dict to cater for old clients.
        # Todo: Remove from Version 2?
        _dict['license'] = self.license.title if self.license else _dict.get('license_id', '')
        _dict['isopen'] = self.isopen()
        tags = [tag.name for tag in self.get_tags()]
        tags.sort() # so it is determinable
        _dict['tags'] = tags
        groups = [getattr(group, ref_group_by) for group in self.get_groups()]
        groups.sort()
        _dict['groups'] = groups
        _dict['extras'] = dict([(key, value) for key, value in self.extras.items()])
        _dict['ratings_average'] = self.get_average_rating()
        _dict['ratings_count'] = len(self.ratings)
        _dict['resources'] = [res.as_dict(core_columns_only=False) \
                              for res in self.resources]
        site_url = config.get('ckan.site_url', None)
        if site_url:
            _dict['ckan_url'] = '%s/dataset/%s' % (site_url, self.name)
        _dict['relationships'] = [rel.as_dict(self, ref_package_by=ref_package_by) for rel in self.get_relationships()]
        _dict['metadata_modified'] = self.metadata_modified.isoformat() \
            if self.metadata_modified else None
        _dict['metadata_created'] = self.metadata_created.isoformat() \
            if self.metadata_created else None
        import ckan.lib.helpers as h
        _dict['notes_rendered'] = h.render_markdown(self.notes)
        _dict['type'] = self.type or u'dataset'
        return _dict

    def add_relationship(self, type_, related_package, comment=u''):
        '''Creates a new relationship between this package and a
        related_package. It leaves the caller to commit the change.

        Raises KeyError if the type_ is invalid.
        '''
        import package_relationship
        if type_ in package_relationship.PackageRelationship.get_forward_types():
            subject = self
            object_ = related_package
        elif type_ in package_relationship.PackageRelationship.get_reverse_types():
            type_ = package_relationship.PackageRelationship.reverse_to_forward_type(type_)
            assert type_
            subject = related_package
            object_ = self
        else:
            raise KeyError, 'Package relationship type: %r' % type_

        rels = self.get_relationships(with_package=related_package,
                                      type=type_, active=False, direction="forward")
        if rels:
            rel = rels[0]
            if comment:
                rel.comment=comment
            if rel.state == core.State.DELETED:
                rel.undelete()
        else:
            rel = package_relationship.PackageRelationship(
                subject=subject,
                object=object_,
                type=type_,
                comment=comment)
        meta.Session.add(rel)
        return rel

    def get_relationships(self, with_package=None, type=None, active=True,
                          direction='both'):
        '''Returns relationships this package has.
        Keeps stored type/ordering (not from pov of self).'''
        assert direction in ('both', 'forward', 'reverse')
        if with_package:
            assert isinstance(with_package, Package)
        from package_relationship import PackageRelationship
        forward_filters = [PackageRelationship.subject==self]
        reverse_filters = [PackageRelationship.object==self]
        if with_package:
            forward_filters.append(PackageRelationship.object==with_package)
            reverse_filters.append(PackageRelationship.subject==with_package)
        if active:
            forward_filters.append(PackageRelationship.state==core.State.ACTIVE)
            reverse_filters.append(PackageRelationship.state==core.State.ACTIVE)
        if type:
            forward_filters.append(PackageRelationship.type==type)
            reverse_type = PackageRelationship.reverse_type(type)
            reverse_filters.append(PackageRelationship.type==reverse_type)
        q = meta.Session.query(PackageRelationship)
        if direction == 'both':
            q = q.filter(or_(
            and_(*forward_filters),
            and_(*reverse_filters),
            ))
        elif direction == 'forward':
            q = q.filter(and_(*forward_filters))
        elif direction == 'reverse':
            q = q.filter(and_(*reverse_filters))
        return q.all()

    def get_relationships_with(self, other_package, type=None, active=True):
        return self.get_relationships(with_package=other_package,
                                      type=type,
                                      active=active)

    def get_relationships_printable(self):
        '''Returns a list of tuples describing related packages, including
        non-direct relationships (such as siblings).
        @return: e.g. [(annakarenina, u"is a parent"), ...]
        '''
        from package_relationship import PackageRelationship
        rel_list = []
        for rel in self.get_relationships():
            if rel.subject == self:
                type_printable = PackageRelationship.make_type_printable(rel.type)
                rel_list.append((rel.object, type_printable, rel.comment))
            else:
                type_printable = PackageRelationship.make_type_printable(\
                    PackageRelationship.forward_to_reverse_type(
                        rel.type)
                    )
                rel_list.append((rel.subject, type_printable, rel.comment))
        # sibling types
        # e.g. 'gary' is a child of 'mum', looking for 'bert' is a child of 'mum'
        # i.e. for each 'child_of' type relationship ...
        for rel_as_subject in self.get_relationships(direction='forward'):
            if rel_as_subject.state != core.State.ACTIVE:
                continue
            # ... parent is the object
            parent_pkg = rel_as_subject.object
            # Now look for the parent's other relationships as object ...
            for parent_rel_as_object in parent_pkg.get_relationships(direction='reverse'):
                if parent_rel_as_object.state != core.State.ACTIVE:
                    continue
                # and check children
                child_pkg = parent_rel_as_object.subject
                if (child_pkg != self and
                    parent_rel_as_object.type == rel_as_subject.type and
                    child_pkg.state == core.State.ACTIVE):
                    type_printable = PackageRelationship.inferred_types_printable['sibling']
                    rel_list.append((child_pkg, type_printable, None))
        return sorted(list(set(rel_list)))
    #
    ## Licenses are currently integrated into the domain model here.

    @classmethod
    def get_license_register(cls):
        if not hasattr(cls, '_license_register'):
            cls._license_register = _license.LicenseRegister()
        return cls._license_register

    @classmethod
    def get_license_options(cls):
        register = cls.get_license_register()
        return [(l.title, l.id) for l in register.values()]

    def get_license(self):
        if self.license_id:
            try:
                license = self.get_license_register()[self.license_id]
            except KeyError:
                license = None
        else:
            license = None
        return license

    def set_license(self, license):
        if type(license) == _license.License:
            self.license_id = license.id
        elif type(license) == dict:
            self.license_id = license['id']
        else:
            msg = "Value not a license object or entity: %s" % repr(license)
            raise Exception, msg

    license = property(get_license, set_license)

    @property
    def all_related_revisions(self):
        '''Returns chronological list of all object revisions related to
        this package. Includes PackageRevisions, PackageTagRevisions,
        PackageExtraRevisions and ResourceRevisions.
        @return List of tuples (revision, [list of object revisions of this
                                           revision])
                Ordered by most recent first.
        '''
        from tag import PackageTag
        from resource import ResourceGroup, Resource
        from package_extra import PackageExtra

        results = {} # revision:[PackageRevision1, PackageTagRevision1, etc.]
        for pkg_rev in self.all_revisions:
            if not results.has_key(pkg_rev.revision):
                results[pkg_rev.revision] = []
            results[pkg_rev.revision].append(pkg_rev)
        for class_ in [ResourceGroup, Resource, PackageExtra, PackageTag]:
            rev_class = class_.__revision_class__
            if class_ == Resource:
                q = meta.Session.query(rev_class).join('continuity',
                                                  'resource_group')
                obj_revisions = q.filter(ResourceGroup.package_id == self.id).all()
            else:
                obj_revisions = meta.Session.query(rev_class).filter_by(package_id=self.id).all()
            for obj_rev in obj_revisions:
                if not results.has_key(obj_rev.revision):
                    results[obj_rev.revision] = []
                results[obj_rev.revision].append(obj_rev)

        result_list = results.items()
        ourcmp = lambda rev_tuple1, rev_tuple2: \
                 cmp(rev_tuple2[0].timestamp, rev_tuple1[0].timestamp)
        return sorted(result_list, cmp=ourcmp)

    @property
    def latest_related_revision(self):
        '''Returns the latest revision for the package and its related
        objects.'''
        return self.all_related_revisions[0][0]

    def diff(self, to_revision=None, from_revision=None):
        '''Overrides the diff in vdm, so that related obj revisions are
        diffed as well as PackageRevisions'''
        from tag import PackageTag
        from resource import ResourceGroup, Resource
        from package_extra import PackageExtra

        results = {} # field_name:diffs
        results.update(super(Package, self).diff(to_revision, from_revision))
        # Iterate over PackageTag, PackageExtra, Resources etc.
        for obj_class in [ResourceGroup, Resource, PackageExtra, PackageTag]:
            obj_rev_class = obj_class.__revision_class__
            # Query for object revisions related to this package
            if obj_class == Resource:
                obj_rev_query = meta.Session.query(obj_rev_class).\
                                join('continuity', 'resource_group').\
                                join('revision').\
                                filter(ResourceGroup.package_id == self.id).\
                                order_by(core.Revision.timestamp.desc())
            else:
                obj_rev_query = meta.Session.query(obj_rev_class).\
                                filter_by(package_id=self.id).\
                                join('revision').\
                                order_by(core.Revision.timestamp.desc())
            # Columns to include in the diff
            cols_to_diff = obj_class.revisioned_fields()
            cols_to_diff.remove('id')
            if obj_class is Resource:
                cols_to_diff.remove('resource_group_id')
            else:
                cols_to_diff.remove('package_id')
            # Particular object types are better known by an invariant field
            if obj_class is PackageTag:
                cols_to_diff.remove('tag_id')
            elif obj_class is PackageExtra:
                cols_to_diff.remove('key')
            # Iterate over each object ID
            # e.g. for PackageTag, iterate over Tag objects
            related_obj_ids = set([related_obj.id for related_obj in obj_rev_query.all()])
            for related_obj_id in related_obj_ids:
                q = obj_rev_query.filter(obj_rev_class.id==related_obj_id)
                to_obj_rev, from_obj_rev = super(Package, self).\
                    get_obj_revisions_to_diff(
                    q, to_revision, from_revision)
                for col in cols_to_diff:
                    values = [getattr(obj_rev, col) if obj_rev else '' for obj_rev in (from_obj_rev, to_obj_rev)]
                    value_diff = self._differ(*values)
                    if value_diff:
                        if obj_class.__name__ == 'PackageTag':
                            display_id = to_obj_rev.tag.name
                        elif obj_class.__name__ == 'PackageExtra':
                            display_id = to_obj_rev.key
                        else:
                            display_id = related_obj_id[:4]
                        key = '%s-%s-%s' % (obj_class.__name__, display_id, col)
                        results[key] = value_diff
        return results

    @property
    @maintain.deprecated('`is_private` attriute of model.Package is ' +
                         'deprecated and should not be used.  Use `private`')
    def is_private(self):
        """
        DEPRECATED in 2.1

        A package is private if belongs to any private groups
        """
        return self.private

    def is_in_group(self, group):
        return group in self.get_groups()

    def get_groups(self, group_type=None, capacity=None):
        import ckan.model as model

        # Gets [ (group, capacity,) ...]
        groups = model.Session.query(model.Group,model.Member.capacity).\
           join(model.Member, model.Member.group_id == model.Group.id and \
                model.Member.table_name == 'package' ).\
           join(model.Package, model.Package.id == model.Member.table_id).\
           filter(model.Member.state == 'active').\
           filter(model.Member.table_id == self.id).all()

        caps   = [g[1] for g in groups]
        groups = [g[0] for g in groups ]
        if group_type:
            groups = [g for g in groups if g.type == group_type]
        if capacity:
            groupcaps = zip( groups,caps )
            groups = [g[0] for g in groupcaps if g[1] == capacity]
        return groups

    @property
    def metadata_created(self):
        import ckan.model as model
        q = meta.Session.query(model.PackageRevision.revision_timestamp)\
            .filter(model.PackageRevision.id == self.id)\
            .order_by(model.PackageRevision.revision_timestamp.asc())
        ts = q.first()
        if ts:
            return ts[0]

    @staticmethod
    def get_fields(core_only=False, fields_to_ignore=None):
        '''Returns a list of the properties of a package.
        @param core_only - limit it to fields actually in the package table and
                           not those on related objects, such as tags & extras.
        @param fields_to_ignore - a list of names of fields to not return if
                           present.
        '''
        # ['id', 'name', 'title', 'version', 'url', 'author', 'author_email', 'maintainer', 'maintainer_email', 'notes', 'license_id', 'state']
        fields = Package.revisioned_fields()
        if not core_only:
            fields += ['resources', 'tags', 'groups', 'extras', 'relationships']

        if fields_to_ignore:
            for field in fields_to_ignore:
                fields.remove(field)

        return fields

    def activity_stream_item(self, activity_type, revision, user_id):
        import ckan.model
        import ckan.logic
        assert activity_type in ("new", "changed"), (
            str(activity_type))

        # Handle 'deleted' objects.
        # When the user marks a package as deleted this comes through here as
        # a 'changed' package activity. We detect this and change it to a
        # 'deleted' activity.
        if activity_type == 'changed' and self.state == u'deleted':
            if meta.Session.query(activity.Activity).filter_by(
                    object_id=self.id, activity_type='deleted').all():
                # A 'deleted' activity for this object has already been emitted
                # FIXME: What if the object was deleted and then activated
                # again?
                return None
            else:
                # Emit a 'deleted' activity for this object.
                activity_type = 'deleted'

        try:
            d = {'package': dictization.table_dictize(self,
                context={'model': ckan.model})}
            return activity.Activity(user_id, self.id, revision.id,
                    "%s package" % activity_type, d)
        except ckan.logic.NotFound:
            # This happens if this package is being purged and therefore has no
            # current revision.
            # TODO: Purge all related activity stream items when a model object
            # is purged.
            return None

    def activity_stream_detail(self, activity_id, activity_type):
        import ckan.model

        # Handle 'deleted' objects.
        # When the user marks a package as deleted this comes through here as
        # a 'changed' package activity. We detect this and change it to a
        # 'deleted' activity.
        if activity_type == 'changed' and self.state == u'deleted':
            activity_type = 'deleted'

        package_dict = dictization.table_dictize(self,
                context={'model':ckan.model})
        return activity.ActivityDetail(activity_id, self.id, u"Package", activity_type,
            {'package': package_dict })

# import here to prevent circular import
import tag

meta.mapper(Package, package_table, properties={
    # delete-orphan on cascade does NOT work!
    # Why? Answer: because of way SQLAlchemy/our code works there are points
    # where PackageTag object is created *and* flushed but does not yet have
    # the package_id set (this cause us other problems ...). Some time later a
    # second commit happens in which the package_id is correctly set.
    # However after first commit PackageTag does not have Package and
    # delete-orphan kicks in to remove it!
    'package_tags':orm.relation(tag.PackageTag, backref='package',
        cascade='all, delete', #, delete-orphan',
        ),
    },
    order_by=package_table.c.name,
    extension=[vdm.sqlalchemy.Revisioner(package_revision_table),
               extension.PluginMapperExtension(),
               ],
    )

vdm.sqlalchemy.modify_base_object_mapper(Package, core.Revision, core.State)
PackageRevision = vdm.sqlalchemy.create_object_version(meta.mapper, Package,
        package_revision_table)

def related_packages(self):
    return [self.continuity]

PackageRevision.related_packages = related_packages


vdm.sqlalchemy.modify_base_object_mapper(tag.PackageTag, core.Revision, core.State)
PackageTagRevision = vdm.sqlalchemy.create_object_version(meta.mapper, tag.PackageTag,
        tag.package_tag_revision_table)

PackageTagRevision.related_packages = lambda self: [self.continuity.package]

########NEW FILE########
__FILENAME__ = package_extra
import vdm.sqlalchemy
import vdm.sqlalchemy.stateful
from sqlalchemy import orm, types, Column, Table, ForeignKey

import meta
import core
import package as _package
import extension
import domain_object
import types as _types
import ckan.lib.dictization
import activity

__all__ = ['PackageExtra', 'package_extra_table', 'PackageExtraRevision',
           'extra_revision_table']

package_extra_table = Table('package_extra', meta.metadata,
    Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
    # NB: only (package, key) pair is unique
    Column('package_id', types.UnicodeText, ForeignKey('package.id')),
    Column('key', types.UnicodeText),
    Column('value', types.UnicodeText),
)

vdm.sqlalchemy.make_table_stateful(package_extra_table)
extra_revision_table= core.make_revisioned_table(package_extra_table)

class PackageExtra(vdm.sqlalchemy.RevisionedObjectMixin,
        vdm.sqlalchemy.StatefulObjectMixin,
        domain_object.DomainObject):

    def related_packages(self):
        return [self.package]

    def activity_stream_detail(self, activity_id, activity_type):
        import ckan.model as model

        # Handle 'deleted' extras.
        # When the user marks an extra as deleted this comes through here as a
        # 'changed' extra. We detect this and change it to a 'deleted'
        # activity.
        if activity_type == 'changed' and self.state == u'deleted':
            activity_type = 'deleted'

        data_dict = ckan.lib.dictization.table_dictize(self,
                context={'model': model})
        return activity.ActivityDetail(activity_id, self.id, u"PackageExtra",
                activity_type, {'package_extra': data_dict})

meta.mapper(PackageExtra, package_extra_table, properties={
    'package': orm.relation(_package.Package,
        backref=orm.backref('_extras',
            collection_class=orm.collections.attribute_mapped_collection(u'key'),
            cascade='all, delete, delete-orphan',
            ),
        ),
    'package_no_state': orm.relation(_package.Package,
        backref=orm.backref('extras_list',
            cascade='all, delete, delete-orphan',
            ),
        )
    },
    order_by=[package_extra_table.c.package_id, package_extra_table.c.key],
    extension=[vdm.sqlalchemy.Revisioner(extra_revision_table),
               extension.PluginMapperExtension(),
               ],
)

vdm.sqlalchemy.modify_base_object_mapper(PackageExtra, core.Revision, core.State)
PackageExtraRevision= vdm.sqlalchemy.create_object_version(meta.mapper, PackageExtra,
        extra_revision_table)

PackageExtraRevision.related_packages = lambda self: [self.continuity.package]

def _create_extra(key, value):
    return PackageExtra(key=unicode(key), value=value)

_extras_active = vdm.sqlalchemy.stateful.DeferredProperty('_extras',
        vdm.sqlalchemy.stateful.StatefulDict, base_modifier=lambda x: x.get_as_of()) 
setattr(_package.Package, 'extras_active', _extras_active)
_package.Package.extras = vdm.sqlalchemy.stateful.OurAssociationProxy('extras_active', 'value',
            creator=_create_extra)


########NEW FILE########
__FILENAME__ = package_relationship
import vdm.sqlalchemy
from sqlalchemy import orm, types, Column, Table, ForeignKey

import meta
import core
import package as _package
import types as _types
import domain_object

# i18n only works when this is run as part of pylons,
# which isn't the case for paster commands.
try:
    from ckan.common import _
    _()
except:
    def _(txt):
        return txt

__all__ = ['PackageRelationship', 'package_relationship_table',
           'package_relationship_revision_table']

package_relationship_table = Table('package_relationship', meta.metadata,
     Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
     Column('subject_package_id', types.UnicodeText, ForeignKey('package.id')),
     Column('object_package_id', types.UnicodeText, ForeignKey('package.id')),
     Column('type', types.UnicodeText),
     Column('comment', types.UnicodeText),
     )

vdm.sqlalchemy.make_table_stateful(package_relationship_table)
package_relationship_revision_table = core.make_revisioned_table(package_relationship_table)

class PackageRelationship(vdm.sqlalchemy.RevisionedObjectMixin,
                          vdm.sqlalchemy.StatefulObjectMixin,
                          domain_object.DomainObject):
    '''The rule with PackageRelationships is that they are stored in the model
    always as the "forward" relationship - i.e. "child_of" but never
    as "parent_of". However, the model functions provide the relationships
    from both packages in the relationship and the type is swapped from
    forward to reverse accordingly, for meaningful display to the user.'''
    
    # List of (type, corresponding_reverse_type)
    # e.g. (A "depends_on" B, B has a "dependency_of" A)
    # don't forget to add specs to Solr's schema.xml
    types = [(u'depends_on', u'dependency_of'),
             (u'derives_from', u'has_derivation'),
             (u'links_to', u'linked_from'),
             (u'child_of', u'parent_of'),
             ]

    types_printable = \
            [(_(u'depends on %s'), _(u'is a dependency of %s')),
             (_(u'derives from %s'), _(u'has derivation %s')),
             (_(u'links to %s'), _(u'is linked from %s')),
             (_(u'is a child of %s'), _(u'is a parent of %s')),
             ]

    inferred_types_printable = \
            {'sibling':_('has sibling %s')}

    def __str__(self):
        return '<%sPackageRelationship %s %s %s>' % ("*" if self.active != core.State.ACTIVE else "",
                                                     self.subject.name, self.type, self.object.name)

    def __repr__(self):
        return str(self)

    def as_dict(self, package=None, ref_package_by='id'):
        """Returns full relationship info as a dict from the point of view
        of the given package if specified.
        e.g. {'subject':u'annakarenina',
              'type':u'depends_on',
              'object':u'warandpeace',
              'comment':u'Since 1843'}"""
        subject_pkg = self.subject
        object_pkg = self.object
        relationship_type = self.type
        if package and package == object_pkg:
            subject_pkg = self.object
            object_pkg = self.subject
            relationship_type = self.forward_to_reverse_type(self.type)
        subject_ref = getattr(subject_pkg, ref_package_by)
        object_ref = getattr(object_pkg, ref_package_by)
        return {'subject':subject_ref,
                'type':relationship_type,
                'object':object_ref,
                'comment':self.comment}

    def as_tuple(self, package):
        '''Returns basic relationship info as a tuple from the point of view
        of the given package with the object package object.
        e.g. rel.as_tuple(warandpeace) gives (u'depends_on', annakarenina)
        meaning warandpeace depends_on annakarenina.'''
        assert isinstance(package, _package.Package), package
        if self.subject == package:
            type_str = self.type
            other_package = self.object
        elif self.object == package:
            type_str = self.forward_to_reverse_type(self.type)
            other_package = self.subject
        else:
            # FIXME do we want a more specific error
            raise Exception('Package %s is not in this relationship: %s' % \
                             (package, self))
        return (type_str, other_package)
        
    @classmethod
    def by_subject(cls, package):
        return meta.Session.query(cls).filter(cls.subject_package_id==package.id)

    @classmethod
    def by_object(cls, package):
        return meta.Session.query(cls).filter(cls.object_package_id==package.id)
    
    @classmethod
    def get_forward_types(cls):
        if not hasattr(cls, 'fwd_types'):
            cls.fwd_types = [fwd for fwd, rev in cls.types]
        return cls.fwd_types

    @classmethod
    def get_reverse_types(cls):
        if not hasattr(cls, 'rev_types'):
            cls.rev_types = [rev for fwd, rev in cls.types]
        return cls.rev_types

    @classmethod
    def get_all_types(cls):
        if not hasattr(cls, 'all_types'):
            cls.all_types = []
            for fwd, rev in cls.types:
                cls.all_types.append(fwd)
                cls.all_types.append(rev)
        return cls.all_types

    @classmethod
    def reverse_to_forward_type(cls, reverse_type):
        for fwd, rev in cls.types:
            if rev == reverse_type:
                return fwd        

    @classmethod
    def forward_to_reverse_type(cls, forward_type):
        for fwd, rev in cls.types:
            if fwd == forward_type:
                return rev

    @classmethod
    def reverse_type(cls, forward_or_reverse_type):
        for fwd, rev in cls.types:
            if fwd == forward_or_reverse_type:
                return rev
            if rev == forward_or_reverse_type:
                return fwd        

    @classmethod
    def make_type_printable(cls, type_):
        for i, types in enumerate(cls.types):
            for j in range(2):
                if type_ == types[j]:
                    return cls.types_printable[i][j]
        raise TypeError, type_

meta.mapper(PackageRelationship, package_relationship_table, properties={
    'subject':orm.relation(_package.Package, primaryjoin=\
           package_relationship_table.c.subject_package_id==_package.Package.id,
           backref='relationships_as_subject'),
    'object':orm.relation(_package.Package, primaryjoin=package_relationship_table.c.object_package_id==_package.Package.id,
           backref='relationships_as_object'),
    },
    extension = [vdm.sqlalchemy.Revisioner(package_relationship_revision_table)]
    )

vdm.sqlalchemy.modify_base_object_mapper(PackageRelationship, core.Revision, core.State)
PackageRelationshipRevision = vdm.sqlalchemy.create_object_version(
    meta.mapper, PackageRelationship, package_relationship_revision_table)

########NEW FILE########
__FILENAME__ = rating
import datetime

from sqlalchemy import orm, types, Column, Table, ForeignKey

import meta
import package as _package
import user
import domain_object
import types as _types

__all__ = ['Rating']

rating_table = Table('rating', meta.metadata,
                     Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
                     Column('user_id', types.UnicodeText, ForeignKey('user.id')),
                     Column('user_ip_address', types.UnicodeText), # alternative to user_id if not logged in
                     Column('package_id', types.UnicodeText, ForeignKey('package.id')),
                     Column('rating', types.Float),
                     Column('created', types.DateTime, default=datetime.datetime.now),
                     )

class Rating(domain_object.DomainObject):
    pass

meta.mapper(Rating, rating_table,
       properties={
            'user': orm.relation(user.User,
                backref=orm.backref('ratings',
                cascade='all, delete, delete-orphan'
                )),
            'package': orm.relation(_package.Package,
                backref=orm.backref('ratings',
                cascade='all, delete, delete-orphan'
                )),
            },
       )

########NEW FILE########
__FILENAME__ = related
import datetime

import sqlalchemy as sa
from sqlalchemy import orm
from sqlalchemy import types, Column, Table, ForeignKey, and_, func

import meta
import domain_object
import types as _types
import package as _package

__all__ = ['Related', 'RelatedDataset', 'related_dataset_table',
           'related_table']

related_table = sa.Table('related',meta.metadata,
        sa.Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
        sa.Column('type', types.UnicodeText, default=u'idea'),
        sa.Column('title', types.UnicodeText),
        sa.Column('description', types.UnicodeText),
        sa.Column('image_url', types.UnicodeText),
        sa.Column('url', types.UnicodeText),
        sa.Column('created', types.DateTime, default=datetime.datetime.now),
        sa.Column('owner_id', types.UnicodeText),
        sa.Column('view_count', types.Integer, default=0),
        sa.Column('featured', types.Integer, default=0)
)

related_dataset_table = Table('related_dataset', meta.metadata,
    Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
    Column('dataset_id', types.UnicodeText, ForeignKey('package.id'),
      nullable=False),
    Column('related_id', types.UnicodeText, ForeignKey('related.id'), nullable=False),
    Column('status', types.UnicodeText, default=u'active'),
    )

class RelatedDataset(domain_object.DomainObject):
    pass

class Related(domain_object.DomainObject):

    @classmethod
    def get(cls, id):
        return meta.Session.query(Related).filter(Related.id == id).first()

    @classmethod
    def get_for_dataset(cls, package, status=u'active'):
        """
        Allows the caller to get non-active state relations between
        the dataset and related, using the RelatedDataset object
        """
        query = meta.Session.query(RelatedDataset).\
                filter(RelatedDataset.dataset_id==package.id).\
                filter(RelatedDataset.status==status).all()
        return query

    def deactivate(self, package):
        related_ds = meta.Session.query(RelatedDataset).\
                          filter(RelatedDataset.dataset_id==package.id).\
                          filter(RelatedDataset.status=='active').first()
        if related_ds:
            related_ds.status = 'inactive'
            meta.Session.commit()


# We have avoided using SQLAlchemy association objects see
# http://bit.ly/sqlalchemy_association_object by only having the
# relation be for 'active' related objects.  For non-active states
# the caller will have to use get_for_dataset() in Related.
meta.mapper(RelatedDataset, related_dataset_table, properties={
    'related': orm.relation(Related),
    'dataset': orm.relation(_package.Package)
})
meta.mapper(Related, related_table, properties={
'datasets': orm.relation(_package.Package,
    backref=orm.backref('related'),
    secondary=related_dataset_table,
    secondaryjoin=and_(related_dataset_table.c.dataset_id==_package.Package.id,
                          RelatedDataset.status=='active'))
})

def _related_count(dataset):
    """
    Returns the *number* of (active) related items for the given dataset.
    """
    return meta.Session.query(func.count(RelatedDataset.id)).\
                        filter(RelatedDataset.dataset_id==dataset.id).\
                        filter(RelatedDataset.status=='active').\
                        scalar()

if hasattr(_package.Package, 'related_count'):
    raise Exception, 'Unable to attach `related_count` to Package class.'

_package.Package.related_count = property(_related_count)

########NEW FILE########
__FILENAME__ = resource
import datetime

from sqlalchemy.util import OrderedDict
from sqlalchemy.ext.orderinglist import ordering_list
from sqlalchemy import orm
from pylons import config
import vdm.sqlalchemy
import vdm.sqlalchemy.stateful
from sqlalchemy import types, Column, Table, ForeignKey, and_

import meta
import core
import package as _package
import types as _types
import extension
import activity
import domain_object
import ckan.lib.dictization

__all__ = ['Resource', 'resource_table',
           'ResourceGroup', 'resource_group_table',
           'ResourceRevision', 'resource_revision_table',
           'ResourceGroupRevision', 'resource_group_revision_table',
           ]

CORE_RESOURCE_COLUMNS = ['url', 'format', 'description', 'hash', 'name',
                         'resource_type', 'mimetype', 'mimetype_inner',
                         'size', 'created', 'last_modified', 'cache_url',
                         'cache_last_updated', 'webstore_url',
                         'webstore_last_updated', 'url_type']

##formally package_resource
resource_table = Table(
    'resource', meta.metadata,
    Column('id', types.UnicodeText, primary_key=True,
           default=_types.make_uuid),
    Column('resource_group_id', types.UnicodeText,
           ForeignKey('resource_group.id')),
    Column('url', types.UnicodeText, nullable=False),
    Column('format', types.UnicodeText),
    Column('description', types.UnicodeText),
    Column('hash', types.UnicodeText),
    Column('position', types.Integer),

    Column('name', types.UnicodeText),
    Column('resource_type', types.UnicodeText),
    Column('mimetype', types.UnicodeText),
    Column('mimetype_inner', types.UnicodeText),
    Column('size', types.BigInteger),
    Column('created', types.DateTime, default=datetime.datetime.now),
    Column('last_modified', types.DateTime),
    Column('cache_url', types.UnicodeText),
    Column('cache_last_updated', types.DateTime),
    Column('webstore_url', types.UnicodeText),
    Column('webstore_last_updated', types.DateTime),
    Column('url_type', types.UnicodeText),
    Column('extras', _types.JsonDictType),
)

resource_group_table = Table(
    'resource_group', meta.metadata,
    Column('id', types.UnicodeText, primary_key=True,
           default=_types.make_uuid),
    Column('package_id', types.UnicodeText, ForeignKey('package.id')),
    Column('label', types.UnicodeText),
    Column('sort_order', types.UnicodeText),
    Column('extras', _types.JsonDictType),
)

vdm.sqlalchemy.make_table_stateful(resource_table)
resource_revision_table = core.make_revisioned_table(resource_table)

vdm.sqlalchemy.make_table_stateful(resource_group_table)
resource_group_revision_table = core.make_revisioned_table(
    resource_group_table)


class Resource(vdm.sqlalchemy.RevisionedObjectMixin,
               vdm.sqlalchemy.StatefulObjectMixin,
               domain_object.DomainObject):
    extra_columns = None

    def __init__(self, resource_group_id=None, url=u'',
                 format=u'', description=u'', hash=u'',
                 extras=None,
                 **kwargs):
        self.id = _types.make_uuid()
        if resource_group_id:
            self.resource_group_id = resource_group_id
        self.url = url
        self.format = format
        self.description = description
        self.hash = hash
        # The base columns historically defaulted to empty strings
        # not None (Null). This is why they are seperate here.
        base_columns = ['url', 'format', 'description', 'hash']
        for key in set(CORE_RESOURCE_COLUMNS) - set(base_columns):
            setattr(self, key, kwargs.pop(key, None))
        self.extras = extras or {}
        extra_columns = self.get_extra_columns()
        for field in extra_columns:
            value = kwargs.pop(field, None)
            if value is not None:
                setattr(self, field, value)
        if kwargs:
            raise TypeError('unexpected keywords %s' % kwargs)

    def as_dict(self, core_columns_only=False):
        _dict = OrderedDict()
        cols = self.get_columns()
        if not core_columns_only:
            cols = ['id', 'resource_group_id'] + cols + ['position']
        for col in cols:
            value = getattr(self, col)
            if isinstance(value, datetime.datetime):
                value = value.isoformat()
            _dict[col] = value
        for k, v in self.extras.items() if self.extras else []:
            _dict[k] = v
        if self.resource_group and not core_columns_only:
            _dict["package_id"] = self.resource_group.package_id
        return _dict

    def get_package_id(self):
        '''Returns the package id for a resource. '''
        query = meta.Session.query(ResourceGroupRevision) \
            .filter(and_(ResourceGroupRevision.id == self.resource_group_id,
                         ResourceGroupRevision.state == u'active',
                         ResourceGroupRevision.current == True))
        resource_group = query.first()
        if resource_group is None:
            return None
        return resource_group.package_id

    @classmethod
    def get(cls, reference):
        '''Returns a resource object referenced by its name or id.'''
        query = meta.Session.query(Resource).filter(Resource.id == reference)
        resource = query.first()
        if resource is None:
            resource = cls.by_name(reference)
        return resource

    @classmethod
    def get_columns(cls, extra_columns=True):
        '''Returns the core editable columns of the resource.'''
        if extra_columns:
            return CORE_RESOURCE_COLUMNS + cls.get_extra_columns()
        else:
            return CORE_RESOURCE_COLUMNS

    @classmethod
    def get_extra_columns(cls):
        if cls.extra_columns is None:
            cls.extra_columns = config.get(
                'ckan.extra_resource_fields', '').split()
            for field in cls.extra_columns:
                setattr(cls, field, DictProxy(field, 'extras'))
        return cls.extra_columns

    def related_packages(self):
        return [self.resource_group.package]

    def activity_stream_detail(self, activity_id, activity_type):
        import ckan.model as model

        # Handle 'deleted' resources.
        # When the user marks a resource as deleted this comes through here as
        # a 'changed' resource activity. We detect this and change it to a
        # 'deleted' activity.
        if activity_type == 'changed' and self.state == u'deleted':
            activity_type = 'deleted'

        res_dict = ckan.lib.dictization.table_dictize(self,
                                                      context={'model': model})
        return activity.ActivityDetail(activity_id, self.id, u"Resource",
                                       activity_type,
                                       {'resource': res_dict})


class ResourceGroup(vdm.sqlalchemy.RevisionedObjectMixin,
                    vdm.sqlalchemy.StatefulObjectMixin,
                    domain_object.DomainObject):
    extra_columns = None

    def __init__(self, package_id=None, sort_order=u'', label=u'',
                 extras=None, **kwargs):
        if package_id:
            self.package_id = package_id
        self.sort_order = sort_order
        self.label = label
        self.extras = extras or {}
        self.state = 'active'

        extra_columns = self.get_extra_columns()
        for field in extra_columns:
            value = kwargs.pop(field, u'')
            setattr(self, field, value)
        if kwargs:
            raise TypeError('unexpected keywords %s' % kwargs)

    def as_dict(self, core_columns_only=False):
        _dict = OrderedDict()
        cols = self.get_columns()
        if not core_columns_only:
            cols = ['package_id', 'label', 'sort_order'] + cols
        for col in cols:
            _dict[col] = getattr(self, col)
        for k, v in self.extras.items() if self.extras else []:
            _dict[k] = v
        return _dict

    @classmethod
    def get_columns(cls, extra_columns=True):
        '''Returns the core editable columns of the resource.'''
        if extra_columns:
            return ['label', 'sort_order'] + cls.get_extra_columns()
        else:
            return ['label', 'sort_order']

    @classmethod
    def get_extra_columns(cls):
        if cls.extra_columns is None:
            cls.extra_columns = config.get(
                'ckan.extra_resource_group_fields', '').split()
            for field in cls.extra_columns:
                setattr(cls, field, DictProxy(field, 'extras'))
        return cls.extra_columns

        ## Mappers

meta.mapper(Resource, resource_table, properties={
    'resource_group': orm.relation(
        ResourceGroup,
        # all resources including deleted
        # formally package_resources_all
        backref=orm.backref('resources_all',
                            collection_class=ordering_list('position'),
                            cascade='all, delete',
                            order_by=resource_table.c.position,
                            ),
    )
},
order_by=[resource_table.c.resource_group_id],
extension=[vdm.sqlalchemy.Revisioner(resource_revision_table),
           extension.PluginMapperExtension(),
           ],
)

meta.mapper(ResourceGroup, resource_group_table, properties={
    'package': orm.relation(
        _package.Package,
        # all resources including deleted
        backref=orm.backref('resource_groups_all',
                            cascade='all, delete, delete-orphan',
                            order_by=resource_group_table.c.sort_order,
                            ),
    )
},
order_by=[resource_group_table.c.package_id],
extension=[vdm.sqlalchemy.Revisioner(resource_group_revision_table),
           extension.PluginMapperExtension(),
           ],
)

## VDM

vdm.sqlalchemy.modify_base_object_mapper(Resource, core.Revision, core.State)
ResourceRevision = vdm.sqlalchemy.create_object_version(
    meta.mapper, Resource, resource_revision_table)

vdm.sqlalchemy.modify_base_object_mapper(ResourceGroup, core.Revision,
                                         core.State)
ResourceGroupRevision = vdm.sqlalchemy.create_object_version(
    meta.mapper, ResourceGroup, resource_group_revision_table)

ResourceGroupRevision.related_packages = lambda self: [
    self.continuity.package
]
ResourceRevision.related_packages = lambda self: [
    self.continuity.resouce_group.package
]


def resource_identifier(obj):
    return obj.id


class DictProxy(object):

    def __init__(self, target_key, target_dict, data_type=unicode):
        self.target_key = target_key
        self.target_dict = target_dict
        self.data_type = data_type

    def __get__(self, obj, type):

        if not obj:
            return self

        proxied_dict = getattr(obj, self.target_dict)
        if proxied_dict:
            return proxied_dict.get(self.target_key)

    def __set__(self, obj, value):

        proxied_dict = getattr(obj, self.target_dict)
        if proxied_dict is None:
            proxied_dict = {}
            setattr(obj, self.target_dict, proxied_dict)

        proxied_dict[self.target_key] = self.data_type(value)

    def __delete__(self, obj):

        proxied_dict = getattr(obj, self.target_dict)
        proxied_dict.pop(self.target_key)

########NEW FILE########
__FILENAME__ = system_info
from sqlalchemy import types, Column, Table

import meta
import core
import domain_object

__all__ = ['system_info_revision_table', 'system_info_table', 'SystemInfo',
          'get_system_info', 'set_system_info']

system_info_table = Table('system_info', meta.metadata,
        Column('id', types.Integer(),  primary_key=True, nullable=False),
        Column('key', types.Unicode(100), unique=True, nullable=False),
        Column('value', types.UnicodeText),
    )

system_info_revision_table = core.make_revisioned_table(system_info_table)


class SystemInfo(domain_object.DomainObject):

    def __init__(self, key, value):
        self.key = key
        self.value = unicode(value)


meta.mapper(SystemInfo, system_info_table)


def get_system_info(key, default=None):
    ''' get data from system_info table '''
    obj = meta.Session.query(SystemInfo).filter_by(key=key).first()
    if obj:
        return obj.value
    else:
        return default


def delete_system_info(key, default=None):
    ''' delete data from system_info table '''
    obj = meta.Session.query(SystemInfo).filter_by(key=key).first()
    if obj:
        meta.Session.delete(obj)
        meta.Session.commit()


def set_system_info(key, value):
    ''' save data in the system_info table '''

    obj = None
    obj = meta.Session.query(SystemInfo).filter_by(key=key).first()
    if obj and obj.value == unicode(value):
        return
    if not obj:
        obj = SystemInfo(key, value)
    else:
        obj.value = unicode(value)
    meta.Session.add(obj)
    meta.Session.commit()

########NEW FILE########
__FILENAME__ = tag
import vdm.sqlalchemy
from sqlalchemy.orm import relation
from sqlalchemy import types, Column, Table, ForeignKey, and_, UniqueConstraint

import package as _package
import extension as _extension
import core
import meta
import types as _types
import domain_object
import vocabulary
import activity
import ckan  # this import is needed
import ckan.lib.dictization

__all__ = ['tag_table', 'package_tag_table', 'Tag', 'PackageTag',
           'package_tag_revision_table',
           'MAX_TAG_LENGTH', 'MIN_TAG_LENGTH']

MAX_TAG_LENGTH = 100
MIN_TAG_LENGTH = 2

tag_table = Table('tag', meta.metadata,
        Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
        Column('name', types.Unicode(MAX_TAG_LENGTH), nullable=False),
        Column('vocabulary_id',
            types.Unicode(vocabulary.VOCABULARY_NAME_MAX_LENGTH),
            ForeignKey('vocabulary.id')),
        UniqueConstraint('name', 'vocabulary_id')
)

package_tag_table = Table('package_tag', meta.metadata,
        Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
        Column('package_id', types.UnicodeText, ForeignKey('package.id')),
        Column('tag_id', types.UnicodeText, ForeignKey('tag.id')),
        )

vdm.sqlalchemy.make_table_stateful(package_tag_table)
# TODO: this has a composite primary key ...
package_tag_revision_table = core.make_revisioned_table(package_tag_table)

class Tag(domain_object.DomainObject):
    def __init__(self, name='', vocabulary_id=None):
        self.name = name
        self.vocabulary_id = vocabulary_id

    # not stateful so same as purge
    def delete(self):
        self.purge()

    @classmethod
    def by_id(cls, tag_id, autoflush=True):
        '''Return the tag with the given id, or None.

        :param tag_id: the id of the tag to return
        :type tag_id: string

        :returns: the tag with the given id, or None if there is no tag with
            that id
        :rtype: ckan.model.tag.Tag

        '''
        query = meta.Session.query(Tag).filter(Tag.id==tag_id)
        query = query.autoflush(autoflush)
        tag = query.first()
        return tag

    @classmethod
    def by_name(cls, name, vocab=None, autoflush=True):
        '''Return the tag with the given name, or None.

        By default only free tags (tags which do not belong to any vocabulary)
        are returned.

        If the optional argument ``vocab`` is given then only tags from that
        vocabulary are returned, or ``None`` if there is no tag with that name
        in that vocabulary.

        :param name: the name of the tag to return
        :type name: string
        :param vocab: the vocabulary to look in (optional, default: None)
        :type vocab: ckan.model.vocabulary.Vocabulary

        :returns: the tag object with the given id or name, or None if there is
            no tag with that id or name
        :rtype: ckan.model.tag.Tag

        '''
        if vocab:
            query = meta.Session.query(Tag).filter(Tag.name==name).filter(
                Tag.vocabulary_id==vocab.id)
        else:
            query = meta.Session.query(Tag).filter(Tag.name==name).filter(
                Tag.vocabulary_id==None)
        query = query.autoflush(autoflush)
        tag = query.first()
        return tag

    @classmethod
    def get(cls, tag_id_or_name, vocab_id_or_name=None):
        '''Return the tag with the given id or name, or None.

        By default only free tags (tags which do not belong to any vocabulary)
        are returned.

        If the optional argument ``vocab_id_or_name`` is given then only tags
        that belong to that vocabulary will be returned, and ``None`` will be
        returned if there is no vocabulary with that vocabulary id or name or
        if there is no tag with that tag id or name in that vocabulary.

        :param tag_id_or_name: the id or name of the tag to return
        :type tag_id_or_name: string
        :param vocab_id_or_name: the id or name of the vocabulary to look for
            the tag in
        :type vocab_id_or_name: string

        :returns: the tag object with the given id or name, or None if there is
            no tag with that id or name
        :rtype: ckan.model.tag.Tag

        '''
        # First try to get the tag by ID.
        tag = Tag.by_id(tag_id_or_name)
        if tag:
            return tag
        else:
            # If that didn't work, try to get the tag by name and vocabulary.
            if vocab_id_or_name:
                vocab = vocabulary.Vocabulary.get(vocab_id_or_name)
                if vocab is None:
                    # The user specified an invalid vocab.
                    raise ckan.logic.NotFound("could not find vocabulary '%s'"
                            % vocab_id_or_name)
            else:
                vocab = None
            tag = Tag.by_name(tag_id_or_name, vocab=vocab)
            return tag
        # Todo: Make sure tag names can't be changed to look like tag IDs?

    @classmethod
    def search_by_name(cls, search_term, vocab_id_or_name=None):
        '''Return all tags whose names contain a given string.

        By default only free tags (tags which do not belong to any vocabulary)
        are returned. If the optional argument ``vocab_id_or_name`` is given
        then only tags from that vocabulary are returned.

        :param search_term: the string to search for in the tag names
        :type search_term: string
        :param vocab_id_or_name: the id or name of the vocabulary to look in
            (optional, default: None)
        :type vocab_id_or_name: string

        :returns: a list of tags that match the search term
        :rtype: list of ckan.model.tag.Tag objects

        '''
        if vocab_id_or_name:
            vocab = vocabulary.Vocabulary.get(vocab_id_or_name)
            if vocab is None:
                # The user specified an invalid vocab.
                return None
            query = meta.Session.query(Tag).filter(Tag.vocabulary_id==vocab.id)
        else:
            query = meta.Session.query(Tag)
        search_term = search_term.strip().lower()
        query = query.filter(Tag.name.contains(search_term))
        query = query.distinct().join(Tag.package_tags)
        return query

    @classmethod
    def all(cls, vocab_id_or_name=None):
        '''Return all tags that are currently applied to any dataset.

        By default only free tags (tags which do not belong to any vocabulary)
        are returned. If the optional argument ``vocab_id_or_name`` is given
        then only tags from that vocabulary are returned.

        :param vocab_id_or_name: the id or name of the vocabulary to look in
            (optional, default: None)
        :type vocab_id_or_name: string

        :returns: a list of all tags that are currently applied to any dataset
        :rtype: list of ckan.model.tag.Tag objects

        '''
        if vocab_id_or_name:
            vocab = vocabulary.Vocabulary.get(vocab_id_or_name)
            if vocab is None:
                # The user specified an invalid vocab.
                raise ckan.logic.NotFound("could not find vocabulary '%s'"
                        % vocab_id_or_name)
            query = meta.Session.query(Tag).filter(Tag.vocabulary_id==vocab.id)
        else:
            query = meta.Session.query(Tag).filter(Tag.vocabulary_id == None)
            query = query.distinct().join(_package.PackageTagRevision)
            query = query.filter(and_(
                _package.PackageTagRevision.state == 'active',
                _package.PackageTagRevision.current == True))
        return query

    @property
    def packages(self):
        '''Return a list of all packages that have this tag, sorted by name.

        :rtype: list of ckan.model.package.Package objects

        '''
        q = meta.Session.query(_package.Package)
        q = q.join(_package.PackageTagRevision)
        q = q.filter(_package.PackageTagRevision.tag_id == self.id)
        q = q.filter(and_(
            _package.PackageTagRevision.state == 'active',
            _package.PackageTagRevision.current == True))
        q = q.order_by(_package.Package.name)
        packages = q.all()
        return packages

    def __repr__(self):
        return '<Tag %s>' % self.name

class PackageTag(vdm.sqlalchemy.RevisionedObjectMixin,
        vdm.sqlalchemy.StatefulObjectMixin,
        domain_object.DomainObject):
    def __init__(self, package=None, tag=None, state=None, **kwargs):
        self.package = package
        self.tag = tag
        self.state = state
        for k,v in kwargs.items():
            setattr(self, k, v)

    def __repr__(self):
        s = u'<PackageTag package=%s tag=%s>' % (self.package.name, self.tag.name)
        return s.encode('utf8')

    def activity_stream_detail(self, activity_id, activity_type):
        if activity_type == 'new':
            # New PackageTag objects are recorded as 'added tag' activities.
            activity_type = 'added'
        elif activity_type == 'changed':
            # Changed PackageTag objects are recorded as 'removed tag'
            # activities.
            # FIXME: This assumes that whenever a PackageTag is changed it's
            # because its' state has been changed from 'active' to 'deleted'.
            # Should do something more here to test whether that is in fact
            # what has changed.
            activity_type = 'removed'
        else:
            return None

        # Return an 'added tag' or 'removed tag' activity.
        import ckan.model as model
        c = {'model': model}
        d = {'tag': ckan.lib.dictization.table_dictize(self.tag, c),
            'package': ckan.lib.dictization.table_dictize(self.package, c)}
        return activity.ActivityDetail(
            activity_id=activity_id,
            object_id=self.id,
            object_type='tag',
            activity_type=activity_type,
            data=d)

    @classmethod
    def by_name(self, package_name, tag_name, vocab_id_or_name=None,
            autoflush=True):
        '''Return the PackageTag for the given package and tag names, or None.

        By default only PackageTags for free tags (tags which do not belong to
        any vocabulary) are returned. If the optional argument
        ``vocab_id_or_name`` is given then only PackageTags for tags from that
        vocabulary are returned.

        :param package_name: the name of the package to look for
        :type package_name: string
        :param tag_name: the name of the tag to look for
        :type tag_name: string
        :param vocab_id_or_name: the id or name of the vocabulary to look for
            the tag in
        :type vocab_id_or_name: string

        :returns: the PackageTag for the given package and tag names, or None
            if there is no PackageTag for those package and tag names
        :rtype: ckan.model.tag.PackageTag

        '''
        if vocab_id_or_name:
            vocab = vocabulary.Vocabulary.get(vocab_id_or_name)
            if vocab is None:
                # The user specified an invalid vocab.
                return None
            query = (meta.Session.query(PackageTag, Tag, _package.Package)
                    .filter(Tag.vocabulary_id == vocab.id)
                    .filter(_package.Package.name==package_name)
                    .filter(Tag.name==tag_name))
        else:
            query = (meta.Session.query(PackageTag)
                    .filter(_package.Package.name==package_name)
                    .filter(Tag.name==tag_name))
        query = query.autoflush(autoflush)
        return query.one()[0]

    def related_packages(self):
        return [self.package]

meta.mapper(Tag, tag_table, properties={
    'package_tags': relation(PackageTag, backref='tag',
        cascade='all, delete, delete-orphan',
        ),
    'vocabulary': relation(vocabulary.Vocabulary,
        order_by=tag_table.c.name)
    },
    order_by=tag_table.c.name,
    )

meta.mapper(PackageTag, package_tag_table, properties={
    'pkg':relation(_package.Package, backref='package_tag_all',
        cascade='none',
        )
    },
    order_by=package_tag_table.c.id,
    extension=[vdm.sqlalchemy.Revisioner(package_tag_revision_table),
               _extension.PluginMapperExtension(),
               ],
    )

########NEW FILE########
__FILENAME__ = task_status
from datetime import datetime
from sqlalchemy import types, Column, Table, UniqueConstraint

import meta
import types as _types
import domain_object

__all__ = ['TaskStatus', 'task_status_table']

task_status_table = Table('task_status', meta.metadata,
    Column('id', types.UnicodeText, primary_key=True, default=_types.make_uuid),
    Column('entity_id', types.UnicodeText, nullable=False),
    Column('entity_type', types.UnicodeText, nullable=False),
    Column('task_type', types.UnicodeText, nullable=False),
    Column('key', types.UnicodeText, nullable=False),
    Column('value', types.UnicodeText, nullable=False),
    Column('state', types.UnicodeText),
    Column('error', types.UnicodeText),
    Column('last_updated', types.DateTime, default=datetime.now),
    UniqueConstraint('entity_id', 'task_type', 'key')
)

class TaskStatus(domain_object.DomainObject):
    @classmethod
    def get(cls, reference):
        '''Returns a task status object referenced by its id.'''
        query = meta.Session.query(cls).filter(cls.id==reference)
        return query.first()

meta.mapper(TaskStatus, task_status_table)

########NEW FILE########
__FILENAME__ = term_translation
from sqlalchemy import Column, Table
from sqlalchemy.types import UnicodeText
import meta

__all__ = ['term_translation_table']

term_translation_table = Table('term_translation', meta.metadata,
    Column('term', UnicodeText, nullable=False),
    Column('term_translation', UnicodeText, nullable=False),
    Column('lang_code', UnicodeText, nullable=False),
)


########NEW FILE########
__FILENAME__ = tracking
from sqlalchemy import types, Column, Table

import meta
import domain_object

__all__ = ['tracking_summary_table', 'TrackingSummary', 'tracking_raw_table']

tracking_raw_table = Table('tracking_raw', meta.metadata,
        Column('user_key', types.Unicode(100), nullable=False),
        Column('url', types.UnicodeText, nullable=False),
        Column('tracking_type', types.Unicode(10), nullable=False),
        Column('access_timestamp', types.DateTime),
    )


tracking_summary_table = Table('tracking_summary', meta.metadata,
        Column('url', types.UnicodeText, primary_key=True, nullable=False),
        Column('package_id', types.UnicodeText),
        Column('tracking_type', types.Unicode(10), nullable=False),
        Column('count', types.Integer, nullable=False),
        Column('running_total', types.Integer, nullable=False),
        Column('recent_views', types.Integer, nullable=False),
        Column('tracking_date', types.DateTime),
    )

class TrackingSummary(domain_object.DomainObject):

    @classmethod
    def get_for_package(cls, package_id):
        obj = meta.Session.query(cls).autoflush(False)
        obj = obj.filter_by(package_id=package_id)
        data = obj.order_by('tracking_date desc').first()
        if data:
            return {'total' : data.running_total,
                    'recent': data.recent_views}

        return {'total' : 0, 'recent' : 0}


    @classmethod
    def get_for_resource(cls, url):
        obj = meta.Session.query(cls).autoflush(False)
        data = obj.filter_by(url=url).order_by('tracking_date desc').first()
        if data:
            return {'total' : data.running_total,
                    'recent': data.recent_views}

        return {'total' : 0, 'recent' : 0}

meta.mapper(TrackingSummary, tracking_summary_table)

########NEW FILE########
__FILENAME__ = types
## IMPORTS FIXED
import datetime
import copy
import uuid
import simplejson as json

from sqlalchemy import types

import meta

__all__ = ['iso_date_to_datetime_for_sqlite', 'make_uuid', 'UuidType',
           'JsonType', 'JsonDictType']

def make_uuid():
    return unicode(uuid.uuid4())

class UuidType(types.TypeDecorator):
    impl = types.Unicode

    def process_bind_param(self, value, engine):
        return unicode(value)

    def process_result_value(self, value, engine):
        # return uuid.UUID(value)
        return value

    def copy(self):
        return UuidType(self.impl.length)

    @classmethod
    def default(cls):
        # return uuid.uuid4()
        return unicode(uuid.uuid4())


class JsonType(types.TypeDecorator):
    '''Store data as JSON serializing on save and unserializing on use.

    Note that default values don\'t appear to work correctly with this
    type, a workaround is to instead override ``__init__()`` to explicitly
    set any default values you expect.
    '''
    impl = types.UnicodeText

    def process_bind_param(self, value, engine):
        if value is None or value == {}: # ensure we stores nulls in db not json "null"
            return None
        else:
            # ensure_ascii=False => allow unicode but still need to convert
            return unicode(json.dumps(value, ensure_ascii=False))

    def process_result_value(self, value, engine):
        if value is None:
            return {}
        else:
            return json.loads(value)

    def copy(self):
        return JsonType(self.impl.length)

    def is_mutable(self):
        return True

    def copy_value(self, value):
        return copy.copy(value)

class JsonDictType(JsonType):

    impl = types.UnicodeText

    def process_bind_param(self, value, engine):
        if value is None or value == {}: # ensure we stores nulls in db not json "null"
            return None
        else:
            if isinstance(value, basestring):
                return unicode(value)
            else:
                return unicode(json.dumps(value, ensure_ascii=False))

    def copy(self):
        return JsonDictType(self.impl.length)

def iso_date_to_datetime_for_sqlite(datetime_or_iso_date_if_sqlite):
    # Because sqlite cannot store dates properly (see this:
    # http://www.sqlalchemy.org/docs/dialects/sqlite.html#date-and-time-types )
    # when you get a result from a date field in the database, you need
    # to call this to convert it into a datetime type. When running on
    # postgres then you have a datetime anyway, so this function doesn't
    # do anything.
    if meta.engine_is_sqlite() and isinstance(datetime_or_iso_date_if_sqlite, basestring):
        return datetime.datetime.strptime(datetime_or_iso_date_if_sqlite,
                                          '%Y-%m-%d %H:%M:%S.%f')
    else:
        return datetime_or_iso_date_if_sqlite

########NEW FILE########
__FILENAME__ = user
import datetime
import re
import os
from hashlib import sha1, md5

from sqlalchemy.sql.expression import or_
from sqlalchemy.orm import synonym
from sqlalchemy import types, Column, Table
import vdm.sqlalchemy

import meta
import core
import types as _types
import domain_object

user_table = Table('user', meta.metadata,
        Column('id', types.UnicodeText, primary_key=True,
               default=_types.make_uuid),
        Column('name', types.UnicodeText, nullable=False, unique=True),
        Column('openid', types.UnicodeText),
        Column('password', types.UnicodeText),
        Column('fullname', types.UnicodeText),
        Column('email', types.UnicodeText),
        Column('apikey', types.UnicodeText, default=_types.make_uuid),
        Column('created', types.DateTime, default=datetime.datetime.now),
        Column('reset_key', types.UnicodeText),
        Column('about', types.UnicodeText),
        Column('activity_streams_email_notifications', types.Boolean,
            default=False),
        Column('sysadmin', types.Boolean, default=False),
        )

vdm.sqlalchemy.make_table_stateful(user_table)


class User(vdm.sqlalchemy.StatefulObjectMixin,
           domain_object.DomainObject):

    VALID_NAME = re.compile(r"^[a-zA-Z0-9_\-]{3,255}$")
    DOUBLE_SLASH = re.compile(':\/([^/])')

    @classmethod
    def by_openid(cls, openid):
        obj = meta.Session.query(cls).autoflush(False)
        return obj.filter_by(openid=openid).first()

    @classmethod
    def by_email(cls, email):
        return meta.Session.query(cls).filter_by(email=email).all()

    @classmethod
    def get(cls, user_reference):
        # double slashes in an openid often get turned into single slashes
        # by browsers, so correct that for the openid lookup
        corrected_openid_user_ref = cls.DOUBLE_SLASH.sub('://\\1',
                                                         user_reference)
        query = meta.Session.query(cls).autoflush(False)
        query = query.filter(or_(cls.name == user_reference,
                                 cls.openid == corrected_openid_user_ref,
                                 cls.id == user_reference))
        return query.first()

    @classmethod
    def all(cls):
        '''Return all users in this CKAN instance.

        :rtype: list of ckan.model.user.User objects

        '''
        q = meta.Session.query(cls)
        return q.all()

    @property
    def display_name(self):
        if self.fullname is not None and len(self.fullname.strip()) > 0:
            return self.fullname
        return self.name

    @property
    def email_hash(self):
        e = ''
        if self.email:
            e = self.email.strip().lower().encode('utf8')
        return md5(e).hexdigest()

    def get_reference_preferred_for_uri(self):
        '''Returns a reference (e.g. name, id, openid) for this user
        suitable for the user\'s URI.
        When there is a choice, the most preferable one will be
        given, based on readability. This is expected when repoze.who can
        give a more friendly name for an openid user.
        The result is not escaped (will get done in url_for/redirect_to).
        '''
        if self.name:
            ref = self.name
        elif self.openid:
            ref = self.openid
        else:
            ref = self.id
        return ref

    def _set_password(self, password):
        '''Hash password on the fly.'''
        if isinstance(password, unicode):
            password_8bit = password.encode('ascii', 'ignore')
        else:
            password_8bit = password

        salt = sha1(os.urandom(60))
        hash = sha1(password_8bit + salt.hexdigest())
        hashed_password = salt.hexdigest() + hash.hexdigest()

        if not isinstance(hashed_password, unicode):
            hashed_password = hashed_password.decode('utf-8')
        self._password = hashed_password

    def _get_password(self):
        '''Return the password hashed'''
        return self._password

    def validate_password(self, password):
        '''
        Check the password against existing credentials.

        :param password: the password that was provided by the user to
            try and authenticate. This is the clear text version that we will
            need to match against the hashed one in the database.
        :type password: unicode object.
        :return: Whether the password is valid.
        :rtype: bool
        '''
        if not password or not self.password:
            return False
        if isinstance(password, unicode):
            password_8bit = password.encode('ascii', 'ignore')
        else:
            password_8bit = password
        hashed_pass = sha1(password_8bit + self.password[:40])
        return self.password[40:] == hashed_pass.hexdigest()

    password = property(_get_password, _set_password)

    @classmethod
    def check_name_valid(cls, name):
        if not name \
            or not len(name.strip()) \
            or not cls.VALID_NAME.match(name):
            return False
        return True

    @classmethod
    def check_name_available(cls, name):
        return cls.by_name(name) == None

    def as_dict(self):
        _dict = domain_object.DomainObject.as_dict(self)
        del _dict['password']
        return _dict

    def number_of_edits(self):
        # have to import here to avoid circular imports
        import ckan.model as model
        revisions_q = meta.Session.query(model.Revision)
        revisions_q = revisions_q.filter_by(author=self.name)
        return revisions_q.count()

    def number_administered_packages(self):
        # have to import here to avoid circular imports
        import ckan.model as model
        q = meta.Session.query(model.PackageRole)
        q = q.filter_by(user=self, role=model.Role.ADMIN)
        return q.count()

    def activate(self):
        ''' Activate the user '''
        self.state = core.State.ACTIVE

    def set_pending(self):
        ''' Set the user as pending '''
        self.state = core.State.PENDING

    def is_deleted(self):
        return self.state == core.State.DELETED

    def is_pending(self):
        return self.state == core.State.PENDING

    def is_in_group(self, group_id):
        return group_id in self.get_group_ids()

    def is_in_groups(self, group_ids):
        ''' Given a list of group ids, returns True if this user is in
        any of those groups '''
        guser = set(self.get_group_ids())
        gids = set(group_ids)

        return len(guser.intersection(gids)) > 0

    def get_group_ids(self, group_type=None, capacity=None):
        ''' Returns a list of group ids that the current user belongs to '''
        return [g.id for g in
                self.get_groups(group_type=group_type, capacity=capacity)]

    def get_groups(self, group_type=None, capacity=None):
        import ckan.model as model

        q = meta.Session.query(model.Group)\
            .join(model.Member, model.Member.group_id == model.Group.id and \
                       model.Member.table_name == 'user').\
               join(model.User, model.User.id == model.Member.table_id).\
               filter(model.Member.state == 'active').\
               filter(model.Member.table_id == self.id)
        if capacity:
            q = q.filter(model.Member.capacity == capacity)
            return q.all()

        if '_groups' not in self.__dict__:
            self._groups = q.all()

        groups = self._groups
        if group_type:
            groups = [g for g in groups if g.type == group_type]
        return groups

    @classmethod
    def search(cls, querystr, sqlalchemy_query=None, user_name=None):
        '''Search name, fullname, email and openid. '''
        if sqlalchemy_query is None:
            query = meta.Session.query(cls)
        else:
            query = sqlalchemy_query
        qstr = '%' + querystr + '%'
        filters = [
            cls.name.ilike(qstr),
            cls.fullname.ilike(qstr),
            cls.openid.ilike(qstr),
        ]
        # sysadmins can search on user emails
        import ckan.new_authz as new_authz
        if user_name and new_authz.is_sysadmin(user_name):
            filters.append(cls.email.ilike(qstr))

        query = query.filter(or_(*filters))
        return query

    @classmethod
    def user_ids_for_name_or_id(self, user_list=[]):
        '''
        This function returns a list of ids from an input that can be a list of
        names or ids
        '''
        query = meta.Session.query(self.id)
        query = query.filter(or_(self.name.in_(user_list),
                                 self.id.in_(user_list)))
        return [user.id for user in query.all()]


meta.mapper(User, user_table,
    properties={'password': synonym('_password', map_column=True)},
    order_by=user_table.c.name)

########NEW FILE########
__FILENAME__ = vocabulary
from sqlalchemy import types, Column, Table

import meta
import types as _types
import tag
import domain_object

VOCABULARY_NAME_MIN_LENGTH = 2
VOCABULARY_NAME_MAX_LENGTH = 100

vocabulary_table = Table(
    'vocabulary', meta.metadata,
    Column('id', types.UnicodeText, primary_key=True,
           default=_types.make_uuid),
    Column('name', types.Unicode(VOCABULARY_NAME_MAX_LENGTH), nullable=False,
        unique=True),
    )


class Vocabulary(domain_object.DomainObject):

    def __init__(self, name):
        self.id = _types.make_uuid()
        self.name = name

    @classmethod
    def get(cls, id_or_name):
        '''Return a Vocabulary object referenced by its id or name, or
        None if there is no vocabulary with the given id or name. '''
        query = meta.Session.query(Vocabulary)
        query = query.filter(Vocabulary.id == id_or_name)
        vocab = query.first()
        if vocab is None:
            vocab = Vocabulary.by_name(id_or_name)
        return vocab

    @property
    def tags(self):
        query = meta.Session.query(tag.Tag)
        return query.filter(tag.Tag.vocabulary_id == self.id)

meta.mapper(Vocabulary, vocabulary_table)

########NEW FILE########
__FILENAME__ = new_authz
import sys
import re
from logging import getLogger

from pylons import config
from paste.deploy.converters import asbool

import ckan.plugins as p
import ckan.model as model
from ckan.common import OrderedDict, _, c

import ckan.lib.maintain as maintain

log = getLogger(__name__)


class AuthFunctions:
    ''' This is a private cache used by get_auth_function() and should never be
    accessed directly we will create an instance of it and then remove it.'''
    _functions = {}

    def clear(self):
        ''' clear any stored auth functions. '''
        self._functions.clear()

    def keys(self):
        ''' Return a list of known auth functions.'''
        if not self._functions:
            self._build()
        return self._functions.keys()

    def get(self, function):
        ''' Return the requested auth function. '''
        if not self._functions:
            self._build()
        return self._functions.get(function)

    def _build(self):
        ''' Gather the auth functions.

        First get the default ones in the ckan/logic/auth directory Rather than
        writing them out in full will use __import__ to load anything from
        ckan.auth that looks like it might be an authorisation function'''

        module_root = 'ckan.logic.auth'

        for auth_module_name in ['get', 'create', 'update', 'delete']:
            module_path = '%s.%s' % (module_root, auth_module_name,)
            try:
                module = __import__(module_path)
            except ImportError:
                log.debug('No auth module for action "%s"' % auth_module_name)
                continue

            for part in module_path.split('.')[1:]:
                module = getattr(module, part)

            for key, v in module.__dict__.items():
                if not key.startswith('_'):
                    # Whitelist all auth functions defined in
                    # logic/auth/get.py as not requiring an authorized user,
                    # as well as ensuring that the rest do. In both cases, do
                    # nothing if a decorator has already been used to define
                    # the behaviour
                    if not hasattr(v, 'auth_allow_anonymous_access'):
                        if auth_module_name == 'get':
                            v.auth_allow_anonymous_access = True
                        else:
                            v.auth_allow_anonymous_access = False
                    self._functions[key] = v

        # Then overwrite them with any specific ones in the plugins:
        resolved_auth_function_plugins = {}
        fetched_auth_functions = {}
        for plugin in p.PluginImplementations(p.IAuthFunctions):
            for name, auth_function in plugin.get_auth_functions().items():
                if name in resolved_auth_function_plugins:
                    raise Exception(
                        'The auth function %r is already implemented in %r' % (
                            name,
                            resolved_auth_function_plugins[name]
                        )
                    )
                log.debug('Auth function {0} from plugin {1} was inserted'.format(name, plugin.name))
                resolved_auth_function_plugins[name] = plugin.name
                fetched_auth_functions[name] = auth_function
        # Use the updated ones in preference to the originals.
        self._functions.update(fetched_auth_functions)

_AuthFunctions = AuthFunctions()
#remove the class
del AuthFunctions


def clear_auth_functions_cache():
    _AuthFunctions.clear()
    CONFIG_PERMISSIONS.clear()


def auth_functions_list():
    '''Returns a list of the names of the auth functions available.  Currently
    this is to allow the Auth Audit to know if an auth function is available
    for a given action.'''
    return _AuthFunctions.keys()


def is_sysadmin(username):
    ''' Returns True is username is a sysadmin '''
    user = _get_user(username)
    return user and user.sysadmin


def _get_user(username):
    ''' Try to get the user from c, if possible, and fallback to using the DB '''
    if not username:
        return None
    # See if we can get the user without touching the DB
    try:
        if c.userobj and c.userobj.name == username:
            return c.userobj
    except TypeError:
        # c is not available
        pass
    # Get user from the DB
    return model.User.get(username)


def get_group_or_org_admin_ids(group_id):
    if not group_id:
        return []
    group_id = model.Group.get(group_id).id
    q = model.Session.query(model.Member) \
        .filter(model.Member.group_id == group_id) \
        .filter(model.Member.table_name == 'user') \
        .filter(model.Member.state == 'active') \
        .filter(model.Member.capacity == 'admin')
    return [a.table_id for a in q.all()]


def is_authorized_boolean(action, context, data_dict=None):
    ''' runs the auth function but just returns True if allowed else False
    '''
    outcome = is_authorized(action, context, data_dict=data_dict)
    return outcome.get('success', False)


def is_authorized(action, context, data_dict=None):
    if context.get('ignore_auth'):
        return {'success': True}

    auth_function = _AuthFunctions.get(action)
    if auth_function:
        username = context.get('user')
        user = _get_user(username)

        if user:
            # deleted users are always unauthorized
            if user.is_deleted():
                return {'success': False}
            # sysadmins can do anything unless the auth_sysadmins_check
            # decorator was used in which case they are treated like all other
            # users.
            elif user.sysadmin:
                if not getattr(auth_function, 'auth_sysadmins_check', False):
                    return {'success': True}

        # If the auth function is flagged as not allowing anonymous access,
        # and an existing user object is not provided in the context, deny
        # access straight away
        if not getattr(auth_function, 'auth_allow_anonymous_access', False) \
           and not context.get('auth_user_obj'):
            return {'success': False,
                    'msg': '{0} requires an authenticated user'
                            .format(auth_function)
                   }

        return auth_function(context, data_dict)
    else:
        raise ValueError(_('Authorization function not found: %s' % action))


# these are the permissions that roles have
ROLE_PERMISSIONS = OrderedDict([
    ('admin', ['admin']),
    ('editor', ['read', 'delete_dataset', 'create_dataset', 'update_dataset', 'manage_group']),
    ('member', ['read', 'manage_group']),
])


def _trans_role_admin():
    return _('Admin')


def _trans_role_editor():
    return _('Editor')


def _trans_role_member():
    return _('Member')


def trans_role(role):
    module = sys.modules[__name__]
    return getattr(module, '_trans_role_%s' % role)()


def roles_list():
    ''' returns list of roles for forms '''
    roles = []
    for role in ROLE_PERMISSIONS:
        roles.append(dict(text=trans_role(role), value=role))
    return roles


def roles_trans():
    ''' return dict of roles with translation '''
    roles = {}
    for role in ROLE_PERMISSIONS:
        roles[role] = trans_role(role)
    return roles


def get_roles_with_permission(permission):
    ''' returns the roles with the permission requested '''
    roles = []
    for role in ROLE_PERMISSIONS:
        permissions = ROLE_PERMISSIONS[role]
        if permission in permissions or 'admin' in permissions:
            roles.append(role)
    return roles


def has_user_permission_for_group_or_org(group_id, user_name, permission):
    ''' Check if the user has the given permissions for the group, allowing for
    sysadmin rights and permission cascading down a group hierarchy.

    '''
    if not group_id:
        return False
    group = model.Group.get(group_id)
    if not group:
        return False
    group_id = group.id

    # Sys admins can do anything
    if is_sysadmin(user_name):
        return True

    user_id = get_user_id_for_username(user_name, allow_none=True)
    if not user_id:
        return False
    if _has_user_permission_for_groups(user_id, permission, [group_id]):
        return True
    # Handle when permissions cascade. Check the user's roles on groups higher
    # in the group hierarchy for permission.
    for capacity in check_config_permission('roles_that_cascade_to_sub_groups'):
        parent_groups = group.get_parent_group_hierarchy(type=group.type)
        group_ids = [group_.id for group_ in parent_groups]
        if _has_user_permission_for_groups(user_id, permission, group_ids,
                                           capacity=capacity):
            return True
    return False


def _has_user_permission_for_groups(user_id, permission, group_ids,
                                    capacity=None):
    ''' Check if the user has the given permissions for the particular
    group (ignoring permissions cascading in a group hierarchy).
    Can also be filtered by a particular capacity.
    '''
    if not group_ids:
        return False
    # get any roles the user has for the group
    q = model.Session.query(model.Member) \
        .filter(model.Member.group_id.in_(group_ids)) \
        .filter(model.Member.table_name == 'user') \
        .filter(model.Member.state == 'active') \
        .filter(model.Member.table_id == user_id)
    if capacity:
        q = q.filter(model.Member.capacity == capacity)
    # see if any role has the required permission
    # admin permission allows anything for the group
    for row in q.all():
        perms = ROLE_PERMISSIONS.get(row.capacity, [])
        if 'admin' in perms or permission in perms:
            return True
    return False


def users_role_for_group_or_org(group_id, user_name):
    ''' Returns the user's role for the group. (Ignores privileges that cascade
    in a group hierarchy.)

    '''
    if not group_id:
        return None
    group_id = model.Group.get(group_id).id

    user_id = get_user_id_for_username(user_name, allow_none=True)
    if not user_id:
        return None
    # get any roles the user has for the group
    q = model.Session.query(model.Member) \
        .filter(model.Member.group_id == group_id) \
        .filter(model.Member.table_name == 'user') \
        .filter(model.Member.state == 'active') \
        .filter(model.Member.table_id == user_id)
    # return the first role we find
    for row in q.all():
        return row.capacity
    return None


def has_user_permission_for_some_org(user_name, permission):
    ''' Check if the user has the given permission for any organization. '''
    user_id = get_user_id_for_username(user_name, allow_none=True)
    if not user_id:
        return False
    roles = get_roles_with_permission(permission)

    if not roles:
        return False
    # get any groups the user has with the needed role
    q = model.Session.query(model.Member) \
        .filter(model.Member.table_name == 'user') \
        .filter(model.Member.state == 'active') \
        .filter(model.Member.capacity.in_(roles)) \
        .filter(model.Member.table_id == user_id)
    group_ids = []
    for row in q.all():
        group_ids.append(row.group_id)
    # if not in any groups has no permissions
    if not group_ids:
        return False

    # see if any of the groups are orgs
    q = model.Session.query(model.Group) \
        .filter(model.Group.is_organization == True) \
        .filter(model.Group.state == 'active') \
        .filter(model.Group.id.in_(group_ids))

    return bool(q.count())


def get_user_id_for_username(user_name, allow_none=False):
    ''' Helper function to get user id '''
    # first check if we have the user object already and get from there
    try:
        if c.userobj and c.userobj.name == user_name:
            return c.userobj.id
    except TypeError:
        # c is not available
        pass
    user = model.User.get(user_name)
    if user:
        return user.id
    if allow_none:
        return None
    raise Exception('Not logged in user')


CONFIG_PERMISSIONS_DEFAULTS = {
    # permission and default
    # these are prefixed with ckan.auth. in config to override
    'anon_create_dataset': False,
    'create_dataset_if_not_in_organization': True,
    'create_unowned_dataset': True,
    'user_create_groups': True,
    'user_create_organizations': True,
    'user_delete_groups': True,
    'user_delete_organizations': True,
    'create_user_via_api': False,
    'create_user_via_web': True,
    'roles_that_cascade_to_sub_groups': 'admin',
}

CONFIG_PERMISSIONS = {}


def check_config_permission(permission):
    ''' Returns the permission configuration, usually True/False '''
    # set up perms if not already done
    if not CONFIG_PERMISSIONS:
        for perm in CONFIG_PERMISSIONS_DEFAULTS:
            key = 'ckan.auth.' + perm
            default = CONFIG_PERMISSIONS_DEFAULTS[perm]
            CONFIG_PERMISSIONS[perm] = config.get(key, default)
            if perm == 'roles_that_cascade_to_sub_groups':
                # this permission is a list of strings (space separated)
                CONFIG_PERMISSIONS[perm] = \
                    CONFIG_PERMISSIONS[perm].split(' ') \
                    if CONFIG_PERMISSIONS[perm] else []
            else:
                # most permissions are boolean
                CONFIG_PERMISSIONS[perm] = asbool(CONFIG_PERMISSIONS[perm])
    if permission in CONFIG_PERMISSIONS:
        return CONFIG_PERMISSIONS[permission]
    return False

@maintain.deprecated('Use auth_is_loggedin_user instead')
def auth_is_registered_user():
    '''
    This function is deprecated, please use the auth_is_loggedin_user instead
    '''
    return auth_is_loggedin_user()

def auth_is_loggedin_user():
    ''' Do we have a logged in user '''
    try:
        context_user = c.user
    except TypeError:
        context_user = None
    return bool(context_user)

def auth_is_anon_user(context):
    ''' Is this an anonymous user?
        eg Not logged in if a web request and not user defined in context
        if logic functions called directly

        See ckan/lib/base.py:232 for pylons context object logic
    '''
    try:
        is_anon_user = (not bool(c.user) and bool(c.author))
    except TypeError:
        # No c object set, this is not a call done via the web interface,
        # but directly, eg from an extension
        context_user = context.get('user')
        is_anon_user = not bool(context_user)

    return is_anon_user

########NEW FILE########
__FILENAME__ = test_util
from nose.tools import assert_equal
from pylons.test import pylonsapp
import paste.fixture

from routes import url_for as url_for


# This is stolen from the old tests and should probably go in __init__.py
# if it is what we want.
class WsgiAppCase(object):
    wsgiapp = pylonsapp
    assert wsgiapp, 'You need to run nose with --with-pylons'
    # Either that, or this file got imported somehow before the tests started
    # running, meaning the pylonsapp wasn't setup yet (which is done in
    # pylons.test.py:begin())
    app = paste.fixture.TestApp(wsgiapp)


class TestUtil(WsgiAppCase):
    def test_redirect_ok(self):
        response = self.app.get(
            url=url_for(controller='util', action='redirect'),
            params={'url': '/dataset'},
            status=302,
        )
        assert_equal(response.header_dict.get('Location'),
                     'http://localhost/dataset')

    def test_redirect_external(self):
        response = self.app.get(
            url=url_for(controller='util', action='redirect'),
            params={'url': 'http://nastysite.com'},
            status=403,
        )

    def test_redirect_no_params(self):
        response = self.app.get(
            url=url_for(controller='util', action='redirect'),
            params={},
            status=400,
        )

    def test_redirect_no_params_2(self):
        response = self.app.get(
            url=url_for(controller='util', action='redirect'),
            params={'url': ''},
            status=400,
        )

########NEW FILE########
__FILENAME__ = factories
'''This is a collection of factory classes for building CKAN users, datasets,
etc.

These are meant to be used by tests to create any objects that are needed for
the tests. They're written using ``factory_boy``:

http://factoryboy.readthedocs.org/en/latest/

These are not meant to be used for the actual testing, e.g. if you're writing
a test for the :py:func:`~ckan.logic.action.create.user_create` function then
call :py:func:`~ckan.new_tests.helpers.call_action`, don't test it via the
:py:class:`~ckan.new_tests.factories.User` factory below.

Usage::

 # Create a user with the factory's default attributes, and get back a
 # user dict:
 user_dict = factories.User()

 # You can create a second user the same way. For attributes that can't be
 # the same (e.g. you can't have two users with the same name) a new value
 # will be generated each time you use the factory:
 another_user_dict = factories.User()

 # Create a user and specify your own user name and email (this works
 # with any params that CKAN's user_create() accepts):
 custom_user_dict = factories.User(name='bob', email='bob@bob.com')

 # Get a user dict containing the attributes (name, email, password, etc.)
 # that the factory would use to create a user, but without actually
 # creating the user in CKAN:
 user_attributes_dict = factories.User.attributes()

 # If you later want to create a user using these attributes, just pass them
 # to the factory:
 user = factories.User(**user_attributes_dict)

'''
import factory
import mock

import ckan.model
import ckan.logic
import ckan.new_tests.helpers as helpers


def _get_action_user_name(kwargs):
    '''Return the name of the user in kwargs, defaulting to the site user

    It can be overriden by explictly setting {'user': None} in the keyword
    arguments. In that case, this method will return None.
    '''

    if 'user' in kwargs:
        user = kwargs['user']
    else:
        user = helpers.call_action('get_site_user')

    if user is None:
        user_name = None
    else:
        user_name = user['name']

    return user_name


def _generate_email(user):
    '''Return an email address for the given User factory stub object.'''

    return '{0}@ckan.org'.format(user.name).lower()


def _generate_reset_key(user):
    '''Return a reset key for the given User factory stub object.'''

    return '{0}_reset_key'.format(user.name).lower()


def _generate_user_id(user):
    '''Return a user id for the given User factory stub object.'''

    return '{0}_user_id'.format(user.name).lower()


def _generate_group_title(group):
    '''Return a title for the given Group factory stub object.'''

    return group.name.replace('_', ' ').title()


class User(factory.Factory):
    '''A factory class for creating CKAN users.'''

    # This is the class that UserFactory will create and return instances
    # of.
    FACTORY_FOR = ckan.model.User

    # These are the default params that will be used to create new users.
    fullname = 'Mr. Test User'
    password = 'pass'
    about = 'Just another test user.'

    # Generate a different user name param for each user that gets created.
    name = factory.Sequence(lambda n: 'test_user_{n}'.format(n=n))

    # Compute the email param for each user based on the values of the other
    # params above.
    email = factory.LazyAttribute(_generate_email)

    # I'm not sure how to support factory_boy's .build() feature in CKAN,
    # so I've disabled it here.
    @classmethod
    def _build(cls, target_class, *args, **kwargs):
        raise NotImplementedError(".build() isn't supported in CKAN")

    # To make factory_boy work with CKAN we override _create() and make it call
    # a CKAN action function.
    # We might also be able to do this by using factory_boy's direct SQLAlchemy
    # support: http://factoryboy.readthedocs.org/en/latest/orms.html#sqlalchemy
    @classmethod
    def _create(cls, target_class, *args, **kwargs):
        if args:
            assert False, "Positional args aren't supported, use keyword args."
        user_dict = helpers.call_action('user_create', **kwargs)
        return user_dict


class Resource(factory.Factory):
    '''A factory class for creating CKAN resources.'''

    FACTORY_FOR = ckan.model.Resource

    name = factory.Sequence(lambda n: 'test_resource_{n}'.format(n=n))
    description = 'Just another test resource.'
    format = 'res_format'
    url = 'http://link.to.some.data'
    package_id = factory.LazyAttribute(lambda _: Dataset()['id'])

    @classmethod
    def _build(cls, target_class, *args, **kwargs):
        raise NotImplementedError(".build() isn't supported in CKAN")

    @classmethod
    def _create(cls, target_class, *args, **kwargs):
        if args:
            assert False, "Positional args aren't supported, use keyword args."

        context = {'user': _get_action_user_name(kwargs)}

        resource_dict = helpers.call_action('resource_create', context=context,
                                            **kwargs)
        return resource_dict


class Sysadmin(factory.Factory):
    '''A factory class for creating sysadmin users.'''

    FACTORY_FOR = ckan.model.User

    fullname = 'Mr. Test Sysadmin'
    password = 'pass'
    about = 'Just another test sysadmin.'

    name = factory.Sequence(lambda n: 'test_sysadmin_{n}'.format(n=n))

    email = factory.LazyAttribute(_generate_email)
    sysadmin = True

    @classmethod
    def _build(cls, target_class, *args, **kwargs):
        raise NotImplementedError(".build() isn't supported in CKAN")

    @classmethod
    def _create(cls, target_class, *args, **kwargs):
        if args:
            assert False, "Positional args aren't supported, use keyword args."

        # Create a sysadmin by accessing the db directly.
        # This is probably bad but I don't think there's another way?
        user = ckan.model.User(**kwargs)
        ckan.model.Session.add(user)
        ckan.model.Session.commit()
        ckan.model.Session.remove()

        # We want to return a user dict not a model object, so call user_show
        # to get one. We pass the user's name in the context because we want
        # the API key and other sensitive data to be returned in the user
        # dict.
        user_dict = helpers.call_action('user_show', id=user.id,
                                        context={'user': user.name})
        return user_dict


class Group(factory.Factory):
    '''A factory class for creating CKAN groups.'''

    FACTORY_FOR = ckan.model.Group

    name = factory.Sequence(lambda n: 'test_group_{n}'.format(n=n))
    title = factory.LazyAttribute(_generate_group_title)
    description = 'A test description for this test group.'

    user = factory.LazyAttribute(lambda _:
                                 helpers.call_action('get_site_user'))

    @classmethod
    def _build(cls, target_class, *args, **kwargs):
        raise NotImplementedError(".build() isn't supported in CKAN")

    @classmethod
    def _create(cls, target_class, *args, **kwargs):
        if args:
            assert False, "Positional args aren't supported, use keyword args."

        context = {'user': _get_action_user_name(kwargs)}

        group_dict = helpers.call_action('group_create',
                                         context=context,
                                         **kwargs)
        return group_dict


class Organization(factory.Factory):
    '''A factory class for creating CKAN organizations.'''

    # This is the class that OrganizationFactory will create and return
    # instances of.
    FACTORY_FOR = ckan.model.Group

    # These are the default params that will be used to create new
    # organizations.
    type = 'organization'
    is_organization = True

    title = 'Test Organization'
    description = 'Just another test organization.'
    image_url = 'http://placekitten.com/g/200/100'

    # Generate a different group name param for each user that gets created.
    name = factory.Sequence(lambda n: 'test_org_{n}'.format(n=n))

    @classmethod
    def _build(cls, target_class, *args, **kwargs):
        raise NotImplementedError(".build() isn't supported in CKAN")

    @classmethod
    def _create(cls, target_class, *args, **kwargs):
        if args:
            assert False, "Positional args aren't supported, use keyword args."

        context = {'user': _get_action_user_name(kwargs)}

        group_dict = helpers.call_action('organization_create',
                                         context=context,
                                         **kwargs)
        return group_dict


class Related(factory.Factory):
    '''A factory class for creating related items.'''

    FACTORY_FOR = ckan.model.Related

    type = 'idea'
    description = 'Look, a description!'
    url = 'http://example.com'

    title = factory.Sequence(lambda n: 'test title {n}'.format(n=n))

    @classmethod
    def _build(cls, target_class, *args, **kwargs):
        raise NotImplementedError(".build() isn't supported in CKAN")

    @classmethod
    def _create(cls, target_class, *args, **kwargs):
        if args:
            assert False, "Positional args aren't supported, use keyword args."

        context = {'user': _get_action_user_name(kwargs)}
        related_dict = helpers.call_action('related_create', context=context,
                                           **kwargs)
        return related_dict


class Dataset(factory.Factory):
    '''A factory class for creating CKAN datasets.'''

    FACTORY_FOR = ckan.model.Package

    # These are the default params that will be used to create new groups.
    title = 'Test Dataset'
    description = 'Just another test dataset.'

    # Generate a different group name param for each user that gets created.
    name = factory.Sequence(lambda n: 'test_dataset_{n}'.format(n=n))

    @classmethod
    def _build(cls, target_class, *args, **kwargs):
        raise NotImplementedError(".build() isn't supported in CKAN")

    @classmethod
    def _create(cls, target_class, *args, **kwargs):
        if args:
            assert False, "Positional args aren't supported, use keyword args."

        context = {'user': _get_action_user_name(kwargs)}

        dataset_dict = helpers.call_action('package_create',
                                           context=context,
                                           **kwargs)
        return dataset_dict


class MockUser(factory.Factory):
    '''A factory class for creating mock CKAN users using the mock library.'''

    FACTORY_FOR = mock.MagicMock

    fullname = 'Mr. Mock User'
    password = 'pass'
    about = 'Just another mock user.'
    name = factory.Sequence(lambda n: 'mock_user_{n}'.format(n=n))
    email = factory.LazyAttribute(_generate_email)
    reset_key = factory.LazyAttribute(_generate_reset_key)
    id = factory.LazyAttribute(_generate_user_id)

    @classmethod
    def _build(cls, target_class, *args, **kwargs):
        raise NotImplementedError(".build() isn't supported in CKAN")

    @classmethod
    def _create(cls, target_class, *args, **kwargs):
        if args:
            assert False, "Positional args aren't supported, use keyword args."
        mock_user = mock.MagicMock()
        for name, value in kwargs.items():
            setattr(mock_user, name, value)
        return mock_user


def validator_data_dict():
    '''Return a data dict with some arbitrary data in it, suitable to be passed
    to validator functions for testing.

    '''
    return {('other key',): 'other value'}


def validator_errors_dict():
    '''Return an errors dict with some arbitrary errors in it, suitable to be
    passed to validator functions for testing.

    '''
    return {('other key',): ['other error']}

########NEW FILE########
__FILENAME__ = helpers
'''This is a collection of helper functions for use in tests.

We want to avoid sharing test helper functions between test modules as
much as possible, and we definitely don't want to share test fixtures between
test modules, or to introduce a complex hierarchy of test class subclasses,
etc.

We want to reduce the amount of "travel" that a reader needs to undertake to
understand a test method -- reducing the number of other files they need to go
and read to understand what the test code does. And we want to avoid tightly
coupling test modules to each other by having them share code.

But some test helper functions just increase the readability of tests so much
and make writing tests so much easier, that it's worth having them despite the
potential drawbacks.

This module is reserved for these very useful functions.

'''
import pylons.config as config
import webtest

import ckan.config.middleware
import ckan.model as model
import ckan.logic as logic


def reset_db():
    '''Reset CKAN's database.

    If a test class uses the database, then it should call this function in its
    ``setup()`` method to make sure that it has a clean database to start with
    (nothing left over from other test classes or from previous test runs).

    If a test class doesn't use the database (and most test classes shouldn't
    need to) then it doesn't need to call this function.

    :returns: ``None``

    '''
    # Close any database connections that have been left open.
    # This prevents CKAN from hanging waiting for some unclosed connection.
    model.Session.close_all()

    model.repo.rebuild_db()


def call_action(action_name, context=None, **kwargs):
    '''Call the named ``ckan.logic.action`` function and return the result.

    This is just a nicer way for user code to call action functions, nicer than
    either calling the action function directly or via
    :py:func:`ckan.logic.get_action`.

    For example::

        user_dict = call_action('user_create', name='seanh',
                                email='seanh@seanh.com', password='pass')

    Any keyword arguments given will be wrapped in a dict and passed to the
    action function as its ``data_dict`` argument.

    Note: this skips authorization! It passes 'ignore_auth': True to action
    functions in their ``context`` dicts, so the corresponding authorization
    functions will not be run.
    This is because ckan.new_tests.logic.action tests only the actions, the
    authorization functions are tested separately in
    ckan.new_tests.logic.auth.
    See the :doc:`testing guidelines </contributing/testing>` for more info.

    This function should eventually be moved to
    :py:func:`ckan.logic.call_action` and the current
    :py:func:`ckan.logic.get_action` function should be
    deprecated. The tests may still need their own wrapper function for
    :py:func:`ckan.logic.call_action`, e.g. to insert ``'ignore_auth': True``
    into the ``context`` dict.

    :param action_name: the name of the action function to call, e.g.
        ``'user_update'``
    :type action_name: string
    :param context: the context dict to pass to the action function
        (optional, if no context is given a default one will be supplied)
    :type context: dict
    :returns: the dict or other value that the action function returns

    '''
    if context is None:
        context = {}
    context.setdefault('user', '127.0.0.1')
    context.setdefault('ignore_auth', True)
    return logic.get_action(action_name)(context=context, data_dict=kwargs)


def call_auth(auth_name, context, **kwargs):
    '''Call the named ``ckan.logic.auth`` function and return the result.

    This is just a convenience function for tests in
    :py:mod:`ckan.new_tests.logic.auth` to use.

    Usage::

        result = helpers.call_auth('user_update', context=context,
                                   id='some_user_id',
                                   name='updated_user_name')

    :param auth_name: the name of the auth function to call, e.g.
        ``'user_update'``
    :type auth_name: string

    :param context: the context dict to pass to the auth function, must
        contain ``'user'`` and ``'model'`` keys,
        e.g. ``{'user': 'fred', 'model': my_mock_model_object}``
    :type context: dict

    :returns: the dict that the auth function returns, e.g.
        ``{'success': True}`` or ``{'success': False, msg: '...'}``
        or just ``{'success': False}``
    :rtype: dict

    '''
    assert 'user' in context, ('Test methods must put a user name in the '
                               'context dict')
    assert 'model' in context, ('Test methods must put a model in the '
                                'context dict')

    return logic.check_access(auth_name, context, data_dict=kwargs)


def _get_test_app():
    '''Return a webtest.TestApp for CKAN, with legacy templates disabled.

    For functional tests that need to request CKAN pages or post to the API.
    Unit tests shouldn't need this.

    '''
    config['ckan.legacy_templates'] = False
    app = ckan.config.middleware.make_app(config['global_conf'], **config)
    app = webtest.TestApp(app)
    return app

########NEW FILE########
__FILENAME__ = test_validators
# -*- coding: utf-8 -*-
'''Unit tests for ckan/lib/navl/validators.py.

'''
import copy

import nose.tools

import ckan.new_tests.factories as factories


def returns_None(function):
    '''A decorator that asserts that the decorated function returns None.

    :param function: the function to decorate
    :type function: function

    Usage:

        @returns_None
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors)

    '''
    def call_and_assert(*args, **kwargs):
        original_args = copy.deepcopy(args)
        original_kwargs = copy.deepcopy(kwargs)

        result = function(*args, **kwargs)

        assert result is None, (
            'Should return None when called with args: {args} and '
            'kwargs: {kwargs}'.format(args=original_args,
                                      kwargs=original_kwargs))
        return result
    return call_and_assert


def raises_StopOnError(function):
    '''A decorator that asserts that the decorated function raises
    dictization_functions.StopOnError.

    :param function: the function to decorate
    :type function: function

    Usage:

        @raises_StopOnError
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors)

    '''
    def call_and_assert(*args, **kwargs):
        import ckan.lib.navl.dictization_functions as df
        nose.tools.assert_raises(df.StopOnError, function, *args, **kwargs)
    return call_and_assert


def does_not_modify_data_dict(validator):
    '''A decorator  that asserts that the decorated validator doesn't modify
    its `data` dict param.

    :param validator: the validator function to decorate
    :type validator: function

    Usage:

        @does_not_modify_data_dict
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors)

    '''
    def call_and_assert(key, data, errors, context=None):
        if context is None:
            context = {}
        original_data = copy.deepcopy(data)
        original_errors = copy.deepcopy(errors)
        original_context = copy.deepcopy(context)

        result = validator(key, data, errors, context=context)

        assert data == original_data, (
            'Should not modify data dict when called with '
            'key: {key}, data: {data}, errors: {errors}, '
            'context: {context}'.format(key=key, data=original_data,
                                        errors=original_errors,
                                        context=original_context))
        return result
    return call_and_assert


def removes_key_from_data_dict(validator):
    '''A decorator  that asserts that the decorated validator removes its key
    from the data dict.

    :param validator: the validator function to decorate
    :type validator: function

    Usage:

        @removes_key_from_data_dict
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors)

    '''
    def call_and_assert(key, data, errors, context=None):
        if context is None:
            context = {}
        original_data = copy.deepcopy(data)
        original_errors = copy.deepcopy(errors)
        original_context = copy.deepcopy(context)

        result = validator(key, data, errors, context=context)

        assert key not in data, (
            'Should remove key from data dict when called with: '
            'key: {key}, data: {data}, errors: {errors}, '
            'context: {context} '.format(key=key, data=original_data,
                                         errors=original_errors,
                                         context=original_context))
        return result
    return call_and_assert


def does_not_modify_other_keys_in_data_dict(validator):
    '''A decorator that asserts that the decorated validator doesn't add,
    modify the value of, or remove any other keys from its ``data`` dict param.

    The function *may* modify its own data dict key.

    :param validator: the validator function to decorate
    :type validator: function

    Usage:

        @does_not_modify_other_keys_in_data_dict
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors)

    '''
    def call_and_assert(key, data, errors, context=None):
        if context is None:
            context = {}
        original_data = copy.deepcopy(data)
        original_errors = copy.deepcopy(errors)
        original_context = copy.deepcopy(context)

        result = validator(key, data, errors, context=context)

        # The validator function is allowed to modify its own key, so remove
        # that key from both dicts for the purposes of the assertions below.
        if key in data:
            del data[key]
        if key in original_data:
            del original_data[key]

        assert data.keys() == original_data.keys(), (
            'Should not add or remove keys from data dict when called with '
            'key: {key}, data: {data}, errors: {errors}, '
            'context: {context}'.format(key=key, data=original_data,
                                        errors=original_errors,
                                        context=original_context))
        for key_ in data:
            assert data[key_] == original_data[key_], (
                'Should not modify other keys in data dict when called with '
                'key: {key}, data: {data}, errors: {errors}, '
                'context: {context}'.format(key=key, data=original_data,
                                            errors=original_errors,
                                            context=original_context))
        return result
    return call_and_assert


def does_not_modify_errors_dict(validator):
    '''A decorator that asserts that the decorated validator doesn't modify its
    `errors` dict param.

    :param validator: the validator function to decorate
    :type validator: function

    Usage:

        @does_not_modify_errors_dict
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors)

    '''
    def call_and_assert(key, data, errors, context=None):
        if context is None:
            context = {}
        original_data = copy.deepcopy(data)
        original_errors = copy.deepcopy(errors)
        original_context = copy.deepcopy(context)

        result = validator(key, data, errors, context=context)

        assert errors == original_errors, (
            'Should not modify errors dict when called with key: {key}, '
            'data: {data}, errors: {errors}, '
            'context: {context}'.format(key=key, data=original_data,
                                        errors=original_errors,
                                        context=original_context))
        return result
    return call_and_assert


class TestValidators(object):

    def test_ignore_missing_with_value_missing(self):
        '''ignore_missing() should raise StopOnError if:

        - data[key] is None, or
        - data[key] is dictization_functions.missing, or
        - key is not in data

        '''
        import ckan.lib.navl.dictization_functions as df
        import ckan.lib.navl.validators as validators

        for value in (None, df.missing, 'skip'):

            # This is the key for the value that is going to be validated.
            key = ('key to be validated',)

            # The data to pass to the validator function for validation.
            data = factories.validator_data_dict()
            if value != 'skip':
                data[key] = value

            # The errors dict to pass to the validator function.
            errors = factories.validator_errors_dict()
            errors[key] = []

            @does_not_modify_other_keys_in_data_dict
            @does_not_modify_errors_dict
            @removes_key_from_data_dict
            @raises_StopOnError
            def call_validator(*args, **kwargs):
                return validators.ignore_missing(*args, **kwargs)
            call_validator(key=key, data=data, errors=errors, context={})

    def test_ignore_missing_with_a_value(self):
        '''If data[key] is neither None or missing, ignore_missing() should do
        nothing.

        '''
        import ckan.lib.navl.validators as validators

        key = ('key to be validated',)
        data = factories.validator_data_dict()
        data[key] = 'value to be validated'
        errors = factories.validator_errors_dict()
        errors[key] = []

        @returns_None
        @does_not_modify_data_dict
        @does_not_modify_errors_dict
        def call_validator(*args, **kwargs):
            return validators.ignore_missing(*args, **kwargs)
        call_validator(key=key, data=data, errors=errors, context={})

########NEW FILE########
__FILENAME__ = test_helpers
import nose

import ckan.lib.helpers as h
import ckan.exceptions

eq_ = nose.tools.eq_
CkanUrlException = ckan.exceptions.CkanUrlException


class TestHelpers(object):
    def test_url_for_static(self):
        url = '/assets/ckan.jpg'
        eq_(h.url_for_static(url), url)

    def test_url_for_static_adds_starting_slash_if_url_doesnt_have_it(self):
        slashless_url = 'ckan.jpg'
        url = '/' + slashless_url
        eq_(h.url_for_static(slashless_url), url)

    def test_url_for_static_converts_unicode_strings_to_regular_strings(self):
        url = u'/ckan.jpg'
        assert isinstance(h.url_for_static(url), str)

    def test_url_for_static_raises_when_called_with_external_urls(self):
        url = 'http://assets.ckan.org/ckan.jpg'
        nose.tools.assert_raises(CkanUrlException, h.url_for_static, url)

    def test_url_for_static_raises_when_called_with_protocol_relative(self):
        url = '//assets.ckan.org/ckan.jpg'
        nose.tools.assert_raises(CkanUrlException, h.url_for_static, url)

    def test_url_for_static_or_external(self):
        url = '/assets/ckan.jpg'
        eq_(h.url_for_static_or_external(url), url)

    def test_url_for_static_or_external_works_with_external_urls(self):
        url = 'http://assets.ckan.org/ckan.jpg'
        eq_(h.url_for_static_or_external(url), url)

    def test_url_for_static_or_external_converts_unicode_to_strings(self):
        url = u'/ckan.jpg'
        assert isinstance(h.url_for_static_or_external(url), str)

    def test_url_for_static_or_external_adds_starting_slash_if_needed(self):
        slashless_url = 'ckan.jpg'
        url = '/' + slashless_url
        eq_(h.url_for_static_or_external(slashless_url), url)

    def test_url_for_static_or_external_works_with_protocol_relative_url(self):
        url = '//assets.ckan.org/ckan.jpg'
        eq_(h.url_for_static_or_external(url), url)

########NEW FILE########
__FILENAME__ = test_create
'''Unit tests for ckan/logic/auth/create.py.

'''

import mock
import nose.tools

import ckan.new_tests.helpers as helpers
import ckan.new_tests.factories as factories
import ckan.model as model
import ckan.logic as logic


class TestUserInvite(object):

    def setup(self):
        helpers.reset_db()

    @mock.patch('ckan.lib.mailer.send_invite')
    def test_user_invite(self, _):
        invited_user = self._invite_user_to_group()

        assert invited_user is not None
        assert invited_user.is_pending()

    @mock.patch('ckan.lib.mailer.send_invite')
    def test_user_invite_creates_user_with_valid_username(self, _):
        email = 'user$%+abc@email.com'
        invited_user = self._invite_user_to_group(email)

        assert invited_user.name.startswith('user---abc'), invited_user

    @mock.patch('ckan.lib.mailer.send_invite')
    def test_user_invite_assigns_user_to_group_in_expected_role(self, _):
        role = 'admin'
        invited_user = self._invite_user_to_group(role=role)

        group_ids = invited_user.get_group_ids(capacity=role)
        assert len(group_ids) == 1, group_ids

    @mock.patch('ckan.lib.mailer.send_invite')
    def test_user_invite_sends_invite(self, send_invite):
        invited_user = self._invite_user_to_group()

        assert send_invite.called
        assert send_invite.call_args[0][0].id == invited_user.id

    @mock.patch('ckan.lib.mailer.send_invite')
    @mock.patch('random.SystemRandom')
    def test_user_invite_works_even_if_username_already_exists(self, rand, _):
        rand.return_value.random.side_effect = [1000, 1000, 1000, 2000,
                                                3000, 4000, 5000]

        for _ in range(3):
            invited_user = self._invite_user_to_group(email='same@email.com')
            assert invited_user is not None, invited_user

    @mock.patch('ckan.lib.mailer.send_invite')
    @nose.tools.raises(logic.ValidationError)
    def test_user_invite_requires_email(self, _):
        self._invite_user_to_group(email=None)

    @mock.patch('ckan.lib.mailer.send_invite')
    @nose.tools.raises(logic.ValidationError)
    def test_user_invite_requires_role(self, _):
        self._invite_user_to_group(role=None)

    @mock.patch('ckan.lib.mailer.send_invite')
    @nose.tools.raises(logic.ValidationError)
    def test_user_invite_requires_group_id(self, _):
        self._invite_user_to_group(group={'id': None})

    def _invite_user_to_group(self, email='user@email.com',
                              group=None, role='member'):
        user = factories.User()
        group = group or factories.Group(user=user)

        context = {
            'user': user['name']
        }
        params = {
            'email': email,
            'group_id': group['id'],
            'role': role
        }

        result = helpers.call_action('user_invite', context, **params)

        return model.User.get(result['id'])


class TestResourceCreate(object):

    @classmethod
    def setup_class(cls):
        helpers.reset_db()

    def setup(self):
        model.repo.rebuild_db()

    def test_it_requires_url(self):
        user = factories.User()
        dataset = factories.Dataset(user=user)
        data_dict = {
            'package_id': dataset['id']
        }

        nose.tools.assert_raises(logic.ValidationError,
                                 helpers.call_action,
                                 'resource_create', **data_dict)

########NEW FILE########
__FILENAME__ = test_get
import nose.tools

import ckan.logic as logic
import ckan.lib.search as search
import ckan.new_tests.helpers as helpers
import ckan.new_tests.factories as factories


eq = nose.tools.eq_


class TestGet(object):

    @classmethod
    def setup_class(cls):
        helpers.reset_db()

    def setup(self):
        import ckan.model as model

        # Reset the db before each test method.
        model.repo.rebuild_db()

        # Clear the search index
        search.clear()

    def test_group_list(self):

        user = factories.User()
        group1 = factories.Group(user=user)
        group2 = factories.Group(user=user)

        group_list = helpers.call_action('group_list')

        assert (sorted(group_list) ==
                sorted([g['name'] for g in [group1, group2]]))

    def test_group_show(self):

        group = factories.Group(user=factories.User())

        group_dict = helpers.call_action('group_show', id=group['id'])

        # FIXME: Should this be returned by group_create?
        group_dict.pop('num_followers', None)
        assert group_dict == group

    def test_group_show_packages_returned(self):

        user_name = helpers.call_action('get_site_user')['name']

        group = factories.Group(user=factories.User())

        datasets = [
            {'name': 'dataset_1', 'groups': [{'name': group['name']}]},
            {'name': 'dataset_2', 'groups': [{'name': group['name']}]},
        ]

        for dataset in datasets:
            helpers.call_action('package_create',
                                context={'user': user_name},
                                **dataset)

        group_dict = helpers.call_action('group_show', id=group['id'])

        assert len(group_dict['packages']) == 2
        assert group_dict['package_count'] == 2

    def test_group_show_no_packages_returned(self):

        user_name = helpers.call_action('get_site_user')['name']

        group = factories.Group(user=factories.User())

        datasets = [
            {'name': 'dataset_1', 'groups': [{'name': group['name']}]},
            {'name': 'dataset_2', 'groups': [{'name': group['name']}]},
        ]

        for dataset in datasets:
            helpers.call_action('package_create',
                                context={'user': user_name},
                                **dataset)

        group_dict = helpers.call_action('group_show', id=group['id'],
                                         include_datasets=False)

        assert not 'packages' in group_dict
        assert group_dict['package_count'] == 2

    def test_organization_list(self):

        org1 = factories.Organization()
        org2 = factories.Organization()

        org_list = helpers.call_action('organization_list')

        assert (sorted(org_list) ==
                sorted([g['name'] for g in [org1, org2]]))

    def test_organization_show(self):

        org = factories.Organization()

        org_dict = helpers.call_action('organization_show', id=org['id'])

        # FIXME: Should this be returned by organization_create?
        org_dict.pop('num_followers', None)
        assert org_dict == org

    def test_organization_show_packages_returned(self):

        user_name = helpers.call_action('get_site_user')['name']

        org = factories.Organization()

        datasets = [
            {'name': 'dataset_1', 'owner_org': org['name']},
            {'name': 'dataset_2', 'owner_org': org['name']},
        ]

        for dataset in datasets:
            helpers.call_action('package_create',
                                context={'user': user_name},
                                **dataset)

        org_dict = helpers.call_action('organization_show', id=org['id'])

        assert len(org_dict['packages']) == 2
        assert org_dict['package_count'] == 2

    def test_organization_show_private_packages_not_returned(self):

        user_name = helpers.call_action('get_site_user')['name']

        org = factories.Organization()

        datasets = [
            {'name': 'dataset_1', 'owner_org': org['name']},
            {'name': 'dataset_2', 'owner_org': org['name'], 'private': True},
        ]

        for dataset in datasets:
            helpers.call_action('package_create',
                                context={'user': user_name},
                                **dataset)

        org_dict = helpers.call_action('organization_show', id=org['id'])

        assert len(org_dict['packages']) == 1
        assert org_dict['packages'][0]['name'] == 'dataset_1'
        assert org_dict['package_count'] == 1

    def test_user_get(self):

        user = factories.User()

        ## auth_ignored
        got_user = helpers.call_action('user_show', id=user['id'])

        assert 'password' not in got_user
        assert 'reset_key' not in got_user
        assert 'apikey' not in got_user
        assert 'email' not in got_user

        got_user = helpers.call_action('user_show',
                                       context={'keep_email': True},
                                       id=user['id'])

        assert got_user['email'] == user['email']
        assert 'apikey' not in got_user
        assert 'password' not in got_user
        assert 'reset_key' not in got_user

        got_user = helpers.call_action('user_show',
                                       context={'keep_apikey': True},
                                       id=user['id'])

        assert 'email' not in got_user
        assert got_user['apikey'] == user['apikey']
        assert 'password' not in got_user
        assert 'reset_key' not in got_user

        sysadmin = factories.User(sysadmin=True)

        got_user = helpers.call_action('user_show',
                                       context={'user': sysadmin['name']},
                                       id=user['id'])

        assert got_user['email'] == user['email']
        assert got_user['apikey'] == user['apikey']
        assert 'password' not in got_user
        assert 'reset_key' not in got_user

    def test_related_list_with_no_params(self):
        '''
        Test related_list with no parameters and default sort
        '''
        user = factories.User()
        related1 = factories.Related(user=user, featured=True)
        related2 = factories.Related(user=user, type='application')

        related_list = helpers.call_action('related_list')
        assert ([related1, related2] == related_list)

    def test_related_list_type_filter(self):
        '''
        Test related_list with type filter
        '''
        user = factories.User()
        related1 = factories.Related(user=user, featured=True)
        related2 = factories.Related(user=user, type='application')

        related_list = helpers.call_action('related_list',
                                           type_filter='application')
        assert ([related2] == related_list)

    def test_related_list_sorted(self):
        '''
        Test related_list with sort parameter
        '''
        user = factories.User()
        related1 = factories.Related(user=user, featured=True)
        related2 = factories.Related(user=user, type='application')

        related_list = helpers.call_action('related_list', sort='created_desc')
        assert ([related2, related1] == related_list)

    def test_related_list_invalid_sort_parameter(self):
        '''
        Test related_list with invalid value for sort parameter
        '''
        user = factories.User()
        related1 = factories.Related(user=user, featured=True)
        related2 = factories.Related(user=user, type='application')

        related_list = helpers.call_action('related_list', sort='invalid')
        assert ([related1, related2] == related_list)

    def test_related_list_featured(self):
        '''
        Test related_list with no featured filter
        '''
        user = factories.User()
        related1 = factories.Related(user=user, featured=True)
        related2 = factories.Related(user=user, type='application')

        related_list = helpers.call_action('related_list', featured=True)
        assert ([related1] == related_list)
        # TODO: Create related items associated with a dataset and test
        # related_list with them

    def test_current_package_list(self):
        '''
        Test current_package_list_with_resources with no parameters
        '''
        user = factories.User()
        dataset1 = factories.Dataset(user=user)
        dataset2 = factories.Dataset(user=user)
        current_package_list = helpers. \
            call_action('current_package_list_with_resources')
        eq(len(current_package_list), 2)

    def test_current_package_list_limit_param(self):
        '''
        Test current_package_list_with_resources with limit parameter
        '''
        user = factories.User()
        dataset1 = factories.Dataset(user=user)
        dataset2 = factories.Dataset(user=user)
        current_package_list = helpers. \
            call_action('current_package_list_with_resources', limit=1)
        eq(len(current_package_list), 1)
        eq(current_package_list[0]['name'], dataset2['name'])

    def test_current_package_list_offset_param(self):
        '''
        Test current_package_list_with_resources with offset parameter
        '''
        user = factories.User()
        dataset1 = factories.Dataset(user=user)
        dataset2 = factories.Dataset(user=user)
        current_package_list = helpers. \
            call_action('current_package_list_with_resources', offset=1)
        eq(len(current_package_list), 1)
        eq(current_package_list[0]['name'], dataset1['name'])

    def test_current_package_list_private_datasets_anonoymous_user(self):
        '''
        Test current_package_list_with_resources with an anoymous user and
        a private dataset
        '''
        user = factories.User()
        org = factories.Organization(user=user)
        dataset1 = factories.Dataset(user=user, owner_org=org['name'],
                                     private=True)
        dataset2 = factories.Dataset(user=user)
        current_package_list = helpers. \
            call_action('current_package_list_with_resources', context={})
        eq(len(current_package_list), 1)

    def test_current_package_list_private_datasets_sysadmin_user(self):
        '''
        Test current_package_list_with_resources with a sysadmin user and a
        private dataset
        '''
        user = factories.User()
        org = factories.Organization(user=user)
        dataset1 = factories.Dataset(user=user, owner_org=org['name'],
                                     private=True)
        dataset2 = factories.Dataset(user=user)
        sysadmin = factories.Sysadmin()
        current_package_list = helpers. \
            call_action('current_package_list_with_resources', context={'user':
                        sysadmin['name']})
        eq(len(current_package_list), 2)


class TestBadLimitQueryParameters(object):
    '''test class for #1258 non-int query parameters cause 500 errors

    Test that validation errors are raised when calling actions with
    bad parameters.
    '''

    def test_activity_list_actions(self):
        actions = [
            'user_activity_list',
            'package_activity_list',
            'group_activity_list',
            'organization_activity_list',
            'recently_changed_packages_activity_list',
            'user_activity_list_html',
            'package_activity_list_html',
            'group_activity_list_html',
            'organization_activity_list_html',
            'recently_changed_packages_activity_list_html',
            'current_package_list_with_resources',
        ]
        for action in actions:
            nose.tools.assert_raises(
                logic.ValidationError, helpers.call_action, action,
                id='test_user', limit='not_an_int', offset='not_an_int')
            nose.tools.assert_raises(
                logic.ValidationError, helpers.call_action, action,
                id='test_user', limit=-1, offset=-1)

    def test_package_search_facet_field_is_json(self):
        kwargs = {'facet.field': 'notjson'}
        nose.tools.assert_raises(
            logic.ValidationError, helpers.call_action, 'package_search',
            **kwargs)

########NEW FILE########
__FILENAME__ = test_update
'''Unit tests for ckan/logic/action/update.py.'''
import datetime

import nose.tools
import mock

import ckan.logic as logic
import ckan.new_tests.helpers as helpers
import ckan.new_tests.factories as factories


def datetime_from_string(s):
    '''Return a standard datetime.datetime object initialised from a string in
    the same format used for timestamps in dictized activities (the format
    produced by datetime.datetime.isoformat())

    '''
    return datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%S.%f')


class TestUpdate(object):

    @classmethod
    def setup_class(cls):

        # Initialize the test db (if it isn't already) and clean out any data
        # left in it.
        # You should only do this in your setup_class() method if your test
        # class uses the db, most test classes shouldn't need to.
        helpers.reset_db()

    def setup(self):
        import ckan.model as model

        # Reset the db before each test method.
        # You should only do this in your setup() method if your test class
        # uses the db, most test classes shouldn't need to.
        model.repo.rebuild_db()

    def teardown(self):
        # Since some of the test methods below use the mock module to patch
        # things, we use this teardown() method to remove remove all patches.
        # (This makes sure the patches always get removed even if the test
        # method aborts with an exception or something.)
        mock.patch.stopall()

    ## START-AFTER

    def test_user_update_name(self):
        '''Test that updating a user's name works successfully.'''

        # The canonical form of a test has four steps:
        # 1. Setup any preconditions needed for the test.
        # 2. Call the function that's being tested, once only.
        # 3. Make assertions about the return value and/or side-effects of
        #    of the function that's being tested.
        # 4. Do nothing else!

        # 1. Setup.
        user = factories.User()

        # 2. Call the function that's being tested, once only.
        # FIXME we have to pass the email address and password to user_update
        # even though we're not updating those fields, otherwise validation
        # fails.
        helpers.call_action('user_update', id=user['name'],
                            email=user['email'],
                            password=factories.User.attributes()['password'],
                            name='updated',
                            )

        # 3. Make assertions about the return value and/or side-effects.
        updated_user = helpers.call_action('user_show', id=user['id'])
        # Note that we check just the field we were trying to update, not the
        # entire dict, only assert what we're actually testing.
        assert updated_user['name'] == 'updated'

        # 4. Do nothing else!

    ## END-BEFORE

    def test_user_update_with_id_that_does_not_exist(self):
        user_dict = factories.User.attributes()
        user_dict['id'] = "there's no user with this id"

        nose.tools.assert_raises(logic.NotFound, helpers.call_action,
                                 'user_update', **user_dict)

    def test_user_update_with_no_id(self):
        user_dict = factories.User.attributes()
        assert 'id' not in user_dict
        nose.tools.assert_raises(logic.ValidationError, helpers.call_action,
                                 'user_update', **user_dict)

    ## START-FOR-LOOP-EXAMPLE

    def test_user_update_with_invalid_name(self):
        user = factories.User()

        invalid_names = ('', 'a', False, 0, -1, 23, 'new', 'edit', 'search',
                         'a' * 200, 'Hi!', 'i++%')
        for name in invalid_names:
            user['name'] = name
            nose.tools.assert_raises(logic.ValidationError,
                                     helpers.call_action, 'user_update',
                                     **user)

    ## END-FOR-LOOP-EXAMPLE

    def test_user_update_to_name_that_already_exists(self):
        fred = factories.User(name='fred')
        bob = factories.User(name='bob')

        # Try to update fred and change his user name to bob, which is already
        # bob's user name
        fred['name'] = bob['name']
        nose.tools.assert_raises(logic.ValidationError, helpers.call_action,
                                 'user_update', **fred)

    def test_user_update_password(self):
        '''Test that updating a user's password works successfully.'''

        user = factories.User()

        # FIXME we have to pass the email address to user_update even though
        # we're not updating it, otherwise validation fails.
        helpers.call_action('user_update', id=user['name'],
                            email=user['email'],
                            password='new password',
                            )

        # user_show() never returns the user's password, so we have to access
        # the model directly to test it.
        import ckan.model as model
        updated_user = model.User.get(user['id'])
        assert updated_user.validate_password('new password')

    def test_user_update_with_short_password(self):
        user = factories.User()

        user['password'] = 'xxx'  # This password is too short.
        nose.tools.assert_raises(logic.ValidationError, helpers.call_action,
                                 'user_update', **user)

    def test_user_update_with_empty_password(self):
        '''If an empty password is passed to user_update, nothing should
        happen.

        No error (e.g. a validation error) is raised, but the password is not
        changed either.

        '''
        user_dict = factories.User.attributes()
        original_password = user_dict['password']
        user_dict = factories.User(**user_dict)

        user_dict['password'] = ''
        helpers.call_action('user_update', **user_dict)

        import ckan.model as model
        updated_user = model.User.get(user_dict['id'])
        assert updated_user.validate_password(original_password)

    def test_user_update_with_null_password(self):
        user = factories.User()

        user['password'] = None
        nose.tools.assert_raises(logic.ValidationError, helpers.call_action,
                                 'user_update', **user)

    def test_user_update_with_invalid_password(self):
        user = factories.User()

        for password in (False, -1, 23, 30.7):
            user['password'] = password
            nose.tools.assert_raises(logic.ValidationError,
                                     helpers.call_action, 'user_update',
                                     **user)

    def test_user_update_without_email_address(self):
        '''You have to pass an email address when you call user_update.

        Even if you don't want to change the user's email address, you still
        have to pass their current email address to user_update.

        FIXME: The point of this feature seems to be to prevent people from
        removing email addresses from user accounts, but making them post the
        current email address every time they post to user update is just
        annoying, they should be able to post a dict with no 'email' key to
        user_update and it should simply not change the current email.

        '''
        user = factories.User()
        del user['email']

        nose.tools.assert_raises(logic.ValidationError,
                                 helpers.call_action, 'user_update',
                                 **user)

    # TODO: Valid and invalid values for the rest of the user model's fields.

    def test_user_update_activity_stream(self):
        '''Test that the right activity is emitted when updating a user.'''

        user = factories.User()
        before = datetime.datetime.now()

        # FIXME we have to pass the email address and password to user_update
        # even though we're not updating those fields, otherwise validation
        # fails.
        helpers.call_action('user_update', id=user['name'],
                            email=user['email'],
                            password=factories.User.attributes()['password'],
                            name='updated',
                            )

        activity_stream = helpers.call_action('user_activity_list',
                                              id=user['id'])
        latest_activity = activity_stream[0]
        assert latest_activity['activity_type'] == 'changed user'
        assert latest_activity['object_id'] == user['id']
        assert latest_activity['user_id'] == user['id']
        after = datetime.datetime.now()
        timestamp = datetime_from_string(latest_activity['timestamp'])
        assert timestamp >= before and timestamp <= after

    def test_user_update_with_custom_schema(self):
        '''Test that custom schemas passed to user_update do get used.

        user_update allows a custom validation schema to be passed to it in the
        context dict. This is just a simple test that if you pass a custom
        schema user_update does at least call a custom method that's given in
        the custom schema. We assume this means it did use the custom schema
        instead of the default one for validation, so user_update's custom
        schema feature does work.

        '''
        import ckan.logic.schema

        user = factories.User()

        # A mock validator method, it doesn't do anything but it records what
        # params it gets called with and how many times.
        mock_validator = mock.MagicMock()

        # Build a custom schema by taking the default schema and adding our
        # mock method to its 'id' field.
        schema = ckan.logic.schema.default_update_user_schema()
        schema['id'].append(mock_validator)

        # Call user_update and pass our custom schema in the context.
        # FIXME: We have to pass email and password even though we're not
        # trying to update them, or validation fails.
        helpers.call_action('user_update', context={'schema': schema},
                            id=user['name'], email=user['email'],
                            password=factories.User.attributes()['password'],
                            name='updated',
                            )

        # Since we passed user['name'] to user_update as the 'id' param,
        # our mock validator method should have been called once with
        # user['name'] as arg.
        mock_validator.assert_called_once_with(user['name'])

    def test_user_update_multiple(self):
        '''Test that updating multiple user attributes at once works.'''

        user = factories.User()

        params = {
            'id': user['id'],
            'name': 'updated_name',
            'fullname': 'updated full name',
            'about': 'updated about',
            # FIXME: We shouldn't have to put email here since we're not
            # updating it, but user_update sucks.
            'email': user['email'],
            # FIXME: We shouldn't have to put password here since we're not
            # updating it, but user_update sucks.
            'password': factories.User.attributes()['password'],
        }

        helpers.call_action('user_update', **params)

        updated_user = helpers.call_action('user_show', id=user['id'])
        assert updated_user['name'] == 'updated_name'
        assert updated_user['fullname'] == 'updated full name'
        assert updated_user['about'] == 'updated about'

    def test_user_update_does_not_return_password(self):
        '''The user dict that user_update returns should not include the user's
        password.'''

        user = factories.User()

        params = {
            'id': user['id'],
            'name': 'updated_name',
            'fullname': 'updated full name',
            'about': 'updated about',
            'email': user['email'],
            'password': factories.User.attributes()['password'],
        }

        updated_user = helpers.call_action('user_update', **params)
        assert 'password' not in updated_user

    def test_user_update_does_not_return_apikey(self):
        '''The user dict that user_update returns should not include the user's
        API key.'''

        user = factories.User()

        params = {
            'id': user['id'],
            'name': 'updated_name',
            'fullname': 'updated full name',
            'about': 'updated about',
            'email': user['email'],
            'password': factories.User.attributes()['password'],
        }

        updated_user = helpers.call_action('user_update', **params)
        assert 'apikey' not in updated_user

    def test_user_update_does_not_return_reset_key(self):
        '''The user dict that user_update returns should not include the user's
        reset key.'''

        import ckan.lib.mailer
        import ckan.model

        user = factories.User()
        ckan.lib.mailer.create_reset_key(ckan.model.User.get(user['id']))

        params = {
            'id': user['id'],
            'name': 'updated_name',
            'fullname': 'updated full name',
            'about': 'updated about',
            'email': user['email'],
            'password': factories.User.attributes()['password'],
        }

        updated_user = helpers.call_action('user_update', **params)
        assert 'reset_key' not in updated_user

    def test_resource_reorder(self):
        resource_urls = ["http://a.html", "http://b.html", "http://c.html"]
        dataset = {"name": "basic",
                   "resources": [{'url': url} for url in resource_urls]
                   }

        dataset = helpers.call_action('package_create', **dataset)
        created_resource_urls = [resource['url'] for resource
                                 in dataset['resources']]
        assert created_resource_urls == resource_urls
        mapping = dict((resource['url'], resource['id']) for resource
                       in dataset['resources'])

        ## This should put c.html at the front
        reorder = {'id': dataset['id'], 'order':
                   [mapping["http://c.html"]]}

        helpers.call_action('package_resource_reorder', **reorder)

        dataset = helpers.call_action('package_show', id=dataset['id'])
        reordered_resource_urls = [resource['url'] for resource
                                   in dataset['resources']]

        assert reordered_resource_urls == ["http://c.html",
                                           "http://a.html",
                                           "http://b.html"]

        reorder = {'id': dataset['id'], 'order': [mapping["http://b.html"],
                                                  mapping["http://c.html"],
                                                  mapping["http://a.html"]]}

        helpers.call_action('package_resource_reorder', **reorder)
        dataset = helpers.call_action('package_show', id=dataset['id'])

        reordered_resource_urls = [resource['url'] for resource
                                   in dataset['resources']]

        assert reordered_resource_urls == ["http://b.html",
                                           "http://c.html",
                                           "http://a.html"]

########NEW FILE########
__FILENAME__ = test_create
'''Unit tests for ckan/logic/auth/create.py.

'''

import mock
import nose

import ckan.new_tests.helpers as helpers
import ckan.new_tests.factories as factories

logic = helpers.logic


class TestCreate(object):

    def setup(self):
        helpers.reset_db()

    @mock.patch('ckan.logic.auth.create.group_member_create')
    def test_user_invite_delegates_correctly_to_group_member_create(self, gmc):
        user = factories.User()
        context = {
            'user': user['name'],
            'model': None,
            'auth_user_obj': user
        }
        data_dict = {'group_id': 42}

        gmc.return_value = {'success': False}
        nose.tools.assert_raises(logic.NotAuthorized, helpers.call_auth,
                                 'user_invite', context=context, **data_dict)

        gmc.return_value = {'success': True}
        result = helpers.call_auth('user_invite', context=context, **data_dict)
        assert result is True

########NEW FILE########
__FILENAME__ = test_init
import nose

import ckan.model as core_model
import ckan.logic as logic
import ckan.new_tests.helpers as helpers
import ckan.logic.auth as logic_auth


class TestGetObjectErrors(object):

    def _get_function(self, obj_type):
        _get_object_functions = {
            'package': logic_auth.get_package_object,
            'resource': logic_auth.get_resource_object,
            'related': logic_auth.get_related_object,
            'user': logic_auth.get_user_object,
            'group': logic_auth.get_group_object,
        }
        return _get_object_functions[obj_type]

    def _get_object_in_context(self, obj_type):

        if obj_type == 'user':
            context = {'user_obj': 'a_fake_object'}
        else:
            context = {obj_type: 'a_fake_object'}

        obj = self._get_function(obj_type)(context)

        assert obj == 'a_fake_object'

    def _get_object_id_not_found(self, obj_type):

        nose.tools.assert_raises(logic.NotFound,
                                 self._get_function(obj_type),
                                 {'model': core_model},
                                 {'id': 'not_here'})

    def _get_object_id_none(self, obj_type):

        nose.tools.assert_raises(logic.ValidationError,
                                 self._get_function(obj_type),
                                 {'model': core_model}, {})

    def test_get_package_object_in_context(self):
        self._get_object_in_context('package')

    def test_get_resource_object_in_context(self):
        self._get_object_in_context('resource')

    def test_get_related_object_in_context(self):
        self._get_object_in_context('related')

    def test_get_user_object_in_context(self):
        self._get_object_in_context('user')

    def test_get_group_object_in_context(self):
        self._get_object_in_context('group')

    def test_get_package_object_id_not_found(self):
        self._get_object_id_not_found('package')

    def test_get_resource_object_id_not_found(self):
        self._get_object_id_not_found('resource')

    def test_get_related_object_id_not_found(self):
        self._get_object_id_not_found('related')

    def test_get_user_object_id_not_found(self):
        self._get_object_id_not_found('user')

    def test_get_group_object_id_not_found(self):
        self._get_object_id_not_found('group')

    def test_get_package_object_id_none(self):
        self._get_object_id_none('package')

    def test_get_resource_object_id_none(self):
        self._get_object_id_none('resource')

    def test_get_related_object_id_none(self):
        self._get_object_id_none('related')

    def test_get_user_object_id_none(self):
        self._get_object_id_none('user')

    def test_get_group_object_id_none(self):
        self._get_object_id_none('group')


class TestGetObject(object):

    @classmethod
    def setup_class(cls):
        helpers.reset_db()

    def setup(self):
        import ckan.model as model

        # Reset the db before each test method.
        model.repo.rebuild_db()

    def test_get_package_object_with_id(self):

        user_name = helpers.call_action('get_site_user')['name']
        dataset = helpers.call_action('package_create',
                                      context={'user': user_name},
                                      name='test_dataset')
        context = {'model': core_model}
        obj = logic_auth.get_package_object(context, {'id': dataset['id']})

        assert obj.id == dataset['id']
        assert context['package'] == obj

    def test_get_resource_object_with_id(self):

        user_name = helpers.call_action('get_site_user')['name']
        dataset = helpers.call_action('package_create',
                                      context={'user': user_name},
                                      name='test_dataset')
        resource = helpers.call_action('resource_create',
                                       context={'user': user_name},
                                       package_id=dataset['id'],
                                       url='http://foo')

        context = {'model': core_model}
        obj = logic_auth.get_resource_object(context, {'id': resource['id']})

        assert obj.id == resource['id']
        assert context['resource'] == obj

    def test_get_related_object_with_id(self):

        user_name = helpers.call_action('get_site_user')['name']
        related = helpers.call_action('related_create',
                                      context={'user': user_name},
                                      title='test related', type='app')
        context = {'model': core_model}
        obj = logic_auth.get_related_object(context, {'id': related['id']})

        assert obj.id == related['id']
        assert context['related'] == obj

    def test_get_user_object_with_id(self):

        user_name = helpers.call_action('get_site_user')['name']
        user = helpers.call_action('user_create',
                                   context={'user': user_name},
                                   name='test_user',
                                   email='a@a.com',
                                   password='pass')
        context = {'model': core_model}
        obj = logic_auth.get_user_object(context, {'id': user['id']})

        assert obj.id == user['id']
        assert context['user_obj'] == obj

    def test_get_group_object_with_id(self):

        user_name = helpers.call_action('get_site_user')['name']
        group = helpers.call_action('group_create',
                                    context={'user': user_name},
                                    name='test_group')
        context = {'model': core_model}
        obj = logic_auth.get_group_object(context, {'id': group['id']})

        assert obj.id == group['id']
        assert context['group'] == obj

########NEW FILE########
__FILENAME__ = test_update
'''Unit tests for ckan/logic/auth/update.py.

'''
import mock
import nose

import ckan.new_tests.helpers as helpers
import ckan.new_tests.factories as factories
import ckan.logic as logic


class TestUpdate(object):

    def test_user_update_visitor_cannot_update_user(self):
        '''Visitors should not be able to update users' accounts.'''

        # Make a mock ckan.model.User object, Fred.
        fred = factories.MockUser(name='fred')

        # Make a mock ckan.model object.
        mock_model = mock.MagicMock()
        # model.User.get(user_id) should return Fred.
        mock_model.User.get.return_value = fred

        # Put the mock model in the context.
        # This is easier than patching import ckan.model.
        context = {'model': mock_model}

        # No user is going to be logged-in.
        context['user'] = '127.0.0.1'

        # Make the visitor try to update Fred's user account.
        params = {
            'id': fred.id,
            'name': 'updated_user_name',
        }

        nose.tools.assert_raises(logic.NotAuthorized, helpers.call_auth,
                                 'user_update', context=context, **params)

    ## START-AFTER

    def test_user_update_user_cannot_update_another_user(self):
        '''Users should not be able to update other users' accounts.'''

        # 1. Setup.

        # Make a mock ckan.model.User object, Fred.
        fred = factories.MockUser(name='fred')

        # Make a mock ckan.model object.
        mock_model = mock.MagicMock()
        # model.User.get(user_id) should return Fred.
        mock_model.User.get.return_value = fred

        # Put the mock model in the context.
        # This is easier than patching import ckan.model.
        context = {'model': mock_model}

        # The logged-in user is going to be Bob, not Fred.
        context['user'] = 'bob'

        # 2. Call the function that's being tested, once only.

        # Make Bob try to update Fred's user account.
        params = {
            'id': fred.id,
            'name': 'updated_user_name',
        }

        # 3. Make assertions about the return value and/or side-effects.

        nose.tools.assert_raises(logic.NotAuthorized, helpers.call_auth,
                                 'user_update', context=context, **params)

        # 4. Do nothing else!

    ## END-BEFORE

    def test_user_update_user_can_update_herself(self):
        '''Users should be authorized to update their own accounts.'''

        # Make a mock ckan.model.User object, Fred.
        fred = factories.MockUser(name='fred')

        # Make a mock ckan.model object.
        mock_model = mock.MagicMock()
        # model.User.get(user_id) should return our mock user.
        mock_model.User.get.return_value = fred

        # Put the mock model in the context.
        # This is easier than patching import ckan.model.
        context = {'model': mock_model}

        # The 'user' in the context has to match fred.name, so that the
        # auth function thinks that the user being updated is the same user as
        # the user who is logged-in.
        context['user'] = fred.name

        # Make Fred try to update his own user name.
        params = {
            'id': fred.id,
            'name': 'updated_user_name',
        }

        result = helpers.call_auth('user_update', context=context, **params)
        assert result is True

    def test_user_update_with_no_user_in_context(self):

        # Make a mock ckan.model.User object.
        mock_user = factories.MockUser(name='fred')

        # Make a mock ckan.model object.
        mock_model = mock.MagicMock()
        # model.User.get(user_id) should return our mock user.
        mock_model.User.get.return_value = mock_user

        # Put the mock model in the context.
        # This is easier than patching import ckan.model.
        context = {'model': mock_model}

        # For this test we're going to have no 'user' in the context.
        context['user'] = None

        params = {
            'id': mock_user.id,
            'name': 'updated_user_name',
        }

        nose.tools.assert_raises(logic.NotAuthorized, helpers.call_auth,
                                 'user_update', context=context, **params)

    # TODO: Tests for user_update's reset_key behavior.

########NEW FILE########
__FILENAME__ = test_converters
# -*- coding: utf-8 -*-
'''Unit tests for ckan/logic/converters.py.

'''
import unittest
import ckan.logic.converters as converters


class TestRemoveWhitespaceConverter(unittest.TestCase):
    def test_leading_space(self):
        string = '  http://example.com'
        expected = 'http://example.com'
        converted = converters.remove_whitespace(string, {})
        self.assertEqual(expected, converted)

    def test_trailing_space(self):
        string = 'http://example.com  '
        expected = 'http://example.com'
        converted = converters.remove_whitespace(string, {})
        self.assertEqual(expected, converted)

    def test_space_between(self):
        string = 'http://example.com/space between url '
        expected = 'http://example.com/space between url'
        converted = converters.remove_whitespace(string, {})
        self.assertEqual(expected, converted)

    def test_not_a_string(self):
        string = 12345
        expected = 12345
        converted = converters.remove_whitespace(string, {})
        self.assertEqual(string, converted)

########NEW FILE########
__FILENAME__ = test_schema
'''

We *don't* write tests for the schemas defined in :py:mod:`ckan.logic.schema`.
The validation done by the schemas is instead tested indirectly by the action
function tests.  The reason for this is that CKAN actually does validation in
multiple places: some validation is done using schemas, some validation is done
in the action functions themselves, some is done in dictization, and some in
the model.  By testing all the different valid and invalid inputs at the action
function level, we catch it all in one place.

'''

########NEW FILE########
__FILENAME__ = test_validators
# -*- coding: utf-8 -*-
'''Unit tests for ckan/logic/validators.py.

'''
import copy
import fractions
import decimal
import warnings

import mock
import nose.tools

import ckan.new_tests.factories as factories
# Import some test helper functions from another module.
# This is bad (test modules shouldn't share code with eachother) but because of
# the way validator functions are organised in CKAN (in different modules in
# different places in the code) we have to either do this or introduce a shared
# test helper functions module (which we also don't want to do).
import ckan.new_tests.lib.navl.test_validators as t
import ckan.lib.navl.dictization_functions as df
import ckan.logic.validators as validators
import ckan.model as model

assert_equals = nose.tools.assert_equals


def returns_arg(function):
    '''A decorator that tests that the decorated function returns the argument
    that it is called with, unmodified.

    :param function: the function to decorate
    :type function: function

    Usage:

        @returns_arg
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors)

    '''
    def call_and_assert(arg, context=None):
        if context is None:
            context = {}
        result = function(arg, context=context)
        assert result == arg, (
            'Should return the argument that was passed to it, unchanged '
            '({arg})'.format(arg=repr(arg)))
        return result
    return call_and_assert


def raises_Invalid(function):
    '''A decorator that asserts that the decorated function raises
    dictization_functions.Invalid.

    Usage:

        @raises_Invalid
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors)

    '''
    def call_and_assert(*args, **kwargs):
        nose.tools.assert_raises(df.Invalid, function, *args, **kwargs)
    return call_and_assert


def does_not_modify_other_keys_in_errors_dict(validator):
    '''A decorator that asserts that the decorated validator doesn't add,
    modify the value of, or remove any other keys from its ``errors`` dict
    param.

    The function *may* modify its own errors dict key.

    :param validator: the validator function to decorate
    :type validator: function

    Usage:

        @does_not_modify_other_keys_in_errors_dict
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors)

    '''
    def call_and_assert(key, data, errors, context=None):
        if context is None:
            context = {}
        original_data = copy.deepcopy(data)
        original_errors = copy.deepcopy(errors)
        original_context = copy.deepcopy(context)

        result = validator(key, data, errors, context=context)

        # The validator function is allowed to modify its own key, so remove
        # that key from both dicts for the purposes of the assertions below.
        if key in errors:
            del errors[key]
        if key in original_errors:
            del original_errors[key]

        assert errors.keys() == original_errors.keys(), (
            'Should not add or remove keys from errors dict when called with '
            'key: {key}, data: {data}, errors: {errors}, '
            'context: {context}'.format(key=key, data=original_data,
                                        errors=original_errors,
                                        context=original_context))
        for key_ in errors:
            assert errors[key_] == original_errors[key_], (
                'Should not modify other keys in errors dict when called with '
                'key: {key}, data: {data}, errors: {errors}, '
                'context: {context}'.format(key=key, data=original_data,
                                            errors=original_errors,
                                            context=original_context))
        return result
    return call_and_assert


def adds_message_to_errors_dict(error_message):
    '''A decorator that asserts the the decorated validator adds a given
    error message to the `errors` dict.

    :param error_message: the error message that the validator is expected to
        add to the `errors` dict
    :type error_message: string

    Usage:

        @adds_message_to_errors_dict('That login name is not available.')
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors)

    '''
    def decorator(validator):
        def call_and_assert(key, data, errors, context):
            result = validator(key, data, errors, context)
            assert errors[key] == [error_message], (
                'Should add message to errors dict: {msg}'.format(
                    msg=error_message))
            return result
        return call_and_assert
    return decorator


class TestValidators(object):

    def test_name_validator_with_invalid_value(self):
        '''If given an invalid value name_validator() should do raise Invalid.

        '''
        invalid_values = [
            # Non-string names aren't allowed as names.
            13,
            23.7,
            100L,
            1.0j,
            None,
            True,
            False,
            ('a', 2, False),
            [13, None, True],
            {'foo': 'bar'},
            lambda x: x ** 2,

            # Certain reserved strings aren't allowed as names.
            'new',
            'edit',
            'search',

            # Strings < 2 characters long aren't allowed as names.
            '',
            'a',
            '2',

            # Strings > PACKAGE_NAME_MAX_LENGTH long aren't allowed as names.
            'a' * (model.PACKAGE_NAME_MAX_LENGTH + 1),

            # Strings containing non-ascii characters aren't allowed as names.
            u"fred_❤%'\"Ußabc@fred.com",

            # Strings containing upper-case characters aren't allowed as names.
            'seanH',

            # Strings containing spaces aren't allowed as names.
            'sean h',

            # Strings containing punctuation aren't allowed as names.
            'seanh!',
        ]

        for invalid_value in invalid_values:
            @raises_Invalid
            def call_validator(*args, **kwargs):
                return validators.name_validator(*args, **kwargs)
            call_validator(invalid_value, context={})

    def test_name_validator_with_valid_value(self):
        '''If given a valid string name_validator() should do nothing and
        return the string.

        '''
        valid_names = [
            'fred',
            'fred-flintstone',
            'fred_flintstone',
            'fred_flintstone-9',
            'f' * model.PACKAGE_NAME_MAX_LENGTH,
            '-' * model.PACKAGE_NAME_MAX_LENGTH,
            '_' * model.PACKAGE_NAME_MAX_LENGTH,
            '9' * model.PACKAGE_NAME_MAX_LENGTH,
            '99',
            '--',
            '__',
            u'fred-flintstone_9',
        ]

        for valid_name in valid_names:
            @returns_arg
            def call_validator(*args, **kwargs):
                return validators.name_validator(*args, **kwargs)
            call_validator(valid_name)

    ## START-AFTER

    def test_user_name_validator_with_non_string_value(self):
        '''user_name_validator() should raise Invalid if given a non-string
        value.

        '''
        non_string_values = [
            13,
            23.7,
            100L,
            1.0j,
            None,
            True,
            False,
            ('a', 2, False),
            [13, None, True],
            {'foo': 'bar'},
            lambda x: x ** 2,
        ]

        # Mock ckan.model.
        mock_model = mock.MagicMock()
        # model.User.get(some_user_id) needs to return None for this test.
        mock_model.User.get.return_value = None

        key = ('name',)
        for non_string_value in non_string_values:
            data = factories.validator_data_dict()
            data[key] = non_string_value
            errors = factories.validator_errors_dict()
            errors[key] = []

            @t.does_not_modify_data_dict
            @raises_Invalid
            def call_validator(*args, **kwargs):
                return validators.user_name_validator(*args, **kwargs)
            call_validator(key, data, errors, context={'model': mock_model})

    ## END-BEFORE

    def test_user_name_validator_with_a_name_that_already_exists(self):
        '''user_name_validator() should add to the errors dict if given a
        user name that already exists.

        '''
        # Mock ckan.model. model.User.get('user_name') will return another mock
        # object rather than None, which will simulate an existing user with
        # the same user name in the database.
        mock_model = mock.MagicMock()

        data = factories.validator_data_dict()
        key = ('name',)
        data[key] = 'user_name'
        errors = factories.validator_errors_dict()
        errors[key] = []

        @does_not_modify_other_keys_in_errors_dict
        @t.does_not_modify_data_dict
        @t.returns_None
        @adds_message_to_errors_dict('That login name is not available.')
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors, context={'model': mock_model})

    def test_user_name_validator_successful(self):
        '''user_name_validator() should do nothing if given a valid name.'''
        data = factories.validator_data_dict()
        key = ('name',)
        data[key] = 'new_user_name'
        errors = factories.validator_errors_dict()
        errors[key] = []

        # Mock ckan.model.
        mock_model = mock.MagicMock()
        # model.User.get(user_name) should return None, to simulate that no
        # user with that name exists in the database.
        mock_model.User.get.return_value = None

        @t.does_not_modify_errors_dict
        @t.does_not_modify_data_dict
        @t.returns_None
        def call_validator(*args, **kwargs):
            return validators.user_name_validator(*args, **kwargs)
        call_validator(key, data, errors, context={'model': mock_model})

    # TODO: Test user_name_validator()'s behavior when there's a 'user_obj' in
    # the context dict.

    def test_if_empty_guess_format(self):
        data = {'name': 'package_name', 'resources': [
            {'url': 'http://fakedomain/my.csv', 'format': ''},
            {'url': 'http://fakedomain/my.pdf',
             'format': df.Missing},
            {'url': 'http://fakedomain/my.pdf', 'format': 'pdf'},
            {'url': 'http://fakedomain/my.pdf',
             'id': 'fake_resource_id', 'format': ''}
        ]}
        data = df.flatten_dict(data)

        @t.does_not_modify_errors_dict
        def call_validator(*args, **kwargs):
            return validators.if_empty_guess_format(*args, **kwargs)

        new_data = copy.deepcopy(data)
        call_validator(key=('resources', 0, 'format'), data=new_data,
                       errors={}, context={})
        assert new_data[('resources', 0, 'format')] == 'text/csv'

        new_data = copy.deepcopy(data)
        call_validator(key=('resources', 1, 'format'), data=new_data,
                       errors={}, context={})
        assert new_data[('resources', 1, 'format')] == 'application/pdf'

        new_data = copy.deepcopy(data)
        call_validator(key=('resources', 2, 'format'), data=new_data,
                       errors={}, context={})
        assert new_data[('resources', 2, 'format')] == 'pdf'

        new_data = copy.deepcopy(data)
        call_validator(key=('resources', 3, 'format'), data=new_data,
                       errors={}, context={})
        assert new_data[('resources', 3, 'format')] == ''

    def test_clean_format(self):
        format = validators.clean_format('csv')
        assert format == 'CSV'

        format = validators.clean_format('text/csv')
        assert format == 'CSV'

        format = validators.clean_format('not a format')
        assert format == 'not a format'

        format = validators.clean_format('')
        assert format == ''

    def test_datasets_with_org_can_be_private_when_creating(self):
        data = factories.validator_data_dict()
        errors = factories.validator_errors_dict()

        key = ('private',)
        data[key] = True
        errors[key] = []

        data[('owner_org',)] = 'some_org_id'

        # Mock ckan.model.
        mock_model = mock.MagicMock()

        @t.does_not_modify_errors_dict
        @t.does_not_modify_data_dict
        @t.returns_None
        def call_validator(*args, **kwargs):
            return validators.datasets_with_no_organization_cannot_be_private(
                *args, **kwargs)
        call_validator(key, data, errors, context={'model': mock_model})

    def test_datasets_with_no_org_cannot_be_private_when_creating(self):
        data = factories.validator_data_dict()
        errors = factories.validator_errors_dict()

        key = ('private',)
        data[key] = True
        errors[key] = []

        # Mock ckan.model.
        mock_model = mock.MagicMock()

        @t.does_not_modify_data_dict
        @adds_message_to_errors_dict(
            "Datasets with no organization can't be private.")
        def call_validator(*args, **kwargs):
            return validators.datasets_with_no_organization_cannot_be_private(
                *args, **kwargs)

        call_validator(key, data, errors, context={'model': mock_model})

    def test_datasets_with_org_can_be_private_when_updating(self):
        data = factories.validator_data_dict()
        errors = factories.validator_errors_dict()

        key = ('private',)
        data[key] = True
        errors[key] = []

        data[('id',)] = 'some_dataset_id'
        data[('owner_org',)] = 'some_org_id'

        # Mock ckan.model.
        mock_model = mock.MagicMock()

        @t.does_not_modify_errors_dict
        @t.does_not_modify_data_dict
        @t.returns_None
        def call_validator(*args, **kwargs):
            return validators.datasets_with_no_organization_cannot_be_private(
                *args, **kwargs)
        call_validator(key, data, errors, context={'model': mock_model})


class TestIntValidator(object):

    def test_int_unchanged(self):
        returns_arg(validators.int_validator)(42)

    def test_zero_unchanged(self):
        returns_arg(validators.int_validator)(0)

    def test_long_unchanged(self):
        returns_arg(validators.int_validator)(3948756923874659827346598)

    def test_None_unchanged(self):
        returns_arg(validators.int_validator)(None)

    def test_float_converted(self):
        assert_equals(validators.int_validator(42.0, None), 42)

    def test_fraction_converted(self):
        assert_equals(validators.int_validator(
            fractions.Fraction(2, 1), {}), 2)

    def test_decimal_converted(self):
        assert_equals(validators.int_validator(
            decimal.Decimal('19.00'), {}), 19)

    def test_long_int_string_converted(self):
        assert_equals(validators.int_validator(
            '528735648764587235684376', {}), 528735648764587235684376)

    def test_negative_int_string_converted(self):
        assert_equals(validators.int_validator('-2', {}), -2)

    def test_positive_int_string_converted(self):
        assert_equals(validators.int_validator('+3', {}), 3)

    def test_zero_prefixed_int_string_converted_as_decimal(self):
        assert_equals(validators.int_validator('0123', {}), 123)

    def test_string_with_whitespace_converted(self):
        assert_equals(validators.int_validator('\t  98\n', {}), 98)

    def test_empty_string_becomes_None(self):
        assert_equals(validators.int_validator('', {}), None)

    def test_whitespace_string_becomes_None(self):
        assert_equals(validators.int_validator('\n\n  \t', {}), None)

    def test_float_with_decimal_raises_Invalid(self):
        raises_Invalid(validators.int_validator)(42.5, {})

    def test_float_string_raises_Invalid(self):
        raises_Invalid(validators.int_validator)('42.0', {})

    def test_exponent_string_raises_Invalid(self):
        raises_Invalid(validators.int_validator)('1e6', {})

    def test_non_numeric_string_raises_Invalid(self):
        raises_Invalid(validators.int_validator)('text', {})

    def test_non_whole_fraction_raises_Invalid(self):
        raises_Invalid(validators.int_validator)(fractions.Fraction(3, 2), {})

    def test_non_whole_decimal_raises_Invalid(self):
        raises_Invalid(validators.int_validator)(decimal.Decimal('19.99'), {})

    def test_complex_with_imaginary_component_raises_Invalid(self):
        with warnings.catch_warnings():  # divmod() issues warning for complex
            warnings.filterwarnings('ignore', category=DeprecationWarning)
            raises_Invalid(validators.int_validator)(1 + 1j, {})

    def test_complex_without_imaginary_component_raises_Invalid(self):
        with warnings.catch_warnings():  # divmod() issues warning for complex
            warnings.filterwarnings('ignore', category=DeprecationWarning)
            raises_Invalid(validators.int_validator)(1 + 0j, {})


#TODO: Need to test when you are not providing owner_org and the validator
#      queries for the dataset with package_show

########NEW FILE########
__FILENAME__ = test_factories
import nose.tools

import ckan.new_tests.helpers as helpers
import ckan.new_tests.factories as factories

assert_equals = nose.tools.assert_equals
assert_not_equals = nose.tools.assert_not_equals


class TestFactories(object):
    @classmethod
    def setup_class(cls):
        helpers.reset_db()

    @classmethod
    def teardown_class(cls):
        helpers.reset_db()

    def test_user_factory(self):
        user1 = factories.User()
        user2 = factories.User()
        assert_not_equals(user1['id'], user2['id'])

    def test_resource_factory(self):
        resource1 = factories.Resource()
        resource2 = factories.Resource()
        assert_not_equals(resource1['id'], resource2['id'])

    def test_sysadmin_factory(self):
        sysadmin1 = factories.Sysadmin()
        sysadmin2 = factories.Sysadmin()
        assert_not_equals(sysadmin1['id'], sysadmin2['id'])

    def test_group_factory(self):
        group1 = factories.Group()
        group2 = factories.Group()
        assert_not_equals(group1['id'], group2['id'])

    def test_organization_factory(self):
        organization1 = factories.Organization()
        organization2 = factories.Organization()
        assert_not_equals(organization1['id'], organization2['id'])

    def test_related_factory(self):
        related1 = factories.Related()
        related2 = factories.Related()
        assert_not_equals(related1['id'], related2['id'])

    def test_dataset_factory(self):
        dataset1 = factories.Dataset()
        dataset2 = factories.Dataset()
        assert_not_equals(dataset1['id'], dataset2['id'])

    def test_dataset_factory_allows_creation_by_anonymous_user(self):
        dataset = factories.Dataset(user=None)
        assert_equals(dataset['creator_user_id'], None)

    def test_mockuser_factory(self):
        mockuser1 = factories.MockUser()
        mockuser2 = factories.MockUser()
        assert_not_equals(mockuser1['id'], mockuser2['id'])

########NEW FILE########
__FILENAME__ = core
'''
Provides plugin services to the CKAN
'''

from contextlib import contextmanager
import logging
from pkg_resources import iter_entry_points
from pyutilib.component.core import PluginGlobals, implements
from pyutilib.component.core import ExtensionPoint as PluginImplementations
from pyutilib.component.core import SingletonPlugin as _pca_SingletonPlugin
from pyutilib.component.core import Plugin as _pca_Plugin
from paste.deploy.converters import asbool

import interfaces

__all__ = [
    'PluginImplementations', 'implements',
    'PluginNotFoundException', 'Plugin', 'SingletonPlugin',
    'load', 'load_all', 'unload', 'unload_all',
    'get_plugin', 'plugins_update',
    'use_plugin', 'plugin_loaded',
]

log = logging.getLogger(__name__)

# Entry point group.
PLUGINS_ENTRY_POINT_GROUP = 'ckan.plugins'

# Entry point group for system plugins (those that are part of core ckan and
# do not need to be explicitly enabled by the user)
SYSTEM_PLUGINS_ENTRY_POINT_GROUP = 'ckan.system_plugins'

# Entry point for test plugins.
TEST_PLUGINS_ENTRY_POINT_GROUP = 'ckan.test_plugins'

GROUPS = [
    PLUGINS_ENTRY_POINT_GROUP,
    SYSTEM_PLUGINS_ENTRY_POINT_GROUP,
    TEST_PLUGINS_ENTRY_POINT_GROUP,
]
# These lists are used to ensure that the correct extensions are enabled.
_PLUGINS = []
_PLUGINS_CLASS = []

# To aid retrieving extensions by name
_PLUGINS_SERVICE = {}


@contextmanager
def use_plugin(*plugins):
    '''Load plugin(s) for testing purposes

    e.g.
    ```
    import ckan.plugins as p
    with p.use_plugin('my_plugin') as my_plugin:
        # run tests with plugin loaded
    ```
    '''

    p = load(*plugins)
    try:
        yield p
    finally:
        unload(*plugins)


class PluginNotFoundException(Exception):
    '''
    Raised when a requested plugin cannot be found.
    '''


class Plugin(_pca_Plugin):
    '''
    Base class for plugins which require multiple instances.

    Unless you need multiple instances of your plugin object you should
    probably use SingletonPlugin.
    '''


class SingletonPlugin(_pca_SingletonPlugin):
    '''
    Base class for plugins which are singletons (ie most of them)

    One singleton instance of this class will be created when the plugin is
    loaded. Subsequent calls to the class constructor will always return the
    same singleton instance.
    '''


def get_plugin(plugin):
    ''' Get an instance of a active plugin by name.  This is helpful for
    testing. '''
    if plugin in _PLUGINS_SERVICE:
        return _PLUGINS_SERVICE[plugin]


def plugins_update():
    ''' This is run when plugins have been loaded or unloaded and allows us
    to run any specific code to ensure that the new plugin setting are
    correctly setup '''

    # It is posible for extra SingletonPlugin extensions to be activated if
    # the file containing them is imported, for example if two or more
    # extensions are defined in the same file.  Therefore we do a sanity
    # check and disable any that should not be active.
    for env in PluginGlobals.env_registry.values():
        for service in env.services.copy():
            if service.__class__ not in _PLUGINS_CLASS:
                service.deactivate()

    # Reset CKAN to reflect the currently enabled extensions.
    import ckan.config.environment as environment
    environment.update_config()


def load_all(config):
    '''
    Load all plugins listed in the 'ckan.plugins' config directive.
    '''
    # Clear any loaded plugins
    unload_all()

    plugins = config.get('ckan.plugins', '').split() + find_system_plugins()
    # Add the synchronous search plugin, unless already loaded or
    # explicitly disabled
    if 'synchronous_search' not in plugins and \
            asbool(config.get('ckan.search.automatic_indexing', True)):
        log.debug('Loading the synchronous search plugin')
        plugins.append('synchronous_search')

    load(*plugins)


def load(*plugins):
    '''
    Load named plugin(s).
    '''

    output = []

    observers = PluginImplementations(interfaces.IPluginObserver)
    for plugin in plugins:
        if plugin in _PLUGINS:
            raise Exception('Plugin `%s` already loaded' % plugin)

        service = _get_service(plugin)
        for observer_plugin in observers:
            observer_plugin.before_load(service)
        service.activate()
        for observer_plugin in observers:
            observer_plugin.after_load(service)

        if interfaces.IGenshiStreamFilter in service.__interfaces__:
            log.warn("Plugin '%s' is using deprecated interface "
                     'IGenshiStreamFilter' % plugin)

        _PLUGINS.append(plugin)
        _PLUGINS_CLASS.append(service.__class__)

        if isinstance(service, SingletonPlugin):
            _PLUGINS_SERVICE[plugin] = service

        output.append(service)
    plugins_update()

    # Return extension instance if only one was loaded.  If more that one
    # has been requested then a list of instances is returned in the order
    # they were asked for.
    if len(output) == 1:
        return output[0]
    return output


def unload_all():
    '''
    Unload (deactivate) all loaded plugins in the reverse order that they
    were loaded.
    '''
    unload(*reversed(_PLUGINS))


def unload(*plugins):
    '''
    Unload named plugin(s).
    '''

    observers = PluginImplementations(interfaces.IPluginObserver)

    for plugin in plugins:
        if plugin in _PLUGINS:
            _PLUGINS.remove(plugin)
            if plugin in _PLUGINS_SERVICE:
                del _PLUGINS_SERVICE[plugin]
        else:
            raise Exception('Cannot unload plugin `%s`' % plugin)

        service = _get_service(plugin)
        for observer_plugin in observers:
            observer_plugin.before_unload(service)

        service.deactivate()

        _PLUGINS_CLASS.remove(service.__class__)

        for observer_plugin in observers:
            observer_plugin.after_unload(service)
    plugins_update()


def plugin_loaded(name):
    '''
    See if a particular plugin is loaded.
    '''
    if name in _PLUGINS:
        return True
    return False


def find_system_plugins():
    '''
    Return all plugins in the ckan.system_plugins entry point group.

    These are essential for operation and therefore cannot be
    enabled/disabled through the configuration file.
    '''

    eps = []
    for ep in iter_entry_points(group=SYSTEM_PLUGINS_ENTRY_POINT_GROUP):
        ep.load()
        eps.append(ep.name)
    return eps


def _get_service(plugin_name):
    '''
    Return a service (ie an instance of a plugin class).

    :param plugin_name: the name of a plugin entry point
    :type plugin_name: string

    :return: the service object
    '''

    if isinstance(plugin_name, basestring):
        for group in GROUPS:
            iterator = iter_entry_points(
                group=group,
                name=plugin_name
            )
            plugin = next(iterator, None)
            if plugin:
                return plugin.load()(name=plugin_name)
        raise PluginNotFoundException(plugin_name)
    else:
        raise TypeError('Expected a plugin name', plugin_name)

########NEW FILE########
__FILENAME__ = interfaces
'''A collection of interfaces that CKAN plugins can implement to customize and
extend CKAN.

'''
__all__ = [
    'Interface',
    'IGenshiStreamFilter', 'IRoutes',
    'IMapper', 'ISession',
    'IMiddleware',
    'IAuthFunctions',
    'IDomainObjectModification', 'IGroupController',
    'IOrganizationController',
    'IPackageController', 'IPluginObserver',
    'IConfigurable', 'IConfigurer',
    'IActions', 'IResourceUrlChange', 'IDatasetForm',
    'IResourcePreview',
    'IResourceController',
    'IGroupForm',
    'ITagController',
    'ITemplateHelpers',
    'IFacets',
    'IAuthenticator',
]

from inspect import isclass
from pyutilib.component.core import Interface as _pca_Interface


class Interface(_pca_Interface):

    @classmethod
    def provided_by(cls, instance):
        return cls.implemented_by(instance.__class__)

    @classmethod
    def implemented_by(cls, other):
        if not isclass(other):
            raise TypeError("Class expected", other)
        try:
            return cls in other._implements
        except AttributeError:
            return False


class IMiddleware(Interface):
    '''Hook into Pylons middleware stack
    '''
    def make_middleware(self, app, config):
        '''Return an app configured with this middleware
        '''
        return app


class IGenshiStreamFilter(Interface):
    '''
    Hook into template rendering.
    See ckan.lib.base.py:render
    '''

    def filter(self, stream):
        """
        Return a filtered Genshi stream.
        Called when any page is rendered.

        :param stream: Genshi stream of the current output document
        :returns: filtered Genshi stream
        """
        return stream


class IRoutes(Interface):
    """
    Plugin into the setup of the routes map creation.

    """
    def before_map(self, map):
        """
        Called before the routes map is generated. ``before_map`` is before any
        other mappings are created so can override all other mappings.

        :param map: Routes map object
        :returns: Modified version of the map object
        """
        return map

    def after_map(self, map):
        """
        Called after routes map is set up. ``after_map`` can be used to
        add fall-back handlers.

        :param map: Routes map object
        :returns: Modified version of the map object
        """
        return map


class IMapper(Interface):
    """
    A subset of the SQLAlchemy mapper extension hooks.
    See http://www.sqlalchemy.org/docs/05/reference/orm/interfaces.html#sqlalchemy.orm.interfaces.MapperExtension

    Example::

        >>> class MyPlugin(SingletonPlugin):
        ...
        ...     implements(IMapper)
        ...
        ...     def after_update(self, mapper, connection, instance):
        ...         log("Updated: %r", instance)
    """

    def before_insert(self, mapper, connection, instance):
        """
        Receive an object instance before that instance is INSERTed into
        its table.
        """

    def before_update(self, mapper, connection, instance):
        """
        Receive an object instance before that instance is UPDATEed.
        """

    def before_delete(self, mapper, connection, instance):
        """
        Receive an object instance before that instance is DELETEed.
        """

    def after_insert(self, mapper, connection, instance):
        """
        Receive an object instance after that instance is INSERTed.
        """

    def after_update(self, mapper, connection, instance):
        """
        Receive an object instance after that instance is UPDATEed.
        """

    def after_delete(self, mapper, connection, instance):
        """
        Receive an object instance after that instance is DELETEed.
        """


class ISession(Interface):
    """
    A subset of the SQLAlchemy session extension hooks.
    """

    def after_begin(self, session, transaction, connection):
        """
        Execute after a transaction is begun on a connection
        """

    def before_flush(self, session, flush_context, instances):
        """
        Execute before flush process has started.
        """

    def after_flush(self, session, flush_context):
        """
        Execute after flush has completed, but before commit has been called.
        """

    def before_commit(self, session):
        """
        Execute right before commit is called.
        """

    def after_commit(self, session):
        """
        Execute after a commit has occured.
        """

    def after_rollback(self, session):
        """
        Execute after a rollback has occured.
        """


class IDomainObjectModification(Interface):
    """
    Receives notification of new, changed and deleted datasets.
    """

    def notify(self, entity, operation):
        pass


class IResourceUrlChange(Interface):
    """
    Receives notification of changed urls.
    """

    def notify(self, resource):
        pass


class IResourcePreview(Interface):
    '''Add custom data previews for resource file-types.

    '''
    def can_preview(self, data_dict):
        '''Return info on whether the plugin can preview the resource.

        This can be done in two ways:

        1. The old way is to just return ``True`` or ``False``.

        2. The new way is to return a dict with  three keys:

           ``'can_preview'`` (``boolean``)
             ``True`` if the extension can preview the resource.

           ``'fixable'`` (``string``)
             A string explaining how preview for the resource could be enabled,
             for example if the ``resource_proxy`` plugin was enabled.

           ``'quality'`` (``int``)
             How good the preview is: ``1`` (poor), ``2`` (average) or
             ``3`` (good). When multiple preview extensions can preview the
             same resource, this is used to determine which extension will
             be used.

        :param data_dict: the resource to be previewed and the dataset that it
          belongs to.
        :type data_dict: dictionary

        Make sure to check the ``on_same_domain`` value of the resource or the
        url if your preview requires the resource to be on the same domain
        because of the same-origin policy.  To find out how to preview
        resources that are on a different domain, read :ref:`resource-proxy`.

        '''

    def setup_template_variables(self, context, data_dict):
        '''
        Add variables to c just prior to the template being rendered.
        The ``data_dict`` contains the resource and the package.

        Change the url to a proxied domain if necessary.
        '''

    def preview_template(self, context, data_dict):
        '''
        Returns a string representing the location of the template to be
        rendered for the read page.
        The ``data_dict`` contains the resource and the package.
        '''


class ITagController(Interface):
    '''
    Hook into the Tag controller. These will usually be called just before
    committing or returning the respective object, i.e. all validation,
    synchronization and authorization setup are complete.

    '''
    def before_view(self, tag_dict):
        '''
        Extensions will recieve this before the tag gets displayed. The
        dictionary passed will be the one that gets sent to the template.

        '''
        return tag_dict


class IGroupController(Interface):
    """
    Hook into the Group controller. These will
    usually be called just before committing or returning the
    respective object, i.e. all validation, synchronization
    and authorization setup are complete.
    """

    def read(self, entity):
        pass

    def create(self, entity):
        pass

    def edit(self, entity):
        pass

    def authz_add_role(self, object_role):
        pass

    def authz_remove_role(self, object_role):
        pass

    def delete(self, entity):
        pass

    def before_view(self, pkg_dict):
        '''
             Extensions will recieve this before the group gets
             displayed. The dictionary passed will be the one that gets
             sent to the template.
        '''
        return pkg_dict


class IOrganizationController(Interface):
    """
    Hook into the Organization controller. These will
    usually be called just before committing or returning the
    respective object, i.e. all validation, synchronization
    and authorization setup are complete.
    """

    def read(self, entity):
        pass

    def create(self, entity):
        pass

    def edit(self, entity):
        pass

    def authz_add_role(self, object_role):
        pass

    def authz_remove_role(self, object_role):
        pass

    def delete(self, entity):
        pass

    def before_view(self, pkg_dict):
        '''
             Extensions will recieve this before the organization gets
             displayed. The dictionary passed will be the one that gets
             sent to the template.
        '''
        return pkg_dict


class IPackageController(Interface):
    """
    Hook into the package controller.
    (see IGroupController)
    """

    def read(self, entity):
        pass

    def create(self, entity):
        pass

    def edit(self, entity):
        pass

    def authz_add_role(self, object_role):
        pass

    def authz_remove_role(self, object_role):
        pass

    def delete(self, entity):
        pass

    def after_create(self, context, pkg_dict):
        '''
            Extensions will receive the validated data dict after the package
            has been created (Note that the create method will return a package
            domain object, which may not include all fields). Also the newly
            created package id will be added to the dict.
        '''
        pass

    def after_update(self, context, pkg_dict):
        '''
            Extensions will receive the validated data dict after the package
            has been updated (Note that the edit method will return a package
            domain object, which may not include all fields).
        '''
        pass

    def after_delete(self, context, pkg_dict):
        '''
            Extensions will receive the data dict (tipically containing
            just the package id) after the package has been deleted.
        '''
        pass

    def after_show(self, context, pkg_dict):
        '''
            Extensions will receive the validated data dict after the package
            is ready for display (Note that the read method will return a
            package domain object, which may not include all fields).
        '''
        pass

    def before_search(self, search_params):
        '''
            Extensions will receive a dictionary with the query parameters,
            and should return a modified (or not) version of it.

            search_params will include an `extras` dictionary with all values
            from fields starting with `ext_`, so extensions can receive user
            input from specific fields.

        '''
        return search_params

    def after_search(self, search_results, search_params):
        '''
            Extensions will receive the search results, as well as the search
            parameters, and should return a modified (or not) object with the
            same structure:

                {'count': '', 'results': '', 'facets': ''}

            Note that count and facets may need to be adjusted if the extension
            changed the results for some reason.

            search_params will include an `extras` dictionary with all values
            from fields starting with `ext_`, so extensions can receive user
            input from specific fields.

        '''

        return search_results

    def before_index(self, pkg_dict):
        '''
             Extensions will receive what will be given to the solr for
             indexing. This is essentially a flattened dict (except for
             multli-valued fields such as tags) of all the terms sent to
             the indexer. The extension can modify this by returning an
             altered version.
        '''
        return pkg_dict

    def before_view(self, pkg_dict):
        '''
             Extensions will recieve this before the dataset gets
             displayed. The dictionary passed will be the one that gets
             sent to the template.
        '''
        return pkg_dict


class IResourceController(Interface):
    """
    Hook into the resource controller.
    """

    def before_show(self, resource_dict):
        '''
            Extensions will receive the validated data dict before the resource
            is ready for display.
        '''
        return resource_dict


class IPluginObserver(Interface):
    """
    Plugin to the plugin loading mechanism
    """

    def before_load(self, plugin):
        """
        Called before a plugin is loaded
        This method is passed the plugin class.
        """

    def after_load(self, service):
        """
        Called after a plugin has been loaded.
        This method is passed the instantiated service object.
        """

    def before_unload(self, plugin):
        """
        Called before a plugin is loaded
        This method is passed the plugin class.
        """

    def after_unload(self, service):
        """
        Called after a plugin has been unloaded.
        This method is passed the instantiated service object.
        """


class IConfigurable(Interface):
    """
    Pass configuration to plugins and extensions
    """

    def configure(self, config):
        """
        Called by load_environment
        """


class IConfigurer(Interface):
    """
    Configure CKAN (pylons) environment via the ``pylons.config`` object
    """

    def update_config(self, config):
        """
        Called by load_environment at earliest point when config is
        available to plugins. The config should be updated in place.

        :param config: ``pylons.config`` object
        """


class IActions(Interface):
    """
    Allow adding of actions to the logic layer.
    """
    def get_actions(self):
        """
        Should return a dict, the keys being the name of the logic
        function and the values being the functions themselves.

        By decorating a function with the `ckan.logic.side_effect_free`
        decorator, the associated action will be made available by a GET
        request (as well as the usual POST request) through the action API.
        """


class IAuthFunctions(Interface):
    '''Override CKAN's authorization functions, or add new auth functions.'''

    def get_auth_functions(self):
        '''Return the authorization functions provided by this plugin.

        Return a dictionary mapping authorization function names (strings) to
        functions. For example::

            {'user_create': my_custom_user_create_function,
             'group_create': my_custom_group_create}

        When a user tries to carry out an action via the CKAN API or web
        interface and CKAN or a CKAN plugin calls
        ``check_access('some_action')`` as a result, an authorization function
        named ``'some_action'`` will be searched for in the authorization
        functions registered by plugins and in CKAN's core authorization
        functions (found in ``ckan/logic/auth/``).

        For example when a user tries to create a package, a
        ``'package_create'`` authorization function is searched for.

        If an extension registers an authorization function with the same name
        as one of CKAN's default authorization functions (as with
        ``'user_create'`` and ``'group_create'`` above), the extension's
        function will override the default one.

        Each authorization function should take two parameters ``context`` and
        ``data_dict``, and should return a dictionary ``{'success': True}`` to
        authorize the action or ``{'success': False}`` to deny it, for
        example::

            def user_create(context, data_dict=None):
                if (some condition):
                    return {'success': True}
                else:
                    return {'success': False, 'msg': 'Not allowed to register'}

        The context object will contain a ``model`` that can be used to query
        the database, a ``user`` containing the name of the user doing the
        request (or their IP if it is an anonymous web request) and an
        ``auth_user_obj`` containing the actual model.User object (or None if
        it is an anonymous request).

        See ``ckan/logic/auth/`` for more examples.

        Note that by default, all auth functions provided by extensions are assumed
        to require a validated user or API key, otherwise a
        :py:class:`ckan.logic.NotAuthorized`: exception will be raised. This check
        will be performed *before* calling the actual auth function. If you want
        to allow anonymous access to one of your actions, its auth function must
        be decorated with the ``auth_allow_anonymous_access`` decorator, available
        on the plugins toolkit.

        For example::

            import ckan.plugins as p

            @p.toolkit.auth_allow_anonymous_access
            def my_search_action(context, data_dict):
                # Note that you can still return {'success': False} if for some
                # reason access is denied.

            def my_create_action(context, data_dict):
                # Unless there is a logged in user or a valid API key provided
                # NotAuthorized will be raised before reaching this function.

        '''


class ITemplateHelpers(Interface):
    '''Add custom template helper functions.

    By implementing this plugin interface plugins can provide their own
    template helper functions, which custom templates can then access via the
    ``h`` variable.

    See ``ckanext/example_itemplatehelpers`` for an example plugin.

    '''
    def get_helpers(self):
        '''Return a dict mapping names to helper functions.

        The keys of the dict should be the names with which the helper
        functions will be made available to templates, and the values should be
        the functions themselves. For example, a dict like:
        ``{'example_helper': example_helper}`` allows templates to access the
        ``example_helper`` function via ``h.example_helper()``.

        Function names should start with the name of the extension providing
        the function, to prevent name clashes between extensions.

        '''


class IDatasetForm(Interface):
    '''Customize CKAN's dataset (package) schemas and forms.

    By implementing this interface plugins can customise CKAN's dataset schema,
    for example to add new custom fields to datasets.

    Multiple IDatasetForm plugins can be used at once, each plugin associating
    itself with different package types using the ``package_types()`` and
    ``is_fallback()`` methods below, and then providing different schemas and
    templates for different types of dataset.  When a package controller action
    is invoked, the ``type`` field of the package will determine which
    IDatasetForm plugin (if any) gets delegated to.

    When implementing IDatasetForm, you can inherit from
    ``ckan.plugins.toolkit.DefaultDatasetForm``, which provides default
    implementations for each of the methods defined in this interface.

    See ``ckanext/example_idatasetform`` for an example plugin.

    '''
    def package_types(self):
        '''Return an iterable of package types that this plugin handles.

        If a request involving a package of one of the returned types is made,
        then this plugin instance will be delegated to.

        There cannot be two IDatasetForm plugins that return the same package
        type, if this happens then CKAN will raise an exception at startup.

        :rtype: iterable of strings

        '''

    def is_fallback(self):
        '''Return ``True`` if this plugin is the fallback plugin.

        When no IDatasetForm plugin's ``package_types()`` match the ``type`` of
        the package being processed, the fallback plugin is delegated to
        instead.

        There cannot be more than one IDatasetForm plugin whose
        ``is_fallback()`` method returns ``True``, if this happens CKAN will
        raise an exception at startup.

        If no IDatasetForm plugin's ``is_fallback()`` method returns ``True``,
        CKAN will use ``DefaultDatasetForm`` as the fallback.

        :rtype: boolean

        '''

    def create_package_schema(self):
        '''Return the schema for validating new dataset dicts.

        CKAN will use the returned schema to validate and convert data coming
        from users (via the dataset form or API) when creating new datasets,
        before entering that data into the database.

        If it inherits from ``ckan.plugins.toolkit.DefaultDatasetForm``, a
        plugin can call ``DefaultDatasetForm``'s ``create_package_schema()``
        method to get the default schema and then modify and return it.

        CKAN's ``convert_to_tags()`` or ``convert_to_extras()`` functions can
        be used to convert custom fields into dataset tags or extras for
        storing in the database.

        See ``ckanext/example_idatasetform`` for examples.

        :returns: a dictionary mapping dataset dict keys to lists of validator
          and converter functions to be applied to those keys
        :rtype: dictionary

        '''

    def update_package_schema(self):
        '''Return the schema for validating updated dataset dicts.

        CKAN will use the returned schema to validate and convert data coming
        from users (via the dataset form or API) when updating datasets, before
        entering that data into the database.

        If it inherits from ``ckan.plugins.toolkit.DefaultDatasetForm``, a
        plugin can call ``DefaultDatasetForm``'s ``update_package_schema()``
        method to get the default schema and then modify and return it.

        CKAN's ``convert_to_tags()`` or ``convert_to_extras()`` functions can
        be used to convert custom fields into dataset tags or extras for
        storing in the database.

        See ``ckanext/example_idatasetform`` for examples.

        :returns: a dictionary mapping dataset dict keys to lists of validator
          and converter functions to be applied to those keys
        :rtype: dictionary

        '''

    def show_package_schema(self):
        '''
        Return a schema to validate datasets before they're shown to the user.

        CKAN will use the returned schema to validate and convert data coming
        from the database before it is returned to the user via the API or
        passed to a template for rendering.

        If it inherits from ``ckan.plugins.toolkit.DefaultDatasetForm``, a
        plugin can call ``DefaultDatasetForm``'s ``show_package_schema()``
        method to get the default schema and then modify and return it.

        If you have used ``convert_to_tags()`` or ``convert_to_extras()`` in
        your ``create_package_schema()`` and ``update_package_schema()`` then
        you should use ``convert_from_tags()`` or ``convert_from_extras()`` in
        your ``show_package_schema()`` to convert the tags or extras in the
        database back into your custom dataset fields.

        See ``ckanext/example_idatasetform`` for examples.

        :returns: a dictionary mapping dataset dict keys to lists of validator
          and converter functions to be applied to those keys
        :rtype: dictionary

        '''

    def setup_template_variables(self, context, data_dict):
        '''Add variables to the template context for use in templates.

        This function is called before a dataset template is rendered. If you
        have custom dataset templates that require some additional variables,
        you can add them to the template context ``ckan.plugins.toolkit.c``
        here and they will be available in your templates. See
        ``ckanext/example_idatasetform`` for an example.

        '''

    def new_template(self):
        '''Return the path to the template for the new dataset page.

        The path should be relative to the plugin's templates dir, e.g.
        ``'package/new.html'``.

        :rtype: string

        '''

    def read_template(self):
        '''Return the path to the template for the dataset read page.

        The path should be relative to the plugin's templates dir, e.g.
        ``'package/read.html'``.

        If the user requests the dataset in a format other than HTML
        (CKAN supports returning datasets in RDF or N3 format by appending .rdf
        or .n3 to the dataset read URL, see
        :doc:`/maintaining/linked-data-and-rdf`) then CKAN will try to render a
        template file with the same path as returned by this function, but a
        different filename extension, e.g. ``'package/read.rdf'``.  If your
        extension doesn't have this RDF version of the template file, the user
        will get a 404 error.

        :rtype: string

        '''

    def edit_template(self):
        '''Return the path to the template for the dataset edit page.

        The path should be relative to the plugin's templates dir, e.g.
        ``'package/edit.html'``.

        :rtype: string

        '''

    def search_template(self):
        '''Return the path to the template for use in the dataset search page.

        This template is used to render each dataset that is listed in the
        search results on the dataset search page.

        The path should be relative to the plugin's templates dir, e.g.
        ``'package/search.html'``.

        :rtype: string

        '''

    def history_template(self):
        '''Return the path to the template for the dataset history page.

        The path should be relative to the plugin's templates dir, e.g.
        ``'package/history.html'``.

        :rtype: string

        '''

    def package_form(self):
        '''Return the path to the template for the dataset form.

        The path should be relative to the plugin's templates dir, e.g.
        ``'package/form.html'``.

        :rtype: string

        '''

    def validate(self, context, data_dict, schema, action):
        """Customize validation of datasets.

        When this method is implemented it is used to perform all validation
        for these datasets. The default implementation calls and returns the
        result from ``ckan.plugins.toolkit.navl_validate``.

        This is an adavanced interface. Most changes to validation should be
        accomplished by customizing the schemas returned from
        ``show_package_schema()``, ``create_package_schema()``
        and ``update_package_schama()``. If you need to have a different
        schema depending on the user or value of any field stored in the
        dataset, or if you wish to use a different method for validation, then
        this method may be used.

        :param context: extra information about the request
        :type context: dictionary
        :param data_dict: the dataset to be validated
        :type data_dict: dictionary
        :param schema: a schema, typically from ``show_package_schema()``,
          ``create_package_schema()`` or ``update_package_schama()``
        :type schema: dictionary
        :param action: ``'package_show'``, ``'package_create'`` or
          ``'package_update'``
        :type action: string
        :returns: (data_dict, errors) where data_dict is the possibly-modified
          dataset and errors is a dictionary with keys matching data_dict
          and lists-of-string-error-messages as values
        :rtype: (dictionary, dictionary)
        """


class IGroupForm(Interface):
    """
    Allows customisation of the group controller as a plugin.

    The behaviour of the plugin is determined by 5 method hooks:

     - package_form(self)
     - form_to_db_schema(self)
     - db_to_form_schema(self)
     - check_data_dict(self, data_dict)
     - setup_template_variables(self, context, data_dict)

    Furthermore, there can be many implementations of this plugin registered
    at once.  With each instance associating itself with 0 or more package
    type strings.  When a package controller action is invoked, the package
    type determines which of the registered plugins to delegate to.  Each
    implementation must implement two methods which are used to determine the
    package-type -> plugin mapping:

     - is_fallback(self)
     - package_types(self)

    Implementations might want to consider mixing in
    ckan.lib.plugins.DefaultGroupForm which provides
    default behaviours for the 5 method hooks.

    """

    ##### These methods control when the plugin is delegated to          #####

    def is_fallback(self):
        """
        Returns true iff this provides the fallback behaviour, when no other
        plugin instance matches a package's type.

        There must be exactly one fallback controller defined, any attempt to
        register more than one will throw an exception at startup.  If there's
        no fallback registered at startup the
        ckan.lib.plugins.DefaultGroupForm used as the fallback.
        """

    def group_types(self):
        """
        Returns an iterable of group type strings.

        If a request involving a package of one of those types is made, then
        this plugin instance will be delegated to.

        There must only be one plugin registered to each group type.  Any
        attempts to register more than one plugin instance to a given group
        type will raise an exception at startup.
        """

    ##### End of control methods

    ##### Hooks for customising the PackageController's behaviour        #####
    ##### TODO: flesh out the docstrings a little more.                  #####
    def new_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the 'new' page. Uses the default_group_type configuration
        option to determine which plugin to use the template from.
        """

    def index_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the index page. Uses the default_group_type configuration
        option to determine which plugin to use the template from.
        """

    def read_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the read page
        """

    def history_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the history page
        """

    def edit_template(self):
        """
        Returns a string representing the location of the template to be
        rendered for the edit page
        """

    def package_form(self):
        """
        Returns a string representing the location of the template to be
        rendered.  e.g. "group/new_group_form.html".
        """

    def form_to_db_schema(self):
        """
        Returns the schema for mapping group data from a form to a format
        suitable for the database.
        """

    def db_to_form_schema(self):
        """
        Returns the schema for mapping group data from the database into a
        format suitable for the form (optional)
        """

    def check_data_dict(self, data_dict):
        """
        Check if the return data is correct.

        raise a DataError if not.
        """

    def setup_template_variables(self, context, data_dict):
        """
        Add variables to c just prior to the template being rendered.
        """

    def validate(self, context, data_dict, schema, action):
        """Customize validation of groups.

        When this method is implemented it is used to perform all validation
        for these groups. The default implementation calls and returns the
        result from ``ckan.plugins.toolkit.navl_validate``.

        This is an adavanced interface. Most changes to validation should be
        accomplished by customizing the schemas returned from
        ``form_to_db_schema()`` and ``db_to_form_schema()``
        If you need to have a different
        schema depending on the user or value of any field stored in the
        group, or if you wish to use a different method for validation, then
        this method may be used.

        :param context: extra information about the request
        :type context: dictionary
        :param data_dict: the group to be validated
        :type data_dict: dictionary
        :param schema: a schema, typically from ``form_to_db_schema()``,
          or ``db_to_form_schama()``
        :type schema: dictionary
        :param action: ``'group_show'``, ``'group_create'``,
          ``'group_update'``, ``'organization_show'``,
          ``'organization_create'`` or ``'organization_update'``
        :type action: string
        :returns: (data_dict, errors) where data_dict is the possibly-modified
          group and errors is a dictionary with keys matching data_dict
          and lists-of-string-error-messages as values
        :rtype: (dictionary, dictionary)
        """

    ##### End of hooks                                                   #####

class IFacets(Interface):
    '''Customize the search facets shown on search pages.

    By implementing this interface plugins can customize the search facets that
    are displayed for filtering search results on the dataset search page,
    organization pages and group pages.

    The ``facets_dict`` passed to each of the functions below is an
    ``OrderedDict`` in which the keys are CKAN's internal names for the facets
    and the values are the titles that will be shown for the facets in the web
    interface. The order of the keys in the dict determine the order that
    facets appear in on the page.  For example::

        {'groups': _('Groups'),
         'tags': _('Tags'),
         'res_format': _('Formats'),
         'license': _('License')}

    To preserve ordering, make sure to add new facets to the existing dict
    rather than updating it, ie do this::

        facets_dict['groups'] = p.toolkit._('Publisher')
        facets_dict['secondary_publisher'] = p.toolkit._('Secondary Publisher')

    rather than this::

        facets_dict.update({
           'groups': p.toolkit._('Publisher'),
           'secondary_publisher': p.toolkit._('Secondary Publisher'),
        })

    Dataset searches can be faceted on any field in the dataset schema that it
    makes sense to facet on. This means any dataset field that is in CKAN's
    Solr search index, basically any field that you see returned by
    :py:func:`~ckan.logic.action.get.package_show`.

    If there are multiple ``IFacets`` plugins active at once, each plugin will
    be called (in the order that they're listed in the CKAN config file) and
    they will each be able to modify the facets dict in turn.

    '''
    def dataset_facets(self, facets_dict, package_type):
        '''Modify and return the ``facets_dict`` for the dataset search page.

        The ``package_type`` is the type of package that these facets apply to.
        Plugins can provide different search facets for different types of
        package. See :py:class:`~ckan.plugins.interfaces.IDatasetForm`.

        :param facets_dict: the search facets as currently specified
        :type facets_dict: OrderedDict

        :param package_type: the package type that these facets apply to
        :type package_type: string

        :returns: the updated ``facets_dict``
        :rtype: OrderedDict

        '''
        return facets_dict

    def group_facets(self, facets_dict, group_type, package_type):
        '''Modify and return the ``facets_dict`` for a group's page.

        The ``package_type`` is the type of package that these facets apply to.
        Plugins can provide different search facets for different types of
        package. See :py:class:`~ckan.plugins.interfaces.IDatasetForm`.

        The ``group_type`` is the type of group that these facets apply to.
        Plugins can provide different search facets for different types of
        group. See :py:class:`~ckan.plugins.interfaces.IGroupForm`.

        :param facets_dict: the search facets as currently specified
        :type facets_dict: OrderedDict

        :param group_type: the group type that these facets apply to
        :type group_type: string

        :param package_type: the package type that these facets apply to
        :type package_type: string

        :returns: the updated ``facets_dict``
        :rtype: OrderedDict

        '''
        return facets_dict

    def organization_facets(self, facets_dict, organization_type, package_type):
        '''Modify and return the ``facets_dict`` for an organization's page.

        The ``package_type`` is the type of package that these facets apply to.
        Plugins can provide different search facets for different types of
        package. See :py:class:`~ckan.plugins.interfaces.IDatasetForm`.

        The ``organization_type`` is the type of organization that these facets
        apply to.  Plugins can provide different search facets for different
        types of organization. See
        :py:class:`~ckan.plugins.interfaces.IGroupForm`.

        :param facets_dict: the search facets as currently specified
        :type facets_dict: OrderedDict

        :param organization_type: the organization type that these facets apply
                                  to
        :type organization_type: string

        :param package_type: the package type that these facets apply to
        :type package_type: string

        :returns: the updated ``facets_dict``
        :rtype: OrderedDict

        '''
        return facets_dict


class IAuthenticator(Interface):
    '''EXPERIMENTAL

    Allows custom authentication methods to be integrated into CKAN.
    Currently it is experimental and the interface may change.'''


    def identify(self):
        '''called to identify the user.

        If the user is identfied then it should set
        c.user: The id of the user
        c.userobj: The actual user object (this may be removed as a
        requirement in a later release so that access to the model is not
        required)
        '''

    def login(self):
        '''called at login.'''

    def logout(self):
        '''called at logout.'''

    def abort(self, status_code, detail, headers, comment):
        '''called on abort.  This allows aborts due to authorization issues
        to be overriden'''
        return (status_code, detail, headers, comment)

########NEW FILE########
__FILENAME__ = toolkit
import inspect
import os
import re

import paste.deploy.converters as converters
import webhelpers.html.tags

__all__ = ['toolkit']


class CkanVersionException(Exception):
    '''Exception raised by
    :py:func:`~ckan.plugins.toolkit.requires_ckan_version` if the required CKAN
    version is not available.

    '''
    pass


class _Toolkit(object):
    '''This class is intended to make functions/objects consistently
    available to plugins, whilst giving core CKAN developers the ability move
    code around or change underlying frameworks etc. This object allows
    us to avoid circular imports while making functions/objects
    available to plugins.

    It should not be used internally within ckan - only by extensions.

    Functions/objects should only be removed after reasonable
    deprecation notice has been given.'''

    # contents should describe the available functions/objects. We check
    # that this list matches the actual availables in the initialisation
    contents = [
        ## Imported functions/objects ##
        '_',                    # i18n translation
        'c',                    # template context
        'request',              # http request object
        'render',               # template render function
        'render_text',          # Genshi NewTextTemplate render function
        'render_snippet',       # snippet render function
        'asbool',               # converts an object to a boolean
        'asint',                # converts an object to an integer
        'aslist',               # converts an object to a list
        'literal',              # stop tags in a string being escaped
        'get_action',           # get logic action function
        'get_converter',        # get validator function
        'get_validator',        # get convertor action function
        'check_access',         # check logic function authorisation
        'navl_validate',        # implements validate method with navl schema
        'ObjectNotFound',       # action not found exception
                                # (ckan.logic.NotFound)
        'NotAuthorized',        # action not authorized exception
        'UnknownConverter',     # convertor not found exception
        'UnknownValidator',     # validator not found exception
        'ValidationError',      # model update validation error
        'Invalid',              # validation invalid exception
        'CkanCommand',          # class for providing cli interfaces
        'DefaultDatasetForm',   # base class for IDatasetForm plugins
        'response',             # response object for cookies etc
        'BaseController',       # Allow controllers to be created
        'abort',                # abort actions
        'redirect_to',          # allow redirections
        'url_for',              # create urls
        'get_or_bust',          # helpful for actions
        'side_effect_free',     # actions can be accessed via api
        'auth_sysadmins_check', # allow auth functions to be checked for sysadmins
        'auth_allow_anonymous_access', # allow anonymous access to an auth function
        'auth_disallow_anonymous_access', # disallow anonymous access to an auth function

        ## Fully defined in this file ##
        'add_template_directory',
        'add_resource',
        'add_public_directory',
        'requires_ckan_version',
        'check_ckan_version',
        'CkanVersionException',
    ]

    def __init__(self):
        self._toolkit = {}

        # For some members in the the toolkit (e.g. that are exported from
        # third-party libraries) we override their docstrings by putting our
        # own docstrings into this dict. The Sphinx plugin that documents this
        # plugins toolkit will use these docstring overrides instead of the
        # object's actual docstring, when present.
        self.docstring_overrides = {}

    def _initialize(self):
        ''' get the required functions/objects, store them for later
        access and check that they match the contents dict. '''

        import ckan
        import ckan.lib.base as base
        import ckan.logic as logic
        import ckan.logic.validators as logic_validators
        import ckan.lib.navl.dictization_functions as dictization_functions
        import ckan.lib.helpers as h
        import ckan.lib.cli as cli
        import ckan.lib.plugins as lib_plugins
        import ckan.common as common
        import pylons

        # Allow class access to these modules
        self.__class__.ckan = ckan
        self.__class__.base = base

        t = self._toolkit

        # imported functions
        t['_'] = common._
        self.docstring_overrides['_'] = '''The Pylons ``_()`` function.

The Pylons ``_()`` function is a reference to the ``ugettext()`` function.
Everywhere in your code where you want strings to be internationalized
(made available for translation into different languages), wrap them in the
``_()`` function, eg.::

    msg = toolkit._("Hello")

'''
        t['c'] = common.c
        self.docstring_overrides['c'] = '''The Pylons template context object.

This object is used to pass request-specific information to different parts of
the code in a thread-safe way (so that variables from different requests being
executed at the same time don't get confused with each other).

Any attributes assigned to :py:attr:`~ckan.plugins.toolkit.c` are
available throughout the template and application code, and are local to the
current request.

'''
        t['request'] = common.request
        self.docstring_overrides['request'] = '''The Pylons request object.

A new request object is created for each HTTP request. It has methods and
attributes for getting things like the request headers, query-string variables,
request body variables, cookies, the request URL, etc.

'''
        t['render'] = base.render
        t['render_text'] = base.render_text
        t['asbool'] = converters.asbool
        self.docstring_overrides['asbool'] = '''Convert a string from the
config file into a boolean.

For example: ``if toolkit.asbool(config.get('ckan.legacy_templates', False)):``

'''
        t['asint'] = converters.asint
        self.docstring_overrides['asint'] = '''Convert a string from the config
file into an int.

For example: ``bar = toolkit.asint(config.get('ckan.foo.bar', 0))``

'''
        t['aslist'] = converters.aslist
        self.docstring_overrides['aslist'] = '''Convert a string from the
config file into a list.

For example: ``bar = toolkit.aslist(config.get('ckan.foo.bar', []))``

'''
        t['literal'] = webhelpers.html.tags.literal

        t['get_action'] = logic.get_action
        t['get_converter'] = logic.get_converter
        t['get_validator'] = logic.get_validator
        t['check_access'] = logic.check_access
        t['navl_validate'] = dictization_functions.validate
        t['ObjectNotFound'] = logic.NotFound  # Name change intentional
        t['NotAuthorized'] = logic.NotAuthorized
        t['ValidationError'] = logic.ValidationError
        t['UnknownConverter'] = logic.UnknownConverter
        t['UnknownValidator'] = logic.UnknownValidator
        t['Invalid'] = logic_validators.Invalid

        t['CkanCommand'] = cli.CkanCommand
        t['DefaultDatasetForm'] = lib_plugins.DefaultDatasetForm

        t['response'] = pylons.response
        self.docstring_overrides['response'] = '''The Pylons response object.

Pylons uses this object to generate the HTTP response it returns to the web
browser. It has attributes like the HTTP status code, the response headers,
content type, cookies, etc.

'''
        t['BaseController'] = base.BaseController
        t['abort'] = base.abort
        t['redirect_to'] = h.redirect_to
        t['url_for'] = h.url_for
        t['get_or_bust'] = logic.get_or_bust
        t['side_effect_free'] = logic.side_effect_free
        t['auth_sysadmins_check'] = logic.auth_sysadmins_check
        t['auth_allow_anonymous_access'] = logic.auth_allow_anonymous_access
        t['auth_disallow_anonymous_access'] = logic.auth_disallow_anonymous_access

        # class functions
        t['render_snippet'] = self._render_snippet
        t['add_template_directory'] = self._add_template_directory
        t['add_public_directory'] = self._add_public_directory
        t['add_resource'] = self._add_resource
        t['requires_ckan_version'] = self._requires_ckan_version
        t['check_ckan_version'] = self._check_ckan_version
        t['CkanVersionException'] = CkanVersionException

        # check contents list correct
        errors = set(t).symmetric_difference(set(self.contents))
        if errors:
            raise Exception('Plugin toolkit error %s not matching' % errors)

    # wrappers
    # Wrapper for the render_snippet function as it uses keywords rather than
    # dict to pass data.
    @classmethod
    def _render_snippet(cls, template, data=None):
        '''Render a template snippet and return the output.

        See :doc:`/theming/index`.

        '''
        data = data or {}
        return cls.base.render_snippet(template, **data)

    # new functions
    @classmethod
    def _add_template_directory(cls, config, relative_path):
        '''Add a path to the :ref:`extra_template_paths` config setting.

        The path is relative to the file calling this function.

        '''
        cls._add_served_directory(config, relative_path,
                                  'extra_template_paths')

    @classmethod
    def _add_public_directory(cls, config, relative_path):
        '''Add a path to the :ref:`extra_public_paths` config setting.

        The path is relative to the file calling this function.

        '''
        cls._add_served_directory(config, relative_path, 'extra_public_paths')

    @classmethod
    def _add_served_directory(cls, config, relative_path, config_var):
        ''' Add extra public/template directories to config. '''
        assert config_var in ('extra_template_paths', 'extra_public_paths')
        # we want the filename that of the function caller but they will
        # have used one of the available helper functions
        frame, filename, line_number, function_name, lines, index =\
            inspect.getouterframes(inspect.currentframe())[2]

        this_dir = os.path.dirname(filename)
        absolute_path = os.path.join(this_dir, relative_path)
        if absolute_path not in config.get(config_var, ''):
            if config.get(config_var):
                config[config_var] += ',' + absolute_path
            else:
                config[config_var] = absolute_path

    @classmethod
    def _add_resource(cls, path, name):
        '''Add a Fanstatic resource library to CKAN.

        Fanstatic libraries are directories containing static resource files
        (e.g. CSS, JavaScript or image files) that can be accessed from CKAN.

        See :doc:`/theming/index` for more details.

        '''
        # we want the filename that of the function caller but they will
        # have used one of the available helper functions
        frame, filename, line_number, function_name, lines, index =\
            inspect.getouterframes(inspect.currentframe())[1]

        this_dir = os.path.dirname(filename)
        absolute_path = os.path.join(this_dir, path)
        import ckan.lib.fanstatic_resources
        ckan.lib.fanstatic_resources.create_library(name, absolute_path)

    @classmethod
    def _version_str_2_list(cls, v_str):
        ''' convert a version string into a list of ints
        eg 1.6.1b --> [1, 6, 1] '''
        v_str = re.sub(r'[^0-9.]', '', v_str)
        return [int(part) for part in v_str.split('.')]

    @classmethod
    def _check_ckan_version(cls, min_version=None, max_version=None):
        '''Return ``True`` if the CKAN version is greater than or equal to
        ``min_version`` and less than or equal to ``max_version``,
        return ``False`` otherwise.

        If no ``min_version`` is given, just check whether the CKAN version is
        less than or equal to ``max_version``.

        If no ``max_version`` is given, just check whether the CKAN version is
        greater than or equal to ``min_version``.

        :param min_version: the minimum acceptable CKAN version,
            eg. ``'2.1'``
        :type min_version: string

        :param max_version: the maximum acceptable CKAN version,
            eg. ``'2.3'``
        :type max_version: string

        '''
        current = cls._version_str_2_list(cls.ckan.__version__)

        if min_version:
            min_required = cls._version_str_2_list(min_version)
            if current < min_required:
                return False
        if max_version:
            max_required = cls._version_str_2_list(max_version)
            if current > max_required:
                return False
        return True

    @classmethod
    def _requires_ckan_version(cls, min_version, max_version=None):
        '''Raise :py:exc:`~ckan.plugins.toolkit.CkanVersionException` if the
        CKAN version is not greater than or equal to ``min_version`` and
        less then or equal to ``max_version``.

        If no ``max_version`` is given, just check whether the CKAN version is
        greater than or equal to ``min_version``.

        Plugins can call this function if they require a certain CKAN version,
        other versions of CKAN will crash if a user tries to use the plugin
        with them.

        :param min_version: the minimum acceptable CKAN version,
            eg. ``'2.1'``
        :type min_version: string

        :param max_version: the maximum acceptable CKAN version,
            eg. ``'2.3'``
        :type max_version: string

        '''
        if not cls._check_ckan_version(min_version=min_version,
                                       max_version=max_version):
            if not max_version:
                error = 'Requires ckan version %s or higher' % min_version
            else:
                error = 'Requires ckan version between %s and %s' % \
                            (min_version, max_version)
            raise CkanVersionException(error)

    def __getattr__(self, name):
        ''' return the function/object requested '''
        if not self._toolkit:
            self._initialize()
        if name in self._toolkit:
            return self._toolkit[name]
        else:
            if name == '__bases__':
                return self.__class__.__bases__
            raise Exception('`%s` not found in plugins toolkit' % name)

    def __dir__(self):
        if not self._toolkit:
            self._initialize()
        return sorted(self._toolkit.keys())


toolkit = _Toolkit()
del _Toolkit

########NEW FILE########
__FILENAME__ = toolkit_sphinx_extension
'''A Sphinx extension to automatically document CKAN's crazy plugins toolkit,
autodoc-style.

Sphinx's autodoc extension can document modules or classes, but although it
masquerades as a module CKAN's plugins toolkit is actually neither a module nor
a class, it's an object-instance of a class, and it's an object with weird
__getattr__ behavior too. Autodoc can't handle it, so we have this custom
Sphinx extension to automate documenting it instead.

This extension plugs into the reading phase of the Sphinx build. It intercepts
the 'toolkit' document (extensions/plugins-toolkit.rst) after Sphinx has read
the reStructuredText source from file. It modifies the source, adding in Sphinx
directives for everything in the plugins toolkit, and then the Sphinx build
continues as normal (just as if the generated reStructuredText had been entered
into plugins-toolkit.rst manually before running Sphinx).

'''
import types
import inspect

import ckan.plugins.toolkit as toolkit


def setup(app):
    '''Setup this Sphinx extension. Called once when initializing Sphinx.

    '''
    # Connect to Sphinx's source-read event, the callback function will be
    # called after each source file is read.
    app.connect('source-read', source_read)


def format_function(name, function, docstring=None):
    '''Return a Sphinx .. function:: directive for the given function.

    The directive includes the function's docstring if it has one.

    :param name: the name to give to the function in the directive,
        eg. 'get_converter'
    :type name: string

    :param function: the function itself
    :type function: function

    :param docstring: if given, use this instead of introspecting the function
        to find its actual docstring
    :type docstring: string

    :returns: a Sphinx .. function:: directive for the function
    :rtype: string

    '''
    # The template we'll use to render the Sphinx function directive.
    template = ('.. py:function:: ckan.plugins.toolkit.{function}{args}\n'
                '\n'
                '{docstring}\n'
                '\n')

    # Get the arguments of the function, as a string like:
    # "(foo, bar=None, ...)"
    argstring = inspect.formatargspec(*inspect.getargspec(function))

    docstring = docstring or inspect.getdoc(function)
    if docstring is None:
        docstring = ''
    else:
        # Indent the docstring by 3 spaces, as needed for the Sphinx directive.
        docstring = '\n'.join(['   ' + line for line in docstring.split('\n')])

    return template.format(function=name, args=argstring, docstring=docstring)


def format_class(name, class_, docstring=None):
    '''Return a Sphinx .. class:: directive for the given class.

    The directive includes the class's docstring if it has one.

    :param name: the name to give to the class in the directive,
        eg. 'DefaultDatasetForm'
    :type name: string

    :param class_: the class itself
    :type class_: class

    :param docstring: if given, use this instead of introspecting the class
        to find its actual docstring
    :type docstring: string

    :returns: a Sphinx .. class:: directive for the class
    :rtype: string

    '''
    # The template we'll use to render the Sphinx class directive.
    template = ('.. py:class:: ckan.plugins.toolkit.{cls}\n'
                '\n'
                '{docstring}\n'
                '\n')

    docstring = docstring or inspect.getdoc(class_)
    if docstring is None:
        docstring = ''
    else:
        # Indent the docstring by 3 spaces, as needed for the Sphinx directive.
        docstring = '\n'.join(['   ' + line for line in docstring.split('\n')])

    return template.format(cls=name, docstring=docstring)


def format_object(name, object_, docstring=None):
    '''Return a Sphinx .. attribute:: directive for the given object.

    The directive includes the object's class's docstring if it has one.

    :param name: the name to give to the object in the directive,
        eg. 'request'
    :type name: string

    :param object_: the object itself
    :type object_: object

    :param docstring: if given, use this instead of introspecting the object
        to find its actual docstring
    :type docstring: string

    :returns: a Sphinx .. attribute:: directive for the object
    :rtype: string

    '''
    # The template we'll use to render the Sphinx attribute directive.
    template = ('.. py:attribute:: ckan.plugins.toolkit.{obj}\n'
                '\n'
                '{docstring}\n'
                '\n')

    docstring = docstring or inspect.getdoc(object_)
    if docstring is None:
        docstring = ''
    else:
        # Indent the docstring by 3 spaces, as needed for the Sphinx directive.
        docstring = '\n'.join(['   ' + line for line in docstring.split('\n')])

    return template.format(obj=name, docstring=docstring)


def source_read(app, docname, source):
    '''Transform the contents of plugins-toolkit.rst to contain reference docs.

    '''
    # We're only interested in the 'plugins-toolkit' doc (plugins-toolkit.rst).
    if docname != 'extensions/plugins-toolkit':
        return

    source_ = ''
    for name, thing in inspect.getmembers(toolkit):

        # The plugins toolkit can override the docstrings of some of its
        # members (e.g. things that are imported from third-party libraries)
        # by putting custom docstrings in this docstring_overrides dict.
        custom_docstring = toolkit.docstring_overrides.get(name)

        if inspect.isfunction(thing):
            source_ += format_function(name, thing, docstring=custom_docstring)
        elif inspect.ismethod(thing):
            # We document plugins toolkit methods as if they're functions. This
            # is correct because the class ckan.plugins.toolkit._Toolkit
            # actually masquerades as a module ckan.plugins.toolkit, and you
            # call its methods as if they were functions.
            source_ += format_function(name, thing, docstring=custom_docstring)
        elif inspect.isclass(thing):
            source_ += format_class(name, thing, docstring=custom_docstring)
        elif isinstance(thing, types.ObjectType):
            source_ += format_object(name, thing, docstring=custom_docstring)

        else:
            assert False, ("Someone added {name}:{thing} to the plugins "
                           "toolkit and this Sphinx extension doesn't know "
                           "how to document that yet. If you're that someone, "
                           "you need to add a new format_*() function for it "
                           "here or the docs won't build.".format(
                               name=name, thing=thing))

    source[0] += source_

    # This is useful for debugging the generated RST.
    #open('/tmp/source', 'w').write(source[0])

########NEW FILE########
__FILENAME__ = rating
import ckan.model as model

MIN_RATING = 1.0
MAX_RATING = 5.0

class RatingValueException(Exception):
    pass

def get_rating(package):
    return package.get_average_rating(), len(package.ratings)

def set_my_rating(c, package, rating):
    if c.user:
        username = c.user
        user_or_ip = model.User.by_name(username)
        q = model.Session.query(model.Rating).filter_by(package=package, user=user_or_ip)
    else:
        user_or_ip = c.author
        q = model.Session.query(model.Rating).filter_by(package=package, user_ip_address=user_or_ip)
    set_rating(user_or_ip, package, rating)

def set_rating(user_or_ip, package, rating):
    # Rates a package.
    # Caller function does need to create a new_revision,
    # but the commit happens in this one. (TODO leave caller to commit.)
    user = None
    if isinstance(user_or_ip, model.User):
        user = user_or_ip
        rating_query = model.Session.query(model.Rating).filter_by(package=package, user=user)
    else:
        ip = user_or_ip
        rating_query = model.Session.query(model.Rating).filter_by(package=package, user_ip_address=ip)

    try:
        rating = float(rating)
    except TypeError, ValueError:
        raise RatingValueException
    if rating > MAX_RATING or rating < MIN_RATING:
        raise RatingValueException
    
    if rating_query.count():
        rating_obj = rating_query.first()
        rating_obj.rating = rating
    elif user:
        rating = model.Rating(package=package,
                              user=user,
                              rating=rating)
        model.Session.add(rating)
    else:
        rating = model.Rating(package=package,
                              user_ip_address=ip,
                              rating=rating)
        model.Session.add(rating)
    model.repo.commit_and_remove()
    

########NEW FILE########
__FILENAME__ = ckantestplugins
from collections import defaultdict

import ckan.plugins as p
import ckan.tests.mock_plugin as mock_plugin


class MapperPlugin(p.SingletonPlugin):
    p.implements(p.IMapper, inherit=True)

    def __init__(self, *args, **kw):
        self.added = []
        self.deleted = []

    def before_insert(self, mapper, conn, instance):
        self.added.append(instance)

    def before_delete(self, mapper, conn, instance):
        self.deleted.append(instance)

class MapperPlugin2(MapperPlugin):
    p.implements(p.IMapper)

class SessionPlugin(p.SingletonPlugin):
    p.implements(p.ISession, inherit=True)

    def __init__(self, *args, **kw):
        self.added = []
        self.deleted = []

    def before_insert(self, mapper, conn, instance):
        self.added.append(instance)

    def before_delete(self, mapper, conn, instance):
        self.deleted.append(instance)

class RoutesPlugin(p.SingletonPlugin):
    p.implements(p.IRoutes, inherit=True)

    def __init__(self, *args, **kw):
        self.calls_made = []

    def before_map(self, map):
        self.calls_made.append('before_map')
        return map

    def after_map(self, map):
        self.calls_made.append('after_map')
        return map


class PluginObserverPlugin(mock_plugin.MockSingletonPlugin):
    p.implements(p.IPluginObserver)

class ActionPlugin(p.SingletonPlugin):
    p.implements(p.IActions)

    def get_actions(self):
        return {'status_show': lambda context, data_dict: {}}

class AuthPlugin(p.SingletonPlugin):
    p.implements(p.IAuthFunctions)

    def get_auth_functions(self):
        return {'package_list': lambda context, data_dict: {}}

class MockGroupControllerPlugin(p.SingletonPlugin):
    p.implements(p.IGroupController)

    def __init__(self, *args, **kw):
        self.calls = defaultdict(int)

    def read(self, entity):
        self.calls['read'] += 1

    def create(self, entity):
        self.calls['create'] += 1

    def edit(self, entity):
        self.calls['edit'] += 1

    def authz_add_role(self, object_role):
        self.calls['authz_add_role'] += 1

    def authz_remove_role(self, object_role):
        self.calls['authz_remove_role'] += 1

    def delete(self, entity):
        self.calls['delete'] += 1

    def before_view(self, data_dict):
        self.calls['before_view'] += 1
        return data_dict


class MockPackageControllerPlugin(p.SingletonPlugin):
    p.implements(p.IPackageController)

    def __init__(self, *args, **kw):
        self.calls = defaultdict(int)

    def read(self, entity):
        self.calls['read'] += 1

    def create(self, entity):
        self.calls['create'] += 1

    def edit(self, entity):
        self.calls['edit'] += 1

    def authz_add_role(self, object_role):
        self.calls['authz_add_role'] += 1

    def authz_remove_role(self, object_role):
        self.calls['authz_remove_role'] += 1

    def delete(self, entity):
        self.calls['delete'] += 1

    def before_search(self, search_params):
        self.calls['before_search'] += 1
        return search_params

    def after_search(self, search_results, search_params):
        self.calls['after_search'] += 1
        return search_results

    def before_index(self, data_dict):
        self.calls['before_index'] += 1
        return data_dict

    def before_view(self, data_dict):
        self.calls['before_view'] += 1
        return data_dict

    def after_create(self, context, data_dict):
        self.calls['after_create'] += 1
        self.id_in_dict = 'id' in data_dict

        return data_dict

    def after_update(self, context, data_dict):
        self.calls['after_update'] += 1
        return data_dict

    def after_delete(self, context, data_dict):
        self.calls['after_delete'] += 1
        return data_dict

    def after_show(self, context, data_dict):
        self.calls['after_show'] += 1
        return data_dict

    def update_facet_titles(self, facet_titles):
        return facet_titles



class MockResourcePreviewExtension(mock_plugin.MockSingletonPlugin):
    p.implements(p.IResourcePreview)

    def __init__(self, *args, **kw):
        self.calls = defaultdict(int)

    def setup_template_variables(self, context, data_dict):
        self.calls['setup_template_variables'] += 1

    def can_preview(self, data_dict):
        assert(isinstance(data_dict['resource'], dict))
        assert(isinstance(data_dict['package'], dict))
        assert('on_same_domain' in data_dict['resource'])

        self.calls['can_preview'] += 1
        return data_dict['resource']['format'].lower() == 'mock'

    def preview_template(self, context, data_dict):
        assert(isinstance(data_dict['resource'], dict))
        assert(isinstance(data_dict['package'], dict))

        self.calls['preview_templates'] += 1
        return 'tests/mock_resource_preview_template.html'


class JsonMockResourcePreviewExtension(mock_plugin.MockSingletonPlugin):
    p.implements(p.IResourcePreview)

    def __init__(self, *args, **kw):
        self.calls = defaultdict(int)

    def setup_template_variables(self, context, data_dict):
        self.calls['setup_template_variables'] += 1

    def can_preview(self, data_dict):
        self.calls['can_preview'] += 1
        return data_dict['resource']['format'].lower() == 'json'

    def preview_template(self, context, data_dict):
        self.calls['preview_templates'] += 1
        return 'tests/mock_json_resource_preview_template.html'


# importing this file loads all these extensions by default
# so clean up the extensions
p.plugins_update()

########NEW FILE########
__FILENAME__ = base
import re
try:
    from cStringIO import StringIO
except ImportError:
    from StringIO import StringIO

import urllib

from pylons import config
import webhelpers.util
from nose.tools import assert_equal
from paste.fixture import TestRequest
from webhelpers.html import url_escape

from ckan.tests import *
import ckan.model as model
from ckan.lib.create_test_data import CreateTestData
from ckan.tests import TestController as ControllerTestCase
from ckan.common import json

ACCESS_DENIED = [403]

class ApiTestCase(object):

    STATUS_200_OK = 200
    STATUS_201_CREATED = 201
    STATUS_400_BAD_REQUEST = 400
    STATUS_403_ACCESS_DENIED = 403
    STATUS_404_NOT_FOUND = 404
    STATUS_409_CONFLICT = 409

    send_authorization_header = True
    extra_environ = {}

    api_version = None

    ref_package_by = ''
    ref_group_by = ''

    def get(self, offset, status=[200]):
        response = self.app.get(offset, status=status,
            extra_environ=self.get_extra_environ())
        return response

    def post(self, offset, data, status=[200,201], *args, **kwds):
        params = '%s=1' % url_escape(self.dumps(data))
        if 'extra_environ' in kwds:
            self.extra_environ = kwds['extra_environ']
        response = self.app.post(offset, params=params, status=status,
            extra_environ=self.get_extra_environ())
        return response

    def app_delete(self, offset, status=[200,201], *args, **kwds):
        response = self.app.delete(offset, status=status,
            extra_environ=self.get_extra_environ())
        return response

    def get_extra_environ(self):
        extra_environ = {}
        for (key,value) in self.extra_environ.items():
            if key == 'Authorization':
                if self.send_authorization_header == True:
                    extra_environ[key] = value
            else:
                extra_environ[key] = value
        return extra_environ

    @classmethod
    def offset(self, path):
        """
        Returns the full path to the resource identified in path.

        Performs necessary url-encodings, ie:

         - encodes unicode to utf8
         - urlencodes the resulting byte array

        This process is described in [1], and has also been confirmed by
        inspecting what a browser does.

        [1] http://www.w3.org/International/articles/idn-and-iri/
        """
        assert self.api_version != None, "API version is missing."
        base = '/api'
        if self.api_version:
            base += '/%s' % self.api_version
        utf8_encoded = (u'%s%s' % (base, path)).encode('utf8')
        url_encoded = urllib.quote(utf8_encoded)
        return url_encoded

    def assert_msg_represents_anna(self, msg):
        assert 'annakarenina' in msg, msg
        data = self.loads(msg)
        self.assert_equal(data['name'], 'annakarenina')
        self.assert_equal(data['license_id'], 'other-open')
        assert '"license_id": "other-open"' in msg, str(msg)
        assert 'russian' in msg, msg
        assert 'tolstoy' in msg, msg
        assert '"extras": {' in msg, msg
        assert '"genre": "romantic novel"' in msg, msg
        assert '"original media": "book"' in msg, msg
        assert 'annakarenina.com/download' in msg, msg
        assert '"plain text"' in msg, msg
        assert '"Index of the novel"' in msg, msg
        assert '"id": "%s"' % self.anna.id in msg, msg
        expected = '"groups": ['
        assert expected in msg, (expected, msg)
        expected = self.group_ref_from_name('roger')
        assert expected in msg, (expected, msg)
        expected = self.group_ref_from_name('david')
        assert expected in msg, (expected, msg)

        # Todo: What is the deal with ckan_url? And should this use IDs rather than names?
        assert 'ckan_url' in msg
        assert '"ckan_url": "http://test.ckan.net/dataset/annakarenina"' in msg, msg

        assert 'tags' in data, "Expected a tags list in json payload"
        assert self.russian.name in data['tags'], data['tags']
        assert self.tolstoy.name in data['tags'], data['tags']
        assert self.flexible_tag.name in data['tags'], data['tags']

    def assert_msg_represents_roger(self, msg):
        assert 'roger' in msg, msg
        data = self.loads(msg)
        keys = set(data.keys())
        expected_keys = set(['id', 'name', 'title', 'description', 'created',
                            'state', 'revision_id', 'packages'])
        missing_keys = expected_keys - keys
        assert not missing_keys, missing_keys
        assert_equal(data['name'], 'roger')
        assert_equal(data['title'], 'Roger\'s books')
        assert_equal(data['description'], 'Roger likes these books.')
        assert_equal(data['state'], 'active')
        assert_equal(data['packages'], [self._ref_package(self.anna)])

    def assert_msg_represents_russian(self, msg):
        data = self.loads(msg)
        pkgs = set(data)
        expected_pkgs = set([self.package_ref_from_name('annakarenina'),
                             self.package_ref_from_name('warandpeace')])
        differences = expected_pkgs ^ pkgs
        assert not differences, '%r != %r' % (pkgs, expected_pkgs)

    def assert_msg_represents_flexible_tag(self, msg):
        """
        Asserts the correct packages are associated with the flexible tag.

        Namely, 'annakarenina' and 'warandpeace'.
        """
        data = self.loads(msg)
        pkgs = set(data)
        expected_pkgs = set([self.package_ref_from_name('annakarenina'),
                             self.package_ref_from_name('warandpeace')])
        differences = expected_pkgs ^ pkgs
        assert not differences, '%r != %r' % (pkgs, expected_pkgs)

    def data_from_res(self, res):
        return self.loads(res.body)

    def package_ref_from_name(self, package_name):
        package = self.get_package_by_name(unicode(package_name))
        if package is None:
            return package_name
        else:
            return self.ref_package(package)

    def package_id_from_ref(self, package_name):
        package = self.get_package_by_name(unicode(package_name))
        if package is None:
            return package_name
        else:
            return self.ref_package(package)

    def ref_package(self, package):
        assert self.ref_package_by in ['id', 'name']
        return getattr(package, self.ref_package_by)

    def get_expected_api_version(self):
        return self.api_version

    def dumps(self, data):
        return json.dumps(data)

    def loads(self, chars):
        try:
            return json.loads(chars)
        except ValueError, inst:
            raise Exception, "Couldn't loads string '%s': %s" % (chars, inst)

    def assert_json_response(self, res, expected_in_body=None):
        content_type = res.header_dict['Content-Type']
        assert 'application/json' in content_type, content_type
        res_json = self.loads(res.body)
        if expected_in_body:
            assert expected_in_body in res_json or \
                   expected_in_body in str(res_json), \
                   'Expected to find %r in JSON response %r' % \
                   (expected_in_body, res_json)

class Api1and2TestCase(object):
    ''' Utils for v1 and v2 API.
          * RESTful URL utils
    '''
    def package_offset(self, package_name=None):
        if package_name is None:
            # Package Register
            return self.offset('/rest/dataset')
        else:
            # Package Entity
            package_ref = self.package_ref_from_name(package_name)
            return self.offset('/rest/dataset/%s' % package_ref)

    def group_offset(self, group_name=None):
        if group_name is None:
            # Group Register
            return self.offset('/rest/group')
        else:
            # Group Entity
            group_ref = self.group_ref_from_name(group_name)
            return self.offset('/rest/group/%s' % group_ref)

    def group_ref_from_name(self, group_name):
        group = self.get_group_by_name(unicode(group_name))
        if group is None:
            return group_name
        else:
            return self.ref_group(group)

    def ref_group(self, group):
        assert self.ref_group_by in ['id', 'name']
        return getattr(group, self.ref_group_by)

    def revision_offset(self, revision_id=None):
        if revision_id is None:
            # Revision Register
            return self.offset('/rest/revision')
        else:
            # Revision Entity
            return self.offset('/rest/revision/%s' % revision_id)

    def rating_offset(self, package_name=None):
        if package_name is None:
            # Revision Register
            return self.offset('/rest/rating')
        else:
            # Revision Entity
            package_ref = self.package_ref_from_name(package_name)
            return self.offset('/rest/rating/%s' % package_ref)

    def anna_offset(self, postfix=''):
        return self.package_offset('annakarenina') + postfix

    def tag_offset(self, tag_name=None):
        if tag_name is None:
            # Tag Register
            return self.offset('/rest/tag')
        else:
            # Tag Entity
            tag_ref = self.tag_ref_from_name(tag_name)
            return self.offset('/rest/tag/%s' % tag_ref)

    def tag_ref_from_name(self, tag_name):
        tag = self.get_tag_by_name(unicode(tag_name))
        if tag is None:
            return tag_name
        else:
            return self.ref_tag(tag)

    def ref_tag(self, tag):
        assert self.ref_tag_by in ['id', 'name']
        return getattr(tag, self.ref_tag_by)

    @classmethod
    def _ref_package(cls, package):
        assert cls.ref_package_by in ['id', 'name']
        return getattr(package, cls.ref_package_by)

    @classmethod
    def _ref_group(cls, group):
        assert cls.ref_group_by in ['id', 'name']
        return getattr(group, cls.ref_group_by)


class Api1TestCase(Api1and2TestCase):

    api_version = 1
    ref_package_by = 'name'
    ref_group_by = 'name'
    ref_tag_by = 'name'

    def assert_msg_represents_anna(self, msg):
        super(Api1TestCase, self).assert_msg_represents_anna(msg)
        assert '"download_url": "http://www.annakarenina.com/download/x=1&y=2"' in msg, msg


class Api2TestCase(Api1and2TestCase):

    api_version = 2
    ref_package_by = 'id'
    ref_group_by = 'id'
    ref_tag_by = 'id'

    def assert_msg_represents_anna(self, msg):
        super(Api2TestCase, self).assert_msg_represents_anna(msg)
        assert 'download_url' not in msg, msg


class Api3TestCase(ApiTestCase):

    api_version = 3
    ref_package_by = 'name'
    ref_group_by = 'name'
    ref_tag_by = 'name'

    def assert_msg_represents_anna(self, msg):
        super(Api2TestCase, self).assert_msg_represents_anna(msg)
        assert 'download_url' not in msg, msg


class BaseModelApiTestCase(ApiTestCase, ControllerTestCase):

    testpackage_license_id = u'gpl-3.0'
    package_fixture_data = {
        'name' : u'testpkg',
        'title': u'Some Title',
        'url': u'http://blahblahblah.mydomain',
        'resources': [{
            u'url':u'http://blah.com/file.xml',
            u'format':u'XML',
            u'description':u'Main file',
            u'hash':u'abc123',
            u'alt_url':u'alt_url',
            u'size_extra':u'200',
        }, {
            u'url':u'http://blah.com/file2.xml',
            u'format':u'XML',
            u'description':u'Second file',
            u'hash':u'def123',
            u'alt_url':u'alt_url',
            u'size_extra':u'200',
        }],
        'tags': [u'russion', u'novel'],
        'license_id': testpackage_license_id,
        'extras': {
            'genre' : u'horror',
            'media' : u'dvd',
        },
    }
    testgroupvalues = {
        'name' : u'testgroup',
        'title' : u'Some Group Title',
        'description' : u'Great group!',
        'packages' : [u'annakarenina', u'warandpeace'],
    }
    user_name = u'http://myrandom.openidservice.org/'

    def setup(self):
        super(BaseModelApiTestCase, self).setup()
#        self.conditional_create_common_fixtures()
#        self.init_extra_environ()

    def teardown(self):
        model.Session.remove()
#        model.repo.rebuild_db()
        super(BaseModelApiTestCase, self).teardown()

    @classmethod
    def init_extra_environ(cls, user_name):
        # essentially 'logs you in', so the http_request methods
        # called elsewhere in this class are run with the specified
        # user logged in.
        cls.user = model.User.by_name(user_name)
        cls.extra_environ={'Authorization' : str(cls.user.apikey)}
        cls.adminuser = model.User.by_name('testsysadmin')
        cls.admin_extra_environ={'Authorization' : str(cls.adminuser.apikey)}

    def post_json(self, offset, data, status=None, extra_environ=None):
        ''' Posts data in the body in application/json format, used by
        javascript libraries.
        (rather than Paste Fixture\'s default format of
        application/x-www-form-urlencoded)

        '''
        return self.http_request(offset, data, content_type='application/json',
                                 request_method='POST',
                                 content_length=len(data),
                                 status=status, extra_environ=extra_environ)

    def delete_request(self, offset, status=None, extra_environ=None):
        ''' Sends a delete request. Similar to the paste.delete but it
        does not send the content type or content length.
        '''
        return self.http_request(offset, data='', content_type=None,
                                 request_method='DELETE',
                                 content_length=None,
                                 status=status,
                                 extra_environ=extra_environ)

    def http_request(self, offset, data,
                     content_type='application/json',
                     request_method='POST',
                     content_length=None,
                     status=None,
                     extra_environ=None):
        ''' Posts data in the body in a user-specified format.
        (rather than Paste Fixture\'s default Content-Type of
        application/x-www-form-urlencoded)

        '''
        environ = self.app._make_environ()
        if content_type:
            environ['CONTENT_TYPE'] = content_type
        if content_length is not None:
            environ['CONTENT_LENGTH'] = str(content_length)
        environ['REQUEST_METHOD'] = request_method
        environ['QUERY_STRING'] = '' # avoids a warning
        environ['wsgi.input'] = StringIO(data)
        if extra_environ:
            environ.update(extra_environ)
        self.app._set_headers({}, environ)
        req = TestRequest(offset, environ, expect_errors=False)
        return self.app.do_request(req, status=status)

    def set_env(self, extra_environ):
        ''' used to reset env when admin has been forced etc '''
        environ = self.app._make_environ()
        environ.update(extra_environ)

########NEW FILE########
__FILENAME__ = test_group
import copy

from ckan import model
from ckan.lib.create_test_data import CreateTestData

from nose.tools import assert_equal

from ckan.tests.functional.api.base import BaseModelApiTestCase
from ckan.tests.functional.api.base import Api1TestCase as Version1TestCase
from ckan.tests.functional.api.base import Api2TestCase as Version2TestCase


class GroupsTestCase(BaseModelApiTestCase):

    @classmethod
    def setup_class(cls):
        CreateTestData.create()
        cls.user_name = u'russianfan' # created in CreateTestData
        cls.init_extra_environ(cls.user_name)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def teardown(self):
        self.purge_group_by_name(self.testgroupvalues['name'])

    def test_register_get_ok(self):
        offset = self.group_offset()
        res = self.app.get(offset, status=self.STATUS_200_OK)
        assert self.ref_group(self.roger) in res, res
        assert self.ref_group(self.david) in res, res

    def test_register_post_ok(self):
        data = self.testgroupvalues
        postparams = '%s=1' % self.dumps(data)
        offset = self.group_offset()
        res = self.app.post(offset, params=postparams,
                            status=self.STATUS_201_CREATED,
                            extra_environ=self.extra_environ)
        # check group object
        group = self.get_group_by_name(self.testgroupvalues['name'])
        assert group
        assert group.title == self.testgroupvalues['title'], group
        assert group.description == self.testgroupvalues['description'], group
        pkg_ids = [member.table_id for member in group.member_all]
        pkgs = model.Session.query(model.Package).filter(model.Package.id.in_(pkg_ids)).all()
        pkg_names = [pkg.name for pkg in pkgs]

        assert set(pkg_names) == set(('annakarenina', 'warandpeace')), pkg_names

        # check register updated
        res = self.app.get(offset, status=self.STATUS_200_OK)
        data = self.loads(res.body)
        assert isinstance(data, list), data
        assert self._ref_group(group) in data, data

        # check entity
        offset = self.group_offset(self.testgroupvalues['name'])
        res = self.app.get(offset, status=self.STATUS_200_OK)
        group = self.loads(res.body)
        expected_group = copy.deepcopy(self.testgroupvalues)
        expected_group['packages'] = \
               sorted([self.ref_package(self.get_package_by_name(pkg_name)) \
                for pkg_name in expected_group['packages']])
        for expected_key, expected_value in expected_group.items():
            assert_equal(group.get(expected_key), expected_value)

        # Test Group Register Post 409 (conflict - create duplicate group).
        offset = self.group_offset()
        postparams = '%s=1' % self.dumps(self.testgroupvalues)
        res = self.app.post(offset, params=postparams,
                            status=self.STATUS_409_CONFLICT,
                            extra_environ=self.extra_environ)
        self.assert_json_response(res, 'Group name already exists')

    def test_entity_get_ok(self):
        offset = self.group_offset(self.roger.name)
        res = self.app.get(offset, status=self.STATUS_200_OK)

        self.assert_msg_represents_roger(msg=res.body)
        assert self.package_ref_from_name('annakarenina') in res, res
        assert self.group_ref_from_name('roger') in res, res
        assert not self.package_ref_from_name('warandpeace') in res, res

    def test_entity_get_then_post(self):
        # (ticket 662) Ensure an entity you 'get' from a register can be
        # returned by posting it back
        offset = self.group_offset(self.david.name)
        res = self.app.get(offset, status=self.STATUS_200_OK)
        data = self.loads(res.body)
        postparams = '%s=1' % self.dumps(data)
        res = self.app.post(offset, params=postparams,
                            status=self.STATUS_200_OK,
                            extra_environ=self.admin_extra_environ)
        res = self.set_env(self.extra_environ)

    def test_05_get_group_entity_not_found(self):
        offset = self.offset('/rest/group/22222')
        res = self.app.get(offset, status=404)
        self.assert_json_response(res, 'Not found')

    def test_10_edit_group(self):
        # create a group with testgroupvalues
        group = model.Group.by_name(self.testgroupvalues['name'])
        if not group:
            offset = self.offset('/rest/group')
            postparams = '%s=1' % self.dumps(self.testgroupvalues)
            res = self.app.post(offset, params=postparams, status=[201],
                    extra_environ=self.extra_environ)
            model.Session.remove()
            group = model.Group.by_name(self.testgroupvalues['name'])
        assert group
        assert len(group.member_all) == 3, group.member_all
        user = model.User.by_name(self.user_name)
        model.setup_default_user_roles(group, [user])

        # edit it
        group_vals = {'name':u'somethingnew', 'title':u'newtesttitle',
                      'packages':[u'annakarenina']}
        offset = self.group_offset(self.testgroupvalues['name'])
        postparams = '%s=1' % self.dumps(group_vals)
        res = self.app.post(offset, params=postparams, status=[200],
                            extra_environ=self.extra_environ)
        model.Session.remove()
        group = model.Session.query(model.Group).filter_by(name=group_vals['name']).one()
        package = model.Session.query(model.Package).filter_by(name='annakarenina').one()
        assert group.name == group_vals['name']
        assert group.title == group_vals['title']
        assert len(group.member_all) == 3, group.member_all
        assert len([mem for mem in group.member_all if mem.state == 'active']) == 2, group.member_all
        for mem in group.member_all:
            if mem.state == 'active' and mem.capacity == 'package':
                assert mem.table_id == package.id

    def test_10_edit_group_name_duplicate(self):
        # create a group with testgroupvalues
        if not model.Group.by_name(self.testgroupvalues['name']):
            rev = model.repo.new_revision()
            group = model.Group()
            model.Session.add(group)
            group.name = self.testgroupvalues['name']
            model.Session.commit()

            group = model.Group.by_name(self.testgroupvalues['name'])
            model.setup_default_user_roles(group, [self.user])
            rev = model.repo.new_revision()
            model.repo.commit_and_remove()
        assert model.Group.by_name(self.testgroupvalues['name'])

        # create a group with name 'dupname'
        dupname = u'dupname'
        if not model.Group.by_name(dupname):
            rev = model.repo.new_revision()
            group = model.Group()
            model.Session.add(group)
            group.name = dupname
            model.Session.commit()
        assert model.Group.by_name(dupname)

        # edit first group to have dupname
        group_vals = {'name':dupname}
        offset = self.group_offset(self.testgroupvalues['name'])
        postparams = '%s=1' % self.dumps(group_vals)
        res = self.app.post(offset, params=postparams, status=[409],
                            extra_environ=self.admin_extra_environ)
        self.assert_json_response(res, 'Group name already exists')
        res = self.set_env(self.extra_environ)

    def test_11_delete_group(self):
        # Test Groups Entity Delete 200.

        # create a group with testgroupvalues
        group = model.Group.by_name(self.testgroupvalues['name'])
        if not group:
            rev = model.repo.new_revision()
            group = model.Group()
            model.Session.add(group)
            group.name = self.testgroupvalues['name']
            model.repo.commit_and_remove()

            rev = model.repo.new_revision()
            group = model.Group.by_name(self.testgroupvalues['name'])
            model.setup_default_user_roles(group, [self.user])
            model.repo.commit_and_remove()
        assert group
        user = model.User.by_name(self.user_name)
        model.setup_default_user_roles(group, [user])

        # delete it
        offset = self.group_offset(self.testgroupvalues['name'])
        res = self.app.delete(offset, status=[200],
                extra_environ=self.admin_extra_environ)

        res = self.set_env(self.extra_environ)

        group = model.Group.by_name(self.testgroupvalues['name'])
        assert group
        assert group.state == 'deleted', group.state

        # Anyone can see groups especially sysadmins
        # maybe we want to do something different with
        # deleted groups but that would be a new requirement
        #res = self.app.get(offset, status=[403])
        #self.assert_json_response(res, 'Access denied')
        res = self.app.get(offset, status=[200],
                           extra_environ=self.admin_extra_environ)
        res = self.set_env(self.extra_environ)

    def test_12_get_group_404(self):
        # Test Package Entity Get 404.
        assert not model.Session.query(model.Group).filter_by(name=self.testgroupvalues['name']).count()
        offset = self.group_offset(self.testgroupvalues['name'])
        res = self.app.get(offset, status=404)
        self.assert_json_response(res, 'Not found')

    def test_13_delete_group_404(self):
        # Test Packages Entity Delete 404.
        assert not model.Session.query(model.Group).filter_by(name=self.testgroupvalues['name']).count()
        offset = self.group_offset(self.testgroupvalues['name'])
        res = self.app.delete(offset, status=[404],
                              extra_environ=self.extra_environ)
        self.assert_json_response(res, 'not found')


class TestGroupsVersion1(Version1TestCase, GroupsTestCase): pass
class TestGroupsVersion2(Version2TestCase, GroupsTestCase): pass

########NEW FILE########
__FILENAME__ = test_group_and_organization_purge
'''Functional tests for the group_ and organization_purge APIs.

'''
import ckan.model as model
import ckan.tests as tests

import paste
import pylons.test


class TestGroupAndOrganizationPurging(object):
    '''Tests for the group_ and organization_purge APIs.

    '''
    @classmethod
    def setup_class(cls):
        cls.app = paste.fixture.TestApp(pylons.test.pylonsapp)

        # Make a sysadmin user.
        cls.sysadmin = model.User(name='test_sysadmin', sysadmin=True)
        model.Session.add(cls.sysadmin)
        model.Session.commit()
        model.Session.remove()

        # A package that will be added to our test groups and organizations.
        cls.package = tests.call_action_api(cls.app, 'package_create',
                                            name='test_package',
                                            apikey=cls.sysadmin.apikey)

        # A user who will not be a member of our test groups or organizations.
        cls.visitor = tests.call_action_api(cls.app, 'user_create',
                                            name='non_member',
                                            email='blah',
                                            password='farm',
                                            apikey=cls.sysadmin.apikey)

        # A user who will become a member of our test groups and organizations.
        cls.member = tests.call_action_api(cls.app, 'user_create',
                                           name='member',
                                           email='blah',
                                           password='farm',
                                           apikey=cls.sysadmin.apikey)

        # A user who will become an editor of our test groups and
        # organizations.
        cls.editor = tests.call_action_api(cls.app, 'user_create',
                                           name='editor',
                                           email='blah',
                                           password='farm',
                                           apikey=cls.sysadmin.apikey)

        # A user who will become an admin of our test groups and organizations.
        cls.admin = tests.call_action_api(cls.app, 'user_create',
                                          name='admin',
                                          email='blah',
                                          password='farm',
                                          apikey=cls.sysadmin.apikey)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def _organization_create(self, organization_name):
        '''Return an organization with some users and a dataset.'''

        # Make an organization with some users.
        users = [{'name': self.member['name'], 'capacity': 'member'},
                 {'name': self.editor['name'], 'capacity': 'editor'},
                 {'name': self.admin['name'], 'capacity': 'admin'}]
        organization = tests.call_action_api(self.app, 'organization_create',
                                             apikey=self.sysadmin.apikey,
                                             name=organization_name,
                                             users=users)

        # Add a dataset to the organization (have to do this separately
        # because the packages param of organization_create doesn't work).
        tests.call_action_api(self.app, 'package_update',
                              name=self.package['name'],
                              owner_org=organization['name'],
                              apikey=self.sysadmin.apikey)

        return organization

    def _group_create(self, group_name):
        '''Return a group with some users and a dataset.'''

        # Make a group with some users and a dataset.
        group = tests.call_action_api(self.app, 'group_create',
                                      apikey=self.sysadmin.apikey,
                                      name=group_name,
                                      users=[
                                          {'name': self.member['name'],
                                           'capacity': 'member',
                                           },
                                          {'name': self.editor['name'],
                                           'capacity': 'editor',
                                           },
                                          {'name': self.admin['name'],
                                           'capacity': 'admin',
                                           }],
                                      packages=[
                                          {'id': self.package['name']}],
                                      )

        return group

    def _test_group_or_organization_purge(self, name, by_id, is_org):
        '''Create a group or organization with the given name, and test
        purging it.

        :param name: the name of the group or organization to create and purge
        :param by_id: if True, pass the organization's id to
            organization_purge, otherwise pass its name
        :type by_id: boolean
        :param is_org: if True create and purge an organization, if False a
            group
        :type is_org: boolean

        '''
        if is_org:
            group_or_org = self._organization_create(name)
        else:
            group_or_org = self._group_create(name)

        # Purge the group or organization.
        if is_org:
            action = 'organization_purge'
        else:
            action = 'group_purge'
        if by_id:
            identifier = group_or_org['id']
        else:
            identifier = group_or_org['name']
        result = tests.call_action_api(self.app, action, id=identifier,
                                       apikey=self.sysadmin.apikey,
                                       )
        assert result is None

        # Now trying to show the group or organization should give a 404.
        if is_org:
            action = 'organization_show'
        else:
            action = 'group_show'
        result = tests.call_action_api(self.app, action, id=name, status=404)
        assert result == {'__type': 'Not Found Error', 'message': 'Not found'}

        # The group or organization should not appear in group_list or
        # organization_list.
        if is_org:
            action = 'organization_list'
        else:
            action = 'group_list'
        assert name not in tests.call_action_api(self.app, action)

        # The package should no longer belong to the group or organization.
        package = tests.call_action_api(self.app, 'package_show',
                                        id=self.package['name'])
        if is_org:
            assert package['organization'] is None
        else:
            assert group_or_org['name'] not in [group_['name'] for group_
                                                in package['groups']]

        # TODO: Also want to assert that user is not in group or organization
        # anymore, but how to get a user's groups or organizations?

        # It should be possible to create a new group or organization with the
        # same name as the purged one (you would not be able to do this if you
        # had merely deleted the original group or organization).
        if is_org:
            action = 'organization_create'
        else:
            action = 'group_create'
        new_group_or_org = tests.call_action_api(self.app, action, name=name,
                                                 apikey=self.sysadmin.apikey,
                                                 )
        assert new_group_or_org['name'] == name

        # TODO: Should we do a model-level check, to check that the group or
        # org is really purged?

    def test_organization_purge_by_name(self):
        '''A sysadmin should be able to purge an organization by name.'''

        self._test_group_or_organization_purge('organization-to-be-purged',
                                               by_id=False, is_org=True)

    def test_group_purge_by_name(self):
        '''A sysadmin should be able to purge a group by name.'''
        self._test_group_or_organization_purge('group-to-be-purged',
                                               by_id=False, is_org=False)

    def test_organization_purge_by_id(self):
        '''A sysadmin should be able to purge an organization by id.'''
        self._test_group_or_organization_purge('organization-to-be-purged-2',
                                               by_id=True, is_org=True)

    def test_group_purge_by_id(self):
        '''A sysadmin should be able to purge a group by id.'''
        self._test_group_or_organization_purge('group-to-be-purged-2',
                                               by_id=True, is_org=False)

    def _test_group_or_org_purge_with_invalid_id(self, is_org):

        if is_org:
            action = 'organization_purge'
        else:
            action = 'group_purge'

        for name in ('foo', 'invalid name', None, ''):
            # Try to purge an organization, but pass an invalid name.
            result = tests.call_action_api(self.app, action,
                                           apikey=self.sysadmin.apikey,
                                           id=name,
                                           status=404,
                                           )
            if is_org:
                message = 'Not found: Organization was not found'
            else:
                message = 'Not found: Group was not found'
            assert result == {'__type': 'Not Found Error', 'message': message}

    def test_organization_purge_with_invalid_id(self):
        '''
        Trying to purge an organization with an invalid ID should give a 404.

        '''
        self._test_group_or_org_purge_with_invalid_id(is_org=True)

    def test_group_purge_with_invalid_id(self):
        '''Trying to purge a group with an invalid ID should give a 404.'''
        self._test_group_or_org_purge_with_invalid_id(is_org=False)

    def _test_group_or_org_purge_with_missing_id(self, is_org):
        if is_org:
            action = 'organization_purge'
        else:
            action = 'group_purge'
        result = tests.call_action_api(self.app, action,
                                       apikey=self.sysadmin.apikey,
                                       status=409,
                                       )
        assert result == {'__type': 'Validation Error',
                          'id': ['Missing value']}

    def test_organization_purge_with_missing_id(self):
        '''Trying to purge an organization without passing an id should give
        a 409.'''
        self._test_group_or_org_purge_with_missing_id(is_org=True)

    def test_group_purge_with_missing_id(self):
        '''Trying to purge a group without passing an id should give a 409.'''
        self._test_group_or_org_purge_with_missing_id(is_org=False)

    def _test_visitors_cannot_purge_groups_or_orgs(self, is_org):
        if is_org:
            group_or_org = self._organization_create('org-to-be-purged-3')
        else:
            group_or_org = self._group_create('group-to-be-purged-3')

        # Try to purge the group or organization without an API key.
        if is_org:
            action = 'organization_purge'
        else:
            action = 'group_purge'
        result = tests.call_action_api(self.app, action, id=group_or_org['id'],
                                       status=403,
                                       )
        assert result['__type'] == 'Authorization Error'

    def test_visitors_cannot_purge_organizations(self):
        '''Visitors (who aren't logged in) should not be authorized to purge
        organizations.

        '''
        self._test_visitors_cannot_purge_groups_or_orgs(is_org=True)

    def test_visitors_cannot_purge_groups(self):
        '''Visitors (who aren't logged in) should not be authorized to purge
        groups.

        '''
        self._test_visitors_cannot_purge_groups_or_orgs(is_org=False)

    def _test_users_cannot_purge_groups_or_orgs(self, is_org):
        if is_org:
            group_or_org = self._organization_create('org-to-be-purged-4')
        else:
            group_or_org = self._group_create('group-to-be-purged-4')

        # Try to purge the group or organization with a non-member's API key.
        if is_org:
            action = 'organization_purge'
        else:
            action = 'group_purge'
        result = tests.call_action_api(self.app, action, id=group_or_org['id'],
                                       apikey=self.visitor['apikey'],
                                       status=403,
                                       )
        assert result == {'__type': 'Authorization Error',
                          'message': 'Access denied'}

    def test_users_cannot_purge_organizations(self):
        '''Users who are not members of an organization should not be
        authorized to purge the organization.

        '''
        self._test_users_cannot_purge_groups_or_orgs(is_org=True)

    def test_users_cannot_purge_groups(self):
        '''Users who are not members of a group should not be authorized to
        purge the group.

        '''
        self._test_users_cannot_purge_groups_or_orgs(is_org=False)

    def _test_members_cannot_purge_groups_or_orgs(self, is_org):
        if is_org:
            group_or_org = self._organization_create('org-to-be-purged-5')
        else:
            group_or_org = self._group_create('group-to-be-purged-5')

        # Try to purge the organization with an organization member's API key.
        if is_org:
            action = 'organization_purge'
        else:
            action = 'group_purge'
        result = tests.call_action_api(self.app, action, id=group_or_org['id'],
                                       apikey=self.member['apikey'],
                                       status=403,
                                       )
        assert result == {'__type': 'Authorization Error',
                          'message': 'Access denied'}

    def test_members_cannot_purge_organizations(self):
        '''Members of an organization should not be authorized to purge the
        organization.

        '''
        self._test_members_cannot_purge_groups_or_orgs(is_org=True)

    def test_members_cannot_purge_groups(self):
        '''Members of a group should not be authorized to purge the group.

        '''
        self._test_members_cannot_purge_groups_or_orgs(is_org=False)

    def _test_editors_cannot_purge_groups_or_orgs(self, is_org):
        if is_org:
            group_or_org = self._organization_create('org-to-be-purged-6')
        else:
            group_or_org = self._group_create('group-to-be-purged-6')

        # Try to purge the group or organization with an editor's API key.
        if is_org:
            action = 'organization_purge'
        else:
            action = 'group_purge'
        result = tests.call_action_api(self.app, action, id=group_or_org['id'],
                                       apikey=self.editor['apikey'],
                                       status=403,
                                       )
        assert result == {'__type': 'Authorization Error',
                          'message': 'Access denied'}

    def test_editors_cannot_purge_organizations(self):
        '''Editors of an organization should not be authorized to purge the
        organization.

        '''
        self._test_editors_cannot_purge_groups_or_orgs(is_org=True)

    def test_editors_cannot_purge_groups(self):
        '''Editors of a group should not be authorized to purge the group.

        '''
        self._test_editors_cannot_purge_groups_or_orgs(is_org=False)

    def _test_admins_cannot_purge_groups_or_orgs(self, is_org):
        if is_org:
            group_or_org = self._organization_create('org-to-be-purged-7')
        else:
            group_or_org = self._group_create('group-to-be-purged-7')

        # Try to purge the group or organization with an admin's API key.
        if is_org:
            action = 'organization_purge'
        else:
            action = 'group_purge'
        result = tests.call_action_api(self.app, action,
                                       id=group_or_org['id'],
                                       apikey=self.admin['apikey'],
                                       status=403,
                                       )
        assert result == {'__type': 'Authorization Error',
                          'message': 'Access denied'}

    def test_admins_cannot_purge_organizations(self):
        '''Admins of an organization should not be authorized to purge the
        organization.

        '''
        self._test_admins_cannot_purge_groups_or_orgs(is_org=True)

    def test_admins_cannot_purge_groups(self):
        '''Admins of a group should not be authorized to purge the group.

        '''
        self._test_admins_cannot_purge_groups_or_orgs(is_org=False)

########NEW FILE########
__FILENAME__ = test_licenses
from nose.tools import assert_equal 

from ckan import model
from ckan.lib.create_test_data import CreateTestData

from ckan.tests.functional.api.base import BaseModelApiTestCase
from ckan.tests.functional.api.base import Api1TestCase as Version1TestCase 
from ckan.tests.functional.api.base import Api2TestCase as Version2TestCase 

class LicensesTestCase(BaseModelApiTestCase):

    @classmethod
    def setup_class(cls):
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_register_get_ok(self):
        from ckan.model.license import LicenseRegister
        register = LicenseRegister()
        assert len(register), "No changesets found in model."
        offset = self.offset('/rest/licenses')
        res = self.app.get(offset, status=[200])
        licenses_data = self.data_from_res(res)
        assert len(licenses_data) == len(register), (len(licenses_data), len(register))
        for license_data in licenses_data:
            id = license_data['id']
            license = register[id]
            assert license['title'] == license.title
            assert license['url'] == license.url


class TestLicensesVersion1(Version1TestCase, LicensesTestCase): pass
class TestLicensesVersion2(Version2TestCase, LicensesTestCase): pass

########NEW FILE########
__FILENAME__ = test_package
import copy

from nose.tools import assert_equal, assert_raises

from ckan.lib.create_test_data import CreateTestData
import ckan.lib.search as search
from ckan.lib.search.common import SolrSettings

from ckan.tests.functional.api.base import BaseModelApiTestCase
from ckan.tests.functional.api.base import Api1TestCase as Version1TestCase
from ckan.tests.functional.api.base import Api2TestCase as Version2TestCase

import ckan.tests as tests

# Todo: Remove this ckan.model stuff.
import ckan.model as model

class PackagesTestCase(BaseModelApiTestCase):

    @classmethod
    def setup_class(cls):
        CreateTestData.create()
        cls.user_name = u'annafan' # created in CreateTestData
        cls.init_extra_environ(cls.user_name)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def teardown(self):
        self.purge_package_by_name(self.package_fixture_data['name'])

    def get_groups_identifiers(self, test_groups, users=[]):
        groups = []
        for grp in test_groups:
            group = model.Group.get(grp)
            if self.get_expected_api_version() == 1:
                groups.append(group.name)
            else:
                groups.append(group.id)

            if users:
                model.setup_default_user_roles(group, users)
        return groups

    def test_register_get_ok(self):
        offset = self.package_offset()
        res = self.app.get(offset, status=self.STATUS_200_OK)
        assert self.ref_package(self.anna) in res, res
        assert self.ref_package(self.war) in res, res

    def test_register_post_ok(self):
        assert not self.get_package_by_name(self.package_fixture_data['name'])
        offset = self.package_offset()
        postparams = '%s=1' % self.dumps(self.package_fixture_data)
        res = self.app.post(offset, params=postparams,
                            status=self.STATUS_201_CREATED,
                            extra_environ=self.admin_extra_environ)

        # Check the returned package is as expected
        pkg = self.loads(res.body)
        assert_equal(pkg['name'], self.package_fixture_data['name'])
        assert_equal(pkg['title'], self.package_fixture_data['title'])
        assert_equal(set(pkg['tags']), set(self.package_fixture_data['tags']))
        assert_equal(len(pkg['resources']), len(self.package_fixture_data['resources']))
        assert_equal(pkg['extras'], self.package_fixture_data['extras'])

        # Check the value of the Location header.
        location = res.header('Location')

        assert offset in location
        res = self.app.get(location, status=self.STATUS_200_OK)
        # Check the database record.
        model.Session.remove()
        package = self.get_package_by_name(self.package_fixture_data['name'])
        assert package
        self.assert_equal(package.title, self.package_fixture_data['title'])
        self.assert_equal(package.url, self.package_fixture_data['url'])
        self.assert_equal(package.license_id, self.testpackage_license_id)
        self.assert_equal(len(package.get_tags()), 2)
        self.assert_equal(len(package.extras), 2)
        for key, value in self.package_fixture_data['extras'].items():
            self.assert_equal(package.extras[key], value)
        self.assert_equal(len(package.resources), len(self.package_fixture_data['resources']))
        for (i, expected_resource) in enumerate(self.package_fixture_data['resources']):
            package_resource = package.resources[i]
            for key in expected_resource.keys():
                if key == 'extras':
                    package_resource_extras = getattr(package_resource, key)
                    expected_resource_extras = expected_resource[key].items()
                    for expected_extras_key, expected_extras_value in expected_resource_extras:
                        package_resource_value = package_resource_extras[expected_extras_key],\
                         'Package:%r Extras:%r Expected_extras:%r' % \
                         (self.package_fixture_data['name'],
                          package_resource_extras, expected_resource)
                else:
                    package_resource_value = getattr(package_resource, key, None)
                    if not package_resource_value:
                        package_resource_value = package_resource.extras[key]

                    expected_resource_value = expected_resource[key]
                    self.assert_equal(package_resource_value, expected_resource_value)

        # Test Package Entity Get 200.
        offset = self.package_offset(self.package_fixture_data['name'])
        res = self.app.get(offset, status=self.STATUS_200_OK)
        # Todo: Instead loads() the data and then check actual values.
        assert self.package_fixture_data['name'] in res, res
        assert '"license_id": "%s"' % self.package_fixture_data['license_id'] in res, res
        assert self.package_fixture_data['tags'][0] in res, res
        assert self.package_fixture_data['tags'][1] in res, res
        assert '"extras": {' in res, res
        for key, value in self.package_fixture_data['extras'].items():
            assert '"%s": "%s"' % (key, value) in res, res

        model.Session.remove()

        # Test Packages Register Post 409 (conflict - create duplicate package).
        offset = self.package_offset()
        postparams = '%s=1' % self.dumps(self.package_fixture_data)
        res = self.app.post(offset, params=postparams, status=self.STATUS_409_CONFLICT,
                extra_environ=self.admin_extra_environ)
        model.Session.remove()

    def test_register_post_with_group(self):
        assert not self.get_package_by_name(self.package_fixture_data['name'])
        offset = self.package_offset()

        test_groups = [u'david']
        user = model.User.by_name(u'testsysadmin')

        groups = self.get_groups_identifiers(test_groups,[user])

        package_fixture_data = self.package_fixture_data
        package_fixture_data['groups'] = groups
        data = self.dumps(package_fixture_data)
        res = self.post_json(offset, data, status=self.STATUS_201_CREATED,
                             extra_environ={'Authorization':str(user.apikey)})

        # Check the database record.
        model.Session.remove()
        package = self.get_package_by_name(self.package_fixture_data['name'])
        assert package
        pkg_groups = model.Session.query(model.Group).\
                    join(model.Member, model.Member.group_id == model.Group.id).\
                    filter(model.Member.table_id == package.id).all()
        if self.get_expected_api_version() == 1:
            self.assert_equal([g.name for g in pkg_groups], groups)
        else:
            self.assert_equal([g.id for g in pkg_groups], groups)
        del package_fixture_data['groups']

    def test_register_post_with_group_not_authorized(self):
        assert not self.get_package_by_name(self.package_fixture_data['name'])
        offset = self.package_offset()

        test_groups = [u'david']
        groups = self.get_groups_identifiers(test_groups)

        package_fixture_data = self.package_fixture_data
        package_fixture_data['groups'] = groups
        data = self.dumps(package_fixture_data)
        res = self.post_json(offset, data, status=self.STATUS_403_ACCESS_DENIED,
                             extra_environ=self.extra_environ)
        del package_fixture_data['groups']

    def test_register_post_with_group_not_found(self):
        assert not self.get_package_by_name(self.package_fixture_data['name'])
        offset = self.package_offset()

        test_groups = [u'this-group-does-not-exist']
        groups = test_groups

        package_fixture_data = self.package_fixture_data
        package_fixture_data['groups'] = groups
        data = self.dumps(package_fixture_data)
        res = self.post_json(offset, data, status=self.STATUS_404_NOT_FOUND,
                             extra_environ=self.extra_environ)
        del package_fixture_data['groups']

    def test_register_post_with_group_sysadmin(self):
        assert not self.get_package_by_name(self.package_fixture_data['name'])
        offset = self.package_offset()
        user = model.User.by_name(u'testsysadmin')
        test_groups = [u'david']
        groups = self.get_groups_identifiers(test_groups)

        package_fixture_data = self.package_fixture_data
        package_fixture_data['groups'] = groups
        data = self.dumps(package_fixture_data)
        res = self.post_json(offset, data, status=self.STATUS_201_CREATED,
                              extra_environ={'Authorization':str(user.apikey)})
        # Check the database record.
        model.Session.remove()
        package = self.get_package_by_name(self.package_fixture_data['name'])
        assert package
        pkg_groups = model.Session.query(model.Group).\
                    join(model.Member, model.Member.group_id == model.Group.id).\
                    filter(model.Member.table_id == package.id).all()
        if self.get_expected_api_version() == 1:
            self.assert_equal([g.name for g in pkg_groups], groups)
        else:
            self.assert_equal([g.id for g in pkg_groups], groups)

        del package_fixture_data['groups']

    def test_register_post_json(self):
        assert not self.get_package_by_name(self.package_fixture_data['name'])
        offset = self.package_offset()
        data = self.dumps(self.package_fixture_data)
        res = self.post_json(offset, data, status=self.STATUS_201_CREATED,
                             extra_environ=self.admin_extra_environ)
        # Check the database record.
        model.Session.remove()
        package = self.get_package_by_name(self.package_fixture_data['name'])
        assert package
        self.assert_equal(package.title, self.package_fixture_data['title'])

    def test_register_post_bad_content_type(self):
        assert not self.get_package_by_name(self.package_fixture_data['name'])
        offset = self.package_offset()
        data = self.dumps(self.package_fixture_data)
        res = self.http_request(offset, data,
                                content_type='something/unheard_of',
                                status=[self.STATUS_400_BAD_REQUEST,
                                        self.STATUS_201_CREATED],
                                extra_environ=self.admin_extra_environ)
        model.Session.remove()
        # Some versions of webob work, some don't. No matter, we record this
        # behaviour.
        package = self.get_package_by_name(self.package_fixture_data['name'])
        if res.status == self.STATUS_400_BAD_REQUEST:
            # Check there is no database record.
            assert not package
        else:
            assert package

    def test_register_post_bad_request(self):
        test_params = {
            'name':u'testpackage06_400',
            'resources':[u'should_be_a_dict'],
        }
        offset = self.offset('/rest/dataset')
        postparams = '%s=1' % self.dumps(test_params)
        res = self.app.post(offset, params=postparams, status=self.STATUS_400_BAD_REQUEST,
                extra_environ=self.admin_extra_environ)

    def test_register_post_denied(self):
        offset = self.offset('/rest/dataset')
        postparams = '%s=1' % self.dumps(self.package_fixture_data)
        res = self.app.post(offset, params=postparams, status=self.STATUS_403_ACCESS_DENIED)

    def test_register_post_readonly_fields(self):
        # (ticket 662) Post a package with readonly field such as 'id'
        offset = self.offset('/rest/dataset')
        data = {'name': u'test_readonly',
                'id': u'not allowed to be set',
                }
        postparams = '%s=1' % self.dumps(data)
        res = self.app.post(offset, params=postparams,
                            status=self.STATUS_409_CONFLICT,
                            extra_environ=self.admin_extra_environ)
        assert_equal(res.body, '{"id": ["The input field id was not expected."]}')

    def test_register_post_indexerror(self):
        """
        Test that we can't add a package if Solr is down.
        """
        bad_solr_url = 'http://127.0.0.1/badsolrurl'
        original_settings = SolrSettings.get()[0]
        try:
            SolrSettings.init(bad_solr_url)

            assert not self.get_package_by_name(self.package_fixture_data['name'])
            offset = self.package_offset()
            data = self.dumps(self.package_fixture_data)

            self.post_json(offset, data, status=500, extra_environ=self.admin_extra_environ)
            model.Session.remove()
        finally:
            SolrSettings.init(original_settings)

    def test_register_post_tag_too_long(self):
        pkg = {'name': 'test_tag_too_long',
               'tags': ['tagok', 't'*101]}
        assert not self.get_package_by_name(pkg['name'])
        offset = self.package_offset()
        data = self.dumps(pkg)
        res = self.post_json(offset, data, status=self.STATUS_409_CONFLICT,
                             extra_environ=self.admin_extra_environ)
        assert 'length is more than maximum 100' in res.body, res.body
        assert 'tagok' not in res.body

    def test_entity_get_ok(self):
        package_refs = [self.anna.name, self.anna.id]
        for ref in package_refs:
            offset = self.offset('/rest/dataset/%s' % ref)
            res = self.app.get(offset, status=self.STATUS_200_OK)
            self.assert_msg_represents_anna(msg=res.body)

    def test_entity_get_ok_jsonp(self):
        offset = self.anna_offset(postfix='?callback=jsoncallback')
        res = self.app.get(offset, status=self.STATUS_200_OK)
        import re
        assert re.match('jsoncallback\(.*\);', res.body), res
        # Unwrap JSONP callback (we want to look at the data).
        msg = res.body[len('jsoncallback')+1:-2]
        self.assert_msg_represents_anna(msg=msg)

    def test_entity_get_not_found(self):
        offset = self.offset('/rest/dataset/22222')
        res = self.app.get(offset, status=self.STATUS_404_NOT_FOUND)
        model.Session.remove()

    def test_entity_get_then_post(self):
        # (ticket 662) Ensure an entity you 'get' from a register can be
        # returned by posting it back
        offset = self.package_offset(self.war.name)
        res = self.app.get(offset, status=self.STATUS_200_OK)
        data = self.loads(res.body)

        postparams = '%s=1' % self.dumps(data)
        res = self.app.post(offset, params=postparams,
                            status=self.STATUS_200_OK,
                            extra_environ=self.admin_extra_environ)
        data_returned = self.loads(res.body)
        assert_equal(data['name'], data_returned['name'])
        assert_equal(data['license_id'], data_returned['license_id'])

    def test_entity_get_then_post_new(self):
        offset = self.package_offset(self.war.name)
        res = self.app.get(offset, status=self.STATUS_200_OK)
        data = self.loads(res.body)

        # change name and create a new package
        data['name'] = u'newpkg'
        data['id'] = None # ensure this doesn't clash or you get 409 error
        postparams = '%s=1' % self.dumps(data)
        # use russianfan now because he has rights to add this package to
        # the 'david' group.
        extra_environ = {'REMOTE_USER': 'testsysadmin'}
        res = self.app.post(self.package_offset(), params=postparams,
                            status=self.STATUS_201_CREATED,
                            extra_environ=extra_environ)
        try:
            data_returned = self.loads(res.body)
            assert_equal(data['name'], data_returned['name'])
            assert_equal(data['license_id'], data_returned['license_id'])
        finally:
            self.purge_package_by_name(data['name'])

    def test_entity_post_changed_readonly(self):
        # (ticket 662) Edit a readonly field gives error
        offset = self.package_offset(self.war.name)
        res = self.app.get(offset, status=self.STATUS_200_OK)
        data = self.loads(res.body)
        data['id'] = 'illegally changed value'
        postparams = '%s=1' % self.dumps(data)
        res = self.app.post(offset, params=postparams,
                            status=self.STATUS_409_CONFLICT,
                            extra_environ=self.admin_extra_environ)
        assert "Cannot change value of key from" in res.body, res.body
        assert "to illegally changed value. This key is read-only" in res.body, res.body

    def test_entity_update_denied(self):
        offset = self.anna_offset()
        postparams = '%s=1' % self.dumps(self.package_fixture_data)
        res = self.app.post(offset, params=postparams, status=self.STATUS_403_ACCESS_DENIED)

    def test_entity_delete_denied(self):
        offset = self.anna_offset()
        res = self.app.delete(offset, status=self.STATUS_403_ACCESS_DENIED)

    def test_09_update_package_entity_not_found(self):
        offset = self.offset('/rest/dataset/22222')
        postparams = '%s=1' % self.dumps(self.package_fixture_data)
        res = self.app.post(offset, params=postparams,
                            status=self.STATUS_404_NOT_FOUND,
                            extra_environ=self.admin_extra_environ)

    def create_package_with_admin_user(self, package_data):
        '''Creates a package with self.user as admin and provided package_data.
        '''
        self.create_package(admins=[self.user], data=package_data)

    def assert_package_update_ok(self, package_ref_attribute,
                                 method_str):
        old_fixture_data = {
            'name': self.package_fixture_data['name'],
            'url': self.package_fixture_data['url'],
            'tags': [u'tag 1.1', u'tag2', u'tag3'],
            'extras': {
                u'key1': u'val1',
                u'key2': u'val2'
            },
        }
        new_fixture_data = {
            'name':u'somethingnew',
            'title':u'newtesttitle',
            'resources': [{
                u'url':u'http://blah.com/file2.xml',
                u'format':u'XML',
                u'description':u'Appendix 1',
                u'hash':u'def123',
                u'alt_url':u'alt123',
                u'size_extra':u'400',
            },{
                u'url':u'http://blah.com/file3.xml',
                u'format':u'XML',
                u'description':u'Appenddic 2',
                u'hash':u'ghi123',
                u'alt_url':u'alt123',
                u'size_extra':u'400',
            }],
            'extras': {
                u'key3': u'val3',
                u'key4': u'',
                u'key2': None,
                u'key7': '["a","b"]',
             },
            'tags': [u'tag 1.1', u'tag2', u'tag 4', u'tag5.'],
        }
        self.create_package_with_admin_user(old_fixture_data)
        pkg = self.get_package_by_name(old_fixture_data['name'])
        # This is the one occasion where we reference package explicitly
        # by name or ID, rather than use the value from self.ref_package_by
        # because you should be able to specify the package both ways round
        # for both versions of the API.
        package_ref = getattr(pkg, package_ref_attribute)
        offset = self.offset('/rest/dataset/%s' % package_ref)
        params = '%s=1' % self.dumps(new_fixture_data)
        method_func = getattr(self.app, method_str)
        res = method_func(offset, params=params, status=self.STATUS_200_OK,
                          extra_environ=self.admin_extra_environ)

        try:
            # Check the returned package is as expected
            pkg = self.loads(res.body)
            assert_equal(pkg['name'], new_fixture_data['name'])
            assert_equal(pkg['title'], new_fixture_data['title'])
            assert_equal(set(pkg['tags']), set(new_fixture_data['tags']))
            assert_equal(len(pkg['resources']), len(new_fixture_data['resources']))
            expected_extras = copy.deepcopy(new_fixture_data['extras'])
            del expected_extras['key2']
            expected_extras['key1'] = old_fixture_data['extras']['key1']
            assert_equal(pkg['extras'], expected_extras)

            # Check submitted field have changed.
            model.Session.remove()
            package = self.get_package_by_name(new_fixture_data['name'])
            # - title
            self.assert_equal(package.title, new_fixture_data['title'])
            # - tags
            package_tagnames = [tag.name for tag in package.get_tags()]
            for tagname in new_fixture_data['tags']:
                assert tagname in package_tagnames, 'tag %r not in %r' % (tagname, package_tagnames)
            # - resources
            assert len(package.resources), "Package has no resources: %s" % package
            self.assert_equal(len(package.resources), 2)
            resource = package.resources[0]
            self.assert_equal(resource.url, u'http://blah.com/file2.xml')
            self.assert_equal(resource.format, u'XML')
            self.assert_equal(resource.description, u'Appendix 1')
            self.assert_equal(resource.hash, u'def123')
            self.assert_equal(resource.alt_url, u'alt123')
            self.assert_equal(resource.extras['size_extra'], u'400')
            resource = package.resources[1]
            self.assert_equal(resource.url, 'http://blah.com/file3.xml')
            self.assert_equal(resource.format, u'XML')
            self.assert_equal(resource.description, u'Appenddic 2')
            self.assert_equal(resource.hash, u'ghi123')
            self.assert_equal(resource.alt_url, u'alt123')
            self.assert_equal(resource.extras['size_extra'], u'400')

            # Check unsubmitted fields have not changed.
            # - url
            self.assert_equal(package.url, self.package_fixture_data['url'])
            # - extras

            self.assert_equal(len(package.extras), 4)
            for key, value in {u'key1':u'val1',
                               u'key3':u'val3',
                               u'key7':'["a","b"]',
                               u'key4':u''}.items():
                self.assert_equal(package.extras[key], value)
            # NB: key4 set to '' creates it
            # but: key2 set to None will delete it
            assert not package.extras.has_key('key2')
        finally:
            self.purge_package_by_name(new_fixture_data['name'])


    def test_package_update_ok_by_id(self):
        self.assert_package_update_ok('id', 'post')

    def test_entity_update_ok_by_name(self):
        self.assert_package_update_ok('name', 'post')

    def test_package_update_ok_by_id_by_put(self):
        self.assert_package_update_ok('id', 'put')

    def test_entity_update_ok_by_name_by_put(self):
        self.assert_package_update_ok('name', 'put')

    def test_package_update_invalid(self):
        old_fixture_data = {
            'name': self.package_fixture_data['name'],
        }
        new_fixture_data = {
            'name':u'somethingnew',
            'resources': [{
                u'url':u'http://blah.com/file1.xml',
                u'size':u'abc', # INVALID
            },{
                u'url':u'http://blah.com/file2.xml',
                u'size':u'400',
                u'last_modified':u'123', # INVALID
            }],
        }
        self.create_package_with_admin_user(old_fixture_data)
        pkg = self.get_package_by_name(old_fixture_data['name'])
        offset = self.offset('/rest/dataset/%s' % pkg.name)
        params = '%s=1' % self.dumps(new_fixture_data)
        res = self.app.post(offset, params=params,
                            status=self.STATUS_409_CONFLICT,
                            extra_environ=self.admin_extra_environ)
        res_dict = self.loads(res.body)
        assert len(res_dict['resources']) == 2, res_dict['resources']
        assert_equal(res_dict['resources'][0], {u'size': [u'Invalid integer']})
        assert_equal(res_dict['resources'][1], {u'last_modified': [u'Date format incorrect']})

    def test_package_update_delete_last_extra(self):
        old_fixture_data = {
            'name': self.package_fixture_data['name'],
            'extras': {
                u'key1': u'val1',
            },
        }
        new_fixture_data = {
            'name':u'somethingnew',
            'extras': {
                u'key1': None,
                },
        }
        self.create_package_with_admin_user(old_fixture_data)
        offset = self.package_offset(old_fixture_data['name'])
        params = '%s=1' % self.dumps(new_fixture_data)
        res = self.app.post(offset, params=params, status=self.STATUS_200_OK,
                            extra_environ=self.admin_extra_environ)

        try:
            # Check the returned package is as expected
            pkg = self.loads(res.body)
            assert_equal(pkg['name'], new_fixture_data['name'])
            expected_extras = copy.deepcopy(new_fixture_data['extras'])
            del expected_extras['key1']
            assert_equal(pkg['extras'], expected_extras)

            # Check extra was deleted
            model.Session.remove()
            package = self.get_package_by_name(new_fixture_data['name'])
            # - title
            self.assert_equal(package.extras, {})
        finally:
            self.purge_package_by_name(new_fixture_data['name'])

    def test_package_update_do_not_delete_last_extra(self):
        old_fixture_data = {
            'name': self.package_fixture_data['name'],
            'extras': {
                u'key1': u'val1',
            },
        }
        new_fixture_data = {
            'name':u'somethingnew',
            'extras': {}, # no extras specified, but existing
                          # ones should be left alone
        }
        self.create_package_with_admin_user(old_fixture_data)
        offset = self.package_offset(old_fixture_data['name'])
        params = '%s=1' % self.dumps(new_fixture_data)
        res = self.app.post(offset, params=params, status=self.STATUS_200_OK,
                            extra_environ=self.admin_extra_environ)

        try:
            # Check the returned package is as expected
            pkg = self.loads(res.body)
            assert_equal(pkg['name'], new_fixture_data['name'])
            expected_extras = {u'key1': u'val1'} # should not be deleted
            assert_equal(pkg['extras'], expected_extras)

            # Check extra was not deleted
            model.Session.remove()
            package = self.get_package_by_name(new_fixture_data['name'])
            # - title
            assert len(package.extras) == 1, package.extras
        finally:
            self.purge_package_by_name(new_fixture_data['name'])

    def test_entity_update_readd_tag(self):
        name = self.package_fixture_data['name']
        old_fixture_data = {
            'name': name,
            'tags': ['tag 1.', 'tag2']
        }
        new_fixture_data = {
            'name': name,
            'tags': ['tag 1.']
        }
        self.create_package_with_admin_user(old_fixture_data)
        offset = self.package_offset(name)
        params = '%s=1' % self.dumps(new_fixture_data)
        res = self.app.post(offset, params=params, status=self.STATUS_200_OK,
                            extra_environ=self.admin_extra_environ)

        # Check the returned package is as expected
        pkg = self.loads(res.body)
        assert_equal(pkg['name'], new_fixture_data['name'])
        assert_equal(pkg['tags'], ['tag 1.'])

        package = self.get_package_by_name(new_fixture_data['name'])
        assert len(package.get_tags()) == 1, package.get_tags()

        # now reinstate the tag
        params = '%s=1' % self.dumps(old_fixture_data)
        res = self.app.post(offset, params=params, status=self.STATUS_200_OK,
                            extra_environ=self.admin_extra_environ)
        pkg = self.loads(res.body)
        assert_equal(pkg['tags'], ['tag 1.', 'tag2'])

    def test_entity_update_conflict(self):
        package1_name = self.package_fixture_data['name']
        package1_data = {'name': package1_name}
        package1 = self.create_package_with_admin_user(package1_data)
        package2_name = u'somethingnew'
        package2_data = {'name': package2_name}
        package2 = self.create_package_with_admin_user(package2_data)
        try:
            package1_offset = self.package_offset(package1_name)
            # trying to rename package 1 to package 2's name
            print package1_offset, package2_data
            self.post(package1_offset, package2_data, self.STATUS_409_CONFLICT, extra_environ=self.admin_extra_environ)
        finally:
            self.purge_package_by_name(package2_name)

    def test_entity_update_empty(self):
        package1_name = self.package_fixture_data['name']
        package1_data = {'name': package1_name}
        package1 = self.create_package_with_admin_user(package1_data)
        package2_data = '' # this is the error
        package1_offset = self.package_offset(package1_name)
        self.app.put(package1_offset, package2_data,
                     status=self.STATUS_400_BAD_REQUEST)

    def test_entity_update_indexerror(self):
        """
        Test that we can't update a package if Solr is down.
        """
        bad_solr_url = 'http://127.0.0.1/badsolrurl'
        original_settings = SolrSettings.get()[0]
        try:
            SolrSettings.init(bad_solr_url)

            assert_raises(
                search.SearchIndexError, self.assert_package_update_ok, 'name', 'post'
            )
        finally:
            SolrSettings.init(original_settings)

    def test_package_update_delete_resource(self):
        old_fixture_data = {
            'name': self.package_fixture_data['name'],
            'resources': [{
                u'url':u'http://blah.com/file2.xml',
                u'format':u'XML',
                u'description':u'Appendix 1',
                u'hash':u'def123',
                u'alt_url':u'alt123',
            },{
                u'url':u'http://blah.com/file3.xml',
                u'format':u'XML',
                u'description':u'Appenddic 2',
                u'hash':u'ghi123',
                u'alt_url':u'alt123',
            }],
        }
        new_fixture_data = {
            'name':u'somethingnew',
            'resources': [],
        }
        self.create_package_with_admin_user(old_fixture_data)
        offset = self.package_offset(old_fixture_data['name'])
        params = '%s=1' % self.dumps(new_fixture_data)
        res = self.app.post(offset, params=params, status=self.STATUS_200_OK,
                            extra_environ=self.admin_extra_environ)

        try:
            # Check the returned package is as expected
            pkg = self.loads(res.body)
            assert_equal(pkg['name'], new_fixture_data['name'])
            assert_equal(pkg['resources'], [])

            # Check resources were deleted
            model.Session.remove()
            package = self.get_package_by_name(new_fixture_data['name'])
            self.assert_equal(len(package.resources), 0)
        finally:
            self.purge_package_by_name(new_fixture_data['name'])

    def test_entity_delete_ok(self):
        # create a package with package_fixture_data
        if not self.get_package_by_name(self.package_fixture_data['name']):
            self.create_package(admins=[self.user], name=self.package_fixture_data['name'])
        assert self.get_package_by_name(self.package_fixture_data['name'])
        # delete it
        offset = self.package_offset(self.package_fixture_data['name'])
        res = self.app.delete(offset, status=self.STATUS_200_OK,
                              extra_environ=self.admin_extra_environ)
        package = self.get_package_by_name(self.package_fixture_data['name'])
        self.assert_equal(package.state, 'deleted')
        model.Session.remove()

    def test_entity_delete_ok_without_request_headers(self):
        # create a package with package_fixture_data
        if not self.get_package_by_name(self.package_fixture_data['name']):
            self.create_package(admins=[self.user], name=self.package_fixture_data['name'])
        assert self.get_package_by_name(self.package_fixture_data['name'])
        # delete it
        offset = self.package_offset(self.package_fixture_data['name'])
        res = self.delete_request(offset, status=self.STATUS_200_OK,
                                  extra_environ=self.admin_extra_environ)
        package = self.get_package_by_name(self.package_fixture_data['name'])
        self.assert_equal(package.state, 'deleted')
        model.Session.remove()

    def test_entity_delete_not_found(self):
        package_name = u'random_one'
        assert not model.Session.query(model.Package).filter_by(name=package_name).count()
        offset = self.offset('/rest/dataset/%s' % package_name)
        res = self.app.delete(offset, status=self.STATUS_404_NOT_FOUND,
                              extra_environ=self.admin_extra_environ)

    def test_package_revisions(self):
        # check original revision
        res = self.app.get(self.offset('/rest/dataset/%s/revisions' % 'annakarenina'))
        revisions = res.json
        assert len(revisions) == 1, len(revisions)
        expected_keys = set(('id', 'message', 'author', 'timestamp', 'approved_timestamp'))
        keys = set(revisions[0].keys())
        assert_equal(keys, expected_keys)

        # edit anna
        pkg = model.Package.by_name('annakarenina')
        model.repo.new_revision()
        pkg.title = 'Tolstoy'
        model.repo.commit_and_remove()

        # check new revision is there
        res = self.app.get(self.offset('/rest/dataset/%s/revisions' % 'annakarenina'))
        revisions = res.json
        assert len(revisions) == 2, len(revisions)

        # check ordering
        assert revisions[0]["timestamp"] > revisions[1]["timestamp"]

        # edit related extra
        pkg = model.Package.by_name('annakarenina')
        model.repo.new_revision()
        pkg.extras['genre'] = 'literary'
        model.repo.commit_and_remove()

        # check new revision is there
        res = self.app.get(self.offset('/rest/dataset/%s/revisions' % 'annakarenina'))
        revisions = res.json
        assert len(revisions) == 3, len(revisions)

    def test_create_private_package_with_no_organization(self):
        '''Test that private packages with no organization cannot be created.

        '''
        testsysadmin = model.User.by_name('testsysadmin')
        result = tests.call_action_api(self.app, 'package_create', name='test',
                private=True, apikey=testsysadmin.apikey, status=409)
        assert result == {'__type': 'Validation Error',
                'private': ["Datasets with no organization can't be private."]}

    def test_create_public_package_with_no_organization(self):
        '''Test that public packages with no organization can be created.'''
        testsysadmin = model.User.by_name('testsysadmin')
        tests.call_action_api(self.app, 'package_create', name='test',
                private=False, apikey=testsysadmin.apikey)

    def test_make_package_with_no_organization_private(self):
        '''Test that private packages with no organization cannot be created
        by package_update.

        '''
        testsysadmin = model.User.by_name('testsysadmin')
        package = tests.call_action_api(self.app, 'package_create',
                name='test_2', private=False, apikey=testsysadmin.apikey)
        package['private'] = True
        result = tests.call_action_api(self.app, 'package_update',
                apikey=testsysadmin.apikey, status=409, **package)
        assert result == {'__type': 'Validation Error',
                'private': ["Datasets with no organization can't be private."]}


class TestPackagesVersion1(Version1TestCase, PackagesTestCase):
    def test_06_create_pkg_using_download_url(self):
        test_params = {
            'name':u'testpkg06',
            'download_url':u'ftp://ftp.monash.edu.au/pub/nihongo/JMdict.gz',
            }
        offset = self.package_offset()
        postparams = '%s=1' % self.dumps(test_params)
        res = self.app.post(offset, params=postparams,
                            extra_environ=self.admin_extra_environ)
        model.Session.remove()
        pkg = self.get_package_by_name(test_params['name'])
        assert pkg
        assert pkg.name == test_params['name'], pkg
        assert len(pkg.resources) == 1, pkg.resources
        assert pkg.resources[0].url == test_params['download_url'], pkg.resources[0]

    def test_10_edit_pkg_with_download_url(self):
        test_params = {
            'name':u'testpkg10',
            'download_url':u'testurl',
            }
        rev = model.repo.new_revision()
        pkg = model.Package()
        model.Session.add(pkg)
        pkg.name = test_params['name']
        pkg.download_url = test_params['download_url']
        model.Session.commit()

        pkg = self.get_package_by_name(test_params['name'])
        model.setup_default_user_roles(pkg, [self.user])
        rev = model.repo.new_revision()
        model.repo.commit_and_remove()
        assert self.get_package_by_name(test_params['name'])

        # edit it
        pkg_vals = {'download_url':u'newurl'}
        offset = self.package_offset(test_params['name'])
        postparams = '%s=1' % self.dumps(pkg_vals)
        res = self.app.post(offset, params=postparams, status=[200],
                            extra_environ=self.admin_extra_environ)
        model.Session.remove()
        pkg = model.Session.query(model.Package).filter_by(name=test_params['name']).one()
        assert len(pkg.resources) == 1, pkg.resources
        assert pkg.resources[0].url == pkg_vals['download_url']

class TestPackagesVersion2(Version2TestCase, PackagesTestCase): pass

########NEW FILE########
__FILENAME__ = test_ratings
from nose.tools import assert_equal 
from nose.plugins.skip import SkipTest

from ckan import model
from ckan.lib.create_test_data import CreateTestData

from ckan.tests.functional.api.base import BaseModelApiTestCase
from ckan.tests.functional.api.base import Api1TestCase as Version1TestCase 
from ckan.tests.functional.api.base import Api2TestCase as Version2TestCase 

class RatingsTestCase(BaseModelApiTestCase):

    @classmethod
    def setup_class(cls):
        CreateTestData.create()
        cls.testsysadmin = model.User.by_name(u'testsysadmin')
        cls.comment = u'Comment umlaut: \xfc.'
        cls.user_name = u'annafan' # created in CreateTestData
        cls.init_extra_environ(cls.user_name)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_register_get(self):
        raise SkipTest('"Rating register get" functionality is not implemented')
        rating1 = model.Rating(user_ip_address='1.2.3.4',
                               package=self.anna,
                               rating=4.0)
        rating2 = model.Rating(user=model.User.by_name(u'annafan'),
                               package=self.anna,
                               rating=2.0)
        model.Session.add_all((rating1, rating2))
        model.repo.commit_and_remove()

        offset = self.rating_offset()
        res = self.app.get(offset, status=[200])

    def test_entity_get(self):
        raise SkipTest('"Rating entity get" functionality is not implemented')
        rating = model.Rating(user_ip_address='1.2.3.4',
                              package=self.anna,
                              rating=4.0)
        model.Session.add(rating)
        model.repo.commit_and_remove()

        offset = self.rating_offset(self.anna.name)
        res = self.app.get(offset, status=[200])
        assert_equal(res, rating_opts['rating'])

    def test_register_post(self):
        # Test Rating Register Post 200.
        self.clear_all_tst_ratings()
        offset = self.rating_offset()
        rating_opts = {'package':u'warandpeace',
                       'rating':5}
        pkg_name = rating_opts['package']
        postparams = '%s=1' % self.dumps(rating_opts)
        res = self.app.post(offset, params=postparams, status=[201],
                extra_environ=self.extra_environ)
        model.Session.remove()
        pkg = self.get_package_by_name(pkg_name)
        assert pkg
        assert len(pkg.ratings) == 1
        assert pkg.ratings[0].rating == rating_opts['rating'], pkg.ratings

        # Get package to see rating
        offset = self.package_offset(pkg_name)
        res = self.app.get(offset, status=[200])
        assert pkg_name in res, res
        assert '"ratings_average": %s.0' % rating_opts['rating'] in res, res
        assert '"ratings_count": 1' in res, res
        
        model.Session.remove()
        
        # Rerate package
        offset = self.rating_offset()
        postparams = '%s=1' % self.dumps(rating_opts)
        res = self.app.post(offset, params=postparams, status=[201],
                extra_environ=self.extra_environ)
        model.Session.remove()
        pkg = self.get_package_by_name(pkg_name)
        assert pkg
        assert len(pkg.ratings) == 1
        assert pkg.ratings[0].rating == rating_opts['rating'], pkg.ratings

    def test_entity_post_invalid(self):
        self.clear_all_tst_ratings()
        offset = self.rating_offset()
        rating_opts = {'package':u'warandpeace',
                       'rating':0}
        postparams = '%s=1' % self.dumps(rating_opts)
        res = self.app.post(offset, params=postparams, status=[409],
                            extra_environ=self.extra_environ)
        self.assert_json_response(res, 'rating')
        model.Session.remove()
        pkg = self.get_package_by_name(rating_opts['package'])
        assert pkg
        assert len(pkg.ratings) == 0

class TestRatingsVersion1(Version1TestCase, RatingsTestCase): pass
class TestRatingsVersion2(Version2TestCase, RatingsTestCase): pass

########NEW FILE########
__FILENAME__ = test_relationships
from nose.tools import assert_equal 
from nose.plugins.skip import SkipTest

from ckan import model
from ckan.lib.create_test_data import CreateTestData

from ckan.tests.functional.api.base import BaseModelApiTestCase
from ckan.tests.functional.api.base import Api1TestCase as Version1TestCase 
from ckan.tests.functional.api.base import Api2TestCase as Version2TestCase 

class RelationshipsTestCase(BaseModelApiTestCase):

    @classmethod
    def setup_class(cls):
        CreateTestData.create()
        cls.testsysadmin = model.User.by_name(u'testsysadmin')
        cls.comment = u'Comment umlaut: \xfc.'
        cls.user_name = u'annafan' # created in CreateTestData
        cls.init_extra_environ(cls.user_name)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def teardown(self):
        relationships = model.Session.query(model.PackageRelationship).all()
        for rel in relationships:
            rel.purge()
        model.repo.commit_and_remove()

    def relationship_offset(self, package_1_name=None,
                            relationship_type=None,
                            package_2_name=None,
                            ):
        assert package_1_name
        package_1_ref = self.package_ref_from_name(package_1_name)
        if package_2_name is None:
            if not relationship_type:
                return self.offset('/rest/dataset/%s/relationships' % \
                                   package_1_ref)
            else:
                return self.offset('/rest/dataset/%s/%s' %
                                   (package_1_ref, relationship_type))
        else:
            package_2_ref = self.package_ref_from_name(package_2_name)
            if not relationship_type:
                return self.offset('/rest/dataset/%s/relationships/%s' % \
                                   (package_1_ref, package_2_ref))
            else:
                return self.offset('/rest/dataset/%s/%s/%s' % \
                                   (package_1_ref,
                                    relationship_type,
                                    package_2_ref))

    def test_01_create_and_read_relationship(self):
        # check anna has no existing relationships
        assert not self.anna.get_relationships()
        assert self.get_relationships(package1_name='annakarenina') == [], self.get_relationships(package1_name='annakarenina')
        assert self.get_relationships(package1_name='annakarenina',
                                       package2_name='warandpeace') == []
        assert self.get_relationships(package1_name='annakarenina',
                                       type='child_of',
                                       package2_name='warandpeace') == 404
        assert self.get_relationships_via_package('annakarenina') == []

        # Create a relationship.
        self.create_annakarenina_parent_of_war_and_peace()

        # Check package relationship register.
        rels = self.get_relationships(package1_name='annakarenina')
        assert len(rels) == 1
        self.check_relationship_dict(rels[0],
               'annakarenina', 'parent_of', 'warandpeace', self.comment)

        # Todo: Name this?
        # Check '/api/VER/rest/package/annakarenina/relationships/warandpeace'
        rels = self.get_relationships(package1_name='annakarenina',
                                       package2_name='warandpeace')
        assert len(rels) == 1
        self.check_relationship_dict(rels[0],
               'annakarenina', 'parent_of', 'warandpeace', self.comment)

        # Todo: Name this?
        # check '/api/VER/rest/package/annakarenina/parent_of/warandpeace'
        rels = self.get_relationships(package1_name='annakarenina',
                                       type='parent_of',
                                       package2_name='warandpeace')
        assert len(rels) == 1
        self.check_relationship_dict(rels[0],
               'annakarenina', 'parent_of', 'warandpeace', self.comment)

        # same checks in reverse direction
        rels = self.get_relationships(package1_name='warandpeace')
        assert len(rels) == 1
        self.check_relationship_dict(rels[0],
               'warandpeace', 'child_of', 'annakarenina', self.comment)

        rels = self.get_relationships(package1_name='warandpeace',
                                       package2_name='annakarenina')
        assert len(rels) == 1
        self.check_relationship_dict(rels[0],
               'warandpeace', 'child_of', 'annakarenina', self.comment)

        rels = self.get_relationships(package1_name='warandpeace',
                                       type='child_of',
                                      package2_name='annakarenina')
        assert len(rels) == 1
        self.check_relationship_dict(rels[0],
               'warandpeace', 'child_of', 'annakarenina', self.comment)

        # Check package entity relationships.
        rels = self.get_relationships_via_package('annakarenina')
        assert len(rels) == 1
        self.check_relationship_dict(rels[0],
               'annakarenina', 'parent_of', 'warandpeace', self.comment)
        
    def test_02_create_relationship_way_2(self):
        # Create a relationship using 2nd way
        self.create_annakarenina_parent_of_war_and_peace(way=2)

    def test_02_create_relationship_way_3(self):
        # Create a relationship using 3rd way
        self.create_annakarenina_parent_of_war_and_peace(way=3)

    def test_02_create_relationship_way_4(self):
        # Create a relationship using 4th way
        self.create_annakarenina_parent_of_war_and_peace(way=4)

    def test_02_create_link_relationship(self):
        offset = self.relationship_offset('annakarenina')
        data = {'type': 'links_to',
                'object': 'warandpeace',
                'comment':self.comment}
        postparams = '%s=1' % self.dumps(data)
        res = self.app.post(offset, params=postparams, status=[201],
                            extra_environ=self.extra_environ)
        # Check the response
        rel = self.loads(res.body)
        assert_equal(rel['type'], 'links_to')
        assert_equal(rel['subject'], self.ref_package(self.anna))
        assert_equal(rel['object'], self.ref_package(self.war))

    def test_03_update_relationship(self):
        # Create a relationship.
        self.create_annakarenina_parent_of_war_and_peace()

        # Check the relationship before update.
        self.check_relationships_rest('warandpeace', 'annakarenina',
                                      [{'type': 'child_of',
                                        'comment': self.comment}])

        # Update the relationship.
        new_comment = u'New comment.'
        self.update_annakarenina_parent_of_war_and_peace(comment=new_comment)

        # Check the relationship after update.
        self.check_relationships_rest('warandpeace', 'annakarenina', [{'type': 'child_of', 'comment': new_comment}])

        # Repeat update with same values, to check it remains the same?

        # Update the relationship.
        new_comment = u'New comment.'
        self.update_annakarenina_parent_of_war_and_peace(comment=new_comment)

        # Check the relationship after update.
        self.check_relationships_rest('warandpeace', 'annakarenina', [{'type': 'child_of', 'comment': new_comment}])

    def test_05_delete_relationship(self):
        self.create_annakarenina_parent_of_war_and_peace()
        self.update_annakarenina_parent_of_war_and_peace()
        expected = [ {'type': 'child_of', 'comment': u'New comment.'} ]
        self.check_relationships_rest('warandpeace', 'annakarenina', expected)

        self.delete_annakarenina_parent_of_war_and_peace()

        expected = []
        self.check_relationships_rest('warandpeace', 'annakarenina', expected)

    def test_create_relationship_unknown(self):
        offset = self.relationship_offset('annakarenina', 'unheard_of_type', 'warandpeace')
        postparams = '%s=1' % self.dumps({'comment':self.comment})
        res = self.app.post(offset, params=postparams, status=[409],
                            extra_environ=self.extra_environ)
        # error message is wrong - ends up in package_create,
        # but at least there is an error

    def create_annakarenina_parent_of_war_and_peace(self, way=1):
        # Create package relationship.
        # More than one 'way' to create a package.
        # Todo: Redesign this in a RESTful style, so that a relationship is 
        # created by posting a relationship to a relationship **register**.
        assert way in (1, 2, 3, 4)
        if way == 1:
            # Dataset Relationship Entity - old way (deprecated)
            offset = self.relationship_offset('annakarenina', 'parent_of', 'warandpeace')
            data = {'comment':self.comment}
        elif way == 2:
            # Dataset Relationships Register 1
            offset = self.relationship_offset('annakarenina', 'relationships')
            data = {'type': 'parent_of',
                    'object': 'warandpeace',
                    'comment':self.comment}
        elif way == 3:
            # Dataset Relationships Register 2
            offset = self.relationship_offset('annakarenina', 'parent_of')
            data = {'object': 'warandpeace',
                    'comment':self.comment}
        elif way == 4:
            # Dataset Relationships Register 3
            offset = self.relationship_offset('annakarenina', 'relationships', 'warandpeace')
            data = {'type': 'parent_of',
                    'comment':self.comment}
        postparams = '%s=1' % self.dumps(data)
        res = self.app.post(offset, params=postparams, status=[201],
                            extra_environ=self.extra_environ)
        # Check the response
        rel = self.loads(res.body)
        assert_equal(rel['type'], 'child_of')
        assert_equal(rel['subject'], self.ref_package(self.war))
        assert_equal(rel['object'], self.ref_package(self.anna))
        
        # Check the model, directly.
        rels = self.anna.get_relationships()
        assert len(rels) == 1, rels
        assert rels[0].type == 'child_of'
        assert rels[0].subject.name == 'warandpeace'
        assert rels[0].object.name == 'annakarenina'

    def update_annakarenina_parent_of_war_and_peace(self, comment=u'New comment.'):
        offset = self.relationship_offset('annakarenina', 'parent_of', 'warandpeace')
        postparams = '%s=1' % self.dumps({'comment':comment})
        res = self.app.put(offset, params=postparams, status=[200], extra_environ=self.extra_environ)
        # Check the response
        rel = self.loads(res.body)
        assert_equal(rel['type'], 'child_of')
        assert_equal(rel['subject'], self.ref_package(self.war))
        assert_equal(rel['object'], self.ref_package(self.anna))

        # Check the model, directly (normalised to 'child_of')
        rels = self.anna.get_relationships()
        assert len(rels) == 1, rels
        assert rels[0].type == 'child_of'
        assert rels[0].subject.name == 'warandpeace'
        assert rels[0].object.name == 'annakarenina'
        return res

    def test_update_relationship_incorrectly(self):
        self.create_annakarenina_parent_of_war_and_peace()
        offset = self.relationship_offset('annakarenina', 'parent_of', 'warandpeace')
        postparams = '%s=1' % self.dumps({'type': 'cat', 'object': 'Matilda', 'comment': 'Tabby'})
        # Should only be able to change the comment.
        # Todo: validate this properly and return an error
        # Currently it just ignores the changed type and subject/object
        res = self.app.put(offset, params=postparams, status=[200],
                           extra_environ=self.extra_environ)
        print res.body
        assert 'cat' not in res.body
        assert 'Matilda' not in res.body
        assert 'Tabby' in res.body

    def delete_annakarenina_parent_of_war_and_peace(self):
        offset = self.relationship_offset('annakarenina', 'parent_of', 'warandpeace')
        res = self.app.delete(offset, status=[200], extra_environ=self.extra_environ)
        assert not res.body, res.body

    def get_relationships(self, package1_name=u'annakarenina', type='relationships', package2_name=None):
        offset = self.relationship_offset(package1_name, type, package2_name)
        allowable_statuses = [200]
        if type:
            allowable_statuses.append(404)
        res = self.app.get(offset, status=allowable_statuses)
        if res.status == 200:
            res_dict = self.data_from_res(res) if res.body else []
            return res_dict
        else:
            return 404

    def get_relationships_via_package(self, package1_name):
        offset = self.package_offset(package1_name)
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        return res_dict['relationships']

    def assert_len_relationships(self, relationships, expected_relationships):
        len_relationships = len(relationships)
        len_expected_relationships = len(expected_relationships)
        if len_relationships != len_expected_relationships:
            msg = 'Found %i relationships, ' % len_relationships
            msg += 'but expected %i.' % len_expected_relationships
            if len_relationships:
                msg += ' Found: '
                for r in relationships:
                    msg += '%s %s %s; ' % (r['subject'], r['type'], r['object'])
                msg += '.'
            raise Exception, msg

    def check_relationships_rest(self, pkg1_name, pkg2_name=None,
                                 expected_relationships=[]):
        rels = self.get_relationships(package1_name=pkg1_name,
                                      package2_name=pkg2_name)
        self.assert_len_relationships(rels, expected_relationships) 
        for rel in rels:
            the_expected_rel = None
            for expected_rel in expected_relationships:
                if expected_rel['type'] == rel['type'] and \
                   (pkg2_name or expected_rel['object'] == pkg2_name):
                    the_expected_rel = expected_rel
                    break
            if not the_expected_rel:
                raise Exception('Unexpected relationship: %s %s %s' %
                                (rel['subject'], rel['type'], rel['object']))
            for field in ('subject', 'object', 'type', 'comment'):
                if the_expected_rel.has_key(field):
                    value = rel[field]
                    expected = the_expected_rel[field]
                    assert value == expected, (value, expected, field, rel)

    def check_relationship_dict(self, rel_dict, subject_name, type, object_name, comment):
        subject_ref = self.package_ref_from_name(subject_name)
        object_ref = self.package_ref_from_name(object_name)

        assert rel_dict['subject'] == subject_ref, (rel_dict, subject_ref)
        assert rel_dict['object'] == object_ref, (rel_dict, object_ref)
        assert rel_dict['type'] == type, (rel_dict, type)
        assert rel_dict['comment'] == comment, (rel_dict, comment)

class TestRelationshipsVersion1(Version1TestCase, RelationshipsTestCase): pass
class TestRelationshipsVersion2(Version2TestCase, RelationshipsTestCase): pass

########NEW FILE########
__FILENAME__ = test_revisions
from nose.tools import assert_equal 

from ckan import model
from ckan.lib.create_test_data import CreateTestData

from ckan.tests.functional.api.base import BaseModelApiTestCase
from ckan.tests.functional.api.base import Api1TestCase as Version1TestCase 
from ckan.tests.functional.api.base import Api2TestCase as Version2TestCase 

class RevisionsTestCase(BaseModelApiTestCase):

    @classmethod
    def setup_class(cls):
        CreateTestData.create()
        cls.user_name = u'annafan' # created in CreateTestData
        cls.init_extra_environ(cls.user_name)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
    
    def test_register_get_ok(self):
        # Comparison list - newest first
        revs = model.Session.query(model.Revision).\
               order_by(model.Revision.timestamp.desc()).all()
        assert revs

        # Check list of revisions
        offset = self.revision_offset()
        res = self.app.get(offset, status=200)
        revs_result = self.data_from_res(res)

        assert_equal(revs_result, [rev.id for rev in revs])

    def test_entity_get_ok(self):
        rev = model.repo.history().all()[0] # newest revision is the creation of pkgs
        assert rev.id
        assert rev.timestamp.isoformat()
        offset = self.revision_offset(rev.id)
        response = self.app.get(offset, status=[200])
        response_data = self.data_from_res(response)
        assert_equal(rev.id, response_data['id'])
        assert_equal(rev.timestamp.isoformat(), response_data['timestamp'])
        assert 'packages' in response_data
        packages = response_data['packages']
        assert isinstance(packages, list)
        #assert len(packages) != 0, "Revision packages is empty: %s" % packages
        assert self.ref_package(self.anna) in packages, packages
        assert self.ref_package(self.war) in packages, packages

    def test_entity_get_404(self):
        revision_id = "xxxxxxxxxxxxxxxxxxxxxxxxxx"
        offset = self.revision_offset(revision_id)
        res = self.app.get(offset, status=404)
        self.assert_json_response(res, 'Not found')

    def test_entity_get_301(self):
        # see what happens when you miss the ID altogether
        revision_id = ''
        offset = self.revision_offset(revision_id)
        res = self.app.get(offset, status=301)
        # redirects "/api/revision/" to "/api/revision"

class TestRevisionsVersion1(Version1TestCase, RevisionsTestCase): pass
class TestRevisionsVersion2(Version2TestCase, RevisionsTestCase): pass

########NEW FILE########
__FILENAME__ = test_tag
import copy

from nose.tools import assert_equal 

from ckan import model
from ckan.lib.create_test_data import CreateTestData
import ckan.lib.search as search

from ckan.tests.functional.api.base import BaseModelApiTestCase
from ckan.tests.functional.api.base import Api1TestCase as Version1TestCase 
from ckan.tests.functional.api.base import Api2TestCase as Version2TestCase 

class TagsTestCase(BaseModelApiTestCase):

    @classmethod
    def setup_class(cls):
        search.clear()
        CreateTestData.create()
        cls.testsysadmin = model.User.by_name(u'testsysadmin')
        cls.comment = u'Comment umlaut: \xfc.'
        cls.user_name = u'annafan' # created in CreateTestData
        cls.init_extra_environ(cls.user_name)

    @classmethod
    def teardown_class(cls):
        search.clear()
        model.repo.rebuild_db()

    def test_register_get_ok(self):
        offset = self.tag_offset()
        res = self.app.get(offset, status=self.STATUS_200_OK)
        results = self.loads(res.body)
        assert self.russian.name in results, results
        assert self.tolstoy.name in results, results
        assert self.flexible_tag.name in results, results
    
    def test_entity_get_ok(self):
        offset = self.tag_offset(self.russian.name)
        res = self.app.get(offset, status=self.STATUS_200_OK)
        self.assert_msg_represents_russian(msg=res.body)

    def test_entity_get_ok_flexible_tag(self):
        """
        Asserts that searching for a tag name with spaces and punctuation works.

        The tag name is u'Flexible \u30a1', and both the 'warandpeace'
        and 'annakarenina' packages should be returned.
        """
        offset = self.tag_offset(self.flexible_tag.name)
        res = self.app.get(offset, status=self.STATUS_200_OK)
        self.assert_msg_represents_flexible_tag(msg=res.body)

    def test_entity_get_not_found(self):
        offset = self.tag_offset('doesntexist')
        res = self.app.get(offset, status=404)
        self.assert_json_response(res, 'Not found')

class TestTagsVersion1(Version1TestCase, TagsTestCase): pass
class TestTagsVersion2(Version2TestCase, TagsTestCase): pass

########NEW FILE########
__FILENAME__ = test_vocabulary
import ckan
import pylons.test
import paste.fixture
import ckan.lib.helpers as helpers
import ckan.lib.dictization.model_dictize as model_dictize


class TestVocabulary(object):

    @classmethod
    def setup_class(self):
        self.app = paste.fixture.TestApp(pylons.test.pylonsapp)

    @classmethod
    def teardown_class(self):
        ckan.model.repo.rebuild_db()

    def setup(self):
        self.clean_vocab()
        model = ckan.model
        context = {'model': model}

        genre = model.Vocabulary("Genre")
        time_period = ckan.model.Vocabulary("Time Period")
        composers = ckan.model.Vocabulary("Composers")
        model.Session.add_all([genre, time_period, composers])

        self.genre_vocab = model_dictize.vocabulary_dictize(genre, context)
        self.timeperiod_vocab = model_dictize.vocabulary_dictize(time_period,
                context)
        self.composers_vocab = model_dictize.vocabulary_dictize(composers,
                context)
        ckan.model.Session.commit()

        self.sysadmin_user = ckan.model.User.get('admin')
        self.normal_user = ckan.model.User.get('normal')
        if not self.sysadmin_user:
            normal_user = ckan.model.User(name=u'normal', password=u'annafan')
            sysadmin_user = ckan.model.User(name=u'admin',
                    password=u'testsysadmin')
            sysadmin_user.sysadmin = True
            ckan.model.Session.add(normal_user)
            ckan.model.Session.add(sysadmin_user)
            ckan.model.Session.commit()
            self.sysadmin_user = ckan.model.User.get('admin')
            self.normal_user = ckan.model.User.get('normal')
        self.sysadmin_apikey = self.sysadmin_user.apikey

    def clean_vocab(self):
        ckan.model.Session.execute('delete from package_tag_revision')
        ckan.model.Session.execute('delete from package_tag')
        ckan.model.Session.execute('delete from tag')
        ckan.model.Session.execute('delete from vocabulary')
        ckan.model.Session.commit()

    @classmethod
    def _post(self, url, params=None, extra_environ=None):
        if params is None:
            params = {}
        param_string = helpers.json.dumps(params)
        response = self.app.post(url, params=param_string,
                extra_environ=extra_environ)
        assert not response.errors
        return response.json

    @classmethod
    def _create_vocabulary(self, vocab_name=None, user=None):
        # Create a new vocabulary.
        params = {'name': vocab_name}
        if user:
            extra_environ = {'Authorization': str(user.apikey)}
        else:
            extra_environ = None
        response = self._post('/api/action/vocabulary_create', params=params,
                extra_environ=extra_environ)

        # Check the values of the response.
        assert response['success'] is True
        assert response['result']
        created_vocab = response['result']
        assert created_vocab['name'] == vocab_name
        assert created_vocab['id']

        # Get the list of vocabularies.
        response = self._post('/api/action/vocabulary_list')
        # Check that the vocabulary we created is in the list.
        assert response['success'] is True
        assert response['result']
        assert response['result'].count(created_vocab) == 1

        # Get the created vocabulary.
        params = {'id': created_vocab['id']}
        response = self._post('/api/action/vocabulary_show', params)
        # Check that retrieving the vocab by name gives the same result.
        by_name_params = {'id': created_vocab['name']}
        assert response == self._post('/api/action/vocabulary_show',
                by_name_params)
        # Check that it matches what we created.
        assert response['success'] is True
        assert response['result'] == created_vocab

        return created_vocab

    def _update_vocabulary(self, params, user=None):
        if user:
            extra_environ = {'Authorization': str(user.apikey)}
        else:
            extra_environ = None

        original_vocab = self._post('/api/action/vocabulary_show',
                {'id': params.get('id') or params.get('name')})['result']

        response = self._post('/api/action/vocabulary_update', params=params,
                extra_environ=extra_environ)

        # Check the values of the response.
        assert response['success'] is True
        assert response['result']
        updated_vocab = response['result']
        # id should never change.
        assert updated_vocab['id'] == original_vocab['id']
        if 'id' in params:
            assert updated_vocab['id'] == params['id']
        # name should change only if given in params.
        if 'name' in params:
            assert updated_vocab['name'] == params['name']
        else:
            assert updated_vocab['name'] == original_vocab['name']
        # tags should change only if given in params.
        if 'tags' in params:
            assert sorted([tag['name'] for tag in params['tags']]) \
                    == sorted([tag['name'] for tag in updated_vocab['tags']])
        else:
            assert updated_vocab['tags'] == original_vocab['tags']

        # Get the list of vocabularies.
        response = self._post('/api/action/vocabulary_list')
        # Check that the vocabulary we created is in the list.
        assert response['success'] is True
        assert response['result']
        assert response['result'].count(updated_vocab) == 1

        # Get the created vocabulary.
        params = {'id': updated_vocab['id']}
        response = self._post('/api/action/vocabulary_show', params)
        # Check that retrieving the vocab by name gives the same result.
        by_name_params = {'id': updated_vocab['name']}
        assert response == self._post('/api/action/vocabulary_show',
                by_name_params)
        # Check that it matches what we created.
        assert response['success'] is True
        assert response['result'] == updated_vocab

        return updated_vocab

    def _delete_vocabulary(self, vocab_id, user=None):
        if user:
            extra_environ = {'Authorization': str(user.apikey)}
        else:
            extra_environ = None
        params = {'id': vocab_id}
        response = self._post('/api/action/vocabulary_delete', params=params,
                extra_environ=extra_environ)

        # Check the values of the response.
        assert response['success'] is True
        assert response['result'] is None
        response['result']

        # Get the list of vocabularies.
        response = self._post('/api/action/vocabulary_list')
        assert response['success'] is True
        assert response['result']
        # Check that the vocabulary we deleted is not in the list.
        assert vocab_id not in [vocab['id'] for vocab in response['result']]

        # Check that the deleted vocabulary can no longer be retrieved.
        response = self.app.post('/api/action/vocabulary_show',
                params=helpers.json.dumps(params),
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=404)
        assert response.json['success'] is False

    def _list_tags(self, vocabulary=None, user=None):
        params = {}
        if vocabulary:
            params['vocabulary_id'] = vocabulary['id']
        if user:
            extra_environ = {'Authorization': str(user.apikey)}
        else:
            extra_environ = None
        response = self._post('/api/action/tag_list', params=params,
                extra_environ=extra_environ)
        assert response['success'] is True
        return response['result']

    def _create_tag(self, user, tag_name, vocabulary=None):
        tag_dict = {'name': tag_name}
        if vocabulary:
            tag_dict['vocabulary_id'] = vocabulary['id']
        if user:
            extra_environ = {'Authorization': str(user.apikey)}
        else:
            extra_environ = None
        response = self._post('/api/action/tag_create', params=tag_dict,
                extra_environ=extra_environ)
        assert response['success'] is True
        return response['result']

    def _delete_tag(self, user, tag_id_or_name, vocab_id_or_name=None):
        params = {'id': tag_id_or_name}
        if vocab_id_or_name:
            params['vocabulary_id'] = vocab_id_or_name
        if user:
            extra_environ = {'Authorization': str(user.apikey)}
        else:
            extra_environ = None
        response = self._post('/api/action/tag_delete', params=params,
                extra_environ=extra_environ)
        assert response['success'] is True
        return response['result']

    def test_vocabulary_create(self):
        '''Test adding a new vocabulary to a CKAN instance via the action
        API.

        '''
        self._create_vocabulary(vocab_name="My cool vocab",
                user=self.sysadmin_user)

    def test_vocabulary_create_with_tags(self):
        '''Test adding a new vocabulary with some tags.

        '''
        params = {'name': 'foobar'}
        tag1 = {'name': 'foo'}
        tag2 = {'name': 'bar'}
        params['tags'] = [tag1, tag2]
        response = self._post('/api/action/vocabulary_create',
                params=params,
                extra_environ={'Authorization': str(self.sysadmin_apikey)})
        assert response['success'] is True
        assert response['result']
        created_vocab = response['result']
        assert created_vocab['name'] == 'foobar'
        assert created_vocab['id']

        # Get the list of vocabularies.
        response = self._post('/api/action/vocabulary_list')
        # Check that the vocabulary we created is in the list.
        assert response['success'] is True
        assert response['result']
        assert response['result'].count(created_vocab) == 1

        # Get the created vocabulary.
        params = {'id': created_vocab['id']}
        response = self._post('/api/action/vocabulary_show', params)
        # Check that retrieving the vocab by name gives the same result.
        by_name_params = {'id': created_vocab['name']}
        assert response == self._post('/api/action/vocabulary_show',
                by_name_params)
        # Check that it matches what we created.
        assert response['success'] is True
        assert response['result'] == created_vocab

        # Get the list of tags for the vocabulary.
        tags = self._list_tags(created_vocab)
        assert len(tags) == 2
        assert tags.count('foo') == 1
        assert tags.count('bar') == 1

    def test_vocabulary_create_bad_tags(self):
        '''Test creating new vocabularies with invalid tags.

        '''
        for tags in (
                [{'id': 'xxx'}, {'name': 'foo'}],
                [{'name': 'foo'}, {'name': None}],
                [{'name': 'foo'}, {'name': ''}],
                [{'name': 'foo'}, {'name': 'f'}],
                [{'name': 'f' * 200}, {'name': 'foo'}],
                [{'name': 'Invalid!'}, {'name': 'foo'}],
                ):
            params = {'name': 'foobar', 'tags': tags}
            response = self.app.post('/api/action/vocabulary_create',
                    params=helpers.json.dumps(params),
                    extra_environ={'Authorization': str(self.sysadmin_apikey)},
                    status=409)
            assert response.json['success'] is False
            assert 'tags' in response.json['error']
            assert len(response.json['error']) == 2

    def test_vocabulary_create_none_tags(self):
        '''Test creating new vocabularies with None for 'tags'.

        '''
        params = {'name': 'foobar', 'tags': None}
        response = self.app.post('/api/action/vocabulary_create',
                params=helpers.json.dumps(params),
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=400)
        assert "Integrity Error" in response.body

    def test_vocabulary_create_empty_tags(self):
        '''Test creating new vocabularies with [] for 'tags'.

        '''
        params = {'name': 'foobar', 'tags': []}
        response = self.app.post('/api/action/vocabulary_create',
                params=helpers.json.dumps(params),
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=200)
        assert response.json['success'] is True
        assert response.json['result']
        created_vocab = response.json['result']
        assert created_vocab['name'] == 'foobar'
        assert created_vocab['id']
        assert created_vocab['tags'] == []
        params = {'id': created_vocab['id']}
        response = self._post('/api/action/vocabulary_show', params)
        assert response['success'] is True
        assert response['result'] == created_vocab
        tags = self._list_tags(created_vocab)
        assert tags == []

    def test_vocabulary_create_id(self):
        '''Test error response when user tries to supply their own ID when
        creating a vocabulary.

        '''
        params = {'id': 'xxx', 'name': 'foobar'}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_create',
                params=param_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert response.json['error']['id'] == [u'The input field id was '
            'not expected.']

    def test_vocabulary_create_no_name(self):
        '''Test error response when user tries to create a vocab without a
        name.

        '''
        params = {}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_create',
                params=param_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert response.json['error']['name'] == [u'Missing value']

    def test_vocabulary_create_invalid_name(self):
        '''Test error response when user tries to create a vocab with an
        invalid name.

        '''
        for name in (None, '', 'a', 'foobar' * 100):
            params = {'name': name}
            param_string = helpers.json.dumps(params)
            response = self.app.post('/api/action/vocabulary_create',
                    params=param_string,
                    extra_environ={'Authorization':
                        str(self.sysadmin_apikey)},
                    status=409)
            assert response.json['success'] is False
            assert response.json['error']['name']

    def test_vocabulary_create_exists(self):
        '''Test error response when user tries to create a vocab that already
        exists.

        '''
        params = {'name': self.genre_vocab['name']}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_create',
                params=param_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert response.json['error']['name'] == [u'That vocabulary name is '
            'already in use.']

    def test_vocabulary_create_not_logged_in(self):
        '''Test that users who are not logged in cannot create vocabularies.'''

        params = {'name':
            "Spam Vocabulary: SpamCo Duck Rental: Rent Your Ducks From Us!"}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_create',
                params=param_string,
                status=403)
        assert response.json['success'] is False
        assert response.json['error']['__type'] == 'Authorization Error'

    def test_vocabulary_create_not_authorized(self):
        '''Test that users who are not authorized cannot create vocabs.'''

        params = {'name': 'My Unauthorised Vocabulary'}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_create',
                params=param_string,
                extra_environ={'Authorization':
                    str(self.normal_user.apikey)},
                status=403)
        assert response.json['success'] is False
        assert response.json['error']['__type'] == 'Authorization Error'

    def test_vocabulary_update_id_only(self):
        self._update_vocabulary({'id': self.genre_vocab['id']},
                self.sysadmin_user)

    def test_vocabulary_update_id_and_same_name(self):
        self._update_vocabulary({'id': self.genre_vocab['id'],
            'name': self.genre_vocab['name']}, self.sysadmin_user)

    def test_vocabulary_update_id_and_new_name(self):
        self._update_vocabulary({'id': self.genre_vocab['id'],
            'name': 'new name'}, self.sysadmin_user)

    def test_vocabulary_update_id_and_same_tags(self):
        self._update_vocabulary({'id': self.genre_vocab['id'],
            'tags': self.genre_vocab['tags']}, self.sysadmin_user)

    def test_vocabulary_update_id_and_new_tags(self):
        tags = [
                {'name': 'new test tag one'},
                {'name': 'new test tag two'},
                {'name': 'new test tag three'},
                ]
        self._update_vocabulary({'id': self.genre_vocab['id'], 'tags': tags},
                self.sysadmin_user)

    def test_vocabulary_update_id_same_name_and_same_tags(self):
        self._update_vocabulary({'id': self.genre_vocab['id'],
            'name': self.genre_vocab['name'],
            'tags': self.genre_vocab['tags']}, self.sysadmin_user)

    def test_vocabulary_update_id_same_name_and_new_tags(self):
        tags = [
                {'name': 'new test tag one'},
                {'name': 'new test tag two'},
                {'name': 'new test tag three'},
                ]
        self._update_vocabulary({'id': self.genre_vocab['id'],
            'name': self.genre_vocab['name'],
            'tags': tags}, self.sysadmin_user)

    def test_vocabulary_update_id_new_name_and_same_tags(self):
        self._update_vocabulary({'id': self.genre_vocab['id'],
            'name': 'new name',
            'tags': self.genre_vocab['tags']}, self.sysadmin_user)

    def test_vocabulary_update_not_exists(self):
        '''Test the error response given when a user tries to update a
        vocabulary that doesn't exist.

        '''
        params = {'id': 'xxxxxxx', 'name': 'updated_name'}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_update',
                params=param_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=404)
        assert response.json['success'] is False
        assert response.json['error']['message'].startswith('Not found: ')

    def test_vocabulary_update_no_id(self):
        params = {'name': 'bagel radio'}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_update',
                params=param_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert 'id' in response.json['error']
        assert response.json['error']['id'] == 'id not in data'

    def test_vocabulary_update_not_logged_in(self):
        '''Test that users who are not logged in cannot update vocabularies.'''
        params = {'id': self.genre_vocab['id']}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_update',
                params=param_string,
                status=403)
        assert response.json['success'] is False
        assert response.json['error']['__type'] == 'Authorization Error'

    def test_vocabulary_update_with_tags(self):
        tags = [
                {'name': 'drone'},
                {'name': 'noise'},
                {'name': 'fuzz'},
                {'name': 'field recordings'},
                {'name': 'hypnagogia'},
                {'name': 'textures without rhythm'},
                ]
        self._update_vocabulary(
                {
                    'id': self.genre_vocab['id'],
                    'name': self.genre_vocab['name'],
                    'tags': tags
                },
                self.sysadmin_user)

        params = {'id': self.genre_vocab['id']}
        response = self._post('/api/action/vocabulary_show', params)
        # Check that retrieving the vocab by name gives the same result.
        assert len(response['result']['tags']) == len(tags)

    def test_vocabulary_update_not_authorized(self):
        '''Test that users who are not authorized cannot update vocabs.'''
        params = {'id': self.genre_vocab['id']}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_update',
                params=param_string,
                extra_environ={'Authorization':
                    str(self.normal_user.apikey)},
                status=403)
        assert response.json['success'] is False
        assert response.json['error']['message'] == 'Access denied'

    def test_vocabulary_update_bad_tags(self):
        '''Test updating vocabularies with invalid tags.

        '''
        apikey = str(self.sysadmin_user.apikey)

        for tags in (
                [{'id': 'xxx'}, {'name': 'foo'}],
                [{'name': 'foo'}, {'name': None}],
                [{'name': 'foo'}, {'name': ''}],
                [{'name': 'foo'}, {'name': 'f'}],
                [{'name': 'f' * 200}, {'name': 'foo'}],
                [{'name': 'Invalid!'}, {'name': 'foo'}],
                ):
            params = {'id': self.genre_vocab['name'], 'tags': tags}
            response = self.app.post('/api/action/vocabulary_update',
                    params=helpers.json.dumps(params),
                    extra_environ={'Authorization': apikey},
                    status=409)
            assert response.json['success'] is False
            assert response.json['error']['tags']

    def test_vocabulary_update_none_tags(self):
        '''Test updating vocabularies with None for 'tags'.

        '''
        params = {'id': self.genre_vocab['id'], 'tags': None}
        response = self.app.post('/api/action/vocabulary_update',
                params=helpers.json.dumps(params),
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=400)
        assert "Integrity Error" in response.body, response.body

    def test_vocabulary_update_empty_tags(self):
        '''Test updating vocabularies with [] for 'tags'.

        '''
        params = {'id': self.genre_vocab['id'], 'tags': []}
        response = self.app.post('/api/action/vocabulary_update',
                params=helpers.json.dumps(params),
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=200)
        assert response.json['success'] is True
        assert response.json['result']
        updated_vocab = response.json['result']
        assert updated_vocab['name'] == self.genre_vocab['name']
        assert updated_vocab['id'] == self.genre_vocab['id']
        assert updated_vocab['tags'] == []
        params = {'id': updated_vocab['id']}
        response = self._post('/api/action/vocabulary_show', params)
        assert response['success'] is True
        assert response['result'] == updated_vocab
        tags = self._list_tags(updated_vocab)
        assert tags == []

    def test_vocabulary_delete(self):
        self._delete_vocabulary(self.genre_vocab['id'], self.sysadmin_user)

    def test_vocabulary_delete_not_exists(self):
        '''Test the error response given when a user tries to delete a
        vocabulary that doesn't exist.

        '''
        params = {'id': 'xxxxxxx'}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_delete',
                params=param_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=404)
        assert response.json['success'] is False
        assert response.json['error']['message'].startswith('Not found: '
                'Could not find vocabulary')

    def test_vocabulary_delete_no_id(self):
        '''Test the error response given when a user tries to delete a
        vocabulary without giving the vocabulary id.

        '''
        params = {}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_delete',
                params=param_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert 'id' in response.json['error']
        assert response.json['error']['id'] == 'id not in data'

    def test_vocabulary_delete_not_logged_in(self):
        '''Test that users who are not logged in cannot delete vocabularies.'''
        params = {'id': self.genre_vocab['id']}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_delete',
                params=param_string,
                status=403)
        assert response.json['success'] is False
        assert response.json['error']['__type'] == 'Authorization Error'

    def test_vocabulary_delete_not_authorized(self):
        '''Test that users who are not authorized cannot delete vocabs.'''
        params = {'id': self.genre_vocab['id']}
        param_string = helpers.json.dumps(params)
        response = self.app.post('/api/action/vocabulary_delete',
                params=param_string,
                extra_environ={'Authorization':
                    str(self.normal_user.apikey)},
                status=403)
        assert response.json['success'] is False
        assert response.json['error']['__type'] == 'Authorization Error'

    def test_add_tag_to_vocab(self):
        '''Test that a tag can be added to and then retrieved from a vocab.'''
        vocab = self.genre_vocab
        tags_before = self._list_tags(vocab)
        tag_created = self._create_tag(self.sysadmin_user, 'noise', vocab)
        tags_after = self._list_tags(vocab)
        new_tag_names = [tag_name for tag_name in tags_after if tag_name not in
                tags_before]
        assert len(new_tag_names) == 1
        assert tag_created['name'] in new_tag_names

    def test_add_tag_no_vocab(self):
        '''Test the error response when a user tries to create a tag without
        specifying a vocab.

        '''
        tag_dict = {'name': 'noise'}
        tag_string = helpers.json.dumps(tag_dict)
        response = self.app.post('/api/action/tag_create',
                params=tag_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert response.json['error']['vocabulary_id'] == ['Missing value']

    def test_add_tag_vocab_not_exists(self):
        '''Test the error response when a user tries to add a tag to a vocab
        that doesn't exist.

        '''
        tag_dict = {'name': 'noise', 'vocabulary_id': 'does not exist'}
        tag_string = helpers.json.dumps(tag_dict)
        response = self.app.post('/api/action/tag_create',
                params=tag_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert response.json['error']['vocabulary_id'] == [
                'Tag vocabulary was not found.']

    def test_add_tag_already_added(self):
        '''Test the error response when a user tries to add a tag to a vocab
        that already has a tag with the same name.

        '''
        self.test_add_tag_to_vocab()
        vocab = self.genre_vocab
        tag_dict = {'name': 'noise', 'vocabulary_id': vocab['id']}
        tag_string = helpers.json.dumps(tag_dict)
        response = self.app.post('/api/action/tag_create',
                params=tag_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert response.json['error']['vocabulary_id'][0].startswith(
            'Tag noise already belongs to vocabulary')

    def test_add_tag_with_id(self):
        '''Test the error response when a user tries to specify the tag ID when
        adding a tag to a vocab.

        '''
        tag_dict = {
                'id': 'dsagdsgsgsd',
                'name': 'noise',
                'vocabulary_id': self.genre_vocab['id']
                }
        tag_string = helpers.json.dumps(tag_dict)
        response = self.app.post('/api/action/tag_create',
                params=tag_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert response.json['error']['id'] == [u'The input field id was not '
            'expected.']

    def test_add_tag_without_name(self):
        '''Test the error response when a user tries to create a tag without a
        name.

        '''
        tag_dict = {
                'vocabulary_id': self.genre_vocab['id']
                }
        tag_string = helpers.json.dumps(tag_dict)
        response = self.app.post('/api/action/tag_create',
                params=tag_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert response.json['error']['name'] == [u'Missing value']

    def test_add_tag_invalid_name(self):
        for name in ('Not a valid tag name!', '', None):
            tag_dict = {
                    'name': name,
                    'vocabulary_id': self.genre_vocab['id']
                    }
            tag_string = helpers.json.dumps(tag_dict)
            response = self.app.post('/api/action/tag_create',
                    params=tag_string,
                    extra_environ={'Authorization':
                        str(self.sysadmin_apikey)},
                    status=409)
            assert response.json['success'] is False
            assert response.json['error']['name']

    def test_add_tag_invalid_vocab_id(self):
        tag_dict = {
                'name': 'noise',
                'vocabulary_id': 'xxcxzczxczxc',
                }
        tag_string = helpers.json.dumps(tag_dict)
        response = self.app.post('/api/action/tag_create',
                params=tag_string,
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=409)
        assert response.json['success'] is False
        assert response.json['error']['vocabulary_id'] == [
                u'Tag vocabulary was not found.']

    def test_add_tag_not_logged_in(self):
        tag_dict = {
                'name': 'noise',
                'vocabulary_id': self.genre_vocab['id']
                }
        tag_string = helpers.json.dumps(tag_dict)
        response = self.app.post('/api/action/tag_create',
                params=tag_string,
                status=403)
        assert response.json['success'] is False
        assert response.json['error']['__type'] == 'Authorization Error'

    def test_add_tag_not_authorized(self):
        tag_dict = {
                'name': 'noise',
                'vocabulary_id': self.genre_vocab['id']
                }
        tag_string = helpers.json.dumps(tag_dict)
        response = self.app.post('/api/action/tag_create',
                params=tag_string,
                    extra_environ={'Authorization':
                        str(self.normal_user.apikey)},
                status=403)
        assert response.json['success'] is False
        assert response.json['error']['__type'] == 'Authorization Error'

    def test_add_vocab_tag_to_dataset(self):
        '''Test that a tag belonging to a vocab can be added to a dataset,
        retrieved from the dataset, and then removed from the dataset.'''

        ckan.model.repo.rebuild_db()
        self.setup()
        ckan.tests.CreateTestData.create()
        # First add a tag to the vocab.
        vocab = self.genre_vocab
        tag = self._create_tag(self.sysadmin_user, 'noise', vocab)

        # Get a package from the API.
        package = (self._post('/api/action/package_show',
            {'id': self._post('/api/action/package_list')['result'][0]})
            ['result'])

        # Add the new vocab tag to the package.
        package['tags'].append(tag)
        updated_package = self._post('/api/action/package_update',
                params={'id': package['id'], 'tags': package['tags']},
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)})['result']

        # Test that the new vocab tag was added to the package.
        tags_in_pkg = [tag_in_pkg for tag_in_pkg in updated_package['tags'] if
                tag_in_pkg['name'] == tag['name'] and
                tag_in_pkg['vocabulary_id'] == tag['vocabulary_id']]
        assert len(tags_in_pkg) == 1

        # Test that the package appears vocabulary_list.
        vocabs = self._post('/api/action/vocabulary_list')['result']
        genre_vocab = [vocab for vocab in vocabs if vocab['name'] == 'Genre']
        assert len(genre_vocab) == 1
        genre_vocab = genre_vocab[0]
        noise_tag = [tag_ for tag_ in genre_vocab['tags']
                if tag_['name'] == 'noise']
        assert len(noise_tag) == 1
        noise_tag = noise_tag[0]
        assert len([p for p in noise_tag['packages'] if
                    p['id'] == updated_package['id']]) == 1

        # Test that the tagged package appears in vocabulary_show.
        genre_vocab = self._post('/api/action/vocabulary_show',
                params={'id': genre_vocab['id']})['result']
        noise_tag = [tag_ for tag_ in genre_vocab['tags']
                if tag_['name'] == 'noise']
        assert len(noise_tag) == 1
        noise_tag = noise_tag[0]
        assert len([p for p in noise_tag['packages'] if
                    p['id'] == updated_package['id']]) == 1

        # Remove the new vocab tag from the package.
        package['tags'].remove(tag)
        updated_package = self._post('/api/action/package_update',
                params={'id': package['id'], 'tags': package['tags']},
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)})['result']

        # Test that the tag no longer appears in the list of tags for the
        # package.
        package = (self._post('/api/action/package_show',
            {'id': self._post('/api/action/package_list')['result'][0]})
            ['result'])
        tags_in_pkg = [tag_in_pkg for tag_in_pkg in package['tags'] if
                tag_in_pkg['name'] == tag['name'] and
                tag_in_pkg['vocabulary_id'] == tag['vocabulary_id']]
        assert len(tags_in_pkg) == 0

    def test_delete_tag_from_vocab(self):
        '''Test that a tag can be deleted from a vocab.'''

        ckan.model.repo.rebuild_db()
        self.setup()
        ckan.tests.CreateTestData.create()
        vocab = self.genre_vocab

        # First add some tags to the vocab.
        noise_tag = self._create_tag(self.sysadmin_user, 'noise', vocab)
        ragga_tag = self._create_tag(self.sysadmin_user, 'ragga', vocab)
        grunge_tag = self._create_tag(self.sysadmin_user, 'grunge', vocab)
        funk_tag = self._create_tag(self.sysadmin_user, 'funk', vocab)
        tags = (noise_tag, ragga_tag, grunge_tag, funk_tag)

        # Get a package from the API.
        package = (self._post('/api/action/package_show',
            {'id': self._post('/api/action/package_list')['result'][0]})
            ['result'])

        # Add the new vocab tags to the package.
        for tag in tags:
            package['tags'].append(tag)
        updated_package = self._post('/api/action/package_update',
                params={'id': package['id'], 'tags': package['tags']},
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)})['result']

        # Test that the new vocab tags were added to the package.
        for tag in tags:
            tags_in_pkg = [tag_in_pkg for tag_in_pkg in
                    updated_package['tags'] if tag_in_pkg['name'] ==
                    tag['name'] and tag_in_pkg['vocabulary_id'] ==
                    tag['vocabulary_id']]
            assert len(tags_in_pkg) == 1

        # Now delete the tags from the vocab.
        tags_before = self._list_tags(vocab)
        self._delete_tag(self.sysadmin_user, noise_tag['name'], vocab['name'])
        self._delete_tag(self.sysadmin_user, ragga_tag['id'], vocab['name'])
        self._delete_tag(self.sysadmin_user, grunge_tag['id'], vocab['id'])
        self._delete_tag(self.sysadmin_user, funk_tag['name'], vocab['id'])

        # Test that the tags no longer appear in the list of tags for the
        # vocab.
        tags_after = self._list_tags(vocab)
        assert len(tags_after) == len(tags_before) - 4
        assert tag['name'] not in tags_after
        difference = [tag_name for tag_name in tags_before if tag_name not in
                tags_after]
        assert sorted(difference) == sorted([tag['name'] for tag in tags])

        # Test that the tags no longer appear in the list of tags for the
        # package.
        package = (self._post('/api/action/package_show',
            {'id': self._post('/api/action/package_list')['result'][0]})
            ['result'])
        for tag in tags:
            tags_in_pkg = [tag_in_pkg for tag_in_pkg in package['tags'] if
                    tag_in_pkg['name'] == tag['name'] and
                    tag_in_pkg['vocabulary_id'] == tag['vocabulary_id']]
            assert len(tags_in_pkg) == 0

    def test_delete_free_tag(self):
        '''Test that a free tag can be deleted via the API, and is
        automatically removed from datasets.

        '''
        ckan.model.repo.rebuild_db()
        self.setup()
        ckan.tests.CreateTestData.create()
        # Get a package from the API.
        package = (self._post('/api/action/package_show',
            {'id': self._post('/api/action/package_list')['result'][0]})
            ['result'])
        package_id = package['id']

        # Add some new free tags to the package.
        tags = package['tags']
        tags.append({'name': 'ducks'})
        tags.append({'name': 'birds'})
        self._post('/api/action/package_update',
                params={'id': package['id'], 'tags': tags},
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)})

        # Test that the new tags appear in the list of tags.
        tags = self._list_tags()
        assert [tag for tag in tags].count('ducks') == 1
        assert [tag for tag in tags].count('birds') == 1

        # Test that the new tags appear in the package's list of tags.
        package = (self._post('/api/action/package_show',
            {'id': package_id})['result'])
        packages_tags = [tag['name'] for tag in package['tags']]
        assert [tag for tag in packages_tags].count('ducks') == 1
        assert [tag for tag in packages_tags].count('birds') == 1

        # Now delete the tags.
        self._delete_tag(self.sysadmin_user, 'ducks')
        birds_tag_id = self._post('/api/action/tag_show',
                {'id': 'birds'})['result']['id']
        self._delete_tag(self.sysadmin_user, birds_tag_id)

        # Test that the tags no longer appear in the list of tags.
        tags = self._list_tags()
        assert [tag for tag in tags].count('ducks') == 0
        assert [tag for tag in tags].count('birds') == 0

        # Test that the tags no longer appear in the package's list of tags.
        package = (self._post('/api/action/package_show',
            {'id': package_id})['result'])
        packages_tags = [tag['name'] for tag in package['tags']]
        assert [tag for tag in packages_tags].count('ducks') == 0
        assert [tag for tag in packages_tags].count('birds') == 0

    def test_delete_tag_no_id(self):
        '''Test the error response when a user tries to delete a tag without
        giving the tag id.

        '''
        vocab = self.genre_vocab
        self._create_tag(self.sysadmin_user, 'noise', vocab)

        for tag_id in ('missing', '', None):
            # Now try to delete the tag from the vocab.
            params = {'vocabulary_id': vocab['name']}
            if tag_id != 'missing':
                params['id'] = tag_id
            response = self.app.post('/api/action/tag_delete',
                    params=helpers.json.dumps(params),
                    extra_environ={'Authorization':
                        str(self.sysadmin_user.apikey)},
                    status=409)
            assert response.json['success'] is False
            assert 'id' in response.json['error']
            assert response.json['error']['id'] == 'id not in data'

    def test_delete_tag_no_vocab(self):
        '''Test the error response when a user tries to delete a vocab tag
        without giving the vocab name.

        '''
        vocab = self.genre_vocab
        tag = self._create_tag(self.sysadmin_user, 'noise', vocab)

        # Now try to delete the tag from the vocab.
        for vocab_name in ('', None, 'missing'):
            params = {'id': tag['name']}
            if vocab_name != 'missing':
                params['vocabulary_id'] = vocab_name
            response = self.app.post('/api/action/tag_delete',
                    params=helpers.json.dumps(params),
                    extra_environ={'Authorization':
                        str(self.sysadmin_user.apikey)},
                    status=404)
            assert response.json['success'] is False
            msg = response.json['error']['message']
            assert msg == u'Not found: Could not find tag "{0}"'.format(
                    tag['name']), msg

    def test_delete_tag_not_exists(self):
        '''Test the error response when a user tries to delete a from a vocab
        but there is no tag with that name in the vocab.

        '''
        vocab = self.genre_vocab
        self._create_tag(self.sysadmin_user, 'noise', vocab)

        params = {'id': 'nonexistent',
                'vocabulary_id': self.genre_vocab['name']}
        response = self.app.post('/api/action/tag_delete',
                params=helpers.json.dumps(params),
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=404)
        assert response.json['success'] is False
        msg = response.json['error']['message']
        assert msg == u'Not found: Could not find tag "%s"' % 'nonexistent', \
                msg

    def test_delete_tag_vocab_not_exists(self):
        '''Test the error response when a user tries to delete a from a vocab
        but there is no vocab with that name.

        '''
        vocab = self.genre_vocab
        tag = self._create_tag(self.sysadmin_user, 'noise', vocab)

        params = {'id': tag['name'],
                'vocabulary_id': 'nonexistent'}
        response = self.app.post('/api/action/tag_delete',
                params=helpers.json.dumps(params),
                extra_environ={'Authorization':
                    str(self.sysadmin_user.apikey)},
                status=404)
        assert response.json['success'] is False
        msg = response.json['error']['message']
        assert msg == u"Not found: could not find vocabulary 'nonexistent'", \
                msg

    def test_delete_tag_invalid_tag(self):
        '''Test the error response when a user tries to delete a tag but gives
        an invalid tag name.

        '''
        vocab = self.genre_vocab
        self._create_tag(self.sysadmin_user, 'noise', vocab)

        for tag_name in ('Invalid!', ' '):
            params = {'id': tag_name,
                    'vocabulary_id': self.genre_vocab['name']}
            response = self.app.post('/api/action/tag_delete',
                    params=helpers.json.dumps(params),
                    extra_environ={'Authorization':
                        str(self.sysadmin_user.apikey)},
                    status=404)
            assert response.json['success'] is False
            msg = response.json['error']['message']
            assert msg == u'Not found: Could not find tag "%s"' % tag_name, msg

    def test_delete_tag_invalid_vocab(self):
        '''Test the error response when a user tries to delete a tag but gives
        an invalid vocab name.

        '''
        vocab = self.genre_vocab
        tag = self._create_tag(self.sysadmin_user, 'noise', vocab)

        for vocab_name in ('Invalid!', ' '):
            params = {'id': tag['name'], 'vocabulary_id': vocab_name}
            response = self.app.post('/api/action/tag_delete',
                    params=helpers.json.dumps(params),
                    extra_environ={'Authorization':
                        str(self.sysadmin_user.apikey)},
                    status=404)
            assert response.json['success'] is False
            msg = response.json['error']['message']
            assert msg == u"Not found: could not find vocabulary '%s'" \
                    % vocab_name, msg

    def test_delete_tag_not_logged_in(self):
        vocab = self.genre_vocab
        tag = self._create_tag(self.sysadmin_user, 'noise', vocab)

        params = {'id': tag['name'],
                'vocabulary_id': self.genre_vocab['name']}
        response = self.app.post('/api/action/tag_delete',
                params=helpers.json.dumps(params),
                status=403)
        assert response.json['success'] is False
        error = response.json['error']['__type']
        assert error == u"Authorization Error", error

    def test_delete_tag_not_authorized(self):
        vocab = self.genre_vocab
        tag = self._create_tag(self.sysadmin_user, 'noise', vocab)

        params = {'id': tag['name'],
                'vocabulary_id': self.genre_vocab['name']}
        response = self.app.post('/api/action/tag_delete',
                params=helpers.json.dumps(params),
                extra_environ={'Authorization':
                    str(self.normal_user.apikey)},
                status=403)
        assert response.json['success'] is False
        msg = response.json['error']['__type']
        assert msg == u"Authorization Error"

########NEW FILE########
__FILENAME__ = test_activity
'''Functional tests for the public activity streams API.

This module tests the contents of the various public activity streams:
use activity streams, dataset activity streams, group activity streams, etc.

This module _does not_ test the private user dashboard activity stream (which
is different because the contents depend on what the user is following), that
is tested in test_dashboard.py.

'''
import datetime
import logging
logger = logging.getLogger(__name__)

import pylons.test
from pylons import config
from paste.deploy.converters import asbool
import paste.fixture
from nose import SkipTest
from ckan.common import json
import ckan.tests as tests


##def package_update(context, data_dict):
##    # These tests call package_update directly which is really bad
##    # setting api_version in context make things seem like the api key
##    # is ok etc
##    context['api_version'] = 3
##    context['ignore_auth'] = True
##    return _package_update(context, data_dict)
##
##def package_create(context, data_dict):
##    # These tests call package_update directly which is really bad
##    # setting api_version in context make things seem like the api key
##    # is ok etc
##    context['api_version'] = 3
##    context['ignore_auth'] = True
##    return _package_create(context, data_dict)
def package_show(app, data_dict, apikey=None):
    if apikey:
        extra_environ = {'Authorization': str(apikey)}
    else:
        extra_environ = None
    response = app.post('/api/action/package_show', json.dumps(data_dict),
            extra_environ=extra_environ)
    response_dict = json.loads(response.body)
    assert response_dict['success'] is True
    package = response_dict['result']
    return package


def package_list(app, data_dict=None, apikey=None):
    if data_dict is None:
        data_dict = {}
    if apikey:
        extra_environ = {'Authorization': str(apikey)}
    else:
        extra_environ = None
    response = app.post('/api/action/package_list',
            json.dumps(data_dict), extra_environ=extra_environ)
    response_dict = json.loads(response.body)
    assert response_dict['success'] is True
    packages = response_dict['result']
    return packages


def group_list(app, data_dict=None, apikey=None):
    if data_dict is None:
        data_dict = {}
    if 'all_fields' not in data_dict:
        data_dict['all_fields'] = True
    if apikey:
        extra_environ = {'Authorization': str(apikey)}
    else:
        extra_environ = None
    response = app.post('/api/action/group_list',
            json.dumps(data_dict), extra_environ=extra_environ)
    response_dict = json.loads(response.body)
    assert response_dict['success'] is True
    groups = response_dict['result']
    return groups


def package_update(app, data_dict, apikey=None):
    if apikey:
        extra_environ = {'Authorization': str(apikey)}
    else:
        extra_environ = None
    response = app.post('/api/action/package_update',
            json.dumps(data_dict), extra_environ=extra_environ)
    response_dict = json.loads(response.body)
    assert response_dict['success'] is True
    updated_package = response_dict['result']
    return updated_package


def group_update(app, data_dict, apikey=None):
    if apikey:
        extra_environ = {'Authorization': str(apikey)}
    else:
        extra_environ = None
    response = app.post('/api/action/group_update',
            json.dumps(data_dict), extra_environ=extra_environ)
    response_dict = json.loads(response.body)
    assert response_dict['success'] is True
    updated_group = response_dict['result']
    return updated_group


def datetime_from_string(s):
    '''Return a standard datetime.datetime object initialised from a string in
    the same format used for timestamps in dictized activities (the format
    produced by datetime.datetime.isoformat())

    '''
    return datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%S.%f')


def make_resource():
    '''Return a test resource in dictionary form.'''
    return {
            'url': 'http://www.example.com',
            'description': 'example resource description',
            'format': 'txt',
            'name': 'example resource',
            }


def make_package(name=None):
    '''Return a test package in dictionary form.'''
    if name is None:
        name = "test_package"

    # A package with no resources, tags, extras or groups.
    pkg = {
        'name': name,
        'title': 'My Test Package',
        'author': 'test author',
        'author_email': 'test_author@test_author.com',
        'maintainer': 'test maintainer',
        'maintainer_email': 'test_maintainer@test_maintainer.com',
        'notes': 'some test notes',
        'url': 'www.example.com',
        }

    # Add some resources to the package.
    res1 = {
            'url': 'http://www.example-resource.info',
            'description': 'an example resource description',
            'format': 'HTML',
            'name': 'an example resource',
        }
    res2 = {
            'url': 'http://www.example-resource2.info',
            'description': 'another example resource description',
            'format': 'PDF',
            'name': 'another example resource',
        }
    pkg['resources'] = [res1, res2]

    # Add some tags to the package.
    tag1 = {'name': 'a_test_tag'}
    tag2 = {'name': 'another_test_tag'}
    pkg['tags'] = [tag1, tag2]

    # Add the package to a group.
    pkg['groups'] = [{'name': 'roger'}]

    return pkg


def find_new_activities(before, after):
    return [activity for activity in after if activity not in before]


class TestActivity:
    @classmethod
    def setup_class(self):
        if not asbool(config.get('ckan.activity_streams_enabled', 'true')):
            raise SkipTest('Activity streams not enabled')
        import ckan
        import ckan.model as model
        ckan.tests.CreateTestData.create()
        sysadmin_user = model.User.get('testsysadmin')
        self.sysadmin_user = {
                'id': sysadmin_user.id,
                'apikey': sysadmin_user.apikey,
                'name': sysadmin_user.name,
                }
        normal_user = model.User.get('annafan')
        self.normal_user = {
                'id': normal_user.id,
                'apikey': normal_user.apikey,
                'name': normal_user.name,
                }
        warandpeace = model.Package.get('warandpeace')
        self.warandpeace = {
                'id': warandpeace.id,
                }
        annakarenina = model.Package.get('annakarenina')
        self.annakarenina = {
                'id': annakarenina.id,
                }
        self.users = [self.sysadmin_user, self.normal_user]
        self.app = paste.fixture.TestApp(pylons.test.pylonsapp)

    @classmethod
    def teardown_class(self):
        import ckan.model as model
        model.repo.rebuild_db()

    def user_activity_stream(self, user_id, apikey=None):
        if apikey:
            extra_environ = {'Authorization': str(apikey)}
        else:
            extra_environ = None
        response = self.app.get("/api/2/rest/user/%s/activity" % user_id,
                extra_environ=extra_environ)
        return json.loads(response.body)

    def package_activity_stream(self, package_id, apikey=None):
        if apikey:
            extra_environ = {'Authorization': str(apikey)}
        else:
            extra_environ = None
        print '@@@@@@@@', extra_environ
        response = self.app.get("/api/2/rest/dataset/%s/activity" % package_id,
                extra_environ=extra_environ)
        return json.loads(response.body)

    def group_activity_stream(self, group_id, apikey=None):
        if apikey:
            extra_environ = {'Authorization': str(apikey)}
        else:
            extra_environ = None
        response = self.app.get("/api/2/rest/group/%s/activity" % group_id,
                extra_environ=extra_environ)
        return json.loads(response.body)

    def recently_changed_datasets_stream(self, apikey=None):
        if apikey:
            extra_environ = {'Authorization': str(apikey)}
        else:
            extra_environ = None
        response = self.app.post(
                '/api/action/recently_changed_packages_activity_list',
                params=json.dumps({}),
                extra_environ=extra_environ,
                status=200)
        assert response.json['success'] is True
        activities = response.json['result']
        return activities

    def activity_details(self, activity):
        response = self.app.get(
                "/api/2/rest/activity/%s/details" % activity['id'])
        return json.loads(response.body)

    def record_details(self, user_id, package_id=None, group_ids=None,
            apikey=None):
        details = {}
        details['user activity stream'] = self.user_activity_stream(user_id,
                apikey)

        if package_id is not None:
            details['package activity stream'] = (
                    self.package_activity_stream(package_id, apikey))

        if group_ids is not None:
            details['group activity streams'] = {}
            for group_id in group_ids:
                details['group activity streams'][group_id] = (
                    self.group_activity_stream(group_id, apikey))

        details['recently changed datasets stream'] = \
                self.recently_changed_datasets_stream(apikey)

        details['time'] = datetime.datetime.now()
        return details

    def _create_package(self, user, name=None):
        if user:
            user_id = user['id']
            apikey = user['apikey']
        else:
            user_id = 'not logged in'
            apikey = None

        before = self.record_details(user_id, apikey=apikey)

        # Create a new package.
        request_data = make_package(name)
        before = self.record_details(user_id=user_id,
                group_ids=[group['name'] for group in request_data['groups']],
                apikey=apikey)
        extra_environ = {'Authorization': str(user['apikey'])}
        response = self.app.post('/api/action/package_create',
                json.dumps(request_data), extra_environ=extra_environ)
        response_dict = json.loads(response.body)
        assert response_dict['success'] is True
        package_created = response_dict['result']

        after = self.record_details(user_id=user_id,
            package_id=package_created['id'],
            group_ids=[group['name'] for group in package_created['groups']],
            apikey=apikey)

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's activity stream.
        pkg_new_activities = after['package activity stream']
        assert pkg_new_activities == [activity]

        # The same new activity should appear in the recently changed datasets
        # stream.
        new_rcd_activities = find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream'])
        assert new_rcd_activities == [activity]

        # The same new activity should appear in the activity streams of the
        # package's groups.
        for group_dict in package_created['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert [activity['id'] for activity in grp_new_activities] == [
                    activity['id']]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == package_created['id'], \
            str(activity['object_id'])
        assert activity['user_id'] == user_id, str(activity['user_id'])
        assert activity['activity_type'] == 'new package', \
            str(activity['activity_type'])
        if 'id' not in activity:
            assert False, "activity object should have an id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity object should have a revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert timestamp >= before['time'] and timestamp <= \
            after['time'], str(activity['timestamp'])

        details = self.activity_details(activity)
        # There should be five activity details: one for the package itself,
        # one for each of its two resources, and one for each of its two tags.

        assert len(details) == 5, "There should be five activity details."

        detail_ids = [detail['object_id'] for detail in details]
        assert detail_ids.count(package_created['id']) == 1, (
            "There should be one activity detail for the package itself.")
        for resource in package_created['resources']:
            assert detail_ids.count(resource['id']) == 1, (
                "There should be one activity detail for each of the "
                "package's resources")

        for detail in details:
            assert detail['activity_id'] == activity['id'], \
                str(detail['activity_id'])

            if detail['object_id'] == package_created['id']:
                assert detail['activity_type'] == "new", (
                    str(detail['activity_type']))
                assert detail['object_type'] == "Package", \
                    str(detail['object_type'])

            elif (detail['object_id'] in
                [resource['id'] for resource in package_created['resources']]):
                assert detail['activity_type'] == "new", (
                    str(detail['activity_type']))
                assert detail['object_type'] == "Resource", (
                    str(detail['object_type']))

            else:
                assert detail['activity_type'] == "added", (
                    str(detail['activity_type']))
                assert detail['object_type'] == "tag", (
                    str(detail['object_type']))

    def _add_resource(self, package, user):
        if user:
            user_id = user['id']
            apikey = user['apikey']
        else:
            user_id = 'not logged in'
            apikey = None

        before = self.record_details(user_id, package['id'],
                [group['name'] for group in package['groups']], apikey=apikey)

        resource_ids_before = [resource['id'] for resource in
                package['resources']]

        # Create a new resource.
        resources = package['resources']
        resources.append(make_resource())
        updated_package = package_update(self.app, package, user['apikey'])

        after = self.record_details(user_id, package['id'],
                [group['name'] for group in package['groups']], apikey=apikey)
        resource_ids_after = [resource['id'] for resource in
                updated_package['resources']]
        assert len(resource_ids_after) == len(resource_ids_before) + 1

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's activity stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # The same new activity should appear in the recently changed datasets
        # stream.
        assert find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream']) \
                        == user_new_activities

        # If the package has any groups, the same new activity should appear
        # in the activity stream of each group.
        for group_dict in package['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert grp_new_activities == [activity]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == updated_package['id'], \
            str(activity['object_id'])
        assert activity['user_id'] == user_id, str(activity['user_id'])
        assert activity['activity_type'] == 'changed package', \
            str(activity['activity_type'])
        if 'id' not in activity:
            assert False, "activity object should have an id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity object should have a revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert (timestamp >= before['time'] and
                timestamp <= after['time']), str(activity['timestamp'])

        # Test for the presence of a correct activity detail item.
        details = self.activity_details(activity)
        assert len(details) == 1, [(detail['activity_type'],
            detail['object_type']) for detail in details]
        detail = details[0]
        assert detail['activity_id'] == activity['id'], \
            str(detail['activity_id'])
        new_resource_ids = [id for id in resource_ids_after if id not in
            resource_ids_before]
        assert len(new_resource_ids) == 1
        new_resource_id = new_resource_ids[0]
        assert detail['object_id'] == new_resource_id, (
            str(detail['object_id']))
        assert detail['object_type'] == "Resource", (
            str(detail['object_type']))
        assert detail['activity_type'] == "new", (
            str(detail['activity_type']))

    def _delete_extra(self, package_dict, user):
        if user:
            user_id = user['id']
            apikey = user['apikey']
        else:
            user_id = 'not logged in'
            apikey = None

        before = self.record_details(user_id, package_dict['id'],
                [group['name'] for group in package_dict['groups']],
                apikey=apikey)

        extras_before = list(package_dict['extras'])
        assert len(extras_before) > 0, (
                "Can't update an extra if the package doesn't have any")

        # Update the package's first extra.
        del package_dict['extras'][0]
        updated_package = package_update(self.app, package_dict,
                user['apikey'])

        after = self.record_details(user_id, package_dict['id'],
                [group['name'] for group in package_dict['groups']],
                apikey=apikey)
        extras_after = updated_package['extras']
        assert len(extras_after) == len(extras_before) - 1, (
                "%s != %s" % (len(extras_after), len(extras_before) - 1))

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's activity stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # The same new activity should appear in the recently changed datasets
        # stream.
        assert find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream']) \
                        == user_new_activities

        # If the package has any groups, the same new activity should appear
        # in the activity stream of each group.
        for group_dict in package_dict['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert grp_new_activities == [activity]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == updated_package['id'], \
            str(activity['object_id'])
        assert activity['user_id'] == user_id, str(activity['user_id'])
        assert activity['activity_type'] == 'changed package', \
            str(activity['activity_type'])
        if 'id' not in activity:
            assert False, "activity object should have an id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity object should have a revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert (timestamp >= before['time'] and
                timestamp <= after['time']), str(activity['timestamp'])

        # Test for the presence of a correct activity detail item.
        details = self.activity_details(activity)
        assert len(details) == 1, (
                "There should be 1 activity detail but found %s"
                % len(details))
        detail = details[0]
        assert detail['activity_id'] == activity['id'], \
            str(detail['activity_id'])
        deleted_extras = [extra for extra in extras_before if extra not in
                extras_after]
        assert len(deleted_extras) == 1, "%s != 1" % len(deleted_extras)
        deleted_extra = deleted_extras[0]
        assert detail['object_type'] == "PackageExtra", (
            str(detail['object_type']))
        assert detail['activity_type'] == "deleted", (
            str(detail['activity_type']))

    def _update_extra(self, package_dict, user):
        if user:
            user_id = user['id']
            apikey = user['apikey']
        else:
            user_id = 'not logged in'
            apikey=None

        before = self.record_details(user_id, package_dict['id'],
                [group['name'] for group in package_dict['groups']],
                apikey=apikey)

        import copy
        extras_before = copy.deepcopy(package_dict['extras'])
        assert len(extras_before) > 0, (
                "Can't update an extra if the package doesn't have any")

        # Update the package's first extra.
        if package_dict['extras'][0]['value'] != '"edited"':
            package_dict['extras'][0]['value'] = '"edited"'
        else:
            assert package_dict['extras'][0]['value'] != '"edited again"'
            package_dict['extras'][0]['value'] = '"edited again"'
        updated_package = package_update(self.app, package_dict,
                user['apikey'])

        after = self.record_details(user_id, package_dict['id'],
                [group['name'] for group in package_dict['groups']],
                apikey=apikey)
        extras_after = updated_package['extras']
        assert len(extras_after) == len(extras_before), (
                "%s != %s" % (len(extras_after), len(extras_before)))

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's activity stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # The same new activity should appear in the recently changed datasets
        # stream.
        assert find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream']) \
                        == user_new_activities

        # If the package has any groups, the same new activity should appear
        # in the activity stream of each group.
        for group_dict in package_dict['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert grp_new_activities == [activity]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == updated_package['id'], \
            str(activity['object_id'])
        assert activity['user_id'] == user_id, str(activity['user_id'])
        assert activity['activity_type'] == 'changed package', \
            str(activity['activity_type'])
        if 'id' not in activity:
            assert False, "activity object should have an id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity object should have a revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert (timestamp >= before['time'] and
                timestamp <= after['time']), str(activity['timestamp'])

        # Test for the presence of a correct activity detail item.
        details = self.activity_details(activity)
        assert len(details) == 1, (
                "There should be 1 activity detail but found %s"
                % len(details))
        detail = details[0]
        assert detail['activity_id'] == activity['id'], \
            str(detail['activity_id'])
        new_extras = [extra for extra in extras_after if extra not in
                extras_before]
        assert len(new_extras) == 1, "%s != 1" % len(new_extras)
        new_extra = new_extras[0]
        assert detail['object_type'] == "PackageExtra", (
            str(detail['object_type']))
        assert detail['activity_type'] == "changed", (
            str(detail['activity_type']))

    def _add_extra(self, package_dict, user, key=None):
        if key is None:
            key = 'quality'
        if user:
            user_id = user['id']
            apikey = user['apikey']
        else:
            user_id = 'not logged in'
            apikey = None

        before = self.record_details(user_id, package_dict['id'],
                [group['name'] for group in package_dict['groups']],
                apikey=apikey)

        # Make a copy of the package's extras before we add a new extra,
        # so we can compare the extras before and after updating the package.
        extras_before = list(package_dict['extras'])

        # Create a new extra.
        extras = package_dict['extras']
        extras.append({'key': key, 'value': '10000'})
        updated_package = package_update(self.app, package_dict,
                user['apikey'])

        after = self.record_details(user_id, package_dict['id'],
                [group['name'] for group in package_dict['groups']],
                apikey=apikey)
        extras_after = updated_package['extras']
        assert len(extras_after) == len(extras_before) + 1, (
                "%s != %s" % (len(extras_after), len(extras_before) + 1))

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's activity stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # The same new activity should appear in the recently changed datasets
        # stream.
        assert find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream']) \
                        == user_new_activities

        # If the package has any groups, the same new activity should appear
        # in the activity stream of each group.
        for group_dict in package_dict['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert grp_new_activities == [activity]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == updated_package['id'], \
            str(activity['object_id'])
        assert activity['user_id'] == user_id, str(activity['user_id'])
        assert activity['activity_type'] == 'changed package', \
            str(activity['activity_type'])
        if 'id' not in activity:
            assert False, "activity object should have an id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity object should have a revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert (timestamp >= before['time'] and
                timestamp <= after['time']), str(activity['timestamp'])

        # Test for the presence of a correct activity detail item.
        details = self.activity_details(activity)
        assert len(details) == 1, (
                "There should be 1 activity detail but found %s"
                % len(details))
        detail = details[0]
        assert detail['activity_id'] == activity['id'], \
            str(detail['activity_id'])
        new_extras = [extra for extra in extras_after if extra not in
                extras_before]
        assert len(new_extras) == 1, "%s != 1" % len(new_extras)
        new_extra = new_extras[0]
        assert detail['object_type'] == "PackageExtra", (
            str(detail['object_type']))
        assert detail['activity_type'] == "new", (
            str(detail['activity_type']))

    def _create_activity(self, user, package, params):
        before = self.record_details(user['id'], package['id'],
                apikey=user['apikey'])

        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])})
        assert response.json['success'] is True

        after = self.record_details(user['id'], package['id'],
                apikey=user['apikey'])

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's activity stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == params['object_id'], (
            str(activity['object_id']))
        assert activity['user_id'] == params['user_id'], (
            str(activity['user_id']))
        assert activity['activity_type'] == params['activity_type'], (
            str(activity['activity_type']))
        if 'id' not in activity:
            assert False, "activity object has no id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity has no revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert (timestamp >= before['time'] and
                timestamp <= after['time']), str(activity['timestamp'])

    def _delete_group(self, group, user):
        """
        Delete the given group and test that the correct activity stream
        item and detail are emitted.

        """
        before = self.record_details(user['id'], group_ids=[group['id']],
                apikey=user['apikey'])

        # Deleted the group.
        group_dict = {'id': group['id'], 'state': 'deleted'}
        group_update(self.app, group_dict, user['apikey'])

        after = self.record_details(user['id'], group_ids=[group['id']],
                apikey=user['apikey'])

        # Find the new activity.
        new_activities = find_new_activities(before['user activity stream'],
            after['user activity stream'])
        assert len(new_activities) == 1, ("There should be 1 new activity in "
            "the user's activity stream, but found %i" % len(new_activities))
        activity = new_activities[0]

        assert find_new_activities(
                before["group activity streams"][group['id']],
                after['group activity streams'][group['id']]) == \
                        new_activities, ("The same activity should also "
                        "appear in the group's activity stream.")

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == group['id'], str(activity['object_id'])
        assert activity['user_id'] == user['id'], str(activity['user_id'])
        assert activity['activity_type'] == 'deleted group', \
            str(activity['activity_type'])
        if 'id' not in activity:
            assert False, "activity object has no id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity has no revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert timestamp >= before['time'] and timestamp <= after['time'], \
            str(activity['timestamp'])

    def _update_group(self, group, user):
        """
        Update the given group and test that the correct activity stream
        item and detail are emitted.

        """
        before = self.record_details(user['id'], group_ids=[group['id']],
                apikey=user['apikey'])

        # Update the group.
        group_dict = {'id': group['id'], 'title': 'edited'}
        group_update(self.app, group_dict, user['apikey'])

        after = self.record_details(user['id'], group_ids=[group['id']],
                apikey=user['apikey'])

        # Find the new activity.
        new_activities = find_new_activities(before['user activity stream'],
            after['user activity stream'])
        assert len(new_activities) == 1, ("There should be 1 new activity in "
            "the user's activity stream, but found %i" % len(new_activities))
        activity = new_activities[0]

        assert find_new_activities(
                before["group activity streams"][group['id']],
                after['group activity streams'][group['id']]) == \
                        new_activities, ("The same activity should also "
                        "appear in the group's activity stream.")

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == group['id'], str(activity['object_id'])
        assert activity['user_id'] == user['id'], str(activity['user_id'])
        assert activity['activity_type'] == 'changed group', \
            str(activity['activity_type'])
        if 'id' not in activity:
            assert False, "activity object has no id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity has no revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert timestamp >= before['time'] and timestamp <= after['time'], \
            str(activity['timestamp'])

    def _delete_resources(self, package):
        """
        Remove all resources (if any) from the given package, and test that
        correct activity item and detail items are emitted.

        """
        before = self.record_details(self.normal_user['id'], package['id'],
                [group['name'] for group in package['groups']],
                apikey=self.normal_user['apikey'])

        num_resources = len(package['resources'])
        assert num_resources > 0, \
                "Cannot delete resources if there aren't any."
        resource_ids = [resource['id'] for resource in package['resources']]

        package['resources'] = []
        package_update(self.app, package, self.normal_user['apikey'])

        after = self.record_details(self.normal_user['id'], package['id'],
                [group['name'] for group in package['groups']],
                apikey=self.normal_user['apikey'])

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's activity stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # The same new activity should appear in the recently changed datasets
        # stream.
        assert find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream']) \
                        == user_new_activities

        # If the package has any groups, the same new activity should appear
        # in the activity stream of each group.
        for group_dict in package['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert grp_new_activities == [activity]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == package['id'], (
            str(activity['object_id']))
        assert activity['user_id'] == self.normal_user['id'], (
            str(activity['user_id']))
        assert activity['activity_type'] == 'changed package', (
            str(activity['activity_type']))
        if 'id' not in activity:
            assert False, "activity object has no id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity has no revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert timestamp >= before['time'], str(activity['timestamp'])
        assert timestamp <= after['time'], str(activity['timestamp'])

        # Test for the presence of correct activity detail items.
        details = self.activity_details(activity)
        assert len(details) == num_resources
        for detail in details:
            assert detail['activity_id'] == activity['id'], (
                "activity_id should be %s but is %s"
                % (activity['id'], detail['activity_id']))
            assert detail['object_id'] in resource_ids, (
                str(detail['object_id']))
            assert detail['object_type'] == "Resource", (
                str(detail['object_type']))
            assert detail['activity_type'] == "deleted", (
                str(detail['activity_type']))

    def _update_package(self, package, user):
        """
        Update the given package and test that the correct activity stream
        item and detail are emitted.

        """
        if user:
            user_id = user['id']
            apikey = user['apikey']
        else:
            user_id = 'not logged in'
            apikey = None

        before = self.record_details(user_id, package['id'], apikey=apikey)

        # Update the package.
        if package['title'] != 'edited':
            package['title'] = 'edited'
        else:
            assert package['title'] != 'edited again'
            package['title'] = 'edited again'
        package_update(self.app, package, user['apikey'])

        after = self.record_details(user_id, package['id'], apikey=apikey)

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's activity stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # The same new activity should appear in the recently changed datasets
        # stream.
        assert find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream']) \
                        == user_new_activities

        # If the package has any groups, the same new activity should appear
        # in the activity stream of each group.
        for group_dict in package['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert grp_new_activities == [activity]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == package['id'], (
            str(activity['object_id']))
        assert activity['user_id'] == user_id, str(activity['user_id'])
        assert activity['activity_type'] == 'changed package', (
            str(activity['activity_type']))
        if 'id' not in activity:
            assert False, "activity object has no id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity has no revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert (timestamp >= before['time'] and
                timestamp <= after['time']), str(activity['timestamp'])

        # Test for the presence of a correct activity detail item.
        details = self.activity_details(activity)
        assert len(details) == 1
        detail = details[0]
        assert detail['activity_id'] == activity['id'], \
            str(detail['activity_id'])
        assert detail['object_id'] == package['id'], str(detail['object_id'])
        assert detail['object_type'] == "Package", (
            str(detail['object_type']))
        assert detail['activity_type'] == "changed", (
            str(detail['activity_type']))

    def _update_resource(self, package, resource, user):
        """
        Update the given resource and test that the correct activity stream
        item and detail are emitted.

        """
        if user:
            user_id = user['id']
            apikey = user['apikey']
        else:
            user_id = 'not logged in'
            apikey = None

        before = self.record_details(user_id, package['id'], apikey=apikey)

        # Update the resource.
        resource['name'] = 'edited'
        package_update(self.app, package)

        after = self.record_details(user_id, package['id'], apikey=apikey)

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's activity stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # The same new activity should appear in the recently changed datasets
        # stream.
        assert find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream']) \
                        == user_new_activities

        # If the package has any groups, the same new activity should appear
        # in the activity stream of each group.
        for group_dict in package['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert grp_new_activities == [activity]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == package['id'], (
            str(activity['object_id']))
        assert activity['user_id'] == user_id, str(activity['user_id'])
        assert activity['activity_type'] == 'changed package', (
            str(activity['activity_type']))
        if not activity['id']:
            assert False, "activity object has no id value"
        # TODO: Test for the _correct_ revision_id value.
        if not activity['revision_id']:
            assert False, "activity has no revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert (timestamp >= before['time'] and
                timestamp <= after['time']), str(activity['timestamp'])

        # Test for the presence of a correct activity detail item.
        details = self.activity_details(activity)
        assert len(details) == 1
        detail = details[0]
        assert detail['activity_id'] == activity['id'], (
            str(detail['activity_id']))
        assert detail['object_id'] == resource.id, str(detail['object_id'])
        assert detail['object_type'] == "Resource", (
            str(detail['object_type']))
        assert detail['activity_type'] == "changed", (
            str(detail['activity_type']))

    def _delete_package(self, package):
        """
        Delete the given package and test that the correct activity stream
        item and detail are emitted.

        """
        before = self.record_details(self.sysadmin_user['id'], package['id'],
                apikey=self.sysadmin_user['apikey'])

        # Delete the package.
        package_dict = {'id': package['id']}
        response = self.app.post('/api/action/package_delete',
            json.dumps(package_dict),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])})
        response_dict = json.loads(response.body)
        assert response_dict['success'] is True

        after = self.record_details(self.sysadmin_user['id'], package['id'],
                apikey=self.sysadmin_user['apikey'])

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # The same new activity should appear in the recently changed datasets
        # stream.
        assert find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream']) \
                        == user_new_activities

        # If the package has any groups, the same new activity should appear
        # in the activity stream of each group.
        for group_dict in package['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert grp_new_activities == [activity]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == package['id'], (
                str(activity['object_id']))
        assert activity['user_id'] == self.sysadmin_user['id'], (
            str(activity['user_id']))
        assert activity['activity_type'] == 'deleted package', (
            str(activity['activity_type']))
        if 'id' not in activity:
            assert False, "activity object has no id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity has no revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert (timestamp >= before['time'] and
                timestamp <= after['time']), str(activity['timestamp'])

        # Test for the presence of a correct activity detail item.
        details = self.activity_details(activity)
        assert len(details) == 1
        detail = details[0]
        assert detail['activity_id'] == activity['id'], \
            str(detail['activity_id'])
        assert detail['object_id'] == package['id'], str(detail['object_id'])
        assert detail['object_type'] == "Package", (
            str(detail['object_type']))
        assert detail['activity_type'] == "deleted", (
            str(detail['activity_type']))

    def test_01_delete_resources(self):
        """
        Test deleted resource activity stream.

        Test that correct activity stream item and detail items are created
        when resources are deleted from packages.

        """
        packages_with_resources = []
        for package_name in package_list(self.app):
            package_dict = package_show(self.app, {'id': package_name})
            if len(package_dict['resources']) > 0:
                packages_with_resources.append(package_dict)
        assert len(packages_with_resources) > 0, \
                "Need some packages with resources to test deleting resources."
        for package in packages_with_resources:
            self._delete_resources(package)

    def test_01_update_group(self):
        """
        Test updated group activity stream.

        Test that correct activity stream item and detail items are created
        when groups are updated.

        """
        for group in group_list(self.app):
            self._update_group(group, user=self.sysadmin_user)

    def test_01_remove_tag(self):
        """
        Test remove tag activity.

        If a package is updated by removing one tag from it, a
        'changed package' activity with a single 'removed tag' activity detail
        should be emitted.

        """
        # Get a package.
        user = self.normal_user
        pkg_name = u"warandpeace"
        pkg_dict = package_show(self.app, {'id': pkg_name}, user['apikey'])

        # Remove one tag from the package.
        assert len(pkg_dict['tags']) >= 1, ("The package has to have at least"
                " one tag to test removing a tag.")
        before = self.record_details(user['id'], pkg_dict['id'],
                [group['name'] for group in pkg_dict['groups']],
                apikey=user['apikey'])
        data_dict = {
            'id': pkg_dict['id'],
            'tags': pkg_dict['tags'][0:-1],
            }
        package_update(self.app, data_dict, user['apikey'])
        after = self.record_details(user['id'], pkg_dict['id'],
                [group['name'] for group in pkg_dict['groups']],
                apikey=user['apikey'])

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # The same new activity should appear in the recently changed datasets
        # stream.
        assert find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream']) \
                        == user_new_activities

        # If the package has any groups, the same new activity should appear
        # in the activity stream of each group.
        for group_dict in pkg_dict['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert grp_new_activities == [activity]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == pkg_dict['id'], (
            str(activity['object_id']))
        assert activity['user_id'] == user['id'], str(activity['user_id'])
        assert activity['activity_type'] == 'changed package', (
            str(activity['activity_type']))
        if 'id' not in activity:
            assert False, "activity object has no id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity has no revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert (timestamp >= before['time'] and
                timestamp <= after['time']), str(activity['timestamp'])

        # Test for the presence of a correct activity detail item.
        details = self.activity_details(activity)
        assert len(details) == 1
        detail = details[0]
        assert detail['activity_id'] == activity['id'], \
            str(detail['activity_id'])
        assert detail['object_type'] == "tag", (
            str(detail['object_type']))
        assert detail['activity_type'] == "removed", (
            str(detail['activity_type']))

    def test_01_update_extras(self):
        """
        Test changed package extra activity stream.

        Test that correct activity stream item and detail items are emitted
        when a package extra is changed.

        """
        packages_with_extras = []
        for package_name in package_list(self.app):
            package_dict = package_show(self.app, {'id': package_name})
            if len(package_dict['extras']) > 0:
                    packages_with_extras.append(package_dict)
        assert len(packages_with_extras) > 0, (
                "Need some packages with extras to test")
        for package_dict in packages_with_extras:
            self._update_extra(package_dict, user=self.normal_user)

    def test_01_update_package(self):
        """
        Test updated package activity stream.

        Test that correct activity stream item and detail items are created
        when packages are updated.

        """
        for package_name in package_list(self.app):
            package_dict = package_show(self.app, {'id': package_name})
            self._update_package(package_dict, user=self.normal_user)

    def test_01_update_resource(self):
        """
        Test that a correct activity stream item and detail item are emitted
        when a resource is updated.

        """
        for package_name in package_list(self.app):
            package_dict = package_show(self.app, {'id': package_name})
            for resource in package_dict['resources']:
                self._update_resource(package_dict, resource,
                        user=self.normal_user)

    def test_01_update_resource_not_logged_in(self):
        """
        Test that a correct activity stream item and detail item are emitted
        when a resource is updated by a user who is not logged in.

        """
        for package_name in package_list(self.app):
            package_dict = package_show(self.app, {'id': package_name})
            for resource in package_dict['resources']:
                self._update_resource(package_dict, resource, user=None)

    def test_create_package(self):
        """
        Test new package activity stream.

        Test that correct activity stream item and detail items are emitted
        when a new package is created.

        """
        self._create_package(user=self.normal_user)

    def test_add_resources(self):
        """
        Test new resource activity stream.

        Test that correct activity stream item and detail items are emitted
        when a resource is added to a package.

        """
        for package_name in package_list(self.app):
            package_dict = package_show(self.app, {'id': package_name})
            self._add_resource(package_dict, user=self.normal_user)

    def test_delete_package(self):
        """
        Test deleted package activity stream.

        Test that correct activity stream item and detail items are created
        when packages are deleted.

        """
        for package_name in package_list(self.app):
            package_dict = package_show(self.app, {'id': package_name})
            self._delete_package(package_dict)

    def test_create_user(self):
        """
        Test new user activity stream.

        Test that correct activity stream item and detail item are created when
        a new user is created.

        """
        before = datetime.datetime.now()

        # Create a new user.
        user_dict = {'name': 'testuser',
                'about': 'Just a test user', 'email': 'me@test.org',
                'password': 'testpass'}
        response = self.app.post('/api/action/user_create',
            json.dumps(user_dict),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])})
        response_dict = json.loads(response.body)
        assert response_dict['success'] is True
        user_created = response_dict['result']

        after = self.record_details(user_created['id'],
                apikey=user_created['apikey'])

        user_activities = after['user activity stream']
        assert len(user_activities) == 1, ("There should be 1 activity in "
            "the user's activity stream, but found %i" % len(user_activities))
        activity = user_activities[0]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == user_created['id'], \
            str(activity['object_id'])
        assert activity['user_id'] == user_created['id'], \
            str(activity['user_id'])
        assert activity['activity_type'] == 'new user', \
            str(activity['activity_type'])
        if 'id' not in activity:
            assert False, "activity object should have an id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity object should have a revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert timestamp >= before and timestamp <= after['time'], \
            str(activity['timestamp'])

        details = self.activity_details(activity)
        assert len(details) == 0, ("There shouldn't be any activity details"
                " for a 'new user' activity")

    def test_create_group(self):

        user = self.normal_user

        before = self.record_details(user['id'], apikey=user['apikey'])

        # Create a new group.
        request_data = {'name': 'a-new-group', 'title': 'A New Group'}
        response = self.app.post('/api/action/group_create',
            json.dumps(request_data),
            extra_environ={'Authorization': str(user['apikey'])})
        response_dict = json.loads(response.body)
        assert response_dict['success'] is True
        group_created = response_dict['result']

        after = self.record_details(user['id'],
                group_ids=[group_created['id']], apikey=user['apikey'])

        # Find the new activity.
        new_activities = find_new_activities(before['user activity stream'],
            after['user activity stream'])
        assert len(new_activities) == 1, ("There should be 1 new activity in "
            "the user's activity stream, but found %i" % len(new_activities))
        activity = new_activities[0]

        assert after['group activity streams'][group_created['id']] == \
                new_activities, ("The same activity should also appear in "
                "the group's activity stream.")

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == group_created['id'], \
            str(activity['object_id'])
        assert activity['user_id'] == user['id'], str(activity['user_id'])
        assert activity['activity_type'] == 'new group', \
            str(activity['activity_type'])
        if 'id' not in activity:
            assert False, "activity object should have an id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity object should have a revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert timestamp >= before['time'] and timestamp <= after['time'], \
            str(activity['timestamp'])

    def test_delete_group(self):
        """
        Test deleted group activity stream.

        Test that correct activity stream item and detail items are created
        when groups are deleted.

        """
        for group in group_list(self.app):
            self._delete_group(group, self.sysadmin_user)

    def test_add_tag(self):
        """
        Test add tag activities.

        If a package is updated by adding one new tag to it, a
        'changed package' activity with a single 'added tag' activity detail
        should be emitted.

        """
        # Get a package.
        user = self.normal_user
        pkg_name = u"warandpeace"
        pkg_dict = package_show(self.app, {'id': pkg_name})

        # Add one new tag to the package.
        before = self.record_details(user['id'], pkg_dict['id'],
                apikey=user['apikey'])
        new_tag_name = 'test tag'
        assert new_tag_name not in [tag['name'] for tag in pkg_dict['tags']]

        pkg_dict['tags'].append({'name': new_tag_name})
        package_update(self.app, pkg_dict, user['apikey'])
        after = self.record_details(user['id'], pkg_dict['id'],
                apikey=user['apikey'])

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 1, ("There should be 1 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))
        activity = user_new_activities[0]

        # The same new activity should appear in the package's stream.
        pkg_new_activities = (find_new_activities(
            before['package activity stream'],
            after['package activity stream']))
        assert pkg_new_activities == user_new_activities

        # The same new activity should appear in the recently changed datasets
        # stream.
        assert find_new_activities(
                before['recently changed datasets stream'],
                after['recently changed datasets stream']) \
                        == user_new_activities

        # If the package has any groups, the same new activity should appear
        # in the activity stream of each group.
        for group_dict in pkg_dict['groups']:
            grp_new_activities = find_new_activities(
                before['group activity streams'][group_dict['name']],
                after['group activity streams'][group_dict['name']])
            assert grp_new_activities == [activity]

        # Check that the new activity has the right attributes.
        assert activity['object_id'] == pkg_dict['id'], (
            str(activity['object_id']))
        assert activity['user_id'] == user['id'], str(activity['user_id'])
        assert activity['activity_type'] == 'changed package', (
            str(activity['activity_type']))
        if 'id' not in activity:
            assert False, "activity object has no id value"
        # TODO: Test for the _correct_ revision_id value.
        if 'revision_id' not in activity:
            assert False, "activity has no revision_id value"
        timestamp = datetime_from_string(activity['timestamp'])
        assert (timestamp >= before['time'] and
                timestamp <= after['time']), str(activity['timestamp'])

        # Test for the presence of a correct activity detail item.
        details = self.activity_details(activity)
        assert len(details) == 1
        detail = details[0]
        assert detail['activity_id'] == activity['id'], \
            str(detail['activity_id'])
        assert detail['object_type'] == "tag", (
            str(detail['object_type']))
        assert detail['activity_type'] == "added", (
            str(detail['activity_type']))

    def test_activity_create_successful_no_data(self):
        """Test creating an activity via the API, without passing the optional
        data dict.

        """
        params = {
            'user_id': self.sysadmin_user['id'],
            'object_id': self.warandpeace['id'],
            'activity_type': 'changed package',
        }
        self._create_activity(self.sysadmin_user, self.warandpeace, params)

    def test_activity_create_successful_with_data(self):
        """Test creating an activity via the API, with the optional data dict.

        """
        params = {
            'user_id': self.sysadmin_user['id'],
            'object_id': self.annakarenina['id'],
            'activity_type': 'deleted package',
            'data': {'a': 1, 'b': 2, 'c': 3}
        }
        self._create_activity(self.sysadmin_user, self.annakarenina, params)

    def test_activity_create_no_authorization(self):
        """Test the error response when the activity_create API is called
        without an authorization header.

        """
        params = {
            'user_id': self.sysadmin_user['id'],
            'object_id': self.warandpeace['id'],
            'activity_type': 'changed package',
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params), status=403)
        assert response.json['success'] is False

    def test_activity_create_not_authorized(self):
        """Test the error response when the activity_create API is called
        with an authorization header for a user who is not authorized to
        create activities.

        """
        params = {
            'user_id': self.normal_user['id'],
            'object_id': self.warandpeace['id'],
            'activity_type': 'changed package',
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.normal_user['apikey'])},
            status=403)
        assert response.json['success'] is False

    def test_activity_create_authorization_not_exists(self):
        """Test the error response when the activity_create API is called
        with an authorization header with an API key that doesn't exist in the
        model.

        """
        params = {
            'user_id': self.normal_user['id'],
            'object_id': self.warandpeace['id'],
            'activity_type': 'changed package',
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': 'xxxxxxxxxx'},
            status=403)
        assert response.json['success'] is False

    def test_activity_create_with_id(self):
        """Test that an ID passed to the activity_create API is ignored and not
        used.

        """
        activity_id = '1234567890'
        user = self.sysadmin_user
        package = self.warandpeace
        params = {
            'id': activity_id,
            'user_id': user['id'],
            'object_id': package['id'],
            'activity_type': 'changed package',
        }
        self._create_activity(self.sysadmin_user, self.warandpeace, params)
        assert activity_id not in [activity['id'] for activity in
                self.user_activity_stream(user['id'])]
        assert activity_id not in [activity['id'] for activity in
                self.package_activity_stream(package['id'])]

    def test_activity_create_with_timestamp(self):
        """Test that a timestamp passed to the activity_create API is ignored
        and not used

        """
        params = {
            'user_id': self.sysadmin_user['id'],
            'object_id': self.warandpeace['id'],
            'activity_type': 'changed package',
            'timestamp': str(datetime.datetime.max),
        }
        self._create_activity(self.sysadmin_user, self.warandpeace, params)
        params['timestamp'] = 'foobar'
        self._create_activity(self.sysadmin_user, self.warandpeace, params)

    def test_activity_create_with_revision(self):
        """Test that a revision_id passed to the activity_create API is ignored
        and not used

        """
        revision_id = '1234567890'
        user = self.sysadmin_user
        package = self.warandpeace
        params = {
            'revision_id': revision_id,
            'user_id': user['id'],
            'object_id': package['id'],
            'activity_type': 'changed package',
        }
        self._create_activity(self.sysadmin_user, self.warandpeace, params)
        assert revision_id not in [activity['revision_id'] for activity in
                self.user_activity_stream(user['id'])]
        assert revision_id not in [activity['revision_id'] for activity in
                self.package_activity_stream(package['id'])]

    def test_activity_create_user_id_missing(self):
        """Test the error response when the activity_create API is called with
        no user ID.

        """
        params = {
            'object_id': self.warandpeace['id'],
            'activity_type': 'changed package',
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'user_id'] == [u'Missing value'], (
                response.json['error'][u'user_id'])

    def test_activity_create_user_id_empty(self):
        """Test the error response when the activity_create API is called with
        an empty user ID.

        """
        params = {
            'user_id': '',
            'object_id': self.warandpeace['id'],
            'activity_type': 'changed package',
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'user_id'] == [u'Missing value'], (
                response.json['error'][u'user_id'])

        params['user_id'] = None
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'user_id'] == [u'Missing value'], (
                response.json['error'][u'user_id'])

    def test_activity_create_user_id_does_not_exist(self):
        """Test the error response when the activity_create API is called with
        a user ID that doesn't exist in the model.

        """
        params = {
            'user_id': '1234567890abcdefghijk',
            'object_id': self.warandpeace['id'],
            'activity_type': 'changed package',
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'user_id'] == [
                u'Not found: User'], (
                response.json['error'][u'user_id'])

    def test_activity_create_object_id_missing(self):
        """Test the error response when the activity_create API is called with
        no object ID.

        """
        params = {
            'user_id': self.sysadmin_user['id'],
            'activity_type': 'changed package',
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'object_id'] == [
                u'Missing value'], (
                response.json['error'][u'user_id'])

    def test_activity_create_object_id_empty(self):
        """Test the error response when the activity_create API is called with
        an empty object ID.

        """
        params = {
            'object_id': '',
            'user_id': self.sysadmin_user['id'],
            'activity_type': 'changed package',
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'object_id'] == [
                u'Missing value'], (
                response.json['error'][u'user_id'])

        params['object_id'] = None
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'object_id'] == [
                u'Missing value'], (
                response.json['error'][u'user_id'])

    def test_activity_create_object_id_does_not_exist(self):
        """Test the error response when the activity_create API is called with
        a user ID that doesn't exist in the model.

        """
        params = {
            'object_id': '1234567890qwertyuiop',
            'user_id': self.sysadmin_user['id'],
            'activity_type': 'changed package',
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'object_id'] == [
                u'Not found: Dataset'], (
                response.json['error'][u'object_id'])

    def test_activity_create_activity_type_missing(self):
        """Test the error response when the activity_create API is called
        without an activity_type.

        """
        params = {
            'user_id': self.normal_user['id'],
            'object_id': self.warandpeace['id'],
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'object_id'] == [
                u'Missing value'], (
                response.json['error'][u'object_id'])

    def test_activity_create_activity_type_empty(self):
        """Test the error response when the activity_create API is called
        with an empty activity_type.

        """
        params = {
            'user_id': self.normal_user['id'],
            'object_id': self.warandpeace['id'],
            'activity_type': ''
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'activity_type'] == [
                u'Missing value'], (
                response.json['error'][u'activity_type'])

        params['activity_type'] = None
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'activity_type'] == [
                u'Missing value'], (
                response.json['error'][u'activity_type'])

    def test_activity_create_activity_type_not_exists(self):
        """Test the error response when the activity_create API is called
        with an activity_type that does not exist.

        """
        params = {
            'user_id': self.normal_user['id'],
            'object_id': self.warandpeace['id'],
            'activity_type': 'foobar'
        }
        response = self.app.post('/api/action/activity_create',
            params=json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user['apikey'])},
            status=409)
        assert response.json['success'] is False
        assert response.json['error'][u'__type'] == u'Validation Error'
        assert response.json['error'][u'activity_type'] == [
            u"Not found: Activity type"], (
                response.json['error'][u'activity_type'])

    def test_add_extras(self):
        """
        Test new package extra activity stream.

        Test that correct activity stream item and detail items are emitted
        when an extra is added to a package.

        """
        for package_name in package_list(self.app):
            package_dict = package_show(self.app, {'id': package_name})
            self._add_extra(package_dict, user=self.normal_user)

    def test_delete_extras(self):
        """
        Test deleted package extra activity stream.

        Test that correct activity stream item and detail items are emitted
        when a package extra is deleted.

        """
        packages_with_extras = []
        for package_name in package_list(self.app):
            package_dict = package_show(self.app, {'id': package_name})
            if len(package_dict['extras']) > 0:
                    packages_with_extras.append(package_dict)
        assert len(packages_with_extras) > 0, (
                "Need some packages with extras to test")
        for package_dict in packages_with_extras:
            self._delete_extra(package_dict, user=self.normal_user)

    def test_follow_dataset(self):
        user = self.sysadmin_user
        before = self.record_details(user['id'], self.warandpeace['id'],
                apikey=user['apikey'])
        data = {'id': self.warandpeace['id']}
        extra_environ = {'Authorization': str(user['apikey'])}
        response = self.app.post('/api/action/follow_dataset',
            json.dumps(data), extra_environ=extra_environ)
        response_dict = json.loads(response.body)
        assert response_dict['success'] is True

        after = self.record_details(user['id'], self.warandpeace['id'],
                apikey=user['apikey'])

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 0, ("There should be 0 new "
            " activity in the user's activity stream, but found %i" %
            len(user_new_activities))

        # The rest of this test is commented out because 'follow dataset'
        # activities are disabled, even they are reenabled then uncomment it.

        #activity = user_new_activities[0]

        # The same new activity should appear in the package's activity stream.
        #pkg_new_activities = after['package activity stream']
        #for activity in user_new_activities:
        #    assert activity in pkg_new_activities

        # Check that the new activity has the right attributes.
        #assert activity['object_id'] == self.warandpeace['id'], \
        #    str(activity['object_id'])
        #assert activity['user_id'] == user['id'], str(activity['user_id'])
        #assert activity['activity_type'] == 'follow dataset', \
        #    str(activity['activity_type'])
        #if 'id' not in activity:
        #    assert False, "activity object should have an id value"
        # TODO: Test for the _correct_ revision_id value.
        #if 'revision_id' not in activity:
        #    assert False, "activity object should have a revision_id value"
        #timestamp = datetime_from_string(activity['timestamp'])
        #assert timestamp >= before['time'] and timestamp <= \
        #    after['time'], str(activity['timestamp'])

        #assert len(self.activity_details(activity)) == 0

    def test_follow_user(self):
        user = self.normal_user
        before = self.record_details(user['id'], apikey=user['apikey'])
        followee_before = self.record_details(self.sysadmin_user['id'],
                apikey=self.sysadmin_user['apikey'])
        data = {'id': self.sysadmin_user['id']}
        extra_environ = {'Authorization': str(user['apikey'])}
        response = self.app.post('/api/action/follow_user',
            json.dumps(data), extra_environ=extra_environ)
        response_dict = json.loads(response.body)
        assert response_dict['success'] is True

        after = self.record_details(user['id'], apikey=user['apikey'])
        followee_after = self.record_details(self.sysadmin_user['id'],
                apikey=self.sysadmin_user['apikey'])

        # Find the new activity in the user's activity stream.
        user_new_activities = (find_new_activities(
            before['user activity stream'], after['user activity stream']))
        assert len(user_new_activities) == 0, ("There should be 0 new "
            " activities in the user's activity stream, but found %i" %
            len(user_new_activities))

        # The rest of this test is commented out because follow_user activities
        # are disabled, uncomment it if they're enabled again.

        #activity = user_new_activities[0]

        # Check that the new activity has the right attributes.
        #assert activity['object_id'] == self.sysadmin_user['id'], \
        #    str(activity['object_id'])
        #assert activity['user_id'] == user['id'], str(activity['user_id'])
        #assert activity['activity_type'] == 'follow user', \
        #    str(activity['activity_type'])
        #if 'id' not in activity:
        #    assert False, "activity object should have an id value"
        # TODO: Test for the _correct_ revision_id value.

        #if 'revision_id' not in activity:
        #    assert False, "activity object should have a revision_id value"
        #timestamp = datetime_from_string(activity['timestamp'])
        #assert timestamp >= before['time'] and timestamp <= \
        #    after['time'], str(activity['timestamp'])

        #assert len(self.activity_details(activity)) == 0

    def test_user_activity_list_by_name(self):
        '''user_activity_list should accept a user name as param.'''
        import ckan.tests
        activities = ckan.tests.call_action_api(self.app, 'user_activity_list',
                id='annafan')
        assert len(activities) > 0

    def test_package_activity_list_by_name(self):
        '''package_activity_list should accept a package name as param.'''
        import ckan.tests
        activities = ckan.tests.call_action_api(self.app,
                'package_activity_list', id='warandpeace',
                apikey=self.sysadmin_user['apikey'])
        assert len(activities) > 0

    def test_group_activity_list_by_name(self):
        '''group_activity_list should accept a group name as param.'''
        import ckan.tests
        activities = ckan.tests.call_action_api(self.app,
                'group_activity_list', id='roger')
        assert len(activities) > 0

    def test_organization_activity_list_by_name(self):
        '''organization_activity_list should accept a org name as param.'''
        import ckan.tests
        organization = ckan.tests.call_action_api(self.app,
                'organization_create', name='test_org',
                apikey=self.sysadmin_user['apikey'])
        activities = ckan.tests.call_action_api(self.app,
                'organization_activity_list', id=organization['name'])
        assert len(activities) > 0

    def test_related_item_new(self):
        user = self.normal_user
        data = {'title': 'random', 'type': 'Application', 'url':
                'http://example.com/application'}
        extra_environ = {'Authorization': str(user['apikey'])}
        response = self.app.post('/api/action/related_create',
                                 json.dumps(data),
                                 extra_environ=extra_environ)
        response_dict = json.loads(response.body)
        assert response_dict['success'] is True

        activity_response = self.app.post('/api/3/action/user_activity_list',
                                         json.dumps({'id': user['id']}))
        activity_response_dict = json.loads(activity_response.body)
        assert (activity_response_dict['result'][0]['activity_type'] == 'new '
                'related item')
        assert activity_response_dict['result'][0]['user_id'] == user['id']
        assert (activity_response_dict['result'][0]['data']['related']['id'] ==
                response_dict['result']['id'])
        assert activity_response_dict['result'][0]['data']['dataset'] is None

    def test_related_item_changed(self):
        # Create related item
        user = self.normal_user
        data = {'title': 'random', 'type': 'Application', 'url':
                'http://example.com/application'}
        extra_environ = {'Authorization': str(user['apikey'])}
        response = self.app.post('/api/action/related_create',
                                 json.dumps(data),
                                 extra_environ=extra_environ)
        response_dict = json.loads(response.body)
        assert response_dict['success'] is True

        # Modify it
        data = {'id': response_dict['result']['id'], 'title': 'random2',
                'owner_id': str(user['id']), 'type': 'Application'}
        response = self.app.post('/api/action/related_update',
            json.dumps(data), extra_environ=extra_environ)
        response_dict = json.loads(response.body)
        assert response_dict['success'] is True

        # Test for activity stream entries
        activity_response = self.app.post('/api/3/action/user_activity_list',
                                         json.dumps({'id': user['id']}))
        activity_response_dict = json.loads(activity_response.body)
        assert (activity_response_dict['result'][0]['activity_type'] ==
                'changed related item')
        assert (activity_response_dict['result'][0]['object_id'] ==
                response_dict['result']['id'])
        assert activity_response_dict['result'][0]['user_id'] == user['id']
        assert (activity_response_dict['result'][0]['data']['related']['id'] ==
                response_dict['result']['id'])
        assert activity_response_dict['result'][0]['data']['dataset'] is None

    def test_related_item_deleted(self):
        # Create related item
        user = self.normal_user
        data = {'title': 'random', 'type': 'Application', 'url':
                'http://example.com/application'}
        extra_environ = {'Authorization': str(user['apikey'])}
        response = self.app.post('/api/action/related_create',
                                 json.dumps(data),
                                 extra_environ=extra_environ)
        response_dict = json.loads(response.body)
        assert response_dict['success'] is True

        # Delete related item
        data = {'id': response_dict['result']['id']}
        deleted_response = self.app.post('/api/action/related_delete',
                                 json.dumps(data),
                                 extra_environ=extra_environ)
        deleted_response_dict = json.loads(deleted_response.body)
        assert deleted_response_dict['success'] is True

        # Test for activity stream entries
        activity_response = self.app.post('/api/3/action/user_activity_list',
                                         json.dumps({'id': user['id']}))
        activity_response_dict = json.loads(activity_response.body)
        assert (activity_response_dict['result'][0]['activity_type'] ==
                'deleted related item')
        assert (activity_response_dict['result'][0]['object_id'] ==
                response_dict['result']['id'])
        assert activity_response_dict['result'][0]['user_id'] == user['id']
        assert (activity_response_dict['result'][0]['data']['related']['id'] ==
                response_dict['result']['id'])

    def test_no_activity_when_creating_private_dataset(self):
        '''There should be no activity when a private dataset is created.'''

        user = self.normal_user
        organization = tests.call_action_api(self.app, 'organization_create',
                name='another_test_org', apikey=user['apikey'])
        dataset = tests.call_action_api(self.app, 'package_create',
                apikey=user['apikey'],
                name='test_private_dataset',
                owner_org=organization['id'], private=True)
        activity_stream = tests.call_action_api(self.app,
                'package_activity_list', id=dataset['id'],
                apikey=user['apikey'])
        assert activity_stream == []

    def test_no_activity_when_updating_private_dataset(self):
        '''There should be no activity when a private dataset is created.'''

        user = self.normal_user
        organization = tests.call_action_api(self.app, 'organization_create',
                name='test_org_3', apikey=user['apikey'])
        dataset = tests.call_action_api(self.app, 'package_create',
                apikey=user['apikey'],
                name='test_private_dataset_2',
                owner_org=organization['id'], private=True)
        dataset['notes'] = 'updated'
        updated_dataset = tests.call_action_api(self.app, 'package_update',
                apikey=user['apikey'], **dataset)
        activity_stream = tests.call_action_api(self.app,
                'package_activity_list', id=dataset['id'],
                apikey=user['apikey'])
        assert activity_stream == []

    def test_no_activity_when_deleting_private_dataset(self):
        '''There should be no activity when a private dataset is created.'''

        user = self.normal_user
        organization = tests.call_action_api(self.app, 'organization_create',
                name='test_org_4', apikey=user['apikey'])
        dataset = tests.call_action_api(self.app, 'package_create',
                apikey=user['apikey'],
                name='test_private_dataset_3',
                owner_org=organization['id'], private=True)
        deleted_dataset = tests.call_action_api(self.app, 'package_delete',
                apikey=user['apikey'], id=dataset['id'])
        activity_stream = tests.call_action_api(self.app,
                'package_activity_list', id=dataset['id'],
                apikey=user['apikey'])
        assert activity_stream == []

########NEW FILE########
__FILENAME__ = test_api
import json

from ckan.tests.functional.api.base import *

import ckan.tests
assert_in = ckan.tests.assert_in

class ApiTestCase(ApiTestCase, ControllerTestCase): 

    def test_get_api(self):
        offset = self.offset('')
        res = self.app.get(offset, status=[200])
        self.assert_version_data(res)

    def assert_version_data(self, res):
        data = self.data_from_res(res)
        assert 'version' in data, data
        expected_version = self.get_expected_api_version()
        self.assert_equal(data['version'], expected_version) 

class TestApi3(Api3TestCase, ApiTestCase):

    def test_readonly_is_get_able_with_normal_url_params(self):
        '''Test that a read-only action is GET-able

        Picks an action within `get.py` and checks that it works if it's
        invoked with a http GET request.  The action's data_dict is
        populated from the url parameters.
        '''
        offset = self.offset('/action/package_search')
        params = {'q': 'russian'}
        res = self.app.get(offset, params=params, status=[200])

    def test_sideeffect_action_is_not_get_able(self):
        '''Test that a non-readonly action is not GET-able.

        Picks an action outside of `get.py`, and checks that it 400s if an
        attempt to invoke with a http GET request is made.
        '''
        offset = self.offset('/action/package_create')
        data_dict = {
            'type': 'dataset',
            'name': 'a-name'
        }
        res = self.app.get(offset,
                           params=data_dict,
                           status=[400],
                           expect_errors=True)
        assert_in('Bad request - JSON Error: No request body data',
                  res.body)

# Tests for Version 1 of the API.
class TestApi1(Api1TestCase, ApiTestCase): pass

# Tests for Version 2 of the API.
class TestApi2(Api2TestCase, ApiTestCase): pass

########NEW FILE########
__FILENAME__ = test_dashboard
'''Test for the dashboard API.

This module tests the various functions of the user dashboard, such as the
contents of the dashboard activity stream and reporting the number of new
activities.

'''
import ckan
from ckan.common import json
import paste
import pylons.test


class TestDashboard(object):
    '''Tests for the logic action functions related to the user's dashboard.'''

    @classmethod
    def user_create(cls):
        '''Create a new user.'''
        params = json.dumps({
            'name': 'mr_new_user',
            'email': 'mr@newuser.com',
            'password': 'iammrnew',
            })
        response = cls.app.post('/api/action/user_create', params=params,
                extra_environ={'Authorization': str(cls.testsysadmin['apikey'])})
        assert response.json['success'] is True
        new_user = response.json['result']
        return new_user

    @classmethod
    def setup_class(cls):
        ckan.tests.CreateTestData.create()
        cls.app = paste.fixture.TestApp(pylons.test.pylonsapp)
        joeadmin = ckan.model.User.get('joeadmin')
        cls.joeadmin = {
                'id': joeadmin.id,
                'apikey': joeadmin.apikey
                }
        annafan = ckan.model.User.get('annafan')
        cls.annafan = {
                'id': annafan.id,
                'apikey': annafan.apikey
                }
        testsysadmin = ckan.model.User.get('testsysadmin')
        cls.testsysadmin = {
                'id': testsysadmin.id,
                'apikey': testsysadmin.apikey
                }
        cls.new_user = cls.user_create()

    @classmethod
    def teardown_class(cls):
        ckan.model.repo.rebuild_db()

    def post(self, action, params=None, apikey=None, status=200):
        '''Post to the CKAN API and return the result.'''
        if params is None:
            params = {}
        params = json.dumps(params)
        response = self.app.post('/api/action/{0}'.format(action),
                params=params,
                extra_environ={'Authorization': str(apikey)},
                status=status)
        if status in (200,):
            assert response.json['success'] is True
            return response.json['result']
        else:
            assert response.json['success'] is False
            return response.json['error']

    def dashboard_new_activities_count(self, user):
        '''Return the given user's new activities count from the CKAN API.'''
        return self.post('dashboard_new_activities_count',
                apikey=user['apikey'])

    def dashboard_activity_list(self, user):
        '''Return the given user's dashboard activity list from the CKAN API.

        '''
        return self.post('dashboard_activity_list', apikey=user['apikey'])

    def dashboard_new_activities(self, user):
        '''Return the activities from the user's dashboard activity stream
        that are currently marked as new.'''
        activity_list = self.dashboard_activity_list(user)
        return [activity for activity in activity_list if activity['is_new']]

    def dashboard_mark_activities_old(self, user):
        self.post('dashboard_mark_activities_old',
                apikey=user['apikey'])

    def test_00_dashboard_activity_list_not_logged_in(self):
        self.post('dashboard_activity_list', status=403)

    def test_00_dashboard_new_activities_count_not_logged_in(self):
        self.post('dashboard_new_activities_count', status=403)

    def test_00_dashboard_mark_new_activities_not_logged_in(self):
        self.post('dashboard_mark_activities_old', status=403)

    def test_01_dashboard_activity_list_for_new_user(self):
        '''Test the contents of a new user's dashboard activity stream.'''
        activities = self.dashboard_activity_list(self.new_user)
        # We expect to find a single 'new user' activity.
        assert len(activities) == 1
        activity = activities[0]
        assert activity['activity_type'] == 'new user'
        assert activity['user_id'] == activity['object_id']
        assert activity['user_id'] == self.new_user['id']

    def test_01_new_activities_count_for_new_user(self):
        '''Test that a newly registered user's new activities count is 0.'''
        assert self.dashboard_new_activities_count(self.new_user) == 0

    def test_01_new_activities_for_new_user(self):
        '''Test that a newly registered user has no activities marked as new
        in their dashboard activity stream.'''
        assert len(self.dashboard_new_activities(self.new_user)) == 0

    def test_02_own_activities_do_not_count_as_new(self):
        '''Make a user do some activities and check that her own activities
        don't increase her new activities count.'''

        # The user has to view her dashboard activity stream first to mark any
        # existing activities as read. For example when she follows a dataset
        # below, past activities from the dataset (e.g. when someone created
        # the dataset, etc.) will appear in her dashboard, and if she has never
        # viewed her dashboard then those activities will be considered
        # "unseen".
        # We would have to do this if, when you follow something, you only get
        # the activities from that object since you started following it, and
        # not all its past activities as well.
        self.dashboard_mark_activities_old(self.new_user)

        # Create a new dataset.
        params = json.dumps({
            'name': 'my_new_package',
            })
        response = self.app.post('/api/action/package_create', params=params,
                extra_environ={'Authorization': str(self.new_user['apikey'])})
        assert response.json['success'] is True

        # Follow a dataset.
        params = json.dumps({'id': 'warandpeace'})
        response = self.app.post('/api/action/follow_dataset', params=params,
                extra_environ={'Authorization': str(self.new_user['apikey'])})
        assert response.json['success'] is True

        # Follow a user.
        params = json.dumps({'id': 'annafan'})
        response = self.app.post('/api/action/follow_user', params=params,
                extra_environ={'Authorization': str(self.new_user['apikey'])})
        assert response.json['success'] is True

        # Follow a group.
        params = json.dumps({'id': 'roger'})
        response = self.app.post('/api/action/follow_group', params=params,
                extra_environ={'Authorization': str(self.new_user['apikey'])})
        assert response.json['success'] is True

        # Update the dataset that we're following.
        params = json.dumps({'name': 'warandpeace', 'notes': 'updated'})
        response = self.app.post('/api/action/package_update', params=params,
                extra_environ={'Authorization': str(self.new_user['apikey'])})
        assert response.json['success'] is True

        # User's own actions should not increase her activity count.
        assert self.dashboard_new_activities_count(self.new_user) == 0

    def test_03_dashboard_activity_list_own_activities(self):
        '''Test that a user's own activities appear in her dashboard.'''
        activities = self.dashboard_activity_list(self.new_user)

        # FIXME: There should actually be 3 activities here, but when you
        # follow something it's old activities (from before you followed it)
        # appear in your activity stream. So here we get more activities than
        # expected.
        assert len(activities) == 5, len(activities)

        assert activities[0]['activity_type'] == 'changed package'
        #assert activities[1]['activity_type'] == 'follow group'
        #assert activities[2]['activity_type'] == 'follow user'
        #assert activities[3]['activity_type'] == 'follow dataset'
        assert activities[1]['activity_type'] == 'new package'
        assert activities[2]['activity_type'] == 'new user'

        # FIXME: Shouldn't need the [:3] here, it's because when you follow
        # something its old activities (from before you started following it)
        # appear in your dashboard.
        for activity in activities[:3]:
            assert activity['user_id'] == self.new_user['id']

    def test_03_own_activities_not_marked_as_new(self):
        '''Make a user do some activities and check that her own activities
        aren't marked as new in her dashboard activity stream.'''
        assert len(self.dashboard_new_activities(self.new_user)) == 0

    def test_04_activities_from_followed_datasets(self):
        '''Activities from followed datasets should show in dashboard.'''

        activities_before = self.dashboard_activity_list(self.new_user)

        # Make someone else who new_user is not following update a dataset that
        # new_user is following.
        params = json.dumps({'name': 'warandpeace', 'notes': 'updated again'})
        response = self.app.post('/api/action/package_update', params=params,
                extra_environ={'Authorization': str(self.joeadmin['apikey'])})
        assert response.json['success'] is True

        # Check the new activity in new_user's dashboard.
        activities = self.dashboard_activity_list(self.new_user)
        new_activities = [activity for activity in activities
                if activity not in activities_before]
        assert len(new_activities) == 1
        activity = new_activities[0]
        assert activity['activity_type'] == 'changed package'
        assert activity['user_id'] == self.joeadmin['id']
        assert activity['data']['package']['name'] == 'warandpeace'

    def test_04_activities_from_followed_users(self):
        '''Activities from followed users should show in the dashboard.'''

        activities_before = self.dashboard_activity_list(self.new_user)

        # Make someone that the user is following create a new dataset.
        params = json.dumps({'name': 'annas_new_dataset'})
        response = self.app.post('/api/action/package_create', params=params,
                extra_environ={'Authorization': str(self.annafan['apikey'])})
        assert response.json['success'] is True

        # Check the new activity in new_user's dashboard.
        activities = self.dashboard_activity_list(self.new_user)
        new_activities = [activity for activity in activities
                if activity not in activities_before]
        assert len(new_activities) == 1
        activity = new_activities[0]
        assert activity['activity_type'] == 'new package'
        assert activity['user_id'] == self.annafan['id']
        assert activity['data']['package']['name'] == 'annas_new_dataset'

    def test_04_activities_from_followed_groups(self):
        '''Activities from followed groups should show in the dashboard.'''

        activities_before = self.dashboard_activity_list(self.new_user)

        # Make someone that the user is not following update a group that the
        # user is following.
        group = self.post('group_show', {'id': 'roger'},
        apikey=self.testsysadmin['apikey'])
        group['description'] = 'updated'
        self.post('group_update', group, apikey=self.testsysadmin['apikey'])

        # Check the new activity in new_user's dashboard.
        activities = self.dashboard_activity_list(self.new_user)
        new_activities = [activity for activity in activities
                if activity not in activities_before]
        assert len(new_activities) == 1
        activity = new_activities[0]
        assert activity['activity_type'] == 'changed group'
        assert activity['user_id'] == self.testsysadmin['id']
        assert activity['data']['group']['name'] == 'roger'

    def test_04_activities_from_datasets_of_followed_groups(self):
        '''Activities from datasets of followed groups should show in the
        dashboard.

        '''
        activities_before = self.dashboard_activity_list(self.new_user)

        # Make someone that the user is not following update a dataset that the
        # user is not following either, but that belongs to a group that the
        # user is following.
        params = json.dumps({'name': 'annakarenina', 'notes': 'updated'})
        response = self.app.post('/api/action/package_update', params=params,
            extra_environ={'Authorization': str(self.joeadmin['apikey'])})
        assert response.json['success'] is True

        # Check the new activity in new_user's dashboard.
        activities = self.dashboard_activity_list(self.new_user)
        new_activities = [activity for activity in activities
                if activity not in activities_before]
        assert len(new_activities) == 1
        activity = new_activities[0]
        assert activity['activity_type'] == 'changed package'
        assert activity['user_id'] == self.joeadmin['id']
        assert activity['data']['package']['name'] == 'annakarenina'

    def test_05_new_activities_count(self):
        '''Test that new activities from objects that a user follows increase
        her new activities count.'''
        assert self.dashboard_new_activities_count(self.new_user) == 4

    def test_06_activities_marked_as_new(self):
        '''Test that new activities from objects that a user follows are
        marked as new in her dashboard activity stream.'''
        assert len(self.dashboard_new_activities(self.new_user)) == 4

    def test_07_mark_new_activities_as_read(self):
        '''Test that a user's new activities are marked as old when she views
        her dashboard activity stream.'''
        assert self.dashboard_new_activities_count(self.new_user) > 0
        assert len(self.dashboard_new_activities(self.new_user)) > 0
        self.dashboard_mark_activities_old(self.new_user)
        assert self.dashboard_new_activities_count(self.new_user) == 0
        assert len(self.dashboard_new_activities(self.new_user)) == 0

    def test_08_maximum_number_of_new_activities(self):
        '''Test that the new activities count does not go higher than 15, even
        if there are more than 15 new activities from the user's followers.'''
        for n in range(0, 20):
            notes = "Updated {n} times".format(n=n)
            params = json.dumps({'name': 'warandpeace', 'notes': notes})
            response = self.app.post('/api/action/package_update',
                params=params,
                extra_environ={'Authorization': str(self.joeadmin['apikey'])})
            assert response.json['success'] is True
        assert self.dashboard_new_activities_count(self.new_user) == 15

    def test_09_activities_that_should_not_show(self):
        '''Test that other activities do not appear on the user's dashboard.'''

        before = self.dashboard_activity_list(self.new_user)

        # Make someone else who new_user is not following create a new dataset.
        params = json.dumps({'name': 'irrelevant_dataset'})
        response = self.app.post('/api/action/package_create', params=params,
            extra_environ={'Authorization': str(self.testsysadmin['apikey'])})
        assert response.json['success'] is True

        after = self.dashboard_activity_list(self.new_user)

        assert before == after

    def test_10_dashboard_activity_list_html_does_not_crash(self):

        params = json.dumps({'name': 'irrelevant_dataset1'})
        response = self.app.post('/api/action/package_create', params=params,
            extra_environ={'Authorization': str(self.annafan['apikey'])})
        assert response.json['success'] is True

        params = json.dumps({'name': 'another_irrelevant_dataset'})
        response = self.app.post('/api/action/package_create', params=params,
            extra_environ={'Authorization': str(self.annafan['apikey'])})
        assert response.json['success'] is True

        res = self.app.get('/api/3/action/dashboard_activity_list_html',
                extra_environ={'Authorization':
                    str(self.annafan['apikey'])})
        assert res.json['success'] is True

########NEW FILE########
__FILENAME__ = test_email_notifications
import time

import ckan.model as model
import ckan.lib.base
import ckan.lib.mailer
import ckan.tests as tests
import ckan.tests.mock_mail_server as mock_mail_server
import ckan.tests.pylons_controller as pylons_controller
import ckan.config.middleware

import paste
import paste.deploy
import pylons.test

from pylons import config

class TestEmailNotifications(mock_mail_server.SmtpServerHarness,
        pylons_controller.PylonsTestCase):

    @classmethod
    def setup_class(cls):
        mock_mail_server.SmtpServerHarness.setup_class()
        pylons_controller.PylonsTestCase.setup_class()
        tests.CreateTestData.create()
        cls.app = paste.fixture.TestApp(pylons.test.pylonsapp)
        joeadmin = model.User.get('joeadmin')
        cls.joeadmin = {'id': joeadmin.id,
                'apikey': joeadmin.apikey,
                }
        testsysadmin = model.User.get('testsysadmin')
        cls.testsysadmin = {'id': testsysadmin.id,
                'apikey': testsysadmin.apikey,
                }
        annafan = model.User.get('annafan')
        cls.annafan = {'id': annafan.id,
                'apikey': annafan.apikey,
                }

    @classmethod
    def teardown_class(cls):
        mock_mail_server.SmtpServerHarness.teardown_class()
        pylons_controller.PylonsTestCase.teardown_class()
        model.repo.rebuild_db()

    def check_email(self, email, address, name, subject):
        assert email[1] == 'info@test.ckan.net'
        assert email[2] == [address]
        encoded_subject = 'Subject: =?utf-8?q?{subject}'.format(
                subject=subject.replace(' ', '_'))
        assert encoded_subject in email[3]
        # TODO: Check that body contains link to dashboard and email prefs.

    def test_00_send_email_notifications_not_logged_in(self):
        '''Not-logged-in users shouldn't be able to send email notifications.

        '''
        tests.call_action_api(self.app, 'send_email_notifications',
                status=403)

    def test_00_send_email_notifications_not_authorized(self):
        '''Unauthorized users shouldn't be able to send email notifications.

        '''
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.annafan['apikey'], status=403)

    def test_01_no_email_notifications_after_registration(self):
        '''A new user who isn't following anything shouldn't get any emails.'''

        # Clear any emails already sent due to CreateTestData.create().
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        self.clear_smtp_messages()

        # Register a new user.
        sara = tests.call_action_api(self.app, 'user_create',
                apikey=self.testsysadmin['apikey'], name='sara',
                email='sara@sararollins.com', password='sara',
                fullname='Sara Rollins',
                activity_streams_email_notifications=True)

        # Save the user for later tests to use.
        TestEmailNotifications.sara = sara

        # No notification emails should be sent to anyone at this point.
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 0

    def test_02_one_new_activity(self):
        '''A user with one new activity should get one email.'''

        # Make Sara follow something, have to do this to get new activity.
        tests.call_action_api(self.app, 'follow_dataset',
                apikey=self.sara['apikey'], id='warandpeace')

        # Make someone else update the dataset Sara's following, this should
        # create a new activity on Sara's dashboard.
        tests.call_action_api(self.app, 'package_update',
                apikey=self.joeadmin['apikey'], name='warandpeace',
                notes='updated')

        # Run the email notifier job, it should send one notification email
        # to Sara.
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 1
        email = self.get_smtp_messages()[0]
        self.check_email(email, 'sara@sararollins.com', 'Sara Rollins',
                '1 new activity from CKAN')

        self.clear_smtp_messages()

    def test_03_multiple_new_activities(self):
        '''Test that a user with multiple new activities gets just one email.

        '''
        # Make someone else update the dataset Sara's following three times,
        # this should create three new activities on Sara's dashboard.
        for i in range(1, 4):
            tests.call_action_api(self.app, 'package_update',
                    apikey=self.joeadmin['apikey'], name='warandpeace',
                    notes='updated {0} times'.format(i))

        # Run the email notifier job, it should send one notification email
        # to Sara.
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 1
        email = self.get_smtp_messages()[0]
        self.check_email(email, 'sara@sararollins.com', 'Sara Rollins',
                '3 new activities from CKAN')

        self.clear_smtp_messages()

    def test_04_no_repeat_email_notifications(self):
        '''Test that a user does not get a second email notification for the
        same new activity.

        '''
        # TODO: Assert that Sara has some new activities and has already had
        # an email about them.
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 0

    def test_05_no_email_if_seen_on_dashboard(self):
        '''Test that emails are not sent for activities already seen on dash.

        If a user gets some new activities in her dashboard activity stream,
        then views her dashboard activity stream, then she should not got any
        email notifications about these new activities.

        '''
        # Make someone else update the dataset Sara's following, this should
        # create a new activity on Sara's dashboard.
        tests.call_action_api(self.app, 'package_update',
                apikey=self.joeadmin['apikey'], name='warandpeace',
                notes='updated by test_05_no_email_if_seen_on_dashboard')

        # At this point Sara should have a new activity on her dashboard.
        num_new_activities = tests.call_action_api(self.app,
                'dashboard_new_activities_count', apikey=self.sara['apikey'])
        assert num_new_activities > 0, num_new_activities

        # View Sara's dashboard.
        tests.call_action_api(self.app, 'dashboard_mark_activities_old',
                apikey=self.sara['apikey'])

        # No email should be sent.
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 0

    def test_05_no_email_notifications_when_disabled_site_wide(self):
        '''Users should not get email notifications when the feature is
        disabled site-wide by a sysadmin.'''

    def test_06_enable_email_notifications_sitewide(self):
        '''When a sysadamin enables email notifications site wide, users
        should not get emails for new activities from before email
        notifications were enabled.

        '''


# It's just easier to separate these tests into their own test class.
class TestEmailNotificationsUserPreference(
        mock_mail_server.SmtpServerHarness,
        pylons_controller.PylonsTestCase):
    '''Tests for the email notifications (on/off) user preference.'''

    @classmethod
    def setup_class(cls):
        mock_mail_server.SmtpServerHarness.setup_class()
        pylons_controller.PylonsTestCase.setup_class()
        tests.CreateTestData.create()
        cls.app = paste.fixture.TestApp(pylons.test.pylonsapp)
        joeadmin = model.User.get('joeadmin')
        cls.joeadmin = {'id': joeadmin.id,
                'apikey': joeadmin.apikey,
                }
        testsysadmin = model.User.get('testsysadmin')
        cls.testsysadmin = {'id': testsysadmin.id,
                'apikey': testsysadmin.apikey,
                }

    @classmethod
    def teardown_class(self):
        mock_mail_server.SmtpServerHarness.teardown_class()
        pylons_controller.PylonsTestCase.teardown_class()
        model.repo.rebuild_db()

    def test_00_email_notifications_disabled_by_default(self):
        '''Email notifications should be disabled for new users.'''

        # Register a new user.
        sara = tests.call_action_api(self.app, 'user_create',
                apikey=self.testsysadmin['apikey'], name='sara',
                email='sara@sararollins.com', password='sara',
                fullname='Sara Rollins')

        # Save the user for later tests to use.
        TestEmailNotificationsUserPreference.sara = sara

        # Email notifications should be disabled for the new user.
        assert sara['activity_streams_email_notifications'] is False
        assert (tests.call_action_api(self.app, 'user_show',
                apikey=self.sara['apikey'], id='sara')[
                    'activity_streams_email_notifications'] is False)

    def test_01_no_email_notifications_when_disabled(self):
        '''Users with email notifications turned off should not get emails.'''

        # First make Sara follow something so she gets some new activity in
        # her dashboard activity stream.
        tests.call_action_api(self.app, 'follow_dataset',
                apikey=self.sara['apikey'], id='warandpeace')

        # Now make someone else update the dataset so Sara gets a new activity.
        tests.call_action_api(self.app, 'package_update',
                apikey=self.joeadmin['apikey'], id='warandpeace',
                notes='updated')

        # Test that Sara has a new activity, just to make sure.
        assert tests.call_action_api(self.app,
            'dashboard_new_activities_count', apikey=self.sara['apikey']) > 0

        # No email notifications should be sent to Sara.
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 0

    def test_02_enable_email_notifications(self):
        '''Users should be able to turn email notifications on.'''

        # Mark all Sara's new activities as old, just to get a fresh start.
        tests.call_action_api(self.app, 'dashboard_mark_activities_old',
                apikey=self.sara['apikey'])
        assert tests.call_action_api(self.app,
            'dashboard_new_activities_count', apikey=self.sara['apikey']) == 0

        # Update the followed dataset a few times so Sara gets a few new
        # activities.
        for i in range(1, 4):
            tests.call_action_api(self.app, 'package_update',
                    apikey=self.joeadmin['apikey'], id='warandpeace',
                    notes='updated {0} times'.format(i))

        # Now Sara should have new activities.
        assert tests.call_action_api(self.app,
            'dashboard_new_activities_count', apikey=self.sara['apikey']) == 3

        # Run the email notifier job.
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 0

        # Enable email notifications for Sara.
        self.sara['activity_streams_email_notifications'] = True
        tests.call_action_api(self.app, 'user_update', **self.sara)

        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 0, ("After a user enables "
            "email notifications she should _not_ get emails about activities "
            "that happened before she enabled them, even if those activities "
            "are still marked as 'new' on her dashboard.")

        # Update the package to generate another new activity.
        tests.call_action_api(self.app, 'package_update',
                apikey=self.joeadmin['apikey'], id='warandpeace',
                notes='updated yet again')

        # Check that Sara has a new activity.
        assert tests.call_action_api(self.app,
            'dashboard_new_activities_count', apikey=self.sara['apikey']) == 4

        # Run the email notifier job, this time Sara should get one email.
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 1
        self.clear_smtp_messages()

    def test_03_disable_email_notifications(self):
        '''Users should be able to turn email notifications off.'''

        self.sara['activity_streams_email_notifications'] = False
        tests.call_action_api(self.app, 'user_update', **self.sara)

        tests.call_action_api(self.app, 'package_update',
                apikey=self.joeadmin['apikey'], id='warandpeace',
                notes='updated yet again')

        assert tests.call_action_api(self.app,
            'dashboard_new_activities_count', apikey=self.sara['apikey']) > 0

        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 0


class TestEmailNotificationsIniSetting(
        mock_mail_server.SmtpServerHarness,
        pylons_controller.PylonsTestCase):
    '''Tests for the ckan.activity_streams_email_notifications config setting.

    '''
    @classmethod
    def setup_class(cls):
        cls._original_config = config.copy()

        # Disable the email notifications feature.
        config['ckan.activity_streams_email_notifications'] = False

        wsgiapp = ckan.config.middleware.make_app(config['global_conf'],
                **config)
        cls.app = paste.fixture.TestApp(wsgiapp)

        mock_mail_server.SmtpServerHarness.setup_class()
        pylons_controller.PylonsTestCase.setup_class()
        tests.CreateTestData.create()

        joeadmin = model.User.get('joeadmin')
        cls.joeadmin = {'id': joeadmin.id,
                'apikey': joeadmin.apikey,
                }
        testsysadmin = model.User.get('testsysadmin')
        cls.testsysadmin = {'id': testsysadmin.id,
                'apikey': testsysadmin.apikey,
                }

    @classmethod
    def teardown_class(cls):
        config.clear()
        config.update(cls._original_config)
        mock_mail_server.SmtpServerHarness.teardown_class()
        pylons_controller.PylonsTestCase.teardown_class()
        model.repo.rebuild_db()

    def test_00_send_email_notifications_feature_disabled(self):
        '''Send_email_notifications API should error when feature disabled.'''

        # Register a new user.
        sara = tests.call_action_api(self.app, 'user_create',
                apikey=self.testsysadmin['apikey'], name='sara',
                email='sara@sararollins.com', password='sara',
                fullname='Sara Rollins')

        # Save the user for later tests to use.
        TestEmailNotificationsIniSetting.sara = sara

        # Enable the new user's email notifications preference.
        sara['activity_streams_email_notifications'] = True
        tests.call_action_api(self.app, 'user_update', **sara)
        assert (tests.call_action_api(self.app, 'user_show',
                apikey=self.sara['apikey'], id='sara')[
                    'activity_streams_email_notifications']
                is True)

        # Make Sara follow something so she gets some new activity in her
        # dashboard activity stream.
        tests.call_action_api(self.app, 'follow_dataset',
                apikey=self.sara['apikey'], id='warandpeace')

        # Now make someone else update the dataset so Sara gets a new activity.
        tests.call_action_api(self.app, 'package_update',
                apikey=self.joeadmin['apikey'], id='warandpeace',
                notes='updated')

        # Test that Sara has a new activity, just to make sure.
        assert tests.call_action_api(self.app,
            'dashboard_new_activities_count', apikey=self.sara['apikey']) > 0

        # We expect an error when trying to call the send_email_notifications
        # API, because the feature is disabled by the ini file setting.
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'], status=409)

    def test_01_no_emails_sent_if_turned_off(self):
        '''No emails should be sent if the feature is disabled site-wide.'''

        # No emails should have been sent by the last test.
        assert len(self.get_smtp_messages()) == 0


class TestEmailNotificationsSinceIniSetting(
        mock_mail_server.SmtpServerHarness,
        pylons_controller.PylonsTestCase):
    '''Tests for the ckan.email_notifications_since config setting.'''

    @classmethod
    def setup_class(cls):
        cls._original_config = config.copy()

        # Don't send email notifications for activities older than 1
        # microsecond.
        config['ckan.email_notifications_since'] = '.000001'

        wsgiapp = ckan.config.middleware.make_app(config['global_conf'],
                **config)
        cls.app = paste.fixture.TestApp(wsgiapp)

        mock_mail_server.SmtpServerHarness.setup_class()
        pylons_controller.PylonsTestCase.setup_class()
        tests.CreateTestData.create()

        joeadmin = model.User.get('joeadmin')
        cls.joeadmin = {'id': joeadmin.id,
                'apikey': joeadmin.apikey,
                }
        testsysadmin = model.User.get('testsysadmin')
        cls.testsysadmin = {'id': testsysadmin.id,
                'apikey': testsysadmin.apikey,
                }

    @classmethod
    def teardown_class(self):
        config.clear()
        config.update(self._original_config)
        mock_mail_server.SmtpServerHarness.teardown_class()
        pylons_controller.PylonsTestCase.teardown_class()
        model.repo.rebuild_db()

    def test_00_email_notifications_since(self):
        '''No emails should be sent for activities older than
        email_notifications_since.

        '''
        # Register a new user.
        sara = tests.call_action_api(self.app, 'user_create',
                apikey=self.testsysadmin['apikey'], name='sara',
                email='sara@sararollins.com', password='sara',
                fullname='Sara Rollins')

        # Save the user for later tests to use.
        TestEmailNotificationsSinceIniSetting.sara = sara

        # Enable the new user's email notifications preference.
        sara['activity_streams_email_notifications'] = True
        tests.call_action_api(self.app, 'user_update', **sara)
        assert (tests.call_action_api(self.app, 'user_show',
                apikey=self.sara['apikey'], id='sara')[
                    'activity_streams_email_notifications']
                is True)

        # Make Sara follow something so she gets some new activity in her
        # dashboard activity stream.
        tests.call_action_api(self.app, 'follow_dataset',
                apikey=self.sara['apikey'], id='warandpeace')

        # Now make someone else update the dataset so Sara gets a new activity.
        tests.call_action_api(self.app, 'package_update',
                apikey=self.joeadmin['apikey'], id='warandpeace',
                notes='updated')

        # Test that Sara has a new activity, just to make sure.
        assert tests.call_action_api(self.app,
            'dashboard_new_activities_count', apikey=self.sara['apikey']) > 0

        # Wait 1 microsecond, just to make sure we're passed the 'since' time.
        time.sleep(0.000001)

        # No emails should be sent.
        tests.call_action_api(self.app, 'send_email_notifications',
                apikey=self.testsysadmin['apikey'])
        assert len(self.get_smtp_messages()) == 0

########NEW FILE########
__FILENAME__ = test_follow
'''Test for the follower API.

This module tests following, unfollowing, getting a list of what you're
following or the number of things you're following, getting a list of who's
following you or the number of followers you have, testing whether or not
you're following something, etc.

This module _does not_ test the user dashboard activity stream (which shows
activities from everything you're following), that is tested in
test_dashboard.py.

'''
import datetime
import paste
import pylons.test
import ckan
from ckan.tests import are_foreign_keys_supported, SkipTest
import ckan.tests

def datetime_from_string(s):
    '''Return a standard datetime.datetime object initialised from a string in
    the same format used for timestamps in dictized activities (the format
    produced by datetime.datetime.isoformat())

    '''
    return datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%S.%f')

def follow(func):
    '''Return a wrapper function for a follow_* function.

    The wrapper functions test the `followee_list` and `followee_count` API
    calls, in addition to any tests carried out by the wrapped function.

    '''
    def wrapped_func(app, follower_id, apikey, object_id, object_arg,
            sysadmin_apikey):
        followee_count_before = ckan.tests.call_action_api(app,
                'followee_count', id=follower_id)
        followees_before = ckan.tests.call_action_api(app, 'followee_list',
                id=follower_id, apikey=sysadmin_apikey)

        func(app, follower_id, apikey, object_id, object_arg, sysadmin_apikey)

        followee_count_after = ckan.tests.call_action_api(app,
                'followee_count', id=follower_id)
        followees_after = ckan.tests.call_action_api(app, 'followee_list',
                id=follower_id, apikey=sysadmin_apikey)

        assert followee_count_after == followee_count_before + 1, (
                "After a user follows an object, the user's `followee_count` "
                "should increase by 1")

        assert len(followees_after) == len(followees_before) + 1, (
                "After a user follows an object, the object should appear in "
                "the user's `followee_list`")
        assert len([followee for followee in followees_after
            if followee['dict']['id'] == object_id]) == 1, (
                "After a user follows an object, the object should appear in "
                "the user's `followee_list`")

    return wrapped_func


@follow
def follow_user(app, follower_id, apikey, object_id, object_arg,
        sysadmin_apikey):
    '''Test a user starting to follow another user via the API.

    :param follower_id: id of the user that will be following something.
    :param apikey: API key of the user that will be following something.
    :param object_id: id of the user that will be followed.
    :param object_arg: the argument to pass to follow_user as the id of
        the object that will be followed, could be the object's id or name.

    '''
    # Record the object's followers count before.
    follower_count_before = ckan.tests.call_action_api(app,
            'user_follower_count', id=object_id)

    # Record the follower's followees count before.
    followee_count_before = ckan.tests.call_action_api(app,
            'user_followee_count', id=follower_id)

    # Check that the user is not already following the object.
    result = ckan.tests.call_action_api(app, 'am_following_user',
            id=object_id, apikey=apikey)
    assert result is False

    # Make the  user start following the object.
    before = datetime.datetime.now()
    follower = ckan.tests.call_action_api(app, 'follow_user', id=object_arg,
            apikey=apikey)
    after = datetime.datetime.now()
    assert follower['follower_id'] == follower_id
    assert follower['object_id'] == object_id
    timestamp = datetime_from_string(follower['datetime'])
    assert (timestamp >= before and timestamp <= after), str(timestamp)

    # Check that am_following_user now returns True.
    result = ckan.tests.call_action_api(app, 'am_following_user',
            id=object_id, apikey=apikey)
    assert result is True

    # Check that the follower appears in the object's list of followers.
    followers = ckan.tests.call_action_api(app, 'user_follower_list',
            id=object_id, apikey=sysadmin_apikey)
    assert len(followers) == follower_count_before + 1
    assert len([follower for follower in followers if follower['id'] == follower_id]) == 1

    # Check that the object appears in the follower's list of followees.
    followees = ckan.tests.call_action_api(app, 'user_followee_list',
            apikey=sysadmin_apikey, id=follower_id)
    assert len(followees) == followee_count_before + 1
    assert len([followee for followee in followees if followee['id'] == object_id]) == 1

    # Check that the object's follower count has increased by 1.
    follower_count_after = ckan.tests.call_action_api(app,
            'user_follower_count', id=object_id)
    assert follower_count_after == follower_count_before + 1

    # Check that the follower's followee count has increased by 1.
    followee_count_after = ckan.tests.call_action_api(app,
            'user_followee_count', id=follower_id)
    assert followee_count_after == followee_count_before + 1


@follow
def follow_dataset(app, follower_id, apikey, dataset_id, dataset_arg,
        sysadmin_apikey):
    '''Test a user starting to follow a dataset via the API.

    :param follower_id: id of the user.
    :param apikey: API key of the user.
    :param dataset_id: id of the dataset.
    :param dataset_arg: the argument to pass to follow_dataset as the id of
        the dataset that will be followed, could be the dataset's id or name.

    '''
    # Record the dataset's followers count before.
    follower_count_before = ckan.tests.call_action_api(app,
            'dataset_follower_count', id=dataset_id)

    # Record the follower's followees count before.
    followee_count_before = ckan.tests.call_action_api(app,
            'dataset_followee_count', id=follower_id)

    # Check that the user is not already following the dataset.
    result = ckan.tests.call_action_api(app, 'am_following_dataset',
            id=dataset_id, apikey=apikey)
    assert result is False

    # Make the  user start following the dataset.
    before = datetime.datetime.now()
    follower = ckan.tests.call_action_api(app, 'follow_dataset',
            id=dataset_arg, apikey=apikey)
    after = datetime.datetime.now()
    assert follower['follower_id'] == follower_id
    assert follower['object_id'] == dataset_id
    timestamp = datetime_from_string(follower['datetime'])
    assert (timestamp >= before and timestamp <= after), str(timestamp)

    # Check that am_following_dataset now returns True.
    result = ckan.tests.call_action_api(app, 'am_following_dataset',
            id=dataset_id, apikey=apikey)
    assert result is True

    # Check that the follower appears in the dataset's list of followers.
    followers = ckan.tests.call_action_api(app, 'dataset_follower_list',
            id=dataset_id, apikey=sysadmin_apikey)
    assert len(followers) == follower_count_before + 1
    assert len([follower for follower in followers if follower['id'] == follower_id]) == 1

    # Check that the dataset appears in the follower's list of followees.
    followees = ckan.tests.call_action_api(app, 'dataset_followee_list',
            apikey=sysadmin_apikey, id=follower_id)
    assert len(followees) == followee_count_before + 1
    assert len([followee for followee in followees if followee['id'] == dataset_id]) == 1

    # Check that the dataset's follower count has increased by 1.
    follower_count_after = ckan.tests.call_action_api(app,
            'dataset_follower_count', id=dataset_id)
    assert follower_count_after == follower_count_before + 1

    # Check that the follower's followee count has increased by 1.
    followee_count_after = ckan.tests.call_action_api(app,
            'dataset_followee_count', id=follower_id)
    assert followee_count_after == followee_count_before + 1


@follow
def follow_group(app, user_id, apikey, group_id, group_arg, sysadmin_apikey):
    '''Test a user starting to follow a group via the API.

    :param user_id: id of the user
    :param apikey: API key of the user
    :param group_id: id of the group
    :param group_arg: the argument to pass to follow_group as the id of
        the group that will be followed, could be the group's id or name

    '''
    # Record the group's followers count before.
    follower_count_before = ckan.tests.call_action_api(app,
            'group_follower_count', id=group_id)

    # Record the user's followees count before.
    followee_count_before = ckan.tests.call_action_api(app,
            'group_followee_count', id=user_id)

    # Check that the user is not already following the group.
    result = ckan.tests.call_action_api(app, 'am_following_group',
            id=group_id, apikey=apikey)
    assert result is False

    # Make the  user start following the group.
    before = datetime.datetime.now()
    follower = ckan.tests.call_action_api(app, 'follow_group', id=group_id,
            apikey=apikey)
    after = datetime.datetime.now()
    assert follower['follower_id'] == user_id
    assert follower['object_id'] == group_id
    timestamp = datetime_from_string(follower['datetime'])
    assert (timestamp >= before and timestamp <= after), str(timestamp)

    # Check that am_following_group now returns True.
    result = ckan.tests.call_action_api(app, 'am_following_group',
            id=group_id, apikey=apikey)
    assert result is True

    # Check that the user appears in the group's list of followers.
    followers = ckan.tests.call_action_api(app, 'group_follower_list',
            id=group_id, apikey=sysadmin_apikey)
    assert len(followers) == follower_count_before + 1
    assert len([follower for follower in followers
        if follower['id'] == user_id]) == 1

    # Check that the group appears in the user's list of followees.
    followees = ckan.tests.call_action_api(app, 'group_followee_list',
            apikey=sysadmin_apikey, id=user_id)
    assert len(followees) == followee_count_before + 1
    assert len([followee for followee in followees
        if followee['id'] == group_id]) == 1

    # Check that the group's follower count has increased by 1.
    follower_count_after = ckan.tests.call_action_api(app,
            'group_follower_count', id=group_id)
    assert follower_count_after == follower_count_before + 1

    # Check that the user's followee count has increased by 1.
    followee_count_after = ckan.tests.call_action_api(app,
            'group_followee_count', id=user_id)
    assert followee_count_after == followee_count_before + 1


class TestFollow(object):
    '''Tests for the follower API.'''

    @classmethod
    def setup_class(self):
        ckan.tests.CreateTestData.create()
        self.testsysadmin = {
                'id': ckan.model.User.get('testsysadmin').id,
                'apikey': ckan.model.User.get('testsysadmin').apikey,
                'name': ckan.model.User.get('testsysadmin').name,
                }
        self.annafan = {
            'id': ckan.model.User.get('annafan').id,
            'apikey': ckan.model.User.get('annafan').apikey,
            'name': ckan.model.User.get('annafan').name,
            }
        self.russianfan = {
            'id': ckan.model.User.get('russianfan').id,
            'apikey': ckan.model.User.get('russianfan').apikey,
            'name': ckan.model.User.get('russianfan').name,
            }
        self.joeadmin = {
            'id': ckan.model.User.get('joeadmin').id,
            'apikey': ckan.model.User.get('joeadmin').apikey,
            'name': ckan.model.User.get('joeadmin').name,
            }
        self.warandpeace = {
            'id': ckan.model.Package.get('warandpeace').id,
            'name': ckan.model.Package.get('warandpeace').name,
            }
        self.annakarenina = {
            'id': ckan.model.Package.get('annakarenina').id,
            'name': ckan.model.Package.get('annakarenina').name,
            }
        self.rogers_group = {
            'id': ckan.model.Group.get('roger').id,
            'name': ckan.model.Group.get('roger').name,
            }
        self.davids_group = {
            'id': ckan.model.Group.get('david').id,
            'name': ckan.model.Group.get('david').name,
            }
        self.app = paste.fixture.TestApp(pylons.test.pylonsapp)

    @classmethod
    def teardown_class(self):
        ckan.model.repo.rebuild_db()

    def test_00_visitor_cannot_get_user_follower_list(self):
        ckan.tests.call_action_api(self.app, 'user_follower_list',
                id=self.russianfan['id'], status=403)

    def test_00_user_cannot_get_user_follower_list(self):
        ckan.tests.call_action_api(self.app, 'user_follower_list',
                id=self.russianfan['id'], status=403,
                apikey=self.annafan['apikey'])

    def test_00_sysadmin_can_get_user_follower_list(self):
        ckan.tests.call_action_api(self.app, 'user_follower_list',
                id=self.russianfan['id'], status=200,
                apikey=self.testsysadmin['apikey'])

    def test_00_visitor_cannot_get_dataset_follower_list(self):
        ckan.tests.call_action_api(self.app, 'dataset_follower_list',
                id='warandpeace', status=403)

    def test_00_user_cannot_get_dataset_follower_list(self):
        ckan.tests.call_action_api(self.app, 'dataset_follower_list',
                id='warandpeace', status=403, apikey=self.annafan['apikey'])

    def test_00_sysadmin_can_get_dataset_follower_list(self):
        ckan.tests.call_action_api(self.app, 'dataset_follower_list',
                id='warandpeace', status=200,
                apikey=self.testsysadmin['apikey'])

    def test_00_visitor_cannot_get_group_follower_list(self):
        ckan.tests.call_action_api(self.app, 'group_follower_list',
                id='roger', status=403)

    def test_00_user_cannot_get_group_follower_list(self):
        ckan.tests.call_action_api(self.app, 'group_follower_list',
                id='roger', status=403, apikey=self.annafan['apikey'])

    def test_00_sysadmin_can_get_group_follower_list(self):
        ckan.tests.call_action_api(self.app, 'group_follower_list',
                id='roger', status=200, apikey=self.testsysadmin['apikey'])

    def test_00_visitor_cannot_get_followee_list(self):
        ckan.tests.call_action_api(self.app, 'followee_list',
                id=self.russianfan['id'], status=403)

    def test_00_user_cannot_get_followee_list(self):
        ckan.tests.call_action_api(self.app, 'followee_list',
                id=self.russianfan['id'], status=403,
                apikey=self.annafan['apikey'])

    def test_00_sysadmin_can_get_followee_list(self):
        ckan.tests.call_action_api(self.app, 'followee_list',
                id=self.russianfan['id'], status=200,
                apikey=self.testsysadmin['apikey'])

    def test_00_visitor_cannot_get_user_followee_list(self):
        '''A visitor cannot see what users a user is following.'''
        ckan.tests.call_action_api(self.app, 'user_followee_list',
                id=self.russianfan['id'], status=403)

    def test_00_user_cannot_get_user_followee_list(self):
        '''A user cannot see what users another user is following.'''
        ckan.tests.call_action_api(self.app, 'user_followee_list',
                id=self.russianfan['id'], status=403,
                apikey=self.annafan['apikey'])

    def test_00_sysadmin_can_get_user_followee_list(self):
        '''A sysadmin can see what users another user is following.'''
        ckan.tests.call_action_api(self.app, 'user_followee_list',
                id=self.russianfan['id'], status=200,
                apikey=self.testsysadmin['apikey'])

    def test_00_user_can_get_own_user_followee_list(self):
        '''A user can see what users she herself is following.'''
        ckan.tests.call_action_api(self.app, 'user_followee_list',
                id=self.russianfan['id'], status=200,
                apikey=self.russianfan['apikey'])

    def test_00_visitor_cannot_get_dataset_followee_list(self):
        '''A visitor cannot see what datasets a user is following.'''
        ckan.tests.call_action_api(self.app, 'dataset_followee_list',
                id=self.russianfan['id'], status=403)

    def test_00_user_cannot_get_dataset_followee_list(self):
        '''A user cannot see what datasets another user is following.'''
        ckan.tests.call_action_api(self.app, 'dataset_followee_list',
                id='russianfan', status=403, apikey=self.annafan['apikey'])

    def test_00_sysadmin_can_get_dataset_followee_list(self):
        '''A sysadmin can see what datasets another user is following.'''
        ckan.tests.call_action_api(self.app, 'dataset_followee_list',
                id='russianfan', status=200,
                apikey=self.testsysadmin['apikey'])

    def test_00_user_can_get_own_dataset_followee_list(self):
        '''A user can see what datasets she herself is following.'''
        ckan.tests.call_action_api(self.app, 'dataset_followee_list',
                id=self.russianfan['id'], status=200,
                apikey=self.russianfan['apikey'])

    def test_00_visitor_cannot_get_group_followee_list(self):
        '''A visitor cannot see what groups a user is following.'''
        ckan.tests.call_action_api(self.app, 'group_followee_list',
                id='roger', status=403)

    def test_00_user_cannot_get_group_followee_list(self):
        '''A user cannot see what groups another user is following.'''
        ckan.tests.call_action_api(self.app, 'group_followee_list',
                id='roger', status=403, apikey=self.annafan['apikey'])

    def test_00_sysadmin_can_get_group_followee_list(self):
        '''A sysadmin can see what groups another user is following.'''
        ckan.tests.call_action_api(self.app, 'group_followee_list',
                id=self.annafan['id'], status=200,
                apikey=self.testsysadmin['apikey'])

    def test_00_user_can_get_own_group_followee_list(self):
        '''A user can see what groups she herself is following.'''
        ckan.tests.call_action_api(self.app, 'group_followee_list',
                id=self.russianfan['id'], status=200,
                apikey=self.russianfan['apikey'])

    def test_01_user_follow_user_bad_apikey(self):
        for apikey in ('bad api key', '', '     ', 'None', '3', '35.7', 'xxx'):
            error = ckan.tests.call_action_api(self.app, 'follow_user',
                    id=self.russianfan['id'], apikey=apikey,
                    status=403)
            assert error['__type'] == 'Authorization Error'

    def test_01_user_follow_dataset_bad_apikey(self):
        for apikey in ('bad api key', '', '     ', 'None', '3', '35.7', 'xxx'):
            error = ckan.tests.call_action_api(self.app, 'follow_dataset',
                    id=self.warandpeace['id'], apikey=apikey,
                    status=403)
            assert error['__type'] == 'Authorization Error'

    def test_01_user_follow_group_bad_apikey(self):
        for apikey in ('bad api key', '', '     ', 'None', '3', '35.7', 'xxx'):
            error = ckan.tests.call_action_api(self.app, 'follow_group',
                    id=self.rogers_group['id'], apikey=apikey,
                    status=403)
            assert error['__type'] == 'Authorization Error'

    def test_01_user_follow_user_missing_apikey(self):
        error = ckan.tests.call_action_api(self.app, 'follow_user',
                id=self.russianfan['id'], status=403)
        assert error['__type'] == 'Authorization Error'

    def test_01_user_follow_dataset_missing_apikey(self):
        error = ckan.tests.call_action_api(self.app, 'follow_dataset',
                id=self.warandpeace['id'], status=403)
        assert error['__type'] == 'Authorization Error'

    def test_01_user_follow_group_missing_apikey(self):
        error = ckan.tests.call_action_api(self.app, 'follow_group',
                id=self.rogers_group['id'], status=403)
        assert error['__type'] == 'Authorization Error'

    def test_01_follow_bad_object_id(self):
        for action in ('follow_user', 'follow_dataset', 'follow_group'):
            for object_id in ('bad id', '     ', 3, 35.7, 'xxx'):
                error = ckan.tests.call_action_api(self.app, action,
                        id=object_id,
                        apikey=self.annafan['apikey'], status=409)
                assert error['id'][0].startswith('Not found')

    def test_01_follow_empty_object_id(self):
        for action in ('follow_user', 'follow_dataset', 'follow_group'):
            for object_id in ('', None):
                error = ckan.tests.call_action_api(self.app, action,
                        id=object_id,
                        apikey=self.annafan['apikey'], status=409)
                assert error['id'] == ['Missing value']

    def test_01_follow_missing_object_id(self):
        for action in ('follow_user', 'follow_dataset', 'follow_group'):
            error = ckan.tests.call_action_api(self.app, action,
                    apikey=self.annafan['apikey'], status=409)
            assert error['id'] == ['Missing value']

    def test_02_user_follow_user_by_id(self):
        follow_user(self.app, self.annafan['id'], self.annafan['apikey'],
                self.russianfan['id'], self.russianfan['id'],
                self.testsysadmin['apikey'])

    def test_02_user_follow_dataset_by_id(self):
        follow_dataset(self.app, self.annafan['id'], self.annafan['apikey'],
                self.warandpeace['id'], self.warandpeace['id'],
                self.testsysadmin['apikey'])

    def test_02_user_follow_group_by_id(self):
        follow_group(self.app, self.annafan['id'], self.annafan['apikey'],
                self.rogers_group['id'], self.rogers_group['id'],
                self.testsysadmin['apikey'])

    def test_02_user_follow_user_by_name(self):
        follow_user(self.app, self.annafan['id'], self.annafan['apikey'],
                self.testsysadmin['id'], self.testsysadmin['name'],
                self.testsysadmin['apikey'])

    def test_02_user_follow_dataset_by_name(self):
        follow_dataset(self.app, self.joeadmin['id'], self.joeadmin['apikey'],
                self.warandpeace['id'], self.warandpeace['name'],
                self.testsysadmin['apikey'])

    def test_02_user_follow_group_by_name(self):
        follow_group(self.app, self.joeadmin['id'], self.joeadmin['apikey'],
                self.rogers_group['id'], self.rogers_group['name'],
                self.testsysadmin['apikey'])

    def test_03_user_follow_user_already_following(self):
        for object_id in (self.russianfan['id'], self.russianfan['name'],
                self.testsysadmin['id'], self.testsysadmin['name']):
            error = ckan.tests.call_action_api(self.app, 'follow_user',
                    id=object_id, apikey=self.annafan['apikey'],
                    status=409)
            assert error['message'].startswith('You are already following ')

    def test_03_user_follow_dataset_already_following(self):
        for object_id in (self.warandpeace['id'], self.warandpeace['name']):
            error = ckan.tests.call_action_api(self.app, 'follow_dataset',
                    id=object_id, apikey=self.annafan['apikey'],
                    status=409)
            assert error['message'].startswith('You are already following ')

    def test_03_user_follow_group_already_following(self):
        for group_id in (self.rogers_group['id'], self.rogers_group['name']):
            error = ckan.tests.call_action_api(self.app, 'follow_group',
                    id=group_id, apikey=self.annafan['apikey'],
                    status=409)
            assert error['message'].startswith('You are already following ')

    def test_03_user_cannot_follow_herself(self):
        error = ckan.tests.call_action_api(self.app, 'follow_user',
                apikey=self.annafan['apikey'], status=409,
                id=self.annafan['id'])
        assert error['message'] == 'You cannot follow yourself'

    def test_04_follower_count_bad_id(self):
        for action in ('user_follower_count', 'dataset_follower_count',
                'group_follower_count'):
            for object_id in ('bad id', '     ', 3, 35.7, 'xxx', ''):
                error = ckan.tests.call_action_api(self.app, action,
                        status=409, id=object_id)
                assert 'id' in error

    def test_04_follower_count_missing_id(self):
        for action in ('user_follower_count', 'dataset_follower_count',
                'group_follower_count'):
            error = ckan.tests.call_action_api(self.app, action, status=409)
            assert error['id'] == ['Missing value']

    def test_04_user_follower_count_no_followers(self):
        follower_count = ckan.tests.call_action_api(self.app,
                'user_follower_count', id=self.annafan['id'])
        assert follower_count == 0

    def test_04_dataset_follower_count_no_followers(self):
        follower_count = ckan.tests.call_action_api(self.app,
                'dataset_follower_count', id=self.annakarenina['id'])
        assert follower_count == 0

    def test_04_group_follower_count_no_followers(self):
        follower_count = ckan.tests.call_action_api(self.app,
                'group_follower_count', id=self.davids_group['id'])
        assert follower_count == 0

    def _followee_count_bad_id(self, action):
        for object_id in ('bad id', '     ', 3, 35.7, 'xxx', ''):
            error = ckan.tests.call_action_api(self.app, action,
                    status=409, id=object_id)
            assert 'id' in error

    def test_04_followee_count_bad_id(self):
        self._followee_count_bad_id('followee_count')

    def test_04_user_followee_count_bad_id(self):
        self._followee_count_bad_id('user_followee_count')

    def test_04_dataset_followee_count_bad_id(self):
        self._followee_count_bad_id('dataset_followee_count')

    def test_04_group_followee_count_bad_id(self):
        self._followee_count_bad_id('group_followee_count')

    def _followee_count_missing_id(self, action):
        error = ckan.tests.call_action_api(self.app, action, status=409)
        assert error['id'] == ['Missing value']

    def test_04_followee_count_missing_id(self):
        self._followee_count_missing_id('followee_count')

    def test_04_user_followee_count_missing_id(self):
        self._followee_count_missing_id('user_followee_count')

    def test_04_dataset_followee_count_missing_id(self):
        self._followee_count_missing_id('dataset_followee_count')

    def test_04_group_followee_count_missing_id(self):
        self._followee_count_missing_id('group_followee_count')

    def _followee_count_not_following_anything(self, action):
        followee_count = ckan.tests.call_action_api(self.app, action,
                id=self.russianfan['id'])
        assert followee_count == 0

    def test_04_followee_count_not_following_anything(self):
        self._followee_count_not_following_anything('followee_count')

    def test_04_user_followee_count_not_following_anything(self):
        self._followee_count_not_following_anything('user_followee_count')

    def test_04_dataset_followee_count_not_following_anything(self):
        self._followee_count_not_following_anything('dataset_followee_count')

    def test_04_group_followee_count_not_following_anything(self):
        self._followee_count_not_following_anything('group_followee_count')

    def test_04_follower_list_bad_id(self):
        for action in ('user_follower_list', 'dataset_follower_list',
                'group_follower_list'):
            for object_id in ('bad id', '     ', 3, 35.7, 'xxx', ''):
                error = ckan.tests.call_action_api(self.app, action,
                        status=409, id=object_id,
                        apikey=self.testsysadmin['apikey'])
                assert error['id']

    def test_04_follower_list_missing_id(self):
        for action in ('user_follower_list', 'dataset_follower_list',
                'group_follower_list'):
            error = ckan.tests.call_action_api(self.app, action, status=409,
                        apikey=self.testsysadmin['apikey'])
            assert error['id'] == ['Missing value']

    def test_04_user_follower_list_no_followers(self):
        followers = ckan.tests.call_action_api(self.app, 'user_follower_list',
                id=self.annafan['id'], apikey=self.testsysadmin['apikey'])
        assert followers == []

    def test_04_dataset_follower_list_no_followers(self):
        followers = ckan.tests.call_action_api(self.app,
                'dataset_follower_list', id=self.annakarenina['id'],
                apikey=self.testsysadmin['apikey'])
        assert followers == []

    def test_04_group_follower_list_no_followers(self):
        followers = ckan.tests.call_action_api(self.app, 'group_follower_list',
                id=self.davids_group['id'], apikey=self.testsysadmin['apikey'])
        assert followers == []

    def _followee_list_bad_id(self, action):
        for object_id in ('bad id', '     ', 3, 35.7, 'xxx', ''):
            error = ckan.tests.call_action_api(self.app, action,
                    status=409, id=object_id,
                    apikey=self.testsysadmin['apikey'])
            assert error['id']

    def test_04_followee_list_bad_id(self):
        self._followee_list_bad_id('followee_list')

    def test_04_user_followee_list_bad_id(self):
        self._followee_list_bad_id('user_followee_list')

    def test_04_dataset_followee_list_bad_id(self):
        self._followee_list_bad_id('dataset_followee_list')

    def test_04_group_followee_list_bad_id(self):
        self._followee_list_bad_id('group_followee_list')

    def _followee_list_missing_id(self, action):
        error = ckan.tests.call_action_api(self.app, action, status=409,
                apikey=self.testsysadmin['apikey'])
        assert error['id'] == ['Missing value']

    def test_04_followee_list_missing_id(self):
        self._followee_list_missing_id('followee_list')

    def test_04_user_followee_list_missing_id(self):
        self._followee_list_missing_id('user_followee_list')

    def test_04_dataset_followee_missing_bad_id(self):
        self._followee_list_missing_id('dataset_followee_list')

    def test_04_group_followee_missing_bad_id(self):
        self._followee_list_missing_id('group_followee_list')

    def _followee_list_not_following_anything(self, action):
        followees = ckan.tests.call_action_api(self.app, action,
                id=self.russianfan['id'], apikey=self.russianfan['apikey'])
        assert followees == []

    def test_04_followee_list_not_following_anything(self):
        self._followee_list_not_following_anything('followee_list')

    def test_04_user_followee_list_not_following_anything(self):
        self._followee_list_not_following_anything('user_followee_list')

    def test_04_dataset_followee_not_following_anything(self):
        self._followee_list_not_following_anything('dataset_followee_list')

    def test_04_group_followee_not_following_anything(self):
        self._followee_list_not_following_anything('group_followee_list')

    def test_04_am_following_bad_id(self):
        for action in ('am_following_dataset', 'am_following_user',
                'am_following_group'):
            for object_id in ('bad id', '     ', 3, 35.7, 'xxx'):
                error = ckan.tests.call_action_api(self.app, action,
                    apikey=self.annafan['apikey'], status=409, id=object_id)
                assert error['id'][0].startswith('Not found: ')

    def test_04_am_following_missing_id(self):
        for action in ('am_following_dataset', 'am_following_user',
                'am_following_group'):
            for id in ('missing', None, ''):
                if id == 'missing':
                    error = ckan.tests.call_action_api(self.app, action,
                            apikey=self.annafan['apikey'], status=409)
                else:
                    error = ckan.tests.call_action_api(self.app, action,
                            apikey=self.annafan['apikey'], status=409, id=id)
                assert error['id'] == [u'Missing value']

    def test_04_am_following_dataset_bad_apikey(self):
        for apikey in ('bad api key', '', '     ', 'None', '3', '35.7', 'xxx'):
            error = ckan.tests.call_action_api(self.app,
                    'am_following_dataset', apikey=apikey, status=403,
                    id=self.warandpeace['id'])
            assert error['message'] == 'Access denied'

    def test_04_am_following_dataset_missing_apikey(self):
        error = ckan.tests.call_action_api(self.app, 'am_following_dataset',
                status=403, id=self.warandpeace['id'])
        assert error['message'] == 'Access denied'

    def test_04_am_following_user_bad_apikey(self):
        for apikey in ('bad api key', '', '     ', 'None', '3', '35.7', 'xxx'):
            error = ckan.tests.call_action_api(self.app, 'am_following_user',
                    apikey=apikey, status=403, id=self.annafan['id'])
            assert error['message'] == 'Access denied'

    def test_04_am_following_user_missing_apikey(self):
        error = ckan.tests.call_action_api(self.app, 'am_following_user',
                status=403, id=self.annafan['id'])
        assert error['message'] == 'Access denied'

    def test_04_am_following_group_bad_apikey(self):
        for apikey in ('bad api key', '', '     ', 'None', '3', '35.7', 'xxx'):
            error = ckan.tests.call_action_api(self.app, 'am_following_group',
                    apikey=apikey, status=403, id=self.rogers_group['id'])
            assert error['message'] == 'Access denied'

    def test_04_am_following_group_missing_apikey(self):
        error = ckan.tests.call_action_api(self.app, 'am_following_group',
                status=403, id=self.rogers_group['id'])
        assert error['message'] == 'Access denied'


class TestFollowerDelete(object):
    '''Tests for the unfollow_* APIs.'''

    @classmethod
    def setup_class(self):
        ckan.tests.CreateTestData.create()
        self.tester = {
                'id': ckan.model.User.get('tester').id,
                'apikey': ckan.model.User.get('tester').apikey,
                'name': ckan.model.User.get('tester').name,
                }
        self.testsysadmin = {
                'id': ckan.model.User.get('testsysadmin').id,
                'apikey': ckan.model.User.get('testsysadmin').apikey,
                'name': ckan.model.User.get('testsysadmin').name,
                }
        self.annafan = {
            'id': ckan.model.User.get('annafan').id,
            'apikey': ckan.model.User.get('annafan').apikey,
            'name': ckan.model.User.get('annafan').name,
            }
        self.russianfan = {
            'id': ckan.model.User.get('russianfan').id,
            'apikey': ckan.model.User.get('russianfan').apikey,
            'name': ckan.model.User.get('russianfan').name,
            }
        self.joeadmin = {
            'id': ckan.model.User.get('joeadmin').id,
            'apikey': ckan.model.User.get('joeadmin').apikey,
            'name': ckan.model.User.get('joeadmin').name,
            }
        self.warandpeace = {
            'id': ckan.model.Package.get('warandpeace').id,
            'name': ckan.model.Package.get('warandpeace').name,
            }
        self.annakarenina = {
            'id': ckan.model.Package.get('annakarenina').id,
            'name': ckan.model.Package.get('annakarenina').name,
            }
        self.rogers_group = {
            'id': ckan.model.Group.get('roger').id,
            'name': ckan.model.Group.get('roger').name,
            }
        self.davids_group = {
            'id': ckan.model.Group.get('david').id,
            'name': ckan.model.Group.get('david').name,
            }
        self.app = paste.fixture.TestApp(pylons.test.pylonsapp)
        follow_user(self.app, self.testsysadmin['id'],
                self.testsysadmin['apikey'], self.joeadmin['id'],
                self.joeadmin['id'], self.testsysadmin['apikey'])
        follow_user(self.app, self.tester['id'], self.tester['apikey'],
                self.joeadmin['id'], self.joeadmin['id'],
                self.testsysadmin['apikey'])
        follow_user(self.app, self.russianfan['id'], self.russianfan['apikey'],
                self.joeadmin['id'], self.joeadmin['id'],
                self.testsysadmin['apikey'])
        follow_user(self.app, self.annafan['id'], self.annafan['apikey'],
                self.joeadmin['id'], self.joeadmin['id'],
                self.testsysadmin['apikey'])
        follow_user(self.app, self.annafan['id'], self.annafan['apikey'],
                self.tester['id'], self.tester['id'],
                self.testsysadmin['apikey'])
        follow_dataset(self.app, self.testsysadmin['id'],
                self.testsysadmin['apikey'], self.warandpeace['id'],
                self.warandpeace['id'], self.testsysadmin['apikey'])
        follow_dataset(self.app, self.tester['id'], self.tester['apikey'],
                self.warandpeace['id'], self.warandpeace['id'],
                self.testsysadmin['apikey'])
        follow_dataset(self.app, self.russianfan['id'], self.russianfan['apikey'],
                self.warandpeace['id'], self.warandpeace['id'],
                self.testsysadmin['apikey'])
        follow_dataset(self.app, self.annafan['id'], self.annafan['apikey'],
                self.warandpeace['id'], self.warandpeace['id'],
                self.testsysadmin['apikey'])
        follow_group(self.app, self.annafan['id'], self.annafan['apikey'],
                self.davids_group['id'], self.davids_group['id'],
                self.testsysadmin['apikey'])

    @classmethod
    def teardown_class(self):
        ckan.model.repo.rebuild_db()

    def test_01_unfollow_user_not_exists(self):
        '''Test the error response when a user tries to unfollow a user that
        she is not following.

        '''
        error = ckan.tests.call_action_api(self.app, 'unfollow_user',
                apikey=self.annafan['apikey'], status=404,
                id=self.russianfan['id'])
        assert error['message'].startswith('Not found: You are not following ')

    def test_01_unfollow_dataset_not_exists(self):
        '''Test the error response when a user tries to unfollow a dataset that
        she is not following.

        '''
        error = ckan.tests.call_action_api(self.app, 'unfollow_dataset',
                apikey=self.annafan['apikey'], status=404,
                id=self.annakarenina['id'])
        assert error['message'].startswith('Not found: You are not following')

    def test_01_unfollow_group_not_exists(self):
        '''Test the error response when a user tries to unfollow a group that
        she is not following.

        '''
        error = ckan.tests.call_action_api(self.app, 'unfollow_group',
                apikey=self.annafan['apikey'], status=404,
                id=self.rogers_group['id'])
        assert error['message'].startswith('Not found: You are not following')

    def test_01_unfollow_bad_apikey(self):
        '''Test the error response when a user tries to unfollow something
        but provides a bad API key.

        '''
        for action in ('unfollow_user', 'unfollow_dataset', 'unfollow_group'):
            for apikey in ('bad api key', '', '     ', 'None', '3', '35.7',
                    'xxx'):
                error = ckan.tests.call_action_api(self.app, action,
                        apikey=apikey, status=403, id=self.joeadmin['id'])
                assert error['__type'] == 'Authorization Error'

    def test_01_unfollow_missing_apikey(self):
        '''Test error response when calling unfollow_* without api key.'''
        for action in ('unfollow_user', 'unfollow_dataset', 'unfollow_group'):
            error = ckan.tests.call_action_api(self.app, action, status=403,
                    id=self.joeadmin['id'])
            assert error['__type'] == 'Authorization Error'

    def test_01_unfollow_bad_object_id(self):
        '''Test error response when calling unfollow_* with bad object id.'''
        for action in ('unfollow_user', 'unfollow_dataset', 'unfollow_group'):
            for object_id in ('bad id', '     ', 3, 35.7, 'xxx'):
                error = ckan.tests.call_action_api(self.app, action,
                        apikey=self.annafan['apikey'], status=409,
                        id=object_id)
                assert error['id'][0].startswith('Not found')

    def test_01_unfollow_missing_object_id(self):
        for action in ('unfollow_user', 'unfollow_dataset', 'unfollow_group'):
            for id in ('missing', None, ''):
                if id == 'missing':
                    error = ckan.tests.call_action_api(self.app, action,
                            apikey=self.annafan['apikey'], status=409)
                else:
                    error = ckan.tests.call_action_api(self.app, action,
                            apikey=self.annafan['apikey'], status=409, id=id)
                assert error['id'] == [u'Missing value']

    def _unfollow_user(self, follower_id, apikey, object_id, object_arg):
        '''Test a user unfollowing a user via the API.

        :param follower_id: id of the follower.
        :param apikey: API key of the follower.
        :param object_id: id of the object to unfollow.
        :param object_arg: the argument to pass to unfollow_user as the id of
            the object to unfollow, could be the object's id or name.

        '''
        # Record the user's number of followers before.
        count_before = ckan.tests.call_action_api(self.app,
                'user_follower_count', id=object_id)
        followee_count_before = ckan.tests.call_action_api(self.app,
                'followee_count', id=follower_id)
        user_followee_count_before = ckan.tests.call_action_api(self.app,
                'user_followee_count', id=follower_id)

        # Check that the user is following the object.
        am_following = ckan.tests.call_action_api(self.app,
                'am_following_user', apikey=apikey, id=object_id)
        assert am_following is True

        # Make the user unfollow the object.
        ckan.tests.call_action_api(self.app, 'unfollow_user', apikey=apikey,
                id=object_arg)

        # Check that am_following_user now returns False.
        am_following = ckan.tests.call_action_api(self.app,
                'am_following_user', apikey=apikey, id=object_id)
        assert am_following is False

        # Check that the user doesn't appear in the object's list of followers.
        followers = ckan.tests.call_action_api(self.app, 'user_follower_list',
                id=object_id, apikey=self.testsysadmin['apikey'])
        assert len([follower for follower in followers if follower['id'] ==
                follower_id]) == 0

        # Check that the object's follower count has decreased by 1.
        count_after = ckan.tests.call_action_api(self.app,
                'user_follower_count', id=object_id)
        assert count_after == count_before - 1

        # Check that the user doesn't appear in the subject's list of
        # followees.
        followees = ckan.tests.call_action_api(self.app, 'followee_list',
                id=follower_id, apikey=apikey)
        assert len([followee for followee in followees
            if followee['dict']['id'] == object_id]) == 0
        followees = ckan.tests.call_action_api(self.app, 'user_followee_list',
                id=follower_id, apikey=apikey)
        assert len([followee for followee in followees
            if followee['id'] == object_id]) == 0

        # Check the the subject's followee cont has decreased by 1.
        count_after = ckan.tests.call_action_api(self.app, 'followee_count',
                id=follower_id)
        assert count_after == followee_count_before - 1
        count_after = ckan.tests.call_action_api(self.app,
                'user_followee_count', id=follower_id)
        assert count_after == user_followee_count_before - 1

    def _unfollow_dataset(self, user_id, apikey, dataset_id, dataset_arg):
        '''Test a user unfollowing a dataset via the API.

        :param user_id: id of the follower.
        :param apikey: API key of the follower.
        :param dataset_id: id of the object to unfollow.
        :param dataset_arg: the argument to pass to unfollow_dataset as the id
            of the object to unfollow, could be the object's id or name.

        '''
        # Record the dataset's number of followers before.
        count_before = ckan.tests.call_action_api(self.app,
                'dataset_follower_count', id=dataset_id)
        followee_count_before = ckan.tests.call_action_api(self.app,
                'followee_count', id=user_id)
        dataset_followee_count_before = ckan.tests.call_action_api(self.app,
                'dataset_followee_count', id=user_id)

        # Check that the user is following the dataset.
        am_following = ckan.tests.call_action_api(self.app,
                'am_following_dataset', apikey=apikey, id=dataset_id)
        assert am_following is True

        # Make the user unfollow the dataset.
        ckan.tests.call_action_api(self.app, 'unfollow_dataset', apikey=apikey,
                id=dataset_arg)

        # Check that am_following_dataset now returns False.
        am_following = ckan.tests.call_action_api(self.app,
                'am_following_dataset', apikey=apikey, id=dataset_id)
        assert am_following is False

        # Check that the user doesn't appear in the dataset's list of
        # followers.
        followers = ckan.tests.call_action_api(self.app,
                'dataset_follower_list', id=dataset_id,
                apikey=self.testsysadmin['apikey'])
        assert len([follower for follower in followers if follower['id'] ==
                user_id]) == 0

        # Check that the dataset's follower count has decreased by 1.
        count_after = ckan.tests.call_action_api(self.app,
                'dataset_follower_count', id=dataset_id)
        assert count_after == count_before - 1

        # Check that the dataset doesn't appear in the user's list of
        # followees.
        followees = ckan.tests.call_action_api(self.app, 'followee_list',
                id=user_id, apikey=apikey)
        assert len([followee for followee in followees
            if followee['dict']['id'] == dataset_id]) == 0
        followees = ckan.tests.call_action_api(self.app,
                'dataset_followee_list', id=user_id, apikey=apikey)
        assert len([followee for followee in followees
            if followee['id'] == dataset_id]) == 0

        # Check the the user's followee count has decreased by 1.
        count_after = ckan.tests.call_action_api(self.app, 'followee_count',
                id=user_id)
        assert count_after == followee_count_before - 1
        count_after = ckan.tests.call_action_api(self.app,
                'dataset_followee_count', id=user_id)
        assert count_after == dataset_followee_count_before - 1

    def _unfollow_group(self, user_id, apikey, group_id, group_arg):
        '''Test a user unfollowing a group via the API.

        :param user_id: id of the user
        :param apikey: API key of the user
        :param group_id: id of the group
        :param group_arg: the argument to pass to unfollow_group as the id
            of the group, could be the group's id or name.

        '''
        # Record the group's number of followers before.
        count_before = ckan.tests.call_action_api(self.app,
                'group_follower_count', id=group_id)
        followee_count_before = ckan.tests.call_action_api(self.app,
                'followee_count', id=user_id)
        group_followee_count_before = ckan.tests.call_action_api(self.app,
                'group_followee_count', id=user_id)

        # Check that the user is following the group.
        am_following = ckan.tests.call_action_api(self.app,
                'am_following_group', apikey=apikey, id=group_id)
        assert am_following is True

        # Make the user unfollow the group.
        ckan.tests.call_action_api(self.app, 'unfollow_group', apikey=apikey,
                id=group_arg)

        # Check that am_following_group now returns False.
        am_following = ckan.tests.call_action_api(self.app,
                'am_following_group', apikey=apikey, id=group_id)
        assert am_following is False

        # Check that the user doesn't appear in the group's list of
        # followers.
        followers = ckan.tests.call_action_api(self.app, 'group_follower_list',
                id=group_id, apikey=self.testsysadmin['apikey'])
        assert len([follower for follower in followers if follower['id'] ==
                user_id]) == 0

        # Check that the group's follower count has decreased by 1.
        count_after = ckan.tests.call_action_api(self.app,
                'group_follower_count', id=group_id)
        assert count_after == count_before - 1

        # Check that the group doesn't appear in the user's list of
        # followees.
        followees = ckan.tests.call_action_api(self.app, 'followee_list',
                id=user_id, apikey=apikey)
        assert len([followee for followee in followees
            if followee['dict']['id'] == group_id]) == 0
        followees = ckan.tests.call_action_api(self.app,
                'group_followee_list', id=user_id,
                apikey=self.testsysadmin['apikey'])
        assert len([followee for followee in followees
            if followee['id'] == group_id]) == 0

        # Check the the user's followee count has decreased by 1.
        count_after = ckan.tests.call_action_api(self.app, 'followee_count',
                id=user_id)
        assert count_after == followee_count_before - 1
        count_after = ckan.tests.call_action_api(self.app,
                'group_followee_count', id=user_id)
        assert count_after == group_followee_count_before - 1

    def test_02_follower_delete_by_id(self):
        self._unfollow_user(self.annafan['id'], self.annafan['apikey'],
                self.joeadmin['id'], self.joeadmin['id'])
        self._unfollow_dataset(self.annafan['id'], self.annafan['apikey'],
                self.warandpeace['id'], self.warandpeace['id'])
        self._unfollow_group(self.annafan['id'], self.annafan['apikey'],
                self.davids_group['id'], self.davids_group['id'])

class TestFollowerCascade(object):
    '''Tests for on delete cascade of follower table rows.'''

    @classmethod
    def setup_class(self):
        ckan.tests.CreateTestData.create()
        self.tester = {
                'id': ckan.model.User.get('tester').id,
                'apikey': ckan.model.User.get('tester').apikey,
                'name': ckan.model.User.get('tester').name,
                }
        self.testsysadmin = {
                'id': ckan.model.User.get('testsysadmin').id,
                'apikey': ckan.model.User.get('testsysadmin').apikey,
                'name': ckan.model.User.get('testsysadmin').name,
                }
        self.annafan = {
            'id': ckan.model.User.get('annafan').id,
            'apikey': ckan.model.User.get('annafan').apikey,
            'name': ckan.model.User.get('annafan').name,
            }
        self.russianfan = {
            'id': ckan.model.User.get('russianfan').id,
            'apikey': ckan.model.User.get('russianfan').apikey,
            'name': ckan.model.User.get('russianfan').name,
            }
        self.joeadmin = {
            'id': ckan.model.User.get('joeadmin').id,
            'apikey': ckan.model.User.get('joeadmin').apikey,
            'name': ckan.model.User.get('joeadmin').name,
            }
        self.warandpeace = {
            'id': ckan.model.Package.get('warandpeace').id,
            'name': ckan.model.Package.get('warandpeace').name,
            }
        self.annakarenina = {
            'id': ckan.model.Package.get('annakarenina').id,
            'name': ckan.model.Package.get('annakarenina').name,
            }
        self.rogers_group = {
            'id': ckan.model.Group.get('roger').id,
            'name': ckan.model.Group.get('roger').name,
            }
        self.davids_group = {
            'id': ckan.model.Group.get('david').id,
            'name': ckan.model.Group.get('david').name,
            }
        self.app = paste.fixture.TestApp(pylons.test.pylonsapp)

        follow_user(self.app, self.joeadmin['id'], self.joeadmin['apikey'],
                self.testsysadmin['id'], self.testsysadmin['id'],
                self.testsysadmin['apikey'])

        follow_user(self.app, self.annafan['id'], self.annafan['apikey'],
                self.testsysadmin['id'], self.testsysadmin['id'],
                self.testsysadmin['apikey'])
        follow_user(self.app, self.russianfan['id'], self.russianfan['apikey'],
                self.testsysadmin['id'], self.testsysadmin['id'],
                self.testsysadmin['apikey'])

        follow_dataset(self.app, self.joeadmin['id'], self.joeadmin['apikey'],
                self.annakarenina['id'], self.annakarenina['id'],
                self.testsysadmin['apikey'])

        follow_dataset(self.app, self.annafan['id'], self.annafan['apikey'],
                self.annakarenina['id'], self.annakarenina['id'],
                self.testsysadmin['apikey'])
        follow_dataset(self.app, self.russianfan['id'], self.russianfan['apikey'],
                self.annakarenina['id'], self.annakarenina['id'],
                self.testsysadmin['apikey'])

        follow_user(self.app, self.tester['id'], self.tester['apikey'],
                self.joeadmin['id'], self.joeadmin['id'],
                self.testsysadmin['apikey'])

        follow_dataset(self.app, self.testsysadmin['id'],
                self.testsysadmin['apikey'], self.warandpeace['id'],
                self.warandpeace['id'], self.testsysadmin['apikey'])

        follow_group(self.app, self.testsysadmin['id'],
                self.testsysadmin['apikey'], self.davids_group['id'],
                self.davids_group['id'], self.testsysadmin['apikey'])

        session = ckan.model.Session()
        session.delete(ckan.model.User.get('joeadmin'))
        session.commit()

        session.delete(ckan.model.Package.get('warandpeace'))
        session.commit()

        session.delete(ckan.model.Group.get('david'))
        session.commit()

    @classmethod
    def teardown_class(self):
        ckan.model.repo.rebuild_db()

    def test_01_on_delete_cascade_api(self):
        '''
        Test that UserFollowingUser and UserFollowingDataset rows cascade.


        '''
        # It should no longer be possible to get joeadmin's follower list.
        error = ckan.tests.call_action_api(self.app, 'user_follower_list',
                status=409, id='joeadmin', apikey=self.testsysadmin['apikey'])
        assert 'id' in error

        # It should no longer be possible to get joeadmin's followee lists.
        for action in ('followee_list', 'user_followee_list',
                'dataset_followee_list', 'group_followee_list'):
            error = ckan.tests.call_action_api(self.app, action, status=409,
                    id='joeadmin', apikey=self.testsysadmin['apikey'])
            assert 'id' in error

        # It should no longer be possible to get warandpeace's follower list.
        error = ckan.tests.call_action_api(self.app, 'dataset_follower_list',
                status=409, id='warandpeace', apikey=self.testsysadmin['apikey'])
        assert 'id' in error

        # It should no longer be possible to get david's follower list.
        error = ckan.tests.call_action_api(self.app, 'group_follower_list',
                status=409, id='david', apikey=self.testsysadmin['apikey'])
        assert 'id' in error

        # It should no longer be possible to get joeadmin's follower count.
        error = ckan.tests.call_action_api(self.app, 'user_follower_count',
                status=409, id='joeadmin')
        assert 'id' in error

        # It should no longer be possible to get joeadmin's followee counts.
        for action in ('followee_count', 'user_followee_count',
                'dataset_followee_count', 'group_followee_count'):
            error = ckan.tests.call_action_api(self.app, action, status=409,
                    id='joeadmin')
            assert 'id' in error

        # It should no longer be possible to get warandpeace's follower count.
        error = ckan.tests.call_action_api(self.app, 'dataset_follower_count',
                status=409, id='warandpeace')
        assert 'id' in error

        # It should no longer be possible to get david's follower count.
        error = ckan.tests.call_action_api(self.app, 'group_follower_count',
                status=409, id='david')
        assert 'id' in error

        # It should no longer be possible to get am_following for joeadmin.
        error = ckan.tests.call_action_api(self.app, 'am_following_user',
                apikey=self.testsysadmin['apikey'], status=409, id='joeadmin')
        assert 'id' in error

        # It should no longer be possible to get am_following for warandpeace.
        error = ckan.tests.call_action_api(self.app, 'am_following_dataset',
                apikey=self.testsysadmin['apikey'], status=409,
                id='warandpeace')
        assert 'id' in error

        # It should no longer be possible to get am_following for david.
        error = ckan.tests.call_action_api(self.app, 'am_following_group',
                apikey=self.testsysadmin['apikey'], status=409, id='david')
        assert 'id' in error

        # It should no longer be possible to unfollow joeadmin.
        error = ckan.tests.call_action_api(self.app, 'unfollow_user',
                apikey=self.tester['apikey'], status=409, id='joeadmin')
        assert error['id'] == ['Not found: User']

        # It should no longer be possible to unfollow warandpeace.
        error = ckan.tests.call_action_api(self.app, 'unfollow_dataset',
                apikey=self.testsysadmin['apikey'], status=409,
                id='warandpeace')
        assert error['id'] == ['Not found: Dataset']

        # It should no longer be possible to unfollow david.
        error = ckan.tests.call_action_api(self.app, 'unfollow_group',
                apikey=self.testsysadmin['apikey'], status=409, id='david')
        assert error['id'] == ['Not found: Group']

        # It should no longer be possible to follow joeadmin.
        error = ckan.tests.call_action_api(self.app, 'follow_user',
                apikey=self.annafan['apikey'], status=409, id='joeadmin')
        assert 'id' in error

        # It should no longer be possible to follow warandpeace.
        error = ckan.tests.call_action_api(self.app, 'follow_dataset',
                apikey=self.annafan['apikey'], status=409, id='warandpeace')
        assert 'id' in error

        # It should no longer be possible to follow david.
        error = ckan.tests.call_action_api(self.app, 'follow_group',
                apikey=self.annafan['apikey'], status=409, id='david')
        assert 'id' in error

        # Users who joeadmin was following should no longer have him in their
        # follower list.
        followers = ckan.tests.call_action_api(self.app, 'user_follower_list',
                id=self.testsysadmin['id'], apikey=self.testsysadmin['apikey'])
        assert 'joeadmin' not in [follower['name'] for follower in followers]

        # Datasets who joeadmin was following should no longer have him in
        # their follower list.
        followers = ckan.tests.call_action_api(self.app,
                'dataset_follower_list', id=self.annakarenina['id'],
                apikey=self.testsysadmin['apikey'])
        assert 'joeadmin' not in [follower['name'] for follower in followers]

    def test_02_on_delete_cascade_db(self):
        if not are_foreign_keys_supported():
            raise SkipTest("Search not supported")

        # After the previous test above there should be no rows with joeadmin's
        # id in the UserFollowingUser or UserFollowingDataset tables.
        from ckan.model import UserFollowingUser, UserFollowingDataset, UserFollowingGroup
        session = ckan.model.Session()

        query = session.query(UserFollowingUser)
        query = query.filter(UserFollowingUser.follower_id==self.joeadmin['id'])
        assert query.count() == 0

        query = session.query(UserFollowingUser)
        query = query.filter(UserFollowingUser.object_id==self.joeadmin['id'])
        assert query.count() == 0

        query = session.query(UserFollowingDataset)
        query = query.filter(UserFollowingUser.follower_id==self.joeadmin['id'])
        assert query.count() == 0

        # There should be no rows with warandpeace's id in the
        # UserFollowingDataset table.
        query = session.query(UserFollowingDataset)
        query = query.filter(
                UserFollowingDataset.object_id==self.warandpeace['id'])
        assert query.count() == 0

        # There should be no rows with david's id in the
        # UserFollowingGroup table.
        query = session.query(UserFollowingGroup)
        query = query.filter(
                UserFollowingGroup.object_id==self.davids_group['id'])
        assert query.count() == 0

########NEW FILE########
__FILENAME__ = test_misc
from paste.deploy.converters import asbool
from ckan.tests.functional.api.base import *
from ckan.lib.create_test_data import CreateTestData
from ckan.tests import TestController as ControllerTestCase

class MiscApiTestCase(ApiTestCase, ControllerTestCase):

    @classmethod
    def setup_class(self):
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    # Todo: Move this method to the Model API?
    def test_0_tag_counts(self):
        offset = self.offset('/tag_counts')
        res = self.app.get(offset, status=200)
        results = self.loads(res.body)
        assert [u'Flexible \u30a1', 2] in results, results
        assert ["russian", 2] in results, results
        assert ["tolstoy", 1] in results, results

class QosApiTestCase(ApiTestCase, ControllerTestCase):

    def test_throughput(self):
        if not asbool(config.get('ckan.enable_call_timing', "false")):
            raise SkipTest
        # Create some throughput.
        import datetime
        start = datetime.datetime.now()
        offset = self.offset('/rest/package')
        while datetime.datetime.now() - start < datetime.timedelta(0,10):
            res = self.app.get(offset, status=[200])
        # Check throughput.
        offset = self.offset('/qos/throughput/')
        res = self.app.get(offset, status=[200])
        data = self.data_from_res(res)
        throughput = float(data)
        assert throughput > 1, throughput

class TestMiscApi1(Api1TestCase, MiscApiTestCase): pass
class TestQosApi1(Api1TestCase, QosApiTestCase): pass
class TestMiscApi2(Api2TestCase, MiscApiTestCase): pass
class TestQosApi2(Api2TestCase, QosApiTestCase): pass
########NEW FILE########
__FILENAME__ = test_package_search
from nose.tools import assert_raises
from nose.plugins.skip import SkipTest

from urllib import quote

from ckan import plugins
import ckan.lib.search as search
from ckan.tests import setup_test_search_index
from ckan.tests.functional.api.base import *
from ckan.tests import TestController as ControllerTestCase
from ckan.controllers.api import ApiController
from webob.multidict import UnicodeMultiDict

class PackageSearchApiTestCase(ApiTestCase, ControllerTestCase):

    @classmethod
    def setup_class(self):
        setup_test_search_index()
        CreateTestData.create()
        self.package_fixture_data = {
            'name' : u'testpkg',
            'title': 'Some Title',
            'url': u'http://blahblahblah.mydomain',
            'resources': [{u'url':u'http://blahblahblah.mydomain',
                           u'format':u'', u'description':''}],
            'tags': ['russion', 'novel'],
            'license_id': u'gpl-3.0',
            'extras': {'national_statistic':'yes',
                       'geographic_coverage':'England, Wales'},
        }
        CreateTestData.create_arbitrary(self.package_fixture_data)
        self.base_url = self.offset('/search/dataset')

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        search.clear()

    def assert_results(self, res_dict, expected_package_names):
        expected_pkgs = [self.package_ref_from_name(expected_package_name) \
                         for expected_package_name in expected_package_names]
        assert_equal(set(res_dict['results']), set(expected_pkgs))

    def test_00_read_search_params(self):
        def check(request_params, expected_params):
            params = ApiController._get_search_params(request_params)
            assert_equal(params, expected_params)
        # uri parameters
        check(UnicodeMultiDict({'q': '', 'ref': 'boris'}),
              {"q": "", "ref": "boris"})
        # uri json
        check(UnicodeMultiDict({'qjson': '{"q": "", "ref": "boris"}'}),
              {"q": "", "ref": "boris"})
        # posted json
        check(UnicodeMultiDict({'{"q": "", "ref": "boris"}': u'1'}),
              {"q": "", "ref": "boris"})
        check(UnicodeMultiDict({'{"q": "", "ref": "boris"}': u''}),
              {"q": "", "ref": "boris"})
        # no parameters
        check(UnicodeMultiDict({}),
              {})

    def test_00_read_search_params_with_errors(self):
        def check_error(request_params):
            assert_raises(ValueError, ApiController._get_search_params, request_params)            
        # uri json
        check_error(UnicodeMultiDict({'qjson': '{"q": illegal json}'}))
        # posted json
        check_error(UnicodeMultiDict({'{"q": illegal json}': u'1'}))

    def test_01_uri_q(self):
        offset = self.base_url + '?q=%s' % self.package_fixture_data['name']
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, ['testpkg'])
        assert res_dict['count'] == 1, res_dict['count']

    def test_02_post_q(self):
        offset = self.base_url
        query = {'q':'testpkg'}
        res = self.app.post(offset, params=query, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, ['testpkg'])
        assert res_dict['count'] == 1, res_dict['count']

    def test_03_uri_qjson(self):
        query = {'q': self.package_fixture_data['name']}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, ['testpkg'])
        assert res_dict['count'] == 1, res_dict['count']

    def test_04_post_json(self):
        query = {'q': self.package_fixture_data['name']}
        json_query = self.dumps(query)
        offset = self.base_url
        res = self.app.post(offset, params=json_query, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, ['testpkg'])
        assert res_dict['count'] == 1, res_dict['count']

    def test_05_uri_json_tags(self):
        query = {'q': 'annakarenina tags:russian tags:tolstoy'}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina'])
        assert res_dict['count'] == 1, res_dict
        
    def test_05_uri_json_tags_multiple(self):
        query = {'q': 'tags:russian tags:tolstoy'}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina'])
        assert res_dict['count'] == 1, res_dict

    def test_06_uri_q_tags(self):
        query = webhelpers.util.html_escape('annakarenina tags:russian tags:tolstoy')
        offset = self.base_url + '?q=%s' % query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina'])
        assert res_dict['count'] == 1, res_dict['count']

    def test_08_uri_qjson_malformed(self):
        offset = self.base_url + '?qjson="q":""' # user forgot the curly braces
        res = self.app.get(offset, status=400)
        self.assert_json_response(res, 'Bad request - Could not read parameters')
        
    def test_09_just_tags(self):
        offset = self.base_url + '?q=tags:russian'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 2, res_dict

    def test_10_multiple_tags(self):
        offset = self.base_url + '?q=tags:tolstoy tags:russian'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 1, res_dict

    def test_12_all_packages_qjson(self):
        query = {'q': ''}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert_equal(res_dict['count'], 3)

    def test_12_all_packages_q(self):
        offset = self.base_url + '?q=""'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert_equal(res_dict['count'], 3)

    def test_12_all_packages_no_q(self):
        offset = self.base_url
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert_equal(res_dict['count'], 3)

    def test_12_filter_by_openness(self):
        offset = self.base_url + '?filter_by_openness=1'
        res = self.app.get(offset, status=400) # feature dropped in #1360
        assert "'filter_by_openness'" in res.body, res.body

    def test_12_filter_by_downloadable(self):
        offset = self.base_url + '?filter_by_downloadable=1'
        res = self.app.get(offset, status=400) # feature dropped in #1360
        assert "'filter_by_downloadable'" in res.body, res.body


class LegacyOptionsTestCase(ApiTestCase, ControllerTestCase):
    '''Here are tests with URIs in the syntax they were in
    for API v1 and v2.'''
    @classmethod
    def setup_class(self):
        setup_test_search_index()
        CreateTestData.create()
        self.package_fixture_data = {
            'name' : u'testpkg',
            'title': 'Some Title',
            'url': u'http://blahblahblah.mydomain',
            'resources': [{u'url':u'http://blahblahblah.mydomain',
                           u'format':u'', u'description':''}],
            'tags': ['russion', 'novel'],
            'license_id': u'gpl-3.0',
            'extras': {'national_statistic':'yes',
                       'geographic_coverage':'England, Wales'},
        }
        CreateTestData.create_arbitrary(self.package_fixture_data)
        self.base_url = self.offset('/search/dataset')

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        search.clear()

    def test_07_uri_qjson_tags(self):
        query = {'q': '', 'tags':['tolstoy']}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina'])
        assert res_dict['count'] == 1, res_dict

    def test_07_uri_qjson_tags_with_flexible_query(self):
        query = {'q': '', 'tags':['Flexible \u30a1']}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina', u'warandpeace'])
        assert res_dict['count'] == 2, res_dict

    def test_07_uri_qjson_tags_multiple(self):
        query = {'q': '', 'tags':['tolstoy', 'russian', u'Flexible \u30a1']}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        print offset
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina'])
        assert res_dict['count'] == 1, res_dict

    def test_07_uri_qjson_tags_reverse(self):
        query = {'q': '', 'tags':['russian']}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina', u'warandpeace'])
        assert res_dict['count'] == 2, res_dict

    def test_07_uri_qjson_extras(self):
        # TODO: solr is not currently set up to allow partial matches 
        #       and extras are not saved as multivalued so this
        #       test will fail. Make extras multivalued or remove?
        raise SkipTest()
    
        query = {"geographic_coverage":"England"}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, ['testpkg'])
        assert res_dict['count'] == 1, res_dict

    def test_07_uri_qjson_extras_2(self):
        query = {"national_statistic":"yes"}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, ['testpkg'])
        assert res_dict['count'] == 1, res_dict

    def test_08_all_fields(self):
        rating = model.Rating(user_ip_address=u'123.1.2.3',
                              package=self.anna,
                              rating=3.0)
        model.Session.add(rating)
        model.repo.commit_and_remove()
        
        query = {'q': 'russian', 'all_fields': 1}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 2, res_dict
        for rec in res_dict['results']:
            if rec['name'] == 'annakarenina':
                anna_rec = rec
                break
        assert anna_rec['name'] == 'annakarenina', res_dict['results']
        assert anna_rec['title'] == 'A Novel By Tolstoy', anna_rec['title']
        assert anna_rec['license_id'] == u'other-open', anna_rec['license_id']
        assert len(anna_rec['tags']) == 3, anna_rec['tags']
        for expected_tag in ['russian', 'tolstoy', u'Flexible \u30a1']:
            assert expected_tag in anna_rec['tags'], anna_rec['tags']

        # try alternative syntax
        offset = self.base_url + '?q=russian&all_fields=1'
        res2 = self.app.get(offset, status=200)
        assert_equal(res2.body, res.body)

    def test_08_all_fields_syntax_error(self):
        offset = self.base_url + '?all_fields=should_be_boolean' # invalid all_fields value
        res = self.app.get(offset, status=400)
        assert('boolean' in res.body)
        assert('all_fields' in res.body)
        self.assert_json_response(res, 'boolean')

    def test_09_just_tags(self):
        offset = self.base_url + '?tags=tolstoy'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 1, res_dict

    def test_10_single_tag_with_plus(self):
        tagname = "Flexible+" + quote(u'\u30a1'.encode('utf8'))
        offset = self.base_url + "?tags=%s&all_fields=1"%tagname
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 2, res_dict

    def test_10_multi_tags_with_ampersand_including_a_multiword_tagame(self):
        tagname = "Flexible+" + quote(u'\u30a1'.encode('utf8'))
        offset = self.base_url + '?tags=tolstoy&tags=%s&all_fields=1' % tagname
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 1, res_dict

    def test_10_multiple_tags_with_ampersand(self):
        offset = self.base_url + '?tags=tolstoy&tags=russian&all_fields=1'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 1, res_dict

    def test_10_many_tags_with_ampersand(self):
        offset = self.base_url + '?tags=tolstoy&tags=russian&tags=tolstoy'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 1, res_dict

    def test_11_pagination_limit(self):
        offset = self.base_url + '?all_fields=1&q=tags:russian&limit=1&order_by=name'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 2, res_dict
        assert len(res_dict['results']) == 1, res_dict
        assert res_dict['results'][0]['name'] == 'annakarenina', res_dict['results'][0]['name']

    def test_11_pagination_offset_limit(self):
        offset = self.base_url + '?all_fields=1&q=tags:russian&offset=1&limit=1&order_by=name'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 2, res_dict
        assert len(res_dict['results']) == 1, res_dict
        assert res_dict['results'][0]['name'] == 'warandpeace', res_dict['results'][0]['name']

    def test_11_pagination_syntax_error(self):
        offset = self.base_url + '?all_fields=1&q="tags:russian"&start=should_be_integer&rows=1&order_by=name' # invalid offset value
        res = self.app.get(offset, status=400)
        print res.body
        assert('should_be_integer' in res.body)

    def test_13_just_groups(self):
        offset = self.base_url + '?groups=roger'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 1, res_dict

    def test_14_empty_parameter_ignored(self):
        offset = self.base_url + '?groups=roger&title='
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 1, res_dic

class TestPackageSearchApi1(Api1TestCase, PackageSearchApiTestCase,
                            LegacyOptionsTestCase): pass
class TestPackageSearchApi2(Api2TestCase, PackageSearchApiTestCase,
                            LegacyOptionsTestCase): pass
class TestPackageSearchApi3(Api3TestCase, PackageSearchApiTestCase):
    '''Here are tests with URIs in specifically SOLR syntax.'''
    def test_07_uri_qjson_tags(self):
        query = {'q': 'tags:tolstoy'}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina'])
        assert res_dict['count'] == 1, res_dict

    def test_07_uri_qjson_tags_with_unicode(self):
        query = {'q': u'tags:"Flexible \u30a1"'}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina', u'warandpeace'])
        assert res_dict['count'] == 2, res_dict

    def test_07_uri_qjson_tags_multiple(self):
        query = {'q': 'tags:tolstoy tags:russian'}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        print offset
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina'])
        assert res_dict['count'] == 1, res_dict

    def test_07_uri_qjson_tags_reverse(self):
        query = {'q': 'tags:russian'}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, [u'annakarenina', u'warandpeace'])
        assert res_dict['count'] == 2, res_dict

    def test_07_uri_qjson_extras_2(self):
        query = {'q': "national_statistic:yes"}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        self.assert_results(res_dict, ['testpkg'])
        assert res_dict['count'] == 1, res_dict

    def test_08_all_fields(self):
        query = {'q': 'russian', 'fl': '*'}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 2, res_dict
        for rec in res_dict['results']:
            if rec['name'] == 'annakarenina':
                anna_rec = rec
                break
        assert anna_rec['name'] == 'annakarenina', res_dict['results']
        assert anna_rec['title'] == 'A Novel By Tolstoy', anna_rec['title']
        assert anna_rec['license_id'] == u'other-open', anna_rec['license_id']
        assert len(anna_rec['tags']) == 3, anna_rec['tags']
        for expected_tag in ['russian', 'tolstoy', u'Flexible \u30a1']:
            assert expected_tag in anna_rec['tags']

        # try alternative syntax
        offset = self.base_url + '?q=russian&fl=*'
        res2 = self.app.get(offset, status=200)
        assert_equal(res2.body, res.body)

    def test_09_just_tags(self):
        offset = self.base_url + '?q=tags:russian&fl=*'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 2, res_dict

    def test_11_pagination_limit(self):
        offset = self.base_url + '?fl=*&q=tags:russian&rows=1&sort=name asc'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 2, res_dict
        assert len(res_dict['results']) == 1, res_dict
        assert res_dict['results'][0]['name'] == 'annakarenina', res_dict['results'][0]['name']

    def test_11_pagination_offset_limit(self):
        offset = self.base_url + '?fl=*&q=tags:russian&start=1&rows=1&sort=name asc'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 2, res_dict
        assert len(res_dict['results']) == 1, res_dict
        assert res_dict['results'][0]['name'] == 'warandpeace', res_dict['results'][0]['name']

    def test_11_pagination_syntax_error(self):
        offset = self.base_url + '?fl=*&q=tags:russian&start=should_be_integer&rows=1&sort=name asc' # invalid offset value
        res = self.app.get(offset, status=400)
        print res.body
        assert('should_be_integer' in res.body)

    def test_12_v1_or_v2_syntax(self):
        offset = self.base_url + '?all_fields=1'
        res = self.app.get(offset, status=400)
        assert("Invalid search parameters: ['all_fields']" in res.body), res.body

    def test_13_just_groups(self):
        offset = self.base_url + '?q=groups:roger'
        res = self.app.get(offset, status=200)
        res_dict = self.data_from_res(res)
        assert res_dict['count'] == 1, res_dict

########NEW FILE########
__FILENAME__ = test_resource
from ckan.tests.functional.api.base import ApiTestCase, CreateTestData
from ckan.tests import TestController as ControllerTestCase
from ckan import model

class TestResourceApi(ApiTestCase, ControllerTestCase):
    api_version = '2'

    @classmethod
    def setup_class(self):
        CreateTestData.create()
        self.ab = 'http://site.com/a/b.txt'
        self.cd = 'http://site.com/c/d.txt'
        self.package_fixture_data = {
            'name' : u'testpkg',
            'title': 'Some Title',
            'url': u'http://blahblahblah.mydomain',
            'resources':[
                {'url':self.ab,
                 'description':'This is site ab.',
                 'format':'Excel spreadsheet',
                 'alt_url':'alt',
                 'extras':{'size':'100'},
                 'hash':'abc-123'},
                {'url':self.cd,
                 'description':'This is site cd.',
                 'format':'CSV',
                 'alt_url':'alt',
                 'extras':{'size':'100'},
                 'hash':'qwe-456'},
                ],
            'tags': ['russian', 'novel'],
            'license_id': u'gpl-3.0',
            'extras': {'national_statistic':'yes',
                       'geographic_coverage':'England, Wales'},
        }
        CreateTestData.create_arbitrary(self.package_fixture_data)
        self.base_url = self.offset('/util/resource')

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_good_input(self):
        offset = self.base_url + '/format_autocomplete?incomplete=cs'
        result = self.app.get(offset, status=200)
        content_type = result.header_dict['Content-Type']
        assert 'application/json' in content_type, content_type
        res_json = self.loads(result.body)
        assert 'ResultSet' in res_json, res_json
        assert 'Result' in res_json.get('ResultSet'), res_json
        result_json = res_json.get('ResultSet').get('Result')
        assert len(result_json) == 1, result_json
        assert 'Format' in result_json[0], result_json
        assert result_json[0].get('Format') == 'csv'

    def test_missing_format(self):
        offset = self.base_url + '/format_autocomplete?incomplete=incorrectformat'
        result = self.app.get(offset, status=200)
        content_type = result.header_dict['Content-Type']
        assert 'application/json' in content_type, content_type
        res_json = self.loads(result.body)
        assert 'ResultSet' in res_json, res_json
        assert 'Result' in res_json.get('ResultSet'), res_json
        result_json = res_json.get('ResultSet').get('Result')
        assert not result_json, result_json

########NEW FILE########
__FILENAME__ = test_resource_search
from ckan.tests.functional.api.base import *
from ckan.tests import TestController as ControllerTestCase

class ResourceSearchApiTestCase(ApiTestCase, ControllerTestCase):

    @classmethod
    def setup_class(self):
        CreateTestData.create()
        self.ab = 'http://site.com/a/b.txt'
        self.cd = 'http://site.com/c/d.txt'
        self.package_fixture_data = {
            'name' : u'testpkg',
            'title': 'Some Title',
            'url': u'http://blahblahblah.mydomain',
            'resources':[
                {'url':self.ab,
                 'description':'This is site ab.',
                 'format':'Excel spreadsheet',
                 'alt_url':'alt',
                 'extras':{'size':'100'},
                 'hash':'abc-123'},
                {'url':self.cd,
                 'description':'This is site cd.',
                 'format':'Office spreadsheet',
                 'alt_url':'alt',
                 'extras':{'size':'100'},
                 'hash':'qwe-456'},
                ],
            'tags': ['russion', 'novel', 'Leo Tolstoy'],
            'license_id': u'gpl-3.0',
            'extras': {'national_statistic':'yes',
                       'geographic_coverage':'England, Wales'},
        }
        CreateTestData.create_arbitrary(self.package_fixture_data)
        self.base_url = self.offset('/search/resource')

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def assert_urls_in_search_results(self, offset, expected_urls):
        result = self.app.get(offset, status=200)
        result_dict = self.loads(result.body)
        resources = [model.Session.query(model.Resource).get(resource_id) for resource_id in result_dict['results']]
        urls = set([resource.url for resource in resources])
        assert urls == set(expected_urls), urls
        

    def test_01_url(self):
        offset = self.base_url + '?url=site'
        self.assert_urls_in_search_results(offset, [self.ab, self.cd])

    def test_02_url_qjson(self):
        query = {'url':'site'}
        json_query = self.dumps(query)
        offset = self.base_url + '?qjson=%s' % json_query
        self.assert_urls_in_search_results(offset, [self.ab, self.cd])

    def test_03_post_qjson(self):
        query = {'url':'site'}
        json_query = self.dumps(query)
        offset = self.base_url
        result = self.app.post(offset, params=json_query, status=200)
        expected_urls = [self.ab, self.cd]
        result_dict = self.loads(result.body)
        resources = [model.Session.query(model.Resource).get(resource_id) for resource_id in result_dict['results']]
        urls = set([resource.url for resource in resources])
        assert urls == set(expected_urls), urls

    def test_04_bad_option(self):
        offset = self.base_url + '?random=option'
        result = self.app.get(offset, status=400)
        self.assert_json_response(result, 'Bad request - Bad search option')

    def test_05_options(self):
        offset = self.base_url + '?url=site&all_fields=1&callback=mycallback'
        result = self.app.get(offset, status=200)
        assert re.match('^mycallback\(.*\);$', result.body), result.body
        assert 'package_id' in result.body, result.body


class TestResourceSearchApi1(Api1TestCase, ResourceSearchApiTestCase): pass
class TestResourceSearchApi2(Api2TestCase, ResourceSearchApiTestCase): pass

########NEW FILE########
__FILENAME__ = test_revision_search
from ckan.tests.functional.api.base import *
from ckan.tests import TestController as ControllerTestCase

class RevisionSearchApiTestCase(ApiTestCase, ControllerTestCase):

    @classmethod
    def setup_class(self):
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_12_search_revision_bad_requests(self):
        offset = self.offset('/search/revision')
        # Check bad request.
        res = self.app.get(offset, status=400)
        self.assert_json_response(res, 'Bad request - Missing search term')
        res = self.app.get(offset+'?since_rev=2010-01-01T00:00:00', status=400)
        self.assert_json_response(res, 'Bad request - Missing search term')
        res = self.app.get(offset+'?since_revision=2010-01-01T00:00:00', status=400)
        self.assert_json_response(res, 'Bad request - Missing search term')
        res = self.app.get(offset+'?since_id=', status=400)
        self.assert_json_response(res, 'Bad request - No revision specified')
        res = self.app.get(offset+'?since_id=1234', status=404)
        self.assert_json_response(res, 'Not found - There is no revision')

    def test_12_search_revision_since_rev(self):
        offset = self.offset('/search/revision')
        revs = model.Session.query(model.Revision).all()
        rev_first = revs[-1]
        params = "?since_id=%s" % rev_first.id
        res = self.app.get(offset+params, status=200)
        res_list = self.data_from_res(res)
        assert rev_first.id not in res_list
        for rev in revs[:-1]:
            assert rev.id in res_list, (rev.id, res_list)
        rev_last = revs[0]
        params = "?since_id=%s" % rev_last.id
        res = self.app.get(offset+params, status=200)
        res_list = self.data_from_res(res)
        assert res_list == [], res_list

    def test_12_search_revision_since_time(self):
        offset = self.offset('/search/revision')
        revs = model.Session.query(model.Revision).all()
        # Check since time of first.
        rev_first = revs[-1]
        params = "?since_time=%s" % rev_first.timestamp.isoformat()
        res = self.app.get(offset+params, status=200)
        res_list = self.data_from_res(res)
        assert rev_first.id not in res_list
        for rev in revs[:-1]:
            assert rev.id in res_list, (rev.id, res_list)
        # Check since time of last.
        rev_last = revs[0]
        params = "?since_time=%s" % rev_last.timestamp.isoformat()
        res = self.app.get(offset+params, status=200)
        res_list = self.data_from_res(res)
        assert res_list == [], res_list
        # Check bad format.
        params = "?since_time=2010-04-31T23:45"
        res = self.app.get(offset+params, status=400)
        self.assert_json_response(res, 'Bad request - ValueError: day is out of range for month')


class TestRevisionSearchApi1(Api1TestCase, RevisionSearchApiTestCase): pass
class TestRevisionSearchApi2(Api2TestCase, RevisionSearchApiTestCase): pass

########NEW FILE########
__FILENAME__ = test_user
import paste
from pylons import config
from nose.tools import assert_equal

import ckan.logic as logic
import ckan.new_authz as new_authz
from ckan import model
from ckan.lib.create_test_data import CreateTestData
from ckan.tests import TestController as ControllerTestCase
from ckan.tests.pylons_controller import PylonsTestCase
from ckan.tests import url_for
import ckan.config.middleware
from ckan.common import json


class TestUserApi(ControllerTestCase):
    @classmethod
    def setup_class(cls):
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_autocomplete(self):
        response = self.app.get(
            url=url_for(controller='api', action='user_autocomplete', ver=2),
            params={
               'q': u'sysadmin',
            },
            status=200,
        )
        print response.json
        assert set(response.json[0].keys()) == set(['id', 'name', 'fullname'])
        assert_equal(response.json[0]['name'], u'testsysadmin')
        assert_equal(response.header('Content-Type'), 'application/json;charset=utf-8')

    def test_autocomplete_multiple(self):
        response = self.app.get(
            url=url_for(controller='api', action='user_autocomplete', ver=2),
            params={
               'q': u'tes',
            },
            status=200,
        )
        print response.json
        assert_equal(len(response.json), 2)

    def test_autocomplete_limit(self):
        response = self.app.get(
            url=url_for(controller='api', action='user_autocomplete', ver=2),
            params={
               'q': u'tes',
               'limit': 1
            },
            status=200,
        )
        print response.json
        assert_equal(len(response.json), 1)


class TestCreateUserApiDisabled(PylonsTestCase):
    '''
    Tests for the creating user when create_user_via_api is disabled.
    '''

    @classmethod
    def setup_class(cls):
        CreateTestData.create()
        cls._original_config = config.copy()
        new_authz.clear_auth_functions_cache()
        wsgiapp = ckan.config.middleware.make_app(
            config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)
        cls.sysadmin_user = model.User.get('testsysadmin')
        PylonsTestCase.setup_class()

    @classmethod
    def teardown_class(cls):
        config.clear()
        config.update(cls._original_config)
        new_authz.clear_auth_functions_cache()
        PylonsTestCase.teardown_class()

        model.repo.rebuild_db()

    def test_user_create_api_enabled_sysadmin(self):
        params = {
            'name': 'testinganewusersysadmin',
            'email': 'testinganewuser@ckan.org',
            'password': 'random',
        }
        res = self.app.post(
            '/api/3/action/user_create',
            json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
            expect_errors=True)
        res_dict = res.json
        assert res_dict['success'] is True

    def test_user_create_api_disabled_anon(self):
        params = {
            'name': 'testinganewuseranon',
            'email': 'testinganewuser@ckan.org',
            'password': 'random',
        }
        res = self.app.post('/api/3/action/user_create', json.dumps(params),
                            expect_errors=True)
        res_dict = res.json
        assert res_dict['success'] is False


class TestCreateUserApiEnabled(PylonsTestCase):
    '''
    Tests for the creating user when create_user_via_api is enabled.
    '''

    @classmethod
    def setup_class(cls):
        CreateTestData.create()
        cls._original_config = config.copy()
        config['ckan.auth.create_user_via_api'] = True
        new_authz.clear_auth_functions_cache()
        wsgiapp = ckan.config.middleware.make_app(
            config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)
        PylonsTestCase.setup_class()
        cls.sysadmin_user = model.User.get('testsysadmin')

    @classmethod
    def teardown_class(cls):
        config.clear()
        config.update(cls._original_config)
        new_authz.clear_auth_functions_cache()
        PylonsTestCase.teardown_class()

        model.repo.rebuild_db()

    def test_user_create_api_enabled_sysadmin(self):
        params = {
            'name': 'testinganewusersysadmin',
            'email': 'testinganewuser@ckan.org',
            'password': 'random',
        }
        res = self.app.post(
            '/api/3/action/user_create',
            json.dumps(params),
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)})
        res_dict = res.json
        assert res_dict['success'] is True

    def test_user_create_api_enabled_anon(self):
        params = {
            'name': 'testinganewuseranon',
            'email': 'testinganewuser@ckan.org',
            'password': 'random',
        }
        res = self.app.post('/api/3/action/user_create', json.dumps(params))
        res_dict = res.json
        assert res_dict['success'] is True


class TestCreateUserWebDisabled(PylonsTestCase):
    '''
    Tests for the creating user by create_user_via_web is disabled.
    '''

    @classmethod
    def setup_class(cls):
        CreateTestData.create()
        cls._original_config = config.copy()
        config['ckan.auth.create_user_via_web'] = False
        new_authz.clear_auth_functions_cache()
        wsgiapp = ckan.config.middleware.make_app(
            config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)
        cls.sysadmin_user = model.User.get('testsysadmin')
        PylonsTestCase.setup_class()

    @classmethod
    def teardown_class(cls):
        config.clear()
        config.update(cls._original_config)
        new_authz.clear_auth_functions_cache()
        PylonsTestCase.teardown_class()

        model.repo.rebuild_db()

    def test_user_create_api_disabled(self):
        params = {
            'name': 'testinganewuser',
            'email': 'testinganewuser@ckan.org',
            'password': 'random',
        }
        res = self.app.post('/api/3/action/user_create', json.dumps(params),
                            expect_errors=True)
        res_dict = res.json
        assert res_dict['success'] is False


class TestCreateUserWebEnabled(PylonsTestCase):
    '''
    Tests for the creating user by create_user_via_web is enabled.
    '''

    @classmethod
    def setup_class(cls):
        CreateTestData.create()
        cls._original_config = config.copy()
        config['ckan.auth.create_user_via_web'] = True
        new_authz.clear_auth_functions_cache()
        wsgiapp = ckan.config.middleware.make_app(
            config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)
        cls.sysadmin_user = model.User.get('testsysadmin')
        PylonsTestCase.setup_class()

    @classmethod
    def teardown_class(cls):
        config.clear()
        config.update(cls._original_config)
        new_authz.clear_auth_functions_cache()
        PylonsTestCase.teardown_class()

        model.repo.rebuild_db()

    def test_user_create_api_disabled(self):
        params = {
            'name': 'testinganewuser',
            'email': 'testinganewuser@ckan.org',
            'password': 'random',
        }
        res = self.app.post('/api/3/action/user_create', json.dumps(params),
                            expect_errors=True)
        res_dict = res.json
        assert res_dict['success'] is False


class TestUserActions(object):

    @classmethod
    def setup_class(cls):
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_user_create_simple(self):
        '''Simple creation of a new user by a non-sysadmin user.'''
        context = {
            'model': model,
            'session': model.Session,
            'user': 'tester'
        }
        data_dict = {
            'name': 'a-new-user',
            'email': 'a.person@example.com',
            'password': 'supersecret',
        }

        user_dict = logic.get_action('user_create')(context, data_dict)

        assert_equal(user_dict['name'], 'a-new-user')
        assert 'email' in user_dict
        assert 'apikey' in user_dict
        assert 'password' not in user_dict

########NEW FILE########
__FILENAME__ = test_util
from nose.tools import assert_equal

from ckan import model, __version__
from ckan.lib.create_test_data import CreateTestData
from ckan.tests import TestController as ControllerTestCase
from ckan.tests import url_for
from ckan.common import json

class TestUtil(ControllerTestCase):
    @classmethod
    def setup_class(cls):
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_package_slug_invalid(self):
        response = self.app.get(
            url=url_for(controller='api', action='is_slug_valid', ver=2),
            params={
               'type': u'package',
               'slug': u'edit',
            },
            status=200,
        )
        assert_equal(response.body, '{"valid": false}')
        assert_equal(response.header('Content-Type'), 'application/json;charset=utf-8')

        response = self.app.get(
            url=url_for(controller='api', action='is_slug_valid', ver=2),
            params={
               'type': u'package',
               'slug': u'new',
            },
            status=200,
        )
        assert_equal(response.body, '{"valid": false}')
        assert_equal(response.header('Content-Type'), 'application/json;charset=utf-8')

    def test_package_slug_valid(self):
        response = self.app.get(
            url=url_for(controller='api', action='is_slug_valid', ver=2),
            params={
               'type': u'package',
               'slug': u'A New Title * With & Funny CHARacters',
            },
            status=200,
        )
        assert_equal(response.body, '{"valid": true}')
        assert_equal(response.header('Content-Type'), 'application/json;charset=utf-8')

        response = self.app.get(
            url=url_for(controller='api', action='is_slug_valid', ver=2),
            params={
               'type': u'package',
               'slug': u'warandpeace',
            },
            status=200,
        )
        assert_equal(response.body, '{"valid": false}')
        assert_equal(response.header('Content-Type'), 'application/json;charset=utf-8')

    def test_dataset_autocomplete_match_name(self):
        url = url_for(controller='api', action='dataset_autocomplete', ver=2)
        assert_equal(url, '/api/2/util/dataset/autocomplete')
        response = self.app.get(
            url=url,
            params={
               'incomplete': u'an',
            },
            status=200,
        )
        assert_equal(response.body, '{"ResultSet": {"Result": [{"match_field": "name", "match_displayed": "annakarenina", "name": "annakarenina", "title": "A Novel By Tolstoy"}]}}')
        assert_equal(response.header('Content-Type'), 'application/json;charset=utf-8')

    def test_dataset_autocomplete_match_title(self):
        url = url_for(controller='api', action='dataset_autocomplete', ver=2)
        assert_equal(url, '/api/2/util/dataset/autocomplete')
        response = self.app.get(
            url=url,
            params={
               'incomplete': u'a n',
            },
            status=200,
        )
        assert_equal(response.body, '{"ResultSet": {"Result": [{"match_field": "title", "match_displayed": "A Novel By Tolstoy (annakarenina)", "name": "annakarenina", "title": "A Novel By Tolstoy"}]}}')
        assert_equal(response.header('Content-Type'), 'application/json;charset=utf-8')

    def test_tag_autocomplete(self):
        url = url_for(controller='api', action='tag_autocomplete', ver=2)
        assert_equal(url, '/api/2/util/tag/autocomplete')
        response = self.app.get(
            url=url,
            params={
               'incomplete': u'ru',
            },
            status=200,
        )
        assert_equal(response.body, '{"ResultSet": {"Result": [{"Name": "russian"}]}}')
        assert_equal(response.header('Content-Type'), 'application/json;charset=utf-8')

    def test_group_autocomplete(self):
        url = url_for(controller='api', action='group_autocomplete', ver=2)
        assert_equal(url, '/api/2/util/group/autocomplete')
        response = self.app.get(
            url=url,
            params={
               'q': u'dave',
            },
            status=200,
        )
        results = json.loads(response.body)
        assert_equal(len(results), 1)
        assert_equal(results[0]['name'], 'david')
        assert_equal(results[0]['title'], 'Dave\'s books')
        assert_equal(response.header('Content-Type'), 'application/json;charset=utf-8')

    def test_markdown(self):
        markdown = '''##Title'''
        response = self.app.get(
            url=url_for(controller='api', action='markdown', ver=2),
            params={'q': markdown},
            status=200,
        )
        assert_equal(response.body, '"<h2>Title</h2>"')

    def test_munge_package_name(self):
        response = self.app.get(
            url=url_for(controller='api', action='munge_package_name', ver=2),
            params={'name': 'test name'},
            status=200,
        )
        assert_equal(response.body, '"test-name"')

    def test_munge_title_to_package_name(self):
        response = self.app.get(
            url=url_for(controller='api', action='munge_title_to_package_name', ver=2),
            params={'name': 'Test title'},
            status=200,
        )
        assert_equal(response.body, '"test-title"')

    def test_munge_tag(self):
        response = self.app.get(
            url=url_for(controller='api', action='munge_tag', ver=2),
            params={'name': 'Test subject'},
            status=200,
        )
        assert_equal(response.body, '"test-subject"')

    def test_status(self):
        response = self.app.get(
            url=url_for(controller='api', action='status', ver=2),
            params={},
            status=200,
        )
        res = json.loads(response.body)
        assert_equal(res['ckan_version'], __version__)
        assert_equal(res['site_url'], 'http://test.ckan.net')
        assert_equal(res['site_title'], 'CKAN')
        assert_equal(res['site_description'], '')
        assert_equal(res['locale_default'], 'en')

        assert_equal(type(res['extensions']), list)
        expected_extensions = set(('stats',))
        assert_equal(set(res['extensions']), expected_extensions)

########NEW FILE########
__FILENAME__ = base
from ckan.tests.html_check import HtmlCheckMethods
from ckan.tests import TestController as ControllerTestCase

class FunctionalTestCase(ControllerTestCase, HtmlCheckMethods):
    pass

########NEW FILE########
__FILENAME__ = test_activity
from pylons import config
from pylons.test import pylonsapp
from paste.deploy.converters import asbool
import paste.fixture
from routes import url_for
from nose import SkipTest

import ckan
from ckan.logic.action.create import package_create, user_create, group_create
from ckan.logic.action.create import follow_dataset, follow_user
from ckan.logic.action.update import package_update, resource_update
from ckan.logic.action.update import user_update, group_update
from ckan.logic.action.delete import package_delete
from ckan.tests.html_check import HtmlCheckMethods

class TestActivity(HtmlCheckMethods):
    """Test the rendering of activity streams into HTML pages.

    Activity streams are tested in detail elsewhere, this class just briefly
    tests the rendering of activity streams to HTML.

    """
    @classmethod
    def setup(cls):
        if not asbool(config.get('ckan.activity_streams_enabled', 'true')):
            raise SkipTest('Activity streams not enabled')
        ckan.tests.CreateTestData.create()
        cls.sysadmin_user = ckan.model.User.get('testsysadmin')
        cls.app = paste.fixture.TestApp(pylonsapp)

    @classmethod
    def teardown(cls):
        ckan.model.repo.rebuild_db()


    def test_user_activity(self):
        """Test user activity streams HTML rendering."""

        # Register a new user.
        user_dict = {'name': 'billybeane',
                'fullname': 'Billy Beane',
                'about': 'General Manager, Oakland Athletics',
                'email': 'billy@beane.org',
                'password': 'b1lly'}
        context = {
            'model': ckan.model,
            'session': ckan.model.Session,
            'user': self.sysadmin_user.name,
            'allow_partial_update': True,
            }
        user = user_create(context, user_dict)
        offset = url_for(controller='user', action='read', id=user['id'])
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s signed up' % user['fullname'] in stripped, stripped

        # Create a new package.
        package = {
            'name' : 'baseball_stats',
            'title' : "Billy's Stats about Baseball Players",
        }
        context['user'] = user['name']
        # FIXME This test use an old way to get at the schema to
        # recreate this we need to pretend to be using the api. We
        # should not be calling package_create like this we should be
        # going via the api or package controllers
        context['api_version'] = 3
        context['ignore_auth'] = True
        package = package_create(context, package)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s created the dataset %s ' % (
                user['fullname'], package['title']) in stripped, stripped

        # Add a resource to the package.
        resource = {
            'url': 'http://www.example.com',
            'description': "Chad Bradford's OBP Stats`",
            'format': 'cvs',
            'name': 'Chad Bradford Stats',
            }
        package['resources'].append(resource)
        request_data = {
                'id': package['id'],
                'resources': package['resources'],
                }
        package = package_update(context, request_data)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s added the resource %s to the dataset %s' % \
                (user['fullname'], resource['name'], package['title']) \
                in stripped, stripped

        # Update the package.
        package['title'] =  "Billy's Updated Stats about Baseball Players"
        package = package_update(context, package)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s updated the dataset %s' \
                % (user['fullname'], package['title']) \
                in stripped, stripped

        # Update the resource.
        resource = package['resources'][0]
        resource['name'] = 'Chad Bradford Updated Stats'
        resource = resource_update(context, resource)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s updated the resource %s in the dataset %s' \
                % (user['fullname'], resource['name'], package['title']) \
                in stripped, stripped

        # Delete the resource.
        context['allow_partial_update'] = False
        package['resources'] = []
        package_update(context, package)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s deleted the resource %s from the dataset %s' % \
                (user['fullname'], resource['name'], package['title']) \
                in stripped, stripped

        # Follow the package.
        follow_dataset(context, {'id': package['id']})
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s started following %s' % (user['fullname'],
                package['title']) not in stripped, stripped

        # Follow another user.
        follow_user(context, {'id': 'joeadmin'})
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s started following %s' % (user['fullname'],
                'joeadmin') not in stripped, stripped

        # Create a new group.
        group = {
            'name': 'baseball-stats-group',
            'title': 'A Group for Datasets about Baseball'
            }
        context['allow_partial_update'] = True
        group = group_create(context, group)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s created the group %s' % (user['fullname'], group['title']) \
                in stripped, stripped

        # Update the group.
        group['title'] = 'updated'
        group = group_update(context, group)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s updated the group %s' % (user['fullname'], group['title']) \
                in stripped, stripped

        # Delete the group.
        group['state'] = 'deleted'
        group_update(context, group)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s deleted the group %s' % (user['fullname'], group['title']) \
                in stripped, stripped

        # Add a new tag to the package.
        tag = {'name': 'baseball'}
        package['tags'].append(tag)
        package = package_update(context, package)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s added the tag %s to the dataset %s' % \
                (user['fullname'], tag['name'], package['title']) \
                in stripped, stripped

        # Remove the tag from the package.
        package['tags'] = []
        context['allow_partial_update'] = False
        package_update(context, package)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s removed the tag %s from the dataset %s' % \
                (user['fullname'], tag['name'], package['title']) \
                in stripped, stripped

        # Add an extra to the package.
        package['extras'].append({'key': 'quality', 'value': '10000'})
        package = package_update(context, package)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s added the extra "%s" to the dataset %s' % \
                (user['fullname'], 'quality', package['title']) \
                in stripped, stripped

        # Update the extra.
        package['extras'][0]['value'] = 'updated'
        package = package_update(context, package)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s changed the extra "%s" of the dataset %s' % \
                (user['fullname'], 'quality', package['title']) \
                in stripped, stripped

        # Delete the extra.
        del package['extras'][0]
        package = package_update(context, package)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s deleted the extra "%s" from the dataset %s' % \
                (user['fullname'], 'quality', package['title']) \
                in stripped, stripped

        # Delete the package.
        # we need to get round the delete permission
        context['ignore_auth'] = True
        package_delete(context, package)
        del context['ignore_auth']
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s deleted the dataset %s' % \
                (user['fullname'], package['title']) \
                in stripped, stripped

        # Update the user's profile.
        user['about'] = ''
        user_update(context, user)
        result = self.app.get(offset, status=200)
        stripped = self.strip_tags(result)
        assert '%s updated their profile' % user['fullname'] \
                in stripped, stripped

        # By now we've created >15 activities, but only the latest 15 should
        # appear on the page.
        result = self.app.get(offset, status=200)
        assert result.body.count('<div class="activity">') \
                == 15

        # The user's dashboard page should load successfully and have the
        # latest 15 activities on it.
        offset = url_for(controller='user', action='dashboard')
        extra_environ = {'Authorization':
                str(ckan.model.User.get('billybeane').apikey)}
        result = self.app.post(offset, extra_environ=extra_environ,
                status=200)
        assert result.body.count('<div class="activity">') == 15

########NEW FILE########
__FILENAME__ = test_admin
import ckan.model as model
from ckan.tests import url_for, CreateTestData, WsgiAppCase

class TestAdminController(WsgiAppCase):
    @classmethod
    def setup_class(cls):
        # setup test data including testsysadmin user
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    #test that only sysadmins can access the /ckan-admin page
    def test_index(self):
        url = url_for('ckanadmin', action='index')
        # redirect as not authorized
        response = self.app.get(url, status=[302])
        # random username
        response = self.app.get(url, status=[401],
                extra_environ={'REMOTE_USER': 'my-random-user-name'})
        # now test real access
        username = u'testsysadmin'.encode('utf8')
        response = self.app.get(url,
                extra_environ={'REMOTE_USER': username})
        assert 'Administration' in response, response

##   This is no longer used
class _TestAdminAuthzController(WsgiAppCase):
    @classmethod
    def setup_class(cls):
        # setup test data including testsysadmin user
        CreateTestData.create()
        model.Session.commit()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_role_table(self):

        #logged in as testsysadmin for all actions
        as_testsysadmin = {'REMOTE_USER': 'testsysadmin'}

        def get_system_user_roles():
            sys_query=model.Session.query(model.SystemRole)
            return sorted([(x.user.name,x.role) for x in sys_query.all() if x.user])

        def get_response():
            response = self.app.get(
                    url_for('ckanadmin', action='authz'),
                    extra_environ=as_testsysadmin)
            assert 'Administration - Authorization' in response, response
            return response

        def get_user_form():
           response = get_response()
           return response.forms['theform']


        def check_and_set_checkbox(theform, user, role, should_be, set_to):
           user_role_string = '%s$%s' % (user, role)
           checkboxes = [x for x in theform.fields[user_role_string] \
                                           if x.__class__.__name__ == 'Checkbox']

           assert(len(checkboxes)==1), \
                "there should only be one checkbox for %s/%s" % (user, role)
           checkbox = checkboxes[0]

           #checkbox should be unticked
           assert checkbox.checked==should_be, \
                         "%s/%s checkbox in unexpected state" % (user, role)

           #tick or untick the box and submit the form
           checkbox.checked=set_to
           return theform

        def submit(form):
          return form.submit('save', extra_environ=as_testsysadmin)

        def authz_submit(form):
          return form.submit('authz_save', extra_environ=as_testsysadmin)

        # get and store the starting state of the system roles
        original_user_roles = get_system_user_roles()

        # before we start changing things, check that the roles on the system are as expected
        assert original_user_roles == \
            [(u'logged_in', u'editor'), (u'testsysadmin', u'admin'),  (u'visitor', u'reader')] , \
            "original user roles not as expected " + str(original_user_roles)


        # visitor is not an admin. check that his admin box is unticked, tick it, and submit
        submit(check_and_set_checkbox(get_user_form(), u'visitor', u'admin', False, True))

        # try again, this time we expect the box to be ticked already
        submit(check_and_set_checkbox(get_user_form(), u'visitor', u'admin', True, True))

        # put it back how it was
        submit(check_and_set_checkbox(get_user_form(), u'visitor', u'admin', True, False))

        # should be back to our starting state
        assert original_user_roles == get_system_user_roles()


        # change lots of things
        form = get_user_form()
        check_and_set_checkbox(form, u'visitor', u'editor', False, True)
        check_and_set_checkbox(form, u'visitor', u'reader', True,  False)
        check_and_set_checkbox(form, u'logged_in', u'editor', True, False)
        check_and_set_checkbox(form, u'logged_in', u'reader', False, True)
        submit(form)

        roles=get_system_user_roles()
        # and assert that they've actually changed
        assert (u'visitor', u'editor') in roles and \
               (u'logged_in', u'editor') not in roles and \
               (u'logged_in', u'reader') in roles and \
               (u'visitor', u'reader')  not in roles, \
               "visitor and logged_in roles seem not to have reversed"


        def get_roles_by_name(user=None, group=None):
            if user:
                return [y for (x,y) in get_system_user_roles() if x==user]
            else:
                assert False, 'miscalled'


        # now we test the box for giving roles to an arbitrary user

        # check that tester doesn't have a system role
        assert len(get_roles_by_name(user=u'tester'))==0, \
              "tester should not have roles"

        # get the put tester in the username box
        form = get_response().forms['addform']
        form.fields['new_user_name'][0].value='tester'
        # get the admin checkbox
        checkbox = [x for x in form.fields['admin'] \
                      if x.__class__.__name__ == 'Checkbox'][0]
        # check it's currently unticked
        assert checkbox.checked == False
        # tick it and submit
        checkbox.checked=True
        response = form.submit('add', extra_environ=as_testsysadmin)
        assert "User Added" in response, "don't see flash message"

        assert get_roles_by_name(user=u'tester') == ['admin'], \
            "tester should be an admin now"



class TestAdminTrashController(WsgiAppCase):
    def setup(cls):
        CreateTestData.create()

    def teardown(self):
        model.repo.rebuild_db()

    def test_purge_revision(self):
        as_testsysadmin = {'REMOTE_USER': 'testsysadmin'}

        # Put a revision in deleted state
        rev = model.repo.youngest_revision()
        revid = rev.id
        rev.state = model.State.DELETED
        model.Session.commit()

        # check it shows up on trash page and
        url = url_for('ckanadmin', action='trash')
        response = self.app.get(url, extra_environ=as_testsysadmin)
        assert revid in response, response

        # check it can be successfully purged
        form = response.forms['form-purge-revisions']
        res = form.submit('purge-revisions', status=[302], extra_environ=as_testsysadmin)
        res = res.follow(extra_environ=as_testsysadmin)
        assert not revid in res, res
        rev = model.Session.query(model.Revision).filter_by(id=revid).first()
        assert rev is None, rev

    def test_purge_package(self):
        as_testsysadmin = {'REMOTE_USER': 'testsysadmin'}

        # Put packages in deleted state
        rev = model.repo.new_revision()
        pkg = model.Package.by_name(u'warandpeace')
        pkg.state = model.State.DELETED
        model.repo.commit_and_remove()

        # Check shows up on trash page
        url = url_for('ckanadmin', action='trash')
        response = self.app.get(url, extra_environ=as_testsysadmin)
        assert 'dataset/warandpeace' in response, response

        # Check we get correct error message on attempted purge
        form = response.forms['form-purge-packages']
        response = form.submit('purge-packages', status=[302],
                extra_environ=as_testsysadmin)
        response = response.follow(extra_environ=as_testsysadmin)
        assert 'Cannot purge package' in response, response
        assert 'dataset/warandpeace' in response

        # now check we really can purge when things are ok
        model.repo.new_revision()
        pkg = model.Package.by_name(u'annakarenina')
        pkg.state = model.State.DELETED
        model.repo.commit_and_remove()

        response = self.app.get(url, extra_environ=as_testsysadmin)
        assert 'dataset/warandpeace' in response, response
        assert 'dataset/annakarenina' in response, response

        form = response.forms['form-purge-packages']
        res = form.submit('purge-packages', status=[302], extra_environ=as_testsysadmin)
        res = res.follow(extra_environ=as_testsysadmin)

        pkgs = model.Session.query(model.Package).all()
        assert len(pkgs) == 0

    def test_purge_youngest_revision(self):
        as_testsysadmin = {'REMOTE_USER': 'testsysadmin'}

        id = u'warandpeace'
        log_message = 'test_1234'
        edit_url = url_for(controller='package', action='edit', id=id)

        # Manually create a revision
        res = self.app.get(edit_url, extra_environ=as_testsysadmin)
        fv = res.forms['dataset-edit']
        fv['title'] = 'RevisedTitle'
        fv['log_message'] = log_message
        res = fv.submit('save', extra_environ=as_testsysadmin)

        # Delete that revision
        rev = model.repo.youngest_revision()
        assert rev.message == log_message
        rev.state = model.State.DELETED
        model.Session.commit()

        # Run a purge
        url = url_for('ckanadmin', action='trash')
        res = self.app.get(url, extra_environ=as_testsysadmin)
        form = res.forms['form-purge-revisions']
        res = form.submit('purge-revisions', status=[302], extra_environ=as_testsysadmin)
        res = res.follow(extra_environ=as_testsysadmin)

        # Verify the edit page can be loaded (ie. does not 404)
        res = self.app.get(edit_url, extra_environ=as_testsysadmin)

    def test_undelete(self):
        as_testsysadmin = {'REMOTE_USER': 'testsysadmin'}

        rev = model.repo.youngest_revision()
        rev_id = rev.id
        rev.state = model.State.DELETED
        model.Session.commit()

        # Click undelete
        url = url_for('ckanadmin', action='trash')
        res = self.app.get(url, extra_environ=as_testsysadmin)
        form = res.forms['undelete-'+rev.id]
        res = form.submit('action', status=[302], extra_environ=as_testsysadmin)
        res = res.follow(extra_environ=as_testsysadmin)

        assert 'Revision updated' in res
        assert not 'DELETED' in res

        rev = model.repo.youngest_revision()
        assert rev.id == rev_id
        assert rev.state == model.State.ACTIVE

########NEW FILE########
__FILENAME__ = test_cors
from ckan.tests import TestController
from ckan.tests import is_search_supported

class TestCORS(TestController):

    def test_options(self):
        out = self.app._gen_request(method='OPTIONS', url='/', status=200)
        assert len(str(out.body)) == 0, 'OPTIONS must return no content'

    def test_headers(self):
        # the home page does a package search so have to skip this test if
        # search is not supported
        if not is_search_supported():
            from nose import SkipTest
            raise SkipTest("Search not supported")

        out = self.app.get('/')
        headers = dict(out.headers)
        print headers
        assert headers['Access-Control-Allow-Origin'] == '*'
        assert headers['Access-Control-Allow-Methods'] == "POST, PUT, GET, DELETE, OPTIONS"
        assert headers['Access-Control-Allow-Headers'] == "X-CKAN-API-KEY, Authorization, Content-Type"


########NEW FILE########
__FILENAME__ = test_error
from base import FunctionalTestCase

class TestError(FunctionalTestCase):
    def test_without_redirect(self):
        # this is what a web bot might do
        res = self.app.get('/error/document')
        assert 'There is no error.' in str(res), str(res)

########NEW FILE########
__FILENAME__ = test_follow
from pylons.test import pylonsapp
import paste.fixture
import ckan
from routes import url_for
from ckan.tests.html_check import HtmlCheckMethods
import json

class TestFollow(HtmlCheckMethods):

    @classmethod
    def setupClass(cls):
        ckan.tests.CreateTestData.create()
        cls.testsysadmin = ckan.model.User.get('testsysadmin')
        cls.annafan = ckan.model.User.get('annafan')
        cls.russianfan = ckan.model.User.get('russianfan')
        cls.tester = ckan.model.User.get('tester')
        cls.joeadmin = ckan.model.User.get('joeadmin')
        cls.warandpeace = ckan.model.Package.get('warandpeace')
        cls.annakarenina = ckan.model.Package.get('annakarenina')
        cls.app = paste.fixture.TestApp(pylonsapp)

        # Make three users follow annakarenina.
        params = {'id': 'annakarenina'}
        extra_environ = {'Authorization': str(cls.joeadmin.apikey)}
        response = cls.app.post('/api/action/follow_dataset',
            params=json.dumps(params), extra_environ=extra_environ).json
        assert response['success'] is True
        params = {'id': 'annakarenina'}
        extra_environ = {'Authorization': str(cls.annafan.apikey)}
        response = cls.app.post('/api/action/follow_dataset',
            params=json.dumps(params), extra_environ=extra_environ).json
        assert response['success'] is True
        params = {'id': 'annakarenina'}
        extra_environ = {'Authorization': str(cls.russianfan.apikey)}
        response = cls.app.post('/api/action/follow_dataset',
            params=json.dumps(params), extra_environ=extra_environ).json
        assert response['success'] is True

        # Make two users follow annafan.
        params = {'id': 'annafan'}
        extra_environ = {'Authorization': str(cls.russianfan.apikey)}
        response = cls.app.post('/api/action/follow_user',
            params=json.dumps(params), extra_environ=extra_environ).json
        assert response['success'] is True
        params = {'id': 'annafan'}
        extra_environ = {'Authorization': str(cls.tester.apikey)}
        response = cls.app.post('/api/action/follow_user',
            params=json.dumps(params), extra_environ=extra_environ).json
        assert response['success'] is True

    @classmethod
    def teardownClass(cls):
        ckan.model.repo.rebuild_db()

    def test_dataset_read_not_logged_in(self):
        offset = url_for(controller='package', action='read',
                id='warandpeace')
        result = self.app.get(offset)
        assert 'href="/dataset/followers/warandpeace"' in result
        assert 'Followers (0)' in result
        assert 'id="dataset_follow_button"' not in result

        offset = url_for(controller='package', action='read',
                id='annakarenina')
        result = self.app.get(offset)
        assert 'href="/dataset/followers/annakarenina"' in result
        assert 'Followers (3)' in result
        assert 'id="dataset_follow_button"' not in result
    
    def test_dataset_followers_not_logged_in(self): 
        '''Not-logged-in users cannot see /dataset/followers/ pages.'''
        offset = url_for(controller='package', action='followers',
                id='warandpeace')
        result = self.app.get(offset)
        assert result.status == 302
        assert '/user/login' in result.header_dict['location']

    def test_user_read_not_logged_in(self):
        offset = url_for(controller='user', action='read',
                id='joeadmin')
        result = self.app.get(offset)
        assert 'href="/user/followers/joeadmin"' in result
        assert 'Followers (0)' in result
        assert 'id="user_follow_button"' not in result

        offset = url_for(controller='user', action='read',
                id='annafan')
        result = self.app.get(offset)
        assert 'href="/user/followers/annafan"' in result
        assert 'Followers (2)' in result
        assert 'id="user_follow_button"' not in result
    
    def test_user_followers_not_logged_in(self):
        offset = url_for(controller='user', action='followers',
                id='joeadmin')
        result = self.app.get(offset)
        assert result.status == 302
        assert '/user/login' in result.header_dict['location']

    def test_own_user_read_logged_in(self):
        offset = url_for(controller='user', action='read',
                id='joeadmin')
        extra_environ = {'Authorization': str(self.joeadmin.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'href="/user/followers/joeadmin"' in result
        assert 'My Followers (0)' in result
        assert 'id="user_follow_button"' not in result

        offset = url_for(controller='user', action='read',
                id='annafan')
        extra_environ = {'Authorization': str(self.annafan.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'href="/user/followers/annafan"' in result
        assert 'My Followers (2)' in result
        assert 'id="user_follow_button"' not in result
    
    def test_own_user_followers_logged_in(self):
        offset = url_for(controller='user', action='followers',
                id='joeadmin')
        extra_environ = {'Authorization': str(self.testsysadmin.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'href="/user/followers/joeadmin"' in result
        assert 'Followers (0)' in result
        assert 'id="user_follow_button"' in result
        assert '<li class="user">' not in result

    def test_dataset_read_logged_in(self):
        offset = url_for(controller='package', action='read',
                id='warandpeace')
        extra_environ = {'Authorization': str(self.testsysadmin.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'href="/dataset/followers/warandpeace"' in result
        assert 'Followers (0)' in result
        assert 'id="dataset_follow_button"' in result

        offset = url_for(controller='package', action='read',
                id='annakarenina')
        extra_environ = {'Authorization': str(self.tester.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'href="/dataset/followers/annakarenina"' in result
        assert 'Followers (3)' in result
        assert 'id="dataset_follow_button"' in result

    def test_dataset_follow_logged_in(self):
        offset = url_for(controller='package', action='followers',
                id='warandpeace')
        extra_environ = {'Authorization': str(self.testsysadmin.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'id="dataset_follow_button"' in result
        assert 'Followers (0)' in result
        assert 'id="dataset_follow_button"' in result
        assert '<li class="user">' not in result

        offset = url_for(controller='package', action='followers',
                id='annakarenina')
        extra_environ = {'Authorization': str(self.testsysadmin.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'href="/dataset/followers/annakarenina"' in result
        assert 'Followers (3)' in result
        assert 'id="dataset_follow_button"' in result
        assert str(result).count('<li class="user">') == 3
        assert self.joeadmin.display_name in result
        assert self.annafan.display_name in result
        assert self.russianfan.display_name in result

        # joeadmin is following annakarenina so he should see an Unfollow
        # button.
        offset = url_for(controller='package', action='followers',
                id='annakarenina')
        extra_environ = {'Authorization': str(self.testsysadmin.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'Unfollow' in result
        
    def test_user_read_logged_in(self):
        offset = url_for(controller='user', action='read',
                id='joeadmin')
        extra_environ = {'Authorization': str(self.tester.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'href="/user/followers/joeadmin"' in result
        assert 'Followers (0)' in result
        assert 'id="user_follow_button"' in result

        offset = url_for(controller='user', action='read',
                id='annafan')
        extra_environ = {'Authorization': str(self.tester.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'href="/user/followers/annafan"' in result
        assert 'Followers (2)' in result
        assert 'id="user_follow_button"' in result

    def test_user_follow_logged_in(self):
        offset = url_for(controller='user', action='followers',
                id='joeadmin')
        extra_environ = {'Authorization': str(self.testsysadmin.apikey)}
        result = self.app.get(offset, extra_environ=extra_environ)
        assert 'href="/user/followers/joeadmin"' in result
        assert 'Followers (0)' in result
        assert '<li class="user">' not in result
        assert 'id="user_follow_button"' in result

########NEW FILE########
__FILENAME__ = test_group
import re

from nose.tools import assert_equal
import mock

import ckan.model as model
import ckan.lib.search as search

from ckan.tests import setup_test_search_index
from ckan import plugins
from ckan.lib.create_test_data import CreateTestData
from ckan.logic import get_action
from ckan.tests import *
from base import FunctionalTestCase
from ckan.tests import is_search_supported


class TestGroup(FunctionalTestCase):

    @classmethod
    def setup_class(self):
        search.clear()
        model.Session.remove()
        CreateTestData.create()

        # reduce extraneous logging
        from ckan.lib import activity_streams_session_extension
        activity_streams_session_extension.logger.level = 100

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_atom_feed_page_zero(self):
        group_name = 'deletetest'
        CreateTestData.create_groups([{'name': group_name,
                                       'packages': []}],
                                     admin_user_name='testsysadmin')

        offset = url_for(controller='feed', action='group',
                         id=group_name)
        offset = offset + '?page=0'
        res = self.app.get(offset)
        assert '<feed' in res, res
        assert 'xmlns="http://www.w3.org/2005/Atom"' in res, res
        assert '</feed>' in res, res

    def test_atom_feed_page_negative(self):
        group_name = 'deletetest'
        CreateTestData.create_groups([{'name': group_name,
                                       'packages': []}],
                                     admin_user_name='testsysadmin')

        offset = url_for(controller='feed', action='group',
                         id=group_name)
        offset = offset + '?page=-2'
        res = self.app.get(offset, expect_errors=True)
        assert '"page" parameter must be a positive integer' in res, res

    def test_children(self):
        if model.engine_is_sqlite():
            from nose import SkipTest
            raise SkipTest("Can't use CTE for sqlite")

        group_name = 'deletetest'
        CreateTestData.create_groups([{'name': group_name,
                                       'packages': []},
                                      {'name': "parent_group",
                                       'packages': []}],
                                     admin_user_name='testsysadmin')

        parent = model.Group.by_name("parent_group")
        group = model.Group.by_name(group_name)

        rev = model.repo.new_revision()
        rev.author = "none"

        member = model.Member(group_id=group.id, table_id=parent.id,
                              table_name='group', capacity='member')
        model.Session.add(member)
        model.repo.commit_and_remove()

        offset = url_for(controller='group', action='edit', id=group_name)
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        main_res = self.main_div(res)
        assert 'Edit: %s' % group.title in main_res, main_res
        assert 'value="active" selected' in main_res, main_res

        parent = model.Group.by_name("parent_group")
        assert_equal(len(parent.get_children_groups()), 1)

        # delete
        form = res.forms['group-edit']
        form['state'] = 'deleted'
        res = form.submit('save', status=302,
                          extra_environ={'REMOTE_USER': 'testsysadmin'})

        group = model.Group.by_name(group_name)
        assert_equal(group.state, 'deleted')

        parent = model.Group.by_name("parent_group")
        assert_equal(len(parent.get_children_groups()), 0)

    def test_sorting(self):
        model.repo.rebuild_db()

        testsysadmin = model.User(name=u'testsysadmin')
        testsysadmin.sysadmin = True
        model.Session.add(testsysadmin)

        pkg1 = model.Package(name="pkg1")
        pkg2 = model.Package(name="pkg2")
        model.Session.add(pkg1)
        model.Session.add(pkg2)

        CreateTestData.create_groups([{'name': "alpha", 'packages': []},
                                      {'name': "beta",
                                       'packages': ["pkg1", "pkg2"]},
                                      {'name': "delta",
                                       'packages': ["pkg1"]},
                                      {'name': "gamma", 'packages': []}],
                                     admin_user_name='testsysadmin')

        context = {'model': model, 'session': model.Session,
                   'user': 'testsysadmin', 'for_view': True,
                   'with_private': False}
        data_dict = {'all_fields': True}
        results = get_action('group_list')(context, data_dict)
        assert results[0]['name'] == u'alpha', results[0]['name']
        assert results[-1]['name'] == u'gamma', results[-1]['name']

        # Test name reverse
        data_dict = {'all_fields': True, 'sort': 'name desc'}
        results = get_action('group_list')(context, data_dict)
        assert results[0]['name'] == u'gamma', results[0]['name']
        assert results[-1]['name'] == u'alpha', results[-1]['name']

        # Test packages reversed
        data_dict = {'all_fields': True, 'sort': 'packages desc'}
        results = get_action('group_list')(context, data_dict)
        assert results[0]['name'] == u'beta', results[0]['name']
        assert results[1]['name'] == u'delta', results[1]['name']

        # Test packages forward
        data_dict = {'all_fields': True, 'sort': 'packages asc'}
        results = get_action('group_list')(context, data_dict)
        assert results[-2]['name'] == u'delta', results[-2]['name']
        assert results[-1]['name'] == u'beta', results[-1]['name']

        # Default ordering for packages
        data_dict = {'all_fields': True, 'sort': 'packages'}
        results = get_action('group_list')(context, data_dict)
        assert results[0]['name'] == u'beta', results[0]['name']
        assert results[1]['name'] == u'delta', results[1]['name']

    def test_mainmenu(self):
        # the home page does a package search so have to skip this test if
        # search is not supported
        if not is_search_supported():
            from nose import SkipTest
            raise SkipTest("Search not supported")

        offset = url_for(controller='home', action='index')
        res = self.app.get(offset)
        assert 'Groups' in res, res
        assert 'Groups</a>' in res, res
        res = res.click(href='/group', index=0)
        assert "Dave's books" in res, res

    def test_index(self):
        offset = url_for(controller='group', action='index')
        res = self.app.get(offset)
        assert re.search('<h1(.*)>\s*Groups', res.body)
        groupname = 'david'
        group = model.Group.by_name(unicode(groupname))
        group_title = group.title
        group_packages_count = len(group.packages())
        group_description = group.description
        self.check_named_element(res, 'tr', group_title,
                                 group_packages_count,
                                 group_description)
        res = res.click(group_title)
        assert groupname in res

    def test_read_non_existent(self):
        name = u'group_does_not_exist'
        offset = url_for(controller='group', action='read', id=name)
        res = self.app.get(offset, status=404)

    def test_read_plugin_hook(self):
        plugins.load('test_group_plugin')
        name = u'david'
        offset = url_for(controller='group', action='read', id=name)
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        p = plugins.get_plugin('test_group_plugin')
        assert p.calls['read'] == 1, p.calls
        plugins.unload('test_group_plugin')

    def test_read_and_authorized_to_edit(self):
        name = u'david'
        title = u'Dave\'s books'
        pkgname = u'warandpeace'
        offset = url_for(controller='group', action='read', id=name)
        res = self.app.get(offset,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        assert title in res, res
        assert 'edit' in res
        assert name in res

    def test_new_page(self):
        offset = url_for(controller='group', action='new')
        res = self.app.get(offset,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        assert 'Add A Group' in res, res


class TestGroupWithSearch(FunctionalTestCase):

    @classmethod
    def setup_class(self):
        setup_test_search_index()
        model.Session.remove()
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_read(self):
        # Relies on the search index being available
        name = u'david'
        title = u'Dave\'s books'
        pkgname = u'warandpeace'
        group = model.Group.by_name(name)
        for group_ref in (group.name, group.id):
            offset = url_for(controller='group', action='read', id=group_ref)
            res = self.app.get(offset)
            main_res = self.main_div(res)
            assert title in res, res
            #assert 'edit' not in main_res, main_res
           # Administrator no longer exists for the group due to auth changes
           # assert 'Administrators' in res, res
           # assert 'russianfan' in main_res, main_res
            assert name in res, res
            no_datasets_found = int(re.search('(\d*) datasets found',
                                    main_res).groups()[0])
            assert_equal(no_datasets_found, 2)
            pkg = model.Package.by_name(pkgname)
            res = res.click(pkg.title)
            assert '%s - Datasets' % pkg.title in res


class TestEdit(FunctionalTestCase):

    @classmethod
    def setup_class(self):
        setup_test_search_index()
        model.Session.remove()
        CreateTestData.create()
        self.groupname = u'david'
        self.packagename = u'testpkg'
        model.repo.new_revision()
        model.Session.add(model.Package(name=self.packagename))
        model.repo.commit_and_remove()

    @classmethod
    def teardown_class(self):
        model.Session.remove()
        model.repo.rebuild_db()
        model.Session.remove()

    def test_0_not_authz(self):
        offset = url_for(controller='group', action='edit', id=self.groupname)
        # 401 gets caught by repoze.who and turned into redirect
        res = self.app.get(offset, status=[302, 401])
        res = res.follow()
        assert res.request.url.startswith('/user/login')

    def test_2_edit(self):
        group = model.Group.by_name(self.groupname)
        offset = url_for(controller='group', action='edit', id=self.groupname)
        print offset
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        assert 'Edit: %s' % group.title in res, res

        form = res.forms['group-edit']
        titlefn = 'title'
        descfn = 'description'
        newtitle = 'xxxxxxx'
        newdesc = '''### Lots of stuff here

Ho ho ho
'''

        form[titlefn] = newtitle
        form[descfn] = newdesc
        pkg = model.Package.by_name(self.packagename)
        form['packages__2__name'] = pkg.name

        res = form.submit('save', status=302,
                          extra_environ={'REMOTE_USER': 'testsysadmin'})
        # should be read page
        # assert 'Groups - %s' % self.groupname in res, res

        model.Session.remove()
        group = model.Group.by_name(self.groupname)
        assert group.title == newtitle, group
        assert group.description == newdesc, group

        # now look at datasets
        assert len(group.packages()) == 3

    def test_3_edit_form_has_new_package(self):
        # check for dataset in autocomplete
        offset = url_for(controller='package', action='autocomplete', q='an')
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        assert 'annakarenina' in res, res
        assert not 'newone' in res, res
        model.repo.new_revision()
        pkg = model.Package(name=u'anewone')
        model.Session.add(pkg)
        model.repo.commit_and_remove()

        model.repo.new_revision()
        pkg = model.Package.by_name(u'anewone')
        user = model.User.by_name(u'testsysadmin')
        model.setup_default_user_roles(pkg, [user])
        model.repo.commit_and_remove()

        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        assert 'annakarenina' in res, res
        assert 'newone' in res

    def test_4_new_duplicate_package(self):
        prefix = ''

        # Create group
        group_name = u'testgrp4'
        CreateTestData.create_groups([{'name': group_name,
                                       'packages': [self.packagename]}],
                                     admin_user_name='testsysadmin')

        # Add same package again
        offset = url_for(controller='group', action='edit', id=group_name)
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        fv = res.forms['group-edit']
        fv['packages__1__name'] = self.packagename
        res = fv.submit('save', status=302,
                        extra_environ={'REMOTE_USER': 'testsysadmin'})
        res = res.follow()
        assert group_name in res, res
        model.Session.remove()

        # check package only added to the group once
        group = model.Group.by_name(group_name)
        pkg_names = [pkg.name for pkg in group.packages()]
        assert_equal(pkg_names, [self.packagename])

    def test_edit_plugin_hook(self):
        plugins.load('test_group_plugin')
        offset = url_for(controller='group', action='edit', id=self.groupname)
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        form = res.forms['group-edit']
        group = model.Group.by_name(self.groupname)
        form['title'] = "huhuhu"
        res = form.submit('save', status=302,
                          extra_environ={'REMOTE_USER': 'testsysadmin'})
        p = plugins.get_plugin('test_group_plugin')
        assert p.calls['edit'] == 1, p.calls
        plugins.unload('test_group_plugin')

    def test_edit_image_url(self):
        group = model.Group.by_name(self.groupname)
        offset = url_for(controller='group', action='edit', id=self.groupname)
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})

        form = res.forms['group-edit']
        image_url = u'http://url.to/image_url'
        form['image_url'] = image_url
        res = form.submit('save', status=302,
                          extra_environ={'REMOTE_USER': 'testsysadmin'})

        model.Session.remove()
        group = model.Group.by_name(self.groupname)
        assert group.image_url == image_url, group

    def test_edit_change_name(self):
        group = model.Group.by_name(self.groupname)
        offset = url_for(controller='group', action='edit', id=self.groupname)
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        assert 'Edit: %s' % group.title in res, res

        def update_group(res, name, with_pkg=True):
            form = res.forms['group-edit']
            titlefn = 'title'
            descfn = 'description'
            newtitle = 'xxxxxxx'
            newdesc = '''### Lots of stuff here

    Ho ho ho
    '''
            form[titlefn] = newtitle
            form[descfn] = newdesc
            form['name'] = name
            if with_pkg:
                pkg = model.Package.by_name(self.packagename)
                form['packages__2__name'] = pkg.name

            res = form.submit('save', status=302,
                              extra_environ={'REMOTE_USER': 'testsysadmin'})
        update_group(res, self.groupname, True)
        update_group(res, 'newname', False)

        model.Session.remove()
        group = model.Group.by_name('newname')

        # We have the datasets in the DB, but we should also see that many
        # on the group read page.
        assert len(group.packages()) == 3

        offset = url_for(controller='group', action='read', id='newname')
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})

        ds = res.body
        ds = ds[ds.index('datasets') - 10: ds.index('datasets') + 10]
        assert '3 datasets found' in res, ds

        # reset the group to how we found it
        offset = url_for(controller='group', action='edit', id='newname')
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})

        update_group(res, self.groupname, True)

    def test_edit_non_existent(self):
        name = u'group_does_not_exist'
        offset = url_for(controller='group', action='edit', id=name)
        res = self.app.get(offset, status=404)

    def test_delete(self):
        group_name = 'deletetest'
        CreateTestData.create_groups([{'name': group_name,
                                       'packages': [self.packagename]}],
                                     admin_user_name='testsysadmin')

        group = model.Group.by_name(group_name)
        offset = url_for(controller='group', action='edit', id=group_name)
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        main_res = self.main_div(res)
        assert 'Edit: %s' % group.title in main_res, main_res
        assert 'value="active" selected' in main_res, main_res

        # delete
        form = res.forms['group-edit']
        form['state'] = 'deleted'
        res = form.submit('save', status=302,
                          extra_environ={'REMOTE_USER': 'testsysadmin'})

        group = model.Group.by_name(group_name)
        assert_equal(group.state, 'deleted')
        res = self.app.get(offset, status=302)
        res = res.follow()
        assert res.request.url.startswith('/user/login'), res.request.url


class TestNew(FunctionalTestCase):
    groupname = u'david'

    @classmethod
    def setup_class(self):
        model.Session.remove()
        CreateTestData.create()

        self.packagename = u'testpkg'
        model.repo.new_revision()
        model.Session.add(model.Package(name=self.packagename))
        model.repo.commit_and_remove()

    @classmethod
    def teardown_class(self):
        model.Session.remove()
        model.repo.rebuild_db()
        model.Session.remove()

    def test_1_not_authz(self):
        offset = url_for(controller='group', action='new')
        # 401 gets caught by repoze.who and turned into redirect
        res = self.app.get(offset, status=[302, 401])
        res = res.follow()
        assert res.request.url.startswith('/user/login')

    def test_2_new(self):
        prefix = ''
        group_name = u'testgroup'
        group_title = u'Test Title'
        group_description = u'A Description'

        # Open 'Add A Group' page
        offset = url_for(controller='group', action='new')
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        assert 'Add A Group' in res, res
        fv = res.forms['group-edit']
        assert fv[prefix + 'name'].value == '', fv.fields
        assert fv[prefix + 'title'].value == ''
        assert fv[prefix + 'description'].value == ''
        assert fv['packages__0__name'].value == '', \
            fv['Member--package_name'].value

        # Edit form
        fv[prefix + 'name'] = group_name
        fv[prefix + 'title'] = group_title
        fv[prefix + 'description'] = group_description
        pkg = model.Package.by_name(self.packagename)
        fv['packages__0__name'] = pkg.name
        res = fv.submit('save', status=302,
                        extra_environ={'REMOTE_USER': 'testsysadmin'})
        res = res.follow()
        assert '%s' % group_title in res, res

        model.Session.remove()
        group = model.Group.by_name(group_name)
        assert group.title == group_title, group
        assert group.description == group_description, group
        assert len(group.packages()) == 1
        pkg = model.Package.by_name(self.packagename)
        assert group.packages() == [pkg]

    def test_3_new_duplicate_group(self):
        prefix = ''

        # Create group
        group_name = u'testgrp1'
        offset = url_for(controller='group', action='new')
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        assert 'Add A Group' in res, res
        fv = res.forms['group-edit']
        assert fv[prefix + 'name'].value == '', fv.fields
        fv[prefix + 'name'] = group_name
        res = fv.submit('save', status=302,
                        extra_environ={'REMOTE_USER': 'testsysadmin'})
        res = res.follow()
        assert group_name in res, res
        model.Session.remove()

        # Create duplicate group
        group_name = u'testgrp1'
        offset = url_for(controller='group', action='new')
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        assert 'Add A Group' in res, res
        fv = res.forms['group-edit']
        assert fv[prefix + 'name'].value == '', fv.fields
        fv[prefix + 'name'] = group_name
        res = fv.submit('save', status=200,
                        extra_environ={'REMOTE_USER': 'testsysadmin'})
        assert 'Group name already exists' in res, res
        self.check_tag(res, '<form', 'has-errors')
        assert 'class="field_error"' in res, res

    def test_new_plugin_hook(self):
        plugins.load('test_group_plugin')
        offset = url_for(controller='group', action='new')
        res = self.app.get(offset, status=200,
                           extra_environ={'REMOTE_USER': 'testsysadmin'})
        form = res.forms['group-edit']
        form['name'] = "hahaha"
        form['title'] = "huhuhu"
        res = form.submit('save', status=302,
                          extra_environ={'REMOTE_USER': 'testsysadmin'})
        p = plugins.get_plugin('test_group_plugin')
        assert p.calls['create'] == 1, p.calls
        plugins.unload('test_group_plugin')

    def test_new_bad_param(self):
        offset = url_for(controller='group', action='new',
                         __bad_parameter='value')
        res = self.app.post(offset, {'save': '1'},
                            extra_environ={'REMOTE_USER': 'testsysadmin'},
                            status=400)
        assert 'Integrity Error' in res.body


class TestRevisions(FunctionalTestCase):
    @classmethod
    def setup_class(self):
        model.Session.remove()
        CreateTestData.create()
        self.name = u'revisiontest1'

        # create pkg
        self.description = [u'Written by Puccini', u'Written by Rossini',
                            u'Not written at all', u'Written again',
                            u'Written off']
        rev = model.repo.new_revision()
        self.grp = model.Group(name=self.name)
        self.grp.description = self.description[0]
        model.Session.add(self.grp)
        model.setup_default_user_roles(self.grp)
        model.repo.commit_and_remove()

        # edit pkg
        for i in range(5)[1:]:
            rev = model.repo.new_revision()
            grp = model.Group.by_name(self.name)
            grp.description = self.description[i]
            model.repo.commit_and_remove()

        self.grp = model.Group.by_name(self.name)

    @classmethod
    def teardown_class(self):
        self.purge_packages([self.name])
        model.repo.rebuild_db()

    def test_0_read_history(self):
        offset = url_for(controller='group', action='history',
                         id=self.grp.name)
        res = self.app.get(offset)
        main_res = self.main_div(res)
        assert self.grp.name in main_res, main_res
        assert 'radio' in main_res, main_res
        latest_rev = self.grp.all_revisions[0]
        oldest_rev = self.grp.all_revisions[-1]
        first_radio_checked_html = \
            '<input checked="checked" id="selected1_%s"' % \
            latest_rev.revision_id
        assert first_radio_checked_html in main_res, '%s %s' % \
            (first_radio_checked_html, main_res)
        last_radio_checked_html = \
            '<input checked="checked" id="selected2_%s"' % \
            oldest_rev.revision_id
        assert last_radio_checked_html in main_res, '%s %s' % \
            (last_radio_checked_html, main_res)

    def test_1_do_diff(self):
        offset = url_for(controller='group', action='history',
                         id=self.grp.name)
        res = self.app.get(offset)
        form = res.forms['group-revisions']
        res = form.submit()
        res = res.follow()
        main_res = self.main_div(res)
        assert 'form-errors' not in main_res.lower(), main_res
        assert 'Revision Differences' in main_res, main_res
        assert self.grp.name in main_res, main_res
        assert "<tr><td>description</td><td><pre>- Written by Puccini\n+" + \
               " Written off</pre></td></tr>" in main_res, main_res

    def test_2_atom_feed(self):
        offset = url_for(controller='group', action='history',
                         id=self.grp.name)
        offset = "%s?format=atom" % offset
        res = self.app.get(offset)
        assert '<feed' in res, res
        assert 'xmlns="http://www.w3.org/2005/Atom"' in res, res
        assert '</feed>' in res, res


class TestMemberInvite(FunctionalTestCase):
    @classmethod
    def setup_class(self):
        model.Session.remove()
        model.repo.rebuild_db()

    def teardown(self):
        model.repo.rebuild_db()

    @mock.patch('ckan.lib.mailer.mail_user')
    def test_member_new_invites_user_if_received_email(self, mail_user):
        user = CreateTestData.create_user('a_user', sysadmin=True)
        group_name = 'a_group'
        CreateTestData.create_groups([{'name': group_name}], user.name)
        group = model.Group.get(group_name)
        url = url_for(controller='group', action='member_new', id=group.id)
        email = 'invited_user@mailinator.com'
        role = 'member'

        params = {'email': email, 'role': role}
        res = self.app.post(url, params,
                            extra_environ={'REMOTE_USER': str(user.name)})

        users = model.User.by_email(email)
        assert len(users) == 1, users
        user = users[0]
        assert user.email == email, user
        assert group.id in user.get_group_ids(capacity=role)

########NEW FILE########
__FILENAME__ = test_home
from pylons.i18n import set_lang

from ckan.lib.create_test_data import CreateTestData
from ckan.controllers.home import HomeController
import ckan.model as model

from ckan.tests import *
from ckan.tests.html_check import HtmlCheckMethods
from ckan.tests.pylons_controller import PylonsTestCase
from ckan.tests import search_related, setup_test_search_index

from ckan.common import c, session

class TestHomeController(TestController, PylonsTestCase, HtmlCheckMethods):
    @classmethod
    def setup_class(cls):
        setup_test_search_index()
        PylonsTestCase.setup_class()
        model.repo.init_db()
        CreateTestData.create()
        
    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_home_page(self):
        offset = url_for('home')
        res = self.app.get(offset)
        # Non logged in users can no longer add datasets
        assert not 'Add a dataset' in res
        assert 'Could not change language' not in res
        assert "Dave's books has 2 datasets" in res, res
        assert "Roger's books has 1 datasets" in res, res

    @search_related
    def test_packages_link(self):
        offset = url_for('home')
        res = self.app.get(offset)
        res.click('Search', index=0)
        
    def test_template_head_end(self):
        offset = url_for('home')
        res = self.app.get(offset)
        assert 'ckan.template_head_end = <link rel="stylesheet" href="TEST_TEMPLATE_HEAD_END.css" type="text/css"> '

    def test_template_footer_end(self):
        offset = url_for('home')
        res = self.app.get(offset)
        assert '<strong>TEST TEMPLATE_FOOTER_END TEST</strong>'

## disabled as I18nMiddlewhare does not get used FIXME
##
##    def test_locale_change(self):
##        offset = url_for('home')
##        res = self.app.get(offset)
##        res = res.click('Deutsch')
##        try:
##            res = res.follow()
##            assert 'Willkommen' in res.body
##        finally:
##            self.clear_language_setting()

##    def test_locale_change(self):
##        offset = url_for('home')
##        res = self.app.get(offset)
##        res = res.click('Deutsch')
##        try:
##            res = res.follow()
##            # Language of the page
##            assert 'Willkommen' in res.body
##            # Flash message
##            assert 'Die Sprache ist jetzt: Deutsch' in res.body
##
##            res = res.click('English')
##            res = res.follow()
##            # Language of the page
##            assert 'Welcome' in res.body
##            # Flash message
##            assert 'Language has been set to: English' in res.body, res.body
##        finally:
##            self.clear_language_setting()
##
##    def test_locale_change_invalid(self):
##        offset = url_for(controller='home', action='locale', locale='')
##        res = self.app.get(offset, status=400)
##        main_res = self.main_div(res)
##        assert 'Invalid language specified' in main_res, main_res
##
##    def test_locale_change_blank(self):
##        offset = url_for(controller='home', action='locale')
##        res = self.app.get(offset, status=400)
##        main_res = self.main_div(res)
##        assert 'No language given!' in main_res, main_res
##
##    def test_locale_change_with_false_hash(self):
##        offset = url_for('home')
##        res = self.app.get(offset)
##        found_html, found_desc, found_attrs = res._find_element(
##            tag='a', href_attr='href',
##            href_extract=None,
##            content='Deutsch',
##            id=None, 
##            href_pattern=None,
##            html_pattern=None,
##            index=None, verbose=False)
##        href = found_attrs['uri']
##        assert href
##        res = res.goto(href)
##        try:
##            assert res.status == 302, res.status # redirect
##
##            href = href.replace('return_to=%2F&', 'return_to=%2Fhackedurl&')
##            res = res.goto(href)
##            assert res.status == 200, res.status # doesn't redirect
##        finally:
##            self.clear_language_setting()

    def test_update_profile_notice(self):
        edit_url = url_for(controller='user', action='edit')
        email_notice = 'Please <a href="%s">update your profile</a>' \
                ' and add your email address.' % (edit_url)
        fullname_notice = 'Please <a href="%s">update your profile' \
                '</a> and add your full name' % (edit_url)
        email_and_fullname_notice ='Please <a href="%s">update your' \
            ' profile</a> and add your email address and your full name.' \
            % (edit_url)
        url = url_for('home')

        # No update profile notices should be flashed if no one is logged in.
        response = self.app.get(url)
        assert email_notice not in response
        assert fullname_notice not in response
        assert email_and_fullname_notice not in response

        # Make some test users.
        user1 = model.user.User(name='user1', fullname="user 1's full name",
                email='user1@testusers.org')
        user2 = model.user.User(name='user2', fullname="user 2's full name")
        user3 = model.user.User(name='user3', email='user3@testusers.org')
        user4 = model.user.User(name='user4')

        # Some test users with Google OpenIDs.
        user5 = model.user.User(
                    name='https://www.google.com/accounts/o8/id/id=ACyQatixLeL'
                         'ODscWvwqsCXWQ2sa3RRaBhaKTkcsvUElI6tNHIQ1_egX_wt1x3fA'
                         'Y983DpW4UQV_U',
                    fullname="user 5's full name", email="user5@testusers.org")
        user6 = model.user.User(
                    name='https://www.google.com/accounts/o8/id/id=ACyQatixLeL'
                         'ODscWvwqsCXWQ2sa3RRaBhaKTkcsvUElI6tNHIQ1_egX_wt1x3fA'
                         'Y983DpW4UQV_J',
                    fullname="user 6's full name")
        user7 = model.user.User(
                    name='https://www.google.com/accounts/o8/id/id=AItOawl27F2'
                         'M92ry4jTdjiVx06tuFNA',
                    email='user7@testusers.org')
        user8 = model.user.User(
                    name='https://www.google.com/accounts/o8/id/id=AItOawl27F2'
                         'M92ry4jTdjiVx06tuFNs'
                    )

        users = (user1, user2, user3, user4, user5, user6, user7, user8)
        google_users = (user5, user6, user7, user8)

        for user in users:
            model.repo.new_revision()
            model.Session.add(user)
            model.Session.commit()

            response = self.app.get(url, extra_environ={'REMOTE_USER':
                user.name.encode('utf-8')})

            model.repo.new_revision()
            model.Session.add(user)

            if user in google_users:
                # Users with Google OpenIDs are asked to give their email if
                # they don't have one and to enter a full name if they don't
                # have one.
                if not user.email and not user.fullname:
                    assert email_and_fullname_notice in response
                    assert email_notice not in response
                    assert fullname_notice not in response
                elif user.email and not user.fullname:
                    assert email_notice not in response
                    assert fullname_notice in response
                    assert email_and_fullname_notice not in response
                elif not user.email and user.fullname:
                    assert email_notice in response
                    assert fullname_notice not in response
                    assert email_and_fullname_notice not in response
                elif user.email and user.fullname:
                    assert email_notice not in response
                    assert fullname_notice not in response
                    assert email_and_fullname_notice not in response
            else:
                # Users without Google OpenIDs are just asked to give their
                # email if they don't have one.
                if not user.email:
                    assert email_notice in response
                    assert email_and_fullname_notice not in response
                    assert fullname_notice not in response
                elif user.email:
                    assert email_notice not in response
                    assert fullname_notice not in response
                    assert email_and_fullname_notice not in response

            if not user.email:
                user.email = "mr_tusks@tusk_family.org"
            if not user.fullname:
                user.fullname = "Mr. Tusks"
            model.Session.commit()

            response = self.app.get(url, extra_environ={'REMOTE_USER':
                user.name.encode('utf-8')})
            assert email_notice not in response
            assert fullname_notice not in response
            assert email_and_fullname_notice not in response

class TestHomeControllerWithoutSearch(TestController, PylonsTestCase, HtmlCheckMethods):
    @classmethod
    def setup_class(cls):
        PylonsTestCase.setup_class()
        
    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()
        
    def test_404(self):
        offset = '/some_nonexistent_url'
        res = self.app.get(offset, status=404)

    def test_about(self):
        offset = url_for(controller='home', action='about')
        res = self.app.get(url_for('about'))
        assert 'CKAN is a community-run catalogue' in res.body, res.body


class TestDatabaseNotInitialised(TestController):
    @classmethod
    def setup_class(cls):
        PylonsTestCase.setup_class()
        model.repo.clean_db()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_home_page(self):
        offset = url_for('home')
        res = self.app.get(offset, status=503)
        assert 'This site is currently off-line. Database is not initialised.' in res

########NEW FILE########
__FILENAME__ = test_package
import datetime

from pylons import config, c
from genshi.core import escape as genshi_escape
from difflib import unified_diff
from nose.tools import assert_equal

from ckan.tests import *
import ckan.tests as tests
from ckan.tests.html_check import HtmlCheckMethods
from ckan.tests.pylons_controller import PylonsTestCase
from base import FunctionalTestCase
import ckan.model as model
from ckan.lib.create_test_data import CreateTestData
from ckan.logic.action import get, update
from ckan import plugins
from ckan.lib.search.common import SolrSettings




existing_extra_html = ('<label class="field_opt" for="Package-%(package_id)s-extras-%(key)s">%(capitalized_key)s</label>', '<input id="Package-%(package_id)s-extras-%(key)s" name="Package-%(package_id)s-extras-%(key)s" size="20" type="text" value="%(value)s">')


class TestPackageBase(FunctionalTestCase):
    key1 = u'key1 Less-than: < Umlaut: \xfc'
    value1 = u'value1 Less-than: < Umlaut: \xfc'
    # Note: Can't put a quotation mark in key1 or value1 because
    # paste.fixture doesn't unescape the value in an input field
    # on form submission. (But it works in real life.)

    def _assert_form_errors(self, res):
        self.check_tag(res, '<form', 'has-errors')
        assert 'field_error' in res, res

    def diff_responses(self, res1, res2):
        return self.diff_html(res1.body, res2.body)

    def diff_html(self, html1, html2):
        return '\n'.join(unified_diff(html1.split('\n'),
                                      html2.split('\n')))

class TestPackageForm(TestPackageBase):
    '''Inherit this in tests for these form testing methods'''
    def _check_package_read(self, res, **params):
        assert not 'Error' in res, res
        assert u'%s - Datasets' % params['title'] in res, res
        main_res = self.main_div(res)
        main_div = main_res
        main_div_str = main_div.encode('utf8')
        assert params['name'] in main_div, main_div_str
        assert params['title'] in main_div, main_div_str
        assert params['version'] in main_div, main_div_str
        self.check_named_element(main_div, 'a', 'href="%s"' % params['url'])
        prefix = 'Dataset-%s-' % params.get('id', '')
        for res_index, values in self._get_resource_values(params['resources'], by_resource=True):
            self.check_named_element(main_div, 'tr', *values)
        assert params['notes'] in main_div, main_div_str
        license = model.Package.get_license_register()[params['license_id']]
        assert license.title in main_div, (license.title, main_div_str)
        tag_names = list(params['tags'])
        self.check_named_element(main_div, 'ul', *tag_names)
        if params.has_key('state'):
            assert 'State: %s' % params['state'] in main_div.replace('</strong>', ''), main_div_str
        if isinstance(params['extras'], dict):
            extras = []
            for key, value in params['extras'].items():
                extras.append((key, value, False))
        elif isinstance(params['extras'], (list, tuple)):
            extras = params['extras']
        else:
            raise NotImplementedError
        for key, value, deleted in extras:
            if not deleted:
                key_in_html_body = self.escape_for_html_body(key)
                value_in_html_body = self.escape_for_html_body(value)
                self.check_named_element(main_div, 'tr', key_in_html_body, value_in_html_body)
            else:
                self.check_named_element(main_div, 'tr', '!' + key)
                self.check_named_element(main_div, 'tr', '!' + value)


    def _get_resource_values(self, resources, by_resource=False):
        assert isinstance(resources, (list, tuple))
        for res_index, resource in enumerate(resources):
            if by_resource:
                values = []
            for i, res_field in enumerate(model.Resource.get_columns(extra_columns = False)):
                if isinstance(resource, (str, unicode)):
                    expected_value = resource if res_field == 'url' else ''
                elif hasattr(resource, res_field):
                    expected_value = getattr(resource, res_field)
                elif isinstance(resource, (list, tuple)):
                    expected_value = resource[i]
                elif isinstance(resource, dict):
                    expected_value = resource.get(res_field, u'')
                else:
                    raise NotImplemented
                if not by_resource:
                    yield (res_index, res_field, expected_value)
                else:
                    values.append(expected_value)
            if by_resource:
                yield(res_index, values)

    def escape_for_html_body(self, unescaped_str):
        # just deal with chars in tests
        return unescaped_str.replace('<', '&lt;')

    def check_form_filled_correctly(self, res, **params):
        if params.has_key('pkg'):
            for key, value in params['pkg'].as_dict().items():
                if key == 'license':
                    key = 'license_id'
                params[key] = value
        prefix = ''
        main_res = self.main_div(res)
        self.check_tag(main_res, prefix+'name', params['name'])
        self.check_tag(main_res, prefix+'title', params['title'])
        self.check_tag(main_res, prefix+'version', params['version'])
        self.check_tag(main_res, prefix+'url', params['url'])
        #for res_index, res_field, expected_value in self._get_resource_values(params['resources']):
        #    ## only check fields that are on the form
        #    if res_field not in ['url', 'id', 'description', 'hash']:
        #        continue
        #    self.check_tag(main_res, '%sresources__%i__%s' % (prefix, res_index, res_field), expected_value)
        self.check_tag_and_data(main_res, prefix+'notes', params['notes'])
        self.check_tag_and_data(main_res, 'selected', params['license_id'])
        if isinstance(params['tags'], (str, unicode)):
            tags = map(lambda s: s.strip(), params['tags'].split(','))
        else:
            tags = params['tags']
        for tag in tags:
            self.check_tag(main_res, prefix+'tag_string', tag)
        if params.has_key('state'):
            self.check_tag_and_data(main_res, 'selected', str(params['state']))
        if isinstance(params['extras'], dict):
            extras = []
            for key, value in params['extras'].items():
                extras.append((key, value, False))
        else:
            extras = params['extras']
        for num, (key, value, deleted) in enumerate(sorted(extras)):
            key_in_html_body = self.escape_for_html_body(key)
            value_in_html_body = self.escape_for_html_body(value)
            key_escaped = genshi_escape(key)
            value_escaped = genshi_escape(value)
            self.check_tag(main_res, 'extras__%s__key' % num, key_in_html_body)
            self.check_tag(main_res, 'extras__%s__value' % num, value_escaped)
            if deleted:
                self.check_tag(main_res, 'extras__%s__deleted' % num, 'checked')

        assert params['log_message'] in main_res, main_res

    def _check_redirect(self, return_url_param, expected_redirect,
                        pkg_name_to_edit='',extra_environ=None):
        '''
        @param return_url_param - encoded url to be given as param - if None
                       then assume redirect is specified in pylons config
        @param expected_redirect - url we expect to redirect to (but <NAME>
                       not yet substituted)
        @param pkg_name_to_edit - '' means create a new dataset
        '''
        try:
            new_name = u'new-name'
            offset_params = {'controller':'package'}
            if pkg_name_to_edit:
                pkg_name = pkg_name_to_edit
                pkg = model.Package.by_name(pkg_name)
                assert pkg
                pkg_id = pkg.id
                offset_params['action'] = 'edit'
                offset_params['id'] = pkg_name_to_edit
            else:
                offset_params['action'] = 'new'
                pkg_id = ''
            if return_url_param:
                offset_params['return_to'] = return_url_param
            offset = url_for(**offset_params)
            res = self.app.get(offset, extra_environ=extra_environ)
            assert 'Datasets -' in res
            fv = res.forms['dataset-edit']
            prefix = ''
            fv[prefix + 'name'] = new_name
            res = fv.submit('save', status=302, extra_environ=extra_environ)
            assert not 'Error' in res, res
            redirected_to = dict(res.headers).get('Location') or dict(res.headers)['location']
            expected_redirect_url = expected_redirect.replace('<NAME>', new_name)
            assert redirected_to == expected_redirect_url, \
                   'Redirected to %s but should have been %s' % \
                   (redirected_to, expected_redirect_url)
        finally:
            # revert name change or pkg creation
            pkg = model.Package.by_name(new_name)
            if pkg:
                rev = model.repo.new_revision()
                if pkg_name_to_edit:
                    pkg.name = pkg_name_to_edit
                else:
                    pkg.purge()
                model.repo.commit_and_remove()

class TestReadOnly(TestPackageForm, HtmlCheckMethods, PylonsTestCase):

    @classmethod
    def setup_class(cls):
        PylonsTestCase.setup_class()
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_read(self):
        name = u'annakarenina'
        c.hide_welcome_message = True
        offset = url_for(controller='package', action='read', id=name)
        res = self.app.get(offset)
        # check you get the same html when specifying the pkg by id
        # instead of by name
        offset = url_for(controller='package', action='read', id=self.anna.id)
        res_by_id = self.app.get(offset)
        # just check the stuff in the package div
        pkg_by_name_main = self.named_div('dataset', res)
        pkg_by_id_main = self.named_div('dataset', res_by_id)
        # rename some things which may be in the wrong order sometimes
        txt_order_non_deterministic = (u'Flexible \u30a1', 'russian', 'tolstoy', 'david', 'roger')
        for txt in txt_order_non_deterministic:
            for pkg_ in (pkg_by_name_main, pkg_by_id_main):
                pkg_ = pkg_.replace(txt, 'placeholder')
        print pkg_by_name_main
        res_diff = self.diff_html(pkg_by_name_main, pkg_by_id_main)
        assert not res_diff, res_diff.encode('utf8')
        # not true as language selection link return url differs:
        #assert len(res_by_id.body) == len(res.body)

        # only retrieve after app has been called
        anna = self.anna
        assert name in res
        assert anna.version in res
        assert anna.url in res
        assert 'Some test notes' in res
        assert '<strong>Some bolded text.</strong>' in res
        self.check_tag_and_data(res, 'left arrow', '&lt;')
        self.check_tag_and_data(res, 'umlaut', u'\xfc')
        #assert 'OKD Compliant::' in res
        assert u'Flexible \u30a1' in res, res
        assert 'russian' in res
        assert 'david' in res
        assert 'roger' in res
        assert 'genre' in res, res
        assert 'romantic novel' in res, res
        assert 'original media' in res, res
        assert 'book' in res, res
        assert 'This dataset satisfies the Open Definition' in res, res

    def test_read_war_rdf(self):
        name = u'warandpeace'
        offset = url_for(controller='package', action='read', id=name + ".rdf")
        res = self.app.get(offset)
        assert '<dct:title>A Wonderful Story</dct:title>' in res, res


    def test_read_war(self):
        name = u'warandpeace'
        c.hide_welcome_message = True
        offset = url_for(controller='package', action='read', id=name)
        res = self.app.get(offset)
        assert 'This dataset is Not Open' in res, res

    def test_read_nonexistentpackage(self):
        name = 'anonexistentpackage'
        offset = url_for(controller='package', action='read', id=name)
        res = self.app.get(offset, status=404)

    def test_read_internal_links(self):
        pkg_name = u'link-test',
        CreateTestData.create_arbitrary([
            {'name':pkg_name,
             'notes':'Decoy link here: decoy:decoy, real links here: dataset:pkg-1, ' \
                   'tag:tag_1 group:test-group-1 and a multi-word tag: tag:"multi word with punctuation."',
             }
            ])
        offset = url_for(controller='package', action='read', id=pkg_name)
        res = self.app.get(offset)
        def check_link(res, controller, id):
            id_in_uri = id.strip('"').replace(' ', '%20') # remove quotes and percent-encode spaces
            self.check_tag_and_data(res, 'a ', '%s/%s' % (controller, id_in_uri),
                                    '%s:%s' % (controller, id.replace('"', '&#34;')))
        check_link(res, 'dataset', 'pkg-1')
        check_link(res, 'tag', 'tag_1')
        check_link(res, 'tag', '"multi word with punctuation."')
        check_link(res, 'group', 'test-group-1')
        assert 'decoy</a>' not in res, res
        assert 'decoy"' not in res, res

        #res = self.app.get(offset)
        #assert 'Datasets' in res
        #name = u'annakarenina'
        #title = u'A Novel By Tolstoy'
        #assert title in res
        #res = res.click(title)
        #assert '%s - Datasets' % title in res, res
        #main_div = self.main_div(res)
        #assert title in main_div, main_div.encode('utf8')

    def test_history(self):
        name = 'annakarenina'
        offset = url_for(controller='package', action='history', id=name)
        res = self.app.get(offset)
        assert 'History' in res
        assert 'Revisions' in res
        assert name in res

    def test_read_plugin_hook(self):
        plugins.load('test_package_controller_plugin')
        plugin = plugins.get_plugin('test_package_controller_plugin')
        name = u'annakarenina'
        offset = url_for(controller='package', action='read', id=name)
        res = self.app.get(offset)

        assert plugin.calls['read'] == 1, plugin.calls
        assert plugin.calls['after_show'] == 1, plugin.calls
        plugins.unload('test_package_controller_plugin')

    def test_resource_list(self):
        # TODO restore this test. It doesn't make much sense with the
        # present resource list design.
        name = 'annakarenina'
        cache_url = 'http://thedatahub.org/test_cache_url.csv'
        # add a cache_url to the first resource in the package
        context = {'model': model, 'session': model.Session, 'user': 'testsysadmin'}
        data = {'id': 'annakarenina'}
        pkg = get.package_show(context, data)
        pkg['resources'][0]['cache_url'] = cache_url
        # FIXME need to pretend to be called by the api
        context['api_version'] = 3
        update.package_update(context, pkg)
        # check that the cache url is included on the dataset view page
        offset = url_for(controller='package', action='read', id=name)
        res = self.app.get(offset)
        #assert '[cached]'in res
        #assert cache_url in res


class TestReadAtRevision(FunctionalTestCase, HtmlCheckMethods):

    @classmethod
    def setup_class(cls):
        cls.before = datetime.datetime(2010, 1, 1)
        cls.date1 = datetime.datetime(2011, 1, 1)
        cls.date2 = datetime.datetime(2011, 1, 2)
        cls.date3 = datetime.datetime(2011, 1, 3)
        cls.today = datetime.datetime.now()
        cls.pkg_name = u'testpkg'

        # create dataset
        rev = model.repo.new_revision()
        rev.timestamp = cls.date1
        pkg = model.Package(name=cls.pkg_name, title=u'title1')
        model.Session.add(pkg)
        model.setup_default_user_roles(pkg)
        model.repo.commit_and_remove()

        # edit dataset
        rev = model.repo.new_revision()
        rev.timestamp = cls.date2
        pkg = model.Package.by_name(cls.pkg_name)
        pkg.title = u'title2'
        pkg.add_tag_by_name(u'tag 2')
        pkg.extras = {'key2': u'value2'}
        model.repo.commit_and_remove()

        # edit dataset again
        rev = model.repo.new_revision()
        rev.timestamp = cls.date3
        pkg = model.Package.by_name(cls.pkg_name)
        pkg.title = u'title3'
        pkg.add_tag_by_name(u'tag3.')
        pkg.extras['key2'] = u'value3'
        model.repo.commit_and_remove()

        cls.offset = url_for(controller='package',
                             action='read',
                             id=cls.pkg_name)
        pkg = model.Package.by_name(cls.pkg_name)
        cls.revision_ids = [rev[0].id for rev in pkg.all_related_revisions[::-1]]
                        # revision order is reversed to be chronological

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_read_normally(self):
        res = self.app.get(self.offset, status=200)
        pkg_html = self.named_div('dataset', res)
        side_html = self.named_div('sidebar', res)
        print 'PKG', pkg_html
        assert 'title3' in res
        assert 'key2' in pkg_html
        assert 'value3' in pkg_html
        print 'SIDE', side_html
        assert 'tag3.' in side_html
        assert 'tag 2' in side_html

    def test_read_date1(self):
        offset = self.offset + self.date1.strftime('@%Y-%m-%d')
        res = self.app.get(offset, status=200)
        pkg_html = self.named_div('dataset', res)
        side_html = self.named_div('sidebar', res)
        assert 'title1' in res, res
        assert 'key2' not in pkg_html, pkg_html
        assert 'value3' not in pkg_html, pkg_html
        assert 'tag3.' not in side_html, side_html
        assert 'tag 2' not in side_html, side_html

    def test_read_date2(self):
        date2_plus_3h = self.date2 + datetime.timedelta(hours=3)
        offset = self.offset + date2_plus_3h.strftime('@%Y-%m-%d')
        res = self.app.get(offset, status=200)
        pkg_html = self.named_div('dataset', res)
        side_html = self.named_div('sidebar', res)
        print 'PKG', pkg_html
        assert 'title2' in res
        assert 'key2' in pkg_html
        assert 'value2' in pkg_html
        print 'SIDE', side_html
        assert 'tag3.' not in side_html
        assert 'tag 2' in side_html

    def test_read_date3(self):
        offset = self.offset + self.date3.strftime('@%Y-%m-%d-%H-%M')
        res = self.app.get(offset, status=200)
        pkg_html = self.named_div('dataset', res)
        side_html = self.named_div('sidebar', res)
        print 'PKG', pkg_html
        assert 'title3' in res
        assert 'key2' in pkg_html
        assert 'value3' in pkg_html
        print 'SIDE', side_html
        assert 'tag3.' in side_html
        assert 'tag 2' in side_html

    def test_read_date_before_created(self):
        offset = self.offset + self.before.strftime('@%Y-%m-%d')
        res = self.app.get(offset, status=404)

    def test_read_date_invalid(self):
        res = self.app.get(self.offset + self.date3.strftime('@%Y-%m'),
                           status=400)
        res = self.app.get(self.offset + self.date3.strftime('@%Y'),
                           status=400)
        res = self.app.get(self.offset + self.date3.strftime('@%Y@%m'),
                           status=400)

    def test_read_revision1(self):
        offset = self.offset + '@%s' % self.revision_ids[0]
        res = self.app.get(offset, status=200)
        main_html = self.main_div(res)
        pkg_html = self.named_div('dataset', res)
        side_html = self.named_div('sidebar', res)
        print 'MAIN', main_html
        assert 'This is an old revision of this dataset' in main_html
        assert 'at January 1, 2011, 00:00' in main_html
        self.check_named_element(main_html, 'a', 'href="/dataset/%s"' % self.pkg_name)
        print 'PKG', pkg_html
        assert 'title1' in res
        assert 'key2' not in pkg_html
        assert 'value3' not in pkg_html
        print 'SIDE', side_html
        assert 'tag3.' not in side_html
        assert 'tag 2' not in side_html

    def test_read_revision2(self):
        offset = self.offset + '@%s' % self.revision_ids[1]
        res = self.app.get(offset, status=200)
        main_html = self.main_div(res)
        pkg_html = self.named_div('dataset', res)
        side_html = self.named_div('sidebar', res)
        print 'MAIN', main_html
        assert 'This is an old revision of this dataset' in main_html
        assert 'at January 2, 2011, 00:00' in main_html
        self.check_named_element(main_html, 'a', 'href="/dataset/%s"' % self.pkg_name)
        print 'PKG', pkg_html
        assert 'title2' in res
        assert 'key2' in pkg_html
        assert 'value2' in pkg_html
        print 'SIDE', side_html
        assert 'tag3.' not in side_html
        assert 'tag 2' in side_html

    def test_read_revision3(self):
        offset = self.offset + '@%s' % self.revision_ids[2]
        res = self.app.get(offset, status=200)
        main_html = self.main_div(res)
        pkg_html = self.named_div('dataset', res)
        side_html = self.named_div('sidebar', res)
        print 'MAIN', main_html
        assert 'This is an old revision of this dataset' not in main_html
        assert 'This is the current revision of this dataset' in main_html
        assert 'at January 3, 2011, 00:00' in main_html
        self.check_named_element(main_html, 'a', 'href="/dataset/%s"' % self.pkg_name)
        print 'PKG', pkg_html
        assert 'title3' in res
        assert 'key2' in pkg_html
        assert 'value3' in pkg_html
        print 'SIDE', side_html
        assert 'tag3.' in side_html
        assert 'tag 2' in side_html

    def test_read_bad_revision(self):
        # this revision doesn't exist in the db
        offset = self.offset + '@ccab6798-1f4b-4a22-bcf5-462703aa4594'
        res = self.app.get(offset, status=404)

class TestEdit(TestPackageForm):
    editpkg_name = u'editpkgtest'

    @classmethod
    def setup_class(self):
        CreateTestData.create()

        self._reset_data()

    def setup(self):
        if not self.res:
            self.res = self.app.get(self.offset,extra_environ=self.extra_environ_admin)
        model.Session.remove()

    @classmethod
    def _reset_data(self):
        model.Session.remove()
        model.repo.rebuild_db()
        CreateTestData.create()
        CreateTestData.create_arbitrary(
            {'name':self.editpkg_name,
             'url':u'editpkgurl.com',
             'tags':[u'mytesttag'],
             'resources':[{'url':u'url escape: & umlaut: \xfc quote: "',
                          'description':u'description escape: & umlaut: \xfc quote "',
                          }],
             'admins':[u'testadmin'],
             })

        self.editpkg = model.Package.by_name(self.editpkg_name)
        self.pkgid = self.editpkg.id
        self.offset = url_for(controller='package', action='edit', id=self.editpkg_name)

        self.editpkg = model.Package.by_name(self.editpkg_name)
        self.admin = model.User.by_name(u'testsysadmin')

        self.extra_environ_admin = {'REMOTE_USER': self.admin.name.encode('utf8')}
        self.extra_environ_russianfan = {'REMOTE_USER': 'russianfan'}
        self.res = None #get's refreshed by setup
        model.Session.remove()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_edit_basic(self):
        # just the absolute basics
        try:
            self.res = self.app.get(self.offset,extra_environ=self.extra_environ_admin)
            assert 'Edit - Datasets' in self.res, self.res
            new_name = u'new-name'
            new_title = u'New Title'
            fv = self.res.forms['dataset-edit']
            prefix = ''
            fv[prefix + 'name'] = new_name
            fv[prefix + 'title'] = new_title
            res = fv.submit('save',extra_environ=self.extra_environ_admin)
            # get redirected ...
            res = res.follow()
            offset = url_for(controller='package', action='read', id=new_name)
            res = self.app.get(offset)
            assert '%s - Datasets' % new_title in res, res
            pkg = model.Package.by_name(new_name)
            assert pkg
            assert pkg.title == new_title
        finally:
            self._reset_data()

    def test_edit(self):
        # just the key fields
        try:
            self.res = self.app.get(self.offset,extra_environ=self.extra_environ_admin)
            assert 'Edit - Datasets' in self.res, self.res
            assert self.editpkg.notes in self.res

            new_name = u'new-name'
            new_title = u'A Short Description of this Dataset'
            newurl = u'http://www.editpkgnewurl.com'
            new_download_url = newurl + u'/download/'
            newlicense_id = u'cc-by'
            newversion = u'0.9b'
            fv = self.res.forms['dataset-edit']
            prefix = ''
            fv[prefix + 'name'] = new_name
            fv[prefix + 'title'] =  new_title
            fv[prefix + 'url'] =  newurl
            #fv[prefix + 'resources__0__url'] =  new_download_url
            fv[prefix + 'license_id'] =  newlicense_id
            fv[prefix + 'version'] = newversion
            res = fv.submit('save',extra_environ=self.extra_environ_admin)
            # get redirected ...
            res = res.follow()
            model.Session.remove()
            offset = url_for(controller='package', action='read', id=new_name)
            res = self.app.get(offset)
            assert '%s - Datasets' % new_title in res, res
            pkg = model.Package.by_name(new_name)
            assert pkg.title == new_title
            assert pkg.url == newurl
            #assert pkg.resources[0].url == new_download_url
            assert pkg.version == newversion
            assert newlicense_id == pkg.license.id
        finally:
            self._reset_data()

    def test_edit_basic_pkg_by_id(self):
        try:
            pkg = model.Package.by_name(u'editpkgtest')
            offset = url_for(controller='package', action='edit', id=pkg.id)
            res = self.app.get(offset, extra_environ=self.extra_environ_admin)
            #assert res.body == self.res.body, self.diff_responses(res, self.res)
            assert 'Edit - Datasets' in res, res
            assert pkg.name in res
            new_name = u'new-name'
            new_title = u'A Short Description of this Dataset'
            fv = self.res.forms['dataset-edit']
            prefix = ''
            fv[prefix + 'name'] = new_name
            fv[prefix + 'title'] =  new_title
            res = fv.submit('save', extra_environ=self.extra_environ_admin)
            # get redirected ...
            res = res.follow()
            offset = url_for(controller='package', action='read', id=new_name)
            res = self.app.get(offset)
            assert '%s - Datasets' % new_title in res, res
            pkg = model.Package.by_name(new_name)
            assert pkg
        finally:
            self._reset_data()

    def test_edit_2_not_groups(self):
        # not allowed to edit groups for now
        prefix = 'Dataset-%s-' % self.pkgid
        fv = self.res.forms['dataset-edit']
        assert not fv.fields.has_key(prefix + 'groups')

    def test_edit_2_tags_and_groups(self):
        # testing tag updating
        newtagnames = [u'russian', u'tolstoy', u'superb book']
        newtags = newtagnames
        tagvalues = ','.join(newtags)
        fv = self.res.forms['dataset-edit']
        prefix = ''
        fv[prefix + 'tag_string'] = tagvalues
        exp_log_message = 'test_edit_2: making some changes'
        fv['log_message'] =  exp_log_message
        res = fv.submit('save', extra_environ=self.extra_environ_admin)
        # get redirected ...
        res = res.follow()
        assert '%s - Datasets' % self.editpkg_name in res
        pkg = model.Package.by_name(self.editpkg.name)
        assert len(pkg.get_tags()) == len(newtagnames)
        outtags = [ tag.name for tag in pkg.get_tags() ]
        for tag in newtags:
            assert tag in outtags
        rev = model.Revision.youngest(model.Session)
        assert rev.author == self.admin.name
        assert rev.message == exp_log_message

    def test_redirect_after_edit_using_param(self):
        return_url = 'http://random.site.com/dataset/<NAME>?test=param'
        # It's useful to know that this url encodes to:
        # 'http%3A%2F%2Frandom.site.com%2Fdataset%2F%3CNAME%3E%3Ftest%3Dparam'
        expected_redirect = return_url
        self._check_redirect(return_url, expected_redirect,
                             pkg_name_to_edit=self.editpkg_name, extra_environ=self.extra_environ_admin)

    def test_redirect_after_edit_using_config(self):
        return_url = '' # redirect comes from test.ini setting
        expected_redirect = config['package_edit_return_url']
        self._check_redirect(return_url, expected_redirect,
                             pkg_name_to_edit=self.editpkg_name, extra_environ=self.extra_environ_admin)

    def test_edit_all_fields(self):
        try:
            # Create new item
            rev = model.repo.new_revision()
            pkg_name = u'new_editpkgtest'
            pkg = model.Package(name=pkg_name)
            pkg.title = u'This is a Test Title'
            pkg.url = u'editpkgurl.com'
            pr1 = model.Resource(url=u'editpkgurl1',
                  format=u'plain text', description=u'Full text',
                  hash=u'123abc',)
            pr2 = model.Resource(url=u'editpkgurl2',
                  format=u'plain text2', description=u'Full text2',
                  hash=u'456abc',)
            pkg.resources.append(pr1)
            pkg.resources.append(pr2)
            pkg.notes= u'this is editpkg'
            pkg.version = u'2.2'
            t1 = model.Tag(name=u'one')
            t2 = model.Tag(name=u'two words')
            pkg.add_tags([t1, t2])
            pkg.state = model.State.DELETED
            pkg.license_id = u'other-open'
            extras = {'key1':'value1', 'key2':'value2', 'key3':'value3'}
            for key, value in extras.items():
                pkg.extras[unicode(key)] = unicode(value)
            for obj in [pkg, t1, t2, pr1, pr2]:
                model.Session.add(obj)
            model.repo.commit_and_remove()
            pkg = model.Package.by_name(pkg_name)
            model.setup_default_user_roles(pkg, [self.admin])
            model.repo.commit_and_remove()

            # Edit it
            offset = url_for(controller='package', action='edit', id=pkg.name)
            res = self.app.get(offset, status=200, extra_environ={'REMOTE_USER':'testsysadmin'})
            assert 'Edit - Datasets' in res, res

            # Check form is correctly filled
            pkg = model.Package.by_name(pkg_name)
            self.check_form_filled_correctly(res, pkg=pkg, log_message='')

            # Amend form
            name = u'test_name'
            title = u'Test Title'
            version = u'1.1'
            url = u'http://something.com/somewhere.zip'
            resources = ((u'http://something.com/somewhere-else.xml', u'xml', u'Best', u'hash1', 'alt'),
                         (u'http://something.com/somewhere-else2.xml', u'xml2', u'Best2', u'hash2', 'alt'),
                         )
            assert len(resources[0]) == 5
            notes = u'Very important'
            license_id = u'odc-by'
            state = model.State.ACTIVE
            tags = (u'tag1', u'tag2', u'tag 3')
            tags_txt = u','.join(tags)
            extra_changed = 'key1', self.value1 + ' CHANGED', False
            extra_new = 'newkey', 'newvalue', False
            log_message = 'This is a comment'
            assert not model.Package.by_name(name)
            fv = res.forms['dataset-edit']
            prefix = ''
            fv[prefix+'name'] = name
            fv[prefix+'title'] = title
            fv[prefix+'version'] = version
            fv[prefix+'url'] = url
            # TODO consider removing this test entirely, or hardcoding column names
            #for res_index, resource in enumerate(resources):
            #    for field_index, res_field in enumerate(model.Resource.get_columns()):
            #        fv[prefix+'resources__%s__%s' % (res_index, res_field)] = resource[field_index]
            fv[prefix+'notes'] = notes
            fv[prefix+'license_id'] = license_id
            fv[prefix+'tag_string'] = tags_txt
            fv[prefix+'state'] = state
            fv[prefix+'extras__0__value'] = extra_changed[1].encode('utf8')
            fv[prefix+'extras__3__key'] = extra_new[0].encode('utf8')
            fv[prefix+'extras__3__value'] = extra_new[1].encode('utf8')
            fv[prefix+'extras__2__deleted'] = True
            fv['log_message'] = log_message

            extras = (('key2', extras['key2'], False),
                       extra_changed,
                       extra_new,
                       ('key3', extras['key3'], True))

            res = fv.submit('save', extra_environ={'REMOTE_USER':'testsysadmin'})

            # Check dataset page
            assert not 'Error' in res, res

            # Check dataset object
            pkg = model.Package.by_name(name)
            assert pkg.name == name
            assert pkg.title == title
            assert pkg.version == version
            assert pkg.url == url
            # TODO consider removing this test entirely, or hardcoding column names
            #for res_index, resource in enumerate(resources):
            #    for field_index, res_field in enumerate(model.Resource.get_columns()):
            #        assert getattr(pkg.resources[res_index], res_field) == resource[field_index]
            assert pkg.notes == notes
            assert pkg.license.id == license_id
            saved_tagnames = [str(tag.name) for tag in pkg.get_tags()]
            saved_tagnames.sort()
            expected_tagnames = list(tags)
            expected_tagnames.sort()
            assert saved_tagnames == expected_tagnames
            assert pkg.state == state
            assert len(pkg.extras) == len([extra for extra in extras if not extra[-1]])
            for key, value, deleted in extras:
                if not deleted:
                    assert pkg.extras[key] == value

            # for some reason environ['REMOTE_ADDR'] is undefined
            rev = model.Revision.youngest(model.Session)
            assert rev.author == 'testsysadmin', rev.author
            assert rev.message == log_message
            # TODO: reinstate once fixed in code
            exp_log_message = u'Creating dataset %s' % name
            #assert rev.message == exp_log_message
        finally:
            self._reset_data()

    # NB: Cannot test resources now because it is all javascript!
##    def test_edit_invalid_resource(self):
##        try:
##            # Create new dataset
##            pkg_name = u'test_res'
##            CreateTestData.create_arbitrary({'name': pkg_name,
##                                             'resources': [{'url': '1.pdf'}]})

##            # Edit it
##            pkg = model.Package.by_name(pkg_name)
##            offset = url_for(controller='package', action='edit', id=pkg.name)
##            res = self.app.get(offset, status=200, extra_environ={'REMOTE_USER':'testadmin'})
##            assert 'Edit - Datasets' in res, res

##            pkg = model.Package.by_name(pkg_name)

##            # Amend form
##            fv = res.forms['dataset-edit']

##            fv['resources__0__size'] = 'abc'
##            res = fv.submit('save', extra_environ={'REMOTE_USER':'testadmin'})

##            # Check dataset page
##            assert 'Errors in form' in res, res
##            assert 'Package resource(s) invalid' in res, res
##            assert 'Resource 1' in res, res
##        finally:
##            self._reset_data()

    def test_edit_bad_log_message(self):
        fv = self.res.forms['dataset-edit']
        prefix = ''
        fv['log_message'] = u'Free enlargements: http://drugs.com/' # spam
        res = fv.submit('save', extra_environ=self.extra_environ_admin)
        assert 'Error' in res, res
        self.check_tag(res, '<form', 'has-errors')
        assert 'No links are allowed' in res, res

    def test_edit_bad_name(self):
        fv = self.res.forms['dataset-edit']
        prefix = ''
        fv[prefix + 'name'] = u'a' # invalid name
        res = fv.submit('save', extra_environ=self.extra_environ_admin)
        assert 'Error' in res, res
        assert 'Name must be at least 2 characters long' in res, res
        # Ensure there is an error at the top of the form and by the field
        self._assert_form_errors(res)


    def test_edit_plugin_hook(self):
        # just the absolute basics
        try:
            plugins.load('test_package_controller_plugin')
            plugin = plugins.get_plugin('test_package_controller_plugin')
            res = self.app.get(self.offset, extra_environ=self.extra_environ_admin)
            new_name = u'new-name'
            new_title = u'New Title'
            fv = res.forms['dataset-edit']
            prefix = ''
            fv[prefix + 'name'] = new_name
            fv[prefix + 'title'] = new_title
            res = fv.submit('save', extra_environ=self.extra_environ_admin)
            # get redirected ...
            assert plugin.calls['edit'] == 1, plugin.calls
            plugins.unload('test_package_controller_plugin')
        finally:
            self._reset_data()

    def test_after_update_plugin_hook(self):
        # just the absolute basics
        try:
            plugins.load('test_package_controller_plugin')
            plugin = plugins.get_plugin('test_package_controller_plugin')
            res = self.app.get(self.offset, extra_environ=self.extra_environ_admin)
            new_name = u'new-name'
            new_title = u'New Title'
            fv = res.forms['dataset-edit']
            prefix = ''
            fv[prefix + 'name'] = new_name
            fv[prefix + 'title'] = new_title
            res = fv.submit('save', extra_environ=self.extra_environ_admin)
            # get redirected ...
            assert plugin.calls['after_update'] == 1, plugin.calls
            assert plugin.calls['after_create'] == 0, plugin.calls
            plugins.unload('test_package_controller_plugin')
        finally:
            self._reset_data()

    def test_edit_700_groups_add(self):
        try:
            pkg = model.Package.by_name(u'editpkgtest')
            grp = model.Group.by_name(u'roger')
            assert len(pkg.get_groups()) == 0
            offset = url_for(controller='package', action='edit', id=pkg.name)

            res = self.app.get(offset, extra_environ=self.extra_environ_admin)
            prefix = ''
            field_name = prefix + "groups__0__id"
            assert field_name in res
            fv = res.forms['dataset-edit']
            fv[prefix + 'groups__0__id'] = grp.id
            res = fv.submit('save', extra_environ=self.extra_environ_admin)
            res = res.follow()
            pkg = model.Package.by_name(u'editpkgtest')
            assert len(pkg.get_groups()) == 1, pkg.get_groups()
            assert 'roger' in res, res
        finally:
            self._reset_data()

    def test_edit_700_groups_remove(self):
        try:
            pkg = model.Package.by_name(u'editpkgtest')
            assert len(pkg.get_groups()) == 0
            grp = model.Group.by_name(u'roger')
            model.repo.new_revision()
            model.Session.add(model.Member(table_id=pkg.id, table_name='package', group=grp))
            model.repo.commit_and_remove()
            pkg = model.Package.by_name(u'editpkgtest')
            assert len(pkg.get_groups()) == 1
            offset = url_for(controller='package', action='edit', id=pkg.name)
            res = self.app.get(offset, extra_environ=self.extra_environ_admin)
            prefix = ''
            field_name = prefix + "groups__0__id"
            fv = res.forms['dataset-edit']
            print field_name
            fv[field_name] = False
            res = fv.submit('save', extra_environ=self.extra_environ_admin)
            model.repo.commit_and_remove()
            pkg = model.Package.by_name(u'editpkgtest')
            assert len(pkg.get_groups()) == 0
        finally:
            self._reset_data()

    def test_edit_404(self):
        self.offset = url_for(controller='package', action='edit', id='random_name')
        self.res = self.app.get(self.offset, status=404)

    def test_edit_indexerror(self):
        bad_solr_url = 'http://127.0.0.1/badsolrurl'
        solr_url = SolrSettings.get()[0]
        try:
            SolrSettings.init(bad_solr_url)

            fv = self.res.forms['dataset-edit']
            fv['log_message'] = u'Test log message'
            res = fv.submit('save', status=500, extra_environ=self.extra_environ_admin)
            assert 'Unable to update search index' in res, res
        finally:
            SolrSettings.init(solr_url)

    def test_edit_pkg_with_relationships(self):
        # 1786
        try:
            # add a relationship to a package
            pkg = model.Package.by_name(self.editpkg_name)
            anna = model.Package.by_name(u'annakarenina')
            model.repo.new_revision()
            pkg.add_relationship(u'depends_on', anna)
            model.repo.commit_and_remove()

            # check relationship before the test
            rels = model.Package.by_name(self.editpkg_name).get_relationships()
            assert_equal(str(rels), '[<*PackageRelationship editpkgtest depends_on annakarenina>]')

            # edit the package
            self.offset = url_for(controller='package', action='edit', id=self.editpkg_name)
            self.res = self.app.get(self.offset, extra_environ=self.extra_environ_admin)
            fv = self.res.forms['dataset-edit']
            fv['title'] = u'New Title'
            res = fv.submit('save')

            # check relationship still exists
            rels = model.Package.by_name(self.editpkg_name).get_relationships()
            assert_equal(str(rels), '[<*PackageRelationship editpkgtest depends_on annakarenina>]')

        finally:
            self._reset_data()


class TestDelete(TestPackageForm):

    pkg_names = []

    @classmethod
    def setup_class(self):
        model.repo.init_db()
        CreateTestData.create()
        CreateTestData.create_test_user()

        self.admin = model.User.by_name(u'testsysadmin')

        self.extra_environ_admin = {'REMOTE_USER': self.admin.name.encode('utf8')}
        self.extra_environ_tester = {'REMOTE_USER': 'tester'}

    @classmethod
    def teardown_class(self):
        self.purge_packages(self.pkg_names)
        model.repo.rebuild_db()

    def test_delete(self):
        plugins.load('test_package_controller_plugin')
        plugin = plugins.get_plugin('test_package_controller_plugin')

        offset = url_for(controller='package', action='delete',
                id='warandpeace')
        # Since organizations, any owned dataset can be edited/deleted by any
        # user
        self.app.post(offset, extra_environ=self.extra_environ_tester)

        self.app.post(offset, extra_environ=self.extra_environ_admin)

        assert model.Package.get('warandpeace').state == u'deleted'

        assert plugin.calls['delete'] == 2
        assert plugin.calls['after_delete'] == 2
        plugins.unload('test_package_controller_plugin')


class TestNew(TestPackageForm):
    pkg_names = []

    @classmethod
    def setup_class(self):
        model.repo.init_db()
        CreateTestData.create_test_user()
#        self.admin = model.User.by_name(u'russianfan')

#        self.extra_environ_admin = {'REMOTE_USER': self.admin.name.encode('utf8')}
        self.extra_environ_tester = {'REMOTE_USER': 'tester'}

    @classmethod
    def teardown_class(self):
        self.purge_packages(self.pkg_names)
        model.repo.rebuild_db()

    def test_new_with_params_1(self):
        offset = url_for(controller='package', action='new',
                url='http://xxx.org', name='xxx.org')
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)
        form = res.forms['dataset-edit']
        assert_equal(form['url'].value, 'http://xxx.org')
        assert_equal(form['name'].value, 'xxx.org')

    def test_new_without_resource(self):
        # new dataset
        prefix = ''
        name = u'test_no_res'
        offset = url_for(controller='package', action='new')
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)
        fv = res.forms['dataset-edit']
        fv[prefix+'name'] = name
        # submit
        self.pkg_names.append(name)
        res = fv.submit('save', extra_environ=self.extra_environ_tester)

        # check dataset page
        assert not 'Error' in res, res
        res = res.follow()
        res1 = self.main_div(res).replace('</strong>', '')
        assert '<td><a href="">' not in res1, res1

        # check object created
        pkg = model.Package.by_name(name)
        assert pkg
        assert pkg.name == name
        assert not pkg.resources, pkg.resources

    def test_new(self):
        assert not model.Package.by_name(u'annakarenina')
        offset = url_for(controller='package', action='new')
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)
        assert 'Add - Datasets' in res
        fv = res.forms['dataset-edit']
        prefix = ''
        fv[prefix + 'name'] = 'annakarenina'
        self.pkg_names.append('annakarenina')
        res = fv.submit('save', extra_environ=self.extra_environ_tester)
        assert not 'Error' in res, res

    def test_new_bad_name(self):
        offset = url_for(controller='package', action='new', id=None)
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)
        assert 'Add - Datasets' in res
        fv = res.forms['dataset-edit']
        prefix = ''
        fv[prefix + 'name'] = u'a' # invalid name
        self.pkg_names.append('a')
        res = fv.submit('save', extra_environ=self.extra_environ_tester)
        assert 'Error' in res, res
        assert 'Name must be at least 2 characters long' in res, res
        self._assert_form_errors(res)

    def test_new_no_name(self):
        offset = url_for(controller='package', action='new', id=None)
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)
        assert 'Add - Datasets' in res
        fv = res.forms['dataset-edit']
        prefix = ''
        # don't set a name
        res = fv.submit('save', extra_environ=self.extra_environ_tester)
        assert 'Error' in res, res
        assert 'URL: Missing value' in res, res
        self._assert_form_errors(res)

    def test_redirect_after_new_using_param(self):
        return_url = 'http://random.site.com/dataset/<NAME>?test=param'
        # It's useful to know that this url encodes to:
        # 'http%3A%2F%2Frandom.site.com%2Fdataset%2F%3CNAME%3E%3Ftest%3Dparam'
        expected_redirect = return_url
        self._check_redirect(return_url, expected_redirect,
                             pkg_name_to_edit='', extra_environ=self.extra_environ_tester)

    def test_redirect_after_new_using_config(self):
        return_url = '' # redirect comes from test.ini setting
        expected_redirect = config['package_new_return_url']
        self._check_redirect(return_url, expected_redirect,
                             pkg_name_to_edit='', extra_environ=self.extra_environ_tester)

    def test_new_all_fields(self):
        name = u'test_name2'
        title = u'Test Title'
        version = u'1.1'
        url = u'http://something.com/somewhere.zip'
        download_url = u'http://something.com/somewhere-else.zip'
        notes = u'Very important'
        license_id = u'odc-by'
        tags = (u'tag1', u'tag2.', u'tag 3', u'SomeCaps')
        tags_txt = u','.join(tags)
        extras = {self.key1:self.value1, 'key2':'value2', 'key3':'value3'}
        log_message = 'This is a comment'
        assert not model.Package.by_name(name)
        offset = url_for(controller='package', action='new')
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)
        assert 'Add - Datasets' in res
        fv = res.forms['dataset-edit']
        prefix = ''
        fv[prefix+'name'] = name
        fv[prefix+'title'] = title
        fv[prefix+'version'] = version
        fv[prefix+'url'] = url
        #fv[prefix+'resources__0__url'] = download_url
        #fv[prefix+'resources__0__description'] = u'description escape: & umlaut: \xfc quote "'.encode('utf8')
        fv[prefix+'notes'] = notes
        fv[prefix+'license_id'] = license_id
        fv[prefix+'tag_string'] = tags_txt
        for i, extra in enumerate(sorted(extras.items())):
            fv[prefix+'extras__%s__key' % i] = extra[0].encode('utf8')
            fv[prefix+'extras__%s__value' % i] = extra[1].encode('utf8')
        fv['log_message'] = log_message
        # Submit
        fv = res.forms['dataset-edit']
        self.pkg_names.append(name)
        res = fv.submit('save', extra_environ=self.extra_environ_tester)

        # Check dataset page
        assert not 'Error' in res, res

        # Check dataset object
        pkg = model.Package.by_name(name)
        assert pkg.name == name
        assert pkg.title == title
        assert pkg.version == version
        assert pkg.url == url
        #assert pkg.resources[0].url == download_url
        assert pkg.notes == notes
        assert pkg.license.id == license_id
        saved_tagnames = [str(tag.name) for tag in pkg.get_tags()]
        saved_tagnames.sort()
        expected_tagnames = sorted(tags)
        assert saved_tagnames == expected_tagnames, '%r != %r' % (saved_tagnames, expected_tagnames)
        saved_groupnames = [str(group.name) for group in pkg.get_groups()]
        assert len(pkg.extras) == len(extras)
        for key, value in extras.items():
            assert pkg.extras[key] == value

        # for some reason environ['REMOTE_ADDR'] is undefined
        rev = model.Revision.youngest(model.Session)
        assert rev.author == 'tester'
        assert rev.message == log_message
        # TODO: reinstate once fixed in code
        exp_log_message = u'Creating dataset %s' % name
        # assert rev.message == exp_log_message

    def test_new_existing_name(self):
        # test creating a dataset with an existing name results in error'
        # create initial dataset
        pkgname = u'testpkg'
        pkgtitle = u'mytesttitle'
        assert not model.Package.by_name(pkgname)
        offset = url_for(controller='package', action='new', id=None)
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)
        assert 'Add - Datasets' in res
        fv = res.forms['dataset-edit']
        prefix = ''
        fv[prefix + 'name'] = pkgname
        self.pkg_names.append(pkgname)
        res = fv.submit('save', extra_environ=self.extra_environ_tester)
        assert not 'Error' in res, res
        assert model.Package.by_name(pkgname)
        # create duplicate dataset
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)
        assert 'Add - Datasets' in res
        fv = res.forms['dataset-edit']
        fv[prefix+'name'] = pkgname
        fv[prefix+'title'] = pkgtitle
        res = fv.submit('save', extra_environ=self.extra_environ_tester)
        assert 'Error' in res, res
        assert 'That URL is already in use.' in res, res
        self._assert_form_errors(res)

    def test_new_plugin_hook(self):
        plugins.load('test_package_controller_plugin')
        plugin = plugins.get_plugin('test_package_controller_plugin')
        offset = url_for(controller='package', action='new')
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)
        new_name = u'plugged'
        fv = res.forms['dataset-edit']
        prefix = ''
        fv[prefix + 'name'] = new_name
        res = fv.submit('save', extra_environ=self.extra_environ_tester)
        # get redirected ...
        assert plugin.calls['edit'] == 0, plugin.calls
        assert plugin.calls['create'] == 1, plugin.calls
        plugins.unload('test_package_controller_plugin')

    def test_after_create_plugin_hook(self):
        plugins.load('test_package_controller_plugin')
        plugin = plugins.get_plugin('test_package_controller_plugin')
        offset = url_for(controller='package', action='new')
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)
        new_name = u'plugged2'
        fv = res.forms['dataset-edit']
        prefix = ''
        fv[prefix + 'name'] = new_name
        res = fv.submit('save', extra_environ=self.extra_environ_tester)
        # get redirected ...
        assert plugin.calls['after_update'] == 0, plugin.calls
        assert plugin.calls['after_create'] == 1, plugin.calls

        assert plugin.id_in_dict
        plugins.unload('test_package_controller_plugin')

    def test_new_indexerror(self):
        bad_solr_url = 'http://127.0.0.1/badsolrurl'
        solr_url = SolrSettings.get()[0]
        try:
            SolrSettings.init(bad_solr_url)
            new_package_name = u'new-package-missing-solr'

            offset = url_for(controller='package', action='new')
            res = self.app.get(offset, extra_environ=self.extra_environ_tester)
            fv = res.forms['dataset-edit']
            fv['name'] = new_package_name

            # this package shouldn't actually be created but
            # add it to the list to purge just in case
            self.pkg_names.append(new_package_name)

            res = fv.submit('save', status=500, extra_environ=self.extra_environ_tester)
            assert 'Unable to add package to search index' in res, res
        finally:
            SolrSettings.init(solr_url)

    def test_change_locale(self):
        offset = url_for(controller='package', action='new')
        res = self.app.get(offset, extra_environ=self.extra_environ_tester)

        res = self.app.get('/de/dataset/new', extra_environ=self.extra_environ_tester)
        try:
            assert 'Datensatz' in res.body, res.body
        finally:
            self.clear_language_setting()

class TestSearch(TestPackageForm):
    pkg_names = []

    @classmethod
    def setup_class(self):
        model.repo.init_db()

    @classmethod
    def teardown_class(self):
        self.purge_packages(self.pkg_names)
        model.repo.rebuild_db()

    def test_search_plugin_hooks(self):
        plugins.load('test_package_controller_plugin')
        plugin = plugins.get_plugin('test_package_controller_plugin')
        offset = url_for(controller='package', action='search')
        res = self.app.get(offset)
        # get redirected ...
        assert plugin.calls['before_search'] == 1, plugin.calls
        assert plugin.calls['after_search'] == 1, plugin.calls
        plugins.unload('test_package_controller_plugin')

class TestNewPreview(TestPackageBase):
    pkgname = u'testpkg'
    pkgtitle = u'mytesttitle'

    @classmethod
    def setup_class(self):
        pass
        model.repo.init_db()

    @classmethod
    def teardown_class(self):
        self.purge_packages([self.pkgname])
        model.repo.rebuild_db()

class TestNonActivePackages(TestPackageBase):

    @classmethod
    def setup_class(self):
        CreateTestData.create()
        self.non_active_name = u'test_nonactive'
        pkg = model.Package(name=self.non_active_name)
        model.repo.new_revision()
        model.Session.add(pkg)
        model.repo.commit_and_remove()

        pkg = model.Session.query(model.Package).filter_by(name=self.non_active_name).one()
        admin = model.User.by_name(u'joeadmin')
        model.setup_default_user_roles(pkg, [admin])
        model.repo.commit_and_remove()

        model.repo.new_revision()
        pkg = model.Session.query(model.Package).filter_by(name=self.non_active_name).one()
        pkg.delete() # becomes non active
        model.repo.commit_and_remove()


    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_read(self):
        offset = url_for(controller='package', action='read', id=self.non_active_name)
        res = self.app.get(offset, status=[302, 401])


    def test_read_as_admin(self):
        offset = url_for(controller='package', action='read', id=self.non_active_name)
        res = self.app.get(offset, status=200, extra_environ={'REMOTE_USER':'testsysadmin'})


class TestRevisions(TestPackageBase):
    @classmethod
    def setup_class(cls):
        model.Session.remove()
        model.repo.init_db()
        cls.name = u'revisiontest1'

        # create pkg
        cls.notes = [u'Written by Puccini', u'Written by Rossini', u'Not written at all', u'Written again', u'Written off']
        rev = model.repo.new_revision()
        cls.pkg1 = model.Package(name=cls.name)
        cls.pkg1.notes = cls.notes[0]
        model.Session.add(cls.pkg1)
        model.setup_default_user_roles(cls.pkg1)
        model.repo.commit_and_remove()

        # edit pkg
        for i in range(5)[1:]:
            rev = model.repo.new_revision()
            pkg1 = model.Package.by_name(cls.name)
            pkg1.notes = cls.notes[i]
            model.repo.commit_and_remove()

        cls.pkg1 = model.Package.by_name(cls.name)
        cls.revision_ids = [rev[0].id for rev in cls.pkg1.all_related_revisions]
                           # revision ids are newest first
        cls.revision_timestamps = [rev[0].timestamp for rev in cls.pkg1.all_related_revisions]
        cls.offset = url_for(controller='package', action='history', id=cls.pkg1.name)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_0_read_history(self):
        res = self.app.get(self.offset)
        main_res = self.main_div(res)
        assert self.pkg1.name in main_res, main_res
        assert 'radio' in main_res, main_res
        latest_rev = self.pkg1.all_revisions[0]
        oldest_rev = self.pkg1.all_revisions[-1]
        first_radio_checked_html = '<input checked="checked" id="selected1_%s"' % latest_rev.revision_id
        assert first_radio_checked_html in main_res, '%s %s' % (first_radio_checked_html, main_res)
        last_radio_checked_html = '<input checked="checked" id="selected2_%s"' % oldest_rev.revision_id
        assert last_radio_checked_html in main_res, '%s %s' % (last_radio_checked_html, main_res)

    def test_1_do_diff(self):
        res = self.app.get(self.offset)
        form = res.forms['dataset-revisions']
        res = form.submit()
        res = res.follow()
        main_res = self.main_div(res)
        assert 'form-errors' not in main_res.lower(), main_res
        assert 'Revision Differences' in main_res, main_res
        assert self.pkg1.name in main_res, main_res
        assert '<tr><td>notes</td><td><pre>- Written by Puccini\n+ Written off</pre></td></tr>' in main_res, main_res

    def test_2_atom_feed(self):
        offset = "%s?format=atom" % self.offset
        res = self.app.get(offset)
        assert '<feed' in res, res
        assert 'xmlns="http://www.w3.org/2005/Atom"' in res, res
        assert '</feed>' in res, res

    def test_3_history_revision_link(self):
        res = self.app.get(self.offset)
        res = res.click('%s' % self.revision_ids[2][:4])
        main_res = self.main_div(res)
        assert 'Revision: %s' % self.revision_ids[2] in main_res

    def test_4_history_revision_package_link(self):
        res = self.app.get(self.offset)
        url = str(self.revision_timestamps[1])[-6:]
        res = res.click(href=url)
        main_html = self.main_div(res)
        assert 'This is an old revision of this dataset' in main_html


class TestMarkdownHtmlWhitelist(TestPackageForm):

    pkg_name = u'markdownhtmlwhitelisttest'
    pkg_notes = u'''
<table width="100%" border="1">
<tr>
<td rowspan="2"><b>Description</b></td>
<td rowspan="2"><b>Documentation</b></td>

<td colspan="2"><b><center>Data -- Pkzipped</center></b> </td>
</tr>
<tr>
<td><b>SAS .tpt</b></td>
<td><b>ASCII CSV</b> </td>
</tr>
<tr>
<td><b>Overview</b></td>
<td><A HREF="http://www.nber.org/patents/subcategories.txt">subcategory.txt</A></td>
<td colspan="2"><center>--</center></td>
</tr>
<script><!--
alert('Hello world!');
//-->
</script>

'''

    def setup(self):
        model.Session.remove()
        model.repo.init_db()
        rev = model.repo.new_revision()
        CreateTestData.create_arbitrary(
            {'name':self.pkg_name,
             'notes':self.pkg_notes,
             'admins':[u'testadmin']}
            )
        self.pkg = model.Package.by_name(self.pkg_name)
        self.pkg_id = self.pkg.id

        offset = url_for(controller='package', action='read', id=self.pkg_name)
        self.res = self.app.get(offset)

    def teardown(self):
        model.repo.rebuild_db()

    def test_markdown_html_whitelist(self):
        self.body = str(self.res)
        self.fail_if_fragment('<table width="100%" border="1">')
        self.fail_if_fragment('<td rowspan="2"><b>Description</b></td>')
        self.fail_if_fragment('<a href="http://www.nber.org/patents/subcategories.txt" target="_blank" rel="nofollow">subcategory.txt</a>')
        self.fail_if_fragment('<td colspan="2"><center>--</center></td>')
        self.fail_if_fragment('<script>')

    def assert_fragment(self, fragment):
        assert fragment in self.body, (fragment, self.body)

    def fail_if_fragment(self, fragment):
        assert fragment not in self.body, (fragment, self.body)

class TestAutocomplete(PylonsTestCase, TestPackageBase):
    @classmethod
    def setup_class(cls):
        PylonsTestCase.setup_class()
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_package_autocomplete(self):
        query = 'a'
        res = self.app.get('/dataset/autocomplete?q=%s' % query)

        expected = ['A Wonderful Story (warandpeace)|warandpeace','annakarenina|annakarenina']
        received = sorted(res.body.split('\n'))
        assert expected == received

class TestResourceListing(TestPackageBase):
    @classmethod
    def setup_class(cls):

        CreateTestData.create()
        cls.tester_user = model.User.by_name(u'tester')
        cls.extra_environ_admin = {'REMOTE_USER': 'testsysadmin'}
        cls.extra_environ_tester = {'REMOTE_USER': 'tester'}
        cls.extra_environ_someone_else = {'REMOTE_USER': 'someone_else'}

        tests.call_action_api(cls.app, 'organization_create',
                                        name='test_org_2',
                                        apikey=cls.tester_user.apikey)

        tests.call_action_api(cls.app, 'package_create',
                                        name='crimeandpunishment',
                                        owner_org='test_org_2',
                                        apikey=cls.tester_user.apikey)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_resource_listing_premissions_sysadmin(self):
        # sysadmin 200
         self.app.get('/dataset/resources/crimeandpunishment', extra_environ=self.extra_environ_admin, status=200)

    def test_resource_listing_premissions_auth_user(self):
        # auth user 200
         self.app.get('/dataset/resources/crimeandpunishment', extra_environ=self.extra_environ_tester, status=200)

    def test_resource_listing_premissions_non_auth_user(self):
        # non auth user 401
         self.app.get('/dataset/resources/crimeandpunishment', extra_environ=self.extra_environ_someone_else, status=[302,401])

    def test_resource_listing_premissions_not_logged_in(self):
        # not logged in 401
         self.app.get('/dataset/resources/crimeandpunishment', status=[302,401])


########NEW FILE########
__FILENAME__ = test_package_relationships
from ckan.tests import *
import ckan.model as model
from ckan.lib.create_test_data import CreateTestData
from base import FunctionalTestCase

class TestRelationships(FunctionalTestCase):
    @classmethod
    def setup_class(self):
        create = CreateTestData
        create.create_family_test_data()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_read_package(self):
        def read_package(pkg_name):
            offset = url_for(controller='package', action='read', id=pkg_name)
            res = self.app.get(offset)
            pkg = model.Package.by_name(pkg_name)
            assert '%s - Datasets' % pkg.title in res
            return res
        res = read_package(u'homer')
        self.check_named_element(res, 'li', 'is a child of', 'abraham')
        self.check_named_element(res, 'li', 'is a child of', '<a href="/dataset/abraham">abraham</a>')
        self.check_named_element(res, 'li', 'is a parent of', 'bart')
        self.check_named_element(res, 'li', 'is a parent of', 'lisa')
        self.check_named_element(res, 'li', 'has derivation', 'homer_derived')
        self.check_named_element(res, 'li', 'depends on', 'beer')
        
        res = read_package(u'bart')
        self.check_named_element(res, 'li', 'has sibling', 'lisa')
        self.check_named_element(res, 'li', 'is a child of', 'homer')

        res = read_package(u'lisa')
        self.check_named_element(res, 'li', 'has sibling', 'bart')

########NEW FILE########
__FILENAME__ = test_pagination
import re

from nose.tools import assert_equal

from ckan.lib.create_test_data import CreateTestData
import ckan.model as model
from ckan.tests import TestController, url_for, setup_test_search_index

def scrape_search_results(response, object_type):
    assert object_type in ('dataset', 'group_dataset', 'group', 'user')
    if object_type is not 'group_dataset':
        results = re.findall('href="/%s/%s_(\d\d)"' % (object_type, object_type),
                             str(response))
    else:
        object_type = 'dataset'
        results = re.findall('href="/%s/%s_(\d\d)"' % (object_type, object_type),
                             str(response))
    return results

def test_scrape_user():
    html = '''
          <li class="username">
          <img src="//gravatar.com/avatar/d41d8cd98f00b204e9800998ecf8427e?s=16&amp;d=http://test.ckan.net/images/icons/user.png" /> <a href="/user/user_00">user_00</a>
          </li>
          ...
          <li class="username">
          <img src="//gravatar.com/avatar/d41d8cd98f00b204e9800998ecf8427e?s=16&amp;d=http://test.ckan.net/images/icons/user.png" /> <a href="/user/user_01">user_01</a>
          </li>

      '''
    res = scrape_search_results(html, 'user')
    assert_equal(res, ['00', '01'])


class TestPaginationPackage(TestController):
    @classmethod
    def setup_class(cls):
        setup_test_search_index()
        model.repo.init_db()

        # no. entities per page is hardcoded into the controllers, so
        # create enough of each here so that we can test pagination
        cls.num_packages_in_large_group = 51

        packages = []
        for i in range(cls.num_packages_in_large_group):
            packages.append({
                # CS: nasty_string ignore
                'name': u'dataset_%s' % str(i).zfill(2),
                'groups': u'group_00'
            })

        CreateTestData.create_arbitrary(packages)

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_package_search_p1(self):
        res = self.app.get(url_for(controller='package', action='search', q='groups:group_00'))
        assert 'href="/dataset?q=groups%3Agroup_00&amp;page=2"' in res
        pkg_numbers = scrape_search_results(res, 'dataset')
        assert_equal(['50', '49', '48', '47', '46', '45', '44', '43', '42', '41', '40', '39', '38', '37', '36', '35', '34', '33', '32', '31'], pkg_numbers)

    def test_package_search_p2(self):
        res = self.app.get(url_for(controller='package', action='search', q='groups:group_00', page=2))
        assert 'href="/dataset?q=groups%3Agroup_00&amp;page=1"' in res
        pkg_numbers = scrape_search_results(res, 'dataset')
        assert_equal(['30', '29', '28', '27', '26', '25', '24', '23', '22', '21', '20', '19', '18', '17', '16', '15', '14', '13', '12', '11'], pkg_numbers)

    def test_group_datasets_read_p1(self):
        res = self.app.get(url_for(controller='group', action='read', id='group_00'))
        assert 'href="/group/group_00?page=2' in res, res
        pkg_numbers = scrape_search_results(res, 'group_dataset')
        assert_equal(['50', '49', '48', '47', '46', '45', '44', '43', '42', '41', '40', '39', '38', '37', '36', '35', '34', '33', '32', '31'], pkg_numbers)

    def test_group_datasets_read_p2(self):
        res = self.app.get(url_for(controller='group', action='read', id='group_00', page=2))
        assert 'href="/group/group_00?page=1' in res, res
        pkg_numbers = scrape_search_results(res, 'group_dataset')
        assert_equal(['30', '29', '28', '27', '26', '25', '24', '23', '22', '21', '20', '19', '18', '17', '16', '15', '14', '13', '12', '11'], pkg_numbers)

class TestPaginationGroup(TestController):
    @classmethod
    def setup_class(cls):
        # no. entities per page is hardcoded into the controllers, so
        # create enough of each here so that we can test pagination
        cls.num_groups = 22

        # CS: nasty_string ignore
        groups = [u'group_%s' % str(i).zfill(2) for i in range(0, cls.num_groups)]

        CreateTestData.create_arbitrary(
            [], extra_group_names=groups
        )

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_group_index(self):
        res = self.app.get(url_for(controller='group', action='index'))
        assert 'href="/group?page=2"' in res, res
        grp_numbers = scrape_search_results(res, 'group')
        assert_equal(['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20'], grp_numbers)

        res = self.app.get(url_for(controller='group', action='index', page=2))
        assert 'href="/group?page=1"' in res
        grp_numbers = scrape_search_results(res, 'group')
        assert_equal(['21'], grp_numbers)

class TestPaginationUsers(TestController):
    @classmethod
    def setup_class(cls):
        # Delete default user as it appears in the first page of results
        model.User.by_name(u'logged_in').purge()
        model.repo.commit_and_remove()

        # no. entities per page is hardcoded into the controllers, so
        # create enough of each here so that we can test pagination
        cls.num_users = 21

        # CS: nasty_string ignore
        users = [u'user_%s' % str(i).zfill(2) for i in range(cls.num_users)]

        CreateTestData.create_arbitrary(
            [], extra_user_names = users,
        )

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_users_index(self):
        # allow for 2 extra users shown on user listing, 'logged_in' and 'visitor'
        res = self.app.get(url_for(controller='user', action='index'))
        assert 'href="/user?q=&amp;order_by=name&amp;page=2"' in res
        user_numbers = scrape_search_results(res, 'user')
        assert_equal(['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19'], user_numbers)

        res = self.app.get(url_for(controller='user', action='index', page=2))
        assert 'href="/user?q=&amp;order_by=name&amp;page=1"' in res
        user_numbers = scrape_search_results(res, 'user')
        assert_equal(['20'], user_numbers)


########NEW FILE########
__FILENAME__ = test_preview_interface
# -*- coding: UTF-8 -*-

import ckan.lib.helpers as h
import ckan.logic as l
import ckan.model as model
import ckan.lib.create_test_data as create_test_data
import ckan.tests.functional.base as base
import ckan.plugins as plugins
import ckan.lib.dictization.model_dictize as model_dictize


class TestPluggablePreviews(base.FunctionalTestCase):
    @classmethod
    def setup_class(cls):
        plugins.load('test_resource_preview', 'test_json_resource_preview')
        cls.plugin = plugins.get_plugin('test_resource_preview')

        create_test_data.CreateTestData.create()

        cls.package = model.Package.get('annakarenina')
        cls.resource = cls.package.resources[0]
        cls.url = h.url_for(controller='package',
            action='resource_read',
            id=cls.package.name,
            resource_id=cls.resource.id)
        cls.preview_url = h.url_for(controller='package',
            action='resource_datapreview',
            id=cls.package.id,
            resource_id=cls.resource.id)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        plugins.unload('test_resource_preview', 'test_json_resource_preview')

    def test_hook(self):
        testpackage = self.package
        resource_dict = model_dictize.resource_dictize(self.resource, {'model': model})

        context = {
            'model': model,
            'session': model.Session,
            'user': model.User.get('testsysadmin').name
        }

        # no preview for type "plain text"
        preview_url = self.preview_url
        result = self.app.get(preview_url, status=409)
        assert 'No preview' in result.body, result.body

        # no preview for type "ümlaut", should not fail
        resource_dict['format'] = u'ümlaut'
        l.action.update.resource_update(context, resource_dict)

        result = self.app.get(preview_url, status=409)
        assert 'No preview' in result.body, result.body

        resource_dict['format'] = 'mock'
        l.action.update.resource_update(context, resource_dict)

        #there should be a preview for type "json"
        preview_url = self.preview_url
        result = self.app.get(preview_url, status=200)

        assert 'mock-preview' in result.body
        assert 'mock-preview.js' in result.body

        assert self.plugin.calls['can_preview'] == 3, self.plugin.calls
        assert self.plugin.calls['setup_template_variables'] == 1, self.plugin.calls
        assert self.plugin.calls['preview_templates'] == 1, self.plugin.calls

        # test whether the json preview is used
        preview_url = h.url_for(controller='package',
                action='resource_datapreview',
                id=testpackage.id,
                resource_id=testpackage.resources[1].id)
        result = self.app.get(preview_url, status=200)

        assert 'mock-json-preview' in result.body
        assert 'mock-json-preview.js' in result.body

        assert self.plugin.calls['can_preview'] == 4, self.plugin.calls
        assert self.plugin.calls['setup_template_variables'] == 1, self.plugin.calls
        assert self.plugin.calls['preview_templates'] == 1, self.plugin.calls

    def test_iframe_is_shown(self):
        result = self.app.get(self.url)
        assert 'data-module="data-viewer"' in result.body, result.body
        assert '<iframe' in result.body, result.body

    def test_iframe_url_is_correct(self):
        result = self.app.get(self.url)
        assert self.preview_url in result.body, (self.preview_url, result.body)

########NEW FILE########
__FILENAME__ = test_related
import json

from nose.tools import assert_equal, assert_raises

import ckan.tests as tests
import ckan.model as model
import ckan.logic as logic
import ckan.lib.helpers as h
import ckan.tests.functional.base as base
import ckan.tests.functional.api.base as apibase


class TestRelatedUI(base.FunctionalTestCase):
    @classmethod
    def setup_class(self):
        model.Session.remove()
        tests.CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_related_new(self):
        offset = h.url_for(controller='related',
                           action='new', id='warandpeace')
        res = self.app.get(offset, status=200,
                           extra_environ={"REMOTE_USER": "testsysadmin"})
        assert 'URL' in res, "URL missing in response text"
        assert 'Title' in res, "Title missing in response text"

        data = {
            "title": "testing_create",
            "url": u"http://ckan.org/feed/",
        }
        res = self.app.post(offset, params=data,
                            status=[200,302],
                            extra_environ={"REMOTE_USER": "testsysadmin"})

    def test_related_new_missing(self):
        offset = h.url_for(controller='related',
                           action='new', id='non-existent dataset')
        res = self.app.get(offset, status=404,
                           extra_environ={"REMOTE_USER": "testsysadmin"})

    def test_related_new_fail(self):
        offset = h.url_for(controller='related',
                           action='new', id='warandpeace')
        print '@@@@', offset
        res = self.app.get(offset, status=200,
                           extra_environ={"REMOTE_USER": "testsysadmin"})
        assert 'URL' in res, "URL missing in response text"
        assert 'Title' in res, "Title missing in response text"

        data = {
            "title": "testing_create",
        }
        res = self.app.post(offset, params=data,
                            status=[200,302],
                            extra_environ={"REMOTE_USER": "testsysadmin"})
        assert 'error' in res, res



class TestRelated:

    @classmethod
    def setup_class(self):
        model.Session.remove()
        tests.CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_create(self):
        p = model.Package.get('warandpeace')
        r = model.Related()
        p.related.append(r)

        assert len(p.related) == 1, p.related
        assert len(r.datasets) == 1, r.datasets

        model.Session.add(p)
        model.Session.add(r)
        model.Session.commit()

        # To get the RelatedDataset objects (for state change)
        assert p.related_count == 1, p.related_count
        assert len(model.Related.get_for_dataset(p)) == 1
        assert len(model.Related.get_for_dataset(p,status='inactive')) == 0
        p.related.remove(r)
        model.Session.delete(r)
        model.Session.commit()

        assert len(p.related) == 0
        assert p.related_count == 0, p.related_count


    def test_inactive_related(self):
        p = model.Package.get('warandpeace')
        r = model.Related()
        p.related.append(r)
        assert len(p.related) == 1, p.related
        model.Session.add(r)
        model.Session.commit()

        # To get the RelatedDataset objects (for state change)
        assert p.related_count == 1, p.related_count
        assert len(model.Related.get_for_dataset(p,status='active')) == 1
        assert len(model.Related.get_for_dataset(p,status='inactive')) == 0
        r.deactivate( p )
        r.deactivate( p ) # Does nothing.
        model.Session.refresh(p)
        assert p.related_count == 0, p.related_count
        assert len(model.Related.get_for_dataset(p,status='active')) == 0
        assert len(model.Related.get_for_dataset(p,status='inactive')) == 1

        model.Session.refresh(p) # Would like to get rid of the need for this
        assert len(p.related) == 0, p.related # not sure inactive item ...
        model.Session.delete(r)


    def _related_create(self, title, description, type, url, image_url):
        usr = logic.get_action('get_site_user')({'model':model,'ignore_auth': True},{})

        context = dict(model=model, user=usr['name'], session=model.Session)
        data_dict = dict(title=title,description=description,
                         url=url,image_url=image_url,type=type)
        return logic.get_action("related_create")( context, data_dict )

    def test_related_create(self):
        rel = self._related_create("Title", "Description",
                        "visualization",
                        "http://ckan.org",
                        "http://ckan.org/files/2012/03/ckanlogored.png")
        assert rel['title'] == "Title", rel
        assert rel['description'] == "Description", rel
        assert rel['type'] == "visualization", rel
        assert rel['url'] == "http://ckan.org", rel
        assert rel['image_url'] == "http://ckan.org/files/2012/03/ckanlogored.png", rel

    def test_related_create_fail(self):
        try:
            rel = self._related_create("Title", "Description",
                        None,
                        "http://ckan.org",
                        "http://ckan.org/files/2012/03/ckanlogored.png")
            assert False, "Create succeeded with missing field"
        except logic.ValidationError, e:
            assert 'type' in e.error_dict and e.error_dict['type'] == [u'Missing value']

    def test_related_create_featured_as_sysadmin(self):
        '''Sysadmin can create featured related items'''
        usr = logic.get_action('get_site_user')({'model':model,'ignore_auth': True},{})

        context = {
            'model': model,
            'user': usr['name'],
            'session': model.Session
        }

        data_dict = {
            'title': 'Title',
            'description': 'Description',
            'type': 'visualization',
            'url': 'http://ckan.org',
            'image_url': 'http://ckan.org/files/2012/03/ckanlogored.png',
            'featured': 1,
        }

        result = logic.get_action("related_create")(context, data_dict)

        assert_equal(result['featured'], 1)

    def test_related_create_featured_as_non_sysadmin_fails(self):
        '''Non-sysadmin users should not be able to create featured relateds'''

        context = {
            'model': model,
            'user': 'annafan',
            'session': model.Session
        }

        data_dict = {
            'title': 'Title',
            'description': 'Description',
            'type': 'visualization',
            'url': 'http://ckan.org',
            'image_url': 'http://ckan.org/files/2012/03/ckanlogored.png',
            'featured': 1,
        }

        assert_raises(
            logic.NotAuthorized,
            logic.get_action('related_create'),
            context,
            data_dict)

    def test_related_create_not_featured_as_non_sysadmin_succeeds(self):
        '''Non-sysadmins can set featured to false'''

        context = {
            'model': model,
            'user': 'annafan',
            'session': model.Session
        }

        data_dict = {
            'title': 'Title',
            'description': 'Description',
            'type': 'visualization',
            'url': 'http://ckan.org',
            'image_url': 'http://ckan.org/files/2012/03/ckanlogored.png',
            'featured': 0,
        }

        result = logic.get_action("related_create")(context, data_dict)

        assert_equal(result['featured'], 0)

    def test_related_create_featured_empty_as_non_sysadmin_succeeds(self):
        '''Non-sysadmins can leave featured empty.'''

        context = {
            'model': model,
            'user': 'annafan',
            'session': model.Session
        }

        data_dict = {
            'title': 'Title',
            'description': 'Description',
            'type': 'visualization',
            'url': 'http://ckan.org',
            'image_url': 'http://ckan.org/files/2012/03/ckanlogored.png',
        }

        result = logic.get_action("related_create")(context, data_dict)

        assert_equal(result['featured'], 0)

    def test_related_delete(self):
        rel = self._related_create("Title", "Description",
                        "visualization",
                        "http://ckan.org",
                        "http://ckan.org/files/2012/03/ckanlogored.png")
        usr = logic.get_action('get_site_user')({'model':model,'ignore_auth': True},{})
        context = dict(model=model, user=usr['name'], session=model.Session)
        data_dict = dict(id=rel['id'])
        logic.get_action('related_delete')(context, data_dict)

        r = model.Related.get(rel['id'])
        assert r is None, r # Ensure it doesn't exist

    def test_related_update(self):
        rel = self._related_create("Title", "Description",
                        "visualization",
                        "http://ckan.org",
                        "http://ckan.org/files/2012/03/ckanlogored.png")

        usr = logic.get_action('get_site_user')({'model':model,'ignore_auth': True},{})
        context = dict(model=model, user=usr['name'], session=model.Session)
        data_dict = rel
        data_dict['title'] = "New Title"
        result = logic.get_action('related_update')(context,data_dict)
        assert result['title'] == 'New Title'

    def test_sysadmin_changes_related_items_featured_field(self):
        '''Sysadmins can change featured field'''
        rel = self._related_create(
            "Title",
            "Description",
            "visualization",
            "http://ckan.org",
            "http://ckan.org/files/2012/03/ckanlogored.png")

        usr = logic.get_action('get_site_user')({'model':model,'ignore_auth': True},{})
        context = {
            'model': model,
            'user': usr['name'],
            'session': model.Session
        }

        data_dict = rel
        data_dict['title'] = "New Title"
        data_dict['featured'] = 1
        result = logic.get_action('related_update')(context,data_dict)
        assert_equal(result['title'], 'New Title')
        assert_equal(result['featured'], 1)

    def test_non_sysadmin_changes_related_items_featured_field_fails(self):
        '''Non-sysadmins cannot change featured field'''

        context = {
            'model': model,
            'user': 'annafan',
            'session': model.Session
        }

        data_dict = {
            'title': 'Title',
            'description': 'Description',
            'type': 'visualization',
            'url': 'http://ckan.org',
            'image_url': 'http://ckan.org/files/2012/03/ckanlogored.png',
        }

        # Create the related item as annafan
        result = logic.get_action('related_create')(context, data_dict)

        # Try to change it to a featured item
        result['featured'] = 1

        try:
            logic.get_action('related_update')(context, result)
        except logic.NotAuthorized, e:
            # Check it's the correct authorization error
            assert 'featured' in str(e)

    def test_non_sysadmin_can_update_related_item(self):
        '''Non-sysadmins can change related item.

        If they don't change the featured field.
        '''

        context = {
            'model': model,
            'user': 'annafan',
            'session': model.Session
        }

        data_dict = {
            'title': 'Title',
            'description': 'Description',
            'type': 'visualization',
            'url': 'http://ckan.org',
            'image_url': 'http://ckan.org/files/2012/03/ckanlogored.png',
        }

        # Create the related item as annafan
        result = logic.get_action('related_create')(context, data_dict)

        # Try to change it to a featured item
        result['title'] = 'New Title'

        result = logic.get_action('related_update')(context, result)
        assert_equal(result['title'], 'New Title')

    def test_related_show(self):
        rel = self._related_create("Title", "Description",
                        "visualization",
                        "http://ckan.org",
                        "http://ckan.org/files/2012/03/ckanlogored.png")

        usr = logic.get_action('get_site_user')({'model':model,'ignore_auth': True},{})
        context = dict(model=model, user=usr['name'], session=model.Session)
        data_dict = {'id': rel['id']}

        result = logic.get_action('related_show')(context,data_dict)
        assert rel['id'] == result['id'], result
        assert rel['title'] == result['title'], result
        assert rel['description'] == result['description'], result
        assert rel['description'] == result['description'], result

    def test_related_list_missing_id_and_name(self):
        p = model.Package.get('warandpeace')
        usr = logic.get_action('get_site_user')({'model':model,'ignore_auth': True},{})
        context = dict(model=model, user=usr['name'], session=model.Session)
        data_dict = {}
        related_list = logic.get_action('related_list')(context, data_dict)
        assert len(related_list) == 8
        related_keys = set(['view_count', 'description', 'title', 'url',
            'created', 'featured', 'image_url', 'type', 'id', 'owner_id'])
        for related in related_list:
            assert set(related.keys()) == related_keys


    def test_related_list(self):
        p = model.Package.get('warandpeace')
        r = model.Related(title="Title", type="idea")
        p.related.append(r)
        r = model.Related(title="Title 2", type="idea")
        p.related.append(r)
        model.Session.add(r)
        model.Session.commit()

        assert len(p.related) == 2
        assert p.related_count == 2, p.related_count

        usr = logic.get_action('get_site_user')({'model':model,'ignore_auth': True},{})
        context = dict(model=model, user=usr['name'], session=model.Session)
        data_dict = {'id': p.id}

        result = logic.get_action('related_list')(context,data_dict)
        assert len(result) == len(p.related)

class TestRelatedActionAPI(apibase.BaseModelApiTestCase):

    @classmethod
    def setup_class(cls):
        model.Session.remove()
        tests.CreateTestData.create()
        cls.user_name = u'russianfan' # created in CreateTestData
        cls.init_extra_environ(cls.user_name)

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_api_create_invalid(self):
        res = self.app.post("/api/3/action/related_create", params="{}=1",
                            status=self.STATUS_409_CONFLICT,
                            extra_environ=self.extra_environ)
        r = json.loads(res.body)
        assert r['success'] == False, r


    def _create(self, rtype="visualization", title="Test related item"):
        r = {
            "type": rtype,
            "title": title
        }
        postparams = '%s=1' % json.dumps(r)
        res = self.app.post("/api/3/action/related_create", params=postparams,
                            status=self.STATUS_200_OK,
                            extra_environ=self.extra_environ)
        r = json.loads(res.body)
        return r

    def test_api_create_valid(self):
        r = self._create()
        assert r['success'] == True, r
        assert r['result']['type'] == "visualization"
        assert r['result']['title'] == "Test related item"

    def test_api_show(self):
        existing = self._create()

        r = {
            "id": existing["result"]["id"]
        }
        postparams = '%s=1' % json.dumps(r)
        res = self.app.post("/api/3/action/related_show", params=postparams,
                            status=self.STATUS_200_OK,
                            extra_environ=self.extra_environ)
        r = json.loads(res.body)
        assert r['success'] == True, r
        assert r['result']['type'] == "visualization"
        assert r['result']['title'] == "Test related item"


    def test_api_list(self):
        p = model.Package.get('warandpeace')
        one = model.Related(type="idea", title="one")
        two = model.Related(type="idea", title="two")
        p.related.append(one)
        p.related.append(two)
        model.Session.commit()

        r = {
            "id": p.id
        }
        postparams = '%s=1' % json.dumps(r)
        res = self.app.post("/api/3/action/related_list", params=postparams,
                            status=self.STATUS_200_OK,
                            extra_environ=self.extra_environ)
        r = json.loads(res.body)
        assert r['success'] == True, r
        assert r['result'][0]['type'] == "idea"
        assert r['result'][0]['title'] == "two", r

        p.related.remove(one)
        p.related.remove(two)
        model.Session.delete(one)
        model.Session.delete(two)

    def test_api_delete(self):
        existing = self._create()

        r = {
            "id": existing["result"]["id"]
        }
        postparams = '%s=1' % json.dumps(r)
        res = self.app.post("/api/3/action/related_delete", params=postparams,
                            status=self.STATUS_200_OK,
                            extra_environ=self.extra_environ)
        r = json.loads(res.body)
        assert r['success'] == True, r
        assert r['result'] is None, r

    def test_api_delete_fail(self):
        existing = self._create()
        r = {
            "id": existing["result"]["id"]
        }

        usr = model.User.by_name("annafan")
        extra={'Authorization' : str(usr.apikey)}

        postparams = '%s=1' % json.dumps(r)
        res = self.app.post("/api/3/action/related_delete", params=postparams,
                            status=self.STATUS_403_ACCESS_DENIED,
                            extra_environ=extra)
        r = json.loads(res.body)
        assert r['success'] == False, r
        assert r[u'error'][u'__type'] == "Authorization Error", r

########NEW FILE########
__FILENAME__ = test_revision
from ckan.tests import search_related, TestController, CreateTestData, url_for
import ckan.model as model

# TODO: purge revisions after creating them
class TestRevisionController(TestController):

    @classmethod
    def setup_class(self):
        model.Session.remove()
        # rebuild db before this test as it depends delicately on what
        # revisions exist
        model.repo.init_db()
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def create_40_revisions(self):
        for i in range(0,40):
            rev = model.repo.new_revision()
            rev.author = "Test Revision %s" % i
            model.repo.commit()

    def test_paginated_list(self):
        # Ugh. Why is the number of items per page hard-coded? A designer might
        # decide that 20 is the right number of revisions to display per page,
        # (in fact I did) but would be forced to stick to 50 because changing
        # this test is so laborious.
        #
        # TODO: do we even need to test pagination in such excruciating detail
        # every time we use it? It's the same (hard-coded) test code N times over.
        #
        # </rant> -- NS 2009-12-17

        self.create_40_revisions()
        revisions = model.repo.history().all()
        revision1 = revisions[0]
        revision2 = revisions[20]
        revision3 = revisions[40]
        revision4 = revisions[-1]
        # Revisions are most recent first, with first rev on last page.
        # Todo: Look at the model to see which revision is last.
        # Todo: Test for last revision on first page.
        # Todo: Test for first revision on last page.
        # Todo: Test for last revision minus 50 on second page.
        # Page 1.   (Implied id=1)
        offset = url_for(controller='revision', action='list')
        res = self.app.get(offset)
        self.assert_click(res, revision1.id, 'Revision: %s' % revision1.id)

        # Page 1.
        res = self.app.get(offset, params={'page':1})
        self.assert_click(res, revision1.id, 'Revision: %s' % revision1.id)

        # Page 2.
        res = self.app.get(offset, params={'page':2})
        self.assert_click(res, revision2.id, 'Revision: %s' % revision2.id)

        # Page 3.
        res = self.app.get(offset, params={'page':3})
        self.assert_click(res, revision3.id, 'Revision: %s' % revision3.id)

        # Last page.
        last_id = 1 + len(revisions) / 20
        res = self.app.get(offset, params={'page':last_id})

        assert 'Revision History' in res
        assert '1' in res
        assert 'Author' in res
        assert 'tester' in res
        assert 'Log Message' in res
        assert 'Creating test data.' in res


    def assert_click(self, res, link_exp, res2_exp):
        try:
            # paginate links are also just numbers
            # res2 = res.click('^%s$' % link_exp)
            res2 = res.click(link_exp)
        except:
            print "\nThe first response (list):\n\n"
            print str(res)
            print "\nThe link that couldn't be followed:"
            print str(link_exp)
            raise
        try:
            assert res2_exp in res2
        except:
            print "\nThe first response (list):\n\n"
            print str(res)
            print "\nThe second response (item):\n\n"
            print str(res2)
            print "\nThe followed link:"
            print str(link_exp)
            print "\nThe expression that couldn't be found:"
            print str(res2_exp)
            raise

    def create_updating_revision(self, name, **kwds):
        rev = model.repo.new_revision()
        rev.author = "Test Revision Updating"
        package = self.get_package(name)
        if 'resources' in kwds:
            resources = kwds.pop('resources')
            for resource in package.resource_groups_all[0].resources_all:
                resource.state = 'deleted'
            for resource in resources:
                resource = model.Resource(**resource)
                model.Session.add(resource)
                package.resource_groups_all[0].resources_all.append(resource)
        if 'extras' in kwds:
            extras_data = kwds.pop('extras')
        #    extras = []
        #    for key,value in extras_data.items():
        #        extra = model.PackageExtra(key=key, value=value)
        #        model.Session.add(extra)
        #        extras.append(extra)
            for key,value in extras_data.items():
                package.extras[key] = value
        for name,value in kwds.items():
            setattr(package, name, value)
        model.Session.add(package)
        model.Session.commit()
        model.Session.remove()
        if not model.repo.history()[0].packages:
            raise Exception, "Didn't set up revision right."

    def create_deleting_revision(self, name):
        rev = model.repo.new_revision()
        rev.author = "Test Revision Deleting"
        package = self.get_package(name)
        package.delete()
        model.repo.commit()

    def get_package(self, name):
        return model.Package.by_name(name) 

    def test_read(self):
        anna = model.Package.by_name(u'annakarenina')
        rev_id = anna.revision.id
        offset = url_for(controller='revision', action='read', id='%s' % rev_id)
        res = self.app.get(offset)
        assert 'Revision %s' % rev_id in res
        assert 'Revision: %s' % rev_id in res
        # Todo: Reinstate asserts below, failing on 'Test Revision Deleting'
        #assert 'Author:</strong> tester' in res
        #assert 'Log Message:' in res
        #assert 'Creating test data.' in res
        #assert 'Dataset: annakarenina' in res
        #assert "Datasets' Tags" in res
        #res = res.click('annakarenina', index=0)
        #assert 'Datasets - annakarenina' in res
        
    def test_list_format_atom(self):
        self.create_40_revisions()
        self.create_updating_revision(u'warandpeace',
            title=u"My Updated 'War and Peace' Title",
        )
        self.create_updating_revision(u'annakarenina',
            title=u"My Updated 'Annakarenina' Title",
            resources=[{
                'url': u'http://www.annakarenina.com/download3',
                'format': u'zip file',
                'description': u'Full text. Needs escaping: " Umlaut: \xfc',
                'hash': u'def456',
            }],
        )
        self.create_updating_revision(u'warandpeace',
            title=u"My Doubly Updated 'War and Peace' Title",
            extras={
                'date_updated': u'2010',
            }
        )
        self.create_deleting_revision(u'annakarenina')
        revisions = model.repo.history().all()
        revision1 = revisions[0]
        # Revisions are most recent first, with first rev on last page.
        # Todo: Look at the model to see which revision is last.
        # Todo: Test for last revision on first page.
        # Todo: Test for first revision on last page.
        # Todo: Test for last revision minus 50 on second page.
        # Page 1.   (Implied id=1)
        offset = url_for(controller='revision', action='list', format='atom')
        res = self.app.get(offset)
        assert '<feed' in res, res
        assert 'xmlns="http://www.w3.org/2005/Atom"' in res, res
        assert '</feed>' in res, res
        # Todo: Better test for 'days' request param.
        #  - fake some older revisions and check they aren't included.
        offset = url_for(controller='revision', action='list', format='atom',
                days=30)
        res = self.app.get(offset)
        assert '<feed' in res, res
        assert 'xmlns="http://www.w3.org/2005/Atom"' in res, res
        assert '</feed>' in res, res

        # Tests for indications about what happened.
        assert 'warandpeace:created' in res, res
        assert 'annakarenina:created' in res, res
        assert 'warandpeace:updated:date_updated' in res, res
        assert 'annakarenina:updated:resources' in res, res
        assert 'annakarenina:deleted' in res, res


########NEW FILE########
__FILENAME__ = test_search
# These only test that the controller is passing on queries correctly
# to the search library. The search library is tested in:
# ckan/tests/lib/test_solr_package_search.py

import re
from nose.tools import assert_equal

from ckan.tests import CreateTestData, setup_test_search_index, search_related
from ckan.tests.pylons_controller import PylonsTestCase
from base import FunctionalTestCase
from ckan import model
import ckan.lib.search as search
import ckan.lib.helpers as h

class TestSearch(FunctionalTestCase):
    # 'penguin' is in all test search packages
    q_all = u'penguin'

    @classmethod
    def setup_class(cls):
        model.Session.remove()
        setup_test_search_index()
        CreateTestData.create_search_test_data()
        cls.count_re = re.compile('<strong>(\d)</strong> datasets found')

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        search.clear()

    def _pkg_names(self, result):
        return ' '.join(result['results'])

    def _check_results(self, res, expected_count, expected_package_names=[]):
        '''Takes a search result web page and determines whether the
        search results displayed match the expected count and names
        of packages.'''
        # get count
        content = self.named_div('content', res)
        count_match = self.count_re.search(content)
        assert count_match
        assert_equal(len(count_match.groups()), 1)
        count = int(count_match.groups()[0])
        assert_equal(count, expected_count)

        # check package names
        if isinstance(expected_package_names, basestring):
            expected_package_names = [expected_package_names]
        for expected_name in expected_package_names:
            expected_html = '<a href="/dataset/%s">' % expected_name
            assert expected_html in res.body, \
                   'Could not find package name %r in the results page'

    def test_1_all_records(self):
        res = self.app.get('/dataset?q')
        result = self._check_results(res, 6, 'gils')

    def test_1_name(self):
        # exact name
        res = self.app.get('/dataset?q=gils')
        result = self._check_results(res, 1, 'gils')

    def test_2_title(self):
        # exact title, one word
        res = self.app.get('/dataset?q=Opengov')
        result = self._check_results(res, 1, 'se-opengov')

        # multiple words
        res = self.app.get('/dataset?q=Government%20Expenditure')
        result = self._check_results(res, 1, 'uk-government-expenditure')

class TestSearch2(FunctionalTestCase, PylonsTestCase):#, TestPackageForm):

    @classmethod
    def setup_class(cls):
        PylonsTestCase.setup_class()
        setup_test_search_index()
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        search.clear()

    @search_related
    def test_search(self):
        offset = h.url_for(controller='package', action='search')
        print offset
        res = self.app.get(offset)
        assert 'Search - ' in res
        self._check_search_results(res, 'annakarenina', ['<strong>1</strong>', 'A Novel By Tolstoy'] )
        self._check_search_results(res, 'warandpeace', ['<strong>1</strong>'])
        self._check_search_results(res, 'warandpeace', ['<strong>1</strong>'])
        self._check_search_results(res, 'annakarenina', ['<strong>1</strong>'])
        # check for something that also finds tags ...
        self._check_search_results(res, 'russian', ['<strong>2</strong>'])

    @search_related
    def test_search_foreign_chars(self):
        offset = h.url_for(controller='package', action='search')
        res = self.app.get(offset)
        assert 'Search - ' in res
        self._check_search_results(res, u'th\xfcmb', ['<strong>1</strong>'])
        self._check_search_results(res, 'thumb', ['<strong>1</strong>'])

    @search_related
    def test_search_escape_chars(self):
        payload = '?q=fjdkf%2B%C2%B4gfhgfkgf%7Bg%C2%B4pk&search=Search+Packages+%C2%BB'
        offset = h.url_for(controller='package', action='search') + payload
        results_page = self.app.get(offset)
        assert 'Search - ' in results_page, results_page
        results_page = self.main_div(results_page)
        # solr's edismax parser won't throw an error, so this should return 0 results
        assert '>0<' in results_page, results_page

    def _check_search_results(self, page, terms, requireds):
        form = page.forms['dataset-search']
        form['q'] = terms.encode('utf8') # paste doesn't handle this!
        results_page = form.submit()
        assert 'Search - ' in results_page, results_page
        results_page = self.main_div(results_page)
        for required in requireds:
            if required not in results_page:
                print results_page
                print 'Could not find %r' % required
                raise AssertionError

class TestNonActivePackages(FunctionalTestCase):
    @classmethod
    def setup_class(self):
        setup_test_search_index()
        CreateTestData.create()
        self.non_active_name = u'test_nonactive'
        pkg = model.Package(name=self.non_active_name)
        model.repo.new_revision()
        model.Session.add(pkg)
        model.repo.commit_and_remove()

        pkg = model.Session.query(model.Package).filter_by(name=self.non_active_name).one()
        admin = model.User.by_name(u'joeadmin')
        model.setup_default_user_roles(pkg, [admin])
        model.repo.commit_and_remove()

        model.repo.new_revision()        
        pkg = model.Session.query(model.Package).filter_by(name=self.non_active_name).one()
        pkg.delete() # becomes non active
        model.repo.commit_and_remove()
        

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()
        search.clear()

    @search_related
    def test_search(self):
        offset = h.url_for(controller='package', action='search')
        res = self.app.get(offset)
        assert 'Search - ' in res
        form = res.forms['dataset-search']
        form['q'] =  'name:' + str(self.non_active_name)
        results_page = form.submit()
        assert 'Search - ' in results_page, results_page
        assert '<strong>0</strong> datasets found' in results_page, (self.non_active_name, results_page)

########NEW FILE########
__FILENAME__ = test_storage
import os

import paste.fixture
import pylons.config as config

import ckan.model as model
from ckan.config.middleware import make_app
from ckan.tests import conf_dir, url_for, CreateTestData
from ckan.controllers.admin import get_sysadmins
from ckan.controllers.storage import create_pairtree_marker


class TestStorageAPIController:
    @classmethod
    def setup_class(cls):
        cls._original_config = config.copy()
        for key in config.keys():
            if key.startswith('ofs'):
                del config[key]
        config['ofs.impl'] = 'pairtree'
        config['ckan.storage.bucket'] = 'ckantest'
        config['ofs.storage_dir'] = '/tmp/ckan-test-ckanext-storage'

        create_pairtree_marker( config['ofs.storage_dir'] )
        wsgiapp = make_app(config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)

        CreateTestData.create_test_user()

    @classmethod
    def teardown_class(cls):
        config.clear()
        config.update(cls._original_config)
        CreateTestData.delete()

    def test_index(self):
        url = url_for('storage_api')
        res = self.app.get(url)
        out = res.json
        assert len(res.json) == 3

    def test_authz(self):
        url = url_for('storage_api_auth_form', label='abc')

        # Non logged in users can not upload
        res = self.app.get(url, status=[302,401])

        # Logged in users can upload
        res = self.app.get(url, status=[200], extra_environ={'REMOTE_USER':'tester'})


        # TODO: ? test for non-authz case
        # url = url_for('storage_api_auth_form', label='abc')
        # res = self.app.get(url, status=[302,401])


class TestStorageAPIControllerLocal:
    @classmethod
    def setup_class(cls):
        cls._original_config = config.copy()
        for key in config.keys():
            if key.startswith('ofs'):
                del config[key]
        config['ckan.storage.bucket'] = 'ckantest'
        config['ofs.impl'] = 'pairtree'
        config['ofs.storage_dir'] = '/tmp/ckan-test-ckanext-storage'
        create_pairtree_marker( config['ofs.storage_dir'] )
        wsgiapp = make_app(config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)
        CreateTestData.create()
        model.Session.remove()
        user = model.User.by_name('tester')
        cls.extra_environ = {'Authorization': str(user.apikey)}

    @classmethod
    def teardown_class(cls):
        config.clear()
        config.update(cls._original_config)
        CreateTestData.delete()

    def test_auth_form(self):
        url = url_for('storage_api_auth_form', label='abc')
        res = self.app.get(url, extra_environ=self.extra_environ, status=200)
        assert res.json['action'] == u'/storage/upload_handle', res.json
        assert res.json['fields'][-1]['value'] == 'abc', res

        url = url_for('storage_api_auth_form', label='abc/xxx')
        res = self.app.get(url, extra_environ=self.extra_environ, status=200)
        assert res.json['fields'][-1]['value'] == 'abc/xxx'

    def test_metadata(self):
        url = url_for('storage_api_get_metadata', label='abc')
        res = self.app.get(url, status=404)

        # TODO: test get metadata on real setup ...
        label = 'abc'
        url = url_for('storage_api_set_metadata',
            extra_environ=self.extra_environ,
            label=label,
            data=dict(
                label=label
                )
            )
        # res = self.app.get(url, status=404)


# Disabling because requires access to google storage to run (and this is not
# generally available to devs ...)
class _TestStorageAPIControllerGoogle:
    @classmethod
    def setup_class(cls):
        cls._original_config = config.copy()
        config['ckan.storage.bucket'] = 'ckantest'
        config['ofs.impl'] = 'google'
        if 'ofs.gs_secret_access_key' not in config:
            raise Exception('You will need to configure access to google storage to run this test')
        # You will need these configured in your
        # config['ofs.gs_access_key_id'] = 'GOOGCABCDASDASD'
        # config['ofs.gs_secret_access_key'] = '134zsdfjkw4234addad'
        # need to ensure not configured for local as breaks google setup
        # (and cannot delete all ofs keys as need the gs access codes)
        if 'ofs.storage_dir' in config:
            del config['ofs.storage_dir']
        wsgiapp = make_app(config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)
        # setup test data including testsysadmin user
        CreateTestData.create()
        model.Session.remove()
        user = model.User.by_name('tester')
        cls.extra_environ = {'Authorization': str(user.apikey)}

    @classmethod
    def teardown_class(cls):
        config.clear()
        config.update(cls._original_config)
        CreateTestData.delete()

    def test_auth_form(self):
        url = url_for('storage_api_auth_form', label='abc')
        res = self.app.get(url, extra_environ=self.extra_environ, status=200)
        assert res.json['fields'][-1]['value'] == 'abc', res

        url = url_for('storage_api_auth_form', label='abc/xxx')
        res = self.app.get(url, extra_environ=self.extra_environ, status=200)
        assert res.json['fields'][-1]['value'] == 'abc/xxx'

        url = url_for('storage_api_auth_form', label='abc',
                success_action_redirect='abc')
        res = self.app.get(url, extra_environ=self.extra_environ, status=200)
        fields = dict([ (x['name'], x['value']) for x in res.json['fields'] ])
        assert fields['success_action_redirect'] == u'http://localhost/storage/upload/success_empty?label=abc'

    # TODO: re-enable
    # Disabling as there seems to be a mismatch between OFS and more recent
    # versions of boto (e.g. >= 2.1.1)
    # Specifically fill_in_auth method on Connection objects has gone away
    def _test_auth_request(self):
        url = url_for('storage_api_auth_request', label='abc')
        res = self.app.get(url, extra_environ=self.extra_environ, status=200)
        assert res.json['method'] == 'POST'
        assert res.json['headers']['Authorization']


########NEW FILE########
__FILENAME__ = test_tag
import json

from ckan.tests import *
import ckan.model as model

HTTP_MOVED_PERMANENTLY = 301

class TestTagController(TestController):

    @classmethod
    def setup_class(self):
        model.Session.remove()
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_index(self):
        offset = url_for(controller='tag', action='index')
        res = self.app.get(offset)
        assert 'Tags' in res
        assert 'There are' in res

    def test_read_moved(self):
        name = 'tolstoy'
        offset = '/tag/read/%s' % name
        res = self.app.get(offset, status=HTTP_MOVED_PERMANENTLY)
        res = res.follow()
        assert '%s - Tags' % name in res
        assert name in res
        # res = res.click(pkgname)
        # assert '%s - Data Packages' % pkgname in res

    def test_read(self):
        name = 'tolstoy'
        pkgname = 'warandpeace'
        offset = url_for(controller='tag', action='read', id=name)
        assert offset == '/tag/tolstoy', offset
        res = self.app.get(offset)
        assert '%s - Tags' % name in res
        assert name in res
        # res = res.click(pkgname)
        # assert '%s - Data Packages' % pkgname in res

    def test_list_short(self):
        offset = url_for(controller='tag', action='index')
        res = self.app.get(offset)
        tagname = 'tolstoy'
        assert tagname in res
        #assert '(2 packages)' in res
        res = res.click(tagname)
        assert tagname in res
        offset = url_for(controller='tag', action='index')
        res = self.app.get(offset)
        assert tagname in res
        #assert '(2 packages)' in res
        tag_count = model.Session.query(model.Tag).count()
        assert 'There are <strong>%s</strong> results for tags.' % tag_count in res
        offset = url_for(controller='tag', action='index')
        res = self.app.get(offset)
        assert tagname in res
        tag_count = model.Session.query(model.Tag).count()
        assert 'There are <strong>%s</strong> results for tags.' % tag_count in res
        # Avoid interactions.
        offset = url_for(controller='tag', action='index')
    
    def test_search(self):
        offset = url_for(controller='tag', action='index', id=None)
        res = self.app.get(offset)
        search_term = 's'
        fv = res.forms['tag-search']
        fv['q'] =  str(search_term)
        res = fv.submit()
        assert 'There are <strong>2</strong> results' in res, res
        assert 'russian' in res, res
        assert 'tolstoy' in res, res

    def test_search_with_unicode_term(self):
        offset = url_for(controller='tag', action='index', id=None)
        res = self.app.get(offset)
        search_term = u' \u30a1'.encode('utf8')
        fv = res.forms['tag-search']
        fv['q'] =  str(search_term)
        res = fv.submit()
        assert 'There are <strong>1</strong> results' in res, res
        assert u'Flexible \u30a1' in res, res

    def test_autocomplete(self):
        controller = 'api'
        action = 'tag_autocomplete'
        offset = url_for(controller=controller, action=action, ver=2)
        res = self.app.get(offset)
        assert '[]' in res
        offset = url_for(controller=controller, action=action, incomplete='russian', ver=2)
        res = self.app.get(offset)
        assert 'russian' in res
        assert 'tolstoy' not in res
        offset = url_for(controller=controller, action=action, incomplete='tolstoy', ver=2)
        res = self.app.get(offset)
        assert 'russian' not in res
        assert 'tolstoy' in res

    def test_autocomplete_with_capital_letter_in_search_term(self):
        controller = 'api'
        action = 'tag_autocomplete'
        offset = url_for(controller=controller, action=action, incomplete='Flex', ver=2)
        res = self.app.get(offset)
        data = json.loads(res.body)
        assert u'Flexible \u30a1' in data['ResultSet']['Result'][0].values()
        
    def test_autocomplete_with_space_in_search_term(self):
        controller = 'api'
        action = 'tag_autocomplete'
        offset = url_for(controller=controller, action=action, incomplete='Flexible ', ver=2)
        res = self.app.get(offset)
        data = json.loads(res.body)
        assert u'Flexible \u30a1' in data['ResultSet']['Result'][0].values()
        
    def test_autocomplete_with_unicode_in_search_term(self):
        controller = 'api'
        action = 'tag_autocomplete'
        offset = url_for(controller=controller, action=action, incomplete=u'ible \u30a1', ver=2)
        res = self.app.get(offset)
        data = json.loads(res.body)
        assert u'Flexible \u30a1' in data['ResultSet']['Result'][0].values()


########NEW FILE########
__FILENAME__ = test_tag_vocab
import json
import paste.fixture
from ckan import model
from ckan.lib.create_test_data import CreateTestData
import ckan.lib.helpers as h
from ckan.tests import WsgiAppCase
import ckan.plugins as plugins

TEST_VOCAB_NAME = 'test-vocab'



# paste.fixture.Field.Select does not handle multiple selects currently,
# so replace with our own implementations of Form and Select
class Form(paste.fixture.Form):
    def __init__(self, response, text):
        paste.fixture.Form.__init__(self, response, text)

    def submit_fields(self, name=None, index=None):
        """
        Return a list of ``[(name, value), ...]`` for the current
        state of the form.
        """
        submit = []
        if name is not None:
            field = self.get(name, index=index)
            submit.append((field.name, field.value_if_submitted()))
        for name, fields in self.fields.items():
            if name is None:
                continue
            for field in fields:
                value = field.value
                if value is None:
                    continue
                if isinstance(value, list):
                    for v in value:
                        submit.append((name, v))
                else:
                    submit.append((name, value))
        return submit


class Select(paste.fixture.Field):
    def __init__(self, *args, **attrs):
        paste.fixture.Field.__init__(self, *args, **attrs)
        self.options = []
        self.selectedIndex = None

    def value__set(self, value):
        if not value:
            self.selectedIndex = None
            self.options = [(option, False) for (option, checked) in self.options]
            return

        for v in value:
            if not v in [option for (option, checked) in self.options]:
                raise ValueError("Option %r not found (from %s)"
                    % (value, ', '.join(
                    [repr(o) for o, checked in self.options]))
                )

        new_options = [(option, True) for (option, checked) in self.options if option in value]
        new_options += [(option, False) for (option, checked) in self.options if not option in value]
        self.options = new_options

    def value__get(self):
        return [option for (option, checked) in self.options if checked]

    value = property(value__get, value__set)

class TestWUI(WsgiAppCase):
    @classmethod
    def setup_class(cls):
        plugins.load('test_tag_vocab_plugin')
        CreateTestData.create(package_type='mock_vocab_tags_plugin')
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.dset = model.Package.get('warandpeace')
        cls.tag1_name = 'vocab-tag-1'
        cls.tag2_name = 'vocab-tag-2'

        # use our custom select class for this test suite
        cls.old_select = paste.fixture.Field.classes['select']
        paste.fixture.Field.classes['select'] = Select

        # create a test vocab
        params = json.dumps({'name': TEST_VOCAB_NAME})
        extra_environ = {'Authorization' : str(cls.sysadmin_user.apikey)}
        cls.extra_environ = {'Authorization' : str(cls.sysadmin_user.apikey)}
        response = cls.app.post('/api/action/vocabulary_create', params=params,
                                extra_environ=extra_environ)
        assert json.loads(response.body)['success']
        vocab_id = json.loads(response.body)['result']['id']

        # add tags to the vocab
        extra_environ = {'Authorization' : str(cls.sysadmin_user.apikey)}
        params = json.dumps({'name': cls.tag1_name, 'vocabulary_id': vocab_id})
        response = cls.app.post('/api/action/tag_create', params=params,
                                 extra_environ=extra_environ)
        assert json.loads(response.body)['success']
        params = json.dumps({'name': cls.tag2_name, 'vocabulary_id': vocab_id})
        response = cls.app.post('/api/action/tag_create', params=params,
                                 extra_environ=extra_environ)
        assert json.loads(response.body)['success']

    @classmethod
    def teardown_class(cls):
        plugins.unload('test_tag_vocab_plugin')
        paste.fixture.Field.classes['select'] = cls.old_select
        model.repo.rebuild_db()

    def _get_vocab_id(self, vocab_name):
        params = json.dumps({'id': vocab_name})
        response = self.app.post('/api/action/vocabulary_show', params=params)
        assert json.loads(response.body)['success']
        return json.loads(response.body)['result']['id']

    def _add_vocab_tag_to_dataset(self, dataset_id, vocab_id, tag_name):
        params = json.dumps({'id': dataset_id})
        response = self.app.post('/api/action/package_show', params=params)
        dataset = json.loads(response.body)['result']
        dataset['tags'] = []
        dataset['tags'].append({'name': tag_name, 'vocabulary_id': vocab_id})
        params = json.dumps(dataset)
        response = self.app.post('/api/action/package_update', params=params,
                                 extra_environ={'Authorization': str(self.sysadmin_user.apikey)})
        assert json.loads(response.body)['success']

    def _remove_vocab_tags(self, dataset_id, vocab_id, tag_name):
        params = json.dumps({'id': dataset_id})
        response = self.app.post('/api/action/package_show', params=params)
        dataset = json.loads(response.body)['result']
        dataset['vocab_tag_selected'] = []
        params = json.dumps(dataset)
        response = self.app.post('/api/action/package_update', params=params,
                                 extra_environ={'Authorization': str(self.sysadmin_user.apikey)})
        assert json.loads(response.body)['success']

    def test_01_dataset_view(self):
        vocab_id = self._get_vocab_id(TEST_VOCAB_NAME)
        self._add_vocab_tag_to_dataset(self.dset.id, vocab_id, self.tag1_name)
        response = self.app.get(h.url_for(controller='package', action='read',
            id=self.dset.id))
        assert self.tag1_name in response.body, self.tag1_name
        self._remove_vocab_tags(self.dset.id, vocab_id, self.tag1_name)

    def test_02_dataset_edit_add_vocab_tag(self):
        vocab_id = self._get_vocab_id(TEST_VOCAB_NAME)
        url = h.url_for(controller='package', action='edit', id=self.dset.id)
        response = self.app.get(url, extra_environ=self.extra_environ)
        fv = response.forms['dataset-edit']
        fv = Form(fv.response, fv.text)
        fv['vocab_tags'] = [self.tag2_name]
        response = fv.submit('save', extra_environ=self.extra_environ)
        response = response.follow()
        assert not self.tag1_name in response.body
        assert self.tag2_name in response.body
        self._remove_vocab_tags(self.dset.id, vocab_id, self.tag1_name)
        self._remove_vocab_tags(self.dset.id, vocab_id, self.tag2_name)

    def test_02_dataset_edit_add_free_and_vocab_tags_then_edit_again(self):
        vocab_id = self._get_vocab_id(TEST_VOCAB_NAME)
        url = h.url_for(controller='package', action='edit', id=self.dset.id)
        response = self.app.get(url, extra_environ=self.extra_environ)
        fv = response.forms['dataset-edit']
        fv = Form(fv.response, fv.text)

        # Add a free tag with a space in its name.
        fv['tag_string'] = 'water quality'

        # Add a vocab tag.
        fv['vocab_tags'] = [self.tag2_name]

        # Save the dataset and visit the page again
        response = fv.submit('save', extra_environ=self.extra_environ)
        response = response.follow()
        assert not self.tag1_name in response.body
        assert self.tag2_name in response.body
        url = h.url_for(controller='package', action='edit', id=self.dset.id)
        response = self.app.get(url, extra_environ=self.extra_environ)
        fv = response.forms['dataset-edit']
        fv = Form(fv.response, fv.text)
        assert fv['vocab_tags'].value == [self.tag2_name], fv['vocab_tags'].value
        self._remove_vocab_tags(self.dset.id, vocab_id, self.tag2_name)

    def test_03_dataset_edit_remove_vocab_tag(self):
        vocab_id = self._get_vocab_id(TEST_VOCAB_NAME)
        self._add_vocab_tag_to_dataset(self.dset.id, vocab_id, self.tag1_name)
        url = h.url_for(controller='package', action='edit', id=self.dset.id)
        response = self.app.get(url, extra_environ=self.extra_environ)
        fv = response.forms['dataset-edit']
        fv = Form(fv.response, fv.text)
        fv['vocab_tags'] = []
        response = fv.submit('save', extra_environ=self.extra_environ)
        response = response.follow()
        assert not self.tag1_name in response.body
        self._remove_vocab_tags(self.dset.id, vocab_id, self.tag1_name)

    def test_04_dataset_edit_change_vocab_tag(self):
        vocab_id = self._get_vocab_id(TEST_VOCAB_NAME)
        self._add_vocab_tag_to_dataset(self.dset.id, vocab_id, self.tag1_name)
        url = h.url_for(controller='package', action='edit', id=self.dset.id)
        response = self.app.get(url, extra_environ=self.extra_environ)
        fv = response.forms['dataset-edit']
        fv = Form(fv.response, fv.text)
        fv['vocab_tags'] = [self.tag2_name]
        response = fv.submit('save', extra_environ=self.extra_environ)
        response = response.follow()
        assert not self.tag1_name in response.body
        assert self.tag2_name in response.body
        self._remove_vocab_tags(self.dset.id, vocab_id, self.tag2_name)

    def test_05_dataset_edit_add_multiple_vocab_tags(self):
        vocab_id = self._get_vocab_id(TEST_VOCAB_NAME)
        url = h.url_for(controller='package', action='edit', id=self.dset.id)
        response = self.app.get(url, extra_environ=self.extra_environ)
        fv = response.forms['dataset-edit']
        fv = Form(fv.response, fv.text)
        fv['vocab_tags'] = [self.tag1_name, self.tag2_name]
        response = fv.submit('save', extra_environ=self.extra_environ)
        response = response.follow()
        assert self.tag1_name in response.body
        assert self.tag2_name in response.body
        self._remove_vocab_tags(self.dset.id, vocab_id, self.tag1_name)
        self._remove_vocab_tags(self.dset.id, vocab_id, self.tag2_name)


########NEW FILE########
__FILENAME__ = test_tracking
'''Functional tests for CKAN's builtin page view tracking feature.'''

import tempfile
import csv
import datetime
import routes

import ckan.tests as tests


class TestTracking(object):

    def tearDown(self):
        import ckan.model as model
        model.repo.rebuild_db()

    def _get_app(self):
        import paste.fixture
        import pylons.test
        return paste.fixture.TestApp(pylons.test.pylonsapp)

    def _create_sysadmin(self, app):
        '''Create a sysadmin user.

        Returns a tuple (sysadmin_user_object, api_key).

        '''
        # You can't create a user via the api
        # (ckan.auth.create_user_via_api = false is in test-core.ini) and you
        # can't make your first sysadmin user via either the api or the web
        # interface anyway, so access the model directly to make a sysadmin
        # user.
        import ckan.model as model
        user = model.User(name='joeadmin', email='joe@admin.net',
                          password='joe rules')
        user.sysadmin = True
        model.Session.add(user)
        model.repo.commit_and_remove()
        return (tests.call_action_api(app, 'user_show', id=user.id),
                user.apikey)

    def _create_package(self, app, apikey, name='look_to_windward'):
        '''Create a package via the action api.'''

        return tests.call_action_api(app, 'package_create', apikey=apikey,
                                     name=name)

    def _create_resource(self, app, package, apikey):
        '''Create a resource via the action api.'''

        return tests.call_action_api(app, 'resource_create', apikey=apikey,
                                     package_id=package['id'],
                                     url='http://example.com')

    def _post_to_tracking(self, app, url, type_='page', ip='199.204.138.90',
                          browser='firefox'):
        '''Post some data to /_tracking directly.

        This simulates what's supposed when you view a page with tracking
        enabled (an ajax request posts to /_tracking).

        '''
        params = {'url': url, 'type': type_}
        extra_environ = {
            # The tracking middleware crashes if these aren't present.
            'HTTP_USER_AGENT': browser,
            'REMOTE_ADDR': ip,
            'HTTP_ACCEPT_LANGUAGE': 'en',
            'HTTP_ACCEPT_ENCODING': 'gzip, deflate',
        }
        app.post('/_tracking', params=params, extra_environ=extra_environ)

    def _update_tracking_summary(self):
        '''Update CKAN's tracking summary data.

        This simulates calling `paster tracking update` on the command line.

        '''
        # FIXME: Can this be done as more of a functional test where we
        # actually test calling the command and passing the args? By calling
        # the method directly, we're not testing the command-line parsing.
        import ckan.lib.cli
        import ckan.model
        date = (datetime.datetime.now() - datetime.timedelta(days=1)).strftime(
            '%Y-%m-%d')
        ckan.lib.cli.Tracking('Tracking').update_all(
            engine=ckan.model.meta.engine, start_date=date)

    def _rebuild_search_index(self):
        '''Rebuild CKAN's search index.

        This simulates calling `paster search-index rebuild` on the command
        line.

        '''
        import ckan.lib.cli
        ckan.lib.cli.SearchIndexCommand('SearchIndexCommand').rebuild()

    def test_package_with_0_views(self):
        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        package = self._create_package(app, apikey)

        # The API should return 0 recent views and 0 total views for the
        # unviewed package.
        package = tests.call_action_api(app, 'package_show',
                                        id=package['name'])
        tracking_summary = package['tracking_summary']
        assert tracking_summary['recent'] == 0, ("A package that has not "
                                                 "been viewed should have 0 "
                                                 "recent views")
        assert tracking_summary['total'] == 0, ("A package that has not "
                                                "been viewed should have 0 "
                                                "total views")

    def test_resource_with_0_views(self):
        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        package = self._create_package(app, apikey)
        resource = self._create_resource(app, package, apikey)

        # The package_show() API should return 0 recent views and 0 total
        # views for the unviewed resource.
        package = tests.call_action_api(app, 'package_show',
                                        id=package['name'])
        assert len(package['resources']) == 1
        resource = package['resources'][0]
        tracking_summary = resource['tracking_summary']
        assert tracking_summary['recent'] == 0, ("A resource that has not "
                                                 "been viewed should have 0 "
                                                 "recent views")
        assert tracking_summary['total'] == 0, ("A resource that has not "
                                                "been viewed should have 0 "
                                                "total views")

        # The resource_show() API should return 0 recent views and 0 total
        # views for the unviewed resource.
        resource = tests.call_action_api(app, 'resource_show',
                                         id=resource['id'])
        tracking_summary = resource['tracking_summary']
        assert tracking_summary['recent'] == 0, ("A resource that has not "
                                                 "been viewed should have 0 "
                                                 "recent views")
        assert tracking_summary['total'] == 0, ("A resource that has not "
                                                "been viewed should have 0 "
                                                "total views")

    def test_package_with_one_view(self):
        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        package = self._create_package(app, apikey)
        self._create_resource(app, package, apikey)

        url = routes.url_for(controller='package', action='read',
                             id=package['name'])
        self._post_to_tracking(app, url)

        self._update_tracking_summary()

        package = tests.call_action_api(app, 'package_show', id=package['id'])
        tracking_summary = package['tracking_summary']
        assert tracking_summary['recent'] == 1, ("A package that has been "
                                                 "viewed once should have 1 "
                                                 "recent view.")
        assert tracking_summary['total'] == 1, ("A package that has been "
                                                "viewed once should have 1 "
                                                "total view")

        assert len(package['resources']) == 1
        resource = package['resources'][0]
        tracking_summary = resource['tracking_summary']
        assert tracking_summary['recent'] == 0, ("Viewing a package should "
                                                 "not increase the recent "
                                                 "views of the package's "
                                                 "resources")
        assert tracking_summary['total'] == 0, ("Viewing a package should "
                                                "not increase the total views "
                                                "of the package's resources")

    def test_resource_with_one_preview(self):
        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        package = self._create_package(app, apikey)
        resource = self._create_resource(app, package, apikey)

        url = routes.url_for(controller='package', action='resource_read',
                             id=package['name'], resource_id=resource['id'])
        self._post_to_tracking(app, url)

        self._update_tracking_summary()

        package = tests.call_action_api(app, 'package_show', id=package['id'])
        assert len(package['resources']) == 1
        resource = package['resources'][0]

        assert package['tracking_summary']['recent'] == 0, ("Previewing a "
                                                            "resource should "
                                                            "not increase the "
                                                            "package's recent "
                                                            "views")
        assert package['tracking_summary']['total'] == 0, ("Previewing a "
                                                           "resource should "
                                                           "not increase the "
                                                           "package's total "
                                                           "views")
        # Yes, previewing a resource does _not_ increase its view count.
        assert resource['tracking_summary']['recent'] == 0, ("Previewing a "
                                                             "resource should "
                                                             "not increase "
                                                             "the resource's "
                                                             "recent views")
        assert resource['tracking_summary']['total'] == 0, ("Previewing a "
                                                            "resource should "
                                                            "not increase the "
                                                            "resource's "
                                                            "recent views")

    def test_resource_with_one_download(self):
        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        package = self._create_package(app, apikey)
        resource = self._create_resource(app, package, apikey)

        self._post_to_tracking(app, resource['url'], type_='resource')
        self._update_tracking_summary()

        package = tests.call_action_api(app, 'package_show', id=package['id'])
        assert len(package['resources']) == 1
        resource = package['resources'][0]
        assert package['tracking_summary']['recent'] == 0, (
            "Downloading a resource should not increase the package's recent "
            "views")
        assert package['tracking_summary']['total'] == 0, (
            "Downloading a resource should not increase the package's total "
            "views")
        assert resource['tracking_summary']['recent'] == 1, (
            "Downloading a resource should increase the resource's recent "
            "views")
        assert resource['tracking_summary']['total'] == 1, (
            "Downloading a resource should increase the resource's total "
            "views")

        # The resource_show() API should return the same result.
        resource = tests.call_action_api(app, 'resource_show',
                                         id=resource['id'])
        tracking_summary = resource['tracking_summary']
        assert tracking_summary['recent'] == 1, (
            "Downloading a resource should increase the resource's recent "
            "views")
        assert tracking_summary['total'] == 1, (
            "Downloading a resource should increase the resource's total "
            "views")

    def test_view_page(self):
        app = self._get_app()

        # Visit the front page.
        self._post_to_tracking(app, url='', type_='page')
        # Visit the /organization page.
        self._post_to_tracking(app, url='/organization', type_='page')
        # Visit the /about page.
        self._post_to_tracking(app, url='/about', type_='page')

        self._update_tracking_summary()

        # There's no way to export page-view (as opposed to resource or
        # dataset) tracking summaries, eg. via the api or a paster command, the
        # only way we can check them is through the model directly.
        import ckan.model as model
        for url in ('', '/organization', '/about'):
            q = model.Session.query(model.TrackingSummary)
            q = q.filter_by(url=url)
            tracking_summary = q.one()
            assert tracking_summary.count == 1, ("Viewing a page should "
                                                 "increase the page's view "
                                                 "count")
            # For pages (as opposed to datasets and resources) recent_views and
            # running_total always stay at 1. Shrug.
            assert tracking_summary.recent_views == 0, (
                "recent_views for a page is always 0")
            assert tracking_summary.running_total == 0, (
                "running_total for a page is always 0")

    def test_package_with_many_views(self):
        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        package = self._create_package(app, apikey)
        self._create_resource(app, package, apikey)

        url = routes.url_for(controller='package', action='read',
                             id=package['name'])

        # View the package three times from different IPs.
        self._post_to_tracking(app, url, ip='111.222.333.44')
        self._post_to_tracking(app, url, ip='111.222.333.55')
        self._post_to_tracking(app, url, ip='111.222.333.66')

        self._update_tracking_summary()

        package = tests.call_action_api(app, 'package_show', id=package['id'])
        tracking_summary = package['tracking_summary']
        assert tracking_summary['recent'] == 3, (
            "A package that has been viewed 3 times recently should have 3 "
            "recent views")
        assert tracking_summary['total'] == 3, (
            "A package that has been viewed 3 times should have 3 total views")

        assert len(package['resources']) == 1
        resource = package['resources'][0]
        tracking_summary = resource['tracking_summary']
        assert tracking_summary['recent'] == 0, (
            "Viewing a package should not increase the recent views of the "
            "package's resources")
        assert tracking_summary['total'] == 0, (
            "Viewing a package should not increase the total views of the "
            "package's resources")

    def test_resource_with_many_downloads(self):
        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        package = self._create_package(app, apikey)
        resource = self._create_resource(app, package, apikey)
        url = resource['url']

        # Download the resource three times from different IPs.
        self._post_to_tracking(app, url, type_='resource', ip='111.222.333.44')
        self._post_to_tracking(app, url, type_='resource', ip='111.222.333.55')
        self._post_to_tracking(app, url, type_='resource', ip='111.222.333.66')

        self._update_tracking_summary()

        package = tests.call_action_api(app, 'package_show', id=package['id'])
        assert len(package['resources']) == 1
        resource = package['resources'][0]
        tracking_summary = resource['tracking_summary']
        assert tracking_summary['recent'] == 3, (
            "A resource that has been downloaded 3 times recently should have "
            "3 recent downloads")
        assert tracking_summary['total'] == 3, (
            "A resource that has been downloaded 3 times should have 3 total "
            "downloads")

        tracking_summary = package['tracking_summary']
        assert tracking_summary['recent'] == 0, (
            "Downloading a resource should not increase the resource's "
            "package's recent views")
        assert tracking_summary['total'] == 0, (
            "Downloading a resource should not increase the resource's "
            "package's total views")

    def test_page_with_many_views(self):
        app = self._get_app()

        # View each page three times, from three different IPs.
        for ip in ('111.111.11.111', '222.222.22.222', '333.333.33.333'):
            # Visit the front page.
            self._post_to_tracking(app, url='', type_='page', ip=ip)
            # Visit the /organization page.
            self._post_to_tracking(app, url='/organization', type_='page',
                                   ip=ip)
            # Visit the /about page.
            self._post_to_tracking(app, url='/about', type_='page', ip=ip)

        self._update_tracking_summary()

        # There's no way to export page-view (as opposed to resource or
        # dataset) tracking summaries, eg. via the api or a paster command, the
        # only way we can check them if through the model directly.
        import ckan.model as model
        for url in ('', '/organization', '/about'):
            q = model.Session.query(model.TrackingSummary)
            q = q.filter_by(url=url)
            tracking_summary = q.one()
            assert tracking_summary.count == 3, (
                "A page that has been viewed three times should have view "
                "count 3")
            # For pages (as opposed to datasets and resources) recent_views and
            # running_total always stay at 1. Shrug.
            assert tracking_summary.recent_views == 0, ("recent_views for "
                                                        "pages is always 0")
            assert tracking_summary.running_total == 0, ("running_total for "
                                                         "pages is always 0")

    def test_recent_views_expire(self):
        # TODO
        # Test that package, resource and page views (maybe 3 different tests)
        # older than 14 days are counted as total views but not as recent
        # views.
        # Will probably have to access the model directly to insert tracking
        # data older than 14 days.
        pass

    def test_dataset_view_count_throttling(self):
        '''If the same user visits the same dataset multiple times on the same
        day, only one view should get counted.

        '''
        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        package = self._create_package(app, apikey)
        self._create_resource(app, package, apikey)
        url = routes.url_for(controller='package', action='read',
                             id=package['name'])

        # Visit the dataset three times from the same IP.
        self._post_to_tracking(app, url)
        self._post_to_tracking(app, url)
        self._post_to_tracking(app, url)

        self._update_tracking_summary()

        package = tests.call_action_api(app, 'package_show', id=package['id'])
        tracking_summary = package['tracking_summary']
        assert tracking_summary['recent'] == 1, ("Repeat dataset views should "
                                                 "not add to recent views "
                                                 "count")
        assert tracking_summary['total'] == 1, ("Repeat dataset views should "
                                                "not add to total views count")

    def test_resource_download_count_throttling(self):
        '''If the same user downloads the same resource multiple times on the
        same day, only one view should get counted.

        '''
        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        package = self._create_package(app, apikey)
        resource = self._create_resource(app, package, apikey)

        # Download the resource three times from the same IP.
        self._post_to_tracking(app, resource['url'], type_='resource')
        self._post_to_tracking(app, resource['url'], type_='resource')
        self._post_to_tracking(app, resource['url'], type_='resource')

        self._update_tracking_summary()

        resource = tests.call_action_api(app, 'resource_show',
                                         id=resource['id'])
        tracking_summary = resource['tracking_summary']
        assert tracking_summary['recent'] == 1, (
            "Repeat resource downloads should not add to recent views count")
        assert tracking_summary['total'] == 1, (
            "Repeat resource downloads should not add to total views count")

    def test_sorting_datasets_by_recent_views(self):
        # FIXME: Have some datasets with different numbers of recent and total
        # views, to make this a better test.
        import ckan.lib.search

        tests.setup_test_search_index()

        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        self._create_package(app, apikey, name='consider_phlebas')
        self._create_package(app, apikey, name='the_player_of_games')
        self._create_package(app, apikey, name='use_of_weapons')

        url = routes.url_for(controller='package', action='read',
                             id='consider_phlebas')
        self._post_to_tracking(app, url)

        url = routes.url_for(controller='package', action='read',
                             id='the_player_of_games')
        self._post_to_tracking(app, url, ip='111.11.111.111')
        self._post_to_tracking(app, url, ip='222.22.222.222')

        url = routes.url_for(controller='package', action='read',
                             id='use_of_weapons')
        self._post_to_tracking(app, url, ip='111.11.111.111')
        self._post_to_tracking(app, url, ip='222.22.222.222')
        self._post_to_tracking(app, url, ip='333.33.333.333')

        self._update_tracking_summary()
        ckan.lib.search.rebuild()

        response = tests.call_action_api(app, 'package_search',
                                         sort='views_recent desc')
        assert response['count'] == 3
        assert response['sort'] == 'views_recent desc'
        packages = response['results']
        assert packages[0]['name'] == 'use_of_weapons'
        assert packages[1]['name'] == 'the_player_of_games'
        assert packages[2]['name'] == 'consider_phlebas'

    def test_sorting_datasets_by_total_views(self):
        # FIXME: Have some datasets with different numbers of recent and total
        # views, to make this a better test.
        import ckan.lib.search

        tests.setup_test_search_index()

        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)
        self._create_package(app, apikey, name='consider_phlebas')
        self._create_package(app, apikey, name='the_player_of_games')
        self._create_package(app, apikey, name='use_of_weapons')

        url = routes.url_for(controller='package', action='read',
                             id='consider_phlebas')
        self._post_to_tracking(app, url)

        url = routes.url_for(controller='package', action='read',
                             id='the_player_of_games')
        self._post_to_tracking(app, url, ip='111.11.111.111')
        self._post_to_tracking(app, url, ip='222.22.222.222')

        url = routes.url_for(controller='package', action='read',
                             id='use_of_weapons')
        self._post_to_tracking(app, url, ip='111.11.111.111')
        self._post_to_tracking(app, url, ip='222.22.222.222')
        self._post_to_tracking(app, url, ip='333.33.333.333')

        self._update_tracking_summary()
        ckan.lib.search.rebuild()

        response = tests.call_action_api(app, 'package_search',
                                         sort='views_total desc')
        assert response['count'] == 3
        assert response['sort'] == 'views_total desc'
        packages = response['results']
        assert packages[0]['name'] == 'use_of_weapons'
        assert packages[1]['name'] == 'the_player_of_games'
        assert packages[2]['name'] == 'consider_phlebas'

    def test_popular_package(self):
        # TODO
        # Test that a package with > 10 views is marked as 'popular'.
        # Currently the popular logic is in the templates, will have to move
        # that into the logic and add 'popular': True/False to package dicts
        # to make this testable.
        # Also test that a package with < 10 views is not marked as popular.
        # Test what kind of views count towards popularity, recent or total,
        # and which don't.
        pass

    def test_popular_resource(self):
        # TODO
        # Test that a resource with > 10 views is marked as 'popular'.
        # Currently the popular logic is in the templates, will have to move
        # that into the logic and add 'popular': True/False to resource dicts
        # to make this testable.
        # Also test that a resource with < 10 views is not marked as popular.
        # Test what kind of views count towards popularity, recent or total,
        # and which don't.
        pass

    def test_same_user_visiting_different_pages_on_same_day(self):
        # TODO
        # Test that if the same user visits multiple pages on the same say,
        # each visit gets counted (this should not get throttled)
        # (May need to test for packages, resources and pages separately)
        pass

    def test_same_user_visiting_same_page_on_different_days(self):
        # TODO
        # Test that if the same user visits the same page on different days,
        # each visit gets counted (this should not get throttled)
        # (May need to test for packages, resources and pages separately)
        # (Probably need to access the model directly to insert old visits
        # into tracking_raw)
        pass

    def test_posting_bad_data_to_tracking(self):
        # TODO: Test how /_tracking handles unexpected and invalid data.
        pass

    def _export_tracking_summary(self):
        '''Export CKAN's tracking data and return it.

        This simulates calling `paster tracking export` on the command line.

        '''
        # FIXME: Can this be done as more of a functional test where we
        # actually test calling the command and passing the args? By calling
        # the method directly, we're not testing the command-line parsing.
        import ckan.lib.cli
        import ckan.model
        f = tempfile.NamedTemporaryFile()
        ckan.lib.cli.Tracking('Tracking').export_tracking(
            engine=ckan.model.meta.engine, output_filename=f.name)
        lines = [line for line in csv.DictReader(open(f.name, 'r'))]
        return lines

    def test_export(self):
        '''`paster tracking export` should export tracking data for all
        datasets in CSV format.

        Only dataset tracking data is output to CSV file, not resource or page
        views.

        '''
        app = self._get_app()
        sysadmin_user, apikey = self._create_sysadmin(app)

        # Create a couple of packages.
        package_1 = self._create_package(app, apikey)
        package_2 = self._create_package(app, apikey, name='another_package')

        # View the package_1 three times from different IPs.
        url = routes.url_for(controller='package', action='read',
                             id=package_1['name'])
        self._post_to_tracking(app, url, ip='111.222.333.44')
        self._post_to_tracking(app, url, ip='111.222.333.55')
        self._post_to_tracking(app, url, ip='111.222.333.66')

        # View the package_2 twice from different IPs.
        url = routes.url_for(controller='package', action='read',
                             id=package_2['name'])
        self._post_to_tracking(app, url, ip='111.222.333.44')
        self._post_to_tracking(app, url, ip='111.222.333.55')

        self._update_tracking_summary()
        lines = self._export_tracking_summary()

        assert len(lines) == 2
        package_1_data = lines[0]
        assert package_1_data['total views'] == '3'
        assert package_1_data['recent views (last 2 weeks)'] == '3'
        package_2_data = lines[1]
        assert package_2_data['total views'] == '2'
        assert package_2_data['recent views (last 2 weeks)'] == '2'

    def test_tracking_urls_with_languages(self):
        # TODO
        # Test that posting to eg /de/dataset/foo is counted the same as
        # /dataset/foo.
        # May need to test for dataset pages, resource previews, resource
        # downloads, and other page views separately.
        pass

    def test_templates_tracking_enabled(self):
        # TODO
        # Test the the page view tracking JS is in the templates when
        # ckan.tracking_enabled = true.
        # Test that the sort by populatiy option is shown on the datasets page.
        pass

    def test_templates_tracking_disabled(self):
        # TODO
        # Test the the page view tracking JS is not in the templates when
        # ckan.tracking_enabled = false.
        # Test that the sort by populatiy option is not on the datasets page.
        pass

    def test_tracking_disabled(self):
        # TODO
        # Just to make sure, set ckan.tracking_enabled = false and then post
        # a bunch of stuff to /_tracking and test that no tracking data is
        # recorded. Maybe /_tracking should return something other than 200,
        # as well.
        # Could also test that 'tracking_summary' is _not_ in package and
        # resource dicts from api when tracking is disabled.
        pass

########NEW FILE########
__FILENAME__ = test_upload
import os
import paste.fixture
from pylons import config

from ckan.config.middleware import make_app
from ckan.tests import conf_dir, url_for, CreateTestData
import ckan.model as model


class TestStorageController:
    @classmethod
    def setup_class(cls):
        cls._original_config = config.copy()
        config['ckan.storage.directory'] = '/tmp'
        wsgiapp = make_app(config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        config.clear()
        config.update(cls._original_config)
        model.Session.remove()
        model.repo.rebuild_db()


    def test_03_authorization_wui(self):
        url = url_for('storage_upload')
        res = self.app.get(url, status=[200] )
        if res.status == 302:
            res = res.follow()
            assert 'Login' in res, res

    def test_04_index(self):
        extra_environ = {'REMOTE_USER': 'tester'}
        url = url_for('storage_upload')
        out = self.app.get(url, extra_environ=extra_environ)
        assert 'Upload' in out, out
        #assert 'action="https://commondatastorage.googleapis.com/ckan' in out, out
        #assert 'key" value="' in out, out
        #assert 'policy" value="' in out, out
        #assert 'failure_action_redirect' in out, out
        #assert 'success_action_redirect' in out, out

        url = url_for('storage_upload', filepath='xyz.txt')
        out = self.app.get(url, extra_environ=extra_environ)
        assert 'file/xyz.txt' in out, out

    # TODO: test file upload itself


########NEW FILE########
__FILENAME__ = test_user
from routes import url_for
from nose.tools import assert_equal
from pylons import config
import hashlib

from ckan.tests import search_related, CreateTestData
from ckan.tests.html_check import HtmlCheckMethods
from ckan.tests.pylons_controller import PylonsTestCase
from ckan.tests.mock_mail_server import SmtpServerHarness
import ckan.model as model
from base import FunctionalTestCase
from ckan.lib.mailer import get_reset_link, create_reset_key

class TestUserController(FunctionalTestCase, HtmlCheckMethods, PylonsTestCase, SmtpServerHarness):
    @classmethod
    def setup_class(cls):
        smtp_server = config.get('smtp.test_server')
        if smtp_server:
            host, port = smtp_server.split(':')
            port = int(port) + int(str(hashlib.md5(cls.__name__).hexdigest())[0], 16)
            config['smtp.test_server'] = '%s:%s' % (host, port)

        PylonsTestCase.setup_class()
        SmtpServerHarness.setup_class()
        CreateTestData.create()

        # make 3 changes, authored by annafan
        for i in range(3):
            rev = model.repo.new_revision()
            pkg = model.Package.by_name(u'annakarenina')
            pkg.notes = u'Changed notes %i' % i
            rev.author = u'annafan'
            model.repo.commit_and_remove()

        CreateTestData.create_user('unfinisher', about='<a href="http://unfinished.tag')
        CreateTestData.create_user('uncloser', about='<a href="http://unclosed.tag">')
        CreateTestData.create_user('spammer', about=u'<a href="http://mysite">mysite</a> <a href=\u201dhttp://test2\u201d>test2</a>')
        CreateTestData.create_user('spammer2', about=u'<a href="http://spamsite1.com\u201d>spamsite1</a>\r\n<a href="http://www.spamsite2.com\u201d>spamsite2</a>\r\n')

    @classmethod
    def teardown_class(self):
        # clear routes 'id' so that next test to run doesn't get it
        self.app.get(url_for(controller='user', action='login', id=None))
        SmtpServerHarness.teardown_class()
        model.repo.rebuild_db()

    def teardown(self):
        # just ensure we're not logged in
        self.app.get('/user/logout')

    def test_user_read(self):
        user = model.User.by_name(u'annafan')
        offset = '/user/%s' % user.id
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'annafan' in res, res
        assert 'Logged in' not in main_res, main_res
        assert 'checkpoint:is-myself' not in main_res, main_res
        assert 'about' in main_res, main_res
        assert 'I love reading Annakarenina' in res, main_res
        self.check_named_element(res, 'a',
                                 'http://anna.com',
                                 'target="_blank"',
                                 'rel="nofollow"')
        assert 'Edit Profile' not in main_res, main_res

    def test_user_delete_redirects_to_user_index(self):
        user = CreateTestData.create_user('a_user')
        url = url_for(controller='user', action='delete', id=user.id)
        extra_environ = {'REMOTE_USER': 'testsysadmin'}

        redirect_url = url_for(controller='user', action='index',
                qualified=True)
        res = self.app.get(url, status=302, extra_environ=extra_environ)

        assert user.is_deleted(), user
        assert res.header('Location').startswith(redirect_url), res.header('Location')

    def test_user_delete_by_unauthorized_user(self):
        user = model.User.by_name(u'annafan')
        url = url_for(controller='user', action='delete', id=user.id)
        extra_environ = {'REMOTE_USER': 'an_unauthorized_user'}

        self.app.get(url, status=401, extra_environ=extra_environ)

    def test_user_read_without_id(self):
        offset = '/user/'
        res = self.app.get(offset, status=302)

    def test_user_read_me_without_id(self):
        offset = '/user/me'
        res = self.app.get(offset, status=302)

    def test_user_read_without_id_but_logged_in(self):
        user = model.User.by_name(u'annafan')
        offset = '/user/annafan'
        res = self.app.get(offset, status=200, extra_environ={'REMOTE_USER': str(user.name)})
        main_res = self.main_div(res)
        assert 'annafan' in main_res, main_res
        assert 'checkpoint:is-myself' in main_res, main_res

    def test_user_read_logged_in(self):
        user = model.User.by_name(u'annafan')
        offset = '/user/%s' % user.id
        res = self.app.get(offset, extra_environ={'REMOTE_USER': str(user.name)})
        main_res = self.main_div(res)
        assert 'annafan' in res, res
        assert 'checkpoint:is-myself' in main_res, main_res
        assert 'Edit Profile' in main_res, main_res


    def test_user_login_page(self):
        offset = url_for(controller='user', action='login', id=None)
        res = self.app.get(offset, status=200)
        assert 'Login' in res, res
        assert 'Please click your account provider' in res, res
        assert 'Forgot your password?' in res, res
        assert 'Don\'t have an OpenID' in res, res

    def test_logout(self):
        res = self.app.get('/user/_logout')
        res2 = res.follow()
        while res2.status == 302:
            res2 = res2.follow()
        assert 'You have logged out successfully.' in res2, res2

    def _get_cookie_headers(self, res):
        # For a request response, returns the Set-Cookie header values.
        cookie_headers = []
        for key, value in res.headers:
            if key == 'Set-Cookie':
                cookie_headers.append(value)
        return cookie_headers

    def test_login(self):
        # create test user
        username = u'testlogin'
        password = u'letmein'
        CreateTestData.create_user(name=username,
                                   password=password)
        user = model.User.by_name(username)

        # do the login
        offset = url_for(controller='user', action='login')
        res = self.app.get(offset)
        fv = res.forms['login']
        fv['login'] = str(username)
        fv['password'] = str(password)
        fv['remember'] = False
        res = fv.submit()

        # check cookies set
        cookies = self._get_cookie_headers(res)
        assert cookies
        for cookie in cookies:
            assert not 'max-age' in cookie.lower(), cookie

        # first get redirected to user/logged_in
        assert_equal(res.status, 302)
        assert res.header('Location').startswith('http://localhost/user/logged_in') or \
               res.header('Location').startswith('/user/logged_in')

        # then get redirected to user's dashboard
        res = res.follow()
        res = res.follow()
        assert_equal(res.status, 302)
        assert res.header('Location').startswith('http://localhost/dashboard') or \
               res.header('Location').startswith('/dashboard')
        res = res.follow()
        assert_equal(res.status, 200)
        assert 'checkpoint:my-dashboard' in res.body

        # check user object created
        user = model.User.by_name(username)
        assert user
        assert_equal(user.name, username)
        assert len(user.apikey) == 36

        # check cookie created
        cookie = res.request.environ['HTTP_COOKIE']
        assert 'auth_tkt=' in cookie, cookie
        assert 'testlogin!userid_type:unicode' in cookie, cookie

        # navigate to another page and check username still displayed
        res = res.click('Search')
        assert 'testlogin' in res.body, res.body

    def test_login_remembered(self):
        # create test user
        username = u'testlogin2'
        password = u'letmein'
        CreateTestData.create_user(name=username,
                                   password=password)
        user = model.User.by_name(username)

        # do the login
        offset = url_for(controller='user', action='login')
        res = self.app.get(offset)
        fv = res.forms['login']
        fv['login'] = str(username)
        fv['password'] = str(password)
        fv['remember'] = True
        res = fv.submit()

        # check cookies set
        cookies = self._get_cookie_headers(res)
        assert cookies
        # check cookie is remembered via Max-Age and Expires
        # (both needed for cross-browser compatibility)
        for cookie in cookies:
            assert 'Max-Age=63072000;' in cookie, cookie
            assert 'Expires=' in cookie, cookie

    def test_login_wrong_password(self):
        # create test user
        username = u'testloginwrong'
        password = u'letmein'
        CreateTestData.create_user(name=username,
                                   password=password)
        user = model.User.by_name(username)

        # do the login
        offset = url_for(controller='user', action='login')
        res = self.app.get(offset)
        fv = res.forms['login']
        fv['login'] = username
        fv['password'] = 'wrong_password'
        res = fv.submit()

        # first get redirected to logged_in
        assert_equal(res.status, 302)
        assert res.header('Location').startswith('http://localhost/user/logged_in') or \
               res.header('Location').startswith('/user/logged_in')

        # then get redirected to login
        res = res.follow()
        res = res.follow()
        assert_equal(res.status, 302)
        assert res.header('Location').startswith('http://localhost/user/login') or \
               res.header('Location').startswith('/user/login')
        res = res.follow()
        assert_equal(res.status, 200)
        assert 'Login failed. Bad username or password.' in res.body
        assert 'Login:' in res.body

    def test_relogin(self):
        '''Login as user A and then (try to) login as user B (without
        logout). #1799.'''
        # create test users A & B
        password = u'letmein'
        CreateTestData.create_user(name=u'user_a',
                                   password=password)
        CreateTestData.create_user(name=u'user_b',
                                   password=password)
        userA = model.User.by_name(u'user_a')
        userB = model.User.by_name(u'user_b')

        # do the login
        offset = url_for(controller='user', action='login')
        res = self.app.get(offset)
        fv = res.forms['login']
        fv['login'] = 'user_a'
        fv['password'] = str(password)
        res = fv.submit()
        while res.status == 302:
            res = res.follow()
        assert_equal(res.status, 200)

        # login as userB
        offset = url_for(controller='user', action='login')
        res = self.app.get(offset)
        assert not res.forms.has_key('login') # i.e. no login box is presented
        assert 'To register or log in as another user' in res.body, res.body
        assert 'logout' in res.body, res.body

        # Test code left commented - shows the problem if you
        # let people try to login whilst still logged in. #1799
##        fv['login'] = 'user_b'
##        fv['password'] = str(password)
##        res = fv.submit()
##        while res.status == 302:
##            res = res.follow()
##        assert_equal(res.status, 200)

##        offset = url_for(controller='user', action='me')
##        res = self.app.get(offset)
##        assert_equal(res.status, 302)
##        res = res.follow()
##        assert 'user_b' in res

    def test_try_to_register_whilst_logged_in(self):
        '''Login as user A and then (try to) register user B (without
        logout). #1799.'''
        # create user A
        password = u'letmein'
        CreateTestData.create_user(name=u'user_a_',
                                   password=password)
        userA = model.User.by_name(u'user_a_')

        # do the login
        offset = url_for(controller='user', action='login')
        res = self.app.get(offset)
        fv = res.forms['login']
        fv['login'] = 'user_a_'
        fv['password'] = str(password)
        res = fv.submit()
        while res.status == 302:
            res = res.follow()
        assert_equal(res.status, 200)

        # try to register
        offset = url_for(controller='user', action='register')
        res = self.app.get(offset)
        assert not res.forms.has_key('Password') # i.e. no registration form
        assert 'To register or log in as another user' in res.body, res.body
        assert 'logout' in res.body, res.body

    def test_register_whilst_logged_in(self):
        '''Start registration form as user B then in another window login
        as user A, and then try and then submit form for user B. #1799.'''
        # create user A
        password = u'letmein'
        CreateTestData.create_user(name=u'user_a__',
                                   password=password)
        userA = model.User.by_name(u'user_a__')
        # make him a sysadmin, to ensure he is allowed to create a user
        model.add_user_to_role(userA, model.Role.ADMIN, model.System())
        model.repo.commit_and_remove()
        userA = model.User.by_name(u'user_a__')

        # start to register user B
        offset = url_for(controller='user', action='register')
        res = self.app.get(offset)
        fvA = res.forms['user-edit']
        fvA['name'] = 'user_b_'
        fvA['fullname'] = 'User B'
        fvA['email'] = 'user@b.com'
        fvA['password1'] = password
        fvA['password2'] = password

        # login user A
        offset = url_for(controller='user', action='login')
        res = self.app.get(offset)
        fvB = res.forms['login']
        fvB['login'] = 'user_a__'
        fvB['password'] = str(password)
        res = fvB.submit()
        while res.status == 302:
            res = res.follow()
        assert_equal(res.status, 200)

        # finish registration of user B
        res = fvA.submit('save')
        assert_equal(res.status, 200)
        assert 'user_a__</a> is currently logged in' in res.body, res.body
        assert 'User "user_b_" is now registered but you are still logged in as "user_a__" from before'.replace('"', '&#34;') in res.body, res.body
        assert 'logout' in res.body, res.body

        # logout and login as user B
        res = self.app.get('/user/_logout')
        res2 = res.follow()
        while res2.status == 302:
            res2 = res2.follow()
        assert 'You have logged out successfully.' in res2, res2
        offset = url_for(controller='user', action='login')
        res = self.app.get(offset)
        fv = res.forms['login']
        fv['login'] = 'user_b_'
        fv['password'] = str(password)
        res = fv.submit()
        while res.status == 302:
            res = res.follow()
        assert_equal(res.status, 200)

    @search_related
    def test_home_login(self):
        offset = url_for('home')
        res = self.app.get(offset)
        res = res.click('Login')
        assert 'Login to CKAN' in res, res.body

    def test_apikey(self):
        username= u'okfntest'
        user = model.User.by_name(u'okfntest')
        if not user:
            user = model.User(name=u'okfntest')
            model.Session.add(user)
            model.Session.commit()
            model.Session.remove()

        # not logged in
        offset = url_for(controller='user', action='read', id=username)
        res = self.app.get(offset)
        assert not 'API key' in res

        offset = url_for(controller='user', action='read', id='okfntest')
        res = self.app.get(offset, extra_environ={'REMOTE_USER': 'okfntest'})
        assert user.apikey in res, res

    def test_user_create(self):
        # create/register user
        username = 'testcreate'
        fullname = u'Test Create'
        password = u'testpassword'
        email = u'test@test.org'
        assert not model.User.by_name(unicode(username))
        rev_id_before_test = model.repo.youngest_revision().id

        offset = url_for(controller='user', action='register')
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'Register' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = username
        fv['fullname'] = fullname
        fv['email'] = email
        fv['password1'] = password
        fv['password2'] = password
        res = fv.submit('save')

        # view user
        assert res.status == 302, self.main_div(res).encode('utf8')
        res = res.follow()
        if res.status == 302:
            res = res.follow()
        if res.status == 302:
            res = res.follow()
        if res.status == 302:
            res = res.follow()
        assert res.status == 200, res
        main_res = self.main_div(res)
        assert fullname in main_res, main_res

        # check saved user object
        user = model.User.by_name(unicode(username))
        assert user
        assert_equal(user.name, username)
        assert_equal(user.fullname, fullname)
        assert_equal(user.email, email)
        assert user.password

        # no revision should be created - User is not revisioned
        rev_id_after_test = model.repo.youngest_revision().id
        assert_equal(rev_id_before_test, rev_id_after_test)

        # check cookies created
        cookie = res.request.environ['HTTP_COOKIE']
        assert 'auth_tkt=' in cookie, cookie
        assert 'testcreate!userid_type:unicode' in cookie, cookie


    def test_user_create_unicode(self):
        # create/register user
        username = u'testcreate4'
        fullname = u'Test Create\xc2\xa0'
        password = u'testpassword\xc2\xa0'
        email = u'me\xc2\xa0@test.org'
        assert not model.User.by_name(username)

        offset = url_for(controller='user', action='register')
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'Register' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = username
        fv['fullname'] = fullname.encode('utf8')
        fv['email'] = email.encode('utf8')
        fv['password1'] = password.encode('utf8')
        fv['password2'] = password.encode('utf8')
        res = fv.submit('save')

        # view user
        assert res.status == 302, self.main_div(res).encode('utf8')
        res = res.follow()
        if res.status == 302:
            res = res.follow()
        if res.status == 302:
            res = res.follow()
        if res.status == 302:
            res = res.follow()
        assert res.status == 200, res
        main_res = self.main_div(res)
        assert fullname in main_res, main_res

        user = model.User.by_name(unicode(username))
        assert user
        assert_equal(user.name, username)
        assert_equal(user.fullname, fullname)
        assert_equal(user.email, email)
        assert user.password

    def test_user_create_no_name(self):
        # create/register user
        password = u'testpassword'

        offset = url_for(controller='user', action='register')
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'Register' in main_res, main_res
        fv = res.forms['user-edit']
        fv['password1'] = password
        fv['password2'] = password
        res = fv.submit('save')
        assert res.status == 200, res
        main_res = self.main_div(res)
        assert 'Name: Missing value' in main_res, main_res

    def test_user_create_bad_name(self):
        # create/register user
        username = u'%%%%%%' # characters not allowed
        password = 'testpass'

        offset = url_for(controller='user', action='register')
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'Register' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = username
        fv['password1'] = password
        fv['password2'] = password
        res = fv.submit('save')
        assert res.status == 200, res
        main_res = self.main_div(res)
        assert 'The form contains invalid entries' in main_res, main_res
        assert 'Url must be purely lowercase alphanumeric' in main_res
        self.check_named_element(main_res, 'input', 'name="name"', 'value="%s"' % username)

    def test_user_create_existing_name(self):
        # create/register user
        username = u'annafan'
        password = 'testpass'

        offset = url_for(controller='user', action='register')
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'Register' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = username
        fv['password1'] = password
        fv['password2'] = password
        res = fv.submit('save')
        assert res.status == 200, res
        main_res = self.main_div(res)
        assert 'The form contains invalid entries' in main_res, main_res
        assert 'That login name is not available' in main_res
        self.check_named_element(main_res, 'input', 'name="name"', 'value="%s"' % username)

    def test_user_create_bad_password(self):
        # create/register user
        username = 'testcreate2'
        password = u'a' # too short

        offset = url_for(controller='user', action='register')
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'Register' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = username
        fv['password1'] = password
        fv['password2'] = password
        res = fv.submit('save')
        assert res.status == 200, res
        main_res = self.main_div(res)
        assert 'password must be 4 characters or longer' in main_res, main_res
        self.check_named_element(main_res, 'input', 'name="name"', 'value="%s"' % username)

    def test_user_create_without_password(self):
        # create/register user
        username = 'testcreate3'
        user = model.User.by_name(unicode(username))

        offset = url_for(controller='user', action='register')
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'Register' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = username
        # no password
        res = fv.submit('save')
        assert res.status == 200, res
        main_res = self.main_div(res)
        assert 'Password: Please enter both passwords' in main_res, main_res
        self.check_named_element(main_res, 'input', 'name="name"', 'value="%s"' % username)

    def test_user_create_only_one_password(self):
        # create/register user
        username = 'testcreate4'
        password = u'testpassword'
        user = model.User.by_name(unicode(username))

        offset = url_for(controller='user', action='register')
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'Register' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = username
        fv['password1'] = password
        # Only password1
        res = fv.submit('save')
        assert res.status == 200, res
        main_res = self.main_div(res)
        assert 'Password: Please enter both passwords' in main_res, main_res
        self.check_named_element(main_res, 'input', 'name="name"', 'value="%s"' % username)

    def test_user_create_invalid_password(self):
        # create/register user
        username = 'testcreate4'
        password = u'tes' # Too short
        user = model.User.by_name(unicode(username))

        offset = url_for(controller='user', action='register')
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'Register' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = username
        fv['password1'] = password
        fv['password2'] = password
        res = fv.submit('save')
        assert res.status == 200, res
        main_res = self.main_div(res)
        assert 'Password: Your password must be 4 characters or longer' in main_res, main_res
        self.check_named_element(main_res, 'input', 'name="name"', 'value="%s"' % username)

    def test_user_create_missing_parameters(self):
        # create/register user
        username = 'testcreate4'
        user = model.User.by_name(unicode(username))
        password = u'testpassword'

        offset = url_for(controller='user', action='register')
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert 'Register' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = username
        fv['password1'] = password
        fv['password2'] = password
        del fv.fields['email']
        res = fv.submit('save')
        assert "Errors in form" in res.body
        assert "Email: Missing value" in res.body

    def test_user_edit(self):
        # create user
        username = 'testedit'
        about = u'Test About'
        user = model.User.by_name(unicode(username))
        if not user:
            model.Session.add(model.User(name=unicode(username), about=about,
                email=u'me@test.org',
                password='letmein'))
            model.repo.commit_and_remove()
            user = model.User.by_name(unicode(username))
        rev_id_before_test = model.repo.youngest_revision().id

        # edit
        new_about = u'Changed about'
        new_password = u'testpass'
        new_openid = u'http://mynewopenid.com/'
        offset = url_for(controller='user', action='edit', id=user.id)
        res = self.app.get(offset, status=200, extra_environ={'REMOTE_USER':username})
        main_res = self.main_div(res)
        assert 'Edit User: ' in main_res, main_res
        assert about in main_res, main_res
        fv = res.forms['user-edit']
        fv['about'] = new_about
        fv['openid'] = new_openid
        fv['password1'] = new_password
        fv['password2'] = new_password

        # commit
        res = fv.submit('save', extra_environ={'REMOTE_USER':username})
        assert res.status == 302, self.main_div(res).encode('utf8')
        res = res.follow()
        main_res = self.main_div(res)
        assert 'testedit' in main_res, main_res
        assert new_about in main_res, main_res

        updated_user = model.User.by_name(unicode(username))
        assert_equal(updated_user.openid, new_openid)

        # read, not logged in
        offset = url_for(controller='user', action='read', id=user.id)
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert new_about in main_res, main_res

        # no revision should be created - User is not revisioned
        rev_id_after_test = model.repo.youngest_revision().id
        assert_equal(rev_id_before_test, rev_id_after_test)

    def test_user_edit_no_password(self):
        # create user
        username = 'testedit2'
        about = u'Test About'
        user = model.User.by_name(unicode(username))
        if not user:
            model.Session.add(model.User(name=unicode(username), about=about,
                email=u'me@test.org',
                password='letmein'))
            model.repo.commit_and_remove()
            user = model.User.by_name(unicode(username))

        old_password = user.password

        # edit
        new_about = u'Changed about'
        offset = url_for(controller='user', action='edit', id=user.id)
        res = self.app.get(offset, status=200, extra_environ={'REMOTE_USER':username})
        main_res = self.main_div(res)
        assert 'Edit User: ' in main_res, main_res
        assert about in main_res, main_res
        fv = res.forms['user-edit']
        fv['about'] = new_about
        fv['password1'] = ''
        fv['password2'] = ''

        # commit
        res = fv.submit('save', extra_environ={'REMOTE_USER':username})
        assert res.status == 302, self.main_div(res).encode('utf8')
        res = res.follow()
        main_res = self.main_div(res)
        assert 'testedit2' in main_res, main_res
        assert new_about in main_res, main_res

        # read, not logged in
        offset = url_for(controller='user', action='read', id=user.id)
        res = self.app.get(offset, status=200)
        main_res = self.main_div(res)
        assert new_about in main_res, main_res

        updated_user = model.User.by_name(unicode(username))
        new_password = updated_user.password

        # Ensure password has not changed
        assert old_password == new_password

    def test_user_edit_no_name(self):
        # create user
        username = 'testedit3'
        about = u'Test About'
        user = model.User.by_name(unicode(username))
        if not user:
            model.Session.add(model.User(name=unicode(username), about=about,
                email=u'me@test.org',
                password='letmein'))
            model.repo.commit_and_remove()
            user = model.User.by_name(unicode(username))

        old_password = user.password

        # edit
        offset = url_for(controller='user', action='edit', id=user.id)
        res = self.app.get(offset, status=200, extra_environ={'REMOTE_USER':username})
        main_res = self.main_div(res)
        assert 'Edit User: ' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = ''

        # commit
        res = fv.submit('save', extra_environ={'REMOTE_USER':username})
        assert res.status == 200
        main_res = self.main_div(res)
        assert 'Name: Missing value' in main_res, main_res

    def test_user_edit_existing_user_name(self):
        # create user
        username = 'testedit3'
        about = u'Test About'
        user = model.User.by_name(unicode(username))
        if not user:
            model.Session.add(model.User(name=unicode(username), about=about,
                email=u'me@test.org',
                password='letmein'))
            model.repo.commit_and_remove()
            user = model.User.by_name(unicode(username))

        # edit
        offset = url_for(controller='user', action='edit', id=user.id)
        res = self.app.get(offset, status=200, extra_environ={'REMOTE_USER':username})
        main_res = self.main_div(res)
        assert 'Edit User: ' in main_res, main_res
        fv = res.forms['user-edit']
        fv['name'] = 'annafan'

        # commit
        res = fv.submit('save', extra_environ={'REMOTE_USER':username})
        assert res.status == 200
        main_res = self.main_div(res)
        assert 'Name: That login name is not available' in main_res, main_res

    def test_user_edit_no_user(self):
        offset = url_for(controller='user', action='edit', id=None)
        res = self.app.get(offset, status=400)
        assert 'No user specified' in res, res

    def test_user_edit_unknown_user(self):
        offset = url_for(controller='user', action='edit', id='unknown_person')
        res = self.app.get(offset, status=302) # redirect to login page
        res = res.follow()
        assert 'Login' in res, res

    def test_user_edit_not_logged_in(self):
        # create user
        username = 'testedit'
        about = u'Test About'
        user = model.User.by_name(unicode(username))
        if not user:
            model.Session.add(model.User(name=unicode(username), about=about,
                                         password='letmein'))
            model.repo.commit_and_remove()
            user = model.User.by_name(unicode(username))

        offset = url_for(controller='user', action='edit', id=username)
        res = self.app.get(offset, status=302)

    def test_edit_spammer(self):
        # create user
        username = 'testeditspam'
        about = u'Test About <a href="http://spamsite.net">spamsite</a>'
        user = model.User.by_name(unicode(username))
        if not user:
            model.Session.add(model.User(name=unicode(username), about=about,
                                         password='letmein'))
            model.repo.commit_and_remove()
            user = model.User.by_name(unicode(username))

        # edit
        offset = url_for(controller='user', action='edit', id=user.id)
        res = self.app.get(offset, status=200, extra_environ={'REMOTE_USER':username})
        main_res = self.main_div(res)
        assert 'Edit User: ' in main_res, main_res
        assert 'Test About &lt;a href="http://spamsite.net"&gt;spamsite&lt;/a&gt;' in main_res, main_res
        fv = res.forms['user-edit']
        # commit
        res = fv.submit('save', extra_environ={'REMOTE_USER':username})
        assert res.status == 200, res.status
        main_res = self.main_div(res)
        assert 'looks like spam' in main_res, main_res
        assert 'Edit User: ' in main_res, main_res

    def test_login_openid_error(self):
        # comes back as a params like this:
        # e.g. /user/login?error=Error%20in%20discovery:%20Error%20fetching%20XRDS%20document:%20(6,%20%22Couldn't%20resolve%20host%20'mysite.myopenid.com'%22)
        res = self.app.get("/user/login?error=Error%20in%20discovery:%20Error%20fetching%20XRDS%20document:%20(6,%20%22Couldn't%20resolve%20host%20'mysite.myopenid.com'%22")
        assert "Couldn&#39;t resolve host" in res, res

    def _login_openid(self, res):
        # this requires a valid account on some openid provider
        # (or for us to stub an open_id provider ...)
        assert 'Please Sign In' in res
        username = u'http://okfntest.myopenid.com'
        fv = res.forms['user-login']
        fv['passurl'] =  username
        web.submit()
        web.code(200)
        assert 'You must sign in to authenticate to' in res
        assert username in res
        fv['password'] =  u'okfntest'
        res = fv.submit()
        assert 'Please carefully verify whether you wish to trust' in res
        fv = res.forms[0]
        res = fv.submit('allow_once')
        # at this point we should return
        # but for some reason this does not work ...
        return res

    def test_request_reset_user_password_link_user_incorrect(self):
        offset = url_for(controller='user',
                         action='request_reset')
        res = self.app.get(offset)
        fv = res.forms['user-password-reset']
        fv['user'] = 'unknown'
        res = fv.submit()
        assert 'No such user: unknown' in res, res # error

    def test_request_reset_user_password_using_search(self):
        offset = url_for(controller='user',
                         action='request_reset')
        CreateTestData.create_user(name='larry1', fullname='kittens')
        CreateTestData.create_user(name='larry2', fullname='kittens')
        res = self.app.get(offset)
        fv = res.forms['user-password-reset']
        fv['user'] = 'kittens'
        res = fv.submit()
        assert '&#34;kittens&#34; matched several users' in res, res
        assert 'larry1' not in res, res
        assert 'larry2' not in res, res

        res = self.app.get(offset)
        fv = res.forms['user-password-reset']
        fv['user'] = ''
        res = fv.submit()
        assert 'No such user:' in res, res

        res = self.app.get(offset)
        fv = res.forms['user-password-reset']
        fv['user'] = 'l'
        res = fv.submit()
        assert 'No such user:' in res, res

    def test_reset_user_password_link(self):
        # Set password
        CreateTestData.create_user(name='bob', email='bob@bob.net', password='test1')

        # Set password to something new
        model.User.by_name(u'bob').password = 'test2'
        model.repo.commit_and_remove()
        test2_encoded = model.User.by_name(u'bob').password
        assert test2_encoded != 'test2'
        assert model.User.by_name(u'bob').password == test2_encoded

        # Click link from reset password email
        create_reset_key(model.User.by_name(u'bob'))
        reset_password_link = get_reset_link(model.User.by_name(u'bob'))
        offset = reset_password_link.replace('http://test.ckan.net', '')
        res = self.app.get(offset)

        # Reset password form
        fv = res.forms['user-reset']
        fv['password1'] = 'test1'
        fv['password2'] = 'test1'
        res = fv.submit('save', status=302)

        # Check a new password is stored
        assert model.User.by_name(u'bob').password != test2_encoded

    def test_perform_reset_user_password_link_key_incorrect(self):
        CreateTestData.create_user(name='jack', password='test1')
        # Make up a key - i.e. trying to hack this
        user = model.User.by_name(u'jack')
        offset = url_for(controller='user',
                         action='perform_reset',
                         id=user.id,
                         key='randomness') # i.e. incorrect
        res = self.app.get(offset, status=403) # error

    def test_perform_reset_user_password_link_key_missing(self):
        CreateTestData.create_user(name='jack', password='test1')
        user = model.User.by_name(u'jack')
        offset = url_for(controller='user',
                         action='perform_reset',
                         id=user.id)  # not, no key specified
        res = self.app.get(offset, status=403) # error


    def test_perform_reset_user_password_link_user_incorrect(self):
        # Make up a key - i.e. trying to hack this
        user = model.User.by_name(u'jack')
        offset = url_for(controller='user',
                         action='perform_reset',
                         id='randomness',  # i.e. incorrect
                         key='randomness')
        res = self.app.get(offset, status=404)

    def test_perform_reset_activates_pending_user(self):
        password = 'password'
        params = { 'password1': password, 'password2': password }
        user = CreateTestData.create_user(name='pending_user',
                                          email='user@email.com')
        user.set_pending()
        create_reset_key(user)
        assert user.is_pending(), user.state

        offset = url_for(controller='user',
                         action='perform_reset',
                         id=user.id,
                         key=user.reset_key)
        res = self.app.post(offset, params=params, status=302)

        user = model.User.get(user.id)
        assert user.is_active(), user

    def test_perform_reset_doesnt_activate_deleted_user(self):
        password = 'password'
        params = { 'password1': password, 'password2': password }
        user = CreateTestData.create_user(name='deleted_user',
                                          email='user@email.com')
        user.delete()
        create_reset_key(user)
        assert user.is_deleted(), user.state

        offset = url_for(controller='user',
                         action='perform_reset',
                         id=user.id,
                         key=user.reset_key)
        res = self.app.post(offset, params=params, status=302)

        user = model.User.get(user.id)
        assert user.is_deleted(), user

########NEW FILE########
__FILENAME__ = html_check
import re
import sgmllib

import paste.fixture


class HtmlCheckMethods(object):
    '''A collection of methods to check properties of a html page, usually
    in the form returned by paster.'''
    
    def named_div(self, div_name, html):
        'strips html to just the <div id="DIV_NAME"> section'
        the_html = self._get_html_from_res(html)
        start_div = the_html.find(u'<div id="%s"' % div_name)
        end_div = the_html.find(u'<!-- #%s -->' % div_name)
        if end_div == -1:
            end_div = the_html.find(u'<!-- /%s -->' % div_name)
        div_html = the_html[start_div:end_div]
        assert div_html
        return div_html

    def main_div(self, html):
        'strips html to just the <div id="main"> section'
        return self.named_div('main', html)

    def sidebar(self, html):
        'strips html to just the <div id="primary"> section'
        return self.named_div('primary', html)

    def strip_tags(self, res):
        '''Call strip_tags on a TestResponse object to strip any and all HTML and normalise whitespace.'''
        if not isinstance(res, basestring):
            res = res.body.decode('utf-8')
        return Stripper().strip(res)    

    def check_named_element(self, html, tag_name, *html_to_find):
        '''Searches in the html and returns True if it can find a particular
        tag and all its subtags & data which contains all the of the
        html_to_find'''
        named_element_re = re.compile('(<(%(tag)s\w*).*?(>.*?</%(tag)s)?>)' % {'tag':tag_name}) 
        html_str = self._get_html_from_res(html)
        self._check_html(named_element_re, html_str.replace('\n', ''), html_to_find)

    def check_tag_and_data(self, html, *html_to_find):
        '''Searches in the html and returns True if it can find a tag and its
        PC Data immediately following it which contains all the of the
        html_to_find'''
        if not hasattr(self, 'tag_and_data_re'):
            self.tag_and_data_re = re.compile('(<(?P<tagname>\w*)[^>]*>[^<]*?</(?P=tagname)>)')
            # matches "<tag stuff> stuff </tag>"
        self._check_html(self.tag_and_data_re, html, html_to_find)

    def check_tag(self, html, *html_to_find):
        '''Searches in the html and returns True if it can find a tag which
        contains all the of the html_to_find'''
        if not hasattr(self, 'tag_re'):
            self.tag_re = re.compile('(<[^>]*>)')
        self._check_html(self.tag_re, html, html_to_find)

    def _get_html_from_res(self, html):
        if isinstance(html, paste.fixture.TestResponse):
            html_str = html.body.decode('utf8')
        elif isinstance(html, unicode):
            html_str = html
        elif isinstance(html, str):
            html_str = html.decode('utf8')
        else:
            raise TypeError
        return html_str # always unicode

    def _check_html(self, regex_compiled, html, html_to_find):
        html_to_find = [unicode(html_bit) for html_bit in html_to_find]
        partly_matching_tags = []
        html_str = self._get_html_from_res(html)
        for tag in regex_compiled.finditer(html_str):
            found_all=True
            for i, html_bit_to_find in enumerate(html_to_find):
                assert isinstance(html_bit_to_find, (str, unicode)), html_bit_to_find
                html_bit_to_find = unicode(html_bit_to_find)
                find_inverse = html_bit_to_find.startswith('!')
                if (find_inverse and html_bit_to_find[1:] in tag.group()) or \
                   (not find_inverse and html_bit_to_find not in tag.group()):
                    found_all = False
                    if i>0:
                        partly_matching_tags.append(tag.group())
                    break
            if found_all:
                return # found it
        # didn't find it
        if partly_matching_tags:
            assert 0, "Couldn't find %s in html. Closest matches were:\n%s" % (', '.join(["'%s'" % html.encode('utf8') for html in html_to_find]), '\n'.join([tag.encode('utf8') for tag in partly_matching_tags]))
        else:
            assert 0, "Couldn't find %s in html. Tags matched were:\n%s" % (', '.join(["'%s'" % html.encode('utf8') for html in html_to_find]), '\n'.join([tag.group() for tag in regex_compiled.finditer(html_str)]))



class Stripper(sgmllib.SGMLParser):
    '''A simple helper class to cleanly strip HTML from a response.'''
    def __init__(self):
        sgmllib.SGMLParser.__init__(self)

    def strip(self, html):
        self.str = u""
        self.feed(html)
        self.close()
        return u' '.join(self.str.split())

    def handle_data(self, data):
        self.str += data

########NEW FILE########
__FILENAME__ = test_accept
from nose.tools import assert_equal

import ckan.lib.accept as accept

class TestAccept:
    def test_accept_invalid(self):
        ct, markup, ext = accept.parse_header(None)
        assert_equal( ct, "text/html; charset=utf-8")
        assert_equal( markup, True)
        assert_equal( ext, "html")

    def test_accept_invalid2(self):
        ct, markup, ext = accept.parse_header("")
        assert_equal( ct, "text/html; charset=utf-8")
        assert_equal( markup, True)
        assert_equal( ext, "html")

    def test_accept_invalid3(self):
        ct, markup, ext = accept.parse_header("wombles")
        assert_equal( ct, "text/html; charset=utf-8")
        assert_equal( markup, True)
        assert_equal( ext, "html")


    def test_accept_valid(self):
        a = "text/turtle,application/turtle,application/rdf+xml,text/plain;q=0.8,*/*;q=.5"
        ct, markup, ext = accept.parse_header(a)
        assert_equal( ct, "application/rdf+xml; charset=utf-8")
        assert_equal( markup, True)
        assert_equal( ext, "rdf")

    def test_accept_valid2(self):
        a = "text/turtle,application/turtle,application/rdf+xml;q=0.9,text/plain;q=0.8,*/*;q=.5"
        ct, markup, ext = accept.parse_header(a)
        assert_equal( ct, "application/rdf+xml; charset=utf-8")
        assert_equal( markup, True)
        assert_equal( ext, "rdf")

    def test_accept_valid4(self):
        a = "application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5"
        ct, markup, ext = accept.parse_header(a)
        assert_equal( ct, "text/html; charset=utf-8")
        assert_equal( markup, True)
        assert_equal( ext, "html")

    def test_accept_valid5(self):
        a = "application/rdf+xml;q=0.5,application/xhtml+xml,text/html;q=0.9"
        ct, markup, ext = accept.parse_header(a)
        assert_equal( ct, "text/html; charset=utf-8")
        assert_equal( markup, True)
        assert_equal( ext, "html")

    def test_accept_valid6(self):
        a = "application/rdf+xml;q=0.9,application/xhtml+xml,text/html;q=0.5"
        ct, markup, ext = accept.parse_header(a)
        assert_equal( ct, "application/rdf+xml; charset=utf-8")
        assert_equal( markup, True)
        assert_equal( ext, "rdf")

########NEW FILE########
__FILENAME__ = test_alphabet_pagination
import re

from nose.tools import assert_equal

from ckan.tests import *
from ckan.tests import regex_related
from ckan.lib.create_test_data import CreateTestData
from ckan import model
import ckan.lib.helpers as h

other = 'Other'

class TestPages:
    @classmethod
    def setup_class(cls):
        # create data
        model.repo.init_db()
        pkgs = []
        for letter in 'abcd12':
            for i in range(0, 10):
                name = u'testpackage_%s_%s' % (letter, i)
                pkgs.append({
                    'name': u'testpackage_%s_%s' % (letter, i),
                    'title': u'%s Testpackage %s' % (letter, i),
                    })
        cls.num_pkgs = len(pkgs)
        CreateTestData.create_arbitrary(pkgs)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_00_model(self):
        query = model.Session.query(model.Package)
        page = h.AlphaPage(
            collection=query,
            alpha_attribute='title',
            page='A',
            other_text=other,
        )
        assert_equal(page.available, {'Other': 20, 'A': 10, 'C': 10, 'B': 10, 'E': 0, 'D': 10, 'G': 0, 'F': 0, 'I': 0, 'H': 0, 'K': 0, 'J': 0, 'M': 0, 'L': 0, 'O': 0, 'N': 0, 'Q': 0, 'P': 0, 'S': 0, 'R': 0, 'U': 0, 'T': 0, 'W': 0, 'V': 0, 'Y': 0, 'X': 0, 'Z': 0})

    def test_01_package_page(self):
        query = model.Session.query(model.Package)
        page = h.AlphaPage(
            collection=query,
            alpha_attribute='title',
            page='A',
            other_text=other,
        )
        pager = page.pager()
        assert pager.startswith('<div class="pagination pagination-alphabet">'), pager
        assert '<li class="active"><a href="/tag?page=A">A</a></li>' in pager, pager
        url_base = '/packages'
        assert re.search(r'\<li\>\<a href="\/tag\?page=B"\>B\<\/a\>\<\/li\>', pager), pager
        assert re.search(r'\<li class="disabled"\>\<a href="\/tag\?page=E"\>E\<\/a\>\<\/li\>', pager), pager
        assert re.search(r'\<li\>\<a href="\/tag\?page=Other"\>Other\<\/a\>\<\/li\>', pager), pager


    def test_02_package_items(self):
        query = model.Session.query(model.Package)
        page = h.AlphaPage(
            collection=query,
            alpha_attribute='title',
            page='B',
            other_text=other,
        )
        items = page.items
        assert len(items) == 10, items
        for item in items:
            assert item.title.startswith('b'), item.title

    @regex_related
    def test_03_package_other_items(self):
        query = model.Session.query(model.Package)
        page = h.AlphaPage(
            collection=query,
            alpha_attribute='title',
            page=other,
            other_text=other,
        )
        items = page.items
        assert len(items) == 20, [item.title for item in items]
        for item in items:
            assert item.title.startswith('1') or item.title.startswith('2'), item.title

    def test_04_count(self):
        query = model.Session.query(model.Package)
        page = h.AlphaPage(
            collection=query,
            alpha_attribute='title',
            page=other,
            other_text=other,
        )
        assert page.item_count == self.num_pkgs, page.item_count

class TestTooFewToPage:
    @classmethod
    def setup_class(cls):
        # create data
        model.repo.init_db()
        pkgs = []
        for letter in 'abcd12':
            for i in range(0, 1):
                name = u'testpackage_%s_%s' % (letter, i)
                pkgs.append({
                    'name': u'testpackage_%s_%s' % (letter, i),
                    'title': u'%s Testpackage %s' % (letter, i),
                    })
        cls.num_pkgs = len(pkgs)
        CreateTestData.create_arbitrary(pkgs)

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_01_package_page(self):
        query = model.Session.query(model.Package)
        page = h.AlphaPage(
            collection=query,
            alpha_attribute='title',
            page='A',
            other_text=other,
        )
        pager = page.pager()
        assert not pager

    def test_02_package_items(self):
        query = model.Session.query(model.Package)
        page = h.AlphaPage(
            collection=query,
            alpha_attribute='title',
            page='B',
            other_text=other,
        )
        items = page.items
        assert len(items) == self.num_pkgs, items

########NEW FILE########
__FILENAME__ = test_authenticator
import ckan

import ckan.lib.create_test_data as ctd
import ckan.lib.authenticator as authenticator

CreateTestData = ctd.CreateTestData


class TestUsernamePasswordAuthenticator(object):
    @classmethod
    def setup_class(cls):
        auth = authenticator.UsernamePasswordAuthenticator()
        cls.authenticate = auth.authenticate

    @classmethod
    def teardown(cls):
        ckan.model.repo.rebuild_db()

    def test_authenticate_succeeds_if_login_and_password_are_correct(self):
        environ = {}
        password = 'somepass'
        user = CreateTestData.create_user('a_user', **{'password': password})
        identity = {'login': user.name, 'password': password}

        username = self.authenticate(environ, identity)
        assert username == user.name, username

    def test_authenticate_fails_if_user_is_deleted(self):
        environ = {}
        password = 'somepass'
        user = CreateTestData.create_user('a_user', **{'password': password})
        identity = {'login': user.name, 'password': password}
        user.delete()

        assert self.authenticate(environ, identity) is None

    def test_authenticate_fails_if_user_is_pending(self):
        environ = {}
        password = 'somepass'
        user = CreateTestData.create_user('a_user', **{'password': password})
        identity = {'login': user.name, 'password': password}
        user.set_pending()

        assert self.authenticate(environ, identity) is None

    def test_authenticate_fails_if_password_is_wrong(self):
        environ = {}
        user = CreateTestData.create_user('a_user')
        identity = {'login': user.name, 'password': 'wrong-password'}
        assert self.authenticate(environ, identity) is None

    def test_authenticate_fails_if_received_no_login_or_pass(self):
        environ = {}
        identity = {}
        assert self.authenticate(environ, identity) is None

    def test_authenticate_fails_if_received_just_login(self):
        environ = {}
        identity = {'login': 'some-user'}
        assert self.authenticate(environ, identity) is None

    def test_authenticate_fails_if_received_just_password(self):
        environ = {}
        identity = {'password': 'some-password'}
        assert self.authenticate(environ, identity) is None

    def test_authenticate_fails_if_user_doesnt_exist(self):
        environ = {}
        identity = {'login': 'inexistent-user'}
        assert self.authenticate(environ, identity) is None


class TestOpenIDAuthenticator(object):
    @classmethod
    def setup_class(cls):
        auth = authenticator.OpenIDAuthenticator()
        cls.authenticate = auth.authenticate

    @classmethod
    def teardown(cls):
        ckan.model.repo.rebuild_db()

    def test_authenticate_succeeds_if_openid_is_correct(self):
        environ = {}
        openid = 'some-openid-key'
        user = CreateTestData.create_user('a_user', **{'openid': openid})
        identity = {'login': user.name,
                    'repoze.who.plugins.openid.userid': openid}

        username = self.authenticate(environ, identity)
        assert username == user.name, username

    def test_authenticate_fails_if_openid_is_incorrect(self):
        environ = {}
        openid = 'wrong-openid-key'
        user = CreateTestData.create_user('a_user')
        identity = {'login': user.name,
                    'repoze.who.plugins.openid.userid': openid}

        assert self.authenticate(environ, identity) is None

    def test_authenticate_fails_if_user_is_deleted(self):
        environ = {}
        openid = 'some-openid-key'
        user = CreateTestData.create_user('a_user', **{'openid': openid})
        user.delete()
        identity = {'login': user.name,
                    'repoze.who.plugins.openid.userid': openid}

        assert self.authenticate(environ, identity) is None

    def test_authenticate_fails_if_user_is_pending(self):
        environ = {}
        openid = 'some-openid-key'
        user = CreateTestData.create_user('a_user', **{'openid': openid})
        user.set_pending()
        identity = {'login': user.name,
                    'repoze.who.plugins.openid.userid': openid}

        assert self.authenticate(environ, identity) is None

    def test_authenticate_fails_if_user_have_no_openid(self):
        environ = {}
        identity = {}
        assert self.authenticate(environ, identity) is None

########NEW FILE########
__FILENAME__ = test_cli
import os
import csv

from nose.tools import assert_equal

from ckan import model
from ckan.lib.cli import ManageDb,SearchIndexCommand
from ckan.lib.create_test_data import CreateTestData
from ckan.common import json

from ckan.lib.search import index_for,query_for

class TestDb:
    @classmethod
    def setup_class(cls):
        cls.db = ManageDb('db')
        CreateTestData.create()

        # delete warandpeace
        rev = model.repo.new_revision()
        model.Package.by_name(u'warandpeace').delete()
        model.repo.commit_and_remove()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_simple_dump_csv(self):
        csv_filepath = '/tmp/dump.tmp'
        self.db.args = ('simple-dump-csv %s' % csv_filepath).split()
        self.db.simple_dump_csv()
        assert os.path.exists(csv_filepath), csv_filepath
        f_obj = open(csv_filepath, "r")
        reader = csv.reader(f_obj)
        rows = [row for row in reader]
        assert_equal(rows[0][:3], ['id', 'name', 'title'])
        pkg_names = set(row[1] for row in rows[1:])
        assert 'annakarenina' in pkg_names, pkg_names
        assert 'warandpeace' not in pkg_names, pkg_names

    def test_simple_dump_json(self):
        json_filepath = '/tmp/dump.tmp'
        self.db.args = ('simple-dump-json %s' % json_filepath).split()
        self.db.simple_dump_json()
        assert os.path.exists(json_filepath), json_filepath
        f_obj = open(json_filepath, "r")
        rows = json.loads(f_obj.read())
        assert set(rows[0].keys()) > set(('id', 'name', 'title')), rows[0].keys()
        pkg_names = set(row['name'] for row in rows)
        assert 'annakarenina' in pkg_names, pkg_names
        assert 'warandpeace' not in pkg_names, pkg_names

class FakeOptions():
    def __init__(self,**kwargs):
        for key in kwargs:
            setattr(self,key,kwargs[key])

class TestSearch:
    @classmethod
    def setup_class(cls):
        cls.search = SearchIndexCommand('search-index')
        cls.index = index_for(model.Package)
        cls.query = query_for(model.Package)
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_clear_and_rebuild_index(self):

        # Clear index
        self.search.args = ()
        self.search.options = FakeOptions()
        self.search.clear()

        self.query.run({'q':'*:*'})

        assert self.query.count == 0

        # Rebuild index
        self.search.args = ()
        self.search.options = FakeOptions(only_missing=False,force=False,refresh=False,commit_each=False)
        self.search.rebuild()
        pkg_count = model.Session.query(model.Package).filter(model.Package.state==u'active').count()

        self.query.run({'q':'*:*'})

        assert self.query.count == pkg_count

    def test_clear_and_rebuild_only_one(self):

        pkg_count = model.Session.query(model.Package).filter(model.Package.state==u'active').count()

        # Clear index for annakarenina
        self.search.args = ('clear annakarenina').split()
        self.search.options = FakeOptions()
        self.search.clear()

        self.query.run({'q':'*:*'})

        assert self.query.count == pkg_count - 1

        # Rebuild index for annakarenina
        self.search.args = ('rebuild annakarenina').split()
        self.search.options = FakeOptions(only_missing=False,force=False,refresh=False,commit_each=False)
        self.search.rebuild()

        self.query.run({'q':'*:*'})

        assert self.query.count == pkg_count

########NEW FILE########
__FILENAME__ = test_datapreview
# -*- coding: utf-8 -*-
import ckan.lib.datapreview as datapreview


class TestDataPreview():
    def test_compare_domains(self):
        ''' see https://en.wikipedia.org/wiki/Same_origin_policy
        '''
        comp = datapreview.compare_domains
        assert comp(['http://www.okfn.org', 'http://www.okfn.org']) is True
        assert comp(['http://www.okfn.org', 'http://www.okfn.org', 'http://www.okfn.org']) is True
        assert comp(['http://www.OKFN.org', 'http://www.okfn.org', 'http://www.okfn.org/test/foo.html']) is True
        assert comp(['http://okfn.org', 'http://okfn.org']) is True
        assert comp(['www.okfn.org', 'http://www.okfn.org']) is True
        assert comp(['//www.okfn.org', 'http://www.okfn.org']) is True

        assert comp(['http://www.okfn.org', 'https://www.okfn.org']) is False
        assert comp(['http://www.okfn.org:80', 'http://www.okfn.org:81']) is False
        assert comp(['http://www.okfn.org', 'http://www.okfn.de']) is False
        assert comp(['http://de.okfn.org', 'http://www.okfn.org']) is False

        assert comp(['http://de.okfn.org', 'http:www.foo.com']) is False

        assert comp(['httpö://wöwöwö.ckan.dö', 'www.ckän.örg']) is False
        assert comp(['www.ckän.örg', 'www.ckän.örg']) is True

        # Wrong URL. Makes urlparse choke
        assert comp(['http://Server=cda3; Service=sde:sqlserver:cda3; Database=NationalDatasets; User=sde; Version=sde.DEFAULT', 'http://www.okf.org']) is False

########NEW FILE########
__FILENAME__ = test_dictization
from ckan.tests import assert_equal, assert_not_in, assert_in
from pprint import pprint, pformat
from difflib import unified_diff
import ckan.lib.search as search

from ckan.lib.create_test_data import CreateTestData
from ckan import model
from ckan.lib.dictization import (table_dictize,
                              table_dict_save)

from ckan.lib.dictization.model_dictize import (package_dictize,
                                                resource_dictize,
                                                group_dictize,
                                                activity_dictize,
                                                package_to_api1,
                                                package_to_api2,
                                                user_dictize,
                                               )
from ckan.lib.dictization.model_save import (package_dict_save,
                                             resource_dict_save,
                                             group_dict_save,
                                             activity_dict_save,
                                             package_api_to_dict,
                                             group_api_to_dict,
                                             package_tag_list_save,
                                            )
from ckan.logic.action.update import make_latest_pending_package_active
import ckan.logic.action.get


class TestBasicDictize:
    @classmethod
    def setup_class(cls):
        # clean the db so we can run these tests on their own
        model.repo.rebuild_db()
        search.clear()
        CreateTestData.create()

        cls.package_expected = {
            'author': None,
            'author_email': None,
            'extras': [
               {'key': u'genre',
                'state': u'active',
                'value': 'romantic novel'},
               {'key': u'original media', 'state': u'active', 'value': u'book'}],
            'groups': [{'description': u'These are books that David likes.',
                        'name': u'david',
                        'capacity': 'public',
                        'image_url': u'',
                        'image_display_url': u'',
                        'display_name': u"Dave's books",
                        'type': u'group',
                        'state': u'active',
                        'is_organization': False,
                        'title': u"Dave's books",
                        "approval_status": u"approved"},
                       {'description': u'Roger likes these books.',
                        'name': u'roger',
                        'capacity': 'public',
                        'image_url': u'',
                        'image_display_url': u'',
                        'display_name': u"Roger's books",
                        'type': u'group',
                        'state': u'active',
                        'is_organization': False,
                        'title': u"Roger's books",
                        "approval_status": u"approved"}],
            'isopen': True,
            'license_id': u'other-open',
            'license_title': u'Other (Open)',
            'creator_user_id': None,
            'owner_org': None,
            'private': False,
            'organization': None,
            'maintainer': None,
            'maintainer_email': None,
            'type': u'dataset',
            'name': u'annakarenina',
            'notes': u'Some test notes\n\n### A 3rd level heading\n\n**Some bolded text.**\n\n*Some italicized text.*\n\nForeign characters:\nu with umlaut \xfc\n66-style quote \u201c\nforeign word: th\xfcmb\n\nNeeds escaping:\nleft arrow <\n\n<http://ckan.net/>\n\n',
            'relationships_as_object': [],
            'relationships_as_subject': [],
            'resources': [{u'alt_url': u'alt123',
                            u'cache_last_updated': None,
                            u'cache_url': None,
                            u'description': u'Full text. Needs escaping: " Umlaut: \xfc',
                            u'format': u'plain text',
                            u'hash': u'abc123',
                            u'last_modified': None,
                            u'mimetype': None,
                            u'mimetype_inner': None,
                            u'name': None,
                            u'position': 0,
                            u'resource_type': None,
                            u'size': None,
                            u'size_extra': u'123',
                             'url_type': None,
                            u'state': u'active',
                            u'url': u'http://www.annakarenina.com/download/x=1&y=2',
                            u'webstore_last_updated': None,
                            u'webstore_url': None},
                           {u'alt_url': u'alt345',
                            u'cache_last_updated': None,
                            u'cache_url': None,
                            u'description': u'Index of the novel',
                            u'format': u'JSON',
                            u'hash': u'def456',
                            u'last_modified': None,
                            u'mimetype': None,
                            u'mimetype_inner': None,
                            u'name': None,
                            u'position': 1,
                            u'resource_type': None,
                             'url_type': None,
                            u'size': None,
                            u'size_extra': u'345',
                            u'state': u'active',
                            u'url': u'http://www.annakarenina.com/index.json',
                            u'webstore_last_updated': None,
                            u'webstore_url': None}],
            'state': u'active',
            'tags': [{'name': u'Flexible \u30a1',
                        'display_name': u'Flexible \u30a1',
                        'state': u'active'},
                     {'name': u'russian', 'display_name': u'russian',
                         'state': u'active'},
                     {'name': u'tolstoy', 'display_name': u'tolstoy',
                         'state': u'active'}],
            'title': u'A Novel By Tolstoy',
            'url': u'http://www.annakarenina.com',
            'version': u'0.7a',
            'num_tags': 3,
            'num_resources': 2,
            }


    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        model.Session.remove()

    def remove_changable_columns(self, dict):
        for key, value in dict.items():
            if key.endswith('id') and key not in ('license_id', 'creator_user_id'):
                dict.pop(key)
            if key == 'created':
                dict.pop(key)
            if 'timestamp' in key:
                dict.pop(key)
            if key in ['metadata_created','metadata_modified']:
                dict.pop(key)
            if isinstance(value, list):
                for new_dict in value:
                    self.remove_changable_columns(new_dict)
        return dict

    def remove_revision_id(self, dict):
        for key, value in dict.items():
            if key in ('revision_id', 'revision_timestamp',
                       'expired_timestamp', 'expired_id'):
                dict.pop(key)
            if isinstance(value, list):
                for new_dict in value:
                    self.remove_revision_id(new_dict)
        return dict

    def test_01_dictize_main_objects_simple(self):

        context = {"model": model,
                   "session": model.Session}

        ## package
        pkg = model.Session.query(model.Package).filter_by(name='annakarenina').first()
        result = table_dictize(pkg, context)
        self.remove_changable_columns(result)

        expected = {
            'author': None,
            'author_email': None,
            'license_id': u'other-open',
            'creator_user_id': None,
            'maintainer': None,
            'maintainer_email': None,
            'name': u'annakarenina',
            'notes': u'Some test notes\n\n### A 3rd level heading\n\n**Some bolded text.**\n\n*Some italicized text.*\n\nForeign characters:\nu with umlaut \xfc\n66-style quote \u201c\nforeign word: th\xfcmb\n\nNeeds escaping:\nleft arrow <\n\n<http://ckan.net/>\n\n',
            'state': u'active',
            'title': u'A Novel By Tolstoy',
            'type': u'dataset',
            'url': u'http://www.annakarenina.com',
            'owner_org': None,
            'private': False,
            'version': u'0.7a'
        }
        assert result == expected, pprint(result)

        ## resource

        resource = pkg.resource_groups_all[0].resources_all[0]

        result = resource_dictize(resource, context)
        self.remove_changable_columns(result)


        assert result == {
            u'alt_url': u'alt123',
             'cache_last_updated': None,
             'cache_url': None,
             'description': u'Full text. Needs escaping: " Umlaut: \xfc',
             'format': u'plain text',
             'hash': u'abc123',
             'last_modified': None,
             'mimetype': None,
             'mimetype_inner': None,
             'name': None,
             'position': 0,
             'resource_type': None,
             'size': None,
             u'size_extra': u'123',
             'state': u'active',
             'url': u'http://www.annakarenina.com/download/x=1&y=2',
             'url_type': None,
             'webstore_last_updated': None,
             'webstore_url': None
            }, pprint(result)

        ## package extra

        key, package_extras = pkg._extras.popitem()

        result = table_dictize(package_extras, context)
        self.remove_changable_columns(result)

        assert result == {
            'key': u'genre',
            'state': u'active',
            'value': u'romantic novel'
        }, pprint(result)


    def test_02_package_dictize(self):

        context = {"model": model,
                   "session": model.Session}

        model.Session.remove()
        pkg = model.Session.query(model.Package).filter_by(name='annakarenina').first()

        result = package_dictize(pkg, context)
        self.remove_changable_columns(result)

        print "\n".join(unified_diff(pformat(result).split("\n"), pformat(self.package_expected).split("\n")))
        assert sorted(result.values()) == sorted(self.package_expected.values())
        assert result == self.package_expected

    def test_03_package_to_api1(self):

        context = {"model": model,
                 "session": model.Session}

        pkg = model.Session.query(model.Package).filter_by(name='annakarenina').first()

        pprint(package_to_api1(pkg, context))
        pprint(pkg.as_dict())
        asdict = pkg.as_dict()
        asdict['download_url'] = asdict['resources'][0]['url']
        asdict['license_title'] = u'Other (Open)'
        asdict['num_tags'] = 3
        asdict['num_resources'] = 2

        dictize = package_to_api1(pkg, context)
        # the is_dict method doesn't care about organizations
        del dictize['organization']
        assert dictize == asdict

    def test_04_package_to_api1_with_relationship(self):

        context = {"model": model,
                 "session": model.Session}

        create = CreateTestData

        create.create_family_test_data()
        pkg = model.Session.query(model.Package).filter_by(name='homer').one()

        as_dict = pkg.as_dict()
        as_dict['license_title'] = None
        as_dict['num_tags'] = 0
        as_dict['num_resources'] = 0
        dictize = package_to_api1(pkg, context)

        as_dict["relationships"].sort(key=lambda x:x.items())
        dictize["relationships"].sort(key=lambda x:x.items())

        # the is_dict method doesn't care about organizations
        del dictize['organization']
        as_dict_string = pformat(as_dict)
        dictize_string = pformat(dictize)
        print as_dict_string
        print dictize_string

        assert as_dict == dictize, "\n".join(unified_diff(as_dict_string.split("\n"), dictize_string.split("\n")))

    def test_05_package_to_api2(self):

        context = {"model": model,
                 "session": model.Session}

        pkg = model.Session.query(model.Package).filter_by(name='annakarenina').first()

        as_dict = pkg.as_dict(ref_package_by='id', ref_group_by='id')
        dictize = package_to_api2(pkg, context)

        as_dict_string = pformat(as_dict)
        dictize_string = pformat(dictize)
        print as_dict_string
        print dictize_string

        assert package_to_api2(pkg, context) == dictize, "\n".join(unified_diff(as_dict_string.split("\n"), dictize_string.split("\n")))

    def test_06_package_to_api2_with_relationship(self):

        context = {"model": model,
                 "session": model.Session}

        pkg = model.Session.query(model.Package).filter_by(name='homer').one()

        as_dict = pkg.as_dict(ref_package_by='id', ref_group_by='id')
        as_dict['license_title'] = None
        as_dict['num_tags'] = 0
        as_dict['num_resources'] = 0
        dictize = package_to_api2(pkg, context)

        as_dict["relationships"].sort(key=lambda x:x.items())
        dictize["relationships"].sort(key=lambda x:x.items())

        # the is_dict method doesn't care about organizations
        del dictize['organization']
        as_dict_string = pformat(as_dict)
        dictize_string = pformat(dictize)
        print as_dict_string
        print dictize_string

        assert as_dict == dictize, "\n".join(unified_diff(as_dict_string.split("\n"), dictize_string.split("\n")))

    def test_07_table_simple_save(self):

        context = {"model": model,
                 "session": model.Session}

        anna1 = model.Session.query(model.Package).filter_by(name='annakarenina').one()

        anna_dictized = self.remove_changable_columns(table_dictize(anna1, context))

        anna_dictized["name"] = 'annakarenina2'

        model.repo.new_revision()
        table_dict_save(anna_dictized, model.Package, context)
        model.Session.commit()

        pkg = model.Session.query(model.Package).filter_by(name='annakarenina2').one()

        assert self.remove_changable_columns(table_dictize(pkg, context)) == anna_dictized, self.remove_changable_columns(table_dictize(pkg, context))

    def test_08_package_save(self):

        context = {"model": model,
                   "user": 'testsysadmin',
                   "session": model.Session}

        anna1 = model.Session.query(model.Package).filter_by(name='annakarenina').one()



        anna_dictized = self.remove_changable_columns(package_dictize(anna1, context))

        anna_dictized["name"] = u'annakarenina3'

        model.repo.new_revision()
        package_dict_save(anna_dictized, context)
        model.Session.commit()

        pkg = model.Session.query(model.Package).filter_by(name='annakarenina3').one()

        package_dictized = self.remove_changable_columns(package_dictize(pkg, context))

        anna_original = pformat(anna_dictized)
        anna_after_save = pformat(package_dictized)

        assert self.remove_changable_columns(package_dictize(pkg, context)) == anna_dictized, "\n".join(unified_diff(anna_original.split("\n"), anna_after_save.split("\n")))

    def test_09_package_alter(self):

        context = {"model": model,
                   "session": model.Session,
                   "user": 'testsysadmin'
                   }

        anna1 = model.Session.query(model.Package).filter_by(name='annakarenina').one()

        anna_dictized = package_dictize(anna1, context)

        anna_dictized["name"] = u'annakarenina_changed'
        anna_dictized["resources"][0]["url"] = u'http://new_url'

        model.repo.new_revision()

        package_dict_save(anna_dictized, context)
        model.Session.commit()
        model.Session.remove()

        pkg = model.Session.query(model.Package).filter_by(name='annakarenina_changed').one()

        package_dictized = package_dictize(pkg, context)

        resources_revisions = model.Session.query(model.ResourceRevision).filter_by(resource_group_id=anna1.resource_groups_all[0].id).all()

        sorted_resources = sorted(resources_revisions, key=lambda x: (x.revision_timestamp, x.url))[::-1]
        for res in sorted_resources:
            print res.id, res.revision_timestamp, res.expired_timestamp, res.state, res.current
        assert len(sorted_resources) == 3

        anna_original = pformat(anna_dictized)
        anna_after_save = pformat(package_dictized)

        print anna_original
        print anna_after_save

        assert self.remove_changable_columns(anna_dictized) == self.remove_changable_columns(package_dictized)
        assert "\n".join(unified_diff(anna_original.split("\n"), anna_after_save.split("\n")))

    def test_10_package_alter_pending(self):

        context = {'model': model,
                   'session': model.Session,
                   "user": 'testsysadmin',
                   'pending': True}

        anna1 = model.Session.query(model.Package).filter_by(name='annakarenina_changed').one()

        anna_dictized = package_dictize(anna1, context)

        anna_dictized['name'] = u'annakarenina_changed2'
        anna_dictized['resources'][0]['url'] = u'http://new_url2'
        anna_dictized['tags'][0]['name'] = u'new_tag'
        anna_dictized['tags'][0].pop('id') #test if
        anna_dictized['extras'][0]['value'] = u'new_value'

        model.repo.new_revision()
        package_dict_save(anna_dictized, context)
        model.Session.commit()
        model.Session.remove()

        pkgrevisions = model.Session.query(model.PackageRevision).filter_by(id=anna1.id).all()

        sorted_packages = sorted(pkgrevisions, key=lambda x:x.revision_timestamp)[::-1]

        assert len(sorted_packages) == 3
        assert sorted_packages[0].state == 'pending'
        assert sorted_packages[1].state == 'active'
        assert sorted_packages[1].current
        assert sorted_packages[2].state == 'active'

        assert str(sorted_packages[0].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_packages[1].expired_timestamp) != '9999-12-31 00:00:00'
        assert str(sorted_packages[2].expired_timestamp) != '9999-12-31 00:00:00'

        resources_revisions = model.Session.query(model.ResourceRevision).filter_by(resource_group_id=anna1.resource_groups_all[0].id).all()
        sorted_resources = sorted(resources_revisions, key=lambda x: (x.revision_timestamp, x.url))[::-1]

        for pkg in sorted_resources:
            print pkg.url, pkg.id, pkg.revision_timestamp, pkg.expired_timestamp, pkg.state, pkg.current

        assert len(sorted_resources) == 4
        assert sorted_resources[0].state == 'pending'
        assert sorted_resources[1].state == 'active'
        assert sorted_resources[1].current
        assert sorted_resources[2].state == 'active'
        assert sorted_resources[2].current
        assert sorted_resources[3].state == 'active'

        assert str(sorted_resources[0].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_resources[1].expired_timestamp) != '9999-12-31 00:00:00'
        assert str(sorted_resources[2].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_resources[3].expired_timestamp) != '9999-12-31 00:00:00'

        tag_revisions = model.Session.query(model.PackageTagRevision).filter_by(package_id=anna1.id).all()

        sorted_tags = sorted(tag_revisions, key=lambda x: (x.revision_timestamp, x.tag.name))[::-1]

        print [(tag.state, tag.tag.name) for tag in sorted_tags]

        assert len(sorted_tags) == 5, len(sorted_tags)
        assert sorted_tags[0].state == 'pending'            # new_tag
        assert sorted_tags[1].state == 'pending-deleted'    # Flexible
        assert sorted_tags[2].state == 'active'             # tolstoy
        assert sorted_tags[3].state == 'active'             # russian
        assert sorted_tags[4].state == 'active'             # Flexible
        assert sorted_tags[2].current
        assert sorted_tags[3].current
        assert sorted_tags[4].current

        assert str(sorted_tags[0].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[1].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[2].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[3].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[4].expired_timestamp) != '9999-12-31 00:00:00'

        extras_revisions = model.Session.query(model.PackageExtraRevision).filter_by(package_id=anna1.id).all()

        sorted_extras = sorted(extras_revisions,
                               key=lambda x: (x.revision_timestamp, x.key))[::-1]

        assert sorted_extras[0].state == 'pending'
        assert sorted_resources[1].current
        assert sorted_extras[1].state == 'active'
        assert sorted_resources[1].current
        assert sorted_extras[2].state == 'active'

        assert str(sorted_extras[0].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_extras[1].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_extras[2].expired_timestamp) != '9999-12-31 00:00:00'


    def test_11_add_pending(self):

        context = {'model': model,
                   'session': model.Session,
                   "user": 'testsysadmin',
                   'pending': True}

        anna1 = model.Session.query(model.Package).filter_by(name='annakarenina_changed2').one()
        anna_dictized = package_dictize(anna1, context)


        anna_dictized['notes'] = 'wee'
        anna_dictized['resources'].append({
                            'format': u'plain text',
                            'url': u'http://newurl'}
                            )
        anna_dictized['tags'].append({'name': u'newnew_tag'})
        anna_dictized['extras'].append({'key': 'david',
                                        'value': u'new_value'})

        model.repo.new_revision()
        package_dict_save(anna_dictized, context)
        model.Session.commit()
        model.Session.remove()

        resources_revisions = model.Session.query(model.ResourceRevision).filter_by(resource_group_id=anna1.resource_groups_all[0].id).all()

        sorted_resources = sorted(resources_revisions, key=lambda x: (x.revision_timestamp, x.url))[::-1]
        pprint(anna_dictized['resources'])

        for pkg in sorted_resources:
            print pkg.url, pkg.id, pkg.revision_timestamp, pkg.expired_timestamp, pkg.state, pkg.current


        assert len(sorted_resources) == 5, len(sorted_resources)
        assert sorted_resources[0].state == 'pending'
        assert sorted_resources[1].state == 'pending'
        assert sorted_resources[2].current
        assert sorted_resources[2].state == 'active'
        assert sorted_resources[3].current
        assert sorted_resources[3].state == 'active'
        assert sorted_resources[4].state == 'active'

        assert str(sorted_resources[0].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_resources[1].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_resources[2].expired_timestamp) != '9999-12-31 00:00:00'
        assert str(sorted_resources[3].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_resources[4].expired_timestamp) != '9999-12-31 00:00:00'

        tag_revisions = model.Session.query(model.PackageTagRevision).filter_by(package_id=anna1.id).all()

        sorted_tags = sorted(tag_revisions, key=lambda x: (x.revision_timestamp, x.tag.name))[::-1]

        print [(tag.state, tag.tag.name) for tag in sorted_tags]

        assert len(sorted_tags) == 6, len(sorted_tags)
        assert sorted_tags[0].state == 'pending'            # newnew_tag
        assert sorted_tags[1].state == 'pending'            # new_tag
        assert sorted_tags[2].state == 'pending-deleted'    # Flexible
        assert sorted_tags[3].state == 'active'             # tolstoy
        assert sorted_tags[4].state == 'active'             # russian
        assert sorted_tags[5].state == 'active'             # Flexible
        assert sorted_tags[3].current
        assert sorted_tags[4].current
        assert sorted_tags[5].current

        assert str(sorted_tags[0].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[1].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[2].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[3].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[4].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[5].expired_timestamp) != '9999-12-31 00:00:00'

        extras_revisions = model.Session.query(model.PackageExtraRevision).filter_by(package_id=anna1.id).all()

        sorted_extras = sorted(extras_revisions,
                               key=lambda x: (x.revision_timestamp, x.key))[::-1]

        print [(extra.state, extra.key, extra.value) for extra in sorted_extras]

        assert sorted_extras[0].state == 'pending'
        assert sorted_extras[1].state == 'pending'
        assert sorted_extras[2].state == 'active'
        assert sorted_extras[3].state == 'active'

        assert str(sorted_extras[0].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_extras[1].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_extras[2].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_extras[3].expired_timestamp) != '9999-12-31 00:00:00'

    def test_12_make_active(self):

        model.repo.new_revision()
        anna1 = model.Session.query(model.Package).filter_by(name='annakarenina_changed2').one()
        context = {"model": model,
                   "session": model.Session,
                   'user': 'testsysadmin'}

        make_latest_pending_package_active(context, {'id': anna1.id})

        pkgrevisions = model.Session.query(model.PackageRevision).filter_by(id=anna1.id).all()
        sorted_packages = sorted(pkgrevisions, key=lambda x:x.revision_timestamp)[::-1]

        assert len(sorted_packages) == 4
        assert sorted_packages[0].state == 'active', sorted_packages[0].state #was pending
        assert sorted_packages[0].current == True

        assert sorted_packages[1].state == 'pending'
        assert sorted_packages[2].state == 'active'
        assert sorted_packages[3].state == 'active'

        resources_revisions = model.Session.query(model.ResourceRevision).filter_by(resource_group_id=anna1.resource_groups_all[0].id).all()
        sorted_resources = sorted(resources_revisions, key=lambda x: (x.revision_timestamp, x.url))[::-1]

        assert len(sorted_resources) == 5
        for res in sorted_resources:
            print res.id, res.revision_timestamp, res.expired_timestamp, res.state
        assert sorted_resources[0].state == 'active'
        assert sorted_resources[0].current == True
        assert sorted_resources[1].state == 'active'
        assert sorted_resources[1].current == True
        assert sorted_resources[2].state == 'active'
        assert sorted_resources[3].state == 'active'
        assert sorted_resources[3].current == True
        assert sorted_resources[4].state == 'active'

        assert str(sorted_resources[0].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_resources[1].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_resources[2].expired_timestamp) != '9999-12-31 00:00:00'
        assert str(sorted_resources[3].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_resources[4].expired_timestamp) != '9999-12-31 00:00:00'

        tag_revisions = model.Session.query(model.PackageTagRevision).filter_by(package_id=anna1.id).all()

        sorted_tags = sorted(tag_revisions, key=lambda x: (x.revision_timestamp, x.tag.name))[::-1]

        print [(tag.state, tag.tag.name) for tag in sorted_tags]

        assert len(sorted_tags) == 6, len(sorted_tags)
        assert sorted_tags[0].state == 'active'     # newnew_tag
        assert sorted_tags[1].state == 'active'     # new_tag
        assert sorted_tags[2].state == 'deleted'    # Flexible
        assert sorted_tags[3].state == 'active'     # tolstoy
        assert sorted_tags[4].state == 'active'     # russian
        assert sorted_tags[5].state == 'active'     # Flexible
        assert sorted_tags[0].current
        assert sorted_tags[1].current
        assert sorted_tags[2].current
        assert not sorted_tags[5].current

        assert str(sorted_tags[0].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[1].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[2].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[3].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[4].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_tags[5].expired_timestamp) != '9999-12-31 00:00:00'

        extras_revisions = model.Session.query(model.PackageExtraRevision).filter_by(package_id=anna1.id).all()

        sorted_extras = sorted(extras_revisions,
                               key=lambda x: (x.revision_timestamp, x.key))[::-1]

        print [(extra.state, extra.key, extra.value) for extra in sorted_extras]

        assert sorted_extras[0].state == 'active'
        assert sorted_extras[1].state == 'active'
        assert sorted_extras[2].state == 'active'
        assert sorted_extras[3].state == 'active'

        assert str(sorted_extras[0].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_extras[1].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_extras[2].expired_timestamp) == '9999-12-31 00:00:00'
        assert str(sorted_extras[3].expired_timestamp) != '9999-12-31 00:00:00'

    def test_13_get_package_in_past(self):

        context = {'model': model,
                   'session': model.Session}

        anna1 = model.Session.query(model.Package).filter_by(name='annakarenina_changed2').one()

        pkgrevisions = model.Session.query(model.PackageRevision).filter_by(id=anna1.id).all()
        sorted_packages = sorted(pkgrevisions, key=lambda x:x.revision_timestamp)

        context['revision_id'] = sorted_packages[0].revision_id #original state

        first_dictized = self.remove_changable_columns(package_dictize(anna1, context))
        assert self.package_expected == first_dictized

        context['revision_id'] = sorted_packages[1].revision_id #original state

        second_dictized = self.remove_changable_columns(package_dictize(anna1, context))

        first_dictized["name"] = u'annakarenina_changed'
        first_dictized["resources"][0]["url"] = u'http://new_url'

        assert second_dictized == first_dictized

        context['revision_id'] = sorted_packages[2].revision_id #original state
        third_dictized = self.remove_changable_columns(package_dictize(anna1, context))

        second_dictized['name'] = u'annakarenina_changed2'
        second_dictized['resources'][0]['url'] = u'http://new_url2'
        second_dictized['tags'][0]['name'] = u'new_tag'
        second_dictized['tags'][0]['display_name'] = u'new_tag'
        second_dictized['extras'][0]['value'] = u'new_value'
        second_dictized['state'] = 'pending'

        print '\n'.join(unified_diff(pformat(second_dictized).split('\n'), pformat(third_dictized).split('\n')))
        assert second_dictized == third_dictized

        context['revision_id'] = sorted_packages[3].revision_id #original state
        forth_dictized = self.remove_changable_columns(package_dictize(anna1, context))

        third_dictized['notes'] = 'wee'
        third_dictized['resources'].insert(2, {
            u'cache_last_updated': None,
            u'cache_url': None,
            u'description': u'',
            u'format': u'plain text',
            u'hash': u'',
            u'last_modified': None,
            u'mimetype': None,
            u'mimetype_inner': None,
            u'name': None,
            u'position': 2,
            u'resource_type': None,
            u'url_type': None,
            u'size': None,
            u'state': u'active',
            u'url': u'http://newurl',
            u'webstore_last_updated': None,
            u'webstore_url': None})
        third_dictized['num_resources'] = third_dictized['num_resources'] + 1

        third_dictized['tags'].insert(1, {'name': u'newnew_tag', 'display_name': u'newnew_tag', 'state': 'active'})
        third_dictized['num_tags'] = third_dictized['num_tags'] + 1
        third_dictized['extras'].insert(0, {'key': 'david',
                                         'value': u'new_value',
                                         'state': u'active'})
        third_dictized['state'] = 'active'
        third_dictized['state'] = 'active'

        pprint(third_dictized)
        pprint(forth_dictized)

        assert third_dictized == forth_dictized

    def test_14_resource_no_id(self):

        context = {"model": model,
                 "session": model.Session}

        model.repo.new_revision()
        model.Session.commit()

        new_resource = {
            'mimetype': None,
            u'alt_url': u'empty resource group id',
            'hash': u'abc123',
            'description': u'Full text. Needs escaping: " Umlaut: \xfc',
            'format': u'plain text',
            'url': u'http://test_new',
            'cache_url': None,
            'webstore_url': None,
            'cache_last_updated': None,
            'state': u'active',
            'mimetype_inner': None,
            'webstore_last_updated': None,
            'url_type': None,
            'last_modified': None,
            'position': 0,
            'size': None,
            'size_extra': u'123',
            'resource_type': None,
            'name': None}

        model.repo.new_revision()
        resource_dict_save(new_resource, context)
        model.Session.commit()
        model.Session.remove()

        res = model.Session.query(model.Resource).filter_by(url=u'http://test_new').one()

        res_dictized = self.remove_changable_columns(resource_dictize(res, context))

        assert res_dictized == new_resource, res_dictized

    def test_15_api_to_dictize(self):

        context = {"model": model,
                   'api_version': 1,
                 "session": model.Session}

        api_data = {
            'name' : u'testpkg',
            'title': u'Some Title',
            'url': u'http://blahblahblah.mydomain',
            'resources': [ {
                u'url':u'http://blah.com/file2.xml',
                u'format':u'xml',
                u'description':u'Second file',
                u'hash':u'def123',
                u'alt_url':u'alt_url',
                u'size':u'200',
            },
                {
                u'url':u'http://blah.com/file.xml',
                u'format':u'xml',
                u'description':u'Main file',
                u'hash':u'abc123',
                u'alt_url':u'alt_url',
                u'size':u'200',
            },
            ],
            'tags': u'russion novel',
            'license_id': u'gpl-3.0',
            'extras': {
                'genre' : u'horror',
                'media' : u'dvd',
            },
        }

        dictized = package_api_to_dict(api_data, context)

        assert dictized == {'extras': [{'key': 'genre', 'value': u'horror'},
                                       {'key': 'media', 'value': u'dvd'}],
                            'license_id': u'gpl-3.0',
                            'name': u'testpkg',
                            'resources': [{u'alt_url': u'alt_url',
                                          u'description': u'Second file',
                                          u'size': u'200',
                                          u'format': u'xml',
                                          u'hash': u'def123',
                                          u'url': u'http://blah.com/file2.xml'},
                                          {u'alt_url': u'alt_url',
                                          u'description': u'Main file',
                                          u'size': u'200',
                                          u'format': u'xml',
                                          u'hash': u'abc123',
                                          u'url': u'http://blah.com/file.xml'}],
                            'tags': [{'name': u'russion'}, {'name': u'novel'}],
                            'title': u'Some Title',
                            'url': u'http://blahblahblah.mydomain'}

        model.repo.new_revision()

        package_dict_save(dictized, context)
        model.Session.commit()
        model.Session.remove()

        pkg = model.Session.query(model.Package).filter_by(name=u'testpkg').one()

        package_dictized = self.remove_changable_columns(package_dictize(pkg, context))

    def test_16_group_dictized(self):

        context = {"model": model,
                  "session": model.Session}

        simple_group_dict = {'name': 'simple',
                             'title': 'simple',
                             'type': 'organization',
                            }
        model.repo.new_revision()
        group_dict_save(simple_group_dict, context)
        model.Session.commit()
        model.Session.remove()

        context = {"model": model,
                  "session": model.Session}

        group_dict = {'name': 'help',
                      'title': 'help',
                      'approval_status': 'approved',
                      'extras': [{'key': 'genre', 'value': u'"horror"'},
                                 {'key': 'media', 'value': u'"dvd"'}],
                      'packages':[{'name': 'annakarenina2'}],
                      'users':[{'name': 'annafan'}],
                      'groups':[{'name': 'simple'}],
                      'tags':[{'name': 'russian'}]
                      }

        model.repo.new_revision()
        group_dict_save(group_dict, context)
        model.Session.commit()
        model.Session.remove()

        group = model.Session.query(model.Group).filter_by(name=u'help').one()

        context = {"model": model,
                  "session": model.Session,
                  "user": None}

        group_dictized = group_dictize(group, context)

        expected = {'description': u'',
                    'extras': [{'key': u'genre', 'state': u'active', 'value': u'"horror"'},
                               {'key': u'media', 'state': u'active', 'value': u'"dvd"'}],
                    'tags': [{'capacity': u'public', 'display_name': u'russian', 'name': u'russian'}],
                    'groups': [{'description': u'',
                               'capacity' : 'public',
                               'display_name': u'simple',
                               'image_url': u'',
                               'image_display_url': u'',
                               'name': u'simple',
                               'packages': 0,
                               'state': u'active',
                               'is_organization': False,
                               'title': u'simple',
                               'type': u'organization',
                               'approval_status': u'approved'}],
                    'users': [{'about': u'I love reading Annakarenina. My site: http://anna.com',
                              'display_name': u'annafan',
                              'capacity' : 'public',
                              'state': 'active',
                              'sysadmin': False,
                              'email_hash': 'd41d8cd98f00b204e9800998ecf8427e',
                              'fullname': None,
                              'name': u'annafan',
                              'number_administered_packages': 1L,
                              'number_of_edits': 0L,
                              'activity_streams_email_notifications': False,
                              }],
                    'name': u'help',
                    'display_name': u'help',
                    'image_url': u'',
                    'image_display_url': u'',
                    'package_count': 1,
                    'is_organization': False,
                    'packages': [{u'author': None,
                              u'author_email': None,
                              u'creator_user_id': None,
                              u'extras': [],
                              u'groups':[
                                 {u'title': u'help',
                                  u'display_name': u'help',
                                  u'description': u'',
                                  u'name': u'help',
                                  u'image_display_url': u''}
                              ],
                              u'isopen': True,
                              u'license_id': u'other-open',
                              u'license_title': u'Other (Open)',
                              u'maintainer': None,
                              u'maintainer_email': None,
                              u'name': u'annakarenina2',
                              u'notes': u'Some test notes\n\n### A 3rd level heading\n\n**Some bolded text.**\n\n*Some italicized text.*\n\nForeign characters:\nu with umlaut \xfc\n66-style quote \u201c\nforeign word: th\xfcmb\n\nNeeds escaping:\nleft arrow <\n\n<http://ckan.net/>\n\n',
                              u'num_resources': 0,
                              u'num_tags': 0,
                              u'organization': None,
                              u'owner_org': None,
                              u'private': False,
                              u'relationships_as_object': [],
                              u'relationships_as_subject': [],
                              u'resources': [],
                              u'state': u'active',
                              u'tags': [],
                              u'title': u'A Novel By Tolstoy',
                              u'tracking_summary': {u'recent': 0, u'total': 0},
                              u'type': u'dataset',
                              u'url': u'http://www.annakarenina.com',
                              u'version': u'0.7a'},
                    ],
                    'state': u'active',
                    'approval_status': u'approved',
                    'title': u'help',
                    'type': u'group'}
        expected['packages'] = sorted(expected['packages'], key=lambda x: x['name'])
        result = self.remove_changable_columns(group_dictized)
        result['packages'] = sorted(result['packages'], key=lambda x: x['name'])

        assert_equal(sorted(result.keys()), sorted(expected.keys()))
        
        for key in result:
            if key in ('is_organization', 'package_count'):
                continue
            assert_equal(sorted(result[key]), sorted(expected[key]))
        assert_equal(result['package_count'], expected['package_count'])

    def test_17_group_apis_to_dict(self):

        context = {"model": model,
                  "session": model.Session}

        api_group = {
            'name' : u'testgroup',
            'title' : u'Some Group Title',
            'description' : u'Great group!',
            'packages' : [u'annakarenina', u'warandpeace'],
        }


        assert group_api_to_dict(api_group, context) == {'description': u'Great group!',
                                                         'name': u'testgroup',
                                                         'packages': [{'id': u'annakarenina'}, {'id': u'warandpeace'}],
                                                         'title': u'Some Group Title'}, pformat(group_api_to_dict(api_group, context))

    def test_18_package_tag_list_save(self):
        name = u'testpkg18'
        context = {'model': model,
                   'session': model.Session}
        pkg_dict = {'name': name}

        rev = model.repo.new_revision()
        package = table_dict_save(pkg_dict, model.Package, context)

        tag_dicts = [{'name': 'tag1'}, {'name': 'tag2'}]
        package_tag_list_save(tag_dicts, package, context)
        model.repo.commit_and_remove()

        pkg = model.Package.by_name(name)
        assert_equal(set([tag.name for tag in pkg.get_tags()]),
                set(('tag1', 'tag2')))

    def test_19_package_tag_list_save_duplicates(self):
        name = u'testpkg19'
        context = {'model': model,
                   'session': model.Session}
        pkg_dict = {'name': name}

        rev = model.repo.new_revision()
        package = table_dict_save(pkg_dict, model.Package, context)

        tag_dicts = [{'name': 'tag1'}, {'name': 'tag1'}] # duplicate
        package_tag_list_save(tag_dicts, package, context)
        model.repo.commit_and_remove()

        pkg = model.Package.by_name(name)
        assert_equal(set([tag.name for tag in pkg.get_tags()]), set(('tag1',)))

    def test_20_activity_save(self):

        # Add a new Activity object to the database by passing a dict to
        # activity_dict_save()
        context = {"model": model, "session": model.Session}
        user = model.User.by_name(u'tester')
        revision = model.repo.new_revision()
        sent = {
                'user_id': user.id,
                'object_id': user.id,
                'revision_id': revision.id,
                'activity_type': 'changed user'
                }
        activity_dict_save(sent, context)
        model.Session.commit()

        # Retrieve the newest Activity object from the database, check that its
        # attributes match those of the dict we saved.
        got = ckan.logic.action.get.user_activity_list(context,
                {'id': user.id})[0]
        assert got['user_id'] == sent['user_id']
        assert got['object_id'] == sent['object_id']
        assert got['revision_id'] == sent['revision_id']
        assert got['activity_type'] == sent['activity_type']

        # The activity object should also have an ID and timestamp.
        assert got['id']
        assert got['timestamp']

        # We didn't pass in any data so this should be empty.
        assert not got['data']


    def test_21_package_dictization_with_deleted_group(self):
        """
        Ensure that the dictization does not return groups that the dataset has
        been removed from.
        """
        # Create a new dataset and 2 new groups
        model.repo.new_revision()
        pkg = model.Package(name='testing-deleted-groups')
        group_1 = model.Group(name='test-group-1')
        group_2 = model.Group(name='test-group-2')
        model.Session.add(pkg)
        model.Session.add(group_1)
        model.Session.add(group_2)
        model.Session.flush()

        # Add the dataset to group_1, and signal that the dataset used
        # to be a member of group_2 by setting its membership state to 'deleted'
        membership_1 = model.Member(table_id = pkg.id,
                                    table_name = 'package',
                                    group = group_1,
                                    group_id = group_1.id,
                                    state = 'active')

        membership_2 = model.Member(table_id = pkg.id,
                                    table_name = 'package',
                                    group = group_2,
                                    group_id = group_2.id,
                                    state = 'deleted')

        model.Session.add(membership_1)
        model.Session.add(membership_2)
        model.repo.commit()

        # Dictize the dataset
        context = {"model": model,
                   "session": model.Session}

        result = package_dictize(pkg, context)
        self.remove_changable_columns(result)
        assert_not_in('test-group-2', [ g['name'] for g in result['groups'] ])
        assert_in('test-group-1', [ g['name'] for g in result['groups'] ])

    def test_22_user_dictize_as_sysadmin(self):
        '''Sysadmins should be allowed to see certain sensitive data.'''
        context = {
            'model': model,
            'session': model.Session,
            'user': 'testsysadmin',
        }

        user = model.User.by_name('tester')

        user_dict = user_dictize(user, context)

        # Check some of the non-sensitive data
        assert 'name' in user_dict
        assert 'about' in user_dict

        # Check sensitive data is available
        assert 'apikey' in user_dict
        assert 'email' in user_dict

        # Passwords and reset keys should never be available
        assert 'password' not in user_dict
        assert 'reset_key' not in user_dict

    def test_23_user_dictize_as_same_user(self):
        '''User should be able to see their own sensitive data.'''
        context = {
            'model': model,
            'session': model.Session,
            'user': 'tester',
        }

        user = model.User.by_name('tester')

        user_dict = user_dictize(user, context)

        # Check some of the non-sensitive data
        assert 'name' in user_dict
        assert 'about' in user_dict

        # Check sensitive data is available
        assert 'apikey' in user_dict
        assert 'email' in user_dict

        # Passwords and reset keys should never be available
        assert 'password' not in user_dict
        assert 'reset_key' not in user_dict

    def test_24_user_dictize_as_other_user(self):
        '''User should not be able to see other's sensitive data.'''
        context = {
            'model': model,
            'session': model.Session,
            'user': 'annafan',
        }

        user = model.User.by_name('tester')

        user_dict = user_dictize(user, context)

        # Check some of the non-sensitive data
        assert 'name' in user_dict
        assert 'about' in user_dict

        # Check sensitive data is not available
        assert 'apikey' not in user_dict
        assert 'reset_key' not in user_dict
        assert 'email' not in user_dict

        # Passwords should never be available
        assert 'password' not in user_dict

    def test_25_user_dictize_as_anonymous(self):
        '''Anonymous should not be able to see other's sensitive data.'''
        context = {
            'model': model,
            'session': model.Session,
            'user': '',
        }

        user = model.User.by_name('tester')

        user_dict = user_dictize(user, context)

        # Check some of the non-sensitive data
        assert 'name' in user_dict
        assert 'about' in user_dict

        # Check sensitive data is not available
        assert 'apikey' not in user_dict
        assert 'reset_key' not in user_dict
        assert 'email' not in user_dict

        # Passwords should never be available
        assert 'password' not in user_dict

    def test_26_package_dictize_whitespace_strippped_from_title(self):

        context = {"model": model,
                   "session": model.Session}

        pkg = model.Session.query(model.Package).first()
        original_title = pkg.title
        pkg.title = "     whitespace title    \t"
        model.Session.add(pkg)
        model.Session.commit()

        result = package_dictize(pkg, context)
        assert result['title'] == 'whitespace title'
        pkg.title = original_title
        model.Session.add(pkg)
        model.Session.commit()


########NEW FILE########
__FILENAME__ = test_dictization_schema
from pprint import pprint, pformat

from ckan.lib.create_test_data import CreateTestData
from ckan import model
from ckan.lib.dictization.model_dictize import (package_dictize,
                                                group_dictize)
from ckan.logic.schema import (default_create_package_schema,
                               default_update_package_schema,
                               default_group_schema,
                               default_tags_schema)
from ckan.lib.navl.dictization_functions import validate


class TestBasicDictize:
    def setup(self):
        self.context = {'model': model,
                        'session': model.Session}

    @classmethod
    def setup_class(cls):
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        model.Session.remove()

    def remove_changable_columns(self, dict):
        for key, value in dict.items():
            if key.endswith('id') and key != 'license_id':
                dict.pop(key)
            if key == 'created':
                dict.pop(key)

            if isinstance(value, list):
                for new_dict in value:
                    self.remove_changable_columns(new_dict)
        return dict

    def remove_revision_id(self, dict):
        for key, value in dict.items():
            if key == 'revision_id':
                dict.pop(key)
            if isinstance(value, list):
                for new_dict in value:
                    self.remove_revision_id(new_dict)
        return dict

    def test_1_package_schema(self):
        pkg = model.Session.query(model.Package)\
            .filter_by(name='annakarenina')\
            .first()

        package_id = pkg.id
        result = package_dictize(pkg, self.context)
        self.remove_changable_columns(result)

        result['name'] = 'anna2'
        # we need to remove these as they have been added
        del result['relationships_as_object']
        del result['relationships_as_subject']

        converted_data, errors = validate(result,
                                          default_create_package_schema(),
                                          self.context)

        expected_data = {
            'extras': [{'key': u'genre', 'value': u'romantic novel'},
                       {'key': u'original media', 'value': u'book'}],
            'groups': [{u'name': u'david',
                        u'title': u"Dave's books"},
                       {u'name': u'roger',
                        u'title': u"Roger's books"}],
            'license_id': u'other-open',
            'name': u'anna2',
            'type': u'dataset',
            'notes': u'Some test notes\n\n### A 3rd level heading\n\n**Some bolded text.**\n\n*Some italicized text.*\n\nForeign characters:\nu with umlaut \xfc\n66-style quote \u201c\nforeign word: th\xfcmb\n\nNeeds escaping:\nleft arrow <\n\n<http://ckan.net/>\n\n',
            'private': False,
            'resources': [{'alt_url': u'alt123',
                           'description': u'Full text. Needs escaping: " Umlaut: \xfc',
                           'format': u'plain text',
                           'hash': u'abc123',
                           'size_extra': u'123',
                           'url': u'http://www.annakarenina.com/download/x=1&y=2'},
                          {'alt_url': u'alt345',
                           'description': u'Index of the novel',
                           'format': u'JSON',
                           'hash': u'def456',
                           'size_extra': u'345',
                           'url': u'http://www.annakarenina.com/index.json'}],
            'tags': [{'name': u'Flexible \u30a1'},
                     {'name': u'russian'},
                     {'name': u'tolstoy'}],
            'title': u'A Novel By Tolstoy',
            'url': u'http://www.annakarenina.com',
            'version': u'0.7a'
        }

        assert converted_data == expected_data, pformat(converted_data)
        assert not errors, errors

        data = converted_data
        data['name'] = u'annakarenina'
        data.pop("title")
        data["resources"][0]["url"] = 'fsdfafasfsaf'
        data["resources"][1].pop("url")

        converted_data, errors = validate(data,
                                          default_create_package_schema(),
                                          self.context)

        assert errors == {
            'name': [u'That URL is already in use.'],
            'resources': [{}, {'url': [u'Missing value']}]
        }, pformat(errors)

        data["id"] = package_id

        converted_data, errors = validate(data,
                                          default_update_package_schema(),
                                          self.context)

        assert errors == {
            'resources': [{}, {'url': [u'Missing value']}]
        }, pformat(errors)

        data['name'] = '????jfaiofjioafjij'

        converted_data, errors = validate(data,
                                          default_update_package_schema(),
                                          self.context)
        assert errors == {
            'name': [u'Url must be purely lowercase alphanumeric (ascii) '
                     'characters and these symbols: -_'],
            'resources': [{}, {'url': [u'Missing value']}]
        }, pformat(errors)

    def test_2_group_schema(self):
        group = model.Session.query(model.Group).first()
        data = group_dictize(group, self.context)

        # we don't want these here
        del data['groups']
        del data['users']
        del data['tags']
        del data['extras']

        converted_data, errors = validate(data,
                                          default_group_schema(),
                                          self.context)
        group_pack = sorted(group.packages(), key=lambda x: x.id)

        converted_data["packages"] = sorted(converted_data["packages"],
                                            key=lambda x: x["id"])

        expected = {
            'description': u'These are books that David likes.',
            'id': group.id,
            'name': u'david',
            'is_organization': False,
            'type': u'group',
            'image_url': u'',
            'image_display_url': u'',
            'packages': sorted([{'id': group_pack[0].id,
                                 'name': group_pack[0].name,
                                 'title': group_pack[0].title},
                                {'id': group_pack[1].id,
                                 'name': group_pack[1].name,
                                 'title':group_pack[1].title}],
                               key=lambda x: x["id"]),
            'title': u"Dave's books",
            'approval_status': u'approved'
        }

        assert not errors
        assert converted_data == expected, pformat(converted_data)

        data["packages"].sort(key=lambda x: x["id"])
        data["packages"][0]["id"] = 'fjdlksajfalsf'
        data["packages"][1].pop("id")
        data["packages"][1].pop("name")

        converted_data, errors = validate(data,
                                          default_group_schema(),
                                          self.context)
        assert errors == {
            'packages': [{'id': [u'Not found: Dataset']},
                         {'id': [u'Missing value']}]
        }, pformat(errors)

    def test_3_tag_schema_allows_spaces(self):
        """Asserts that a tag name with space is valid"""
        ignored = ""
        data = {
            'name': u'with space',
            'revision_timestamp': ignored,
            'state': ignored
        }
        _, errors = validate(data, default_tags_schema(), self.context)
        assert not errors, str(errors)

    def test_4_tag_schema_allows_limited_punctuation(self):
        """Asserts that a tag name with limited punctuation is valid"""
        ignored = ""
        data = {
            'name': u'.-_',
            'revision_timestamp': ignored,
            'state': ignored
        }
        _, errors = validate(data, default_tags_schema(), self.context)
        assert not errors, str(errors)

    def test_5_tag_schema_allows_capital_letters(self):
        """Asserts that tag names can have capital letters"""
        ignored = ""
        data = {
            'name': u'CAPITALS',
            'revision_timestamp': ignored,
            'state': ignored
        }
        _, errors = validate(data, default_tags_schema(), self.context)
        assert not errors, str(errors)

    def test_6_tag_schema_disallows_most_punctuation(self):
        """Asserts most punctuation is disallowed"""
        not_allowed = r'!?"\'+=:;@#~[]{}()*&^%$,'
        ignored = ""
        data = {
            'revision_timestamp': ignored,
            'state': ignored
        }
        for ch in not_allowed:
            data['name'] = "Character " + ch
            _, errors = validate(data, default_tags_schema(), self.context)
            assert errors, pprint(errors)
            assert 'name' in errors
            error_message = errors['name'][0]
            assert data['name'] in error_message, error_message
            assert "must be alphanumeric" in error_message

    def test_7_tag_schema_disallows_whitespace_other_than_spaces(self):
        """Asserts whitespace characters, such as tabs, are not allowed."""
        not_allowed = '\t\n\r\f\v'
        ignored = ""
        data = {
            'revision_timestamp': ignored,
            'state': ignored
        }
        for ch in not_allowed:
            data['name'] = "Bad " + ch + " character"
            _, errors = validate(data, default_tags_schema(), self.context)
            assert errors, repr(ch)
            assert 'name' in errors
            error_message = errors['name'][0]
            assert data['name'] in error_message, error_message
            assert "must be alphanumeric" in error_message

########NEW FILE########
__FILENAME__ = test_email_notifications
'''Tests for the ckan.lib.email_notifications module.

Note that email_notifications is used by an action function, so most of the
tests for the module are done by testing the action function in
ckan.test.functional.api. This test module contains some additional unit tests.

'''
import datetime

import nose.tools

import ckan.lib.email_notifications as email_notifications
import ckan.logic as logic


def test_string_to_time_delta():
    assert email_notifications.string_to_timedelta('1 day') == (
            datetime.timedelta(days=1))
    assert email_notifications.string_to_timedelta('1  day') == (
            datetime.timedelta(days=1))
    assert email_notifications.string_to_timedelta('2 days') == (
            datetime.timedelta(days=2))
    assert email_notifications.string_to_timedelta('2\tdays') == (
            datetime.timedelta(days=2))
    assert email_notifications.string_to_timedelta('14 days') == (
            datetime.timedelta(days=14))
    assert email_notifications.string_to_timedelta('4:35:00') == (
            datetime.timedelta(hours=4, minutes=35, seconds=00))
    assert email_notifications.string_to_timedelta('4:35:12.087465') == (
            datetime.timedelta(hours=4, minutes=35, seconds=12,
                milliseconds=87, microseconds=465))
    assert email_notifications.string_to_timedelta('1 day, 3:23:34') == (
            datetime.timedelta(days=1, hours=3, minutes=23, seconds=34))
    assert email_notifications.string_to_timedelta('1 day,   3:23:34') == (
            datetime.timedelta(days=1, hours=3, minutes=23, seconds=34))
    assert email_notifications.string_to_timedelta('7 days, 3:23:34') == (
            datetime.timedelta(days=7, hours=3, minutes=23, seconds=34))
    assert email_notifications.string_to_timedelta('7 days,\t3:23:34') == (
            datetime.timedelta(days=7, hours=3, minutes=23, seconds=34))
    assert email_notifications.string_to_timedelta(
            '7 days, 3:23:34.087465') == datetime.timedelta(days=7, hours=3,
                    minutes=23, seconds=34, milliseconds=87, microseconds=465)
    assert email_notifications.string_to_timedelta('.123456') == (
            datetime.timedelta(milliseconds=123, microseconds=456))
    nose.tools.assert_raises(logic.ValidationError,
        email_notifications.string_to_timedelta, 'foobar')

########NEW FILE########
__FILENAME__ = test_field_types
import formalchemy

from ckan.lib.field_types import *
from ckan.tests import *
from unittest import TestCase

class TestDate(TestCase):
    def test_0_parse_timedate(self):
        expected_parse = {
            'form':[
                ('27/2/2008', 'DD/MM/YYYY', [2008, 2, 27]),
                ('27/2/08', 'DD/MM/YYYY', [2008, 2, 27]),
                ('27/2/98', 'DD/MM/YYYY', [1998, 2, 27]),
                ('27-Feb-2008', 'DD/MM/YYYY', [2008, 2, 27]),
                ('2/2008', 'MM/YYYY', [2008, 2]),
                ('Jun-2008', 'MM/YYYY', [2008, 6]),
                ('2008', 'YYYY', [2008]),
                ('13:16 27/2/2008', 'HH:MM DD/MM/YYYY', [2008, 2, 27, 13, 16]),
                ('2/11/67 9:04', 'DD/MM/YYYY HH:MM', [1967, 11, 2, 9, 04]),
                ],
            'db':[
                ('2008', 'YYYY', [2008]),
                ('2008-02-27', 'YYYY-MM-DD', [2008, 2, 27]),
                ],
            }
        expected_fields = ('year', 'month', 'day', 'hour', 'minute')
        for format_type in ('form', 'db'):
            for timedate_str, expected_format, expected_list in expected_parse[format_type]:
                expected_dict = {}
                for index, expected_val in enumerate(expected_list):
                    expected_dict[expected_fields[index]] = expected_val
                expected_dict['readable_format'] = expected_format
                out = DateType.parse_timedate(timedate_str, format_type)
                assert out == expected_dict, '%s value %r gives %r, not %r' % (format_type, timedate_str, out, expected_dict)
        
    def test_1_form_to_db(self):
        expected_form_to_db = [
            ('27/2/2008', '2008-02-27'),
            ('27/2/08', '2008-02-27'),
            ('27/2/98', '1998-02-27'),
            ('27-Feb-2008', '2008-02-27'),
            ('2/2008', '2008-02'),
            ('Jun-2008', '2008-06'),
            ('2008', '2008'),
            ('13:16 27/2/2008', '2008-02-27 13:16'),
            ('9:04 2/11/67', '1967-11-02 09:04'),
            ]
        for form_date, expected_db_date in expected_form_to_db:
            out = DateType.form_to_db(form_date)
            assert out == expected_db_date, 'From %r matched %r, not %r' % (form_date, out, expected_db_date)

    def test_2_form_validator(self):
        valid_dates = ['25/2/2009', '25/Feb/2009', '', ' ', None]
        invalid_dates = ['humpty', '2135', '345', '2000BC', '45/2009',
                         '-2/2009', '35/3/2009', '35/Feb/2009', '25/ABC/2009',
                         '24:03 2/11/67']
        for date_str in valid_dates:
            assert DateType.form_validator(date_str) is None, date_str
        for date_str in invalid_dates:
            self.assertRaises(formalchemy.ValidationError, DateType.form_validator, date_str)
        
    def test_3_db_to_form(self):
        expected_db_to_form = [
            ('2008-02-27 12:20', '12:20 27/2/2008'),
            ('2008-02-27', '27/2/2008'),
            ('2008-02', '2/2008'),
            ('2008', '2008'),
            ('10/2/03', '3/2/2010'),
            ('humpty', 'humpty'), #invalid
            ('27/2/2008', '27/2/2008'), #invalid
            ]
        for db_date, expected_form_date in expected_db_to_form:
            out = DateType.db_to_form(db_date)
            assert out == expected_form_date, 'From %r gives %r, not %r' % (db_date, out, expected_form_date)

    def test_4_iso_to_db(self):
        out = DateType.iso_to_db('Wed, 06 Jan 2010 09:30:00', '%a, %d %b %Y %H:%M:%S')
        assert out == '2010-01-06', out

    def test_5_strip_iso_timezone(self):
        out = DateType.strip_iso_timezone('Wed, 06 Jan 2010 09:30:00 GMT')
        assert out == 'Wed, 06 Jan 2010 09:30:00', out
        out = DateType.strip_iso_timezone('Wed, 06 Jan 2010 09:30:00 +0100')
        assert out == 'Wed, 06 Jan 2010 09:30:00', out


########NEW FILE########
__FILENAME__ = test_hash
from nose.tools import assert_equals

from ckan.lib.hash import get_message_hash, get_redirect

class TestHash:
    @classmethod
    def setup_class(cls):
        global secret
        secret = '42' # so that these tests are repeatable

    def test_get_message_hash(self):
        assert_equals(len(get_message_hash(u'/tag/country-uk')), len('6f58ff51b42e6b2d2e700abd1a14c9699e115c61'))

    def test_get_message_hash_unicode(self):
        assert_equals(len(get_message_hash(u'/tag/biocombust\xedveis')), len('d748fa890eb6a964cd317e6ff62905fad645b43d'))
    

########NEW FILE########
__FILENAME__ = test_helpers
# -*- coding: utf-8 -*-
import datetime
from nose.tools import assert_equal, assert_raises

from pylons import config

from ckan.tests import *
import ckan.lib.helpers as h


WITH_HTML = u'''Data exposed: &mdash;
Size of dump and data set: size?
Notes: this is the classic RDF source but historically has had some problems with RDF correctness.
'''

WITH_UNICODE = u'''[From the project website] This project collects information on China’s foreign aid from the China Commerce Yearbook (中国商务年鉴) and the Almanac of China’s Foreign Economic Relations & Trade (中国对外经济贸易年间), published annually by China’s Ministry of Commerce (MOFCOM). Data is reported for each year between 1990 and 2005, with the exception of 2002, in which year China’s Ministry of Commerce published no project-level data on its foreign aid giving.'''


class TestHelpers(TestController):

    def test_extract_markdown(self):
        assert "Data exposed" in h.markdown_extract(WITH_HTML)
        assert "collects information" in h.markdown_extract(WITH_UNICODE)

    def test_render_datetime(self):
        res = h.render_datetime(datetime.datetime(2008, 4, 13, 20, 40, 20, 123456))
        assert_equal(res, 'April 13, 2008')

    def test_render_datetime_but_from_string(self):
        res = h.render_datetime('2008-04-13T20:40:20.123456')
        assert_equal(res, 'April 13, 2008')

    def test_render_datetime_blank(self):
        res = h.render_datetime(None)
        assert_equal(res, '')

    def test_datetime_to_date_str(self):
        res = datetime.datetime(2008, 4, 13, 20, 40, 20, 123456).isoformat()
        assert_equal(res, '2008-04-13T20:40:20.123456')

    def test_date_str_to_datetime_date_only(self):
        res = h.date_str_to_datetime('2008-04-13')
        assert_equal(res, datetime.datetime(2008, 4, 13))

    def test_date_str_to_datetime(self):
        res = h.date_str_to_datetime('2008-04-13T20:40:20.123456')
        assert_equal(res, datetime.datetime(2008, 4, 13, 20, 40, 20, 123456))

    def test_date_str_to_datetime_without_microseconds(self):
        # This occurs in ckan.net timestamps - not sure how they appeared
        res = h.date_str_to_datetime('2008-04-13T20:40:20')
        assert_equal(res, datetime.datetime(2008, 4, 13, 20, 40, 20))

    def test_date_str_to_datetime_with_timezone(self):
        assert_raises(ValueError,
                      h.date_str_to_datetime,
                      '2008-04-13T20:40:20-01:30')

    def test_date_str_to_datetime_with_timezone_without_colon(self):
        assert_raises(ValueError,
                      h.date_str_to_datetime,
                      '2008-04-13T20:40:20-0130')

    def test_date_str_to_datetime_with_garbage_on_end(self):
        assert_raises(ValueError,
                      h.date_str_to_datetime,
                      '2008-04-13T20:40:20foobar')

    def test_date_str_to_datetime_with_ambiguous_microseconds(self):
        assert_raises(ValueError,
                      h.date_str_to_datetime,
                      '2008-04-13T20:40:20.500')

    def test_time_ago_in_words_from_str(self):
        two_months_ago = datetime.datetime.now() - datetime.timedelta(days=65)
        two_months_ago_str = two_months_ago.isoformat()
        res = h.time_ago_in_words_from_str(two_months_ago_str)
        assert_equal(res, '2 months')

    def test_gravatar(self):
        email = 'zephod@gmail.com'
        expected = ['<a href="https://gravatar.com/"',
                '<img src="//gravatar.com/avatar/7856421db6a63efa5b248909c472fbd2?s=200&amp;d=mm"', '</a>']
        # Hash the email address
        import hashlib
        email_hash = hashlib.md5(email).hexdigest()
        res = h.linked_gravatar(email_hash, 200, default='mm')
        for e in expected:
            assert e in res, (e, res)

    def test_gravatar_config_set_default(self):
        """Test when default gravatar is None, it is pulled from the config file"""
        email = 'zephod@gmail.com'
        default = config.get('ckan.gravatar_default', 'identicon')
        expected = ['<a href="https://gravatar.com/"',
                   '<img src="//gravatar.com/avatar/7856421db6a63efa5b248909c472fbd2?s=200&amp;d=%s"' % default,
                   '</a>']
        # Hash the email address
        import hashlib
        email_hash = hashlib.md5(email).hexdigest()
        res = h.linked_gravatar(email_hash, 200)
        for e in expected:
            assert e in res, (e, res)

    def test_gravatar_encodes_url_correctly(self):
        """Test when the default gravatar is a url, it gets urlencoded"""
        email = 'zephod@gmail.com'
        default = 'http://example.com/images/avatar.jpg'
        expected = ['<a href="https://gravatar.com/"',
                   '<img src="//gravatar.com/avatar/7856421db6a63efa5b248909c472fbd2?s=200&amp;d=http%3A%2F%2Fexample.com%2Fimages%2Favatar.jpg"',
                   '</a>']
        # Hash the email address
        import hashlib
        email_hash = hashlib.md5(email).hexdigest()
        res = h.linked_gravatar(email_hash, 200, default=default)
        for e in expected:
            assert e in res, (e, res)

    def test_parse_rfc_2822_no_timezone_specified(self):
        """
        Parse "Tue, 15 Nov 1994 12:45:26" successfully.

        Assuming it's UTC.
        """
        dt = h.parse_rfc_2822_date('Tue, 15 Nov 1994 12:45:26')
        assert_equal(dt.isoformat(), '1994-11-15T12:45:26+00:00')

    def test_parse_rfc_2822_no_timezone_specified_assuming_local(self):
        """
        Parse "Tue, 15 Nov 1994 12:45:26" successfully.

        Assuming it's local.
        """
        dt = h.parse_rfc_2822_date('Tue, 15 Nov 1994 12:45:26', assume_utc=False)
        assert_equal(dt.isoformat(), '1994-11-15T12:45:26')
        assert_equal(dt.tzinfo, None)

    def test_parse_rfc_2822_gmt_case(self):
        """
        Parse "Tue, 15 Nov 1994 12:45:26 GMT" successfully.

        GMT obs-zone specified
        """
        dt = h.parse_rfc_2822_date('Tue, 15 Nov 1994 12:45:26 GMT')
        assert_equal(dt.isoformat(), '1994-11-15T12:45:26+00:00')

    def test_parse_rfc_2822_with_offset(self):
        """
        Parse "Tue, 15 Nov 1994 12:45:26 +0700" successfully.
        """
        dt = h.parse_rfc_2822_date('Tue, 15 Nov 1994 12:45:26 +0700')
        assert_equal(dt.isoformat(), '1994-11-15T12:45:26+07:00')

    def test_escape_js(self):

        input_str = '{"type":"point", "desc":"Bla bla O\'hara.\\nNew line."}'

        expected_str = '{\\"type\\":\\"point\\", \\"desc\\":\\"Bla bla O\\\'hara.\\\\nNew line.\\"}'

        output_str = h.escape_js(input_str)

        assert_equal(output_str, expected_str)

    def test_get_pkg_dict_extra(self):

        from ckan.lib.create_test_data import CreateTestData
        from ckan import model
        from ckan.logic import get_action

        CreateTestData.create()

        pkg_dict = get_action('package_show')({'model': model, 'user': u'tester'}, {'id': 'annakarenina'})

        assert_equal(h.get_pkg_dict_extra(pkg_dict, 'genre'), 'romantic novel')

        assert_equal(h.get_pkg_dict_extra(pkg_dict, 'extra_not_found'), None)

        assert_equal(h.get_pkg_dict_extra(pkg_dict, 'extra_not_found', 'default_value'), 'default_value')

########NEW FILE########
__FILENAME__ = test_i18n
from nose.tools import assert_equal, assert_raises
from pylons import config, session
import pylons

import ckan.lib.i18n

from ckan.tests.pylons_controller import PylonsTestCase


class TestI18n(PylonsTestCase):

    def handle_request(self, session_language=None, languages_header=[]):
        session['locale'] = session_language
        class FakePylons:
            translator = None
        class FakeRequest:
            # Populated from the HTTP_ACCEPT_LANGUAGE header normally
            languages = languages_header
            # Stores details of the translator
            environ = {'pylons.pylons': FakePylons()}
        request = FakeRequest()
        real_pylons_request = pylons.request
        try:
            pylons.request = request # for set_lang to work
            class FakeTmplContext:
                language = None # gets filled in by handle_request
            tmpl_context = FakeTmplContext()
            ckan.lib.i18n.handle_request(request, tmpl_context)
            return tmpl_context.language # the language that got set
        finally:
            pylons.request = real_pylons_request

    def test_handle_request__default(self):
        assert_equal(self.handle_request(),
                     config['ckan.locale_default'])

## Session no longer used to set languages so test no longer relevant
## see #1653

##    def test_handle_request__session(self):
##        assert_equal(self.handle_request(session_language='fr'),
##                     'fr')

## Browser lang detection disabled - see #1452

##    def test_handle_request__header(self):
##        assert_equal(self.handle_request(languages_header=['de']),
##                     'de')

##    def test_handle_request__header_negotiate(self):
##        # Language so is not an option, so reverts to next one
##        assert_equal(self.handle_request(languages_header=['so_KE', 'de']),
##                     'de')

##    def test_handle_request__header_but_defaults(self):
##        # Language so is not an option, so reverts to default
##        assert_equal(self.handle_request(languages_header=['so_KE']),
##                     'en')

##    def test_handle_request__header_territory(self):
##        # Request for specific version of German ends up simply as de.
##        assert_equal(self.handle_request(languages_header=['fr_CA', 'en']),
##                     'fr')


########NEW FILE########
__FILENAME__ = test_mailer
from nose.tools import assert_equal, assert_raises
from pylons import config
from email.mime.text import MIMEText
import hashlib

import ckan.model as model
import ckan.lib.mailer as mailer
from ckan.tests.pylons_controller import PylonsTestCase
from ckan.tests.mock_mail_server import SmtpServerHarness
from ckan.lib.create_test_data import CreateTestData
from ckan.lib.base import g

class TestMailer(SmtpServerHarness, PylonsTestCase):
    @classmethod
    def setup_class(cls):
        smtp_server = config.get('smtp.test_server')
        if smtp_server:
            host, port = smtp_server.split(':')
            port = int(port) + int(str(hashlib.md5(cls.__name__).hexdigest())[0], 16)
            config['smtp.test_server'] = '%s:%s' % (host, port)
        CreateTestData.create_user(name='bob', email='bob@bob.net')
        CreateTestData.create_user(name='mary') #NB No email addr provided
        SmtpServerHarness.setup_class()
        PylonsTestCase.setup_class()

    @classmethod
    def teardown_class(cls):
        SmtpServerHarness.teardown_class()
        model.repo.rebuild_db()

    def setup(self):
        self.clear_smtp_messages()

    def mime_encode(self, msg, recipient_name):
        sender_name = g.site_title
        sender_url = g.site_url
        body = mailer.add_msg_niceties(recipient_name, msg, sender_name, sender_url)
        encoded_body = MIMEText(body.encode('utf-8'), 'plain', 'utf-8').get_payload().strip()
        return encoded_body

    def test_mail_recipient(self):
        msgs = self.get_smtp_messages()
        assert_equal(msgs, [])

        # send email
        test_email = {'recipient_name': 'Bob',
                      'recipient_email':'bob@bob.net',
                      'subject': 'Meeting', 
                      'body': 'The meeting is cancelled.',
                      'headers': {'header1': 'value1'}}
        mailer.mail_recipient(**test_email)

        # check it went to the mock smtp server
        msgs = self.get_smtp_messages()
        assert_equal(len(msgs), 1)
        msg = msgs[0]
        assert_equal(msg[1], config['smtp.mail_from'])
        assert_equal(msg[2], [test_email['recipient_email']])
        assert test_email['headers'].keys()[0] in msg[3], msg[3]
        assert test_email['headers'].values()[0] in msg[3], msg[3]
        assert test_email['subject'] in msg[3], msg[3]
        expected_body = self.mime_encode(test_email['body'],
                                         test_email['recipient_name'])
        assert expected_body in msg[3], '%r not in %r' % (expected_body, msg[3])

    def test_mail_user(self):
        msgs = self.get_smtp_messages()
        assert_equal(msgs, [])

        # send email
        test_email = {'recipient': model.User.by_name(u'bob'),
                      'subject': 'Meeting', 
                      'body': 'The meeting is cancelled.',
                      'headers': {'header1': 'value1'}}
        mailer.mail_user(**test_email)

        # check it went to the mock smtp server
        msgs = self.get_smtp_messages()
        assert_equal(len(msgs), 1)
        msg = msgs[0]
        assert_equal(msg[1], config['smtp.mail_from'])
        assert_equal(msg[2], [model.User.by_name(u'bob').email])
        assert test_email['headers'].keys()[0] in msg[3], msg[3]
        assert test_email['headers'].values()[0] in msg[3], msg[3]
        assert test_email['subject'] in msg[3], msg[3]
        expected_body = self.mime_encode(test_email['body'],
                                         'bob')
        assert expected_body in msg[3], '%r not in %r' % (expected_body, msg[3])

    def test_mail_user_without_email(self):
        # send email
        test_email = {'recipient': model.User.by_name(u'mary'),
                      'subject': 'Meeting', 
                      'body': 'The meeting is cancelled.',
                      'headers': {'header1': 'value1'}}
        assert_raises(mailer.MailerException, mailer.mail_user, **test_email)

    def test_send_reset_email(self):
        # send email
        mailer.send_reset_link(model.User.by_name(u'bob'))

        # check it went to the mock smtp server
        msgs = self.get_smtp_messages()
        assert_equal(len(msgs), 1)
        msg = msgs[0]
        assert_equal(msg[1], config['smtp.mail_from'])
        assert_equal(msg[2], [model.User.by_name(u'bob').email])
        assert 'Reset' in msg[3], msg[3]
        test_msg = mailer.get_reset_link_body(model.User.by_name(u'bob'))
        expected_body = self.mime_encode(test_msg,
                                         u'bob')
        assert expected_body in msg[3], '%r not in %r' % (expected_body, msg[3])

        # reset link tested in user functional test

    def test_send_invite_email(self):
        user = model.User.by_name(u'bob')
        assert user.reset_key is None, user
        # send email
        mailer.send_invite(user)

        # check it went to the mock smtp server
        msgs = self.get_smtp_messages()
        assert_equal(len(msgs), 1)
        msg = msgs[0]
        assert_equal(msg[1], config['smtp.mail_from'])
        assert_equal(msg[2], [model.User.by_name(u'bob').email])
        test_msg = mailer.get_invite_body(model.User.by_name(u'bob'))
        expected_body = self.mime_encode(test_msg,
                                         u'bob') 
        assert expected_body in msg[3], '%r not in %r' % (expected_body, msg[3])
        assert user.reset_key is not None, user
        
        # reset link tested in user functional test

########NEW FILE########
__FILENAME__ = test_munge
from nose.tools import assert_equal

import ckan.lib.munge

class TestMunge:
    def test_munge_name(self):
        def test_munge(title, expected_munge):
            munge = ckan.lib.munge.munge_name(title)
            assert_equal(munge, expected_munge)

        test_munge('unchanged', 'unchanged')
        test_munge('bad spaces', 'bad-spaces')
        test_munge('s', 's_') # too short
        test_munge('random:other%character&', 'random-othercharacter')
        test_munge(u'u with umlaut \xfc', 'u-with-umlaut-u') 

    def test_munge_title_to_name(self):
        def test_munge(title, expected_munge):
            munge = ckan.lib.munge.munge_title_to_name(title)
            assert_equal(munge, expected_munge)

        test_munge('unchanged', 'unchanged')
        test_munge('some spaces  here', 'some-spaces-here')
        test_munge('s', 's_') # too short
        test_munge('random:other%character&', 'random-othercharacter')
        test_munge(u'u with umlaut \xfc', 'u-with-umlaut-u') 
        test_munge('reallylong'*12 , 'reallylong'*9 + 'reall') 
        test_munge('reallylong'*12 + ' - 2012' , 'reallylong'*9 + '-2012') 

    def test_munge_tag(self):
        def test_munge(title, expected_munge):
            munge = ckan.lib.munge.munge_tag(title)
            assert_equal(munge, expected_munge)

        test_munge('unchanged', 'unchanged')
        test_munge('s', 's_') # too short
        test_munge('some spaces  here', 'some-spaces--here')
        test_munge('random:other%character&', 'randomothercharacter')

########NEW FILE########
__FILENAME__ = test_navl
from ckan.lib.navl.dictization_functions import (flatten_schema,
                                   get_all_key_combinations,
                                   make_full_schema,
                                   flatten_dict,
                                   unflatten,
                                   missing,
                                   augment_data,
                                   validate,
                                   validate_flattened)
from pprint import pprint, pformat
from ckan.lib.navl.validators import (identity_converter,
                        empty,
                        not_empty,
                        ignore_missing,
                        default,
                        convert_int,
                        ignore)

from formencode import validators


schema = {
    "__after": [identity_converter],
    "__extra": [identity_converter],
    "__junk": [identity_converter],
    "0": [identity_converter],
    "1": [identity_converter],
    "2": {
        "__before": [identity_converter],
        "__after": [identity_converter],
        "20": [identity_converter],
        "22": [identity_converter],
        "21": {
            "210": [identity_converter],
        },
    },
    "3": {
        "30": [identity_converter],
    }
}

data = {
    ("0",): "0 value",
    #key 1 missing
    ("2", 0, "20"): "20 value 0",
    #key 2,22 missing
    ("2", 0, "21", 0, "210"): "210 value 0,0",
    #key 3 missing subdict
    ("2", 1, "20"): "20 value 1",
    ("2", 1, "22"): "22 value 1",
    ("2", 1, "21", 0, "210"): "210 value 1,0",
    ("2", 1, "21", 1, "210"): "210 value 1,1",
    ("2", 1, "21", 3, "210"): "210 value 1,3", ##out of order sequence
    ("4", 1, "30"): "30 value 1", #junk key as no 4 and no subdict
    ("4",): "4 value", #extra key 4
#    ("2", 2, "21", 0, "210"): "210 value 2,0" #junk key as it does not have a parent
}


def test_flatten_schema():

    flattened_schema = flatten_schema(schema)

    assert flattened_schema == {
         ('0',): [identity_converter],
         ('1',): [identity_converter],
         ('2', '20'): [identity_converter],
         ('2', '__after'): [identity_converter],
         ('2', '__before'): [identity_converter],
         ('2', '21', '210'): [identity_converter],
         ('2', '22'): [identity_converter],
         ('3', '30'): [identity_converter],
         ('__after',): [identity_converter],
         ('__extra',): [identity_converter],
         ('__junk',): [identity_converter],
    }, pprint(flattened_schema)

def test_get_key_combination():

    flattened_schema = flatten_schema(schema)
    assert get_all_key_combinations(data, flattened_schema) ==\
        set([(),
            ('2', 0), 
            ('2', 1), 
            ('2', 1, '21', 0),
            ('2', 0, '21', 0),
            ('2', 1, '21', 1), 
            ('2', 1, '21', 3), 
            ]), get_all_key_combinations(data, flattened_schema)

    #state = {}
    #make_flattened_schema(data, schema, state)

def test_make_full_schema():

    full_schema = make_full_schema(data, schema)

    print set(full_schema.keys()) - set(data.keys())

    assert set(full_schema.keys()) - set(data.keys()) == set([('2', 1, '__before'),
                                                              ('2', 0, '__after'),
                                                              ('2', 0, '22'),
                                                              ('1',),
                                                              ('2', 1, '__after'),
                                                              ('2', 0, '__before'),
                                                              ('__after',),
                                                              ('__extra',),
                                                              ('__junk',),
                                                             ])

    print set(data.keys()) - set(full_schema.keys())

    assert set(data.keys()) - set(full_schema.keys()) == set([('4',),
                                                              ('4', 1, '30')])


def test_augment_junk_and_extras():

    assert augment_data(data, schema) == {
         ('__junk',): {('4', 1, '30'): '30 value 1'},
         ('0',): '0 value',
         ('1',): missing,
         ('2', 0, '20'): '20 value 0',
         ('2', 0, '21', 0, '210'): '210 value 0,0',
         ('2', 0, '22'): missing,
         ('2', 1, '20'): '20 value 1',
         ('2', 1, '21', 0, '210'): '210 value 1,0',
         ('2', 1, '21', 1, '210'): '210 value 1,1',
         ('2', 1, '21', 3, '210'): '210 value 1,3',
         ('2', 1, '22'): '22 value 1',
         ('__extras',): {'4': '4 value'}}, pprint(augment_data(data, schema))


def test_identity_validation():

    
    converted_data, errors = validate_flattened(data, schema)
    print errors
    print converted_data

    assert not errors


    assert sorted(converted_data) == sorted({
         ('__junk',): {('2', 2, '21', 0, '210'): '210 value 2,0',
                       ('4', 1, '30'): '30 value 1'},
         ('0',): '0 value',
         ('1',): missing,
         ('2', 0, '20'): '20 value 0',
         ('2', 0, '21', 0, '210'): '210 value 0,0',
         ('2', 0, '22'): missing,
         ('2', 1, '20'): '20 value 1',
         ('2', 1, '21', 0, '210'): '210 value 1,0',
         ('2', 1, '21', 1, '210'): '210 value 1,1',
         ('2', 1, '21', 3, '210'): '210 value 1,3',
         ('2', 1, '22'): '22 value 1',
         ('__extras',): {'4': '4 value'}}), pformat(sorted(converted_data))


def test_basic_errors():
    schema = {
        "__junk": [empty],
        "__extras": [empty],
        "0": [identity_converter],
        "1": [not_empty],
        "2": {
            "__before": [identity_converter],
            "__after": [identity_converter],
            "20": [identity_converter],
            "22": [identity_converter],
            "__extras": [empty],
            "21": {
                "210": [identity_converter],
            },
        },
        "3": {
            "30": [identity_converter],
        },
    }

    converted_data, errors = validate_flattened(data, schema)

    assert errors == {('__junk',): [u'The input field __junk was not expected.'], ('1',): [u'Missing value'], ('__extras',): [u'The input field __extras was not expected.']}, errors

def test_default():
    schema = {
        "__junk": [ignore],
        "__extras": [ignore, default("weee")],
        "__before": [ignore],
        "__after": [ignore],
        "0": [default("default")],
        "1": [default("default")],
    }

    converted_data, errors = validate_flattened(data, schema)

    assert not errors
    assert converted_data == {('1',): 'default', ('0',): '0 value'}, converted_data


def test_flatten():

    data = {'extras': [{'key': 'genre', 'value': u'horror'},
                       {'key': 'media', 'value': u'dvd'}],
            'license_id': u'gpl-3.0',
            'name': u'testpkg',
            'resources': [{u'alt_url': u'alt_url',
                          u'description': u'Second file',
                          u'extras': {u'size': u'200'},
                          u'format': u'xml',
                          u'hash': u'def123',
                          u'url': u'http://blah.com/file2.xml'},
                          {u'alt_url': u'alt_url',
                          u'description': u'Main file',
                          u'extras': {u'size': u'200'},
                          u'format': u'xml',
                          u'hash': u'abc123',
                          u'url': u'http://blah.com/file.xml'}],
            'tags': [{'name': u'russion'}, {'name': u'novel'}],
            'title': u'Some Title',
            'url': u'http://blahblahblah.mydomain'}

    assert flatten_dict(data) == {('extras', 0, 'key'): 'genre',
                                 ('extras', 0, 'value'): u'horror',
                                 ('extras', 1, 'key'): 'media',
                                 ('extras', 1, 'value'): u'dvd',
                                 ('license_id',): u'gpl-3.0',
                                 ('name',): u'testpkg',
                                 ('resources', 0, u'alt_url'): u'alt_url',
                                 ('resources', 0, u'description'): u'Second file',
                                 ('resources', 0, u'extras'): {u'size': u'200'},
                                 ('resources', 0, u'format'): u'xml',
                                 ('resources', 0, u'hash'): u'def123',
                                 ('resources', 0, u'url'): u'http://blah.com/file2.xml',
                                 ('resources', 1, u'alt_url'): u'alt_url',
                                 ('resources', 1, u'description'): u'Main file',
                                 ('resources', 1, u'extras'): {u'size': u'200'},
                                 ('resources', 1, u'format'): u'xml',
                                 ('resources', 1, u'hash'): u'abc123',
                                 ('resources', 1, u'url'): u'http://blah.com/file.xml',
                                 ('tags', 0, 'name'): u'russion',
                                 ('tags', 1, 'name'): u'novel',
                                 ('title',): u'Some Title',
                                 ('url',): u'http://blahblahblah.mydomain'}, pformat(flatten_dict(data))

    assert data == unflatten(flatten_dict(data))


def test_simple():
    schema = {
        "name": [not_empty],
        "age": [ignore_missing, convert_int],
        "gender": [default("female")],
    }

    data = {
        "name": "fred",
        "age": "32",
    }


    converted_data, errors = validate(data, schema)

    assert not errors
    assert converted_data == {'gender': 'female', 'age': 32, 'name': 'fred'}, converted_data

    data = {
        "name": "",
        "age": "dsa32",
        "extra": "extra",
    }

    converted_data, errors = validate(data, schema)

    assert errors == {'age': [u'Please enter an integer value'], 'name': [u'Missing value']}, errors

    assert converted_data == {'gender': 'female', 'age': 'dsa32', 'name': '', '__extras': {'extra': 'extra'}}


    data = {"name": "fred",
            "numbers": [{"number": "13221312"},
                        {"number": "432423432", "code": "+44"}]
            }

    schema = {
           "name": [not_empty],
           "numbers": {
               "number": [convert_int],
               "code": [not_empty],
               "__extras": [ignore],
           }
        }

    converted_data, errors = validate(data, schema)

    print errors
    assert errors == {'numbers': [{'code': [u'Missing value']}, {}]}


def test_simple_converter_types():
    schema = {
        "name": [not_empty, unicode],
        "age": [ignore_missing, int],
        "gender": [default("female")],
    }

    data = {
        "name": "fred",
        "age": "32",
    }

    converted_data, errors = validate(data, schema)
    assert not errors
    assert converted_data == {'gender': 'female', 'age': 32, 'name': u'fred'}, converted_data

    assert isinstance(converted_data["name"], unicode)
    assert not isinstance(converted_data["gender"], unicode)


def test_formencode_compat():
    schema = {
        "name": [not_empty, unicode],
        "email": [validators.Email],
        "email2": [validators.Email],
    }

    data = {
        "name": "fred",
        "email": "32",
        "email2": "david@david.com",
    }

    converted_data, errors = validate(data, schema)
    assert errors == {'email': [u'An email address must contain a single @']}, errors

def test_range_validator():

    schema = {
        "name": [not_empty, unicode],
        "email": [validators.Int(min=1, max=10)],
        "email2": [validators.Email],
    }

    data = {
        "email": "32",
        "email2": "david@david.com",
    }

    converted_data, errors = validate(data, schema)
    assert errors == {'name': [u'Missing value'], 'email': [u'Please enter a number that is 10 or smaller']}, errors





########NEW FILE########
__FILENAME__ = test_resource_search
from webob.multidict import UnicodeMultiDict, MultiDict
from nose.tools import assert_raises, assert_equal

from ckan.tests import *
from ckan.tests import is_search_supported
import ckan.lib.search as search
from ckan import model
from ckan.lib.create_test_data import CreateTestData

class TestSearch(object):
    @classmethod
    def setup_class(self):
        if not is_search_supported():
            raise SkipTest("Search not supported")

        self.ab = 'http://site.com/a/b.txt'
        self.cd = 'http://site.com/c/d.txt'
        self.ef = 'http://site.com/e/f.txt'
        self.pkgs = [
            {'name':'pkg1',
             'resources':[
                 {'url':self.ab,
                  'description':'This is site ab.',
                  'format':'Excel spreadsheet',
                  'hash':'abc-123',
                  'alt_url': 'alt1',
                  'extras':{'size_extra': '100'},
                  },
                 {'url':self.cd,
                  'description':'This is site cd.',
                  'format':'Office spreadsheet',
                  'hash':'qwe-456',
                  'alt_url':'alt2',
                  'extras':{'size_extra':'200'},
                  },
                 ]
             },
            {'name':'pkg2',
             'resources':[
                 {'url':self.cd,
                  'alt_url': 'alt1',
                  'description':'This is site cd.'},
                 {'url':self.ef,
                  'description':'This is site ef.'},
                 {'url':self.ef,
                  'description':'This is site gh.'},
                 {'url':self.ef,
                  'description':'This is site ij.'},
                 ]
             },
            ]
        CreateTestData.create_arbitrary(self.pkgs)

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def res_search(self, query='', fields={}, terms=[], options=search.QueryOptions()):
        result = search.query_for(model.Resource).run(query=query, fields=fields, terms=terms, options=options)
        resources = [model.Session.query(model.Resource).get(resource_id) for resource_id in result['results']]
        urls = set([resource.url for resource in resources])
        return urls

    def test_01_search_url(self):
        fields = {'url':'site.com'}
        result = search.query_for(model.Resource).run(fields=fields)
        assert result['count'] == 6, result
        resources = [model.Session.query(model.Resource).get(resource_id) for resource_id in result['results']]
        urls = set([resource.url for resource in resources])
        assert set([self.ab, self.cd, self.ef]) == urls, urls

    def test_02_search_url_2(self):
        urls = self.res_search(fields={'url':'a/b'})
        assert set([self.ab]) == urls, urls

    def test_03_search_url_multiple_words(self):
        fields = UnicodeMultiDict(MultiDict(url='e'))
        fields.add('url', 'f')
        urls = self.res_search(fields=fields)
        assert set([self.ef]) == urls, urls

    def test_04_search_url_none(self):
        urls = self.res_search(fields={'url':'nothing'})
        assert set() == urls, urls

    def test_05_search_description(self):
        urls = self.res_search(fields={'description':'cd'})
        assert set([self.cd]) == urls, urls

    def test_06_search_format(self):
        urls = self.res_search(fields={'format':'excel'})
        assert set([self.ab]) == urls, urls

    def test_07_search_format_2(self):
        urls = self.res_search(fields={'format':'sheet'})
        assert set([self.ab, self.cd]) == urls, urls

    def test_08_search_hash_complete(self):
        urls = self.res_search(fields={'hash':'abc-123'})
        assert set([self.ab]) == urls, urls

    def test_09_search_hash_partial(self):
        urls = self.res_search(fields={'hash':'abc'})
        assert set([self.ab]) == urls, urls

    def test_10_search_hash_partial_but_not_initial(self):
        urls = self.res_search(fields={'hash':'123'})
        assert set() == urls, urls

    def test_11_search_several_fields(self):
        urls = self.res_search(fields={'description':'ab', 'format':'sheet'})
        assert set([self.ab]) == urls, urls

    def test_12_search_all_fields(self):
        fields = {'url':'a/b'}
        options = search.QueryOptions(all_fields=True)
        result = search.query_for(model.Resource).run(fields=fields, options=options)
        assert result['count'] == 1, result
        res_dict = result['results'][0]
        assert isinstance(res_dict, dict)
        res_keys = set(res_dict.keys())
        expected_res_keys = set(model.Resource.get_columns())
        expected_res_keys.update(['id', 'resource_group_id', 'package_id', 'position', 'size_extra'])
        assert_equal(res_keys, expected_res_keys)
        pkg1 = model.Package.by_name(u'pkg1')
        ab = pkg1.resources[0]
        assert res_dict['id'] == ab.id
        assert res_dict['package_id'] == pkg1.id
        assert res_dict['url'] == ab.url
        assert res_dict['description'] == ab.description
        assert res_dict['format'] == ab.format
        assert res_dict['hash'] == ab.hash
        assert res_dict['position'] == 0

    def test_13_pagination(self):
        # large search
        options = search.QueryOptions(order_by='id')
        fields = {'url':'site'}
        all_results = search.query_for(model.Resource).run(fields=fields, options=options)
        all_resources = all_results['results']
        all_resource_count = all_results['count']
        assert all_resource_count >= 6, all_results

        # limit
        options = search.QueryOptions(order_by='id')
        options.limit = 2
        result = search.query_for(model.Resource).run(fields=fields, options=options)
        resources = result['results']
        count = result['count']
        assert len(resources) == 2, resources
        assert count == all_resource_count, (count, all_resource_count)
        assert resources == all_resources[:2], '%r, %r' % (resources, all_resources)

        # offset
        options = search.QueryOptions(order_by='id')
        options.limit = 2
        options.offset = 2
        result = search.query_for(model.Resource).run(fields=fields, options=options)
        resources = result['results']
        assert len(resources) == 2, resources
        assert resources == all_resources[2:4]

        # larger offset
        options = search.QueryOptions(order_by='id')
        options.limit = 2
        options.offset = 4
        result = search.query_for(model.Resource).run(fields=fields, options=options)
        resources = result['results']
        assert len(resources) == 2, resources
        assert resources == all_resources[4:6]

    def test_14_extra_info(self):
        fields = {'alt_url':'alt1'}
        result = search.query_for(model.Resource).run(fields=fields)
        assert result['count'] == 2, result

        fields = {'alt_url':'alt2'}
        result = search.query_for(model.Resource).run(fields=fields)
        assert result['count'] == 1, result

        # Document that resource extras not in ckan.extra_resource_fields
        # can't be searched
        fields = {'size_extra':'100'}
        assert_raises(search.SearchError, search.query_for(model.Resource).run, fields=fields)

########NEW FILE########
__FILENAME__ = test_simple_search
from nose.tools import assert_equal

from ckan import model
from ckan.lib.create_test_data import CreateTestData
from ckan.lib.search.sql import PackageSearchQuery

class TestSimpleSearch:
    @classmethod
    def setup_class(cls):
        CreateTestData.create()
    
    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_get_all_entity_ids(self):
        ids = PackageSearchQuery().get_all_entity_ids()
        anna = model.Package.by_name(u'annakarenina')
        assert anna.id in ids
        assert len(ids) >= 2, len(ids)
        
    def test_run_query_basic(self):
        res = PackageSearchQuery().run({'q':'annakarenina'})
        anna = model.Package.by_name(u'annakarenina')
        assert_equal(res, {'results': [{'id': anna.id}], 'count': 1})

    def test_run_query_home(self):
        # This is the query from the CKAN home page
        res = PackageSearchQuery().run({'q': '*:*'})
        assert res['count'] >= 2, res['count']

    def test_run_query_all(self):
        # This is the default query from the search page
        res = PackageSearchQuery().run({'q': u''})
        assert res['count'] >= 2, res['count']

########NEW FILE########
__FILENAME__ = test_solr_package_search
from nose.tools import assert_equal, assert_raises

from ckan import model
import ckan.lib.search as search

from ckan.tests import TestController, CreateTestData, setup_test_search_index
from ckan.tests.lib import check_search_results


class TestQuery:
    def test_1_convert_legacy_params_to_solr(self):
        convert = search.convert_legacy_parameters_to_solr
        assert_equal(convert({'title': 'bob'}), {'q': 'title:bob'})
        assert_equal(convert({'title': 'bob', 'fl': 'name'}),
                     {'q': 'title:bob', 'fl': 'name'})
        assert_equal(convert({'title': 'bob perkins'}), {'q': 'title:"bob perkins"'})
        assert_equal(convert({'q': 'high+wages'}), {'q': 'high wages'})
        assert_equal(convert({'q': 'high+wages summary'}), {'q': 'high wages summary'})
        assert_equal(convert({'title': 'high+wages'}), {'q': 'title:"high wages"'})
        assert_equal(convert({'title': 'bob', 'all_fields': 1}), {'q': 'title:bob', 'fl': '*'})
        assert_raises(search.SearchError, convert, {'title': 'bob', 'all_fields': 'non-boolean'})
        assert_equal(convert({'q': 'bob', 'order_by': 'name'}), {'q': 'bob', 'sort':'name asc'})
        assert_equal(convert({'q': 'bob', 'offset': '0', 'limit': '10'}), {'q': 'bob', 'start':'0', 'rows':'10'})
        assert_equal(convert({'tags': ['russian', 'tolstoy']}), {'q': 'tags:"russian" tags:"tolstoy"'})
        assert_equal(convert({'tags': ['russian', 'multi word']}), {'q': 'tags:"russian" tags:"multi word"'})
        assert_equal(convert({'tags': ['with CAPITALS']}), {'q': 'tags:"with CAPITALS"'})
        assert_equal(convert({'tags': [u'with greek omega \u03a9']}), {'q': u'tags:"with greek omega \u03a9"'})
        assert_equal(convert({'tags': ['tolstoy']}), {'q': 'tags:"tolstoy"'})
        assert_equal(convert({'tags': 'tolstoy'}), {'q': 'tags:"tolstoy"'})
        assert_equal(convert({'tags': 'more than one tolstoy'}), {'q': 'tags:"more than one tolstoy"'})
        assert_equal(convert({'tags': u'with greek omega \u03a9'}), {'q': u'tags:"with greek omega \u03a9"'})
        assert_equal(convert({'title': 'Seymour: An Introduction'}), {'q': 'title:"Seymour\: An Introduction"'})
        assert_equal(convert({'title': 'Pop!'}), {'q': 'title:Pop\!'})


        assert_raises(search.SearchError, convert, {'tags': {'tolstoy':1}})

class TestSearch(TestController):
    # 'penguin' is in all test search packages
    q_all = u'penguin'

    @classmethod
    def setup_class(cls):
        model.Session.remove()
        setup_test_search_index()
        CreateTestData.create_search_test_data()
        # now remove a tag so we can test search with deleted tags
        model.repo.new_revision()
        gils = model.Package.by_name(u'gils')
        # an existing tag used only by gils
        cls.tagname = u'registry'
        idx = [t.name for t in gils.get_tags()].index(cls.tagname)
        gils.remove_tag(gils.get_tags()[idx])
        model.repo.commit_and_remove()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        search.clear()

    def _pkg_names(self, result):
        return ' '.join(result['results'])

    def _check_entity_names(self, result, names_in_result):
        names = result['results']
        for name in names_in_result:
            if name not in names:
                return False
        return True

    def test_1_all_records(self):
        result = search.query_for(model.Package).run({'q': self.q_all})
        assert 'gils' in result['results'], result['results']
        assert result['count'] == 6, result['count']

    def test_1_name(self):
        # exact name
        result = search.query_for(model.Package).run({'q': u'gils'})
        assert result['count'] == 1, result
        assert self._pkg_names(result) == 'gils', result

    def test_1_name_multiple_results(self):
        result = search.query_for(model.Package).run({'q': u'gov'})
        assert self._check_entity_names(result, ('us-gov-images', 'usa-courts-gov')), self._pkg_names(result)
        assert result['count'] == 4, self._pkg_names(result)

    def test_1_name_token(self):
        result = search.query_for(model.Package).run({'q': u'name:gils'})
        assert self._pkg_names(result) == 'gils', self._pkg_names(result)
        result = search.query_for(model.Package).run({'q': u'title:gils'})
        assert not self._check_entity_names(result, ('gils')), self._pkg_names(result)

    def test_2_title(self):
        # exact title, one word
        result = search.query_for(model.Package).run({'q': u'Opengov'})

        assert self._pkg_names(result) == 'se-opengov', self._pkg_names(result)
        # multiple words
        result = search.query_for(model.Package).run({'q': u'Government Expenditure'})
        # uk-government-expenditure is the best match but all other results should be retured
        assert self._pkg_names(result).startswith('uk-government-expenditure'), self._pkg_names(result)
        # multiple words wrong order
        result = search.query_for(model.Package).run({'q': u'Expenditure Government'})
        assert self._pkg_names(result).startswith('uk-government-expenditure'), self._pkg_names(result)
        # multiple words all should match government

        result = search.query_for(model.Package).run({'q': u'Expenditure Government China'})
        assert len(result['results']) == 1, self._pkg_names(result)

    def test_3_license(self):
        # this should result, but it is here to check that at least it does not error
        result = search.query_for(model.Package).run({'q': u'license:"OKD::Other (PublicsDomain)"'})
        assert result['count'] == 0, result

    def test_quotation(self):
        # multiple words quoted
        result = search.query_for(model.Package).run({'q': u'"Government Expenditure"'})
        assert self._pkg_names(result) == 'uk-government-expenditure', self._pkg_names(result)
        # multiple words quoted wrong order
        result = search.query_for(model.Package).run({'q': u'"Expenditure Government"'})
        assert self._pkg_names(result) == '', self._pkg_names(result)

    def test_string_not_found(self):
        result = search.query_for(model.Package).run({'q': u'randomthing'})
        assert self._pkg_names(result) == '', self._pkg_names(result)

    def test_tags_field(self):
        result = search.query_for(model.Package).run({'q': u'country-sweden'})
        assert self._check_entity_names(result, ['se-publications', 'se-opengov']), self._pkg_names(result)

    def test_tags_field_split_word(self):
        result = search.query_for(model.Package).run({'q': u'todo split'})
        assert self._check_entity_names(result, ['us-gov-images']), self._pkg_names(result)

    def test_tags_field_with_capitals(self):
        result = search.query_for(model.Package).run({'q': u'CAPITALS'})
        assert self._check_entity_names(result, ['se-publications']), self._pkg_names(result)

    def dont_test_tags_field_with_basic_unicode(self):
        result = search.query_for(model.Package).run({'q': u'greek omega \u03a9'})
        assert self._check_entity_names(result, ['se-publications']), self._pkg_names(result)

    def test_tags_token_simple(self):
        result = search.query_for(model.Package).run({'q': u'tags:country-sweden'})
        assert self._check_entity_names(result, ['se-publications', 'se-opengov']), self._pkg_names(result)
        result = search.query_for(model.Package).run({'q': u'tags:wildlife'})
        assert self._pkg_names(result) == 'us-gov-images', self._pkg_names(result)

    def test_tags_token_with_multi_word_tag(self):
        result = search.query_for(model.Package).run({'q': u'tags:"todo split"'})
        assert self._check_entity_names(result, ['us-gov-images']), self._pkg_names(result)

    def test_tags_token_simple_with_deleted_tag(self):
        # registry has been deleted
        result = search.query_for(model.Package).run({'q': u'tags:registry'})
        assert self._pkg_names(result) == '', self._pkg_names(result)

    def test_tags_token_multiple(self):
        result = search.query_for(model.Package).run({'q': u'tags:country-sweden tags:format-pdf'})
        assert self._pkg_names(result) == 'se-publications', self._pkg_names(result)
        result = search.query_for(model.Package).run({'q': u'tags:"todo split" tags:war'})
        assert self._pkg_names(result) == 'us-gov-images', self._pkg_names(result)

    def test_tags_token_complicated(self):
        result = search.query_for(model.Package).run({'q': u'tags:country-sweden tags:somethingrandom'})
        assert self._pkg_names(result) == '', self._pkg_names(result)

    def test_tags_token_with_capitals(self):
        result = search.query_for(model.Package).run({'q': u'tags:"CAPITALS"'})
        assert self._check_entity_names(result, ['se-publications']), self._pkg_names(result)

    def test_tags_token_with_punctuation(self):
        result = search.query_for(model.Package).run({'q': u'tags:"surprise."'})
        assert self._check_entity_names(result, ['se-publications']), self._pkg_names(result)

    def test_tags_token_with_basic_unicode(self):
        result = search.query_for(model.Package).run({'q': u'tags:"greek omega \u03a9"'})
        assert self._check_entity_names(result, ['se-publications']), self._pkg_names(result)

    def test_pagination(self):
        # large search
        all_results = search.query_for(model.Package).run({'q': self.q_all})
        all_pkgs = all_results['results']
        all_pkg_count = all_results['count']

        # limit
        query = {
            'q': self.q_all,
            'rows': 2
        }
        result = search.query_for(model.Package).run(query)
        pkgs = result['results']
        count = result['count']
        assert len(pkgs) == 2, pkgs
        assert count == all_pkg_count
        assert pkgs == all_pkgs[:2]

        # offset
        query = {
            'q': self.q_all,
            'rows': 2,
            'start': 2
        }
        result = search.query_for(model.Package).run(query)
        pkgs = result['results']
        assert len(pkgs) == 2, pkgs
        assert pkgs == all_pkgs[2:4]

        # larger offset
        query = {
            'q': self.q_all,
            'rows': 2,
            'start': 4
        }
        result = search.query_for(model.Package).run(query)
        pkgs = result['results']
        assert len(pkgs) == 2, pkgs
        assert pkgs == all_pkgs[4:6]

    def test_order_by(self):
        # TODO: fix this test
        #
        # as we are not using the 'edismax' query parser now (requires solr >= 3.*), the
        # search weighting has been changed
        from nose import SkipTest
        raise SkipTest()

        # large search
        all_results = search.query_for(model.Package).run({'q': self.q_all})
        all_pkgs = all_results['results']
        all_pkg_count = all_results['count']

        # rank
        query = {
            'q': 'government',
            'sort': 'rank'
        }
        result = search.query_for(model.Package).run(query)
        pkgs = result['results']
        fields = [model.Package.by_name(pkg_name).name for pkg_name in pkgs]
        assert fields[0] == 'gils', fields # has government in tags, title and notes

        # name
        query = {
            'q': self.q_all,
            'sort': 'name asc'
        }
        result = search.query_for(model.Package).run(query)
        pkgs = result['results']
        fields = [model.Package.by_name(pkg_name).name for pkg_name in pkgs]
        sorted_fields = fields; sorted_fields.sort()
        assert fields == sorted_fields, repr(fields) + repr(sorted_fields)

        # title
        query = {
            'q': self.q_all,
            'sort': 'title asc'
        }
        result = search.query_for(model.Package).run(query)
        pkgs = result['results']
        fields = [model.Package.by_name(pkg_name).title for pkg_name in pkgs]
        sorted_fields = fields; sorted_fields.sort()
        assert fields == sorted_fields, repr(fields) + repr(sorted_fields)

        # notes
        query = {
            'q': self.q_all,
            'sort': 'notes asc'
        }
        result = search.query_for(model.Package).run(query)
        pkgs = result['results']
        fields = [model.Package.by_name(pkg_name).notes for pkg_name in pkgs]
        sorted_fields = fields; sorted_fields.sort()
        assert fields == sorted_fields, repr(fields) + repr(sorted_fields)

        # extra field
        query = {
            'q': self.q_all,
            'sort': 'date_released asc'
        }
        result = search.query_for(model.Package).run(query)
        pkgs = result['results']
        fields = [model.Package.by_name(pkg_name) for pkg_name in pkgs]
        fields = [field.extras.get('date_released') for field in fields]
        sorted_fields = fields; sorted_fields.sort()
        assert fields == sorted_fields, repr(fields) + repr(sorted_fields)

    def test_search_notes_on(self):
        result = search.query_for(model.Package).run({'q': u'restrictions'})
        pkgs = result['results']
        count = result['count']
        assert len(pkgs) == 2, pkgs

    def test_search_foreign_chars(self):
        result = search.query_for(model.Package).run({'q': 'umlaut'})
        assert result['results'] == ['gils'], result['results']
        result = search.query_for(model.Package).run({'q': u'thumb'})
        assert result['results'] == ['gils'], result['results']
        result = search.query_for(model.Package).run({'q': u'th\xfcmb'})
        assert result['results'] == ['gils'], result['results']

    def test_groups(self):
        result = search.query_for(model.Package).run({'q': u'groups:random'})
        assert self._pkg_names(result) == '', self._pkg_names(result)
        result = search.query_for(model.Package).run({'q': u'groups:ukgov'})
        assert result['count'] == 4, self._pkg_names(result)
        result = search.query_for(model.Package).run({'q': u'groups:ukgov tags:us'})
        assert result['count'] == 2, self._pkg_names(result)

class TestSearchOverall(TestController):
    @classmethod
    def setup_class(cls):
        setup_test_search_index()
        CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        search.clear()

    def test_overall(self):
        check_search_results('annakarenina', 1, ['annakarenina'])
        check_search_results('warandpeace', 1, ['warandpeace'])
        check_search_results('', 2)

        check_search_results('Tolstoy', 1, ['annakarenina'])
        check_search_results('title:Novel', 1, ['annakarenina'])
        check_search_results('title:peace', 0)
        check_search_results('name:warandpeace', 1)
        check_search_results('groups:david', 2)
        check_search_results('groups:roger', 1)
        check_search_results('groups:lenny', 0)
        check_search_results('tags:"russian"', 2)
        check_search_results(u'tags:"Flexible \u30a1"', 2)
        check_search_results(u'Flexible \u30a1', 2)
        check_search_results(u'Flexible', 2)
        check_search_results(u'flexible', 2)


class TestGeographicCoverage(TestController):
    @classmethod
    def setup_class(cls):
        setup_test_search_index()
        init_data = [
            {'name':'eng',
             'extras':{'geographic_coverage':'100000: England'},},
            {'name':'eng_ni',
             'extras':{'geographic_coverage':'100100: England, Northern Ireland'},},
            {'name':'uk',
             'extras':{'geographic_coverage':'111100: United Kingdom (England, Scotland, Wales, Northern Ireland'},},
            {'name':'gb',
             'extras':{'geographic_coverage':'111000: Great Britain (England, Scotland, Wales)'},},
            {'name':'none',
             'extras':{'geographic_coverage':'000000:'},},
        ]
        CreateTestData.create_arbitrary(init_data)

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()
        search.clear()

    def _do_search(self, q, expected_pkgs, count=None):
        query = {
            'q': q,
            'sort': 'score desc, name asc'
        }
        result = search.query_for(model.Package).run(query)
        pkgs = result['results']
        fields = [model.Package.by_name(pkg_name).name for pkg_name in pkgs]
        if not (count is None):
            assert result['count'] == count, result['count']
        for expected_pkg in expected_pkgs:
            assert expected_pkg in fields, expected_pkg

    def _filtered_search(self, value, expected_pkgs, count=None):
        query = {
            'q': 'geographic_coverage:%s' % value,
            'sort': 'rank'
        }
        result = search.query_for(model.Package).run(query)
        pkgs = result['results']
        fields = [model.Package.by_name(pkg_name).name for pkg_name in pkgs]
        if not (count is None):
            assert result['count'] == count, result['count']
        for expected_pkg in expected_pkgs:
            assert expected_pkg in fields, expected_pkg

    def test_0_basic(self):
        self._do_search(u'england', ['eng', 'eng_ni', 'uk', 'gb'], 4)
        self._do_search(u'northern ireland', ['eng_ni', 'uk'], 2)
        self._do_search(u'united kingdom', ['uk'], 1)
        self._do_search(u'great britain', ['gb'], 1)

    def test_1_filtered(self):
        # TODO: solr is not currently set up to allow partial matches
        #       and extras are not saved as multivalued so this
        #       test will fail. Make multivalued or remove?
        from ckan.tests import SkipTest
        raise SkipTest

        self._filtered_search(u'england', ['eng', 'eng_ni', 'uk', 'gb'], 4)

class TestExtraFields(TestController):
    @classmethod
    def setup_class(cls):
        setup_test_search_index()
        init_data = [
            {'name':'a',
             'extras':{'department':'abc',
                       'agency':'ag-a'},},
            {'name':'b',
             'extras':{'department':'bcd',
                       'agency':'ag-b'},},
            {'name':'c',
             'extras':{'department':'cde abc'},},
            {'name':'none',
             'extras':{'department':''},},
            ]
        CreateTestData.create_arbitrary(init_data)

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()
        search.clear()

    def _do_search(self, department, expected_pkgs, count=None):
        result = search.query_for(model.Package).run({'q': 'department: %s' % department})
        pkgs = result['results']
        fields = [model.Package.by_name(pkg_name).name for pkg_name in pkgs]
        if not (count is None):
            assert result['count'] == count, result['count']
        for expected_pkg in expected_pkgs:
            assert expected_pkg in fields, expected_pkg

    def test_0_basic(self):
        self._do_search(u'bcd', 'b', 1)
        self._do_search(u'"cde abc"', 'c', 1)

    def test_1_extras_in_all_fields(self):
        response = search.query_for(model.Package).run({'q': 'abc', 'fl': '*'})
        assert response['count'] == 2

        results = response['results']
        for result in results:
            assert 'extras' in result.keys(), result
            assert 'department' in result['extras'], result['extras']
            assert result['extras']['department'] in ['abc', 'cde abc'], result['extras']['department']

class TestRank(TestController):
    @classmethod
    def setup_class(cls):
        setup_test_search_index()
        init_data = [{'name':u'test1-penguin-canary',
                      'title':u'penguin',
                      'tags':u'canary goose squirrel wombat wombat'.split()},
                     {'name':u'test2-squirrel-squirrel-canary-goose',
                      'title':u'squirrel goose',
                      'tags':u'penguin wombat'.split()},
                     ]
        CreateTestData.create_arbitrary(init_data)
        cls.pkg_names = [
            u'test1-penguin-canary',
            u'test2-squirrel-squirrel-canary-goose'
        ]

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()
        search.clear()

    def _do_search(self, q, wanted_results):
        query = {
            'q': q,
            'sort': 'score desc, name asc',
        }
        result = search.query_for(model.Package).run(query)
        results = result['results']
        err = 'Wanted %r, got %r' % (wanted_results, results)
        assert wanted_results[0] == results[0], err
        assert wanted_results[1] == results[1], err

    def test_0_basic(self):
        self._do_search(u'wombat', self.pkg_names)
        self._do_search(u'squirrel', self.pkg_names[::-1])
        self._do_search(u'canary', self.pkg_names)

    def test_1_weighting(self):
        self._do_search(u'penguin', self.pkg_names)
        self._do_search(u'goose', self.pkg_names[::-1])

########NEW FILE########
__FILENAME__ = test_solr_package_search_synchronous_update
from ckan import model
import ckan.lib.search as search

from ckan.tests import CreateTestData, setup_test_search_index
from ckan.tests.lib import check_search_results
import json

class TestSearchOverallWithSynchronousIndexing:
    '''Repeat test from test_package_search with synchronous indexing
    '''

    @classmethod
    def setup_class(cls):
        setup_test_search_index()
        # Force a garbage collection to trigger issue #695
        import gc
        gc.collect()

        CreateTestData.create()

        cls.new_pkg_dict = {
            'name': 'council-owned-litter-bins',
            'notes': 'Location of Council owned litter bins within Borough.',
            'resources': [{'description': 'Resource locator',
                           'format': 'Unverified',
                           'url': 'http://www.barrowbc.gov.uk'}],
            'tags': ['Utility and governmental services'],
            'title': 'Council Owned Litter Bins',
            'extras': {
                'INSPIRE': 'True',
                'bbox-east-long': '-3.12442',
                'bbox-north-lat': '54.218407',
                'bbox-south-lat': '54.039634',
                'bbox-west-long': '-3.32485',
                'constraint': 'conditions unknown; (e) intellectual property rights;',
                'dataset-reference-date': json.dumps(
                                          [{'type': 'creation',
                                            'value': '2008-10-10'},
                                           {'type': 'revision',
                                            'value': '2009-10-08'}]),
                'guid': '00a743bf-cca4-4c19-a8e5-e64f7edbcadd',
                'metadata-date': '2009-10-16',
                'metadata-language': 'eng',
                'published_by': 0,
                'resource-type': 'dataset',
                'spatial-reference-system': 'test-spatial',
                'temporal_coverage-from': '1977-03-10T11:45:30',
                'temporal_coverage-to': '2005-01-15T09:10:00'
            }
        }

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        search.clear()

    def setup(self):
        self._create_package()
        
    def teardown(self):
        self._remove_package()
        self._remove_package(u'new_name')
        
    def _create_package(self, package=None):
        CreateTestData.create_arbitrary(self.new_pkg_dict)
        return model.Package.by_name(self.new_pkg_dict['name'])
    
    def _remove_package(self, name=None):
        package = model.Package.by_name(name or 'council-owned-litter-bins')
        if package:
            package.purge()
            model.repo.commit_and_remove()

    def test_02_add_package_from_dict(self):
        check_search_results('', 3)
        check_search_results('spatial', 1, ['council-owned-litter-bins'])

    def test_03_update_package_from_dict(self):
        package = model.Package.by_name('council-owned-litter-bins')

        # update package
        rev = model.repo.new_revision()
        package.name = u'new_name'
        extra = model.PackageExtra(key='published_by', value='barrow')
        package._extras[extra.key] = extra
        model.repo.commit_and_remove()
        
        check_search_results('', 3)
        check_search_results('barrow', 1, ['new_name'])

        # update package again
        package = model.Package.by_name('new_name')
        rev = model.repo.new_revision()
        package.name = u'council-owned-litter-bins'
        model.repo.commit_and_remove()

        check_search_results('', 3)
        check_search_results('spatial', 1, ['council-owned-litter-bins'])

    def test_04_delete_package_from_dict(self):
        package = model.Package.by_name('council-owned-litter-bins')
        assert package
        check_search_results('', 3)

        # delete it
        rev = model.repo.new_revision()
        package.delete()
        model.repo.commit_and_remove()
        
        check_search_results('', 2)

########NEW FILE########
__FILENAME__ = test_solr_schema_version
import os
from ckan.tests import TestController

class TestSolrSchemaVersionCheck(TestController):

    @classmethod
    def setup_class(cls):

        cls.root_dir = os.path.dirname(os.path.realpath(__file__))

    def _get_current_schema(self):

        current_schema = os.path.join(self.root_dir,'..','..','config','solr','schema.xml')

        return current_schema

    def test_current_schema_exists(self):

        current_schema = self._get_current_schema()

        assert os.path.exists(current_schema)


    def test_solr_schema_version_check(self):

        from ckan.lib.search import check_solr_schema_version, SearchError

        schema_file = self._get_current_schema()

        # Check that current schema version schema is supported
        assert check_solr_schema_version(schema_file)

        # An exception is thrown if version could not be extracted
        try:
            schema_file = os.path.join(self.root_dir,'solr','schema-no-version.xml')
            check_solr_schema_version(schema_file)

            #Should not happen
            assert False
        except SearchError,e:
            assert 'Could not extract version info' in str(e)

        # An exception is thrown if the schema version is not supported
        try:
            schema_file = os.path.join(self.root_dir,'solr','schema-wrong-version.xml')
            check_solr_schema_version(schema_file)

            #Should not happen
            assert False
        except SearchError,e:
            assert 'SOLR schema version not supported' in str(e)



########NEW FILE########
__FILENAME__ = test_solr_search_index
from datetime import datetime
import hashlib
import socket
import solr
from pylons import config
from ckan import model
import ckan.lib.search as search
from ckan.tests import TestController, CreateTestData, setup_test_search_index, is_search_supported

class TestSolrConfig(TestController):
    """
    Make sure that solr is enabled for this ckan instance.
    """
    def test_solr_url_exists(self):
        if not is_search_supported():
            from nose import SkipTest
            raise SkipTest("Search not supported")

        conn = search.make_connection()
        try:
            # solr.SolrConnection.query will throw a socket.error if it
            # can't connect to the SOLR instance
            q = conn.query("*:*", rows=1)
            conn.close()
        except socket.error, e:
            if not config.get('solr_url'):
                raise AssertionError("Config option 'solr_url' needs to be defined in this CKAN's development.ini. Default of %s didn't work: %s" % (search.DEFAULT_SOLR_URL, e))
            else:
                raise AssertionError('SOLR connection problem. Connection defined in development.ini as: solr_url=%s Error: %s' % (config['solr_url'], e))


class TestSolrSearchIndex(TestController):
    """
    Tests that a package is indexed when the packagenotification is
    received by the indexer.
    """
    @classmethod
    def setup_class(cls):
        setup_test_search_index()
        CreateTestData.create()
        cls.solr = search.make_connection()
        cls.fq = " +site_id:\"%s\" " % config['ckan.site_id']

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        cls.solr.close()

    def teardown(self):
        # clear the search index after every test
        search.index_for('Package').clear()

    def _get_index_id(self,pkg_id):
        return hashlib.md5('%s%s' % (pkg_id,config['ckan.site_id'])).hexdigest()

    def test_index(self):

        datetime_now = datetime.now()
        pkg_dict = {
            'id': u'penguin-id',
            'title': u'penguin',
            'state': u'active',
            'type': u'dataset',
            'private': False,
            'owner_org': None,
            'metadata_created': datetime_now.isoformat(),
            'metadata_modified': datetime_now.isoformat(),
            'extras': [
                {'key': 'test_date', 'value': '2013-03-01'},
                {'key': 'test_wrong_date', 'value': 'Not a date'},
            ]
        }
        search.dispatch_by_operation('Package', pkg_dict, 'new')
        response = self.solr.query('title:penguin', fq=self.fq)
        assert len(response) == 1, len(response)
        assert response.results[0]['index_id'] == self._get_index_id (pkg_dict['id'])
        assert response.results[0]['title'] == 'penguin'

        # looks like solrpy messes with microseconds and time zones,
        # so ignore them for testing
        assert datetime_now.strftime('%Y-%m-%d %H:%M:%S') == response.results[0]['metadata_created'].strftime('%Y-%m-%d %H:%M:%S')
        assert datetime_now.strftime('%Y-%m-%d %H:%M:%S') == response.results[0]['metadata_modified'].strftime('%Y-%m-%d %H:%M:%S')

    def test_no_state_not_indexed(self):
        pkg_dict = {
            'title': 'penguin'
        }
        search.dispatch_by_operation('Package', pkg_dict, 'new')
        response = self.solr.query('title:penguin', fq=self.fq)
        assert len(response) == 0, len(response)

    def test_index_clear(self):
        pkg_dict = {
            'id': u'penguin-id',
            'title': u'penguin',
            'state': u'active',
            'type': u'dataset',
            'private': False,
            'owner_org': None,
            'metadata_created': datetime.now().isoformat(),
            'metadata_modified': datetime.now().isoformat(),
        }
        search.dispatch_by_operation('Package', pkg_dict, 'new')
        response = self.solr.query('title:penguin', fq=self.fq)
        assert len(response) == 1, len(response)
        search.index_for('Package').clear()
        response = self.solr.query('title:penguin', fq=self.fq)
        assert len(response) == 0
        # clear whilst empty
        search.index_for('Package').clear()
        response = self.solr.query('title:penguin', fq=self.fq)
        assert len(response) == 0

    def test_index_illegal_xml_chars(self):

        pkg_dict = {
            'id': u'penguin-id',
            'title': u'\u00c3a\u0001ltimo n\u00famero penguin',
            'notes': u'\u00c3a\u0001ltimo n\u00famero penguin',
            'state': u'active',
            'type': u'dataset',
            'private': False,
            'owner_org': None,
            'metadata_created': datetime.now().isoformat(),
            'metadata_modified': datetime.now().isoformat(),
        }
        search.dispatch_by_operation('Package', pkg_dict, 'new')
        response = self.solr.query('title:penguin', fq=self.fq)
        assert len(response) == 1, len(response)
        assert response.results[0]['index_id'] == self._get_index_id (pkg_dict['id'])
        assert response.results[0]['title'] == u'\u00c3altimo n\u00famero penguin'


class TestSolrSearch:
    @classmethod
    def setup_class(cls):
        setup_test_search_index()
        CreateTestData.create_search_test_data()
        cls.solr = search.make_connection()
        cls.fq = " +site_id:\"%s\" " % config['ckan.site_id']
        search.rebuild()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        cls.solr.close()
        search.index_for('Package').clear()

    def test_0_indexing(self):
        """
        Make sure that all packages created by CreateTestData.create_search_test_data
        have been added to the search index.
        """
        results = self.solr.query('*:*', fq=self.fq)
        assert len(results) == 6, len(results)

    def test_1_basic(self):
        results = self.solr.query('sweden', fq=self.fq)
        assert len(results) == 2
        result_names = [r['name'] for r in results]
        assert 'se-publications' in result_names
        assert 'se-opengov' in result_names


########NEW FILE########
__FILENAME__ = test_tag_search
from nose.tools import assert_raises
from ckan.tests import *
from ckan.tests import is_search_supported
import ckan.lib.search as search
from ckan import model
from ckan.lib.create_test_data import CreateTestData

class TestTagSearch(object):
    @classmethod
    def setup_class(self):
        if not is_search_supported():
            raise SkipTest("Search not supported")
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_good_search_query(self):
        result = search.query_for(model.Tag).run(query=u'ru')
        assert result['count'] == 1, result
        assert 'russian' in result['results'], result

        result = search.query_for(model.Tag).run(query=u's')
        assert result['count'] == 2, result
        assert 'russian' in result['results'], result
        assert 'tolstoy' in result['results'], result

    def test_good_search_queries(self):
        result = search.query_for(model.Tag).run(query=[u'ru', u's'])
        assert result['count'] == 1, result
        assert 'russian' in result['results'], result

    def test_bad_search_query(self):
        result = search.query_for(model.Tag).run(query=u'asdf')
        assert result['count'] == 0, result

    def test_search_with_capital_letter_in_tagname(self):
        """
        Asserts that it doesn't matter if the tagname has capital letters in it.
        """
        result = search.query_for(model.Tag).run(query=u'lexible')
        assert u'Flexible \u30a1' in result['results']

    def test_search_with_capital_letter_in_search_query(self):
        """
        Asserts that search works with a capital letter in the search query.
        """
        result = search.query_for(model.Tag).run(query=u'Flexible')
        assert u'Flexible \u30a1' in result['results']

    def test_search_with_unicode_in_search_query(self):
        """
        Asserts that search works with a unicode character above \u00ff.
        """
        result = search.query_for(model.Tag).run(query=u' \u30a1')
        assert u'Flexible \u30a1' in result['results']

    def test_search_is_case_insensitive(self):
        result = search.query_for(model.Tag).run(query=u'flexible')
        assert u'Flexible \u30a1' in result['results']
        

    def test_good_search_fields(self):
        result = search.query_for(model.Tag).run(fields={'tags': u'ru'})
        assert result['count'] == 1, result
        assert 'russian' in result['results'], result

        result = search.query_for(model.Tag).run(fields={'tags': u's'})
        assert result['count'] == 2, result
        assert 'russian' in result['results'], result
        assert 'tolstoy' in result['results'], result

    def test_bad_search_fields(self):
        result = search.query_for(model.Tag).run(fields={'tags': u'asdf'})
        assert result['count'] == 0, result

########NEW FILE########
__FILENAME__ = test_action
import re
import json
import urllib
from pprint import pprint
from nose.tools import assert_equal, assert_raises
from nose.plugins.skip import SkipTest
from pylons import config
import datetime
import mock

import vdm.sqlalchemy
import ckan
from ckan.lib.create_test_data import CreateTestData
from ckan.lib.dictization.model_dictize import resource_dictize
import ckan.model as model
import ckan.tests as tests
from ckan.tests import WsgiAppCase
from ckan.tests.functional.api import assert_dicts_equal_ignoring_ordering
from ckan.tests import setup_test_search_index, search_related
from ckan.tests import StatusCodes
from ckan.logic import get_action, NotAuthorized
from ckan.logic.action import get_domain_object
from ckan.tests import TestRoles
import ckan.lib.search as search

from ckan import plugins
from ckan.plugins import SingletonPlugin, implements, IPackageController

class TestAction(WsgiAppCase):

    sysadmin_user = None

    normal_user = None

    @classmethod
    def setup_class(cls):
        search.clear()
        CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        CreateTestData.make_some_vocab_tags()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def _add_basic_package(self, package_name=u'test_package', **kwargs):
        package = {
            'name': package_name,
            'title': u'A Novel By Tolstoy',
            'resources': [{
                'description': u'Full text.',
                'format': u'plain text',
                'url': u'http://www.annakarenina.com/download/'
            }]
        }
        package.update(kwargs)

        postparams = '%s=1' % json.dumps(package)
        res = self.app.post('/api/action/package_create', params=postparams,
                            extra_environ={'Authorization': 'tester'})
        return json.loads(res.body)['result']

    def test_01_package_list(self):
        res = json.loads(self.app.post('/api/action/package_list',
                         headers={'content-type': 'application/json'}).body)
        assert res['success'] is True
        assert len(res['result']) == 2
        assert 'warandpeace' in res['result']
        assert 'annakarenina' in res['result']
        assert res['help'].startswith(
            "Return a list of the names of the site's datasets (packages).")

        postparams = '%s=1' % json.dumps({'limit': 1})
        res = json.loads(self.app.post('/api/action/package_list',
                         params=postparams).body)
        assert res['success'] is True
        assert len(res['result']) == 1
        assert 'warandpeace' in res['result'] or 'annakarenina' in res['result']

		# Test GET request
        res = json.loads(self.app.get('/api/action/package_list').body)
        assert len(res['result']) == 2
        assert 'warandpeace' in res['result']
        assert 'annakarenina' in res['result']

    def test_01_package_list_private(self):
        tests.call_action_api(self.app, 'organization_create',
                                        name='test_org_2',
                                        apikey=self.sysadmin_user.apikey)

        tests.call_action_api(self.app, 'package_create',
                                        name='public_dataset',
                                        owner_org='test_org_2',
                                        apikey=self.sysadmin_user.apikey)

        res = tests.call_action_api(self.app, 'package_list')

        assert len(res) == 3
        assert 'warandpeace' in res
        assert 'annakarenina' in res
        assert 'public_dataset' in res

        tests.call_action_api(self.app, 'package_create',
                                        name='private_dataset',
                                        owner_org='test_org_2',
                                        private=True,
                                        apikey=self.sysadmin_user.apikey)

        res = tests.call_action_api(self.app, 'package_list')
        assert len(res) == 3
        assert 'warandpeace' in res
        assert 'annakarenina' in res
        assert 'public_dataset' in res
        assert not 'private_dataset' in res

    def test_01_package_show(self):
        anna_id = model.Package.by_name(u'annakarenina').id
        postparams = '%s=1' % json.dumps({'id': anna_id})
        res = self.app.post('/api/action/package_show', params=postparams)
        res_dict = json.loads(res.body)
        assert_equal(res_dict['success'], True)
        assert res_dict['help'].startswith(
            "Return the metadata of a dataset (package) and its resources.")
        pkg = res_dict['result']
        assert_equal(pkg['name'], 'annakarenina')
        missing_keys = set(('title', 'groups')) - set(pkg.keys())
        assert not missing_keys, missing_keys

    def test_01_package_show_with_jsonp(self):
        anna_id = model.Package.by_name(u'annakarenina').id
        postparams = '%s=1' % json.dumps({'id': anna_id})
        res = self.app.post('/api/action/package_show?callback=jsoncallback', params=postparams)

        assert re.match('jsoncallback\(.*\);', res.body), res
        # Unwrap JSONP callback (we want to look at the data).
        msg = res.body[len('jsoncallback')+1:-2]
        res_dict = json.loads(msg)
        assert_equal(res_dict['success'], True)
        assert res_dict['help'].startswith(
            "Return the metadata of a dataset (package) and its resources.")
        pkg = res_dict['result']
        assert_equal(pkg['name'], 'annakarenina')
        missing_keys = set(('title', 'groups')) - set(pkg.keys())
        assert not missing_keys, missing_keys

    def test_02_package_autocomplete_match_name(self):
        postparams = '%s=1' % json.dumps({'q':'war', 'limit': 5})
        res = self.app.post('/api/action/package_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert_equal(res_obj['success'], True)
        pprint(res_obj['result'][0]['name'])
        assert_equal(res_obj['result'][0]['name'], 'warandpeace')
        assert_equal(res_obj['result'][0]['title'], 'A Wonderful Story')
        assert_equal(res_obj['result'][0]['match_field'], 'name')
        assert_equal(res_obj['result'][0]['match_displayed'], 'warandpeace')

    def test_02_package_autocomplete_match_title(self):
        postparams = '%s=1' % json.dumps({'q':'a%20w', 'limit': 5})
        res = self.app.post('/api/action/package_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert_equal(res_obj['success'], True)
        pprint(res_obj['result'][0]['name'])
        assert_equal(res_obj['result'][0]['name'], 'warandpeace')
        assert_equal(res_obj['result'][0]['title'], 'A Wonderful Story')
        assert_equal(res_obj['result'][0]['match_field'], 'title')
        assert_equal(res_obj['result'][0]['match_displayed'], 'A Wonderful Story (warandpeace)')

    def test_03_create_update_package(self):

        package = {
            'author': None,
            'author_email': None,
            'extras': [{'key': u'original media','value': u'"book"'}],
            'license_id': u'other-open',
            'maintainer': None,
            'maintainer_email': None,
            'name': u'annakareninanew',
            'notes': u'Some test now',
            'resources': [{'alt_url': u'alt123',
                           'description': u'Full text.',
                           'extras': {u'alt_url': u'alt123', u'size': u'123'},
                           'format': u'plain text',
                           'hash': u'abc123',
                           'position': 0,
                           'url': u'http://www.annakarenina.com/download/'},
                          {'alt_url': u'alt345',
                           'description': u'Index of the novel',
                           'extras': {u'alt_url': u'alt345', u'size': u'345'},
                           'format': u'JSON',
                           'hash': u'def456',
                           'position': 1,
                           'url': u'http://www.annakarenina.com/index.json'}],
            'tags': [{'name': u'russian'}, {'name': u'tolstoy'}],
            'title': u'A Novel By Tolstoy',
            'url': u'http://www.annakarenina.com',
            'version': u'0.7a'
        }

        wee = json.dumps(package)
        postparams = '%s=1' % json.dumps(package)
        res = self.app.post('/api/action/package_create', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)})
        package_created = json.loads(res.body)['result']
        print package_created
        package_created['name'] = 'moo'
        postparams = '%s=1' % json.dumps(package_created)
        res = self.app.post('/api/action/package_update', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)})

        package_updated = json.loads(res.body)['result']
        package_updated.pop('revision_id')
        package_updated.pop('revision_timestamp')
        package_updated.pop('metadata_created')
        package_updated.pop('metadata_modified')

        package_created.pop('revision_id')
        package_created.pop('revision_timestamp')
        package_created.pop('metadata_created')
        package_created.pop('metadata_modified')
        assert package_updated == package_created#, (pformat(json.loads(res.body)), pformat(package_created['result']))

    def test_03_create_private_package(self):

        # Make an organization, because private datasets must belong to one.
        organization = tests.call_action_api(self.app, 'organization_create',
                                             name='test_org',
                                             apikey=self.sysadmin_user.apikey)

        # Create a dataset without specifying visibility
        package_dict = {
            'extras': [{'key': u'original media','value': u'"book"'}],
            'license_id': u'other-open',
            'maintainer_email': None,
            'name': u'annakarenina_vis',
            'notes': u'Some test now',
            'resources': [{'alt_url': u'alt123',
                           'description': u'Full text.',
                           'extras': {u'alt_url': u'alt123', u'size': u'123'},
                           'format': u'plain text',
                           'hash': u'abc123',
                           'position': 0,
                           'url': u'http://www.annakarenina.com/download/'},
                          {'alt_url': u'alt345',
                           'description': u'Index of the novel',
                           'extras': {u'alt_url': u'alt345', u'size': u'345'},
                           'format': u'JSON',
                           'hash': u'def456',
                           'position': 1,
                           'url': u'http://www.annakarenina.com/index.json'}],
            'tags': [{'name': u'russian'}, {'name': u'tolstoy'}],
            'title': u'A Novel By Tolstoy',
            'url': u'http://www.annakarenina.com',
            'owner_org': organization['id'],
            'version': u'0.7a',
        }
        package_created = tests.call_action_api(self.app, 'package_create',
                                              apikey=self.sysadmin_user.apikey,
                                              **package_dict)
        assert package_created['private'] is False

        # Create a new one, explicitly saying it is public
        package_dict['name'] = u'annakareninanew_vis_public'
        package_dict['private'] = False

        package_created_public = tests.call_action_api(self.app,
                                              'package_create',
                                              apikey=self.sysadmin_user.apikey,
                                              **package_dict)
        assert package_created_public['private'] is False

        # Create a new one, explicitly saying it is private
        package_dict['name'] = u'annakareninanew_vis_private'
        package_dict['private'] = True

        package_created_private = tests.call_action_api(self.app,
                                              'package_create',
                                              apikey=self.sysadmin_user.apikey,
                                              **package_dict)
        assert package_created_private['private'] is True


    def test_18_create_package_not_authorized(self):
        # I cannot understand the logic on this one we seem to be user
        # tester but no idea how.
        raise SkipTest

        package = {
            'extras': [{'key': u'original media','value': u'"book"'}],
            'license_id': u'other-open',
            'maintainer': None,
            'maintainer_email': None,
            'name': u'annakareninanew_not_authorized',
            'notes': u'Some test now',
            'tags': [{'name': u'russian'}, {'name': u'tolstoy'}],
            'title': u'A Novel By Tolstoy',
            'url': u'http://www.annakarenina.com',
        }

        wee = json.dumps(package)
        postparams = '%s=1' % json.dumps(package)
        res = self.app.post('/api/action/package_create', params=postparams,
                                     status=StatusCodes.STATUS_403_ACCESS_DENIED)

    def test_41_create_resource(self):

        anna_id = model.Package.by_name(u'annakarenina').id
        resource = {'package_id': anna_id, 'url': 'http://new_url'}
        api_key = model.User.get('testsysadmin').apikey.encode('utf8')
        postparams = '%s=1' % json.dumps(resource)
        res = self.app.post('/api/action/resource_create', params=postparams,
                            extra_environ={'Authorization': api_key })

        resource = json.loads(res.body)['result']

        assert resource['url'] == 'http://new_url'

    def test_42_create_resource_with_error(self):

        anna_id = model.Package.by_name(u'annakarenina').id
        resource = {'package_id': anna_id, 'url': 'new_url', 'created': 'bad_date'}
        api_key = model.User.get('testsysadmin').apikey.encode('utf8')

        postparams = '%s=1' % json.dumps(resource)
        res = self.app.post('/api/action/resource_create', params=postparams,
                            extra_environ={'Authorization': api_key},
                            status=StatusCodes.STATUS_409_CONFLICT)

        assert json.loads(res.body)['error'] ==  {"__type": "Validation Error", "created": ["Date format incorrect"]}



    def test_04_user_list(self):
        # Create deleted user to make sure he won't appear in the user_list
        deleted_user = CreateTestData.create_user('deleted_user')
        deleted_user.delete()
        model.repo.commit()

        postparams = '%s=1' % json.dumps({})
        res = self.app.post('/api/action/user_list', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith(
                "Return a list of the site's user accounts.")
        assert res_obj['success'] == True
        assert len(res_obj['result']) == 7
        assert res_obj['result'][0]['name'] == 'annafan'
        assert res_obj['result'][0]['about'] == 'I love reading Annakarenina. My site: http://anna.com'
        assert not 'apikey' in res_obj['result'][0]

    def test_05_user_show(self):
        # Anonymous request
        postparams = '%s=1' % json.dumps({'id':'annafan'})
        res = self.app.post('/api/action/user_show', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith("Return a user account.")
        assert res_obj['success'] == True
        result = res_obj['result']
        assert result['name'] == 'annafan'
        assert result['about'] == 'I love reading Annakarenina. My site: http://anna.com'
        assert 'activity' in result
        assert 'created' in result
        assert 'display_name' in result
        assert 'number_administered_packages' in result
        assert 'number_of_edits' in result
        assert not 'apikey' in result
        assert not 'reset_key' in result

        # Same user can see his api key
        res = self.app.post('/api/action/user_show', params=postparams,
                            extra_environ={'Authorization': str(self.normal_user.apikey)})

        res_obj = json.loads(res.body)
        result = res_obj['result']
        assert result['name'] == 'annafan'
        assert 'apikey' in result

        # Sysadmin user can see everyone's api key
        res = self.app.post('/api/action/user_show', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)})

        res_obj = json.loads(res.body)
        result = res_obj['result']
        assert result['name'] == 'annafan'
        assert 'apikey' in result

    def test_05_user_show_edits(self):
        postparams = '%s=1' % json.dumps({'id':'tester'})
        res = self.app.post('/api/action/user_show', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith("Return a user account.")
        assert res_obj['success'] == True
        result = res_obj['result']
        assert result['name'] == 'tester'
        assert_equal(result['about'], None)
        assert result['number_of_edits'] >= 1
        edit = result['activity'][-1] # first edit chronologically
        assert_equal(edit['author'], 'tester')
        assert 'timestamp' in edit
        assert_equal(edit['state'], 'active')
        assert_equal(edit['approved_timestamp'], None)
        assert_equal(set(edit['groups']), set(( 'roger', 'david')))
        assert_equal(edit['state'], 'active')
        assert edit['message'].startswith('Creating test data.')
        assert_equal(set(edit['packages']), set(('warandpeace', 'annakarenina')))
        assert 'id' in edit

    def test_05b_user_show_datasets(self):
        postparams = '%s=1' % json.dumps({'id':'annafan'})
        res = self.app.post('/api/action/user_show', params=postparams)
        res_obj = json.loads(res.body)
        result = res_obj['result']
        datasets = result['datasets']
        assert_equal(len(datasets), 1)
        dataset = result['datasets'][0]
        assert_equal(dataset['name'], u'annakarenina')


    def test_10_user_create_parameters_missing(self):
        user_dict = {}

        postparams = '%s=1' % json.dumps(user_dict)
        res = self.app.post('/api/action/user_create', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
                            status=StatusCodes.STATUS_409_CONFLICT)
        res_obj = json.loads(res.body)
        assert res_obj['error'] == {
                '__type': 'Validation Error',
                'name': ['Missing value'],
                'email': ['Missing value'],
                'password': ['Missing value']
            }
        assert res_obj['help'].startswith("Create a new user.")
        assert res_obj['success'] is False

    def test_11_user_create_wrong_password(self):
        user_dict = {'name':'test_create_from_action_api_2',
                'email':'me@test.org',
                      'password':'tes'} #Too short

        postparams = '%s=1' % json.dumps(user_dict)
        res = self.app.post('/api/action/user_create', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
                            status=StatusCodes.STATUS_409_CONFLICT)

        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith('Create a new user.')
        assert res_obj['success'] is False
        assert res_obj['error'] == { '__type': 'Validation Error',
                'password': ['Your password must be 4 characters or longer']}

    def test_12_user_update(self):
        normal_user_dict = {'id': self.normal_user.id,
                            'name': self.normal_user.name,
                            'fullname': 'Updated normal user full name',
                            'email': 'me@test.org',
                            'about':'Updated normal user about'}

        sysadmin_user_dict = {'id': self.sysadmin_user.id,
                            'fullname': 'Updated sysadmin user full name',
                            'email': 'me@test.org',
                            'about':'Updated sysadmin user about'}

        #Normal users can update themselves
        postparams = '%s=1' % json.dumps(normal_user_dict)
        res = self.app.post('/api/action/user_update', params=postparams,
                            extra_environ={'Authorization': str(self.normal_user.apikey)})

        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith("Update a user account.")
        assert res_obj['success'] == True
        result = res_obj['result']
        assert result['id'] == self.normal_user.id
        assert result['name'] == self.normal_user.name
        assert result['fullname'] == normal_user_dict['fullname']
        assert result['about'] == normal_user_dict['about']
        assert 'apikey' in result
        assert 'created' in result
        assert 'display_name' in result
        assert 'number_administered_packages' in result
        assert 'number_of_edits' in result
        assert not 'password' in result

        #Sysadmin users can update themselves
        postparams = '%s=1' % json.dumps(sysadmin_user_dict)
        res = self.app.post('/api/action/user_update', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)})

        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith("Update a user account.")
        assert res_obj['success'] == True
        result = res_obj['result']
        assert result['id'] == self.sysadmin_user.id
        assert result['name'] == self.sysadmin_user.name
        assert result['fullname'] == sysadmin_user_dict['fullname']
        assert result['about'] == sysadmin_user_dict['about']

        #Sysadmin users can update all users
        postparams = '%s=1' % json.dumps(normal_user_dict)
        res = self.app.post('/api/action/user_update', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)})

        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith("Update a user account.")
        assert res_obj['success'] == True
        result = res_obj['result']
        assert result['id'] == self.normal_user.id
        assert result['name'] == self.normal_user.name
        assert result['fullname'] == normal_user_dict['fullname']
        assert result['about'] == normal_user_dict['about']

        #Normal users can not update other users
        postparams = '%s=1' % json.dumps(sysadmin_user_dict)
        res = self.app.post('/api/action/user_update', params=postparams,
                            extra_environ={'Authorization': str(self.normal_user.apikey)},
                            status=StatusCodes.STATUS_403_ACCESS_DENIED)

        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith("Update a user account.")
        assert res_obj['error']['__type'] == 'Authorization Error'
        assert res_obj['success'] is False

    def test_12_user_update_errors(self):
        test_calls = (
            # Empty name
                {'user_dict': {'id': self.normal_user.id,
                          'name':'',
                          'email':'test@test.com'},
                 'messages': [('name','Name must be at least 2 characters long')]},

            # Invalid characters in name
                {'user_dict': {'id': self.normal_user.id,
                          'name':'i++%',
                          'email':'test@test.com'},
                 'messages': [('name','Url must be purely lowercase alphanumeric')]},
            # Existing name
                {'user_dict': {'id': self.normal_user.id,
                          'name':self.sysadmin_user.name,
                          'email':'test@test.com'},
                 'messages': [('name','That login name is not available')]},
            # Missing email
                {'user_dict': {'id': self.normal_user.id,
                          'name':self.normal_user.name},
                 'messages': [('email','Missing value')]},
                 )

        for test_call in test_calls:
            postparams = '%s=1' % json.dumps(test_call['user_dict'])
            res = self.app.post('/api/action/user_update', params=postparams,
                                extra_environ={'Authorization': str(self.normal_user.apikey)},
                                status=StatusCodes.STATUS_409_CONFLICT)
            res_obj = json.loads(res.body)
            for expected_message in test_call['messages']:
                assert expected_message[1] in ''.join(res_obj['error'][expected_message[0]])

    def test_user_delete(self):
        name = 'normal_user'
        CreateTestData.create_user(name)
        user = model.User.get(name)
        user_dict = {'id': user.id}
        postparams = '%s=1' % json.dumps(user_dict)

        res = self.app.post('/api/action/user_delete', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)})

        res_obj = json.loads(res.body)
        deleted_user = model.User.get(name)
        assert res_obj['success'] is True
        assert deleted_user.is_deleted(), deleted_user

    def test_user_delete_requires_data_dict_with_key_id(self):
        user_dict = {'name': 'normal_user'}
        postparams = '%s=1' % json.dumps(user_dict)

        res = self.app.post('/api/action/user_delete', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
                            status=StatusCodes.STATUS_409_CONFLICT)

        res_obj = json.loads(res.body)
        assert res_obj['success'] is False
        assert res_obj['error']['id'] == ['Missing value']

    def test_13_group_list(self):
        postparams = '%s=1' % json.dumps({})
        res = self.app.post('/api/action/group_list', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['result'] == ['david', 'roger']
        assert res_obj['success'] is True
        assert res_obj['help'].startswith(
                "Return a list of the names of the site's groups.")

        # Test GET request
        res = self.app.get('/api/action/group_list')
        res_obj = json.loads(res.body)
        assert res_obj['result'] == ['david', 'roger']

        #Get all fields
        postparams = '%s=1' % json.dumps({'all_fields':True})
        res = self.app.post('/api/action/group_list', params=postparams)
        res_obj = json.loads(res.body)

        assert res_obj['success'] == True
        assert res_obj['result'][0]['name'] == 'david'
        assert res_obj['result'][0]['display_name'] == 'Dave\'s books'
        assert res_obj['result'][0]['packages'] == 2
        assert res_obj['result'][1]['name'] == 'roger', res_obj['result'][1]
        assert res_obj['result'][1]['packages'] == 1
        assert 'id' in res_obj['result'][0]
        assert 'revision_id' in res_obj['result'][0]
        assert 'state' in res_obj['result'][0]

    def test_13_group_list_by_size(self):
        postparams = '%s=1' % json.dumps({'order_by': 'packages'})
        res = self.app.post('/api/action/group_list',
                            params=postparams)
        res_obj = json.loads(res.body)
        assert_equal(sorted(res_obj['result']), ['david','roger'])

    def test_13_group_list_by_size_all_fields(self):
        postparams = '%s=1' % json.dumps({'order_by': 'packages',
                                          'all_fields': 1})
        res = self.app.post('/api/action/group_list',
                            params=postparams)
        res_obj = json.loads(res.body)
        result = res_obj['result']
        assert_equal(len(result), 2)
        assert_equal(result[0]['name'], 'david')
        assert_equal(result[0]['packages'], 2)
        assert_equal(result[1]['name'], 'roger')
        assert_equal(result[1]['packages'], 1)

    def test_14_group_show(self):
        postparams = '%s=1' % json.dumps({'id':'david'})
        res = self.app.post('/api/action/group_show', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith("Return the details of a group.")
        assert res_obj['success'] == True
        result = res_obj['result']
        assert result['name'] == 'david'
        assert result['title'] == result['display_name'] == 'Dave\'s books'
        assert result['state'] == 'active'
        assert 'id' in result
        assert 'revision_id' in result
        assert len(result['packages']) == 2

        #Group not found
        postparams = '%s=1' % json.dumps({'id':'not_present_in_the_db'})
        res = self.app.post('/api/action/group_show', params=postparams,
                            status=StatusCodes.STATUS_404_NOT_FOUND)

        res_obj = json.loads(res.body)
        pprint(res_obj)
        assert res_obj['error'] == {
                '__type': 'Not Found Error',
                'message': 'Not found'
            }
        assert res_obj['help'].startswith('Return the details of a group.')
        assert res_obj['success'] is False

    def test_16_user_autocomplete(self):
        # Create deleted user to make sure he won't appear in the user_list
        deleted_user = CreateTestData.create_user('joe')
        deleted_user.delete()
        model.repo.commit()

        #Empty query
        postparams = '%s=1' % json.dumps({})
        res = self.app.post(
            '/api/action/user_autocomplete',
            params=postparams,
            status=StatusCodes.STATUS_409_CONFLICT)
        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith(
                "Return a list of user names that contain a string.")
        assert res_obj['success'] is False

        #Normal query
        postparams = '%s=1' % json.dumps({'q':'joe'})
        res = self.app.post('/api/action/user_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['result'][0]['name'] == 'joeadmin'
        assert 'id','fullname' in res_obj['result'][0]

    def test_17_bad_action(self):
        #Empty query
        postparams = '%s=1' % json.dumps({})
        res = self.app.post('/api/action/bad_action_name', params=postparams,
                            status=400)
        res_obj = json.loads(res.body)
        assert_equal(res_obj, u'Bad request - Action name not known: bad_action_name')

    def test_19_update_resource(self):
        package = {
            'name': u'annakareninanew',
            'resources': [{
                'alt_url': u'alt123',
                'description': u'Full text.',
                'extras': {u'alt_url': u'alt123', u'size': u'123'},
                'format': u'plain text',
                'hash': u'abc123',
                'position': 0,
                'url': u'http://www.annakarenina.com/download/'
            }],
            'title': u'A Novel By Tolstoy',
            'url': u'http://www.annakarenina.com',
        }

        postparams = '%s=1' % json.dumps(package)
        res = self.app.post('/api/action/package_create', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)})
        package_created = json.loads(res.body)['result']

        resource_created = package_created['resources'][0]
        new_resource_url = u'http://www.annakareinanew.com/download/'
        resource_created['url'] = new_resource_url
        postparams = '%s=1' % json.dumps(resource_created)
        res = self.app.post('/api/action/resource_update', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)})

        resource_updated = json.loads(res.body)['result']
        assert resource_updated['url'] == new_resource_url, resource_updated

        resource_updated.pop('url')
        resource_updated.pop('revision_id')
        resource_updated.pop('revision_timestamp', None)
        resource_created.pop('url')
        resource_created.pop('revision_id')
        resource_created.pop('revision_timestamp', None)
        assert_equal(resource_updated, resource_created)

    def test_20_task_status_update(self):
        package_created = self._add_basic_package(u'test_task_status_update')

        task_status = {
            'entity_id': package_created['id'],
            'entity_type': u'package',
            'task_type': u'test_task',
            'key': u'test_key',
            'value': u'test_value',
            'state': u'test_state',
            'error': u'test_error',
        }
        postparams = '%s=1' % json.dumps(task_status)
        res = self.app.post(
            '/api/action/task_status_update', params=postparams,
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
        )
        task_status_updated = json.loads(res.body)['result']

        task_status_id = task_status_updated.pop('id')
        task_status_updated.pop('last_updated')
        assert task_status_updated == task_status, (task_status_updated, task_status)

        task_status_updated['id'] = task_status_id
        task_status_updated['value'] = u'test_value_2'
        postparams = '%s=1' % json.dumps(task_status_updated)
        res = self.app.post(
            '/api/action/task_status_update', params=postparams,
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
        )
        task_status_updated_2 = json.loads(res.body)['result']
        task_status_updated_2.pop('last_updated')
        assert task_status_updated_2 == task_status_updated, task_status_updated_2

    def test_21_task_status_update_many(self):
        package_created = self._add_basic_package(u'test_task_status_update_many')
        task_statuses = {
            'data': [
                {
                    'entity_id': package_created['id'],
                    'entity_type': u'package',
                    'task_type': u'test_task',
                    'key': u'test_task_1',
                    'value': u'test_value_1',
                    'state': u'test_state',
                    'error': u'test_error'
                },
                {
                    'entity_id': package_created['id'],
                    'entity_type': u'package',
                    'task_type': u'test_task',
                    'key': u'test_task_2',
                    'value': u'test_value_2',
                    'state': u'test_state',
                    'error': u'test_error'
                }
            ]
        }
        postparams = '%s=1' % json.dumps(task_statuses)
        res = self.app.post(
            '/api/action/task_status_update_many', params=postparams,
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
        )
        task_statuses_updated = json.loads(res.body)['result']['results']
        for i in range(len(task_statuses['data'])):
            task_status = task_statuses['data'][i]
            task_status_updated = task_statuses_updated[i]
            task_status_updated.pop('id')
            task_status_updated.pop('last_updated')
            assert task_status == task_status_updated, (task_status_updated, task_status, i)

    def test_22_task_status_normal_user_not_authorized(self):
        task_status = {}
        postparams = '%s=1' % json.dumps(task_status)
        res = self.app.post(
            '/api/action/task_status_update', params=postparams,
            extra_environ={'Authorization': str(self.normal_user.apikey)},
            status=StatusCodes.STATUS_403_ACCESS_DENIED
        )
        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith("Update a task status.")
        assert res_obj['success'] is False
        assert res_obj['error']['__type'] == 'Authorization Error'

    def test_23_task_status_validation(self):
        task_status = {}
        postparams = '%s=1' % json.dumps(task_status)
        res = self.app.post(
            '/api/action/task_status_update', params=postparams,
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
            status=StatusCodes.STATUS_409_CONFLICT
        )

    def test_24_task_status_show(self):
        package_created = self._add_basic_package(u'test_task_status_show')

        task_status = {
            'entity_id': package_created['id'],
            'entity_type': u'package',
            'task_type': u'test_task',
            'key': u'test_task_status_show',
            'value': u'test_value',
            'state': u'test_state',
            'error': u'test_error'
        }
        postparams = '%s=1' % json.dumps(task_status)
        res = self.app.post(
            '/api/action/task_status_update', params=postparams,
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
        )
        task_status_updated = json.loads(res.body)['result']

        # make sure show works when giving a task status ID
        postparams = '%s=1' % json.dumps({'id': task_status_updated['id']})
        res = self.app.post(
            '/api/action/task_status_show', params=postparams,
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
        )
        task_status_show = json.loads(res.body)['result']

        task_status_show.pop('last_updated')
        task_status_updated.pop('last_updated')
        assert task_status_show == task_status_updated, (task_status_show, task_status_updated)

        # make sure show works when giving a (entity_id, task_type, key) tuple
        postparams = '%s=1' % json.dumps({
            'entity_id': task_status['entity_id'],
            'task_type': task_status['task_type'],
            'key': task_status['key']
        })
        res = self.app.post(
            '/api/action/task_status_show', params=postparams,
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
        )
        task_status_show = json.loads(res.body)['result']

        task_status_show.pop('last_updated')
        assert task_status_show == task_status_updated, (task_status_show, task_status_updated)

    def test_25_task_status_delete(self):
        package_created = self._add_basic_package(u'test_task_status_delete')

        task_status = {
            'entity_id': package_created['id'],
            'entity_type': u'package',
            'task_type': u'test_task',
            'key': u'test_task_status_delete',
            'value': u'test_value',
            'state': u'test_state',
            'error': u'test_error'
        }
        postparams = '%s=1' % json.dumps(task_status)
        res = self.app.post(
            '/api/action/task_status_update', params=postparams,
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
        )
        task_status_updated = json.loads(res.body)['result']

        postparams = '%s=1' % json.dumps({'id': task_status_updated['id']})
        res = self.app.post(
            '/api/action/task_status_delete', params=postparams,
            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
        )
        task_status_delete = json.loads(res.body)
        assert task_status_delete['success'] == True

    def test_26_resource_show(self):
        pkg = model.Package.get('annakarenina')
        resource = pkg.resources[0]
        postparams = '%s=1' % json.dumps({'id': resource.id})
        res = self.app.post('/api/action/resource_show', params=postparams)
        result = json.loads(res.body)['result']

        # Remove tracking data from the result dict. This tracking data is
        # added by the logic, so the other resource dict taken straight from
        # resource_dictize() won't have it.
        del result['tracking_summary']

        resource_dict = resource_dictize(resource, {'model': model})
        assert result == resource_dict, (result, resource_dict)

    def test_27_get_site_user_not_authorized(self):
        assert_raises(NotAuthorized,
                     get_action('get_site_user'),
                     {'model': model}, {})
        user = model.User.get('test.ckan.net')
        assert not user

        site_id = config.get('ckan.site_id')
        user = get_action('get_site_user')({'model': model, 'ignore_auth': True}, {})
        assert user['name'] == site_id

        user = model.User.get(site_id)
        assert user

        user=get_action('get_site_user')({'model': model, 'ignore_auth': True}, {})
        assert user['name'] == site_id

        user = model.Session.query(model.User).filter_by(name=site_id).one()
        assert user

    def test_28_group_package_show(self):
        group_id = model.Group.get('david').id
        group_packages = get_action('group_package_show')(
            {'model': model, 'user': self.normal_user.name, 'ignore_auth': True},
            {'id': group_id}
        )
        assert len(group_packages) == 2, group_packages
        group_names = set([g.get('name') for g in group_packages])
        assert group_names == set(['annakarenina', 'warandpeace']), group_names

    def test_29_group_package_show_pending(self):
        context = {'model': model, 'session': model.Session, 'user': self.sysadmin_user.name, 'api_version': 2, 'ignore_auth': True}
        group = {
            'name': 'test_group_pending_package',
            'packages': [{'id': model.Package.get('annakarenina').id}]
        }
        group = get_action('group_create')(context, group)

        pkg = {
            'name': 'test_pending_package',
            'groups': [{'id': group['id']}]
        }
        pkg = get_action('package_create')(context, pkg)
        # can't seem to add a package with 'pending' state, so update it
        pkg['state'] = 'pending'
        get_action('package_update')(context, pkg)

        group_packages = get_action('group_package_show')(context, {'id': group['id']})
        assert len(group_packages) == 2, (len(group_packages), group_packages)
        group_names = set([g.get('name') for g in group_packages])
        assert group_names == set(['annakarenina', 'test_pending_package']), group_names

        get_action('group_delete')(context, group)
        get_action('package_delete')(context, pkg)

    def test_30_status_show(self):
        postparams = '%s=1' % json.dumps({})
        res = self.app.post('/api/action/status_show', params=postparams)
        status = json.loads(res.body)['result']
        assert_equal(status['site_title'], 'CKAN')
        assert_equal(status['ckan_version'], ckan.__version__)
        assert_equal(status['site_url'], 'http://test.ckan.net')

    def test_31_bad_request_format(self):
        postparams = '%s=1' % json.dumps('not a dict')
        res = self.app.post('/api/action/package_list', params=postparams,
                            status=400)
        assert "Bad request - JSON Error: Request data JSON decoded to 'not a dict' but it needs to be a dictionary." in res.body, res.body

    def test_31_bad_request_format_not_json(self):
        postparams = '=1'
        res = self.app.post('/api/action/package_list', params=postparams,
                            status=400)
        assert "Bad request - Bad request data: Request data JSON decoded to '' but it needs to be a dictionary." in res.body, res.body

    def test_32_get_domain_object(self):
        anna = model.Package.by_name(u'annakarenina')
        assert_equal(get_domain_object(model, anna.name).name, anna.name)
        assert_equal(get_domain_object(model, anna.id).name, anna.name)
        group = model.Group.by_name(u'david')
        assert_equal(get_domain_object(model, group.name).name, group.name)
        assert_equal(get_domain_object(model, group.id).name, group.name)

    def test_33_roles_show(self):
        anna = model.Package.by_name(u'annakarenina')
        annafan = model.User.by_name(u'annafan')
        postparams = '%s=1' % json.dumps({'domain_object': anna.id})
        res = self.app.post('/api/action/roles_show', params=postparams,
                            extra_environ={'Authorization': str(annafan.apikey)},
                            status=200)
        results = json.loads(res.body)['result']
        anna = model.Package.by_name(u'annakarenina')
        assert_equal(results['domain_object_id'], anna.id)
        assert_equal(results['domain_object_type'], 'Package')
        roles = results['roles']
        assert len(roles) > 2, results
        assert set(roles[0].keys()) > set(('user_id', 'package_id', 'role',
                                           'context', 'user_object_role_id'))

    def test_34_roles_show_for_user(self):
        anna = model.Package.by_name(u'annakarenina')
        annafan = model.User.by_name(u'annafan')
        postparams = '%s=1' % json.dumps({'domain_object': anna.id,
                                          'user': 'annafan'})
        res = self.app.post('/api/action/roles_show', params=postparams,
                            extra_environ={'Authorization': str(annafan.apikey)},
                            status=200)
        results = json.loads(res.body)['result']
        anna = model.Package.by_name(u'annakarenina')
        assert_equal(results['domain_object_id'], anna.id)
        assert_equal(results['domain_object_type'], 'Package')
        roles = results['roles']
        assert_equal(len(roles), 1)
        assert set(roles[0].keys()) > set(('user_id', 'package_id', 'role',
                                           'context', 'user_object_role_id'))


    def test_35_user_role_update(self):
        anna = model.Package.by_name(u'annakarenina')
        annafan = model.User.by_name(u'annafan')
        roles_before = get_action('roles_show') \
                                 ({'model': model, 'session': model.Session}, \
                                  {'domain_object': anna.id,
                                   'user': 'tester'})
        postparams = '%s=1' % json.dumps({'user': 'tester',
                                          'domain_object': anna.id,
                                          'roles': ['reader']})

        res = self.app.post('/api/action/user_role_update', params=postparams,
                            extra_environ={'Authorization': str(annafan.apikey)},
                            status=200)
        results = json.loads(res.body)['result']
        assert_equal(len(results['roles']), 1)
        anna = model.Package.by_name(u'annakarenina')
        tester = model.User.by_name(u'tester')
        assert_equal(results['roles'][0]['role'], 'reader')
        assert_equal(results['roles'][0]['package_id'], anna.id)
        assert_equal(results['roles'][0]['user_id'], tester.id)

        roles_after = get_action('roles_show') \
                      ({'model': model, 'session': model.Session}, \
                       {'domain_object': anna.id,
                        'user': 'tester'})
        assert_equal(results['roles'], roles_after['roles'])


    def test_37_user_role_update_disallowed(self):
        # Roles are no longer used so ignore this test
        raise SkipTest
        anna = model.Package.by_name(u'annakarenina')
        postparams = '%s=1' % json.dumps({'user': 'tester',
                                          'domain_object': anna.id,
                                          'roles': ['editor']})
        # tester has no admin priviledges for this package
        res = self.app.post('/api/action/user_role_update', params=postparams,
                            extra_environ={'Authorization': 'tester'},
                            status=403)

    def test_38_user_role_bulk_update(self):
        anna = model.Package.by_name(u'annakarenina')
        annafan = model.User.by_name(u'annafan')
        all_roles_before = TestRoles.get_roles(anna.id)
        user_roles_before = TestRoles.get_roles(anna.id, user_ref=annafan.name)
        roles_before = get_action('roles_show') \
                                 ({'model': model, 'session': model.Session}, \
                                  {'domain_object': anna.id})
        postparams = '%s=1' % json.dumps({'domain_object': anna.id,
                                          'user_roles': [
                    {'user': 'annafan',
                     'roles': ('admin', 'editor')},
                    {'user': 'russianfan',
                     'roles': ['editor']},
                                              ]})

        res = self.app.post('/api/action/user_role_bulk_update', params=postparams,
                            extra_environ={'Authorization': str(annafan.apikey)},
                            status=200)
        results = json.loads(res.body)['result']

        # check there are 2 new roles (not 3 because annafan is already admin)
        all_roles_after = TestRoles.get_roles(anna.id)
        user_roles_after = TestRoles.get_roles(anna.id, user_ref=annafan.name)
        assert_equal(set(all_roles_before) ^ set(all_roles_after),
                     set([u'"annafan" is "editor" on "annakarenina"',
                          u'"russianfan" is "editor" on "annakarenina"']))

        roles_after = get_action('roles_show') \
                      ({'model': model, 'session': model.Session}, \
                       {'domain_object': anna.id})
        assert_equal(results['roles'], roles_after['roles'])

    def test_40_task_resource_status(self):

        try:
            import ckan.lib.celery_app as celery_app
        except ImportError:
            raise SkipTest('celery not installed')

        backend = celery_app.celery.backend
        ##This creates the database tables as a side effect, can not see another way
        ##to make tables unless you actually create a task.
        celery_result_session = backend.ResultSession()

        ## need to do inserts as setting up an embedded celery is too much for these tests
        model.Session.connection().execute(
            '''INSERT INTO task_status (id, entity_id, entity_type, task_type, key, value, state, error, last_updated) VALUES ('5753adae-cd0d-4327-915d-edd832d1c9a3', '749cdcf2-3fc8-44ae-aed0-5eff8cc5032c', 'resource', 'qa', 'celery_task_id', '51f2105d-85b1-4393-b821-ac11475919d9', NULL, '', '2012-04-20 21:32:45.553986');
               INSERT INTO celery_taskmeta (id, task_id, status, result, date_done, traceback) VALUES (2, '51f2105d-85b1-4393-b821-ac11475919d9', 'FAILURE', '52e', '2012-04-20 21:33:01.622557', 'Traceback')'''
        )
        model.Session.commit()
        res = json.loads(self.app.post('/api/action/resource_status_show',
                            params=json.dumps({'id': '749cdcf2-3fc8-44ae-aed0-5eff8cc5032c'}),
                            status=200).body)

        assert res['help'].startswith(
                "Return the statuses of a resource's tasks.")
        assert res['success'] is True
        assert res['result'] == [{"status": "FAILURE", "entity_id": "749cdcf2-3fc8-44ae-aed0-5eff8cc5032c", "task_type": "qa", "last_updated": "2012-04-20T21:32:45.553986", "date_done": "2012-04-20T21:33:01.622557", "entity_type": "resource", "traceback": "Traceback", "value": "51f2105d-85b1-4393-b821-ac11475919d9", "state": None, "key": "celery_task_id", "error": "", "id": "5753adae-cd0d-4327-915d-edd832d1c9a3"}]

    def test_41_missing_action(self):
        try:
            get_action('unicorns')
            assert False, "We found a non-existent action"
        except KeyError:
            assert True

    def test_42_resource_search_with_single_field_query(self):
        request_body = {
            'query': ["description:index"],
        }
        postparams = json.dumps(request_body)
        response = self.app.post('/api/action/resource_search',
                                 params=postparams)
        result = json.loads(response.body)['result']['results']
        count = json.loads(response.body)['result']['count']

        ## Due to the side-effect of previously run tests, there may be extra
        ## resources in the results.  So just check that each found Resource
        ## matches the search criteria
        assert count > 0
        for resource in result:
            assert "index" in resource['description'].lower()

    def test_42_resource_search_across_multiple_fields(self):
        request_body = {
            'query': ["description:index", "format:json"],
        }
        postparams = json.dumps(request_body)
        response = self.app.post('/api/action/resource_search',
                                 params=postparams)
        result = json.loads(response.body)['result']['results']
        count = json.loads(response.body)['result']['count']

        ## Due to the side-effect of previously run tests, there may be extra
        ## resources in the results.  So just check that each found Resource
        ## matches the search criteria
        assert count > 0
        for resource in result:
            assert "index" in resource['description'].lower()
            assert "json" in resource['format'].lower()

    def test_42_resource_search_test_percentage_is_escaped(self):
        request_body = {
            'query': ["description:index%"],
        }
        postparams = json.dumps(request_body)
        response = self.app.post('/api/action/resource_search',
                                 params=postparams)
        count = json.loads(response.body)['result']['count']

        # There shouldn't be any results.  If the '%' character wasn't
        # escaped correctly, then the search would match because of the
        # unescaped wildcard.
        assert count is 0

    def test_42_resource_search_fields_parameter_still_accepted(self):
        '''The fields parameter is deprecated, but check it still works.

        Remove this test when removing the fields parameter.  (#2603)
        '''
        request_body = {
            'fields': {"description": "index"},
        }

        postparams = json.dumps(request_body)
        response = self.app.post('/api/action/resource_search',
                                 params=postparams)
        result = json.loads(response.body)['result']['results']
        count = json.loads(response.body)['result']['count']

        ## Due to the side-effect of previously run tests, there may be extra
        ## resources in the results.  So just check that each found Resource
        ## matches the search criteria
        assert count > 0
        for resource in result:
            assert "index" in resource['description'].lower()

    def test_42_resource_search_accessible_via_get_request(self):
        response = self.app.get('/api/action/resource_search'
                                '?query=description:index&query=format:json')

        result = json.loads(response.body)['result']['results']
        count = json.loads(response.body)['result']['count']

        ## Due to the side-effect of previously run tests, there may be extra
        ## resources in the results.  So just check that each found Resource
        ## matches the search criteria
        assert count > 0
        for resource in result:
            assert "index" in resource['description'].lower()
            assert "json" in resource['format'].lower()

    def test_package_create_duplicate_extras_error(self):
        import ckan.tests
        import paste.fixture
        import pylons.test

        # Posting a dataset dict to package_create containing two extras dicts
        # with the same key, should return a Validation Error.
        app = paste.fixture.TestApp(pylons.test.pylonsapp)
        error = ckan.tests.call_action_api(app, 'package_create',
                apikey=self.sysadmin_user.apikey, status=409,
                name='foobar', extras=[{'key': 'foo', 'value': 'bar'},
                    {'key': 'foo', 'value': 'gar'}])
        assert error['__type'] == 'Validation Error'
        assert error['extras_validation'] == ['Duplicate key "foo"']

    def test_package_update_remove_org_error(self):
        import ckan.tests
        import paste.fixture
        import pylons.test

        app = paste.fixture.TestApp(pylons.test.pylonsapp)
        org = ckan.tests.call_action_api(app, 'organization_create',
                apikey=self.sysadmin_user.apikey, name='myorganization')
        package = ckan.tests.call_action_api(app, 'package_create',
                apikey=self.sysadmin_user.apikey, name='foobarbaz', owner_org=org['id'])

        assert package['owner_org']
        package['owner_org'] = ''
        res = ckan.tests.call_action_api(app, 'package_update',
                apikey=self.sysadmin_user.apikey, **package)
        assert not res['owner_org'], res['owner_org']

    def test_package_update_duplicate_extras_error(self):
        import ckan.tests
        import paste.fixture
        import pylons.test

        # We need to create a package first, so that we can update it.
        app = paste.fixture.TestApp(pylons.test.pylonsapp)
        package = ckan.tests.call_action_api(app, 'package_create',
                apikey=self.sysadmin_user.apikey, name='foobar')

        # Posting a dataset dict to package_update containing two extras dicts
        # with the same key, should return a Validation Error.
        package['extras'] = [{'key': 'foo', 'value': 'bar'},
                    {'key': 'foo', 'value': 'gar'}]
        error = ckan.tests.call_action_api(app, 'package_update',
                apikey=self.sysadmin_user.apikey, status=409, **package)
        assert error['__type'] == 'Validation Error'
        assert error['extras_validation'] == ['Duplicate key "foo"']

class TestActionTermTranslation(WsgiAppCase):

    @classmethod
    def setup_class(self):
        CreateTestData.create()
        self.sysadmin_user = model.User.get('testsysadmin')
        self.normal_user = model.User.get('annafan')

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_1_update_single(self):
        postparams = '%s=1' % json.dumps(
            {"term" : "moo",
             "term_translation": "moo",
             "lang_code" : "fr"
            }
        )

        res = self.app.post('/api/action/term_translation_update', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
                            status=200)

        assert json.loads(res.body)['success']

        postparams = '%s=1' % json.dumps(
            {"term" : "moo",
             "term_translation": "moomoo",
             "lang_code" : "fr"
            }
        )

        res = self.app.post('/api/action/term_translation_update', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
                            status=200)

        assert json.loads(res.body)['success']

        postparams = '%s=1' % json.dumps(
            {"term" : "moo",
             "term_translation": "moomoo",
             "lang_code" : "en"
            }
        )

        res = self.app.post('/api/action/term_translation_update', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
                            status=200)

        assert json.loads(res.body)['success']

        postparams = '%s=1' % json.dumps({"terms" : ["moo"]})

        res = self.app.post('/api/action/term_translation_show', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
                            status=200)

        assert json.loads(res.body)['success']
        assert json.loads(res.body)['result'] == [{u'lang_code': u'fr', u'term': u'moo', u'term_translation': u'moomoo'},
                                                  {u'lang_code': u'en', u'term': u'moo', u'term_translation': u'moomoo'}], json.loads(res.body)

    def test_2_update_many(self):

        postparams = '%s=1' % json.dumps({'data': [
             {"term" : "many",
              "term_translation": "manymoo",
              "lang_code" : "fr"
             },
             {"term" : "many",
              "term_translation": "manymoo",
              "lang_code" : "en"
             },
             {"term" : "many",
              "term_translation": "manymoomoo",
              "lang_code" : "en"
             }
            ]
        }
        )
        res = self.app.post('/api/action/term_translation_update_many', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
                            status=200)

        assert json.loads(res.body)['result']['success'] == '3 rows updated', json.loads(res.body)

        postparams = '%s=1' % json.dumps({"terms" : ["many"]})
        res = self.app.post('/api/action/term_translation_show', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)},
                            status=200)

        assert json.loads(res.body)['result'] == [{u'lang_code': u'fr', u'term': u'many', u'term_translation': u'manymoo'},
                                                  {u'lang_code': u'en', u'term': u'many', u'term_translation': u'manymoomoo'}], json.loads(res.body)




class TestActionPackageSearch(WsgiAppCase):

    @classmethod
    def setup_class(cls):
        setup_test_search_index()
        CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_1_basic(self):
        params = {
                'q':'tolstoy',
                'facet.field': ['groups', 'tags', 'res_format', 'license'],
                'rows': 20,
                'start': 0,
            }
        postparams = '%s=1' % json.dumps(params)
        res = self.app.post('/api/action/package_search', params=postparams)
        res = json.loads(res.body)
        result = res['result']
        assert_equal(res['success'], True)
        assert_equal(result['count'], 1)
        assert_equal(result['results'][0]['name'], 'annakarenina')

        # Test GET request
        params_json_list = params
        params_json_list['facet.field'] = json.dumps(params['facet.field'])
        url_params = urllib.urlencode(params_json_list)
        res = self.app.get('/api/action/package_search?{0}'.format(url_params))
        res = json.loads(res.body)
        result = res['result']
        assert_equal(res['success'], True)
        assert_equal(result['count'], 1)
        assert_equal(result['results'][0]['name'], 'annakarenina')

    def test_1_facet_limit(self):
        params = {
                'q':'*:*',
                'facet.field': ['groups', 'tags', 'res_format', 'license'],
                'rows': 20,
                'start': 0,
            }
        postparams = '%s=1' % json.dumps(params)
        res = self.app.post('/api/action/package_search', params=postparams)
        res = json.loads(res.body)
        assert_equal(res['success'], True)

        assert_equal(len(res['result']['search_facets']['groups']['items']), 2)

        params = {
                'q':'*:*',
                'facet.field': ['groups', 'tags', 'res_format', 'license'],
                'facet.limit': 1,
                'rows': 20,
                'start': 0,
            }
        postparams = '%s=1' % json.dumps(params)
        res = self.app.post('/api/action/package_search', params=postparams)
        res = json.loads(res.body)
        assert_equal(res['success'], True)

        assert_equal(len(res['result']['search_facets']['groups']['items']), 1)

        params = {
                'q':'*:*',
                'facet.field': ['groups', 'tags', 'res_format', 'license'],
                'facet.limit': -1, # No limit
                'rows': 20,
                'start': 0,
            }
        postparams = '%s=1' % json.dumps(params)
        res = self.app.post('/api/action/package_search', params=postparams)
        res = json.loads(res.body)
        assert_equal(res['success'], True)

        assert_equal(len(res['result']['search_facets']['groups']['items']), 2)

    def test_1_basic_no_params(self):
        postparams = '%s=1' % json.dumps({})
        res = self.app.post('/api/action/package_search', params=postparams)
        res = json.loads(res.body)
        result = res['result']
        assert_equal(res['success'], True)
        assert_equal(result['count'], 2)
        assert result['results'][0]['name'] in ('annakarenina', 'warandpeace')

        # Test GET request
        res = self.app.get('/api/action/package_search')
        res = json.loads(res.body)
        result = res['result']
        assert_equal(res['success'], True)
        assert_equal(result['count'], 2)
        assert result['results'][0]['name'] in ('annakarenina', 'warandpeace')

    def test_2_bad_param(self):
        postparams = '%s=1' % json.dumps({
                'sort':'metadata_modified',
            })
        res = self.app.post('/api/action/package_search', params=postparams,
                            status=409)
        assert '"message": "Search error:' in res.body, res.body
        assert 'SOLR returned an error' in res.body, res.body
        # solr error is 'Missing sort order' or 'Missing_sort_order',
        # depending on the solr version.
        assert 'sort' in res.body, res.body

    def test_3_bad_param(self):
        postparams = '%s=1' % json.dumps({
                'weird_param':True,
            })
        res = self.app.post('/api/action/package_search', params=postparams,
                            status=400)
        assert '"message": "Search Query is invalid:' in res.body, res.body
        assert '"Invalid search parameters: [\'weird_param\']' in res.body, res.body

    def test_4_sort_by_metadata_modified(self):
        search_params = '%s=1' % json.dumps({
            'q': '*:*',
            'fl': 'name, metadata_modified',
            'sort': u'metadata_modified desc'
        })

        # modify warandpeace, check that it is the first search result
        rev = model.repo.new_revision()
        pkg = model.Package.get('warandpeace')
        pkg.title = "War and Peace [UPDATED]"

        pkg.metadata_modified = datetime.datetime.utcnow()
        model.repo.commit_and_remove()

        res = self.app.post('/api/action/package_search', params=search_params)
        result = json.loads(res.body)['result']
        result_names = [r['name'] for r in result['results']]
        assert result_names == ['warandpeace', 'annakarenina'], result_names

        # modify annakarenina, check that it is the first search result
        rev = model.repo.new_revision()
        pkg = model.Package.get('annakarenina')
        pkg.title = "A Novel By Tolstoy [UPDATED]"
        pkg.metadata_modified = datetime.datetime.utcnow()
        model.repo.commit_and_remove()

        res = self.app.post('/api/action/package_search', params=search_params)
        result = json.loads(res.body)['result']
        result_names = [r['name'] for r in result['results']]
        assert result_names == ['annakarenina', 'warandpeace'], result_names

        # add a tag to warandpeace, check that it is the first result
        pkg = model.Package.get('warandpeace')
        pkg_params = '%s=1' % json.dumps({'id': pkg.id})
        res = self.app.post('/api/action/package_show', params=pkg_params)
        pkg_dict = json.loads(res.body)['result']
        pkg_dict['tags'].append({'name': 'new-tag'})
        pkg_params = '%s=1' % json.dumps(pkg_dict)
        res = self.app.post('/api/action/package_update', params=pkg_params,
                            extra_environ={'Authorization':  str(self.sysadmin_user.apikey)})

        res = self.app.post('/api/action/package_search', params=search_params)
        result = json.loads(res.body)['result']
        result_names = [r['name'] for r in result['results']]
        assert result_names == ['warandpeace', 'annakarenina'], result_names

class MockPackageSearchPlugin(SingletonPlugin):
    implements(IPackageController, inherit=True)

    def before_index(self, data_dict):
        data_dict['extras_test'] = 'abcabcabc'
        return data_dict

    def before_search(self, search_params):
        if 'extras' in search_params and 'ext_avoid' in search_params['extras']:
            assert 'q' in search_params

        if 'extras' in search_params and 'ext_abort' in search_params['extras']:
            assert 'q' in search_params
            # Prevent the actual query
            search_params['abort_search'] = True

        return search_params

    def after_search(self, search_results, search_params):

        assert 'results' in search_results
        assert 'count' in search_results
        assert 'search_facets' in search_results

        if 'extras' in search_params and 'ext_avoid' in search_params['extras']:
            # Remove results with a certain value
            avoid = search_params['extras']['ext_avoid']

            for i,result in enumerate(search_results['results']):
                if avoid.lower() in result['name'].lower() or avoid.lower() in result['title'].lower():
                    search_results['results'].pop(i)
                    search_results['count'] -= 1

        return search_results

    def before_view(self, data_dict):

        data_dict['title'] = 'string_not_found_in_rest_of_template'

        return data_dict

MockPackageSearchPlugin().disable()

class TestSearchPluginInterface(WsgiAppCase):

    @classmethod
    def setup_class(cls):
        MockPackageSearchPlugin().activate()
        MockPackageSearchPlugin().enable()
        setup_test_search_index()
        CreateTestData.create()
        MockPackageSearchPlugin().disable()
        cls.sysadmin_user = model.User.get('testsysadmin')

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def setup(self):
        MockPackageSearchPlugin().enable()

    def teardown(self):
        MockPackageSearchPlugin().disable()

    def test_search_plugin_interface_search(self):
        avoid = 'Tolstoy'
        search_params = '%s=1' % json.dumps({
            'q': '*:*',
            'extras' : {'ext_avoid':avoid}
        })

        res = self.app.post('/api/action/package_search', params=search_params)

        results_dict = json.loads(res.body)['result']
        for result in results_dict['results']:
            assert not avoid.lower() in result['title'].lower()

        assert results_dict['count'] == 1

    def test_search_plugin_interface_abort(self):

        search_params = '%s=1' % json.dumps({
            'q': '*:*',
            'extras' : {'ext_abort':True}
        })

        res = self.app.post('/api/action/package_search', params=search_params)

        # Check that the query was aborted and no results returned
        res_dict = json.loads(res.body)['result']
        assert res_dict['count'] == 0
        assert len(res_dict['results']) == 0

    def test_before_index(self):

        # no datasets get aaaaaaaa
        search_params = '%s=1' % json.dumps({
            'q': 'aaaaaaaa',
        })

        res = self.app.post('/api/action/package_search', params=search_params)

        res_dict = json.loads(res.body)['result']
        assert res_dict['count'] == 0
        assert len(res_dict['results']) == 0

        # all datasets should get abcabcabc
        search_params = '%s=1' % json.dumps({
            'q': 'abcabcabc',
        })
        res = self.app.post('/api/action/package_search', params=search_params)

        res_dict = json.loads(res.body)['result']
        assert res_dict['count'] == 2, res_dict['count']
        assert len(res_dict['results']) == 2

    def test_before_view(self):
        res = self.app.get('/dataset/annakarenina')

        assert 'string_not_found_in_rest_of_template' in res.body

        res = self.app.get('/dataset?q=')
        assert res.body.count('string_not_found_in_rest_of_template') == 2


class TestBulkActions(WsgiAppCase):

    @classmethod
    def setup_class(cls):
        search.clear()
        model.Session.add_all([
            model.User(name=u'sysadmin', apikey=u'sysadmin',
                       password=u'sysadmin', sysadmin=True),
        ])
        model.Session.commit()

        data_dict = '%s=1' % json.dumps({
            'name': 'org',
        })
        res = cls.app.post('/api/action/organization_create',
                            extra_environ={'Authorization': 'sysadmin'},
                            params=data_dict)
        cls.org_id = json.loads(res.body)['result']['id']

        cls.package_ids = []
        for i in range(0,12):
            data_dict = '%s=1' % json.dumps({
                'name': 'name{i}'.format(i=i),
                'owner_org': 'org',
            })
            res = cls.app.post('/api/action/package_create',
                                extra_environ={'Authorization': 'sysadmin'},
                                params=data_dict)
            cls.package_ids.append(json.loads(res.body)['result']['id'])


    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_01_make_private_then_public(self):
        data_dict = '%s=1' % json.dumps({
            'datasets': self.package_ids,
            'org_id': self.org_id,
        })
        res = self.app.post('/api/action/bulk_update_private',
                            extra_environ={'Authorization': 'sysadmin'},
                            params=data_dict)

        dataset_list = [row.private for row in
                        model.Session.query(model.Package.private).all()]
        assert len(dataset_list) == 12, len(dataset_list)
        assert all(dataset_list)

        res = self.app.get('/api/action/package_search?q=*:*')
        assert json.loads(res.body)['result']['count'] == 0

        res = self.app.post('/api/action/bulk_update_public',
                            extra_environ={'Authorization': 'sysadmin'},
                            params=data_dict)

        dataset_list = [row.private for row in
                        model.Session.query(model.Package.private).all()]
        assert len(dataset_list) == 12, len(dataset_list)
        assert not any(dataset_list)

        res = self.app.get('/api/action/package_search?q=*:*')
        assert json.loads(res.body)['result']['count'] == 12

    def test_02_bulk_delete(self):

        data_dict = '%s=1' % json.dumps({
            'datasets': self.package_ids,
            'org_id': self.org_id,
        })
        res = self.app.post('/api/action/bulk_update_delete',
                            extra_environ={'Authorization': 'sysadmin'},
                            params=data_dict)

        dataset_list = [row.state for row in
                        model.Session.query(model.Package.state).all()]
        assert len(dataset_list) == 12, len(dataset_list)
        assert all(state == 'deleted' for state in dataset_list)

        res = self.app.get('/api/action/package_search?q=*:*')
        assert json.loads(res.body)['result']['count'] == 0


class TestGroupOrgView(WsgiAppCase):

    @classmethod
    def setup_class(cls):
        model.Session.add_all([
            model.User(name=u'sysadmin', apikey=u'sysadmin',
                       password=u'sysadmin', sysadmin=True),
        ])
        model.Session.commit()

        org_dict = '%s=1' % json.dumps({
            'name': 'org',
        })
        res = cls.app.post('/api/action/organization_create',
                            extra_environ={'Authorization': 'sysadmin'},
                            params=org_dict)
        cls.org_id = json.loads(res.body)['result']['id']

        group_dict = '%s=1' % json.dumps({
            'name': 'group',
        })
        res = cls.app.post('/api/action/group_create',
                            extra_environ={'Authorization': 'sysadmin'},
                            params=group_dict)
        cls.group_id = json.loads(res.body)['result']['id']

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_1_view_org(self):
        res = self.app.get('/api/action/organization_show',
                params={'id': self.org_id})
        res_json = json.loads(res.body)
        assert res_json['success'] is True

        res = self.app.get('/api/action/group_show',
                params={'id': self.org_id}, expect_errors=True)
        res_json = json.loads(res.body)
        assert res_json['success'] is False

    def test_2_view_group(self):
        res = self.app.get('/api/action/group_show',
                params={'id': self.group_id})
        res_json = json.loads(res.body)
        assert res_json['success'] is True

        res = self.app.get('/api/action/organization_show',
                params={'id': self.group_id}, expect_errors=True)
        res_json = json.loads(res.body)
        assert res_json['success'] is False


class TestResourceAction(WsgiAppCase):

    sysadmin_user = None

    normal_user = None

    @classmethod
    def setup_class(cls):
        search.clear()
        CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def _add_basic_package(self, package_name=u'test_package', **kwargs):
        package = {
            'name': package_name,
            'title': u'A Novel By Tolstoy',
            'resources': [{
                'description': u'Full text.',
                'format': u'plain text',
                'url': u'http://www.annakarenina.com/download/'
            }]
        }
        package.update(kwargs)

        postparams = '%s=1' % json.dumps(package)
        res = self.app.post('/api/action/package_create', params=postparams,
                            extra_environ={'Authorization': 'tester'})
        return json.loads(res.body)['result']

    def test_01_delete_resource(self):
        res_dict = self._add_basic_package()
        pkg_id = res_dict['id']

        resource_count = len(res_dict['resources'])
        id = res_dict['resources'][0]['id']
        url = '/api/action/resource_delete'

        # Use the sysadmin user because this package doesn't belong to an org
        res = self.app.post(url, params=json.dumps({'id': id}),
                extra_environ={'Authorization': str(self.sysadmin_user.apikey)})
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        url = '/api/action/package_show'
        res = self.app.get(url, {'id': pkg_id})
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        assert len(res_dict['result']['resources']) == resource_count - 1


class TestMember(WsgiAppCase):

    sysadmin = None

    group = None

    def setup(self):
        username = 'sysadmin'
        groupname = 'test group'
        organization_name = 'test organization'
        CreateTestData.create_user('sysadmin', **{ 'sysadmin': True })
        CreateTestData.create_groups([{ 'name': groupname },
                                      { 'name': organization_name,
                                        'type': 'organization'}])
        self.sysadmin = model.User.get(username)
        self.group = model.Group.get(groupname)

    def teardown(self):
        model.repo.rebuild_db()

    def test_group_member_create_works_user_id_and_group_id(self):
        self._assert_we_can_add_user_to_group(self.sysadmin.id, self.group.id)

    def test_group_member_create_works_with_user_id_and_group_name(self):
        self._assert_we_can_add_user_to_group(self.sysadmin.id, self.group.name)

    def test_group_member_create_works_with_user_name_and_group_name(self):
        self._assert_we_can_add_user_to_group(self.sysadmin.name, self.group.name)

    def _assert_we_can_add_user_to_group(self, user_id, group_id):
        user = model.User.get(user_id)
        group = model.Group.get(group_id)
        url = '/api/action/group_member_create'
        role = 'member'
        postparams = '%s=1' % json.dumps({
            'id': group_id,
            'username': user_id,
            'role': role})

        res = self.app.post(url, params=postparams,
                            extra_environ={'Authorization': str(user.apikey)})

        res = json.loads(res.body)
        groups = user.get_groups(group.type, role)
        group_ids = [g.id for g in groups]
        assert res['success'] is True, res
        assert group.id in group_ids, (group, user_groups)


class TestRelatedAction(WsgiAppCase):

    sysadmin_user = None

    normal_user = None

    @classmethod
    def setup_class(cls):
        search.clear()
        CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def _add_basic_package(self, package_name=u'test_package', **kwargs):
        package = {
            'name': package_name,
            'title': u'A Novel By Tolstoy',
            'resources': [{
                'description': u'Full text.',
                'format': u'plain text',
                'url': u'http://www.annakarenina.com/download/'
            }]
        }
        package.update(kwargs)

        postparams = '%s=1' % json.dumps(package)
        res = self.app.post('/api/action/package_create', params=postparams,
                            extra_environ={'Authorization': 'tester'})
        return json.loads(res.body)['result']

    def test_update_add_related_item(self):
        package = self._add_basic_package()
        related_item = {
            "description": "Testing a Description",
            "url": "http://example.com/image.png",
            "title": "Testing",
            "featured": 0,
            "image_url": "http://example.com/image.png",
            "type": "idea",
            "dataset_id": package['id'],
        }
        related_item_json = json.dumps(related_item)
        res_create = self.app.post('/api/action/related_create',
                                   params=related_item_json,
                                   extra_environ={'Authorization': 'tester'})
        assert res_create.json['success']

        related_update = res_create.json['result']
        related_update = {'id': related_update['id'], 'title': 'Updated'}
        related_update_json = json.dumps(related_update)
        res_update = self.app.post('/api/action/related_update',
                                   params=related_update_json,
                                   extra_environ={'Authorization': 'tester'})
        assert res_update.json['success']
        res_update_json = res_update.json['result']
        assert res_update_json['title'] == related_update['title']

        related_item.pop('title')
        related_item.pop('dataset_id')
        for field in related_item:
            assert related_item[field] == res_update_json[field]

########NEW FILE########
__FILENAME__ = test_auth
import mock

import ckan.tests as tests
from ckan.logic import get_action
import ckan.model as model
import ckan.new_authz as new_authz
from ckan.lib.create_test_data import CreateTestData
import json

INITIAL_TEST_CONFIG_PERMISSIONS = {
    'anon_create_dataset': False,
    'create_dataset_if_not_in_organization': False,
    'user_create_groups': False,
    'user_create_organizations': False,
    'user_delete_groups': False,
    'user_delete_organizations': False,
    'create_unowned_dataset': False,
    'create_user_via_api': False,
    'create_user_via_web': True,
    'roles_that_cascade_to_sub_groups': ['admin'],
}


class TestAuth(tests.WsgiAppCase):
    @classmethod
    def setup_class(cls):
        admin_api = get_action('get_site_user')(
            {'model': model, 'ignore_auth': True}, {})['apikey']
        ## This is a mutable dict on the class level so tests can
        ## add apikeys as they go along
        cls.apikeys = {'sysadmin': admin_api, 'random_key': 'moo'}

        cls.old_perm = new_authz.CONFIG_PERMISSIONS.copy()
        new_authz.CONFIG_PERMISSIONS.update(INITIAL_TEST_CONFIG_PERMISSIONS)

    @classmethod
    def teardown_class(cls):
        new_authz.CONFIG_PERMISSIONS.update(cls.old_perm)
        model.repo.rebuild_db()

    @classmethod
    def _call_api(cls, action, data, user, status=None):
        params = '%s=1' % json.dumps(data)
        res = cls.app.post('/api/action/%s' % action,
                            params=params,
                            extra_environ={'Authorization': cls.apikeys[user]},
                            status=[200, 403, 409])
        if res.status != (status or 200):
            error = json.loads(res.body)['error']
            raise AssertionError('Status was %s but should be %s. Error: %s' %
                                 (res.status, status, error))
        return res

    @classmethod
    def create_user(cls, name):
        user = {'name': name,
                'password': 'pass',
                'email': 'moo@moo.com'}
        res = cls._call_api('user_create', user, 'sysadmin', 200)
        cls.apikeys[name] = str(json.loads(res.body)['result']['apikey'])


class TestAuthUsers(TestAuth):
    def test_only_sysadmins_can_delete_users(self):
        username = 'username'
        user = {'id': username}
        self.create_user(username)

        self._call_api('user_delete', user, username, 403)
        self._call_api('user_delete', user, 'sysadmin', 200)

    def test_auth_deleted_users_are_always_unauthorized(self):
        always_success = lambda x,y: {'success': True}
        new_authz._AuthFunctions._build()
        new_authz._AuthFunctions._functions['always_success'] = always_success
        # We can't reuse the username with the other tests because we can't
        # rebuild_db(), because in the setup_class we get the sysadmin. If we
        # rebuild the DB, we would delete the sysadmin as well.
        username = 'deleted_user'
        self.create_user(username)
        user = model.User.get(username)
        user.delete()
        assert not new_authz.is_authorized_boolean('always_success', {'user': username})
        del new_authz._AuthFunctions._functions['always_success']


class TestAuthOrgs(TestAuth):
    def test_01_create_users(self):
        # actual roles assigned later
        self.create_user('org_admin')
        self.create_user('no_org')
        self.create_user('org_editor')
        self.create_user('editor_wannabe')

        user = {'name': 'user_no_auth',
                'password': 'pass',
                'email': 'moo@moo.com'}

        self._call_api('user_create', user, 'random_key', 403)
        self._call_api('user_create', user, 'no_org', 403)

    def test_02_create_orgs(self):
        org = {'name': 'org_no_user'}
        self._call_api('organization_create', org, 'random_key', 403)
        self._call_api('organization_create', org, 'sysadmin')

        org = {'name': 'org_with_user'}
        self._call_api('organization_create', org, 'random_key', 403)
        self._call_api('organization_create', org, 'sysadmin')

        #no user should be able to create org
        org = {'name': 'org_should_not_be_created'}
        self._call_api('organization_create', org, 'org_admin', 403)

    def test_03_create_dataset_no_org(self):

        # no owner_org supplied
        dataset = {'name': 'admin_create_no_org'}
        self._call_api('package_create', dataset, 'sysadmin', 409)

        dataset = {'name': 'should_not_be_created'}
        self._call_api('package_create', dataset, 'no_org', 403)

    def test_04_create_dataset_with_org(self):
        org_with_user = self._call_api('organization_show', {'id':
            'org_with_user'}, 'sysadmin')
        dataset = {'name': 'admin_create_with_user',
                   'owner_org': org_with_user.json['result']['id']}
        self._call_api('package_create', dataset, 'sysadmin', 200)

        org_no_user = self._call_api('organization_show', {'id':
            'org_no_user'}, 'sysadmin')
        dataset = {'name': 'sysadmin_create_no_user',
                   'owner_org': org_no_user.json['result']['id']}
        self._call_api('package_create', dataset, 'sysadmin', 200)
        dataset = {'name': 'user_create_with_org',
                   'owner_org': org_with_user.json['result']['id']}

    def test_05_add_users_to_org(self):

        member = {'username': 'org_admin',
                  'role': 'admin',
                  'id': 'org_with_user'}
        self._call_api('organization_member_create', member, 'sysadmin')

        ## admin user should be able to add users now
        member = {'username': 'org_editor',
                  'role': 'editor',
                  'id': 'org_with_user'}
        self._call_api('organization_member_create', member, 'org_admin')

        ## admin user should be able to add users now
        ## editor should not be able to approve others as editors
        member = {'username': 'editor_wannabe',
                  'role': 'editor',
                  'id': 'org_with_user'}
        self._call_api('organization_member_create', member, 'org_editor', 403)

    def _add_datasets(self, user):

        #org admin/editor should be able to add dataset to org.
        dataset = {'name': user + '_dataset', 'owner_org': 'org_with_user'}
        self._call_api('package_create', dataset, user, 200)

        #not able to add dataset to org admin does not belong to.
        dataset = {'name': user + '_dataset_bad', 'owner_org': 'org_no_user'}
        self._call_api('package_create', dataset, user, 403)

        #admin not able to make dataset not owned by a org
        dataset = {'name': user + '_dataset_bad'}
        self._call_api('package_create', dataset, user, 409)

        #not able to add org to not existant org
        dataset = {'name': user + '_dataset_bad', 'owner_org': 'org_not_exist'}
        self._call_api('package_create', dataset, user, 403)

    def test_07_add_datasets(self):
        self._add_datasets('org_admin')
        self._add_datasets('org_editor')

    def _update_datasets(self, user):
        ##editor/admin should be able to update dataset
        dataset = {'id': 'org_editor_dataset', 'title': 'test'}
        self._call_api('package_update', dataset, user, 200)
        # editor/admin tries to change owner org
        dataset = {'id': 'org_editor_dataset', 'owner_org': 'org_no_user'}
        self._call_api('package_update', dataset, user, 409)
        # editor/admin tries to update dataset in different org
        dataset = {'id': 'sysadmin_create_no_user', 'title': 'test'}
        self._call_api('package_update', dataset, user, 403)
        #non existant owner org
        dataset = {'id': 'org_editor_dataset', 'owner_org': 'org_not_exist'}
        self._call_api('package_update', dataset, user, 409)

    def test_08_update_datasets(self):
        self._update_datasets('org_admin')
        self._update_datasets('org_editor')

    def _delete_datasets(self, user):
        #editor/admin should be able to update dataset
        dataset = {'id': 'org_editor_dataset'}
        self._call_api('package_delete', dataset, user, 200)
        #not able to delete dataset in org user does not belong to
        dataset = {'id': 'sysadmin_create_no_user'}
        self._call_api('package_delete', dataset, user, 403)

    def test_09_delete_datasets(self):
        self._delete_datasets('org_admin')
        self._delete_datasets('org_editor')

    def test_10_edit_org(self):
        org = {'id': 'org_no_user', 'title': 'test'}
        #change an org user does not belong to
        self._call_api('organization_update', org, 'org_editor', 403)
        self._call_api('organization_update', org, 'org_admin', 403)

        #change an org a user belongs to
        org = {'id': 'org_with_user', 'title': 'test'}
        self._call_api('organization_update', org, 'org_editor', 403)
        self._call_api('organization_update', org, 'org_admin', 200)

    def test_11_delete_org(self):
        org = {'id': 'org_no_user', 'title': 'test'}
        self._call_api('organization_delete', org, 'org_editor', 403)
        self._call_api('organization_delete', org, 'org_admin', 403)
        org = {'id': 'org_with_user'}
        self._call_api('organization_delete', org, 'org_editor', 403)
        self._call_api('organization_delete', org, 'org_admin', 403)

ORG_HIERARCHY_PERMISSIONS = {
    'roles_that_cascade_to_sub_groups': ['admin'],
    }

class TestAuthOrgHierarchy(TestAuth):
    # Tests are in the same vein as TestAuthOrgs, testing the cases where the
    # group hierarchy provides extra permissions through cascading

    @classmethod
    def setup_class(cls):
        TestAuth.setup_class()
        CreateTestData.create_group_hierarchy_test_data()
        for user in model.Session.query(model.User):
            cls.apikeys[user.name] = str(user.apikey)
        new_authz.CONFIG_PERMISSIONS.update(ORG_HIERARCHY_PERMISSIONS)
        CreateTestData.create_arbitrary(
            package_dicts= [{'name': 'adataset',
                             'groups': ['national-health-service']}],
            extra_user_names=['john'])

    def _reset_a_datasets_owner_org(self):
        rev = model.repo.new_revision()
        get_action('package_owner_org_update')(
            {'model': model, 'ignore_auth': True},
            {'id': 'adataset',
             'organization_id': 'national-health-service'})

    def _undelete_package_if_needed(self, package_name):
        pkg = model.Package.by_name(package_name)
        if pkg and pkg.state == 'deleted':
            rev = model.repo.new_revision()
            pkg.state = 'active'
            model.repo.commit_and_remove()

    def test_05_add_users_to_org_1(self):
        member = {'username': 'john', 'role': 'admin',
                  'id': 'department-of-health'}
        self._call_api('organization_member_create', member, 'nhsadmin', 403)
    def test_05_add_users_to_org_2(self):
        member = {'username': 'john', 'role': 'editor',
                  'id': 'department-of-health'}
        self._call_api('organization_member_create', member, 'nhsadmin', 403)
    def test_05_add_users_to_org_3(self):
        member = {'username': 'john', 'role': 'admin',
                  'id': 'national-health-service'}
        self._call_api('organization_member_create', member, 'nhsadmin', 200)
    def test_05_add_users_to_org_4(self):
        member = {'username': 'john', 'role': 'editor',
                  'id': 'national-health-service'}
        self._call_api('organization_member_create', member, 'nhsadmin', 200)
    def test_05_add_users_to_org_5(self):
        member = {'username': 'john', 'role': 'admin',
                  'id': 'nhs-wirral-ccg'}
        self._call_api('organization_member_create', member, 'nhsadmin', 200)
    def test_05_add_users_to_org_6(self):
        member = {'username': 'john', 'role': 'editor',
                  'id': 'nhs-wirral-ccg'}
        self._call_api('organization_member_create', member, 'nhsadmin', 200)
    def test_05_add_users_to_org_7(self):
        member = {'username': 'john', 'role': 'editor',
                  'id': 'national-health-service'}
        self._call_api('organization_member_create', member, 'nhseditor', 403)

    def test_07_add_datasets_1(self):
        dataset = {'name': 't1', 'owner_org': 'department-of-health'}
        self._call_api('package_create', dataset, 'nhsadmin', 403)

    def test_07_add_datasets_2(self):
        dataset = {'name': 't2', 'owner_org': 'national-health-service'}
        self._call_api('package_create', dataset, 'nhsadmin', 200)

    def test_07_add_datasets_3(self):
        dataset = {'name': 't3', 'owner_org': 'nhs-wirral-ccg'}
        self._call_api('package_create', dataset, 'nhsadmin', 200)

    def test_07_add_datasets_4(self):
        dataset = {'name': 't4', 'owner_org': 'department-of-health'}
        self._call_api('package_create', dataset, 'nhseditor', 403)

    def test_07_add_datasets_5(self):
        dataset = {'name': 't5', 'owner_org': 'national-health-service'}
        self._call_api('package_create', dataset, 'nhseditor', 200)

    def test_07_add_datasets_6(self):
        dataset = {'name': 't6', 'owner_org': 'nhs-wirral-ccg'}
        self._call_api('package_create', dataset, 'nhseditor', 403)

    def test_08_update_datasets_1(self):
        dataset = {'name': 'adataset', 'owner_org': 'department-of-health'}
        self._call_api('package_update', dataset, 'nhsadmin', 409)

    def test_08_update_datasets_2(self):
        dataset = {'name': 'adataset', 'owner_org': 'national-health-service'}
        self._call_api('package_update', dataset, 'nhsadmin', 200)

    def test_08_update_datasets_3(self):
        dataset = {'name': 'adataset', 'owner_org': 'nhs-wirral-ccg'}
        try:
            self._call_api('package_update', dataset, 'nhsadmin', 200)
        finally:
            self._reset_a_datasets_owner_org()

    def test_08_update_datasets_4(self):
        dataset = {'name': 'adataset', 'owner_org': 'department-of-health'}
        self._call_api('package_update', dataset, 'nhseditor', 409)

    def test_08_update_datasets_5(self):
        dataset = {'name': 'adataset', 'owner_org': 'national-health-service'}
        try:
            self._call_api('package_update', dataset, 'nhseditor', 200)
        finally:
            self._reset_a_datasets_owner_org()

    def test_08_update_datasets_6(self):
        dataset = {'name': 'adataset', 'owner_org': 'nhs-wirral-ccg'}
        self._call_api('package_update', dataset, 'nhseditor', 409)

    def test_09_delete_datasets_1(self):
        dataset = {'id': 'doh-spend'}
        try:
            self._call_api('package_delete', dataset, 'nhsadmin', 403)
        finally:
            self._undelete_package_if_needed(dataset['id'])

    def test_09_delete_datasets_2(self):
        dataset = {'id': 'nhs-spend'}
        try:
            self._call_api('package_delete', dataset, 'nhsadmin', 200)
        finally:
            self._undelete_package_if_needed(dataset['id'])

    def test_09_delete_datasets_3(self):
        dataset = {'id': 'wirral-spend'}
        try:
            self._call_api('package_delete', dataset, 'nhsadmin', 200)
        finally:
            self._undelete_package_if_needed(dataset['id'])

    def test_09_delete_datasets_4(self):
        dataset = {'id': 'nhs-spend'}
        try:
            self._call_api('package_delete', dataset, 'nhseditor', 200)
        finally:
            self._undelete_package_if_needed(dataset['id'])

    def test_09_delete_datasets_5(self):
        dataset = {'id': 'wirral-spend'}
        try:
            self._call_api('package_delete', dataset, 'nhseditor', 403)
        finally:
            self._undelete_package_if_needed(dataset['id'])

    def _flesh_out_organization(self, org):
        # When calling organization_update, unless you include the list of
        # editor and admin users and parent groups, it will remove them. So
        # get the current list
        existing_org = get_action('organization_show')(
            {'model': model, 'ignore_auth': True}, {'id': org['id']})
        org.update(existing_org)

    def test_10_edit_org_1(self):
        org = {'id': 'department-of-health', 'title': 'test'}
        self._flesh_out_organization(org)
        self._call_api('organization_update', org, 'nhsadmin', 403)

    def test_10_edit_org_2(self):
        org = {'id': 'national-health-service', 'title': 'test'}
        self._flesh_out_organization(org)
        import pprint; pprint.pprint(org)
        print model.Session.query(model.Member).filter_by(state='deleted').all()
        self._call_api('organization_update', org, 'nhsadmin', 200)
        print model.Session.query(model.Member).filter_by(state='deleted').all()

    def test_10_edit_org_3(self):
        org = {'id': 'nhs-wirral-ccg', 'title': 'test'}
        self._flesh_out_organization(org)
        self._call_api('organization_update', org, 'nhsadmin', 200)

    def test_10_edit_org_4(self):
        org = {'id': 'department-of-health', 'title': 'test'}
        self._flesh_out_organization(org)
        self._call_api('organization_update', org, 'nhseditor', 403)

    def test_10_edit_org_5(self):
        org = {'id': 'national-health-service', 'title': 'test'}
        self._flesh_out_organization(org)
        self._call_api('organization_update', org, 'nhseditor', 403)

    def test_10_edit_org_6(self):
        org = {'id': 'nhs-wirral-ccg', 'title': 'test'}
        self._flesh_out_organization(org)
        self._call_api('organization_update', org, 'nhseditor', 403)

    def test_11_delete_org_1(self):
        org = {'id': 'department-of-health'}
        self._call_api('organization_delete', org, 'nhsadmin', 403)
        self._call_api('organization_delete', org, 'nhseditor', 403)

    def test_11_delete_org_2(self):
        org = {'id': 'national-health-service'}
        self._call_api('organization_delete', org, 'nhsadmin', 403)
        self._call_api('organization_delete', org, 'nhseditor', 403)

    def test_11_delete_org_3(self):
        org = {'id': 'nhs-wirral-ccg'}
        self._call_api('organization_delete', org, 'nhsadmin', 403)
        self._call_api('organization_delete', org, 'nhseditor', 403)


class TestAuthGroups(TestAuth):

    def test_01_create_groups(self):
        group = {'name': 'group_no_user'}
        self._call_api('group_create', group, 'random_key', 403)
        self._call_api('group_create', group, 'sysadmin')

        group = {'name': 'group_with_user'}
        self._call_api('group_create', group, 'random_key', 403)
        self._call_api('group_create', group, 'sysadmin')

    def test_02_add_users_to_group(self):
        self.create_user('org_admin')
        self.create_user('org_editor')
        self.create_user('org_editor_wannabe')
        self.create_user('no_group')

        member = {'username': 'org_admin',
                  'role': 'admin',
                  'id': 'group_with_user'}
        self._call_api('group_member_create', member, 'sysadmin')

        ## admin user should be able to add users now
        member = {'username': 'org_editor',
                  'role': 'editor',
                  'id': 'group_with_user'}
        self._call_api('group_member_create', member, 'org_admin')

        ## editor should not be able to approve others as editors
        member = {'username': 'org_editor_wannabe',
                  'role': 'editor',
                  'id': 'group_with_user'}
        self._call_api('group_member_create', member, 'org_editor', 403)

    def test_03_add_dataset_to_group(self):
        org = {'name': 'org'}
        self._call_api('organization_create', org, 'sysadmin')
        package = {'name': 'package_added_by_admin', 'owner_org': 'org'}
        self._call_api('package_create', package, 'sysadmin')
        package = {'name': 'package_added_by_editor', 'owner_org': 'org'}
        self._call_api('package_create', package, 'sysadmin')

        res = self._call_api('group_show',
                             {'id': 'group_with_user'},
                             'org_admin')
        group = json.loads(res.body)['result']
        self._call_api('group_update', group, 'no_group', 403)
        self._call_api('group_update', group, 'org_admin')

        group = {'id': 'group_with_user',
                 'packages': [{'id': 'package_added_by_admin'},
                              {'id': 'package_added_by_editor'}]}
        # org editor doesn't have edit rights
        self._call_api('group_update', group, 'org_editor', 403)

    def test_04_modify_group(self):
        res = self._call_api('group_show',
                             {'id': 'group_with_user'},
                             'org_admin')
        group = json.loads(res.body)['result']
        group.update({
            'title': 'moo',
            'packages': [{'id': 'package_added_by_admin'}]
        })
        self._call_api('group_update', group, 'org_admin')

        # need to think about this as is horrible may just let editor edit
        # group for this case even though spec says otherwise
        self._call_api('group_update', group, 'org_editor', 403)

    def test_05_delete_group(self):
        org = {'id': 'group_with_user'}
        self._call_api('group_delete', org, 'org_editor', 403)
        self._call_api('group_delete', org, 'org_admin', 403)
        org = {'id': 'group_with_user'}
        self._call_api('group_delete', org, 'org_editor', 403)
        self._call_api('group_delete', org, 'org_admin', 403)

########NEW FILE########
__FILENAME__ = test_init
import nose.tools as tools

import ckan.model as model
import ckan.logic as logic

import ckan.lib.create_test_data as create_test_data


class TestMemberLogic(object):
    def test_model_name_to_class(self):
        assert logic.model_name_to_class(model, 'package') == model.Package
        tools.assert_raises(logic.ValidationError,
                            logic.model_name_to_class,
                            model,
                            'inexistent_model_name')


class TestCheckAccess(object):

    @classmethod
    def setup_class(cls):
        model.Session.close_all()
        model.repo.delete_all()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def setup(self):
        model.repo.rebuild_db()

    def test_check_access_auth_user_obj_is_set(self):

        create_test_data.CreateTestData.create_test_user()

        user_name = 'tester'
        context = {'user': user_name}

        result = logic.check_access('package_create', context)

        assert result
        assert context['__auth_user_obj_checked']
        assert context['auth_user_obj'].name == user_name

    def test_check_access_auth_user_obj_is_not_set_when_ignoring_auth(self):

        create_test_data.CreateTestData.create_test_user()

        user_name = 'tester'
        context = {'user': user_name, 'ignore_auth': True}

        result = logic.check_access('package_create', context)

        assert result
        assert '__auth_user_obj_checked' not in context
        assert context['auth_user_obj'] is None

    def test_check_access_auth_user_obj_is_not_set(self):

        user_names = ('unknown_user', '', None,)
        for user_name in user_names:
            context = {'user': user_name}

            result = logic.check_access('package_search', context)

            assert result
            assert context['__auth_user_obj_checked']
            assert context['auth_user_obj'] is None

########NEW FILE########
__FILENAME__ = test_member
from nose.tools import assert_raises
import ckan.model as model
import ckan.logic as logic
import ckan.lib.create_test_data as create_test_data


class TestMemberLogic(object):

    @classmethod
    def setup_class(cls):
        model.repo.new_revision()
        create_test_data.CreateTestData.create()
        cls.user = model.User.get('testsysadmin')
        cls.tester = model.User.get('tester')
        cls.group = model.Group.get('david')
        cls.roger = model.Group.get('roger')
        cls.pkgs = [model.Package.by_name('warandpeace'),
                    model.Package.by_name('annakarenina')]

        # 'Tester' becomes an admin for the 'roger' group
        model.repo.new_revision()
        model.Member(group=cls.roger, table_id=cls.tester.id,
                     table_name='user', capacity='admin')
        model.repo.commit_and_remove()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_member_create(self):
        self._member_create(self.pkgs[0].id, 'package', 'public')
        res = self._member_list()
        assert (self.pkgs[0].id, 'package', 'public') in res, res

    def test_member_create_should_update_member_if_it_already_exists(self):
        initial = self._member_create(self.pkgs[0].id, 'package', 'public')
        final = self._member_create(self.pkgs[0].id, 'package', 'private')
        assert initial['id'] == final['id'], [initial, final]
        assert initial['capacity'] == u'public'
        assert final['capacity'] == u'private'

    def test_member_create_raises_if_user_unauthorized_to_update_group(self):
        ctx, dd = self._build_context(self.pkgs[0].id, 'package',
                                      user='unauthorized_user')
        assert_raises(logic.NotAuthorized,
                      logic.get_action('member_create'), ctx, dd)

    def test_member_create_with_child_group_permission(self):
        # 'tester' has admin priviledge for roger, so anyone can make it
        # a child group.
        self._member_create_group_hierarchy(parent_group=self.group,
                                            child_group=self.roger,
                                            user=self.tester)

    def test_member_create_raises_when_only_have_parent_group_permission(self):
        assert_raises(logic.NotAuthorized,
                      self._member_create_group_hierarchy,
                      self.roger,  # parent
                      self.group,  # child
                      self.tester)

    def test_member_create_accepts_group_name_or_id(self):
        by_name = self._member_create_in_group(self.pkgs[0].id, 'package',
                                               'public', self.group.name)
        by_id = self._member_create_in_group(self.pkgs[0].id, 'package',
                                             'public', self.group.id)
        assert by_name['id'] == by_id['id']

    def test_member_create_accepts_object_name_or_id(self):
        test_cases = ((self.pkgs[0], 'package', 'public'),
                      (self.user, 'user', 'admin'))
        for case in test_cases:
            obj = case[0]
            by_name = self._member_create(obj.name, case[1], case[2])
            by_id = self._member_create(obj.id, case[1], case[2])
            assert by_name['id'] == by_id['id']

    def test_member_create_raises_if_any_required_parameter_isnt_defined(self):
        ctx, dd = self._build_context(self.pkgs[0].id, 'package')
        for key in dd.keys():
            new_dd = dd.copy()
            del new_dd[key]
            assert_raises(logic.ValidationError,
                          logic.get_action('member_create'), ctx, new_dd)

    def test_member_create_raises_if_group_wasnt_found(self):
        assert_raises(logic.NotFound,
                      self._member_create_in_group,
                      self.pkgs[0].id, 'package', 'public', 'inexistent_group')

    def test_member_create_raises_if_object_wasnt_found(self):
        assert_raises(logic.NotFound,
                      self._member_create,
                      'inexistent_package', 'package', 'public')

    def test_member_create_raises_if_object_type_is_invalid(self):
        assert_raises(logic.ValidationError,
                      self._member_create,
                      'obj_id', 'invalid_obj_type', 'public')

    def test_member_list(self):
        self._member_create(self.pkgs[0].id, 'package', 'public')
        self._member_create(self.pkgs[1].id, 'package', 'public')
        res = self._member_list('package')
        assert (self.pkgs[0].id, 'package', 'public') in res
        assert (self.pkgs[1].id, 'package', 'public') in res

        res = self._member_list('user', 'admin')
        assert len(res) == 0, res

        assert_raises(logic.NotFound,
                      self._member_list, 'user', 'admin', 'inexistent_group')

        self._member_create(self.user.id, 'user', 'admin')
        res = self._member_list('user', 'admin')
        assert (self.user.id, 'user', 'Admin') in res, res

    def test_member_create_accepts_group_name_or_id(self):
        for group_key in [self.group.id, self.group.name]:
            self._member_create(self.user.id, 'user', 'admin')

            self._member_delete_in_group(self.user.id, 'user', group_key)

            res = self._member_list('user', 'admin')
            assert (self.user.id, 'user', 'Admin') not in res, res

    def test_member_delete_accepts_object_name_or_id(self):
        for key in [self.user.id, self.user.name]:
            self._member_create(key, 'user', 'admin')

            self._member_delete(key, 'user')

            res = self._member_list('user', 'admin')
            assert (self.user.id, 'user', 'Admin') not in res, res

    def test_member_delete_raises_if_user_unauthorized_to_update_group(self):
        ctx, dd = self._build_context(self.pkgs[0].id, 'package',
                                      user='unauthorized_user')
        assert_raises(logic.NotAuthorized,
                      logic.get_action('member_delete'), ctx, dd)

    def test_member_delete_raises_if_any_required_parameter_isnt_defined(self):
        ctx, dd = self._build_context(self.pkgs[0].id, 'package')
        for key in ['id', 'object', 'object_type']:
            new_dd = dd.copy()
            del new_dd[key]
            assert_raises(logic.ValidationError,
                          logic.get_action('member_delete'), ctx, new_dd)

    def test_member_delete_raises_if_group_wasnt_found(self):
        assert_raises(logic.NotFound,
                      self._member_delete_in_group,
                      self.pkgs[0].id, 'package', 'inexistent_group')

    def test_member_delete_raises_if_object_wasnt_found(self):
        assert_raises(logic.NotFound,
                      self._member_delete, 'unexistent_package', 'package')

    def test_member_delete_raises_if_object_type_is_invalid(self):
        assert_raises(logic.ValidationError,
                      self._member_delete, 'obj_id', 'invalid_obj_type')

    def _member_create(self, obj, obj_type, capacity):
        '''Makes the given object a member of cls.group.'''
        ctx, dd = self._build_context(obj, obj_type, capacity)
        return logic.get_action('member_create')(ctx, dd)

    def _member_create_in_group(self, obj, obj_type, capacity, group_id):
        '''Makes the given object a member of the given group.'''
        ctx, dd = self._build_context(obj, obj_type, capacity, group_id)
        return logic.get_action('member_create')(ctx, dd)

    def _member_create_as_user(self, obj, obj_type, capacity, user):
        '''Makes the given object a member of cls.group using privileges of
        the given user.'''
        ctx, dd = self._build_context(obj, obj_type, capacity, user=user)
        return logic.get_action('member_create')(ctx, dd)

    def _member_list(self, obj_type=None, capacity=None, group_id=None):
        ctx, dd = self._build_context(None, obj_type, capacity, group_id)
        return logic.get_action('member_list')(ctx, dd)

    def _member_delete(self, obj, obj_type):
        ctx, dd = self._build_context(obj, obj_type)
        return logic.get_action('member_delete')(ctx, dd)

    def _member_delete_in_group(self, obj, obj_type, group_id):
        ctx, dd = self._build_context(obj, obj_type, group_id=group_id)
        return logic.get_action('member_delete')(ctx, dd)

    def _member_create_group_hierarchy(self, parent_group, child_group, user):
        ctx, dd = self._build_context(parent_group.name, 'group', 'parent',
                                      group_id=child_group.name, user=user.id)
        return logic.get_action('member_create')(ctx, dd)

    def _build_context(self, obj, obj_type, capacity='public',
                       group_id=None, user=None):
        ctx = {'model': model,
               'session': model.Session,
               'user': user or self.user.id}
        ctx['auth_user_obj'] = model.User.get(ctx['user'])
        dd = {'id': group_id or self.group.name,
              'object': obj,
              'object_type': obj_type,
              'capacity': capacity}
        return ctx, dd

########NEW FILE########
__FILENAME__ = test_tag
import json
from pprint import pprint
from nose.tools import assert_equal, assert_raises
import ckan.lib.search as search

import ckan.model as model
from ckan.lib.create_test_data import CreateTestData
from ckan.tests import WsgiAppCase
from ckan.tests import StatusCodes

class TestAction(WsgiAppCase):
    @classmethod
    def setup_class(cls):
        search.clear()
        CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        CreateTestData.make_some_vocab_tags()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_06a_tag_list(self):
        postparams = '%s=1' % json.dumps({})
        res = self.app.post('/api/action/tag_list', params=postparams)
        resbody = json.loads(res.body)
        assert resbody['success'] is True
        assert sorted(resbody['result']) == sorted(['russian', 'tolstoy',
                u'Flexible \u30a1', 'tollbooth', 'tolkien', 'toledo',
                'tolerance'])
        assert resbody['help'].startswith(
                "Return a list of the site's tags.")
        #Get all fields
        postparams = '%s=1' % json.dumps({'all_fields':True})
        res = self.app.post('/api/action/tag_list', params=postparams)
        res_obj = json.loads(res.body)
        pprint(res_obj)
        assert res_obj['success'] == True

        names = [ res_obj['result'][i]['name'] for i in xrange(len(res_obj['result'])) ]
        russian_index = names.index('russian')
        tolstoy_index = names.index('tolstoy')
        flexible_index = names.index(u'Flexible \u30a1')

        assert res_obj['result'][russian_index]['name'] == 'russian'
        assert res_obj['result'][tolstoy_index]['name'] == 'tolstoy'

        assert 'id' in res_obj['result'][0]
        assert 'id' in res_obj['result'][1]
        assert 'id' in res_obj['result'][2]

    def test_06b_tag_list_vocab(self):
        vocab_name = 'test-vocab'
        tag_name = 'test-vocab-tag'

        # create vocab
        params = json.dumps({'name': vocab_name})
        extra_environ = {'Authorization' : str(self.sysadmin_user.apikey)}
        response = self.app.post('/api/action/vocabulary_create', params=params,
                                 extra_environ=extra_environ)
        assert response.json['success']
        vocab_id = response.json['result']['id']

        # create new tag with vocab
        params = json.dumps({'name': tag_name, 'vocabulary_id': vocab_id})
        extra_environ = {'Authorization' : str(self.sysadmin_user.apikey)}
        response = self.app.post('/api/action/tag_create', params=params,
                                 extra_environ=extra_environ)
        assert response.json['success'] == True

        # check that tag shows up in list
        params = '%s=1' % json.dumps({'vocabulary_id': vocab_name})
        res = self.app.post('/api/action/tag_list', params=params)
        body = json.loads(res.body)
        assert body['success'] is True
        assert body['result'] == [tag_name]
        assert body['help'].startswith("Return a list of the site's tags.")

        # check that invalid vocab name results in a 404
        params = '%s=1' % json.dumps({'vocabulary_id': 'invalid-vocab-name'})
        res = self.app.post('/api/action/tag_list', params=params, status=404)

    def test_07_tag_show(self):
        postparams = '%s=1' % json.dumps({'id':'russian'})
        res = self.app.post('/api/action/tag_show', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith(
                "Return the details of a tag and all its datasets.")
        assert res_obj['success'] == True
        result = res_obj['result']
        assert result['name'] == 'russian'
        assert 'id' in result
        assert 'packages' in result

        packages = [package['name'] for package in result['packages']]

        # the "moo" package may be part of the retrieved packages, depending
        # upon whether or not this test is run in isolation from the other tests
        # in the suite.
        expected_packages = ['annakarenina', 'warandpeace'] + (
            ['moo'] if 'moo' in packages else [])

        assert sorted(packages) == sorted(expected_packages), "%s != %s" %(packages, expected_packages)

    def test_07_flexible_tag_show(self):
        """
        Asserts that the api can be used to retrieve the details of the flexible tag.

        The flexible tag is the tag with spaces, punctuation and foreign
        characters in its name, that's created in `ckan/lib/create_test_data.py`.
        """
        postparams = '%s=1' % json.dumps({'id':u'Flexible \u30a1'})
        res = self.app.post('/api/action/tag_show', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith(
                "Return the details of a tag and all its datasets.")
        assert res_obj['success'] == True
        result = res_obj['result']
        assert result['name'] == u'Flexible \u30a1'
        assert 'id' in result
        assert 'packages' in result and len(result['packages']) == 2

        assert sorted([package['name'] for package in result['packages']]) == \
               sorted(['annakarenina', 'warandpeace'])

    def test_07_tag_show_unknown_license(self):
        # create a tagged package which has an invalid license
        CreateTestData.create_arbitrary([{
            'name': u'tag_test',
            'tags': u'tolstoy',
            'license': 'never_heard_of_it',
            }])
        postparams = '%s=1' % json.dumps({'id':'tolstoy'})
        res = self.app.post('/api/action/tag_show', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success'] == True
        result = res_obj['result']
        for pkg in result['packages']:
            if pkg['name'] == 'tag_test':
                break
        else:
            assert 0, 'tag_test not among packages'
        assert_equal(pkg['license_id'], 'never_heard_of_it')
        assert_equal(pkg['isopen'], False)

    def test_08_user_create_not_authorized(self):
        postparams = '%s=1' % json.dumps({'name':'test_create_from_action_api', 'password':'testpass'})
        res = self.app.post('/api/action/user_create', params=postparams,
                            status=StatusCodes.STATUS_403_ACCESS_DENIED)
        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith("Create a new user.")
        assert res_obj['success'] is False
        assert res_obj['error']['__type'] == 'Authorization Error'

    def test_09_user_create(self):
        user_dict = {'name':'test_create_from_action_api',
                      'about': 'Just a test user',
                      'email': 'me@test.org',
                      'password':'testpass'}

        postparams = '%s=1' % json.dumps(user_dict)
        res = self.app.post('/api/action/user_create', params=postparams,
                            extra_environ={'Authorization': str(self.sysadmin_user.apikey)})
        res_obj = json.loads(res.body)
        assert res_obj['help'].startswith("Create a new user.")
        assert res_obj['success'] == True
        result = res_obj['result']
        assert result['name'] == user_dict['name']
        assert result['about'] == user_dict['about']
        assert 'apikey' in result
        assert 'created' in result
        assert 'display_name' in result
        assert 'number_administered_packages' in result
        assert 'number_of_edits' in result
        assert not 'password' in result

    def test_15a_tag_search_with_empty_query(self):
        for q in ('missing', None, '', '  '):
            paramd = {}
            if q != 'missing':
                paramd['q'] = q
            params = json.dumps(paramd)
            res = self.app.post('/api/action/tag_search', params=params)
            assert res.json['success'] is True
            assert res.json['result']['count'] == 0
            assert res.json['result']['results'] == []

    def test_15a_tag_search_with_no_matches(self):
        paramd = {'q': 'no matches' }
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_search', params=params)
        assert res.json['success'] is True
        assert res.json['result']['count'] == 0
        assert res.json['result']['results'] == []

    def test_15a_tag_search_with_one_match(self):
        paramd = {'q': 'russ' }
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_search', params=params)
        assert res.json['success'] is True
        assert res.json['result']['count'] == 1
        tag_dicts = res.json['result']['results']
        assert len(tag_dicts) == 1
        assert tag_dicts[0]['name'] == 'russian'

    def test_15a_tag_search_with_one_match_using_fields_parameter(self):
        paramd = {'fields': {'tags': 'russ'} }
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_search', params=params)
        assert res.json['success'] is True
        assert res.json['result']['count'] == 1
        tag_dicts = res.json['result']['results']
        assert len(tag_dicts) == 1
        assert tag_dicts[0]['name'] == 'russian'

    def test_15a_tag_search_with_many_matches(self):
        paramd = {'q': 'tol' }
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_search', params=params)
        assert res.json['success'] is True
        assert res.json['result']['count'] == 5
        tag_dicts = res.json['result']['results']
        assert ([tag['name'] for tag in tag_dicts] ==
                sorted(['tolkien', 'toledo', 'tolerance', 'tollbooth', 'tolstoy']))

    def test_15a_tag_search_with_many_matches_paged(self):
        paramd = {'q': 'tol', 'limit': 2, 'offset': 2 }
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_search', params=params)
        assert res.json['success'] is True
        assert res.json['result']['count'] == 5
        tag_dicts = res.json['result']['results']
        assert_equal ([tag['name'] for tag in tag_dicts],
                      [u'tolkien', u'tollbooth'])

    def test_15a_tag_search_with_vocab_and_empty_query(self):
        for q in ('missing', None, '', '  '):
            paramd = {'vocabulary_id': 'genre'}
            if q != 'missing':
                paramd['q'] = q
            params = json.dumps(paramd)
            res = self.app.post('/api/action/tag_search', params=params)
            assert res.json['success'] is True
            assert res.json['result']['count'] == 0
            assert res.json['result']['results'] == []

    def test_15a_tag_search_with_vocab_and_one_match(self):
        paramd = {'q': 'son', 'vocabulary_id': 'genre' }
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_search', params=params)
        assert res.json['success'] is True
        assert res.json['result']['count'] == 1
        tag_dicts = res.json['result']['results']
        assert len(tag_dicts) == 1
        assert tag_dicts[0]['name'] == 'sonata'

    def test_15a_tag_search_with_vocab_and_multiple_matches(self):
        paramd = {'q': 'neo', 'vocabulary_id': 'genre' }
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_search', params=params)
        assert res.json['success'] is True
        assert res.json['result']['count'] == 6
        tag_dicts = res.json['result']['results']
        assert [tag['name'] for tag in tag_dicts] == sorted(('neoclassical',
            'neofolk', 'neomedieval', 'neoprog', 'neopsychedelia', 'neosoul'))

    def test_15a_tag_search_with_vocab_and_no_matches(self):
        paramd = {'q': 'xxxxxxx', 'vocabulary_id': 'genre' }
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_search', params=params)
        assert res.json['success'] is True
        assert res.json['result']['count'] == 0
        tag_dicts = res.json['result']['results']
        assert tag_dicts == []

    def test_15a_tag_search_with_vocab_that_does_not_exist(self):
        paramd = {'q': 'neo', 'vocabulary_id': 'xxxxxx' }
        params = json.dumps(paramd)
        self.app.post('/api/action/tag_search', params=params, status=404)

    def test_15a_tag_search_with_invalid_vocab(self):
        for vocab_name in (None, '', 'a', 'e'*200):
            paramd = {'q': 'neo', 'vocabulary_id': vocab_name }
            params = json.dumps(paramd)
            self.app.post('/api/action/tag_search', params=params, status=404)

    def test_15_tag_autocomplete(self):
        #Empty query
        postparams = '%s=1' % json.dumps({})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success'] == True
        assert res_obj['result'] == []
        assert res_obj['help'].startswith(
                "Return a list of tag names that contain a given string.")

        #Normal query
        postparams = '%s=1' % json.dumps({'q':'r'})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success'] == True
        assert res_obj['result'] == ['russian', 'tolerance']
        assert res_obj['help'].startswith(
                'Return a list of tag names that contain a given string.')

    def test_15_tag_autocomplete_tag_with_spaces(self):
        """Asserts autocomplete finds tags that contain spaces"""

        CreateTestData.create_arbitrary([{
            'name': u'package-with-tag-that-has-a-space-1',
            'tags': [u'with space'],
            'license': 'never_heard_of_it',
            }])

        postparams = '%s=1' % json.dumps({'q':'w'})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success']
        assert 'with space' in res_obj['result'], res_obj['result']

    def test_15_tag_autocomplete_tag_with_foreign_characters(self):
        """Asserts autocomplete finds tags that contain foreign characters"""

        CreateTestData.create_arbitrary([{
            'name': u'package-with-tag-that-has-a-foreign-character-1',
            'tags': [u'greek beta \u03b2'],
            'license': 'never_heard_of_it',
            }])

        postparams = '%s=1' % json.dumps({'q':'greek'})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success']
        assert u'greek beta \u03b2' in res_obj['result'], res_obj['result']

    def test_15_tag_autocomplete_tag_with_punctuation(self):
        """Asserts autocomplete finds tags that contain punctuation"""

        CreateTestData.create_arbitrary([{
            'name': u'package-with-tag-that-has-a-fullstop-1',
            'tags': [u'fullstop.'],
            'license': 'never_heard_of_it',
            }])

        postparams = '%s=1' % json.dumps({'q':'fullstop'})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success']
        assert u'fullstop.' in res_obj['result'], res_obj['result']

    def test_15_tag_autocomplete_tag_with_capital_letters(self):
        """
        Asserts autocomplete finds tags that contain capital letters
        """

        CreateTestData.create_arbitrary([{
            'name': u'package-with-tag-that-has-a-capital-letter-1',
            'tags': [u'CAPITAL idea old chap'],
            'license': 'never_heard_of_it',
            }])

        postparams = '%s=1' % json.dumps({'q':'idea'})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success']
        assert u'CAPITAL idea old chap' in res_obj['result'], res_obj['result']

    def test_15_tag_autocomplete_search_with_space(self):
        """
        Asserts that a search term containing a space works correctly
        """

        CreateTestData.create_arbitrary([{
            'name': u'package-with-tag-that-has-a-space-2',
            'tags': [u'with space'],
            'license': 'never_heard_of_it',
            }])

        postparams = '%s=1' % json.dumps({'q':'th sp'})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success']
        assert 'with space' in res_obj['result'], res_obj['result']

    def test_15_tag_autocomplete_search_with_foreign_character(self):
        """
        Asserts that a search term containing a foreign character works correctly
        """

        CreateTestData.create_arbitrary([{
            'name': u'package-with-tag-that-has-a-foreign-character-2',
            'tags': [u'greek beta \u03b2'],
            'license': 'never_heard_of_it',
            }])

        postparams = '%s=1' % json.dumps({'q':u'\u03b2'})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success']
        assert u'greek beta \u03b2' in res_obj['result'], res_obj['result']

    def test_15_tag_autocomplete_search_with_punctuation(self):
        """
        Asserts that a search term containing punctuation works correctly
        """

        CreateTestData.create_arbitrary([{
            'name': u'package-with-tag-that-has-a-fullstop-2',
            'tags': [u'fullstop.'],
            'license': 'never_heard_of_it',
            }])

        postparams = '%s=1' % json.dumps({'q':u'stop.'})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success']
        assert 'fullstop.' in res_obj['result'], res_obj['result']

    def test_15_tag_autocomplete_search_with_capital_letters(self):
        """
        Asserts that a search term containing capital letters works correctly
        """

        CreateTestData.create_arbitrary([{
            'name': u'package-with-tag-that-has-a-capital-letter-2',
            'tags': [u'CAPITAL idea old chap'],
            'license': 'never_heard_of_it',
            }])

        postparams = '%s=1' % json.dumps({'q':u'CAPITAL'})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success']
        assert 'CAPITAL idea old chap' in res_obj['result'], res_obj['result']

    def test_15_tag_autocomplete_is_case_insensitive(self):
        CreateTestData.create_arbitrary([{
            'name': u'package-with-tag-that-has-a-capital-letter-3',
            'tags': [u'MIX of CAPITALS and LOWER case'],
            'license': 'never_heard_of_it',
            }])

        postparams = '%s=1' % json.dumps({'q':u'lower case'})
        res = self.app.post('/api/action/tag_autocomplete', params=postparams)
        res_obj = json.loads(res.body)
        assert res_obj['success']
        assert 'MIX of CAPITALS and LOWER case' in res_obj['result'], res_obj['result']

    def test_15_tag_autocomplete_with_vocab_and_empty_query(self):
        for q in ('missing', None, '', '  '):
            paramd = {'vocabulary_id': u'genre'}
            if q != 'missing':
                paramd['q'] = q
            params = json.dumps(paramd)
            res = self.app.post('/api/action/tag_autocomplete', params=params)
            assert res.json['success'] is True
            assert res.json['result'] == []

    def test_15_tag_autocomplete_with_vocab_and_single_match(self):
        paramd = {'vocabulary_id': u'genre', 'q': 'son'}
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_autocomplete', params=params)
        assert res.json['success'] is True
        assert res.json['result'] == ['sonata'], res.json['result']

    def test_15_tag_autocomplete_with_vocab_and_multiple_matches(self):
        paramd = {'vocabulary_id': 'genre', 'q': 'neo'}
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_autocomplete', params=params)
        assert res.json['success'] is True
        assert res.json['result'] == sorted(('neoclassical', 'neofolk',
            'neomedieval', 'neoprog', 'neopsychedelia', 'neosoul'))

    def test_15_tag_autocomplete_with_vocab_and_no_matches(self):
        paramd = {'vocabulary_id': 'composers', 'q': 'Jonny Greenwood'}
        params = json.dumps(paramd)
        res = self.app.post('/api/action/tag_autocomplete', params=params)
        assert res.json['success'] is True
        assert res.json['result'] == []

    def test_15_tag_autocomplete_with_vocab_that_does_not_exist(self):
        for q in ('', 'neo'):
            paramd = {'vocabulary_id': 'does_not_exist', 'q': q}
            params = json.dumps(paramd)
            res = self.app.post('/api/action/tag_autocomplete', params=params,
                    status=404)
            assert res.json['success'] is False

    def test_15_tag_autocomplete_with_invalid_vocab(self):
        for vocab_name in (None, '', 'a', 'e'*200):
            for q in (None, '', 'son'):
                paramd = {'vocabulary_id': vocab_name, 'q': q}
                params = json.dumps(paramd)
                res = self.app.post('/api/action/tag_autocomplete', params=params,
                        status=404)
                assert res.json['success'] is False

########NEW FILE########
__FILENAME__ = test_tag_vocab
import ckan.model as model
import ckan.logic as logic
import ckan.logic.converters as converters
import ckan.lib.navl.dictization_functions as df
import ckan.tests as tests
import ckan.lib.create_test_data as ctd

TEST_VOCAB_NAME = 'test-vocab'


class TestConverters(object):
    @classmethod
    def setup_class(cls):
        cls.vocab = model.Vocabulary(TEST_VOCAB_NAME)
        model.Session.add(cls.vocab)
        model.Session.commit()
        vocab_tag_1 = model.Tag('tag1', cls.vocab.id)
        vocab_tag_2 = model.Tag('tag2', cls.vocab.id)
        model.Session.add(vocab_tag_1)
        model.Session.add(vocab_tag_2)
        model.Session.commit()
        model.Session.remove()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_convert_to_tags(self):
        def convert(tag_string, vocab):
            key = 'vocab_tags'
            data = {key: tag_string}
            errors = []
            context = {'model': model, 'session': model.Session}
            converters.convert_to_tags(vocab)(key, data, errors, context)
            del data[key]
            return data

        data = df.unflatten(convert(['tag1', 'tag2'], 'test-vocab'))
        for tag in data['tags']:
            assert tag['name'] in ['tag1', 'tag2'], tag['name']
            assert tag['vocabulary_id'] == self.vocab.id, tag['vocabulary_id']

    def test_convert_from_tags(self):
        key = 'tags'
        data = {
            ('tags', 0, '__extras'): {'name': 'tag1', 'vocabulary_id': self.vocab.id},
            ('tags', 1, '__extras'): {'name': 'tag2', 'vocabulary_id': self.vocab.id}
        }
        errors = []
        context = {'model': model, 'session': model.Session}
        converters.convert_from_tags(self.vocab.name)(key, data, errors, context)
        assert 'tag1' in data['tags']
        assert 'tag2' in data['tags']

    def test_free_tags_only(self):
        key = ('tags', 0, '__extras')
        data = {
            ('tags', 0, '__extras'): {'name': 'tag1', 'vocabulary_id': self.vocab.id},
            ('tags', 0, 'vocabulary_id'): self.vocab.id,
            ('tags', 1, '__extras'): {'name': 'tag2', 'vocabulary_id': None},
            ('tags', 1, 'vocabulary_id'): None
        }
        errors = []
        context = {'model': model, 'session': model.Session}
        converters.free_tags_only(key, data, errors, context)
        assert len(data) == 2
        assert ('tags', 1, 'vocabulary_id') in data.keys()
        assert ('tags', 1, '__extras') in data.keys()


class TestVocabFacets(object):
    @classmethod
    def setup_class(cls):
        if not tests.is_search_supported():
            raise tests.SkipTest("Search not supported")
        tests.setup_test_search_index()

        ctd.CreateTestData.create()

        model.repo.new_revision()
        cls.vocab = model.Vocabulary(TEST_VOCAB_NAME)
        model.Session.add(cls.vocab)
        model.Session.commit()

        vocab_tag_1 = model.Tag('tag1', cls.vocab.id)
        vocab_tag_2 = model.Tag('tag2', cls.vocab.id)
        model.Session.add(vocab_tag_1)
        model.Session.add(vocab_tag_2)

        pkg = model.Package.get('warandpeace')
        pkg_tag1 = model.PackageTag(pkg, vocab_tag_1)
        pkg_tag2 = model.PackageTag(pkg, vocab_tag_2)
        model.Session.add(pkg_tag1)
        model.Session.add(pkg_tag2)

        model.Session.commit()
        model.Session.remove()

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_vocab_facets(self):
        vocab_facet = 'vocab_%s' % TEST_VOCAB_NAME

        context = {'model': model, 'session': model.Session}
        data = {
            'q': 'warandpeace',
            'facet': 'true',
            'facet.field': ['groups', 'tags', vocab_facet],
            'facet.limit': '50',
            'facet.mincount': 1,
        }

        result = logic.get_action('package_search')(context, data)
        facets = result['search_facets']
        facet_tags = [t['name'] for t in facets['tags']['items']]
        assert len(facet_tags)

        # make sure vocab tags are not in 'tags' facet
        assert not 'tag1' in facet_tags
        assert not 'tag2' in facet_tags

        # make sure vocab tags are in vocab_<TEST_VOCAB_NAME> facet
        vocab_facet_tags = [t['name'] for t in facets[vocab_facet]['items']]
        assert 'tag1' in vocab_facet_tags
        assert 'tag2' in vocab_facet_tags

    def test_vocab_facets_searchable(self):
        context = {'model': model, 'session': model.Session}
        data = {'q': 'tag1', 'facet': 'false'}
        result = logic.get_action('package_search')(context, data)
        assert result['count'] == 1
        assert result['results'][0]['name'] == 'warandpeace'

########NEW FILE########
__FILENAME__ = test_validators
from nose.tools import assert_equal

from ckan import model
from ckan.logic.validators import tag_string_convert

class TestValidators:
    def test_01_tag_string_convert(self):
        def convert(tag_string):
            key = 'tag_string'
            data = {key: tag_string}
            errors = []
            context = {'model': model, 'session': model.Session}
            tag_string_convert(key, data, errors, context)
            tags = []
            i = 0
            while True:
                tag = data.get(('tags', i, 'name'))
                if not tag:
                    break
                tags.append(tag)
                i += 1
            return tags
        assert_equal(convert('big, good'), ['big', 'good'])
        assert_equal(convert('one, several word tag, with-hyphen'),
                     ['one', 'several word tag', 'with-hyphen'])
        assert_equal(convert(''),
                     [])
        assert_equal(convert('trailing comma,'),
                     ['trailing comma'])
        assert_equal(convert('trailing comma space, '),
                     ['trailing comma space'])


########NEW FILE########
__FILENAME__ = test_format_text
import ckan.lib.helpers as h

class TestFormatText:

    def test_markdown(self):
        instr = '''# Hello World

**Some bolded text.**

*Some italicized text.*
'''
        exp = '''<h1>Hello World</h1>
<p><strong>Some bolded text.</strong>
</p>
<p><em>Some italicized text.</em>
</p>'''
        out = h.render_markdown(instr)
        assert out == exp

    def test_markdown_blank(self):
        instr = None
        out = h.render_markdown(instr)
        assert out == ''

    def test_evil_markdown(self):
        instr = 'Evil <script src="http://evilserver.net/evil.js";>'
        exp = '''<p>Evil \n</p>'''
        out = h.render_markdown(instr)
        assert out == exp, out

    def test_internal_link(self):
        instr = 'dataset:test-_pkg'
        exp = '<p><a href="/dataset/test-_pkg">dataset:test-_pkg</a>\n</p>'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_internal_tag_link(self):
        """Asserts links like 'tag:test-tag' work"""
        instr = 'tag:test-tag foobar'
        exp = '<a href="/tag/test-tag">tag:test-tag</a> foobar'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_internal_tag_linked_with_quotes(self):
        """Asserts links like 'tag:"test-tag"' work"""
        instr = 'tag:"test-tag" foobar'
        exp = '<p><a href="/tag/test-tag">tag:&#34;test-tag&#34;</a> foobar\n</p>'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_internal_tag_linked_with_quotes_and_space(self):
        """Asserts links like 'tag:"test tag"' work"""
        instr = 'tag:"test tag" foobar'
        exp = '<p><a href="/tag/test%20tag">tag:&#34;test tag&#34;</a> foobar\n</p>'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_internal_tag_with_no_opening_quote_only_matches_single_word(self):
        """Asserts that without an opening quote only one word is matched"""
        instr = 'tag:test tag" foobar'  # should match 'tag:test'
        exp = '<a href="/tag/test">tag:test</a> tag" foobar'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_internal_tag_with_no_opening_quote_wont_match_the_closing_quote(self):
        """Asserts that 'tag:test" tag' is matched, but to 'tag:test'"""
        instr = 'tag:test" foobar'  # should match 'tag:test'
        exp = '<a href="/tag/test">tag:test</a>" foobar'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_internal_tag_with_no_closing_quote_does_not_match(self):
        """Asserts that without an opening quote only one word is matched"""
        instr = 'tag:"test tag foobar'
        out = h.render_markdown(instr)
        assert "<a href" not in out

    def test_tag_names_match_simple_punctuation(self):
        """Asserts punctuation and capital letters are matched in the tag name"""
        instr = 'tag:"Test- _." foobar'
        exp = '<p><a href="/tag/Test-%20_.">tag:&#34;Test- _.&#34;</a> foobar\n</p>'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_tag_names_do_not_match_commas(self):
        """Asserts commas don't get matched as part of a tag name"""
        instr = 'tag:Test,tag foobar'
        exp = '<a href="/tag/Test">tag:Test</a>,tag foobar'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_tag_names_dont_match_non_space_whitespace(self):
        """Asserts that the only piece of whitespace matched in a tagname is a space"""
        whitespace_characters = '\t\n\r\f\v'
        for ch in whitespace_characters:
            instr = 'tag:Bad' + ch + 'space'
            exp = '<a href="/tag/Bad">tag:Bad</a>'
            out = h.render_markdown(instr)
            assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_tag_names_with_unicode_alphanumeric(self):
        """Asserts that unicode alphanumeric characters are captured"""
        instr = u'tag:"Japanese katakana \u30a1" blah'
        exp = u'<p><a href="/tag/Japanese%20katakana%20%E3%82%A1">tag:&#34;Japanese katakana \u30a1&#34;</a> blah\n</p>'
        out = h.render_markdown(instr)
        assert exp in out, u'\nGot: %s\nWanted: %s' % (out, exp)

    def test_normal_link(self):
        instr = 'http://somelink/'
        exp = '<a href="http://somelink/" target="_blank" rel="nofollow">http://somelink/</a>'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

        instr = 'http://somelink.com/#anchor'
        exp = '<a href="http://somelink.com/#anchor" target="_blank" rel="nofollow">http://somelink.com/#anchor</a>'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

        instr = 'http://www.somelink.com/#anchor'
        exp = '<a href="http://www.somelink.com/#anchor" target="_blank" rel="nofollow">http://www.somelink.com/#anchor</a>'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_auto_link(self):
        instr = 'http://somelink.com'
        exp = '<a href="http://somelink.com" target="_blank" rel="nofollow">http://somelink.com</a>'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_auto_link_after_whitespace(self):
        instr = 'go to http://somelink.com'
        exp = 'go to <a href="http://somelink.com" target="_blank" rel="nofollow">http://somelink.com</a>'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_malformed_link_1(self):
        instr = u'<a href=\u201dsomelink\u201d>somelink</a>'
        exp = '<p>somelink\n</p>'
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

    def test_multiline_links(self):
        instr = u'''I get 10 times more traffic from [Google][] than from
[Yahoo][] or [MSN][].

  [google]: http://google.com/        "Google"
  [yahoo]:  http://search.yahoo.com/  "Yahoo Search"
  [msn]:    http://search.msn.com/    "MSN Search"'''
        exp = '''<p>I get 10 times more traffic from <a href="http://google.com/" title="Google">Google</a> than from
   <a href="http://search.yahoo.com/" title="Yahoo Search">Yahoo</a> or <a href="http://search.msn.com/" title="MSN Search">MSN</a>.
</p>'''
        # NB when this is put into Genshi, it will close the tag for you.
        out = h.render_markdown(instr)
        assert exp in out, '\nGot: %s\nWanted: %s' % (out, exp)

########NEW FILE########
__FILENAME__ = test_mock_mail_server
import time
from nose.tools import assert_equal
from pylons import config
from email.mime.text import MIMEText
import hashlib

from ckan.tests.pylons_controller import PylonsTestCase
from ckan.tests.mock_mail_server import SmtpServerHarness
from ckan.lib.mailer import mail_recipient

class TestMockMailServer(SmtpServerHarness, PylonsTestCase):
    @classmethod
    def setup_class(cls):
        smtp_server = config.get('smtp.test_server')
        if smtp_server:
            host, port = smtp_server.split(':')
            port = int(port) + int(str(hashlib.md5(cls.__name__).hexdigest())[0], 16)
            config['smtp.test_server'] = '%s:%s' % (host, port)
        SmtpServerHarness.setup_class()
        PylonsTestCase.setup_class()

    @classmethod
    def teardown_class(cls):
        SmtpServerHarness.teardown_class()

    def test_basic(self):
        msgs = self.get_smtp_messages()
        assert_equal(msgs, [])

        test_email = {'recipient_name': 'Bob',
                      'recipient_email':'bob@bob.net',
                      'subject': 'Meeting', 
                      'body': 'The meeting is cancelled.',
                      'headers': {'header1': 'value1'}}
        mail_recipient(**test_email)
        time.sleep(0.1)

        msgs = self.get_smtp_messages()
        assert_equal(len(msgs), 1)

########NEW FILE########
__FILENAME__ = test_sync
import os
import subprocess
import urllib2
import time

from pylons import config

import ckan.model as model
from ckan.tests import *
from ckan.lib.create_test_data import CreateTestData
from ckan.common import json

instance_dir = config['here']

class Options:
    pid_file = 'paster.pid'

# TODO: Reenable this when sync functionality is in place
class _TestSync(TestController):
    @classmethod
    def setup_class(self):
        # setup Server A (sub process)
        subprocess.call('paster db clean --config=test_sync.ini', shell=True)
        subprocess.call('paster db init --config=test_sync.ini', shell=True)
        subprocess.call('paster create-test-data --config=test_sync.ini', shell=True)
        self.sub_proc = subprocess.Popen(['paster', 'serve', 'test_sync.ini'])
        # setup Server B (this process)
        # (clean)

        self._last_synced_revision_id = {'http://localhost:5050':None}
        
    @classmethod
    def teardown_class(self):
        self.sub_proc.kill()
        model.repo.rebuild_db()

    def sub_app_get(self, offset):
        count = 0
        while True:
            try:
                f = urllib2.urlopen('http://localhost:5050%s' % offset)
            except urllib2.URLError, e:
                if hasattr(e, 'reason') and type(e.reason) == urllib2.socket.error:
                    # i.e. process not started up yet
                    count += 1
                    time.sleep(1)
                    assert count < 5, '%s: %r; %r' % (offset, e, e.args)
                else:
                    print 'Error opening url: %s' % offset
                    assert 0, e # Print exception
            else:
                break
        return f.read()

    def sub_app_get_deserialized(offset):
        res = sub_app_get(offset)
        if res == None:
            return None
        else:
            return json.loads(res)

    def test_0_check_setup(self):
        offset = '/api/rest/package'
        resB = self.app.get(offset).body
        resA = self.sub_app_get(offset)
        pkgsB = json.loads(resB or '[]')
        pkgsA = json.loads(resA or '[]')
        assert len(pkgsA) == 2
        assert len(pkgsB) == 0

    def test_1_first_sync(self):
        server = self._last_synced_revision_id.keys()[0]
        assert server == 'http://localhost:5050'
        
        # find id of last revision synced
        last_sync_rev_id = self._last_synced_revision_id[server]
        assert last_sync_rev_id == None # no syncs yet

        # get revision ids since then
        remote_rev_ids = self.sub_app_get_deserialized('%s/api/search/revision?since=%s' % (server, last_sync_rev_id))
        assert len(remote_rev_ids) == 3
        remote_latest_rev_id = remote_rev_ids[-1]

        # get revision diffs
        diffs = self.sub_app_get_deserialized('%s/api/diff/revision?diff=%s&oldid=%s' % (server, remote_latest_rev_id, last_sync_rev_id))
        assert len(diffs) == 3
                                      
        # apply diffs

        
        



########NEW FILE########
__FILENAME__ = mock_mail_server
import threading
import asyncore
import socket
from smtpd import SMTPServer
import hashlib

from pylons import config

from ckan.lib.mailer import _mail_recipient

class MockSmtpServer(SMTPServer):
    '''A mock SMTP server that operates in an asyncore loop'''
    def __init__(self, host, port):
        self.msgs = []
        SMTPServer.__init__(self, (host, port), None)
        
    def process_message(self, peer, mailfrom, rcpttos, data):
        self.msgs.append((peer, mailfrom, rcpttos, data))

    def get_smtp_messages(self):
        return self.msgs

    def clear_smtp_messages(self):
        self.msgs = []

class MockSmtpServerThread(threading.Thread):
    '''Runs the mock SMTP server in a thread'''
    def __init__(self, host, port):   
        self.assert_port_free(host, port)
        # init thread
        self._stop_event = threading.Event()
        self.thread_name = self.__class__
        threading.Thread.__init__(self, name=self.thread_name)
        # init smtp server
        self.server = MockSmtpServer(host, port)

    def assert_port_free(self, host, port):
        test_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        test_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR,
                               test_socket.getsockopt(socket.SOL_SOCKET,
                                                      socket.SO_REUSEADDR) | 1 )
        test_socket.bind((host, port))
        test_socket.close()
        
    def run(self):
        while not self._stop_event.isSet():
            asyncore.loop(timeout=0.01, count=1)

    def stop(self, timeout=None):
        self._stop_event.set()
        threading.Thread.join(self, timeout)
        self.server.close()

    def get_smtp_messages(self):
        return self.server.get_smtp_messages()

    def clear_smtp_messages(self):
        return self.server.clear_smtp_messages()
        
class SmtpServerHarness(object):
    '''Derive from this class to run MockSMTP - a test harness that
    records what email messages are requested to be sent by it.'''

    @classmethod
    def setup_class(cls):
        smtp_server  = config.get('smtp.test_server') or config['smtp_server']
        if ':' in smtp_server:
            host, port = smtp_server.split(':')
        else:
            host, port = smtp_server, 25
        cls.port = port
        cls.smtp_thread = MockSmtpServerThread(host, int(port))
        cls.smtp_thread.start()

    @classmethod
    def teardown_class(cls):
        cls.smtp_thread.stop()

    def get_smtp_messages(self):
        return self.smtp_thread.get_smtp_messages()

    def clear_smtp_messages(self):
        return self.smtp_thread.clear_smtp_messages()
    

########NEW FILE########
__FILENAME__ = mock_plugin
from ckan.plugins import Plugin, SingletonPlugin

class _MockPlugin(object):
    """
    MockPlugin tracks method calls via __getattr__ for rapid mocking of
    plugins.

    Use MockPlugin.calls or MockPlugin.<methodname>.calls to access
    call information
    """

    class MockMethod(object):
        registry = {}
        def __init__(self, boundto, name):
            self.name = name
            self.calls = []
            self.boundto = boundto

        def __call__(self, *args, **kwargs):
            self.boundto.calls.append((self.name, args, kwargs))
            self.calls.append((args, kwargs))

    def __init__(self, *arg, **kw):
        self.calls = []
        self.__mockmethods__ = {}

    def __getattr__(self, name):
        if name not in self.__mockmethods__:
            self.__mockmethods__[name] = self.MockMethod(self, name)
        return self.__mockmethods__[name]

    def reset_calls(self):
        """
        Reset call information for this instance
        """
        for mockmethod in self.MockMethod.registry.values():
            mockmethod.calls = []
        self.__mockmethods__ = {}
        self.calls = []

class MockPlugin(_MockPlugin, Plugin):
    """
    Mock a plugin
    """

class MockSingletonPlugin(_MockPlugin, SingletonPlugin):
    """
    Mock a singleton plugin
    """

########NEW FILE########
__FILENAME__ = test_activity
import ckan.model as model

Activity = model.Activity
ActivityDetail = model.ActivityDetail


class TestActivityDetail(object):
    def test_by_activity_id(self):
        activity = Activity('user-id', 'object-id',
                            'revision-id', 'activity-type')
        activity.save()
        activity_detail = ActivityDetail(activity.id, 'object-id',
                                         'object-type', 'activity-type')
        activity_detail.save()
        activities = ActivityDetail.by_activity_id(activity.id)
        assert activities == [activity_detail], activity_detail

########NEW FILE########
__FILENAME__ = test_extras
from ckan.tests import *

import ckan.model as model

class TestExtras:
    @classmethod 
    def setup_class(self):
        CreateTestData.create()

    @classmethod 
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_1(self):
        startrev = model.repo.youngest_revision().id
        pkg = model.Package.by_name(u'warandpeace')
        assert pkg is not None

        rev = model.repo.new_revision()
        pkg._extras[u'country'] = model.PackageExtra(key=u'country', value='us')
        pkg.extras_active[u'xxx'] = model.PackageExtra(key=u'xxx', value='yyy')
        pkg.extras[u'format'] = u'rdf'
        model.repo.commit_and_remove()

        # now test it is saved
        rev1 = model.repo.youngest_revision().id
        samepkg = model.Package.by_name(u'warandpeace')
        assert len(samepkg._extras) == 3, samepkg._extras
        assert samepkg.extras_active[u'country'].value == 'us', samepkg.extras_active
        assert samepkg.extras[u'country'] == 'us'
        assert samepkg.extras[u'format'] == 'rdf'
        model.Session.remove()

        # now delete and extras
        samepkg = model.Package.by_name(u'warandpeace')
        model.repo.new_revision()
        del samepkg.extras[u'country']
        model.repo.commit_and_remove()

        samepkg = model.Package.by_name(u'warandpeace')
        assert len(samepkg._extras) == 3
        assert len(samepkg.extras) == 2
        extra = model.Session.query(model.PackageExtra).filter_by(key=u'country').first()
        assert extra and extra.state == model.State.DELETED, extra
        model.Session.remove()
        
        samepkg = model.Package.by_name(u'warandpeace')
        samepkg.get_as_of(model.Session.query(model.Revision).get(rev1))
        assert len(samepkg.extras) == 3, len(samepkg.extras)
        model.Session.remove()

        # now restore it ...
        model.repo.new_revision()
        samepkg = model.Package.by_name(u'warandpeace')
        samepkg.extras[u'country'] = 'uk'
        model.repo.commit_and_remove()

        samepkg = model.Package.by_name(u'warandpeace')
        assert len(samepkg.extras) == 3
        assert len(samepkg._extras) == 3
        assert samepkg.extras[u'country'] == 'uk'
        

########NEW FILE########
__FILENAME__ = test_follower
import ckan.model as model
import ckan.lib.create_test_data as ctd

CreateTestData = ctd.CreateTestData


class FollowerClassesTests(object):
    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_get(self):
        following = self.FOLLOWER_CLASS.get(self.follower.id, self.followee.id)
        assert following.follower_id == self.follower.id, following
        assert following.object_id == self.followee.id, following

    def test_get_returns_none_if_couldnt_find_users(self):
        following = self.FOLLOWER_CLASS.get('some-id', 'other-id')
        assert following is None, following

    def test_is_following(self):
        assert self.FOLLOWER_CLASS.is_following(self.follower.id,
                                                self.followee.id)

    def test_is_following_returns_false_if_user_isnt_following(self):
        assert not self.FOLLOWER_CLASS.is_following(self.followee.id,
                                                    self.follower.id)

    def test_followee_count(self):
        count = self.FOLLOWER_CLASS.followee_count(self.follower.id)
        assert count == 1, count

    def test_followee_list(self):
        followees = self.FOLLOWER_CLASS.followee_list(self.follower.id)
        object_ids = [f.object_id for f in followees]
        assert object_ids == [self.followee.id], object_ids

    def test_follower_count(self):
        count = self.FOLLOWER_CLASS.follower_count(self.followee.id)
        assert count == 1, count

    def test_follower_list(self):
        followers = self.FOLLOWER_CLASS.follower_list(self.followee.id)
        follower_ids = [f.follower_id for f in followers]
        assert follower_ids == [self.follower.id], follower_ids


class TestUserFollowingUser(FollowerClassesTests):
    FOLLOWER_CLASS = model.UserFollowingUser

    @classmethod
    def setup_class(cls):
        model.repo.rebuild_db()
        cls.follower = CreateTestData.create_user('follower')
        cls.followee = CreateTestData.create_user('followee')
        cls.FOLLOWER_CLASS(cls.follower.id, cls.followee.id).save()
        cls._create_deleted_models()

    @classmethod
    def _create_deleted_models(cls):
        deleted_user = CreateTestData.create_user('deleted_user')
        cls.FOLLOWER_CLASS(deleted_user.id, cls.followee.id).save()
        cls.FOLLOWER_CLASS(cls.follower.id, deleted_user.id).save()
        deleted_user.delete()
        deleted_user.save()


class TestUserFollowingDataset(FollowerClassesTests):
    FOLLOWER_CLASS = model.UserFollowingDataset

    @classmethod
    def setup_class(cls):
        model.repo.rebuild_db()
        cls.follower = CreateTestData.create_user('follower')
        cls.followee = cls._create_dataset('followee')
        cls.FOLLOWER_CLASS(cls.follower.id, cls.followee.id).save()
        cls._create_deleted_models()

    @classmethod
    def _create_deleted_models(cls):
        deleted_user = CreateTestData.create_user('deleted_user')
        cls.FOLLOWER_CLASS(deleted_user.id, cls.followee.id).save()
        deleted_user.delete()
        deleted_user.save()
        deleted_dataset = cls._create_dataset('deleted_dataset')
        cls.FOLLOWER_CLASS(cls.follower.id, deleted_dataset.id).save()
        deleted_dataset.delete()
        deleted_dataset.save()

    @classmethod
    def _create_dataset(self, name):
        CreateTestData.create_arbitrary({'name': name})
        return model.Package.get(name)


class TestUserFollowingGroup(FollowerClassesTests):
    FOLLOWER_CLASS = model.UserFollowingGroup

    @classmethod
    def setup_class(cls):
        model.repo.rebuild_db()
        model.repo.new_revision()
        cls.follower = CreateTestData.create_user('follower')
        cls.followee = cls._create_group('followee')
        cls.FOLLOWER_CLASS(cls.follower.id, cls.followee.id).save()
        cls._create_deleted_models()
        model.repo.commit_and_remove()

    @classmethod
    def _create_deleted_models(cls):
        deleted_user = CreateTestData.create_user('deleted_user')
        cls.FOLLOWER_CLASS(deleted_user.id, cls.followee.id).save()
        deleted_user.delete()
        deleted_user.save()
        deleted_group = cls._create_group('deleted_group')
        cls.FOLLOWER_CLASS(cls.follower.id, deleted_group.id).save()
        deleted_group.delete()
        deleted_group.save()

    @classmethod
    def _create_group(self, name):
        group = model.Group(name)
        group.save()
        return group

########NEW FILE########
__FILENAME__ = test_group
from ckan.tests import assert_equal, assert_in, assert_not_in, CreateTestData

import ckan.model as model

class TestGroup(object):

    @classmethod
    def setup_class(self):
        CreateTestData.create()
        model.Session.remove()

    @classmethod
    def teardown_class(self):
        model.Session.remove()
        model.repo.rebuild_db()
        model.Session.remove()

    def test_1_basic(self):
        model.repo.new_revision()
        group1 = model.Group(name=u'group1', title=u'Test Group',
                             description=u'This is a test group')
        model.Session.add(group1)
        model.repo.commit_and_remove()
        grp = model.Group.by_name(u'group1')
        assert grp.title == u'Test Group'
        assert grp.description == u'This is a test group'
        assert grp.packages() == []

    def test_2_add_packages(self):
        model.repo.new_revision()
        
        self.russian_group = model.Group(name=u'russian',
                                         title=u'Russian Group',
                             description=u'This is the russian group')
        model.Session.add(self.russian_group)
        anna = model.Package.by_name(u'annakarenina')
        war = model.Package.by_name(u'warandpeace')
        model.Session.add(model.Member(group=self.russian_group,
                                       table_id=anna.id,
                                       table_name='package')
                         )
        model.Session.add(model.Member(group=self.russian_group,
                                       table_id=war.id,
                                       table_name='package')
                         )
        model.repo.commit_and_remove()
        
        grp = model.Group.by_name(u'russian')
        assert grp.title == u'Russian Group'
        anna = model.Package.by_name(u'annakarenina')
        war = model.Package.by_name(u'warandpeace')
        assert set(grp.packages()) == set((anna, war)), grp.packages()
        assert grp in anna.get_groups()

    def test_3_search(self):
        model.repo.new_revision()
        model.Session.add(model.Group(name=u'test_org',
                                       title=u'Test org',
                                       type=u'organization'
                         ))
        model.repo.commit_and_remove()


        assert_equal(self._search_results('random'), set([]))
        assert_equal(self._search_results('david'), set(['david']))
        assert_equal(self._search_results('roger'), set(['roger']))
        assert_equal(self._search_results('roger '), set(['roger']))
        assert_equal(self._search_results('David'), set(['david']))
        assert_equal(self._search_results('Dave'), set(['david']))
        assert_equal(self._search_results('Dave\'s'), set(['david']))
        assert_equal(self._search_results('Dave\'s books'), set(['david']))
        assert_equal(self._search_results('Books'), set(['david', 'roger']))
        assert_equal(self._search_results('Books', is_org=True), set([]))
        assert_equal(self._search_results('Test', is_org=True), set(['test_org']))

    def test_search_by_name_or_title_only_returns_active_groups(self):
        model.repo.new_revision()

        active_group = model.Group(name=u'active_group')
        active_group.state = u'active'
        inactive_group = model.Group(name=u'inactive_group')
        inactive_group.state = u'inactive'
        model.Session.add(active_group)
        model.Session.add(inactive_group)
        model.repo.commit_and_remove()

        assert_equal(self._search_results('active_group'), set(['active_group']))
        assert_equal(self._search_results('inactive_group'), set([]))

    def _search_results(self, query, is_org=False):
        results = model.Group.search_by_name_or_title(query,is_org=is_org)
        return set([group.name for group in results])

name_set_from_dicts = lambda groups: set([group['name'] for group in groups])
name_set_from_group_tuple = lambda tuples: set([t[1] for t in tuples])
name_set_from_groups = lambda groups: set([group.name for group in groups])
names_from_groups = lambda groups: [group.name for group in groups]

group_type = 'organization'

class TestHierarchy:
    @classmethod
    def setup_class(self):
        CreateTestData.create_group_hierarchy_test_data()

    def test_get_children_groups(self):
        res = model.Group.by_name(u'department-of-health').\
              get_children_groups(type=group_type)
        # check groups
        assert_equal(name_set_from_groups(res),
                     set(('national-health-service',
                          'food-standards-agency')))
        # check each group is a Group
        assert isinstance(res[0], model.Group)
        assert_in(res[0].name, ('national-health-service', 'food-standards-agency'))
        assert_in(res[0].title, ('National Health Service', 'Food Standards Agency'))

    def test_get_children_group_hierarchy__from_top_2(self):
        groups = model.Group.by_name(u'department-of-health').\
                get_children_group_hierarchy(type=group_type)
        # the first group must be NHS or Food Standards Agency - i.e. on the
        # first level down
        nhs = groups[0]
        assert_in(nhs[1], ('national-health-service', 'food-standards-agency'))
        assert_equal(model.Group.get(nhs[3]).name, 'department-of-health')

    def test_get_children_group_hierarchy__from_top(self):
        assert_equal(name_set_from_group_tuple(model.Group.by_name(u'department-of-health').\
                                       get_children_group_hierarchy(type=group_type)),
                     set(('national-health-service', 'food-standards-agency',
                          'nhs-wirral-ccg', 'nhs-southwark-ccg')))
        # i.e. not cabinet-office

    def test_get_children_group_hierarchy__from_tier_two(self):
        assert_equal(name_set_from_group_tuple(model.Group.by_name(u'national-health-service').\
                                       get_children_group_hierarchy(type=group_type)),
                     set(('nhs-wirral-ccg',
                          'nhs-southwark-ccg')))
        # i.e. not department-of-health or food-standards-agency

    def test_get_children_group_hierarchy__from_bottom_tier(self):
        assert_equal(name_set_from_group_tuple(model.Group.by_name(u'nhs-wirral-ccg').\
                                       get_children_group_hierarchy(type=group_type)),
                     set())

    def test_get_parents__top(self):
        assert_equal(names_from_groups(model.Group.by_name(u'department-of-health').\
                get_parent_groups(type=group_type)),
                    [])

    def test_get_parents__tier_two(self):
        assert_equal(names_from_groups(model.Group.by_name(u'national-health-service').\
                get_parent_groups(type=group_type)),
                    ['department-of-health'])

    def test_get_parents__tier_three(self):
        assert_equal(names_from_groups(model.Group.by_name(u'nhs-wirral-ccg').\
                get_parent_groups(type=group_type)),
                    ['national-health-service'])

    def test_get_parent_groups_up_hierarchy__from_top(self):
        assert_equal(names_from_groups(model.Group.by_name(u'department-of-health').\
                                      get_parent_group_hierarchy(type=group_type)),
                     [])

    def test_get_parent_groups_up_hierarchy__from_tier_two(self):
        assert_equal(names_from_groups(model.Group.by_name(u'national-health-service').\
                                       get_parent_group_hierarchy(type=group_type)),
                     ['department-of-health'])

    def test_get_parent_groups_up_hierarchy__from_tier_three(self):
        assert_equal(names_from_groups(model.Group.by_name(u'nhs-wirral-ccg').\
                                       get_parent_group_hierarchy(type=group_type)),
                     ['department-of-health',
                      'national-health-service'])

    def test_get_top_level_groups(self):
        assert_equal(names_from_groups(model.Group.by_name(u'nhs-wirral-ccg').\
                                       get_top_level_groups(type=group_type)),
                     ['cabinet-office', 'department-of-health'])

    def test_groups_allowed_to_be_its_parent(self):
        groups = model.Group.by_name(u'national-health-service').\
            groups_allowed_to_be_its_parent(type=group_type)
        names = names_from_groups(groups)
        assert_in('department-of-health', names)
        assert_in('cabinet-office', names)
        assert_not_in('natonal-health-service', names)
        assert_not_in('nhs-wirral-ccg', names)

class TestGroupRevisions:
    @classmethod
    def setup_class(self):
        model.Session.remove()
        CreateTestData.create()
        self.name = u'revisiontest'

        # create pkg
        self.descriptions = [u'Written by Puccini', u'Written by Rossini', u'Not written at all', u'Written again', u'Written off']
        rev = model.repo.new_revision()
        self.grp = model.Group(name=self.name)
        model.Session.add(self.grp)
        self.grp.description = self.descriptions[0]
        self.grp.extras['mykey'] = self.descriptions[0]
        model.repo.commit_and_remove()

        # edit pkg
        for i in range(5)[1:]:
            rev = model.repo.new_revision()
            grp = model.Group.by_name(self.name)
            grp.description = self.descriptions[i]
            grp.extras['mykey'] = self.descriptions[i]
            model.repo.commit_and_remove()

        self.grp = model.Group.by_name(self.name)        

    @classmethod
    def teardown_class(self):
        #rev = model.repo.new_revision()
        #grp = model.Group.by_name(self.name)
        #grp.purge()
        #model.repo.commit_and_remove()
        model.repo.rebuild_db()

    def test_1_all_revisions(self):
        all_rev = self.grp.all_revisions
        num_descs = len(self.descriptions)
        assert len(all_rev) == num_descs, len(all_rev)
        for i, rev in enumerate(all_rev):
            assert rev.description == self.descriptions[num_descs - i - 1], \
                '%s != %s' % (rev.description, self.descriptions[i])
                
    def test_2_extras(self):
        all_rev = self.grp.all_revisions
        num_descs = len(self.descriptions)
        assert len(all_rev) == num_descs, len(all_rev)
        for i, rev in enumerate(all_rev):
            #print "REVISION", dir(rev)
            #assert rev.extras['mykey'] == self.descriptions[num_descs - i - 1], \
            #    '%s != %s' % (rev.extras['mykey'], self.descriptions[i])
            pass


########NEW FILE########
__FILENAME__ = test_license
from ckan.model.license import LicenseRegister
import datetime

class TestCase(object):

    def assert_unicode(self, val):
        assert isinstance(val, unicode), "Value is not a unicode value: %s" % repr(val)

    def assert_datetime(self, val):
        assert isinstance(val, datetime.datetime), "Value is not a datetime value: %s" % repr(val)


class TestLicense(TestCase):

    def setup(self):
        self.licenses = LicenseRegister()

    def teardown(self):
        self.licenses = None

    def test_keys(self):
        for license_id in self.licenses.keys():
            self.assert_unicode(license_id)
    
    def test_values(self):
        for license in self.licenses.values():
            self.assert_unicode(license.id)
    
    def test_iter(self):
        for license_id in self.licenses:
            self.assert_unicode(license_id)
    
    def test_getitem(self):
        for license_id in self.licenses.keys():
            license = self.licenses[license_id]
            self.assert_unicode(license.id)
            self.assert_unicode(license.title)
            self.assert_unicode(license.url)


########NEW FILE########
__FILENAME__ = test_misc
from nose.tools import assert_equal

from ckan.tests import *
import ckan.model as model
from ckan.model.misc import escape_sql_like_special_characters

class TestRevisionExtraAttributes:
    @classmethod
    def setup_class(self):
        model.Session.remove()
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_revision_packages(self):
        rev = model.repo.youngest_revision()
        assert len(rev.packages) == 2
        assert rev.packages[0].__class__.__name__ == 'Package'
        names = [ p.name for p in rev.packages ]
        assert 'annakarenina' in names

    def test_revision_user(self):
        rev = model.repo.youngest_revision()
        assert rev.user is not None, rev
        assert rev.user.name == rev.author

_sql_escape = escape_sql_like_special_characters
class TestEscapeSqlLikeCharacters(object):
    """
    Tests for model.misc.escape_sql_like_special_characters
    """

    def test_identity(self):
        """Asserts that it escapes nothing if nothing needs escaping"""
        terms = ['',
                 'word',
                 'two words']
        for term, expected_term in zip(terms, terms):
            assert_equal(_sql_escape(term), expected_term)

    def test_escape_chararacter_is_escaped(self):
        """Asserts that the escape character is escaped"""
        term = r'backslash \ character'
        assert_equal (_sql_escape(term, escape='\\'),
                      r'backslash \\ character')

        term = 'surprise!'
        assert_equal (_sql_escape(term, escape='!'),
                      r'surprise!!')

    def test_default_escape_character_is_a_backslash(self):
        """Asserts that the default escape character is the backslash"""
        term = r'backslash \ character'
        assert_equal (_sql_escape(term),
                      r'backslash \\ character')

    def test_sql_like_special_characters_are_escaped(self):
        """Asserts that '%' and '_' are escaped correctly"""
        terms = [
            (r'percents %', r'percents \%'),
            (r'underscores _', r'underscores \_'),
            (r'backslash \ ', r'backslash \\ '),
            (r'all three \ _%', r'all three \\ \_\%'),
            ]

        for term, expected_result in terms:
            assert_equal(_sql_escape(term), expected_result)


########NEW FILE########
__FILENAME__ = test_package
from nose.tools import assert_equal

from ckan.tests import *
import ckan.model as model

# Todo: More domain logic tests e.g. for isopen() and other domain logic.

class TestPackage:
    @classmethod
    def setup_class(self):
        CreateTestData.create()
        self.name = u'geodata'
        self.notes = 'A <b>great</b> package <script href="dodgy.js"/> like package:pollution_stats'
        pkgs = model.Session.query(model.Package).filter_by(name=self.name).all()
        for p in pkgs:
            p.purge()
        model.Session.commit()
        rev = model.repo.new_revision()
        self.pkg1 = model.Package(name=self.name)
        model.Session.add(self.pkg1)
        self.pkg1.notes = self.notes
        self.pkg1.license_id = u'odc-by'
        model.Session.commit()
        model.Session.remove()

    @classmethod
    def teardown_class(self):
        pkg1 = model.Session.query(model.Package).filter_by(name=self.name).one()
        
        pkg1.purge()
        model.Session.commit()
        model.repo.rebuild_db()
        model.Session.remove()

    def test_basic_revisioning(self):
        # create a package with package_fixture_data
        name = "frob"
        rev = model.repo.new_revision()
        package = model.Package(name=name)
        model.Session.add(package)
        model.Session.flush()
        revision_id = model.Session().revision.id
        timestamp = model.Session().revision.timestamp
        model.repo.commit_and_remove()

        package = model.Package.by_name(name)
        assert len(package.all_revisions) == 1
        assert package.all_revisions[0].revision_id == revision_id
        assert package.all_revisions[0].revision_timestamp == timestamp
        assert package.all_revisions[0].expired_id is None

        # change it
        rev = model.repo.new_revision()
        package = model.Package.by_name(name)
        package.title = "wobsnasm"
        revision_id2 = model.Session().revision.id
        timestamp2 = model.Session().revision.timestamp
        model.repo.commit_and_remove()

        package = model.Package.by_name(name)
        assert len(package.all_revisions) == 2
        assert package.all_revisions[0].revision_id == revision_id2
        assert package.all_revisions[0].revision_timestamp == timestamp2
        assert package.all_revisions[0].expired_id is None

        assert package.all_revisions[1].revision_id == revision_id
        assert package.all_revisions[1].revision_timestamp == timestamp
        assert package.all_revisions[1].expired_id == revision_id2

    def test_create_package(self):
        package = model.Package.by_name(self.name)
        assert package.name == self.name
        assert package.notes == self.notes
        assert package.license.id == u'odc-by'
        assert package.license.title == u'Open Data Commons Attribution License', package.license.title

    def test_update_package(self):
        newnotes = u'Written by Beethoven'
        author = u'jones'

        rev2 = model.repo.new_revision()
        pkg = model.Package.by_name(self.name)
        pkg.notes = newnotes
        rev2.author = u'jones'
        model.Session.commit()
        try:
            model.Session.expunge_all()
        except AttributeError: # sqlalchemy 0.4
            model.Session.clear()
        outpkg = model.Package.by_name(self.name)
        assert outpkg.notes == newnotes
        assert len(outpkg.all_revisions) > 0
        assert outpkg.all_revisions[0].revision.author == author

    def test_package_license(self):
        # Check unregistered license_id causes license to be 'None'.
        package = model.Package.by_name(self.name)
        package.license_id = u'zzzzzzz'
        assert package.license == None
        model.Session.remove() # forget change

    def test_as_dict(self):
        pkg = model.Package.by_name(self.name)
        out = pkg.as_dict()
        assert out['name'] == pkg.name
        assert out['license'] == pkg.license.title
        assert out['license_id'] == pkg.license.id
        assert out['tags'] == [tag.name for tag in pkg.get_tags()]
        assert out['metadata_modified'] == pkg.metadata_modified.isoformat()
        assert out['metadata_created'] == pkg.metadata_created.isoformat()
        assert_equal(out['notes'], pkg.notes)
        assert_equal(out['notes_rendered'], '<p>A great package  like <a href="/dataset/pollution_stats">package:pollution_stats</a>\n</p>')


class TestPackageWithTags:
    """
    WARNING: with sqlite these tests may fail (depending on the order they are
    run in) as sqlite does not support ForeignKeys properly.
    """
    # Todo: Remove comment, since it pertains to sqlite, which CKAN doesn't support?

    @classmethod
    def setup_class(self):
        model.repo.init_db()
        rev1 = model.repo.new_revision()
        self.tagname = u'test tag m2m!'
        self.tagname2 = u'testtagm2m2'
        self.tagname3 = u'test tag3!'
        self.pkgname = u'testpkgm2m'
        pkg = model.Package(name=self.pkgname)
        self.tag = model.Tag(name=self.tagname)
        self.tag2 = model.Tag(name=self.tagname2)
        pkg2tag = model.PackageTag(package=pkg, tag=self.tag)
        pkg.add_tag(self.tag2)
        model.Session.add_all([pkg,self.tag,self.tag2,pkg2tag])
        model.Session.commit()
        self.pkg2tag_id = pkg2tag.id
        self.rev = rev1

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_1(self):
        pkg = model.Package.by_name(self.pkgname)
        assert len(pkg.get_tags()) == 2
        # pkg2tag = model.Session.query(model.PackageTag).get(self.pkg2tag_id)
        # assert pkg2tag.package.name == self.pkgname

    def test_tags(self):
        pkg = model.Package.by_name(self.pkgname)
        # TODO: go back to this
        # 2 default packages each with 2 tags so we have 2 + 4
        all = model.Session.query(model.Tag).all() 
        assert len(all) == 3, all

    def test_add_tag_by_name(self):
        rev = model.repo.new_revision()
        pkg = model.Package.by_name(self.pkgname)
        pkg.add_tag_by_name(self.tagname3)
        model.Session.commit()
        try:
            model.Session.expunge_all()
        except AttributeError: # sqlalchemy 0.4
            model.Session.clear()
        outpkg = model.Package.by_name(self.pkgname)
        assert len(outpkg.get_tags()) == 3
        t1 = model.Tag.by_name(self.tagname)
        assert len(t1.package_tags) == 1

    def test_add_tag_by_name_existing(self):
        try:
            model.Session.expunge_all()
        except AttributeError: # sqlalchemy 0.4
            model.Session.clear()
        pkg = model.Package.by_name(self.pkgname)
        assert len(pkg.get_tags()) == 3, len(pkg.get_tags())
        pkg.add_tag_by_name(self.tagname)
        assert len(pkg.get_tags()) == 3


class TestPackageTagSearch:
    @classmethod 
    def setup_class(self):
        CreateTestData.create()

        model.repo.new_revision()
        self.orderedfirst = u'000-zzz'
        # tag whose association will get deleted
        self.tagname = u'russian-tag-we-will-delete'
        tag3 = model.Tag(name=self.tagname)
        pkg = model.Package.by_name(u'annakarenina')
        pkg.add_tag(tag3)
        model.repo.commit_and_remove()

        model.repo.new_revision()
        pkg = model.Package.by_name(u'annakarenina')
        pkg.remove_tag(tag3)
        # now do a tag for ordering
        tagordered = model.Tag(name=self.orderedfirst)
        wap = model.Package.by_name(u'warandpeace')
        # do them the wrong way round
        wap.add_tag(tagordered)
        pkg.add_tag(tagordered)
        model.repo.commit_and_remove()

    @classmethod 
    def teardown_class(self):
        model.Session.remove()
        model.repo.rebuild_db()

    def test_0_deleted_package_tags(self):
        pkg = model.Package.by_name(u'annakarenina')
        tag = model.Tag.by_name(self.tagname)
        assert len(pkg.get_tags()) == 4, len(pkg.get_tags())
        assert len(tag.packages) == 0

    def test_1_tag_search_1(self):
        out = list(model.Tag.search_by_name(u'russian'))
        assert len(out) == 2
        assert out[0].name == 'russian'

    def test_1_tag_search_2(self):
        out = list(model.Tag.search_by_name(u'us'))
        assert len(out) == 2

    def test_1_tag_search_3(self):
        out = list(model.Tag.search_by_name(u's'))
        assert len(out) == 3
    
    def test_alphabetical_ordering(self):
        pkg = model.Package.by_name(u'annakarenina')
        tag = pkg.get_tags()[0]
        assert tag.name == self.orderedfirst
        assert tag.packages[0].name == 'annakarenina', tag.packages


class TestPackageRevisions:
    @classmethod
    def setup_class(self):
        model.Session.remove()
        model.repo.init_db()
        self.name = u'revisiontest'

        # create pkg
        self.notes = [u'Written by Puccini', u'Written by Rossini', u'Not written at all', u'Written again', u'Written off']
        rev = model.repo.new_revision()
        self.pkg1 = model.Package(name=self.name)
        model.Session.add(self.pkg1)
        self.pkg1.notes = self.notes[0]
        self.pkg1.extras['mykey'] = self.notes[0]
        model.repo.commit_and_remove()

        # edit pkg
        for i in range(5)[1:]:
            rev = model.repo.new_revision()
            pkg1 = model.Package.by_name(self.name)
            pkg1.notes = self.notes[i]
            pkg1.extras['mykey'] = self.notes[i]
            model.repo.commit_and_remove()

        self.pkg1 = model.Package.by_name(self.name)        

    @classmethod
    def teardown_class(self):
        rev = model.repo.new_revision()
        pkg1 = model.Package.by_name(self.name)
        pkg1.purge()
        model.repo.commit_and_remove()
        model.repo.rebuild_db()

    def test_1_all_revisions(self):
        all_rev = self.pkg1.all_revisions
        num_notes = len(self.notes)
        assert len(all_rev) == num_notes, len(all_rev)
        for i, rev in enumerate(all_rev):
            assert rev.notes == self.notes[num_notes - i - 1], '%s != %s' % (rev.notes, self.notes[i])
            #assert rev.extras['mykey'] == self.notes[num_notes - i - 1], '%s != %s' % (rev.extras['mykey'], self.notes[i])


class TestRelatedRevisions:
    @classmethod
    def setup_class(self):
        CreateTestData.create()
        model.Session.remove()
        self.name = u'difftest'

        # create pkg - PackageRevision
        rev = model.repo.new_revision()
        self.pkg1 = model.Package(name=self.name)
        model.Session.add(self.pkg1)
        self.pkg1.version = u'First version'
        model.repo.commit_and_remove()

        # edit pkg - PackageRevision
        rev = model.repo.new_revision()
        pkg1 = model.Package.by_name(self.name)
        pkg1.notes = u'New notes'
        rev.message = u'Added notes'
        model.repo.commit_and_remove()

        # edit pkg - PackageExtraRevision
        rev = model.repo.new_revision()
        pkg1 = model.Package.by_name(self.name)
        pkg1.extras = {u'a':u'b', u'c':u'd'}
        rev.message = u'Added extras'
        model.repo.commit_and_remove()

        # edit pkg - PackageTagRevision
        rev = model.repo.new_revision()
        pkg1 = model.Package.by_name(self.name)
        pkg1.add_tag_by_name(u'geo')
        pkg1.add_tag_by_name(u'scientific')
        rev.message = u'Added tags'
        model.repo.commit_and_remove()

        # edit pkg - ResourceRevision
        rev = model.repo.new_revision()
        pkg1 = model.Package.by_name(self.name)
        pkg1.resource_groups_all[0].resources_all.append(model.Resource(url=u'http://url1.com',
                                                    format=u'xls',
                                                    description=u'It is.',
                                                    hash=u'abc123'))
        rev.message = u'Added resource'
        model.repo.commit_and_remove()

        # edit pkg - ResourceRevision
        rev = model.repo.new_revision()
        pkg1 = model.Package.by_name(self.name)
        pkg1.resource_groups_all[0].resources_all[0].url = u'http://url1.com/edited'
        pkg1.resource_groups_all[0].resources_all.append(model.Resource(url=u'http://url2.com'))
        rev.message = u'Added resource'
        model.repo.commit_and_remove()

        # edit pkg - PackageRevision
        rev = model.repo.new_revision()
        pkg1 = model.Package.by_name(self.name)
        pkg1.notes = u'Changed notes'
        rev.message = u'Changed notes'
        model.repo.commit_and_remove()

        self.pkg1 = model.Package.by_name(self.name)
        self.res1 = model.Session.query(model.Resource).filter_by(url=u'http://url1.com/edited').one()
        self.res2 = model.Session.query(model.Resource).filter_by(url=u'http://url2.com').one()
        assert self.pkg1

    @classmethod
    def teardown_class(self):
        rev = model.repo.new_revision()
        pkg1 = model.Package.by_name(self.name)
        pkg1.purge()
        model.repo.commit_and_remove()
        model.repo.rebuild_db()

    def test_1_all_revisions(self):
        assert len(self.pkg1.all_revisions) == 3, self.pkg1.all_revisions
        assert len(self.pkg1.all_related_revisions) == 7, self.pkg1.all_related_revisions        

    def test_2_diff(self):
        rev_q = model.repo.history()
        rev_q = rev_q.order_by(model.Revision.timestamp.desc())
        last_rev = rev_q.first()
        first_rev = rev_q.all()[-1]
        second_rev = rev_q.all()[-2]
        diff = self.pkg1.diff(last_rev, second_rev)
        assert diff['notes'] == '- None\n+ Changed notes', diff['notes']
        assert diff.get('PackageTag-geo-state') == u'- \n+ active', diff
        assert diff.get('PackageTag-scientific-state') == u'- \n+ active', diff
        assert diff.get('PackageExtra-a-value') == u'- \n+ b', diff
        assert diff.get('PackageExtra-a-state') == u'- \n+ active', diff
        assert diff.get('PackageExtra-c-value') == u'- \n+ d', diff
        assert diff.get('PackageExtra-c-state') == u'- \n+ active', diff
        def test_res(diff, res, field, expected_value):
            key = 'Resource-%s-%s' % (res.id[:4], field)
            got_value = diff.get(key)
            expected_value = u'- \n+ %s' % expected_value
            assert got_value == expected_value, 'Key: %s Got: %r Expected: %r' % (key, got_value, expected_value)
        test_res(diff, self.res1, 'url', 'http://url1.com/edited')
        test_res(diff, self.res1, 'position', '0')
        test_res(diff, self.res1, 'format', 'xls')
        test_res(diff, self.res1, 'description', 'It is.')
        test_res(diff, self.res1, 'hash', 'abc123')
        test_res(diff, self.res1, 'state', 'active')
        test_res(diff, self.res2, 'url', 'http://url2.com')

class TestPackagePurge:
    @classmethod
    def setup_class(self):
        CreateTestData.create()
    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()
    def test_purge(self):
        pkgs = model.Session.query(model.Package).all()
        for p in pkgs:
           p.purge()
        model.Session.commit()
        pkgs = model.Session.query(model.Package).all()
        assert len(pkgs) == 0



########NEW FILE########
__FILENAME__ = test_package_relationships
from ckan.tests import *
import ckan.model as model
from ckan.lib.create_test_data import CreateTestData

class TestCreation:
    @classmethod
    def teardown(self):
        model.repo.rebuild_db()
        
    def test_normal_creation(self):
        create = CreateTestData
        create.create_arbitrary([{'name':u'the-parent', 'title':u'The Parent'},
                                 {'name':u'the-child', 'title':u'The Child'},
                                 ])
        theparent = model.Package.by_name(u'the-parent')
        thechild = model.Package.by_name(u'the-child')
        rev = model.repo.new_revision()
        thechild.add_relationship(u'child_of', theparent, u'Some comment')
        model.repo.commit_and_remove()

        theparent = model.Package.by_name(u'the-parent')
        thechild = model.Package.by_name(u'the-child')
        assert len(thechild.get_relationships()) == 1, thechild.get_relationships()
        pr = thechild.get_relationships()[0]
        assert theparent.get_relationships() == [pr], theparent.relationships
        assert thechild.relationships_as_subject == [pr], thechild.relationships_as_subject
        assert thechild.get_relationships(direction='forward') == [pr], thechild.get_relationships(direction='forward')
        assert not thechild.relationships_as_object, thechild.relationships_as_object
        assert not thechild.get_relationships(direction='reverse'), thechild.get_relationships(direction='reverse')
        assert not theparent.relationships_as_subject, theparent.relationships_as_subject
        assert theparent.relationships_as_object == [pr], theparent.relationships_as_object
        assert pr.type == u'child_of', pr.type
        assert pr.comment == u'Some comment', pr.comment
        assert pr.subject == thechild
        assert pr.object == theparent

    def test_reverse_creation(self):
        create = CreateTestData
        create.create_arbitrary([{'name':u'the-parent', 'title':u'The Parent'},
                                 {'name':u'the-child', 'title':u'The Child'},
                                 ])
        theparent = model.Package.by_name(u'the-parent')
        thechild = model.Package.by_name(u'the-child')
        rev = model.repo.new_revision()
        theparent.add_relationship(u'parent_of', thechild, u'Some comment')
        model.repo.commit_and_remove()

        theparent = model.Package.by_name(u'the-parent')
        thechild = model.Package.by_name(u'the-child')
        assert len(thechild.get_relationships()) == 1, thechild.get_relationships()
        pr = thechild.get_relationships()[0]
        assert pr.type == u'child_of', pr.type
        assert pr.comment == u'Some comment', pr.comment
        assert pr.subject == thechild
        assert pr.object == theparent
        
    def test_types(self):
        create = CreateTestData
        create.create_arbitrary([{'name':u'pkga', 'title':u'The Parent'},
                                 {'name':u'pkgb', 'title':u'The Child'},
                                 ])
        pkga = model.Package.by_name(u'pkga')
        pkgb = model.Package.by_name(u'pkgb')
        rev = model.repo.new_revision()
        pkgb.add_relationship(u'parent_of', pkga)
        pkgb.add_relationship(u'has_derivation', pkga)
        pkgb.add_relationship(u'child_of', pkga)
        pkgb.add_relationship(u'depends_on', pkga)
        model.repo.commit_and_remove()
        # i.e.  pkga child_of pkgb
        #       pkga derives_from pkgb
        #       pkgb child_of pkga
        #       pkgb depends_on pkga
        
        pkga = model.Package.by_name(u'pkga')
        pkgb = model.Package.by_name(u'pkgb')
        assert len(pkga.relationships_as_subject) == 2, pkga.relationships_as_subject
        assert len(pkgb.relationships_as_subject) == 2, pkga.relationships_as_subject
        assert len(pkga.relationships_as_object) == 2, pkga.relationships_as_object
        assert len(pkgb.relationships_as_object) == 2, pkga.relationships_as_object
        assert len(pkga.get_relationships()) == 4, pkga.get_relationships()
        assert len(pkgb.get_relationships()) == 4, pkgb.get_relationships()
        rel1, rel2 = pkga.relationships_as_subject if pkga.relationships_as_subject[0].type == u'child_of' else pkga.relationships_as_subject[::-1]
        assert rel1.type == u'child_of', rel1.type
        assert rel1.subject == pkga, rel1.subject
        assert rel1.object == pkgb, rel1.type
        assert rel2.type == u'derives_from', rel2.type
        assert rel2.subject == pkga, rel2.subject
        assert rel2.object == pkgb, rel2.type
        rel3, rel4 = pkga.relationships_as_object if pkga.relationships_as_object[0].type == u'child_of' else pkga.relationships_as_object[::-1]
        assert rel3.type == u'child_of', rel3.type
        assert rel3.subject == pkgb, rel3.subject
        assert rel3.object == pkga, rel3.type
        assert rel4.type == u'depends_on', rel4.type
        assert rel4.subject == pkgb, rel4.subject
        assert rel4.object == pkga, rel4.type

class TestSimple:
    @classmethod
    def setup_class(self):
        create = CreateTestData
        create.create_arbitrary([
            {'name':u'pkga', 'title':u'The Parent'},
            {'name':u'pkgb', 'title':u'The Child'},
            {'name':u'pkgc', 'title':u'The Child\s Child'},
            ])
        pkga = model.Package.by_name(u'pkga')
        pkgb = model.Package.by_name(u'pkgb')
        pkgc = model.Package.by_name(u'pkgc')
        rev = model.repo.new_revision()
        pkgb.add_relationship(u'parent_of', pkga)
        pkgb.add_relationship(u'has_derivation', pkga)
        pkgb.add_relationship(u'child_of', pkga)
        pkgb.add_relationship(u'depends_on', pkga)
        pkgc.add_relationship(u'child_of', pkgb)
        model.repo.commit_and_remove()

        self.pkga = model.Package.by_name(u'pkga')
        self.pkgb = model.Package.by_name(u'pkgb')
        self.pkgc = model.Package.by_name(u'pkgc')

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_usage(self):
        pkga_subject_query = model.PackageRelationship.by_subject(self.pkga)
        assert pkga_subject_query.count() == 2
        for rel in pkga_subject_query:
            assert rel.subject == self.pkga
            
        pkgb_object_query = model.PackageRelationship.by_object(self.pkgb)
        assert pkgb_object_query.count() == 3, pkgb_object_query.count()
        for rel in pkgb_object_query:
            assert rel.object == self.pkgb
        
class TestComplicated:
    @classmethod
    def setup_class(self):
        create = CreateTestData
        create.create_family_test_data()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_rels(self):
        rels = model.Package.by_name(u'homer').relationships
        assert len(rels) == 5, '%i: %s' % (len(rels), [rel for rel in rels])
        def check(rels, subject, type, object):
            for rel in rels:
                if rel.subject.name == subject and rel.type == type and rel.object.name == object:
                    return
            assert 0, 'Could not find relationship in: %r' % rels
        check(rels, 'homer', 'child_of', 'abraham')
        check(rels, 'bart', 'child_of', 'homer')
        check(rels, 'lisa', 'child_of', 'homer')
        check(rels, 'homer_derived', 'derives_from', 'homer')
        check(rels, 'homer', 'depends_on', 'beer')
        rels = model.Package.by_name(u'bart').relationships
        assert len(rels) == 1, len(rels)
        check(rels, 'bart', 'child_of', 'homer')

        pkgc_subject_query = model.PackageRelationship.by_subject(self.pkgc)
        assert pkgc_subject_query.count() == 1, pkgc_subject_query.count()
        for rel in pkgc_subject_query:
            assert rel.subject == self.pkgc

    def test_relationships_with(self):
        rels = self.pkgb.get_relationships_with(self.pkgc)
        assert len(rels) == 1, rels
        assert rels[0].type == 'child_of'

        rels = self.pkgb.get_relationships_with(self.pkga)
        assert len(rels) == 4, rels

        rels = self.pkgb.get_relationships_with(self.pkgc, type=u'parent_of')
        assert len(rels) == 1, rels

        rels = self.pkgb.get_relationships_with(self.pkgc, type=u'child_of')
        assert len(rels) == 0, rels

        rels = self.pkgc.get_relationships_with(self.pkgb, type=u'child_of')
        assert len(rels) == 1, rels

    def test_types(self):
        all_types = model.PackageRelationship.get_all_types()
        assert len(all_types) >= 6
        assert all_types[0] == u'depends_on', all_types

class TestComplicated:
    @classmethod
    def setup_class(self):
        create = CreateTestData
        create.create_family_test_data()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_01_rels(self):
        "audit the simpsons family relationships"
        rels = model.Package.by_name(u'homer').get_relationships()
        assert len(rels) == 5, '%i: %s' % (len(rels), [rel for rel in rels])
        def check(rels, subject, type, object):
            for rel in rels:
                if rel.subject.name == subject and rel.type == type and rel.object.name == object:
                    return
            assert 0, 'Could not find relationship in: %r' % rels
        check(rels, 'homer', 'child_of', 'abraham')
        check(rels, 'bart', 'child_of', 'homer')
        check(rels, 'lisa', 'child_of', 'homer')
        check(rels, 'homer_derived', 'derives_from', 'homer')
        check(rels, 'homer', 'depends_on', 'beer')
        rels = model.Package.by_name(u'bart').get_relationships()
        assert len(rels) == 2, len(rels)
        check(rels, 'bart', 'child_of', 'homer')
        check(rels, 'bart', 'child_of', 'marge')

    def test_02_deletion(self):
        "delete bart is child of homer"
        rels = model.Package.by_name(u'bart').get_relationships()
        assert len(rels) == 2
        assert rels[0].state == model.State.ACTIVE

    
        model.repo.new_revision()
        rels[0].delete()
        rels[1].delete()
        model.repo.commit_and_remove()
        
        rels = model.Package.by_name(u'bart').get_relationships()
        assert len(rels) == 0

        bart = model.Package.by_name(u'bart')
        q = model.Session.query(model.PackageRelationship).filter_by(subject=bart)
        assert q.count() == 2
        assert q.first().state == model.State.DELETED
        q = q.filter_by(state=model.State.ACTIVE)
        assert q.count() == 0

    def test_03_recreate(self):
        "recreate bart is child of homer"
        bart = model.Package.by_name(u"bart")
        homer = model.Package.by_name(u"homer")
        marge = model.Package.by_name(u"marge")

        rels = bart.get_relationships()
        assert len(rels) == 0, "expected bart to have no relations, found %s" % rels

        model.repo.new_revision()
        bart.add_relationship(u"child_of", homer)
        bart.add_relationship(u"child_of", marge)
        model.repo.commit_and_remove()

        rels = bart.get_relationships()
        assert len(rels) == 2, "expected bart to have one relation, found %s" % rels

        q = model.Session.query(model.PackageRelationship).filter_by(subject=bart)
        count = q.count()
        assert count == 2, "bart has %d relationships, expected 2" % count
        active = q.filter_by(state=model.State.ACTIVE).count()
        assert active == 2, "bart has %d active relationships, expected 2" % active
        deleted = q.filter_by(state=model.State.DELETED).count()
        assert deleted == 0, "bart has %d deleted relationships, expect 0" % deleted

    def test_04_relationship_display(self):

        bart = model.Package.by_name(u"bart")
        assert len(bart.get_relationships_printable()) == 3, len(bart.get_relationships_printable())

        model.repo.new_revision()
        lisa = model.Package.by_name(u"lisa")
        lisa.state = 'deleted'
        model.Session.commit()

        bart = model.Package.by_name(u"bart")
        assert len(bart.get_relationships_printable()) == 2, len(bart.get_relationships_printable())






########NEW FILE########
__FILENAME__ = test_purge_revision
from ckan.tests import *

import ckan.model as model

class TestRevisionPurge:
    
    @classmethod
    def setup_class(self):
        model.Session.remove()
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def setup(self):
        self.pkgname = u'revision-purge-test'

        model.repo.new_revision()
        self.pkg = model.Package(name=self.pkgname)
        self.old_url = u'abc.com'
        self.pkg.url = self.old_url
        tag1 = model.Tag.by_name(u'russian')
        tag2 = model.Tag.by_name(u'tolstoy')
        self.pkg.add_tag(tag1)
        self.pkg.add_tag(tag2)
        model.repo.commit_and_remove()

        txn2 = model.repo.new_revision()
        pkg = model.Package.by_name(self.pkgname)
        newurl = u'blah.com'
        pkg.url = newurl
        for tag in pkg.get_tags():
            pkg.remove_tag(tag)
        self.pkgname2 = u'revision-purge-test-2'
        self.pkg_new = model.Package(name=self.pkgname2)
        model.repo.commit_and_remove()

    def teardown(self):
        model.Session.remove()
        pkg_new = model.Package.by_name(self.pkgname2)
        if pkg_new:
            pkg_new.purge()
        pkg = model.Package.by_name(self.pkgname)
        pkg.purge()
        model.Session.commit()
        model.Session.remove()

    def test_1(self):
        rev = model.repo.youngest_revision()
        model.repo.purge_revision(rev, leave_record=True)

        rev = model.repo.youngest_revision()
        pkg = model.Package.by_name(self.pkgname)

        assert rev.message.startswith('PURGED'), rev.message
        assert pkg.url == self.old_url
        pkg2 = model.Package.by_name(self.pkgname2)
        assert pkg2 is None, 'pkgname2 should no longer exist'
        assert len(pkg.get_tags()) == 2

    def test_2(self):
        rev = model.repo.youngest_revision()
        num = rev.id
        model.repo.purge_revision(rev, leave_record=True)

        rev = model.repo.youngest_revision()
        # TODO: should youngest_revision be made purge aware
        # (requires state on revision)
        assert rev.id == num

    def test_purge_first_revision(self):
        rev = model.repo.youngest_revision()
        num = rev.id
        q = model.repo.history()
        q = q.order_by(model.Revision.timestamp.desc())
        q = q.limit(2)
        rev2 = q.all()[1]
        model.repo.purge_revision(rev, leave_record=True)

        rev = model.repo.youngest_revision()
        assert rev.id == num
        # either none or should equal num - 2 or be None (if no lower revision)
        pkg = model.Package.by_name(self.pkgname)
        assert len(pkg.all_revisions) == 1


########NEW FILE########
__FILENAME__ = test_resource
from sqlalchemy import MetaData, __version__ as sqav
from nose.tools import assert_equal, raises

from ckan.tests import *
import ckan.model as model
from ckan.lib.create_test_data import CreateTestData


class TestResource:
    def setup(self):
        self.pkgname = u'resourcetest'
        assert not model.Package.by_name(self.pkgname)
        assert model.Session.query(model.Resource).count() == 0
        self.urls = [u'http://somewhere.com/', u'http://elsewhere.com/']
        self.format = u'csv'
        self.description = u'Important part.'
        self.hash = u'abc123'
        self.alt_url = u'http://alturl' 
        self.size = 200
        self.label = 'labeltest'
        self.sort_order = '1'
        rev = model.repo.new_revision()
        pkg = model.Package(name=self.pkgname)
        model.Session.add(pkg)
        rg = pkg.resource_groups_all[0]
        for url in self.urls:
            pr = model.Resource(url=url,
                                format=self.format,
                                description=self.description,
                                hash=self.hash,
                                alt_url=self.alt_url,
                                extras={u'size':self.size},
                                )
            rg.resources_all.append(pr)
        pr = model.Resource(url="no_extra",
                            format=self.format,
                            description=self.description,
                            hash=self.hash,
                            )
        rg.resources_all.append(pr)
        model.repo.commit_and_remove()

    def teardown(self):
        model.repo.rebuild_db()
        
    def test_01_create_package_resources(self):

        pkg = model.Package.by_name(self.pkgname)
        assert len(pkg.resource_groups_all) == 1
        assert len(pkg.resource_groups_all[0].resources_all) == 3, pkg.resource_groups_all[0].resources

        resource_group_0 = pkg.resource_groups_all[0]
        assert resource_group_0.label == 'default', resource_group_0
        assert resource_group_0.sort_order == '' , resource_group_0

        resource_0 = resource_group_0.resources_all[0]

        assert resource_0.url == self.urls[0], resource_0
        assert resource_0.description == self.description, resource_0
        assert resource_0.hash == self.hash, resource_0
        assert resource_0.position == 0, resource_0.position
        assert resource_0.alt_url == self.alt_url, resource_0.alt_url
        assert_equal(resource_0.extras[u'size'], self.size)

        assert resource_group_0.package == pkg, resource_group_0.package
        assert resource_0.resource_group == resource_group_0, resource.resource_group

        generated_dict_resource = resource_0.as_dict()
        assert generated_dict_resource['alt_url'] == u'http://alturl', generated_dict_resource['alt_url']
        assert_equal(generated_dict_resource['size'], 200)

        generated_dict_resource_group = resource_group_0.as_dict()
        assert generated_dict_resource_group['label'] == 'default', generated_dict_resource_group['label']

        ## check to see if extra descriptor deletes properly
        rev = model.repo.new_revision()
        del resource_0.extras[u'size']
        assert resource_0.extras == {u'alt_url': u'http://alturl'}, pkg.resources[0].extras

        del resource_0.alt_url
        assert resource_0.extras == {}, pkg.resources[0].extras
        assert resource_0.alt_url is None

        resource_0.alt_url = 'weeee'
        assert resource_0.extras == {u'alt_url': u'weeee'}, resource_0.extras

        model.Session.add(resource_0)

        model.repo.commit_and_remove()
        pkg = model.Package.by_name(self.pkgname)

        assert resource_0.extras == {u'alt_url': u'weeee'}, resource_0.extras
        assert resource_0.alt_url == 'weeee', resource_0.alt_url

        pkg = model.Package.by_name(self.pkgname)

        assert pkg.resources[2].extras == {}, pkg.resources[2].extras


    def test_02_delete_resource(self):
        pkg = model.Package.by_name(self.pkgname)
        rg = pkg.resource_groups_all[0]
        res = rg.package.resources[0]
        assert len(rg.package.resources) == 3, rg.resources
        rev = model.repo.new_revision()
        res.delete()
        model.repo.commit_and_remove()

        pkg = model.Package.by_name(self.pkgname)
        rg = pkg.resource_groups_all[0]
        assert len(rg.package.resources) == 2, rg.resources
        assert len(rg.resources_all) == 3, rg.resources_all
    
    def test_03_reorder_resources(self):
        rev = model.repo.new_revision()
        pkg = model.Package.by_name(self.pkgname)
        rg = pkg.resource_groups_all[0]

        res0 = rg.resources_all[0]
        del rg.resources_all[0]
        rg.resources_all.append(res0)
        # this assert will fail
        # assert pkg.resources[1].position == 1
        # Why? According to docs for ordering list it does not reorder appended
        # elements by default (see
        # http://www.sqlalchemy.org/trac/browser/lib/sqlalchemy/ext/orderinglist.py#L197)
        # so we have to call reorder directly in supported versions
        # of sqlalchemy and set position to None in older ones.
        rg.resources_all.reorder()
        model.repo.commit_and_remove()

        pkg = model.Package.by_name(self.pkgname)
        assert len(rg.resources_all) == 3, len(rg.package.resources)
        lastres = rg.package.resources[2]
        assert lastres.position == 2, lastres
        print lastres
        assert lastres.url == self.urls[0], (self.urls, lastres.url)
        

    def test_04_insert_resource(self):
        pkg = model.Package.by_name(self.pkgname)
        rev = model.repo.new_revision()
        newurl = u'http://xxxxxxxxxxxxxxx'

        resource = model.Resource(url=newurl)
        rg = pkg.resource_groups_all[0]

        rg.resources_all.insert(0, resource)
        model.repo.commit_and_remove()

        rg = model.Package.by_name(self.pkgname).resource_groups_all[0]
        assert len(rg.package.resources) == 4, rg.resources
        assert rg.resources_all[1].url == self.urls[0]
        assert len(rg.resources_all[1].all_revisions) == 2

    def test_05_delete_package(self):
        pkg = model.Package.by_name(self.pkgname)
        all_resources = model.Session.query(model.Resource)
        active_resources = model.Session.query(model.Resource).\
                           filter_by(state=model.State.ACTIVE)
        assert all_resources.count() == 3, all_resources.all()
        assert active_resources.count() == 3, active_resources.count()
        rev = model.repo.new_revision()
        pkg.delete()
        model.repo.commit_and_remove()

        pkg = model.Package.by_name(self.pkgname)
        # OK for resources remain active
        assert all_resources.count() == 3, all_resources.all()
        assert active_resources.count() == 3, active_resources.count()

    @raises(AssertionError)
    def test_06_not_allow_two_resource_groups(self):
        pkg = model.Package.by_name(self.pkgname)
        resource_group = model.ResourceGroup(label="new")
        pkg.resource_groups_all.append(resource_group)
        pkg.resources

    def test_07_purge_package(self):
        pkg = model.Package.by_name(self.pkgname)
        all_resources = model.Session.query(model.Resource).all()
        assert len(all_resources) == 3, pkg.resources
        rev = model.repo.new_revision()
        pkg.purge()
        model.repo.commit_and_remove()

        pkg = model.Package.by_name(self.pkgname)
        all_resources = model.Session.query(model.Resource).\
                        filter_by(state=model.State.ACTIVE).all()
        assert len(all_resources) == 0, pkg.resources



########NEW FILE########
__FILENAME__ = test_revision
import datetime

from nose.tools import assert_equal

from ckan.tests import *
import ckan.model as model

# NB Lots of revision tests are part of vdm. No need to repeat those here.

class TestRevision:
    @classmethod
    def setup_class(cls):
        # Create a test package
        rev = model.repo.new_revision()
        rev.author = 'Tester'
        rev.timestamp = datetime.datetime(2020, 1, 1)
        rev.approved_timestamp = datetime.datetime(2020, 1, 2)
        rev.message = 'Test message'
        pkg = model.Package(name='testpkg')
        model.Session.add(pkg)
        model.Session.commit()
        model.Session.remove()

        revs = model.Session.query(model.Revision).\
               order_by(model.Revision.timestamp.desc()).all()
        cls.rev = revs[0] # newest

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()

    def test_revision_as_dict(self):
        rev_dict = model.revision_as_dict(self.rev,
                                          include_packages=True,
                                          include_groups=True,
                                          ref_package_by='name')
        
        assert_equal(rev_dict['id'], self.rev.id)
        assert_equal(rev_dict['author'], self.rev.author)
        assert_equal(rev_dict['timestamp'], '2020-01-01T00:00:00')
        assert_equal(rev_dict['approved_timestamp'], '2020-01-02T00:00:00')
        assert_equal(rev_dict['message'], self.rev.message)
        assert_equal(rev_dict['packages'], [u'testpkg'])
        

########NEW FILE########
__FILENAME__ = test_user
from nose.tools import assert_equal

from ckan.tests import *
import ckan.model as model
from ckan.lib.create_test_data import CreateTestData



class TestUser:

    @classmethod
    def setup_class(self):
        CreateTestData.create_user('brian', password='pass',
                                   fullname='Brian', email='brian@brian.com')
        CreateTestData.create_user(openid='http://sandra.owndomain.com/',
                                   fullname='Sandra')

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()
        
    def test_0_basic(self):
        out = model.User.by_name(u'brian')
        assert_equal(out.name, u'brian')
        assert_equal(len(out.apikey), 36)
        assert_equal(out.fullname, 'Brian')
        assert_equal(out.email, u'brian@brian.com')

        out = model.User.by_openid(u'http://sandra.owndomain.com/')
        assert_equal(out.fullname, u'Sandra')

    def test_1_timestamp_any_existing(self):
        user = model.Session.query(model.User).first()
        assert len(str(user.created)) > 5, out.created

    def test_2_timestamp_new(self):
        user = model.User()
        openid = u'http://xyz.com'
        user.name = openid
        model.Session.add(user)
        model.repo.commit_and_remove()

        out = model.User.by_name(openid)
        assert len(str(out.created)) > 5, out.created

    def test_3_get(self):
        out = model.User.get(u'brian')
        assert out.fullname == u'Brian'

        out = model.User.get(u'http://sandra.owndomain.com/')
        assert out.fullname == u'Sandra'

    def test_4_get_openid_missing_slash(self):
        # browsers seem to lose the double slash
        out = model.User.get(u'http:/sandra.owndomain.com/')
        assert out
        assert out.fullname == u'Sandra'

    def test_is_deleted(self):
        user = CreateTestData._create_user_without_commit('a_user')
        user.state = 'some-state'
        assert not user.is_deleted(), user
        user.delete()
        assert user.is_deleted(), user

    def test_user_is_active_by_default(self):
        user = CreateTestData._create_user_without_commit('a_user')
        assert user.is_active(), user

    def test_activate(self):
        user = CreateTestData._create_user_without_commit('a_user')
        user.state = 'some-state'
        assert not user.is_active(), user
        user.activate()
        assert user.is_active(), user

    def test_activate(self):
        user = CreateTestData._create_user_without_commit('a_user')
        user.state = 'some-state'
        assert not user.is_active(), user
        user.activate()
        assert user.is_active(), user

    def test_is_pending(self):
        user = CreateTestData._create_user_without_commit('a_user')
        user.state = 'some-state'
        assert not user.is_pending(), user
        user.set_pending()
        assert user.is_pending(), user


def to_names(domain_obj_list):
    '''Takes a list of domain objects and returns a corresponding list
    of their names.'''
    objs = []
    for obj in domain_obj_list:
        objs.append(obj.name if obj else None)
    return objs

class TestUserGroups:
    @classmethod
    def setup_class(self):
        CreateTestData.create_arbitrary([{'name': 'testpkg'}],
                                        extra_user_names=['brian', 'sandra'])
        CreateTestData.create_groups([
            {'name': 'grp1',
             'phone': '1234',
             }
            ])
        model.repo.new_revision()
        grp1 = model.Group.by_name(u'grp1')
        brian = model.User.by_name(u'brian')
        model.Session.add(model.Member(group=grp1,
                                       table_id=brian.id,
                                       table_name='user',
                                       capacity='admin')
                         )
        model.repo.commit_and_remove()
        
    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()
    
    def test_get_groups(self):
        brian = model.User.by_name(u'brian')
        groups = brian.get_groups()
        assert_equal(to_names(groups), ['grp1'])
        assert_equal(groups[0].extras, {'phone': '1234'})

        # check cache works between sessions
        model.Session.expunge_all()
        #don't refresh brian user since this is how c.user works
        # i.e. don't do this: brian = model.User.by_name(u'brian')
        groups = brian.get_groups()
        assert_equal(to_names(groups), ['grp1'])
        assert_equal(groups[0].extras, {'phone': '1234'})


class TestUser2(object):
    '''
        This class was originally in ckan/model/test_user.py
    '''

    @classmethod
    def setup_class(self):
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.Session.remove()
        model.repo.rebuild_db()

    def test_number_of_edits(self):
        # initially annafan won't have made any edits
        assert model.User.by_name(u'annafan').number_of_edits() == 0, \
                    "annafan shouldn't have made any edits"

        # so we'll get him to edit his package twice
        for i in [1,2]:

            rev = model.repo.new_revision()
            pkg = model.Package.by_name(u'annakarenina')
            pkg.notes = u'Changed notes %i' % i
            rev.author = u'annafan'
            model.repo.commit_and_remove()

            #and each time check that number_of_edits is correct
            assert model.User.by_name(u'annafan').number_of_edits() == i, \
                   "annafan should have made %i edit(s)" % i


    def test_number_of_administered_packages(self):
        model.User.by_name(u'annafan').number_administered_packages() == 1, \
            "annafan should own one package"
        model.User.by_name(u'joeadmin').number_administered_packages() == 0, \
            "joeadmin shouldn't own any packages"


    def test_search(self):
        anna_names = [a.name for a in  model.User.search('anna').all()]
        assert anna_names==['annafan'], \
            "Search for anna should find annafan only."

        test_names = [a.name for a in  model.User.search('test').all()]
        assert ( len(test_names) == 2 and
                 'tester' in test_names and
                 'testsysadmin' in test_names ), \
                 "Search for test should find tester and testsysadmin (only)"


########NEW FILE########
__FILENAME__ = pylons_controller
'''For unit testing that does not use paste fixture web requests, but needs
pylons set up for access to c, g or the template engine.

Based on answer at:
http://groups.google.com/group/pylons-discuss/browse_thread/thread/5f8d8f59fd459a77
'''

from unittest import TestCase 
from paste.registry import Registry 
import pylons 
from pylons.util import AttribSafeContextObj
import ckan.lib.app_globals as app_globals
from pylons.controllers.util import Request, Response 
from routes.util import URLGenerator

from ckan.config.routing import make_map
from ckan.tests import *
from ckan.lib.cli import MockTranslator

class TestPylonsSession(dict):
    last_accessed = None

    def save(self):
        pass


class PylonsTestCase(object):
    """A basic test case which allows access to pylons.c and pylons.request. 
    """
    @classmethod
    def setup_class(cls):
        cls.registry=Registry() 
        cls.registry.prepare() 

        cls.context_obj=AttribSafeContextObj()
        cls.registry.register(pylons.c, cls.context_obj)

        cls.app_globals_obj = app_globals.app_globals
        cls.registry.register(pylons.g, cls.app_globals_obj)

        cls.request_obj=Request(dict(HTTP_HOST="nohost", REQUEST_METHOD="GET")) 
        cls.registry.register(pylons.request, cls.request_obj) 

        cls.translator_obj=MockTranslator() 
        cls.registry.register(pylons.translator, cls.translator_obj) 

        cls.buffet = pylons.templating.Buffet('genshi', template_root='ckan.templates')
        cls.registry.register(pylons.buffet, cls.buffet)

        cls.registry.register(pylons.response, Response())
        mapper = make_map()
        cls.registry.register(pylons.url, URLGenerator(mapper, {}))
        cls.registry.register(pylons.session, TestPylonsSession())

        # Templates often want to find out the request's routes info, so put
        # some dummy values into the routes_dict, so the templates that do
        # this don't cause an exception.
        pylons.request.environ.update({'pylons.routes_dict': {
            'action': 'test-action',
            'controller': 'test-package::',
        }})
        pylons.c.environ = pylons.request.environ

    @classmethod
    def teardown_class(cls):
        """
        Although there is nothing to teardown in this class, `PylonsTestCase`
        is used as the superclass for a bunch of test cases.  So this empty
        declaration exists to that subclasses can safely call `teardown_class`
        on their superclasses.
        """
        pass

########NEW FILE########
__FILENAME__ = test_schema
from nose.tools import assert_equal

import ckan
from ckan.lib.navl.dictization_functions import validate
import ckan.logic.schema

class TestPackage:
    def test_name_validation(self):
        context = {'model': ckan.model,
                   'session': ckan.model.Session}
        schema = ckan.logic.schema.default_create_package_schema()
        def get_package_name_validation_errors(package_name):
            data_dict = {'name': package_name}
            data, errors = validate(data_dict, schema, context)
            return errors.get('name', [])

        good_names = ('blah', 'ab', 'ab1', 'some-random-made-up-name', 'has_underscore', 'annakarenina')
        bad_names = (('', [u'Missing value']),
                     ('blAh', [u'Url must be purely lowercase alphanumeric (ascii) characters and these symbols: -_']),
                     ('a', [u'Name must be at least 2 characters long', u'Name NAME length is less than minimum 2']),
                     ('dot.in.name', [u'Url must be purely lowercase alphanumeric (ascii) characters and these symbols: -_']),
                     (u'unicode-\xe0', [u'Url must be purely lowercase alphanumeric (ascii) characters and these symbols: -_']),
                     ('percent%', [u'Url must be purely lowercase alphanumeric (ascii) characters and these symbols: -_']),
                     ('p'*101, [u'Name must be a maximum of 100 characters long', u'Name NAME length is more than maximum 100']),
                     )

        for package_name in good_names:
            errors = get_package_name_validation_errors(package_name)
            assert_equal(errors, [])

        for package_name, expected_errors in bad_names:
            errors = get_package_name_validation_errors(package_name)
            errors = [err.replace('"%s"' % package_name, 'NAME') for err in errors]
            assert errors==expected_errors, \
                   '%r: %r != %r' % (package_name, errors, expected_errors)

    def test_version_validation(self):
        context = {'model': ckan.model,
                   'session': ckan.model.Session}
        schema = ckan.logic.schema.default_create_package_schema()
        def get_package_version_validation_errors(package_version):
            data_dict = {'version': package_version}
            data, errors = validate(data_dict, schema, context)
            return errors.get('version', [])

        good_versions = ('1.0', '')
        bad_versions = (
                     ('p'*101, [u'Version must be a maximum of 100 characters long']),
                     )

        for package_version in good_versions:
            errors = get_package_version_validation_errors(package_version)
            assert_equal(errors, [])

        for package_version, expected_errors in bad_versions:
            errors = get_package_version_validation_errors(package_version)
            errors = [err.replace('"%s"' % package_version, 'VERSION') for err in errors]
            assert errors==expected_errors, \
                   '%r: %r != %r' % (package_version, errors, expected_errors)


    def test_convert_from_extras(self):
        from ckan import logic
        context = {'model': ckan.model,
                   'session': ckan.model.Session}
        schema = ckan.logic.schema.default_create_package_schema()
        schema.update({
            'my_field': [logic.converters.convert_from_extras]
        })
        data_dict = {
            'name': 'my-pkg',
            'extras': [
                {'key': 'my_field', 'value': 'hola'},
                {'key': 'another_extra', 'value': 'caracola'}
                ]
            }
        data, errors = validate(data_dict, schema, context)

        assert 'my_field' in data
        assert data['my_field'] == 'hola'
        assert data['extras'][0]['key'] ==  'another_extra'

class TestTag:
    def test_tag_name_validation(self):
        context = {'model': ckan.model}
        schema = ckan.logic.schema.default_tags_schema()
        def get_tag_validation_errors(tag_name):
            data_dict = {'name': tag_name}

            data, errors = validate(data_dict, schema, context)
            return errors.get('name', [])

        good_names = ('blah', 'ab', 'ab1', 'some-random-made-up-name',\
                      'has_underscore', u'unicode-\xe0', 'dot.in.name',\
                      'multiple words', u'with Greek omega \u03a9', 'CAPITALS')
        bad_names = (('a', [u'Tag TAG length is less than minimum 2']),
                     ('  ,leading comma', [u'Tag TAG must be alphanumeric characters or symbols: -_.']),
                     ('trailing comma,', [u'Tag TAG must be alphanumeric characters or symbols: -_.']),\
                     ('empty,,tag', [u'Tag TAG must be alphanumeric characters or symbols: -_.']),
                     ('quote"character', [u'Tag TAG must be alphanumeric characters or symbols: -_.']),
                     ('p'*101, [u'Tag TAG length is more than maximum 100']),
                     )

        for tag_name in good_names:
            errors = get_tag_validation_errors(tag_name)
            assert_equal(errors, [])

        for tag_name, expected_errors in bad_names:
            errors = get_tag_validation_errors(tag_name)
            errors = [err.replace('"%s"' % tag_name, 'TAG') for err in errors]
            assert_equal(errors, expected_errors)

    def test_tag_string_parsing(self):
        # 'tag_string' is what you type into the tags field in the package
        # edit form. This test checks that it is parsed correctly or reports
        # errors correctly.
        context = {'model': ckan.model,
                   'session': ckan.model.Session}
        schema = ckan.logic.schema.default_update_package_schema()

        # basic parsing of comma separated values
        tests = (('tag', ['tag'], []),
                 ('tag1, tag2', ['tag1', 'tag2'], []),
                 ('tag 1', ['tag 1'], []),
                 )
        for tag_string, expected_tags, expected_errors in tests:
            data_dict = {'tag_string': tag_string}
            data, errors = validate(data_dict, schema, context)
            assert_equal(errors.get('tags', []), expected_errors)
            tag_names = [tag_dict['name'] for tag_dict in data['tags']]
            assert_equal(tag_names, expected_tags)
            
        # test whitespace chars are stripped
        whitespace_characters = u'\t\n\r\f\v '
        for ch in whitespace_characters:
            tag = ch + u'tag name' + ch
            data_dict = {'tag_string': tag}
            data, errors = validate(data_dict, schema, context)
            assert_equal(data['tags'], [{'name': u'tag name'}])



########NEW FILE########
__FILENAME__ = test_coding_standards
'''
The aim of these tests is to check and improve the coding standards in ckan.
Common issues are tested for here and tests fail if they are discovered in
files that are either new or were previously good. Bad files are
blacklisted to prevent them throwing errors in many cases because of the
number of affected files e.g. PEP8.  However if files start to pass a test
will fail and the file should be removed from the blacklist so that it will
then be kept clean in future.

The idea is to slowly improve the code quality in ckan without having files
deteriourating when they do reach the required standard.

Please do not add new files to the list as any new files should meet the
current coding standards.  Please add comments by files that fail if there
are legitamate reasons for the failure.
'''

import sys
import os
import re
import cStringIO
import inspect
import itertools

import pep8

file_path = os.path.dirname(__file__)
base_path = os.path.abspath(os.path.join(file_path, '..', '..'))


def process_directory(directory, ext='.py'):
    base_len = len(base_path) + 1
    for (dirpath, dirnames, filenames) in os.walk(directory):
        # ignore hidden files and dir
        filenames = [f for f in filenames if not f[0] == '.']
        dirnames[:] = [d for d in dirnames if not d[0] == '.']
        for name in filenames:
            if name.endswith(ext):
                path = os.path.join(dirpath, name)
                filename = path[base_len:]
                yield path, filename


def output_errors(filename, errors):
    out = ['']
    out.append('-' * len(filename))
    out.append(filename)
    out.append('-' * len(filename))
    for error in errors:
        out.append(error)
    return '\n'.join(out)


def show_fails(msg, errors):
    if errors:
        msg = ['\n%s' % msg]
        for error in errors:
            msg.append(errors[error])
        msg.append('\n\nFailing Files:\n==============')
        msg += sorted(errors)
        raise Exception('\n'.join(msg))


def show_passing(msg, errors):
    if errors:
        raise Exception('\n%s\n\n' % msg + '\n'.join(sorted(errors)))


def cs_filter(f, filter_, ignore_comment_lines=True):
    ''' filter the file removing comments if requested.
    looks for comments like
    # CS: <filter_> ignore
    # CS: <filter_> ignore x line
    and removes the requested number of lines.  Lines are removed by
    blanking so the line numbers reported will be correct.  This allows us
    to check files that have known violations of the test rules. '''

    # this RegEx is of poor quality but works
    exp = r'^\s*#\s+CS:.*%s.*ignore\D*((\d+)\s+line)*'
    re_ignore = re.compile(exp % filter_)
    ignore = 0
    out = []
    count = 1
    for line in f:
        # ignore the line if we have been told too
        if ignore > 0:
            line = ''
            ignore -= 1
        matches = re_ignore.search(line)
        if matches:
            ignore = int(matches.group(2) or 1)
        # ignore comments out lines
        if ignore_comment_lines and line.lstrip().startswith('#'):
            line = ''
        out.append(line)
        count += 1
    return out


class TestBadSpellings(object):

    BAD_SPELLING_BLACKLIST_FILES = []

    # these are the bad spellings with the correct spelling
    # use LOWER case
    BAD_SPELLINGS = {
        # CS: bad_spelling ignore 2 lines
        'licence': 'license',
        'organisation': 'organization',
    }

    fails = {}
    passes = []
    done = False

    @classmethod
    def setup(cls):
        if not cls.done:
            cls.process()
        cls.done = True

    @classmethod
    def process(cls):
        blacklist = cls.BAD_SPELLING_BLACKLIST_FILES
        re_bad_spelling = re.compile(
            r'(%s)' % '|'.join([x for x in cls.BAD_SPELLINGS]),
            flags=re.IGNORECASE
        )
        files = itertools.chain.from_iterable([
            process_directory(base_path),
            process_directory(base_path, ext='.rst')])
        for path, filename in files:
            f = open(path, 'r')
            count = 1
            errors = []
            for line in cs_filter(f, 'bad_spelling'):
                matches = re_bad_spelling.findall(line)
                if matches:
                    bad_words = []
                    for m in matches:
                        if m not in bad_words:
                            bad_words.append('%s use %s' %
                                             (m, cls.BAD_SPELLINGS[m.lower()]))
                    bad = ', '.join(bad_words)
                    errors.append('ln:%s \t%s\n<%s>' % (count, line[:-1], bad))
                count += 1
            if errors and not filename in blacklist:
                cls.fails[filename] = output_errors(filename, errors)
            elif not errors and filename in blacklist:
                cls.passes.append(filename)

    def test_good(self):
        msg = 'The following files passed bad spellings rules'
        msg += '\nThey need removing from the test blacklist'
        show_passing(msg, self.passes)

    def test_bad(self):
        msg = 'The following files have bad spellings that need fixing'
        show_fails(msg, self.fails)


class TestNastyString(object):
    # CS: nasty_string ignore
    ''' Look for a common coding problem in ckan '..%s..' % str(x) '''

    # Nasty str() issues
    #
    # There are places in ckan where code is like `'...%s..' % str(..)`
    # these cause problems when unicode is present but can remain dormant
    # for a long time before the issue is apparent so try to remove these.
    # The value is converted to a string anyway so the str() is unneeded in
    # any place.

    NASTY_STR_BLACKLIST_FILES = []

    fails = {}
    passes = []
    done = False

    @classmethod
    def setup(cls):
        if not cls.done:
            cls.process()
        cls.done = True

    @classmethod
    def process(cls):
        blacklist = cls.NASTY_STR_BLACKLIST_FILES
        re_nasty_str = re.compile(
            r'''("[^"]*\%s[^"]*"|'[^']*\%s[^']*').*%.*str\('''
        )
        for path, filename in process_directory(base_path):
            f = open(path, 'r')
            count = 1
            errors = []
            for line in cs_filter(f, 'nasty_string'):
                if re_nasty_str.search(line):
                    errors.append('ln:%s \t%s' % (count, line[:-1]))
                count += 1
            if errors and not filename in blacklist:
                cls.fails[filename] = output_errors(filename, errors)
            elif not errors and filename in blacklist:
                cls.passes.append(filename)

    def test_good(self):
        msg = 'The following files passed nasty str() rules'
        msg += '\nThey need removing from the test blacklist'
        show_passing(msg, self.passes)

    def test_bad(self):
        # CS: nasty_string ignore next 2 lines
        msg = ('The following files have nasty str() issues that need'
               ' resolving\nCode is like `\'...%s..\' % str(..)`'
               'and should just be `\'...%s..\' % ..`')
        show_fails(msg, self.fails)


class TestImportFromCkan(object):
    ''' Find files using from ckan import ... style imports '''

    # Ckan import file exceptions
    #
    # These files contain lines like `from ckan import x` This should not be
    # done except from ckan.common which is written specifically to share
    # external functions.  When files are fixed they should be removed from
    # this list.
    #
    # The reason for this is to try to remove as many of the circular import
    # issues that exist.

    CKAN_IMPORTS_BLACKLIST_FILES = [
        'bin/ckan-hmg-breakdown.py',
        'bin/dump-ukgov.py',
        'ckan/config/middleware.py',
        'ckan/controllers/error.py',
        'ckan/controllers/storage.py',
        'ckan/lib/authenticator.py',
        'ckan/lib/munge.py',
        'ckan/lib/plugins.py',
        'ckan/lib/search/index.py',
        'ckan/lib/search/query.py',
        'ckan/lib/search/sql.py',
        'ckan/logic/action/__init__.py',
        'ckan/logic/action/create.py',
        'ckan/logic/auth/delete.py',
        'ckan/logic/auth/get.py',
        'ckan/logic/auth/update.py',
        'ckan/logic/schema.py',
        'ckan/logic/validators.py',
        'ckan/migration/versions/034_resource_group_table.py',
        'ckan/migration/versions/035_harvesting_doc_versioning.py',
        'ckan/model/test_user.py',
        'ckan/plugins/__init__.py',
        'ckan/tests/__init__.py',
        'ckan/tests/ckantestplugin/ckantestplugin/__init__.py',
        'ckan/tests/functional/api/base.py',
        'ckan/tests/functional/api/model/test_group.py',
        'ckan/tests/functional/api/model/test_licenses.py',
        'ckan/tests/functional/api/model/test_package.py',
        'ckan/tests/functional/api/model/test_ratings.py',
        'ckan/tests/functional/api/model/test_relationships.py',
        'ckan/tests/functional/api/model/test_revisions.py',
        'ckan/tests/functional/api/model/test_tag.py',
        'ckan/tests/functional/api/test_api.py',
        'ckan/tests/functional/api/test_follow.py',
        'ckan/tests/functional/api/test_misc.py',
        'ckan/tests/functional/api/test_package_search.py',
        'ckan/tests/functional/api/test_resource.py',
        'ckan/tests/functional/api/test_resource_search.py',
        'ckan/tests/functional/api/test_revision_search.py',
        'ckan/tests/functional/api/test_user.py',
        'ckan/tests/functional/api/test_util.py',
        'ckan/tests/functional/base.py',
        'ckan/tests/functional/test_activity.py',
        'ckan/tests/functional/test_admin.py',
        'ckan/tests/functional/test_cors.py',
        'ckan/tests/functional/test_follow.py',
        'ckan/tests/functional/test_group.py',
        'ckan/tests/functional/test_home.py',
        'ckan/tests/functional/test_package.py',
        'ckan/tests/functional/test_package_relationships.py',
        'ckan/tests/functional/test_pagination.py',
        'ckan/tests/functional/test_revision.py',
        'ckan/tests/functional/test_search.py',
        'ckan/tests/functional/test_storage.py',
        'ckan/tests/functional/test_tag.py',
        'ckan/tests/functional/test_tag_vocab.py',
        'ckan/tests/functional/test_upload.py',
        'ckan/tests/functional/test_user.py',
        'ckan/tests/lib/__init__.py',
        'ckan/tests/lib/test_alphabet_pagination.py',
        'ckan/tests/lib/test_cli.py',
        'ckan/tests/lib/test_dictization.py',
        'ckan/tests/lib/test_dictization_schema.py',
        'ckan/tests/lib/test_field_types.py',
        'ckan/tests/lib/test_hash.py',
        'ckan/tests/lib/test_helpers.py',
        'ckan/tests/lib/test_i18n.py',
        'ckan/tests/lib/test_mailer.py',
        'ckan/tests/lib/test_navl.py',
        'ckan/tests/lib/test_resource_search.py',
        'ckan/tests/lib/test_simple_search.py',
        'ckan/tests/lib/test_solr_package_search.py',
        'ckan/tests/lib/test_solr_package_search_synchronous_update.py',
        'ckan/tests/lib/test_solr_schema_version.py',
        'ckan/tests/lib/test_solr_search_index.py',
        'ckan/tests/lib/test_tag_search.py',
        'ckan/tests/logic/test_action.py',
        'ckan/tests/logic/test_auth.py',
        'ckan/tests/logic/test_tag.py',
        'ckan/tests/logic/test_validators.py',
        'ckan/tests/misc/test_mock_mail_server.py',
        'ckan/tests/misc/test_sync.py',
        'ckan/tests/mock_mail_server.py',
        'ckan/tests/mock_plugin.py',
        'ckan/tests/models/test_extras.py',
        'ckan/tests/models/test_group.py',
        'ckan/tests/models/test_license.py',
        'ckan/tests/models/test_misc.py',
        'ckan/tests/models/test_package.py',
        'ckan/tests/models/test_package_relationships.py',
        'ckan/tests/models/test_purge_revision.py',
        'ckan/tests/models/test_resource.py',
        'ckan/tests/models/test_revision.py',
        'ckan/tests/models/test_user.py',
        'ckan/tests/pylons_controller.py',
        'ckan/tests/schema/test_schema.py',
        'ckan/tests/test_dumper.py',
        'ckan/tests/test_plugins.py',
        'ckan/tests/test_wsgi_ckanclient.py',
        'ckan/websetup.py',
        'ckanext/multilingual/plugin.py',
        'ckanext/reclinepreview/tests/test_preview.py',
        'ckanext/stats/controller.py',
        'ckanext/stats/tests/__init__.py',
        'ckanext/stats/tests/test_stats_lib.py',
        'ckanext/stats/tests/test_stats_plugin.py',
        'ckanext/test_tag_vocab_plugin.py',
        'setup.py',
    ]
    fails = {}
    passes = []
    done = False

    @classmethod
    def setup(cls):
        if not cls.done:
            cls.process()
        cls.done = True

    @classmethod
    def process(cls):
        blacklist = cls.CKAN_IMPORTS_BLACKLIST_FILES
        re_bad_import = re.compile(r'^from\s.*\bckan\b(?!\.common).*\bimport')
        for path, filename in process_directory(base_path):
            f = open(path, 'r')
            count = 1
            errors = []
            for line in f:
                if re_bad_import.search(line):
                    errors.append('ln:%s \t%s' % (count, line[:-1]))
                count += 1
            if errors and not filename in blacklist:
                cls.fails[filename] = output_errors(filename, errors)
            elif not errors and filename in blacklist:
                cls.passes.append(filename)

    def test_import_good(self):
        msg = 'The following files passed ckan import rules'
        msg += '\nThey need removing from the test blacklist'
        show_passing(msg, self.passes)

    def test_import_bad(self):
        msg = ('The following files have ckan import issues that need'
               'resolving\nThese files contain lines like `from ckan import x`'
               ' This should not be done except from ckan.common which is'
               ' written specifically to share external functions.')
        show_fails(msg, self.fails)


class TestImportStar(object):
    ''' Find files using from xxx import * '''

    # Import * file exceptions
    #
    # The following files contain one or more `from ... import *` lines
    # which should not be used in ckan where possible.  If the files get
    # fixed they should be removed from this list.
    #
    # import * is bad for many reasons and should be avoided.

    IMPORT_STAR_BLACKLIST_FILES = [
        'ckan/lib/helpers.py',
        'ckan/migration/versions/001_add_existing_tables.py',
        'ckan/migration/versions/002_add_author_and_maintainer.py',
        'ckan/migration/versions/003_add_user_object.py',
        'ckan/migration/versions/004_add_group_object.py',
        'ckan/migration/versions/005_add_authorization_tables.py',
        'ckan/migration/versions/006_add_ratings.py',
        'ckan/migration/versions/007_add_system_roles.py',
        'ckan/migration/versions/008_update_vdm_ids.py',
        'ckan/migration/versions/009_add_creation_timestamps.py',
        'ckan/migration/versions/010_add_user_about.py',
        'ckan/migration/versions/011_add_package_search_vector.py',
        'ckan/migration/versions/012_add_resources.py',
        'ckan/migration/versions/013_add_hash.py',
        'ckan/migration/versions/014_hash_2.py',
        'ckan/migration/versions/015_remove_state_object.py',
        'ckan/migration/versions/016_uuids_everywhere.py',
        'ckan/migration/versions/017_add_pkg_relationships.py',
        'ckan/migration/versions/018_adjust_licenses.py',
        'ckan/migration/versions/019_pkg_relationships_state.py',
        'ckan/migration/versions/020_add_changeset.py',
        'ckan/migration/versions/022_add_group_extras.py',
        'ckan/migration/versions/023_add_harvesting.py',
        'ckan/migration/versions/024_add_harvested_document.py',
        'ckan/migration/versions/025_add_authorization_groups.py',
        'ckan/migration/versions/026_authorization_group_user_pk.py',
        'ckan/migration/versions/027_adjust_harvester.py',
        'ckan/migration/versions/028_drop_harvest_source_status.py',
        'ckan/migration/versions/029_version_groups.py',
        'ckan/migration/versions/030_additional_user_attributes.py',
        'ckan/migration/versions/031_move_openid_to_new_field.py',
        'ckan/migration/versions/032_add_extra_info_field_to_resources.py',
        'ckan/migration/versions/033_auth_group_user_id_add_conditional.py',
        'ckan/migration/versions/034_resource_group_table.py',
        'ckan/migration/versions/035_harvesting_doc_versioning.py',
        'ckan/migration/versions/036_lockdown_roles.py',
        'ckan/migration/versions/037_role_anon_editor.py',
        'ckan/migration/versions/038_delete_migration_tables.py',
        'ckan/migration/versions/039_add_expired_id_and_dates.py',
        'ckan/migration/versions/040_reset_key_on_user.py',
        'ckan/migration/versions/041_resource_new_fields.py',
        'ckan/migration/versions/042_user_revision_indexes.py',
        'ckan/migration/versions/043_drop_postgres_search.py',
        'ckan/migration/versions/044_add_task_status.py',
        'ckan/migration/versions/045_user_name_unique.py',
        'ckan/migration/versions/046_drop_changesets.py',
        'ckan/migration/versions/047_rename_package_group_member.py',
        'ckan/migration/versions/048_add_activity_streams_tables.py',
        'ckan/migration/versions/049_add_group_approval_status.py',
        'ckan/migration/versions/050_term_translation_table.py',
        'ckan/migration/versions/051_add_tag_vocabulary.py',
        'ckan/migration/versions/052_update_member_capacities.py',
        'ckan/migration/versions/053_add_group_logo.py',
        'ckan/migration/versions/056_add_related_table.py',
        'ckan/migration/versions/057_tracking.py',
        'ckan/migration/versions/058_add_follower_tables.py',
        'ckan/migration/versions/059_add_related_count_and_flag.py',
        'ckan/migration/versions/060_add_system_info_table.py',
        'ckan/migration/versions/061_add_follower__group_table.py',
        'ckan/migration/versions/062_add_dashboard_table.py',
        'ckan/migration/versions/063_org_changes.py',
        'ckan/migration/versions/064_add_email_last_sent_column.py',
        'ckan/migration/versions/065_add_email_notifications_preference.py',
        'ckan/plugins/__init__.py',
        'ckan/tests/functional/api/base.py',
        'ckan/tests/functional/api/test_api.py',
        'ckan/tests/functional/api/test_misc.py',
        'ckan/tests/functional/api/test_package_search.py',
        'ckan/tests/functional/api/test_resource_search.py',
        'ckan/tests/functional/api/test_revision_search.py',
        'ckan/tests/functional/test_group.py',
        'ckan/tests/functional/test_home.py',
        'ckan/tests/functional/test_package.py',
        'ckan/tests/functional/test_package_relationships.py',
        'ckan/tests/functional/test_tag.py',
        'ckan/tests/lib/test_alphabet_pagination.py',
        'ckan/tests/lib/test_field_types.py',
        'ckan/tests/lib/test_helpers.py',
        'ckan/tests/lib/test_resource_search.py',
        'ckan/tests/lib/test_tag_search.py',
        'ckan/tests/misc/test_sync.py',
        'ckan/tests/models/test_extras.py',
        'ckan/tests/models/test_misc.py',
        'ckan/tests/models/test_package.py',
        'ckan/tests/models/test_package_relationships.py',
        'ckan/tests/models/test_purge_revision.py',
        'ckan/tests/models/test_resource.py',
        'ckan/tests/models/test_revision.py',
        'ckan/tests/models/test_user.py',
        'ckan/tests/pylons_controller.py',
        'ckan/tests/test_dumper.py',
        'ckan/tests/test_wsgi_ckanclient.py',
        'fabfile.py',
    ]
    fails = {}
    passes = []
    done = False

    @classmethod
    def setup(cls):
        if not cls.done:
            cls.process()
        cls.done = True

    @classmethod
    def process(cls):
        blacklist = cls.IMPORT_STAR_BLACKLIST_FILES
        re_import_star = re.compile(r'^\s*from\s+.*\simport\s+\*')
        for path, filename in process_directory(base_path):
            f = open(path, 'r')
            count = 1
            errors = []
            for line in f:
                if re_import_star.search(line):
                    errors.append('%s ln:%s import *\n\t%s'
                                  % (filename, count, line))
                count += 1
            if errors and not filename in blacklist:
                cls.fails[filename] = output_errors(filename, errors)
            elif not errors and filename in blacklist:
                cls.passes.append(filename)

    def test_import_good(self):
        msg = 'The following files passed import * rules'
        msg += '\nThey need removing from the test blacklist'
        show_passing(msg, self.passes)

    def test_import_bad(self):
        msg = ('The following files have import * issues that need resolving\n'
               '`from ... import *` lines which should not be used in ckan'
               ' where possible.')
        show_fails(msg, self.fails)


class TestPep8(object):
    ''' Check that .py files are pep8 compliant '''

    # PEP8 File exceptions
    #
    # The following files have known PEP8 errors.  When the files get to a
    # point of not having any such errors they should be removed from this
    # list to prevent new errors being added to the file.

    PEP8_BLACKLIST_FILES = [
        'bin/canada.py',
        'bin/ckan-correct-tags.py',
        'bin/ckan-edit-tags.py',
        'bin/ckan-edit-tags2.py',
        'bin/ckan-hmg-breakdown.py',
        'bin/ckan-hmg-update-licenses.py',
        'bin/ckan-rest-edit-tags.py',
        'bin/ckan_edit_local.py',
        'bin/ckan_spam.py',
        'bin/copy-ckan-2-ckan.py',
        'bin/dump-ukgov.py',
        'bin/dump_23_pkgs.py',
        'bin/fixes.py',
        'bin/loadconfig.py',
        'bin/ons-load.py',
        'bin/revision_manager.py',
        'bin/running_stats.py',
        'bin/status.py',
        'bin/talisckan.py',
        'bin/webstore_test.py',
        'ckan/__init__.py',
        'ckan/ckan_nose_plugin.py',
        'ckan/config/middleware.py',
        'ckan/config/routing.py',
        'ckan/config/sp_config.py',
        'ckan/controllers/admin.py',
        'ckan/controllers/api.py',
        'ckan/controllers/group.py',
        'ckan/controllers/package.py',
        'ckan/controllers/revision.py',
        'ckan/exceptions.py',
        'ckan/i18n/check_po_files.py',
        'ckan/include/rcssmin.py',
        'ckan/include/rjsmin.py',
        'ckan/lib/activity_streams.py',
        'ckan/lib/activity_streams_session_extension.py',
        'ckan/lib/alphabet_paginate.py',
        'ckan/lib/app_globals.py',
        'ckan/lib/authenticator.py',
        'ckan/lib/captcha.py',
        'ckan/lib/cli.py',
        'ckan/lib/create_test_data.py',
        'ckan/lib/dictization/__init__.py',
        'ckan/lib/dictization/model_dictize.py',
        'ckan/lib/dictization/model_save.py',
        'ckan/lib/dumper.py',
        'ckan/lib/email_notifications.py',
        'ckan/lib/extract.py',
        'ckan/lib/fanstatic_extensions.py',
        'ckan/lib/fanstatic_resources.py',
        'ckan/lib/field_types.py',
        'ckan/lib/formatters.py',
        'ckan/lib/hash.py',
        'ckan/lib/help/flash_messages.py',
        'ckan/lib/helpers.py',
        'ckan/lib/i18n.py',
        'ckan/lib/jinja_extensions.py',
        'ckan/lib/jsonp.py',
        'ckan/lib/mailer.py',
        'ckan/lib/maintain.py',
        'ckan/lib/munge.py',
        'ckan/lib/navl/dictization_functions.py',
        'ckan/lib/navl/validators.py',
        'ckan/lib/package_saver.py',
        'ckan/lib/plugins.py',
        'ckan/lib/render.py',
        'ckan/lib/repoze_patch.py',
        'ckan/lib/search/__init__.py',
        'ckan/lib/search/index.py',
        'ckan/lib/search/query.py',
        'ckan/lib/search/sql.py',
        'ckan/logic/__init__.py',
        'ckan/logic/action/__init__.py',
        'ckan/logic/action/delete.py',
        'ckan/logic/action/get.py',
        'ckan/logic/action/update.py',
        'ckan/logic/auth/create.py',
        'ckan/logic/auth/delete.py',
        'ckan/logic/auth/get.py',
        'ckan/logic/auth/update.py',
        'ckan/logic/converters.py',
        'ckan/logic/schema.py',
        'ckan/logic/validators.py',
        'ckan/migration/versions/001_add_existing_tables.py',
        'ckan/migration/versions/002_add_author_and_maintainer.py',
        'ckan/migration/versions/003_add_user_object.py',
        'ckan/migration/versions/004_add_group_object.py',
        'ckan/migration/versions/005_add_authorization_tables.py',
        'ckan/migration/versions/006_add_ratings.py',
        'ckan/migration/versions/007_add_system_roles.py',
        'ckan/migration/versions/008_update_vdm_ids.py',
        'ckan/migration/versions/009_add_creation_timestamps.py',
        'ckan/migration/versions/010_add_user_about.py',
        'ckan/migration/versions/011_add_package_search_vector.py',
        'ckan/migration/versions/012_add_resources.py',
        'ckan/migration/versions/013_add_hash.py',
        'ckan/migration/versions/014_hash_2.py',
        'ckan/migration/versions/015_remove_state_object.py',
        'ckan/migration/versions/016_uuids_everywhere.py',
        'ckan/migration/versions/017_add_pkg_relationships.py',
        'ckan/migration/versions/018_adjust_licenses.py',
        'ckan/migration/versions/019_pkg_relationships_state.py',
        'ckan/migration/versions/020_add_changeset.py',
        'ckan/migration/versions/022_add_group_extras.py',
        'ckan/migration/versions/023_add_harvesting.py',
        'ckan/migration/versions/024_add_harvested_document.py',
        'ckan/migration/versions/025_add_authorization_groups.py',
        'ckan/migration/versions/026_authorization_group_user_pk.py',
        'ckan/migration/versions/027_adjust_harvester.py',
        'ckan/migration/versions/028_drop_harvest_source_status.py',
        'ckan/migration/versions/029_version_groups.py',
        'ckan/migration/versions/030_additional_user_attributes.py',
        'ckan/migration/versions/031_move_openid_to_new_field.py',
        'ckan/migration/versions/032_add_extra_info_field_to_resources.py',
        'ckan/migration/versions/033_auth_group_user_id_add_conditional.py',
        'ckan/migration/versions/034_resource_group_table.py',
        'ckan/migration/versions/035_harvesting_doc_versioning.py',
        'ckan/migration/versions/036_lockdown_roles.py',
        'ckan/migration/versions/037_role_anon_editor.py',
        'ckan/migration/versions/038_delete_migration_tables.py',
        'ckan/migration/versions/039_add_expired_id_and_dates.py',
        'ckan/migration/versions/040_reset_key_on_user.py',
        'ckan/migration/versions/041_resource_new_fields.py',
        'ckan/migration/versions/042_user_revision_indexes.py',
        'ckan/migration/versions/043_drop_postgres_search.py',
        'ckan/migration/versions/044_add_task_status.py',
        'ckan/migration/versions/045_user_name_unique.py',
        'ckan/migration/versions/046_drop_changesets.py',
        'ckan/migration/versions/047_rename_package_group_member.py',
        'ckan/migration/versions/048_add_activity_streams_tables.py',
        'ckan/migration/versions/049_add_group_approval_status.py',
        'ckan/migration/versions/050_term_translation_table.py',
        'ckan/migration/versions/051_add_tag_vocabulary.py',
        'ckan/migration/versions/052_update_member_capacities.py',
        'ckan/migration/versions/053_add_group_logo.py',
        'ckan/migration/versions/054_add_resource_created_date.py',
        'ckan/migration/versions/055_update_user_and_activity_detail.py',
        'ckan/migration/versions/056_add_related_table.py',
        'ckan/migration/versions/057_tracking.py',
        'ckan/migration/versions/058_add_follower_tables.py',
        'ckan/migration/versions/059_add_related_count_and_flag.py',
        'ckan/migration/versions/060_add_system_info_table.py',
        'ckan/migration/versions/061_add_follower__group_table.py',
        'ckan/migration/versions/062_add_dashboard_table.py',
        'ckan/migration/versions/063_org_changes.py',
        'ckan/migration/versions/064_add_email_last_sent_column.py',
        'ckan/migration/versions/065_add_email_notifications_preference.py',
        'ckan/migration/versions/067_turn_extras_to_strings.py',
        'ckan/misc.py',
        'ckan/model/__init__.py',
        'ckan/model/activity.py',
        'ckan/model/authz.py',
        'ckan/model/dashboard.py',
        'ckan/model/domain_object.py',
        'ckan/model/extension.py',
        'ckan/model/follower.py',
        'ckan/model/group.py',
        'ckan/model/group_extra.py',
        'ckan/model/license.py',
        'ckan/model/meta.py',
        'ckan/model/misc.py',
        'ckan/model/modification.py',
        'ckan/model/package.py',
        'ckan/model/package_extra.py',
        'ckan/model/package_relationship.py',
        'ckan/model/rating.py',
        'ckan/model/related.py',
        'ckan/model/resource.py',
        'ckan/model/system_info.py',
        'ckan/model/tag.py',
        'ckan/model/task_status.py',
        'ckan/model/term_translation.py',
        'ckan/model/test_user.py',
        'ckan/model/tracking.py',
        'ckan/model/types.py',
        'ckan/model/user.py',
        'ckan/model/vocabulary.py',
        'ckan/new_authz.py',
        'ckan/pastertemplates/__init__.py',
        'ckan/plugins/interfaces.py',
        'ckan/plugins/toolkit.py',
        'ckan/poo.py',
        'ckan/rating.py',
        'ckan/templates_legacy/home/__init__.py',
        'ckan/tests/__init__.py',
        'ckan/tests/ckantestplugin/ckantestplugin/__init__.py',
        'ckan/tests/ckantestplugin/setup.py',
        'ckan/tests/ckantestplugins.py',
        'ckan/tests/functional/api/base.py',
        'ckan/tests/functional/api/model/test_group.py',
        'ckan/tests/functional/api/model/test_licenses.py',
        'ckan/tests/functional/api/model/test_package.py',
        'ckan/tests/functional/api/model/test_ratings.py',
        'ckan/tests/functional/api/model/test_relationships.py',
        'ckan/tests/functional/api/model/test_revisions.py',
        'ckan/tests/functional/api/model/test_tag.py',
        'ckan/tests/functional/api/model/test_vocabulary.py',
        'ckan/tests/functional/api/test_activity.py',
        'ckan/tests/functional/api/test_api.py',
        'ckan/tests/functional/api/test_dashboard.py',
        'ckan/tests/functional/api/test_email_notifications.py',
        'ckan/tests/functional/api/test_follow.py',
        'ckan/tests/functional/api/test_misc.py',
        'ckan/tests/functional/api/test_package_search.py',
        'ckan/tests/functional/api/test_resource.py',
        'ckan/tests/functional/api/test_resource_search.py',
        'ckan/tests/functional/api/test_revision_search.py',
        'ckan/tests/functional/api/test_user.py',
        'ckan/tests/functional/api/test_util.py',
        'ckan/tests/functional/base.py',
        'ckan/tests/functional/test_activity.py',
        'ckan/tests/functional/test_admin.py',
        'ckan/tests/functional/test_cors.py',
        'ckan/tests/functional/test_error.py',
        'ckan/tests/functional/test_follow.py',
        'ckan/tests/functional/test_home.py',
        'ckan/tests/functional/test_package.py',
        'ckan/tests/functional/test_package_relationships.py',
        'ckan/tests/functional/test_pagination.py',
        'ckan/tests/functional/test_preview_interface.py',
        'ckan/tests/functional/test_related.py',
        'ckan/tests/functional/test_revision.py',
        'ckan/tests/functional/test_search.py',
        'ckan/tests/functional/test_storage.py',
        'ckan/tests/functional/test_tag.py',
        'ckan/tests/functional/test_tag_vocab.py',
        'ckan/tests/functional/test_upload.py',
        'ckan/tests/functional/test_user.py',
        'ckan/tests/html_check.py',
        'ckan/tests/lib/__init__.py',
        'ckan/tests/lib/test_accept.py',
        'ckan/tests/lib/test_alphabet_pagination.py',
        'ckan/tests/lib/test_cli.py',
        'ckan/tests/lib/test_dictization.py',
        'ckan/tests/lib/test_email_notifications.py',
        'ckan/tests/lib/test_field_types.py',
        'ckan/tests/lib/test_hash.py',
        'ckan/tests/lib/test_helpers.py',
        'ckan/tests/lib/test_i18n.py',
        'ckan/tests/lib/test_mailer.py',
        'ckan/tests/lib/test_munge.py',
        'ckan/tests/lib/test_navl.py',
        'ckan/tests/lib/test_resource_search.py',
        'ckan/tests/lib/test_simple_search.py',
        'ckan/tests/lib/test_solr_package_search.py',
        'ckan/tests/lib/test_solr_package_search_synchronous_update.py',
        'ckan/tests/lib/test_solr_schema_version.py',
        'ckan/tests/lib/test_solr_search_index.py',
        'ckan/tests/lib/test_tag_search.py',
        'ckan/tests/logic/test_action.py',
        'ckan/tests/logic/test_auth.py',
        'ckan/tests/logic/test_tag.py',
        'ckan/tests/logic/test_validators.py',
        'ckan/tests/misc/test_format_text.py',
        'ckan/tests/misc/test_mock_mail_server.py',
        'ckan/tests/misc/test_sync.py',
        'ckan/tests/mock_mail_server.py',
        'ckan/tests/mock_plugin.py',
        'ckan/tests/models/test_extras.py',
        'ckan/tests/models/test_group.py',
        'ckan/tests/models/test_license.py',
        'ckan/tests/models/test_misc.py',
        'ckan/tests/models/test_package.py',
        'ckan/tests/models/test_package_relationships.py',
        'ckan/tests/models/test_purge_revision.py',
        'ckan/tests/models/test_resource.py',
        'ckan/tests/models/test_revision.py',
        'ckan/tests/models/test_user.py',
        'ckan/tests/monkey.py',
        'ckan/tests/pylons_controller.py',
        'ckan/tests/schema/test_schema.py',
        'ckan/tests/test_dumper.py',
        'ckan/tests/test_plugins.py',
        'ckan/tests/test_versions.py',
        'ckan/tests/test_wsgi_ckanclient.py',
        'ckan/tests/wsgi_ckanclient.py',
        'ckan/websetup.py',
        'ckanext/datastore/bin/datastore_setup.py',
        'ckanext/datastore/logic/action.py',
        'ckanext/datastore/plugin.py',
        'ckanext/datastore/tests/test_create.py',
        'ckanext/datastore/tests/test_search.py',
        'ckanext/datastore/tests/test_upsert.py',
        'ckanext/example_idatasetform/plugin.py',
        'ckanext/example_itemplatehelpers/plugin.py',
        'ckanext/multilingual/plugin.py',
        'ckanext/reclinepreview/plugin.py',
        'ckanext/reclinepreview/tests/test_preview.py',
        'ckanext/resourceproxy/plugin.py',
        'ckanext/stats/controller.py',
        'ckanext/stats/plugin.py',
        'ckanext/stats/stats.py',
        'ckanext/stats/tests/__init__.py',
        'ckanext/stats/tests/test_stats_lib.py',
        'ckanext/stats/tests/test_stats_plugin.py',
        'ckanext/test_tag_vocab_plugin.py',
        'ckanext/tests/plugin.py',
        'doc/conf.py',
        'fabfile.py',
        'profile_tests.py',
        'setup.py',
    ]
    fails = {}
    passes = []
    done = False

    @classmethod
    def setup(cls):
        if not cls.done:
            cls.process()
        cls.done = True

    @classmethod
    def process(cls):
        blacklist = cls.PEP8_BLACKLIST_FILES
        for path, filename in process_directory(base_path):
            errors = cls.find_pep8_errors(filename=path)
            if errors and not filename in blacklist:
                cls.fails[filename] = output_errors(filename, errors)
            elif not errors and filename in blacklist:
                cls.passes.append(filename)

    def test_pep8_fails(self):
        msg = 'The following files have pep8 issues that need resolving'
        msg += '\nThey need removing from the test blacklist'
        show_fails(msg, self.fails)

    def test_pep8_pass(self):
        msg = 'The following files passed pep8 but are blacklisted'
        show_passing(msg, self.passes)

    @classmethod
    def find_pep8_errors(cls, filename=None, lines=None):
        try:
            sys.stdout = cStringIO.StringIO()
            config = {}

            # Ignore long lines on test files, as the test names can get long
            # when following our test naming standards.
            if cls._is_test(filename):
                config['ignore'] = ['E501']

            checker = pep8.Checker(filename=filename, lines=lines,
                                   **config)
            checker.check_all()
            output = sys.stdout.getvalue()
        finally:
            sys.stdout = sys.__stdout__

        errors = []
        for line in output.split('\n'):
            parts = line.split(' ', 2)
            if len(parts) == 3:
                location, error, desc = parts
                line_no = location.split(':')[1]
                errors.append('%s ln:%s %s' % (error, line_no, desc))
        return errors

    @classmethod
    def _is_test(cls, filename):
        return bool(re.search('(^|\W)test_.*\.py$', filename, re.IGNORECASE))


class TestActionAuth(object):
    ''' These tests check the logic auth/action functions are compliant. The
    main tests are that each action has a corresponding auth function and
    that each auth function has an action.  We check the function only
    accepts (context, data_dict) as parameters. '''

    ACTION_FN_SIGNATURES_BLACKLIST = [
        'create: activity_create',
    ]

    ACTION_NO_AUTH_BLACKLIST = [
        'create: follow_dataset',
        'create: follow_group',
        'create: follow_user',
        'create: package_relationship_create_rest',
        'delete: package_relationship_delete_rest',
        'delete: unfollow_dataset',
        'delete: unfollow_group',
        'delete: unfollow_user',
        'get: activity_detail_list',
        'get: am_following_dataset',
        'get: am_following_group',
        'get: am_following_user',
        'get: dashboard_activity_list_html',
        'get: dataset_followee_count',
        'get: dataset_follower_count',
        'get: followee_count',
        'get: group_activity_list',
        'get: group_activity_list_html',
        'get: group_followee_count',
        'get: group_follower_count',
        'get: group_package_show',
        'get: member_list',
        'get: organization_activity_list',
        'get: organization_activity_list_html',
        'get: organization_follower_count',
        'get: package_activity_list',
        'get: package_activity_list_html',
        'get: recently_changed_packages_activity_list',
        'get: recently_changed_packages_activity_list_html',
        'get: related_list',
        'get: resource_search',
        'get: roles_show',
        'get: status_show',
        'get: tag_search',
        'get: term_translation_show',
        'get: user_activity_list',
        'get: user_activity_list_html',
        'get: user_followee_count',
        'get: user_follower_count',
        'get: vocabulary_list',
        'get: vocabulary_show',
        'update: package_relationship_update_rest',
        'update: task_status_update_many',
        'update: term_translation_update_many',
        'update: user_role_bulk_update',
        'update: user_role_update',
    ]

    AUTH_NO_ACTION_BLACKLIST = [
        'create: file_upload',
        'delete: revision_delete',
        'delete: revision_undelete',
        'get: group_autocomplete',
        'get: group_list_available',
        'get: sysadmin',
        'get: request_reset',
        'get: user_reset',
        'update: group_change_state',
        'update: group_edit_permissions',
        'update: package_change_state',
        'update: revision_change_state',
    ]

    ACTION_NO_DOC_STR_BLACKLIST = [
        'create: group_create_rest',
        'create: package_create_rest',
        'create: package_relationship_create_rest',
        'delete: package_relationship_delete_rest',
        'get: get_site_user',
        'get: group_show_rest',
        'get: package_show_rest',
        'get: tag_show_rest',
        'update: group_update_rest',
        'update: package_relationship_update_rest',
        'update: package_update_rest',
    ]

    done = False

    @classmethod
    def setup(cls):
        if not cls.done:
            cls.process()
        cls.done = True

    @classmethod
    def process(cls):
        def get_functions(module_root):
            fns = {}
            for auth_module_name in ['get', 'create', 'update', 'delete']:
                module_path = '%s.%s' % (module_root, auth_module_name,)
                try:
                    module = __import__(module_path)
                except ImportError:
                    print ('No auth module for action "%s"' % auth_module_name)

                for part in module_path.split('.')[1:]:
                    module = getattr(module, part)

                for key, v in module.__dict__.items():
                    if not hasattr(v, '__call__'):
                        continue
                    if v.__module__ != module_path:
                        continue
                    if not key.startswith('_'):
                        name = '%s: %s' % (auth_module_name, key)
                        fns[name] = v
            return fns
        cls.actions = get_functions('logic.action')
        cls.auths = get_functions('logic.auth')

    def test_actions_have_auth_fn(self):
        actions_no_auth = set(self.actions.keys()) - set(self.auths.keys())
        actions_no_auth -= set(self.ACTION_NO_AUTH_BLACKLIST)
        assert not actions_no_auth, 'These actions have no auth function\n%s' \
            % '\n'.join(sorted(list(actions_no_auth)))

    def test_actions_have_auth_fn_blacklist(self):
        actions_no_auth = set(self.actions.keys()) & set(self.auths.keys())
        actions_no_auth &= set(self.ACTION_NO_AUTH_BLACKLIST)
        assert not actions_no_auth, 'These actions blacklisted but ' + \
            'shouldn\'t be \n%s' % '\n'.join(sorted(list(actions_no_auth)))

    def test_auths_have_action_fn(self):
        auths_no_action = set(self.auths.keys()) - set(self.actions.keys())
        auths_no_action -= set(self.AUTH_NO_ACTION_BLACKLIST)
        assert not auths_no_action, 'These auth functions have no action\n%s' \
            % '\n'.join(sorted(list(auths_no_action)))

    def test_auths_have_action_fn_blacklist(self):
        auths_no_action = set(self.auths.keys()) & set(self.actions.keys())
        auths_no_action &= set(self.AUTH_NO_ACTION_BLACKLIST)
        assert not auths_no_action, 'These auths functions blacklisted but' + \
            ' shouldn\'t be \n%s' % '\n'.join(sorted(list(auths_no_action)))

    def test_fn_signatures(self):
        errors = []
        for name, fn in self.actions.iteritems():
            args_info = inspect.getargspec(fn)
            if (args_info.args != ['context', 'data_dict']
                    or args_info.varargs is not None
                    or args_info.keywords is not None):
                if name not in self.ACTION_FN_SIGNATURES_BLACKLIST:
                    errors.append(name)
        assert not errors, 'These action functions have the wrong function' + \
            ' signature, should be (context, data_dict)\n%s' \
            % '\n'.join(sorted(errors))

    def test_fn_docstrings(self):
        errors = []
        for name, fn in self.actions.iteritems():
            if not getattr(fn, '__doc__', None):
                if name not in self.ACTION_NO_DOC_STR_BLACKLIST:
                    errors.append(name)
        assert not errors, 'These action functions need docstrings\n%s' \
            % '\n'.join(sorted(errors))


class TestBadExceptions(object):
    ''' Look for a common coding problem in ckan Exception(_'...') '''

    # Exceptions should not on the whole be translated as they are for
    # programmers to read in trace backs or log files.  However some like
    # Invalid used in validation functions do get passed back up to the user
    # and so should be translated.

    NASTY_EXCEPTION_BLACKLIST_FILES = [
        'ckan/controllers/api.py',
        'ckan/controllers/user.py',
        'ckan/lib/mailer.py',
        'ckan/logic/action/create.py',
        'ckan/logic/action/delete.py',
        'ckan/logic/action/get.py',
        'ckan/logic/action/update.py',
        'ckan/logic/auth/create.py',
        'ckan/logic/auth/delete.py',
        'ckan/logic/auth/get.py',
        'ckan/new_authz.py',
        'ckanext/datastore/logic/action.py',
    ]
    fails = {}
    passes = []
    done = False

    @classmethod
    def setup(cls):
        if not cls.done:
            cls.process()
        cls.done = True

    @classmethod
    def process(cls):
        blacklist = cls.NASTY_EXCEPTION_BLACKLIST_FILES
        re_nasty_exception = re.compile(
            r'''raise\W+(?![^I]*Invalid\().*_\('''
        )
        for path, filename in process_directory(base_path):
            f = open(path, 'r')
            count = 1
            errors = []
            for line in f:
                if re_nasty_exception.search(line):
                    errors.append('ln:%s \t%s' % (count, line[:-1]))
                count += 1
            if errors and not filename in blacklist:
                cls.fails[filename] = output_errors(filename, errors)
            elif not errors and filename in blacklist:
                cls.passes.append(filename)

    def test_good(self):
        msg = 'The following files passed nasty exceptions rules'
        msg += '\nThey need removing from the test blacklist'
        show_passing(msg, self.passes)

    def test_bad(self):
        msg = ('The following files have nasty exception issues that need'
               ' resolving\nWe should not be translating exceptions in most'
               ' situations.  We need to when the exception message is passed'
               ' to the front end for example validation')
        show_fails(msg, self.fails)

########NEW FILE########
__FILENAME__ = test_dumper
import tempfile
import os
from time import time

import ckan
from ckan.tests import *
import ckan.model as model
import ckan.lib.dumper as dumper
from ckan.common import json
from ckan.lib.dumper import Dumper
simple_dumper = dumper.SimpleDumper()

class TestSimpleDump(TestController):

    @classmethod
    def setup_class(self):
        model.repo.rebuild_db()
        CreateTestData.create()

    @classmethod
    def teardown_class(self):
        model.Session.remove()
        model.repo.rebuild_db()

    def test_simple_dump_csv(self):
        dump_file = tempfile.TemporaryFile()
        simple_dumper.dump(dump_file, 'csv')
        dump_file.seek(0)
        res = dump_file.read()
        assert 'annakarenina' in res, res
        assert 'tolstoy' in res, res
        assert 'russian' in res, res
        assert 'genre' in res, res
        assert 'romantic novel' in res, res
        assert 'annakarenina.com/download' in res, res
        assert 'Index of the novel' in res, res
        assert 'joeadmin' not in res, res
        self.assert_correct_field_order(res)
        
    def test_simple_dump_json(self):
        dump_file = tempfile.TemporaryFile()
        simple_dumper.dump(dump_file, 'json')
        dump_file.seek(0)
        res = dump_file.read()
        assert 'annakarenina' in res, res
        assert '"russian"' in res, res
        assert 'genre' in res, res
        assert 'romantic novel' in res, res
        assert 'joeadmin' not in res, res
        self.assert_correct_field_order(res)

    def assert_correct_field_order(self, res):
        correct_field_order = ('id', 'name', 'title', 'version', 'url')
        field_position = [res.find('"%s"' % field) for field in correct_field_order]
        field_position_sorted = field_position[:]
        field_position_sorted.sort()
        assert field_position == field_position_sorted, field_position

class TestDumper(object):
# TODO this doesn't work on sqlite - we should fix this
    @classmethod
    def setup_class(self):
        model.Session.remove()
        CreateTestData.create()
        d = Dumper()
        ts = int(time())
        self.outpath = '/tmp/mytestdump-%s.js' % ts
        if os.path.exists(self.outpath):
            os.remove(self.outpath)
        d.dump_json(self.outpath)

    @classmethod
    def teardown_class(self):
        model.repo.rebuild_db()

    def test_dump(self):
        assert os.path.exists(self.outpath) 
        dumpeddata = json.load(open(self.outpath))
        assert dumpeddata['version'] == ckan.__version__
        tables = dumpeddata.keys()
        for key in ['Package', 'Tag', 'Group', 'Member', 'PackageExtra']:
            assert key in tables, '%r not in %s' % (key, tables)
        for key in ['User']:
            assert key not in tables, '%s should not be in %s' % (key, tables)
        assert len(dumpeddata['Package']) == 2, len(dumpeddata['Package'])
        assert len(dumpeddata['Tag']) == 3, len(dumpeddata['Tag'])
        assert len(dumpeddata['PackageRevision']) == 2, len(dumpeddata['PackageRevision'])
        assert len(dumpeddata['Group']) == 2, len(dumpeddata['Group'])

    # Disabled 22/9/09 because not used anymore
    def _test_load(self):
        model.repo.rebuild_db()
        model.repo.create_db()
        d = Dumper()
        d.load_json(self.outpath)
        assert len(model.Package.query.all()) == 2


########NEW FILE########
__FILENAME__ = test_plugins
"""
Tests for plugin loading via PCA
"""
from nose.tools import raises
from unittest import TestCase
from pyutilib.component.core import PluginGlobals
from pylons import config

import ckan.logic as logic
import ckan.new_authz as new_authz
import ckan.plugins as plugins
from ckan.plugins.core import find_system_plugins
from ckan.lib.create_test_data import CreateTestData


def _make_calls(*args):
    out = []
    for arg in args:
        out.append(((arg,), {}))
    return out


class IFoo(plugins.Interface):
    pass

class IBar(plugins.Interface):
    pass

class FooImpl(object):
    plugins.implements(IFoo)

class BarImpl(object):
    plugins.implements(IBar)

class FooBarImpl(object):
    plugins.implements(IFoo)
    plugins.implements(IBar)

class TestInterface(TestCase):

    def test_implemented_by(self):
        assert IFoo.implemented_by(FooImpl)
        assert IFoo.implemented_by(FooBarImpl)
        assert not IFoo.implemented_by(BarImpl)

    @raises(TypeError)
    def test_implemented_by_raises_exception_on_instances(self):
        assert not IFoo.implemented_by(FooImpl())

    def test_provided_by(self):
        assert IFoo.provided_by(FooImpl())
        assert IFoo.provided_by(FooBarImpl())
        assert not IFoo.provided_by(BarImpl())

class TestIPluginObserverPlugin(object):


    @classmethod
    def setup(cls):
        cls.observer = plugins.load('test_observer_plugin')

    @classmethod
    def teardown(cls):
        plugins.unload('test_observer_plugin')

    def test_notified_on_load(self):

        observer = self.observer
        observer.reset_calls()
        with plugins.use_plugin('action_plugin') as action:
            assert observer.before_load.calls == _make_calls(action), observer.before_load.calls
            assert observer.after_load.calls == _make_calls(action), observer.after_load.calls
            assert observer.before_unload.calls == []
            assert observer.after_unload.calls == []

    def test_notified_on_unload(self):

        with plugins.use_plugin('action_plugin') as action:
            observer = self.observer
            observer.reset_calls()
        assert observer.before_load.calls == []
        assert observer.after_load.calls == []
        assert observer.before_unload.calls == _make_calls(action)
        assert observer.after_unload.calls == _make_calls(action)

class TestPlugins(object):


    def test_plugins_load(self):

        config_plugins = config['ckan.plugins']
        config['ckan.plugins'] = 'mapper_plugin routes_plugin'
        plugins.load_all(config)

        # synchronous_search automatically gets loaded
        current_plugins = set([plugins.get_plugin(p) for p in ['mapper_plugin', 'routes_plugin', 'synchronous_search'] + find_system_plugins()])
        assert PluginGlobals.env().services == current_plugins
        # cleanup
        config['ckan.plugins'] = config_plugins
        plugins.load_all(config)

    def test_only_configured_plugins_loaded(self):
        with plugins.use_plugin('mapper_plugin') as p:
            # MapperPlugin should be loaded as it is listed in
            assert p in plugins.PluginImplementations(plugins.IMapper)
            # MapperPlugin2 and RoutesPlugin should NOT be loaded
            assert len(plugins.PluginImplementations(plugins.IMapper)) == 1

    def test_plugin_loading_order(self):
        """
        Check that plugins are loaded in the order specified in the config
        """
        config_plugins = config['ckan.plugins']
        config['ckan.plugins'] = 'test_observer_plugin mapper_plugin mapper_plugin2'
        plugins.load_all(config)

        observerplugin = plugins.get_plugin('test_observer_plugin')

        expected_order = _make_calls(plugins.get_plugin('mapper_plugin'),
                                     plugins.get_plugin('mapper_plugin2'))
        assert observerplugin.before_load.calls[:-2] == expected_order
        expected_order = _make_calls(plugins.get_plugin('test_observer_plugin'),
                                     plugins.get_plugin('mapper_plugin'),
                                     plugins.get_plugin('mapper_plugin2'))
        assert observerplugin.after_load.calls[:-2] == expected_order

        config['ckan.plugins'] = 'test_observer_plugin mapper_plugin2 mapper_plugin'
        plugins.load_all(config)

        expected_order = _make_calls(plugins.get_plugin('mapper_plugin2'),
                                     plugins.get_plugin('mapper_plugin'))
        assert observerplugin.before_load.calls[:-2] == expected_order
        expected_order = _make_calls(plugins.get_plugin('test_observer_plugin'),
                                     plugins.get_plugin('mapper_plugin2'),
                                     plugins.get_plugin('mapper_plugin'))
        assert observerplugin.after_load.calls[:-2] == expected_order
        # cleanup
        config['ckan.plugins'] = config_plugins
        plugins.load_all(config)

    def test_mapper_plugin_fired(self):
        with plugins.use_plugin('mapper_plugin') as mapper_plugin:
            CreateTestData.create_arbitrary([{'name':u'testpkg'}])
            # remove this data
            CreateTestData.delete()
            assert len(mapper_plugin.added) == 2 # resource group table added automatically
            assert mapper_plugin.added[0].name == 'testpkg'

    def test_routes_plugin_fired(self):
        with plugins.use_plugin('routes_plugin'):
            routes_plugin = PluginGlobals.env_registry['pca'].plugin_registry['RoutesPlugin'].__instance__
            assert routes_plugin.calls_made == ['before_map', 'after_map'], \
                   routes_plugin.calls_made


    def test_action_plugin_override(self):
        status_show_original = logic.get_action('status_show')(None, {})
        with plugins.use_plugin('action_plugin'):
            assert logic.get_action('status_show')(None, {}) != status_show_original
        assert logic.get_action('status_show')(None, {}) == status_show_original

    def test_auth_plugin_override(self):
        package_list_original = new_authz.is_authorized('package_list', {})
        with plugins.use_plugin('auth_plugin'):
            assert new_authz.is_authorized('package_list', {}) != package_list_original
        assert new_authz.is_authorized('package_list', {}) == package_list_original

    @raises(plugins.PluginNotFoundException)
    def test_inexistent_plugin_loading(self):
        plugins.load('inexistent-plugin')

########NEW FILE########
__FILENAME__ = test_versions
import subprocess

class TestVersions(object):

    no_db = True

    def test_pylons(self):
        p = subprocess.Popen(
                'pip freeze | grep Pylons', shell=True,
                stdout=subprocess.PIPE)
        pylons_version = p.communicate()[0].strip()
        assert pylons_version == "Pylons==0.9.7"

########NEW FILE########
__FILENAME__ = test_wsgi_ckanclient
from nose.tools import assert_raises

from ckan.tests import *
import ckan.model as model

from wsgi_ckanclient import *
from ckanclient import CkanApiError

class TestWsgiCkanClient(TestController):
    def setup(self):
        self.client = WsgiCkanClient(self.app)
        model.repo.rebuild_db() # Needed for full run of tests - not sure
                                # why annafan, tester and testpackage still
                                # exist.
        CreateTestData.create()
        
    def teardown(self):
        model.repo.rebuild_db()

    def test_get_package_registry(self):
        register = self.client.package_register_get()
        assert self.client.last_status == 200
        assert len(register) == 2, register

    def test_404(self):
        assert_raises(CkanApiError, self.client.open_url, '/random')
        assert self.client.last_status == 404

########NEW FILE########
__FILENAME__ = wsgi_ckanclient
import urllib

import paste.fixture

from ckanclient import CkanClient, CkanApiError
try:
    from ckanclient import ApiRequest
except ImportError:
    # older versions of ckanclient
    from ckanclient import Request as ApiRequest

__all__ = ['WsgiCkanClient', 'ClientError']

__version__ = '0.5'

class ClientError(Exception):
    pass

class WsgiCkanClient(CkanClient):
    '''Same as CkanClient, but instead of requests going through urllib,
    they are passed directly to an application\'s Paste (webtest/wsgi)
    interface.'''
    def __init__(self, app, **kwargs):
        self.app = app
        super(WsgiCkanClient, self).__init__(**kwargs)

    def open_url(self, location, data=None, headers={}, method=None):
        if self.is_verbose:
            print "ckanclient: Opening %s" % location
        self.last_location = location

        if data != None:
            data = urllib.urlencode({data: 1})
        # Don't use request beyond getting the method
        req = ApiRequest(location, data, headers, method=method)

        # Make header values ascii strings
        for key, value in headers.items():
            headers[key] = str('%s' % value)

        method = req.get_method()
        kwargs = {'status':'*', 'headers':headers}
        try:
            if method == 'GET':
                assert not data
                res = self.app.get(location, **kwargs)
            elif method == 'POST':
                res = self.app.post(location, data, **kwargs)
            elif method == 'PUT':
                res = self.app.put(location, data, **kwargs)
            elif method == 'DELETE':
                assert not data
                res = self.app.delete(location, **kwargs)
            else:
                raise ClientError('No Paste interface for method \'%s\': %s' % \
                                  (method, location))
        except paste.fixture.AppError, inst:
            print "ckanclient: error: %s" % inst
            self.last_http_error = inst
            self.last_status = 500
            self.last_message = repr(inst.args)
        else:
            if res.status not in (200, 201):
                print "ckanclient: Received HTTP error code from CKAN resource."
                print "ckanclient: location: %s" % location
                print "ckanclient: response code: %s" % res.status
                print "ckanclient: request headers: %s" % headers
                print "ckanclient: request data: %s" % data
                print "ckanclient: error: %s" % res
                self.last_http_error = res
                self.last_status = res.status
                self.last_message = res.body
            else:
                print "ckanclient: OK opening CKAN resource: %s" % location
                self.last_status = res.status
                print 'ckanclient: last status %s' % self.last_status
                self.last_body = res.body
                print 'ckanclient: last body %s' % self.last_body
                self.last_headers = dict(res.headers)
                print 'ckanclient: last headers %s' % self.last_headers
                content_type = self.last_headers['Content-Type']
                print 'ckanclient: content type: %s' % content_type
                is_json_response = False
                if 'json' in content_type:
                    is_json_response = True
                if is_json_response:
                    self.last_message = self._loadstr(self.last_body)
                else:
                    self.last_message = self.last_body
                print 'ckanclient: last message %s' % self.last_message
        if self.last_status not in (200, 201):
            raise CkanApiError(self.last_message)

        

########NEW FILE########
__FILENAME__ = helpers
import ckan.plugins.toolkit as toolkit


def datapusher_status(resource_id):
    try:
        return toolkit.get_action('datapusher_status')(
            {}, {'resource_id': resource_id})
    except toolkit.ObjectNotFound:
        return {
            'status': 'unknown'
        }


def datapusher_status_description(status):
    _ = toolkit._

    if status.get('status'):
        captions = {
            'complete': _('Complete'),
            'pending': _('Pending'),
            'submitting': _('Submitting'),
            'error': _('Error'),
        }

        return captions.get(status['status'], status['status'].capitalize())
    else:
        return _('Not Uploaded Yet')

########NEW FILE########
__FILENAME__ = action
import logging
import json
import urlparse
import datetime

import pylons
import requests

import ckan.lib.navl.dictization_functions
import ckan.logic as logic
import ckan.plugins as p
import ckanext.datapusher.logic.schema as dpschema

log = logging.getLogger(__name__)
_get_or_bust = logic.get_or_bust
_validate = ckan.lib.navl.dictization_functions.validate


def datapusher_submit(context, data_dict):
    ''' Submit a job to the datapusher. The datapusher is a service that
    imports tabular data into the datastore.

    :param resource_id: The resource id of the resource that the data
        should be imported in. The resource's URL will be used to get the data.
    :type resource_id: string
    :param set_url_type: If set to True, the ``url_type`` of the resource will
        be set to ``datastore`` and the resource URL will automatically point
        to the :ref:`datastore dump <dump>` URL. (optional, default: False)
    :type set_url_type: bool

    Returns ``True`` if the job has been submitted and ``False`` if the job
    has not been submitted, i.e. when the datapusher is not configured.

    :rtype: bool
    '''

    schema = context.get('schema', dpschema.datapusher_submit_schema())
    data_dict, errors = _validate(data_dict, schema, context)
    if errors:
        raise p.toolkit.ValidationError(errors)

    res_id = data_dict['resource_id']

    p.toolkit.check_access('datapusher_submit', context, data_dict)

    datapusher_url = pylons.config.get('ckan.datapusher.url')

    site_url = pylons.config['ckan.site_url']
    callback_url = site_url.rstrip('/') + '/api/3/action/datapusher_hook'

    user = p.toolkit.get_action('user_show')(context, {'id': context['user']})

    task = {
        'entity_id': res_id,
        'entity_type': 'resource',
        'task_type': 'datapusher',
        'last_updated': str(datetime.datetime.now()),
        'state': 'submitting',
        'key': 'datapusher',
        'value': '{}',
        'error': '{}',
    }
    try:
        task_id = p.toolkit.get_action('task_status_show')(context, {
            'entity_id': res_id,
            'task_type': 'datapusher',
            'key': 'datapusher'
        })['id']
        task['id'] = task_id
    except logic.NotFound:
        pass

    context['ignore_auth'] = True
    result = p.toolkit.get_action('task_status_update')(context, task)
    task_id = result['id']

    try:
        r = requests.post(
            urlparse.urljoin(datapusher_url, 'job'),
            headers={
                'Content-Type': 'application/json'
            },
            data=json.dumps({
                'api_key': user['apikey'],
                'job_type': 'push_to_datastore',
                'result_url': callback_url,
                'metadata': {
                    'ckan_url': site_url,
                    'resource_id': res_id,
                    'set_url_type': data_dict.get('set_url_type', False)
                }
            }))
        r.raise_for_status()
    except requests.exceptions.ConnectionError, e:
        error = {'message': 'Could not connect to DataPusher.',
                 'details': str(e)}
        task['error'] = json.dumps(error)
        task['state'] = 'error'
        task['last_updated'] = str(datetime.datetime.now()),
        p.toolkit.get_action('task_status_update')(context, task)
        raise p.toolkit.ValidationError(error)

    except requests.exceptions.HTTPError, e:
        m = 'An Error occurred while sending the job: {0}'.format(e.message)
        try:
            body = e.response.json()
        except ValueError:
            body = e.response.text
        error = {'message': m,
                 'details': body,
                 'status_code': r.status_code}
        task['error'] = json.dumps(error)
        task['state'] = 'error'
        task['last_updated'] = str(datetime.datetime.now()),
        p.toolkit.get_action('task_status_update')(context, task)
        raise p.toolkit.ValidationError(error)

    value = json.dumps({'job_id': r.json()['job_id'],
                        'job_key': r.json()['job_key']})

    task['value'] = value
    task['state'] = 'pending'
    task['last_updated'] = str(datetime.datetime.now()),
    p.toolkit.get_action('task_status_update')(context, task)

    return True


def datapusher_hook(context, data_dict):
    ''' Update datapusher task. This action is typically called by the
    datapusher whenever the status of a job changes.

    :param metadata: metadata produced by datapuser service must have
       resource_id property.
    :type metadata: dict
    :param status: status of the job from the datapusher service
    :type status: string
    '''

    metadata, status = _get_or_bust(data_dict, ['metadata', 'status'])

    res_id = _get_or_bust(metadata, 'resource_id')

    # Pass metadata, not data_dict, as it contains the resource id needed
    # on the auth checks
    p.toolkit.check_access('datapusher_submit', context, metadata)

    task = p.toolkit.get_action('task_status_show')(context, {
        'entity_id': res_id,
        'task_type': 'datapusher',
        'key': 'datapusher'
    })

    task['state'] = status
    task['last_updated'] = str(datetime.datetime.now())

    context['ignore_auth'] = True
    p.toolkit.get_action('task_status_update')(context, task)


def datapusher_status(context, data_dict):
    ''' Get the status of a datapusher job for a certain resource.

    :param resource_id: The resource id of the resource that you want the
        datapusher status for.
    :type resource_id: string
    '''

    p.toolkit.check_access('datapusher_status', context, data_dict)

    if 'id' in data_dict:
        data_dict['resource_id'] = data_dict['id']
    res_id = _get_or_bust(data_dict, 'resource_id')

    task = p.toolkit.get_action('task_status_show')(context, {
        'entity_id': res_id,
        'task_type': 'datapusher',
        'key': 'datapusher'
    })

    datapusher_url = pylons.config.get('ckan.datapusher.url')
    if not datapusher_url:
        raise p.toolkit.ValidationError(
            {'configuration': ['ckan.datapusher.url not in config file']})

    value = json.loads(task['value'])
    job_key = value.get('job_key')
    job_id = value.get('job_id')
    url = None
    job_detail = None

    if job_id:
        url = urlparse.urljoin(datapusher_url, 'job' + '/' + job_id)
        try:
            r = requests.get(url, headers={'Content-Type': 'application/json',
                                           'Authorization': job_key})
            r.raise_for_status()
            job_detail = r.json()
        except (requests.exceptions.ConnectionError,
                requests.exceptions.HTTPError), e:
            job_detail = {'error': 'cannot connect to datapusher'}

    return {
        'status': task['state'],
        'job_id': job_id,
        'job_url': url,
        'last_updated': task['last_updated'],
        'job_key': job_key,
        'task_info': job_detail,
        'error': json.loads(task['error'])
    }

########NEW FILE########
__FILENAME__ = auth
import ckanext.datastore.logic.auth as auth


def datapusher_submit(context, data_dict):
    return auth.datastore_auth(context, data_dict)


def datapusher_status(context, data_dict):
    return auth.datastore_auth(context, data_dict)

########NEW FILE########
__FILENAME__ = schema
import ckan.plugins as p
import ckanext.datastore.logic.schema as dsschema

get_validator = p.toolkit.get_validator

not_missing = get_validator('not_missing')
not_empty = get_validator('not_empty')
resource_id_exists = get_validator('resource_id_exists')
package_id_exists = get_validator('package_id_exists')
ignore_missing = get_validator('ignore_missing')
empty = get_validator('empty')
boolean_validator = get_validator('boolean_validator')
int_validator = get_validator('int_validator')
OneOf = get_validator('OneOf')


def datapusher_submit_schema():
    schema = {
        'resource_id': [not_missing, not_empty, unicode],
        'id': [ignore_missing],
        'set_url_type': [ignore_missing, boolean_validator],
        '__junk': [empty],
        '__before': [dsschema.rename('id', 'resource_id')]
    }
    return schema

########NEW FILE########
__FILENAME__ = plugin
import logging

import ckan.plugins as p
import ckan.lib.base as base
import ckan.lib.helpers as core_helpers
import ckanext.datapusher.logic.action as action
import ckanext.datapusher.logic.auth as auth
import ckanext.datapusher.helpers as helpers
import ckan.logic as logic
import ckan.model as model
import ckan.plugins.toolkit as toolkit

log = logging.getLogger(__name__)
_get_or_bust = logic.get_or_bust

DEFAULT_FORMATS = [
    'csv', 'xls', 'xlsx', 'tsv', 'application/csv',
    'application/vnd.ms-excel',
    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
]


class DatastoreException(Exception):
    pass


class ResourceDataController(base.BaseController):

    def resource_data(self, id, resource_id):

        if toolkit.request.method == 'POST':
            try:
                toolkit.c.pkg_dict = p.toolkit.get_action('datapusher_submit')(
                    None, {'resource_id': resource_id}
                )
            except logic.ValidationError:
                pass

            base.redirect(core_helpers.url_for(
                controller='ckanext.datapusher.plugin:ResourceDataController',
                action='resource_data',
                id=id,
                resource_id=resource_id)
            )

        try:
            toolkit.c.pkg_dict = p.toolkit.get_action('package_show')(
                None, {'id': id}
            )
            toolkit.c.resource = p.toolkit.get_action('resource_show')(
                None, {'id': resource_id}
            )
        except logic.NotFound:
            base.abort(404, _('Resource not found'))
        except logic.NotAuthorized:
            base.abort(401, _('Unauthorized to edit this resource'))

        try:
            datapusher_status = p.toolkit.get_action('datapusher_status')(
                None, {'resource_id': resource_id}
            )
        except logic.NotFound:
            datapusher_status = {}

        return base.render('package/resource_data.html',
                           extra_vars={'status': datapusher_status})


class DatapusherPlugin(p.SingletonPlugin):
    p.implements(p.IConfigurable, inherit=True)
    p.implements(p.IActions)
    p.implements(p.IAuthFunctions)
    p.implements(p.IResourceUrlChange)
    p.implements(p.IDomainObjectModification, inherit=True)
    p.implements(p.ITemplateHelpers)
    p.implements(p.IRoutes, inherit=True)

    legacy_mode = False
    resource_show_action = None

    def configure(self, config):
        self.config = config

        datapusher_formats = config.get('ckan.datapusher.formats', '').lower()
        self.datapusher_formats = datapusher_formats.split() or DEFAULT_FORMATS

        for config_option in ('ckan.site_url', 'ckan.datapusher.url',):
            if not config.get(config_option):
                raise Exception(
                    'Config option `{0}` must be set to use the DataPusher.'
                    .format(config_option))

    def notify(self, entity, operation=None):
        if isinstance(entity, model.Resource):
            if (operation == model.domain_object.DomainObjectOperation.new
                    or not operation):
                # if operation is None, resource URL has been changed, as
                # the notify function in IResourceUrlChange only takes
                # 1 parameter
                context = {'model': model, 'ignore_auth': True,
                           'defer_commit': True}
                if (entity.format and
                        entity.format.lower() in self.datapusher_formats and
                        entity.url_type != 'datapusher'):
                    try:
                        p.toolkit.get_action('datapusher_submit')(context, {
                            'resource_id': entity.id
                        })
                    except p.toolkit.ValidationError, e:
                        # If datapusher is offline want to catch error instead
                        # of raising otherwise resource save will fail with 500
                        log.critical(e)
                        pass

    def before_map(self, m):
        m.connect(
            'resource_data', '/dataset/{id}/resource_data/{resource_id}',
            controller='ckanext.datapusher.plugin:ResourceDataController',
            action='resource_data', ckan_icon='cloud-upload')
        return m

    def get_actions(self):
        return {'datapusher_submit': action.datapusher_submit,
                'datapusher_hook': action.datapusher_hook,
                'datapusher_status': action.datapusher_status}

    def get_auth_functions(self):
        return {'datapusher_submit': auth.datapusher_submit,
                'datapusher_status': auth.datapusher_status}

    def get_helpers(self):
        return {
            'datapusher_status': helpers.datapusher_status,
            'datapusher_status_description':
            helpers.datapusher_status_description,
        }

########NEW FILE########
__FILENAME__ = test
import json
import httpretty
import nose
import sys
import datetime

import pylons
from pylons import config
import sqlalchemy.orm as orm
import paste.fixture

import ckan.plugins as p
import ckan.lib.create_test_data as ctd
import ckan.model as model
import ckan.tests as tests
import ckan.config.middleware as middleware

import ckanext.datastore.db as db
from ckanext.datastore.tests.helpers import rebuild_all_dbs, set_url_type


# avoid hanging tests https://github.com/gabrielfalcao/HTTPretty/issues/34
if sys.version_info < (2, 7, 0):
    import socket
    socket.setdefaulttimeout(1)


class TestDatastoreCreate(tests.WsgiAppCase):
    sysadmin_user = None
    normal_user = None

    @classmethod
    def setup_class(cls):

        wsgiapp = middleware.make_app(config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        p.load('datastore')
        p.load('datapusher')
        ctd.CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        engine = db._get_engine(
            {'connection_url': pylons.config['ckan.datastore.write_url']})
        cls.Session = orm.scoped_session(orm.sessionmaker(bind=engine))
        set_url_type(
            model.Package.get('annakarenina').resources, cls.sysadmin_user)

    @classmethod
    def teardown_class(cls):
        rebuild_all_dbs(cls.Session)
        p.unload('datastore')
        p.unload('datapusher')

    def test_create_ckan_resource_in_package(self):
        package = model.Package.get('annakarenina')
        data = {
            'resource': {'package_id': package.id}
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=200)
        res_dict = json.loads(res.body)

        assert 'resource_id' in res_dict['result']
        assert len(model.Package.get('annakarenina').resources) == 3

        res = tests.call_action_api(
            self.app, 'resource_show', id=res_dict['result']['resource_id'])
        assert res['url'] == '/datastore/dump/' + res['id'], res

    @httpretty.activate
    def test_providing_res_with_url_calls_datapusher_correctly(self):
        pylons.config['datapusher.url'] = 'http://datapusher.ckan.org'
        httpretty.HTTPretty.register_uri(
            httpretty.HTTPretty.POST,
            'http://datapusher.ckan.org/job',
            content_type='application/json',
            body=json.dumps({'job_id': 'foo', 'job_key': 'bar'}))

        package = model.Package.get('annakarenina')

        tests.call_action_api(
            self.app, 'datastore_create', apikey=self.sysadmin_user.apikey,
            resource=dict(package_id=package.id, url='demo.ckan.org'))

        assert len(package.resources) == 4, len(package.resources)
        resource = package.resources[3]
        data = json.loads(httpretty.last_request().body)
        assert data['metadata']['resource_id'] == resource.id, data
        assert data['result_url'].endswith('/action/datapusher_hook'), data
        assert data['result_url'].startswith('http://'), data

    def test_cant_provide_resource_and_resource_id(self):
        package = model.Package.get('annakarenina')
        resource = package.resources[0]
        data = {
            'resource_id': resource.id,
            'resource': {'package_id': package.id}
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['error']['__type'] == 'Validation Error'

    @httpretty.activate
    def test_send_datapusher_creates_task(self):
        httpretty.HTTPretty.register_uri(
            httpretty.HTTPretty.POST,
            'http://datapusher.ckan.org/job',
            content_type='application/json',
            body=json.dumps({'job_id': 'foo', 'job_key': 'bar'}))

        package = model.Package.get('annakarenina')
        resource = package.resources[0]

        context = {
            'ignore_auth': True,
            'user': self.sysadmin_user.name
        }

        p.toolkit.get_action('datapusher_submit')(context, {
            'resource_id': resource.id
        })

        context.pop('task_status', None)

        task = p.toolkit.get_action('task_status_show')(context, {
            'entity_id': resource.id,
            'task_type': 'datapusher',
            'key': 'datapusher'
        })

        assert task['state'] == 'pending', task

    def _call_datapusher_hook(self, user):
        package = model.Package.get('annakarenina')
        resource = package.resources[0]

        context = {
            'user': self.sysadmin_user.name
        }

        p.toolkit.get_action('task_status_update')(context, {
            'entity_id': resource.id,
            'entity_type': 'resource',
            'task_type': 'datapusher',
            'key': 'datapusher',
            'value': '{"job_id": "my_id", "job_key":"my_key"}',
            'last_updated': str(datetime.datetime.now()),
            'state': 'pending'
        })

        data = {
            'status': 'success',
            'metadata': {
                'resource_id': resource.id
            }
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(user.apikey)}
        res = self.app.post('/api/action/datapusher_hook', params=postparams,
                            extra_environ=auth, status=200)
        print res.body
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        task = tests.call_action_api(
            self.app, 'task_status_show', entity_id=resource.id,
            task_type='datapusher', key='datapusher')

        assert task['state'] == 'success', task

        task = tests.call_action_api(
            self.app, 'task_status_show', entity_id=resource.id,
            task_type='datapusher', key='datapusher')

        assert task['state'] == 'success', task

    def test_datapusher_hook_sysadmin(self):

        self._call_datapusher_hook(self.sysadmin_user)

    def test_datapusher_hook_normal_user(self):

        self._call_datapusher_hook(self.normal_user)

    def test_datapusher_hook_no_metadata(self):
        data = {
            'status': 'success',
        }
        postparams = '%s=1' % json.dumps(data)

        self.app.post('/api/action/datapusher_hook', params=postparams,
                      status=409)

    def test_datapusher_hook_no_status(self):
        data = {
            'metadata': {'resource_id': 'res_id'},
        }
        postparams = '%s=1' % json.dumps(data)

        self.app.post('/api/action/datapusher_hook', params=postparams,
                      status=409)

    def test_datapusher_hook_no_resource_id_in_metadata(self):
        data = {
            'status': 'success',
            'metadata': {}
        }
        postparams = '%s=1' % json.dumps(data)

        self.app.post('/api/action/datapusher_hook', params=postparams,
                      status=409)

########NEW FILE########
__FILENAME__ = commands
import logging

import ckan.lib.cli as cli
import bin.datastore_setup as setup

log = logging.getLogger(__name__)


class SetupDatastoreCommand(cli.CkanCommand):
    '''Perform commands to set up the datastore.
    Make sure that the datastore URLs are set properly before you run
    these commands.

    Usage::

        paster datastore set-permissions SQL_SUPER_USER

    Where:
        SQL_SUPER_USER is the name of a postgres user with sufficient
                       permissions to create new tables, users, and grant
                       and revoke new permissions.  Typically, this would
                       be the "postgres" user.

    '''
    summary = __doc__.split('\n')[0]
    usage = __doc__

    def __init__(self, name):

        super(SetupDatastoreCommand, self).__init__(name)

    def command(self):
        '''
        Parse command line arguments and call appropriate method.
        '''
        if not self.args or self.args[0] in ['--help', '-h', 'help']:
            print SetupDatastoreCommand.__doc__
            return

        cmd = self.args[0]
        self._load_config()

        self.db_write_url_parts = cli.parse_db_config(
            'ckan.datastore.write_url')
        self.db_read_url_parts = cli.parse_db_config(
            'ckan.datastore.read_url')
        self.db_ckan_url_parts = cli.parse_db_config(
            'sqlalchemy.url')

        write_db = self.db_write_url_parts['db_name']
        read_db = self.db_read_url_parts['db_name']
        assert write_db == read_db,\
            "write and read db have to be the same"

        if len(self.args) != 2:
            print self.usage
            return

        if cmd == 'set-permissions':
            setup.set_permissions(
                pguser=self.args[1],
                ckandb=self.db_ckan_url_parts['db_name'],
                datastoredb=self.db_write_url_parts['db_name'],
                ckanuser=self.db_ckan_url_parts['db_user'],
                writeuser=self.db_write_url_parts['db_user'],
                readonlyuser=self.db_read_url_parts['db_user']
            )
            if self.verbose:
                print 'Set permissions for read-only user: SUCCESS'
        else:
            print self.usage
            log.error('Command "%s" not recognized' % (cmd,))
            return

########NEW FILE########
__FILENAME__ = controller
import StringIO
import unicodecsv as csv

import pylons

import ckan.plugins as p
import ckan.lib.base as base
import ckan.model as model

from ckan.common import request


class DatastoreController(base.BaseController):
    def dump(self, resource_id):
        context = {
            'model': model,
            'session': model.Session,
            'user': p.toolkit.c.user
        }

        data_dict = {
            'resource_id': resource_id,
            'limit': request.GET.get('limit', 100000),
            'offset': request.GET.get('offset', 0)
        }

        action = p.toolkit.get_action('datastore_search')
        try:
            result = action(context, data_dict)
        except p.toolkit.ObjectNotFound:
            base.abort(404, p.toolkit._('DataStore resource not found'))

        pylons.response.headers['Content-Type'] = 'text/csv'
        pylons.response.headers['Content-disposition'] = \
            'attachment; filename="{name}.csv"'.format(name=resource_id)
        f = StringIO.StringIO()
        wr = csv.writer(f, encoding='utf-8')

        header = [x['id'] for x in result['fields']]
        wr.writerow(header)

        for record in result['records']:
            wr.writerow([record[column] for column in header])
        return f.getvalue()

########NEW FILE########
__FILENAME__ = db
import json
import datetime
import shlex
import os
import urllib
import urllib2
import urlparse
import random
import string
import logging
import pprint

import distutils.version
import sqlalchemy
from sqlalchemy.exc import (ProgrammingError, IntegrityError,
                            DBAPIError, DataError)
import psycopg2.extras
import ckan.lib.cli as cli
import ckan.plugins.toolkit as toolkit

log = logging.getLogger(__name__)

if not os.environ.get('DATASTORE_LOAD'):
    import paste.deploy.converters as converters
    ValidationError = toolkit.ValidationError
else:
    log.warn("Running datastore without CKAN")

    class ValidationError(Exception):
        def __init__(self, error_dict):
            pprint.pprint(error_dict)

_pg_types = {}
_type_names = set()
_engines = {}

_TIMEOUT = 60000  # milliseconds

# See http://www.postgresql.org/docs/9.2/static/errcodes-appendix.html
_PG_ERR_CODE = {
    'unique_violation': '23505',
    'query_canceled': '57014',
    'undefined_object': '42704',
    'syntax_error': '42601',
    'permission_denied': '42501',
    'duplicate_table': '42P07',
    'duplicate_alias': '42712',
}

_DATE_FORMATS = ['%Y-%m-%d',
                 '%Y-%m-%d %H:%M:%S',
                 '%Y-%m-%dT%H:%M:%S',
                 '%Y-%m-%dT%H:%M:%SZ',
                 '%d/%m/%Y',
                 '%m/%d/%Y',
                 '%d-%m-%Y',
                 '%m-%d-%Y']

_INSERT = 'insert'
_UPSERT = 'upsert'
_UPDATE = 'update'


def _strip(input):
    if isinstance(input, basestring) and len(input) and input[0] == input[-1]:
        return input.strip().strip('"')
    return input


def _pluck(field, arr):
    return [x[field] for x in arr]


def _get_list(input, strip=True):
    '''Transforms a string or list to a list'''
    if input is None:
        return
    if input == '':
        return []

    l = converters.aslist(input, ',', True)
    if strip:
        return [_strip(x) for x in l]
    else:
        return l


def _is_valid_field_name(name):
    '''
    Check that field name is valid:
    * can't start with underscore
    * can't contain double quote (")
    * can't be empty
    '''
    return name.strip() and not name.startswith('_') and not '"' in name


def _is_valid_table_name(name):
    if '%' in name:
        return False
    return _is_valid_field_name(name)


def _validate_int(i, field_name, non_negative=False):
    try:
        i = int(i)
    except ValueError:
        raise ValidationError({
            field_name: ['{0} is not an integer'.format(i)]
        })
    if non_negative and i < 0:
        raise ValidationError({
            field_name: ['{0} is not a non-negative integer'.format(i)]
        })


def _get_engine(data_dict):
    '''Get either read or write engine.'''
    connection_url = data_dict['connection_url']
    engine = _engines.get(connection_url)

    if not engine:
        engine = sqlalchemy.create_engine(connection_url)
        _engines[connection_url] = engine
    return engine


def _cache_types(context):
    if not _pg_types:
        connection = context['connection']
        results = connection.execute(
            'SELECT oid, typname FROM pg_type;'
        )
        for result in results:
            _pg_types[result[0]] = result[1]
            _type_names.add(result[1])
        if 'nested' not in _type_names:
            native_json = _pg_version_is_at_least(connection, '9.2')

            log.info("Create nested type. Native JSON: {0}".format(
                native_json))

            import pylons
            data_dict = {
                'connection_url': pylons.config['ckan.datastore.write_url']}
            engine = _get_engine(data_dict)
            with engine.begin() as connection:
                connection.execute(
                    'CREATE TYPE "nested" AS (json {0}, extra text)'.format(
                        'json' if native_json else 'text'))
            _pg_types.clear()

            ## redo cache types with json now available.
            return _cache_types(context)

        psycopg2.extras.register_composite('nested',
                                           connection.connection,
                                           True)


def _pg_version_is_at_least(connection, version):
    try:
        v = distutils.version.LooseVersion(version)
        pg_version = connection.execute('select version();').fetchone()
        pg_version_number = pg_version[0].split()[1]
        pv = distutils.version.LooseVersion(pg_version_number)
        return v <= pv
    except ValueError:
        return False


def _is_valid_pg_type(context, type_name):
    if type_name in _type_names:
        return True
    else:
        connection = context['connection']
        try:
            connection.execute('SELECT %s::regtype', type_name)
        except ProgrammingError, e:
            if e.orig.pgcode in [_PG_ERR_CODE['undefined_object'],
                                 _PG_ERR_CODE['syntax_error']]:
                return False
            raise
        else:
            return True


def _get_type(context, oid):
    _cache_types(context)
    return _pg_types[oid]


def _rename_json_field(data_dict):
    '''Rename json type to a corresponding type for the datastore since
    pre 9.2 postgres versions do not support native json'''
    return _rename_field(data_dict, 'json', 'nested')


def _unrename_json_field(data_dict):
    return _rename_field(data_dict, 'nested', 'json')


def _rename_field(data_dict, term, replace):
    fields = data_dict.get('fields', [])
    for i, field in enumerate(fields):
        if 'type' in field and field['type'] == term:
            data_dict['fields'][i]['type'] = replace
    return data_dict


def _guess_type(field):
    '''Simple guess type of field, only allowed are
    integer, numeric and text'''
    data_types = set([int, float])
    if isinstance(field, (dict, list)):
        return 'nested'
    if isinstance(field, int):
        return 'int'
    if isinstance(field, float):
        return 'float'
    for data_type in list(data_types):
        try:
            data_type(field)
        except (TypeError, ValueError):
            data_types.discard(data_type)
            if not data_types:
                break
    if int in data_types:
        return 'integer'
    elif float in data_types:
        return 'numeric'

    ##try iso dates
    for format in _DATE_FORMATS:
        try:
            datetime.datetime.strptime(field, format)
            return 'timestamp'
        except (ValueError, TypeError):
            continue
    return 'text'


def _get_fields(context, data_dict):
    fields = []
    all_fields = context['connection'].execute(
        u'SELECT * FROM "{0}" LIMIT 1'.format(data_dict['resource_id'])
    )
    for field in all_fields.cursor.description:
        if not field[0].startswith('_'):
            fields.append({
                'id': field[0].decode('utf-8'),
                'type': _get_type(context, field[1])
            })
    return fields


def json_get_values(obj, current_list=None):
    if current_list is None:
        current_list = []
    if isinstance(obj, basestring):
        current_list.append(obj)
    if isinstance(obj, list):
        for item in obj:
            json_get_values(item, current_list)
    if isinstance(obj, dict):
        for item in obj.values():
            json_get_values(item, current_list)
    return current_list


def check_fields(context, fields):
    '''Check if field types are valid.'''
    for field in fields:
        if field.get('type') and not _is_valid_pg_type(context, field['type']):
            raise ValidationError({
                'fields': ['"{0}" is not a valid field type'.format(
                    field['type'])]
            })
        elif not _is_valid_field_name(field['id']):
            raise ValidationError({
                'fields': ['"{0}" is not a valid field name'.format(
                    field['id'])]
            })


def convert(data, type_name):
    if data is None:
        return None
    if type_name == 'nested':
        return json.loads(data[0])
    # array type
    if type_name.startswith('_'):
        sub_type = type_name[1:]
        return [convert(item, sub_type) for item in data]
    if type_name == 'tsvector':
        return unicode(data, 'utf-8')
    if isinstance(data, datetime.datetime):
        return data.isoformat()
    if isinstance(data, (int, float)):
        return data
    return unicode(data)


def create_table(context, data_dict):
    '''Create table from combination of fields and first row of data.'''

    datastore_fields = [
        {'id': '_id', 'type': 'serial primary key'},
        {'id': '_full_text', 'type': 'tsvector'},
    ]

    # check first row of data for additional fields
    extra_fields = []
    supplied_fields = data_dict.get('fields', [])
    check_fields(context, supplied_fields)
    field_ids = _pluck('id', supplied_fields)
    records = data_dict.get('records')

    # if type is field is not given try and guess or throw an error
    for field in supplied_fields:
        if 'type' not in field:
            if not records or field['id'] not in records[0]:
                raise ValidationError({
                    'fields': ['"{0}" type not guessable'.format(field['id'])]
                })
            field['type'] = _guess_type(records[0][field['id']])

    if records:
        # check record for sanity
        if not isinstance(records[0], dict):
            raise ValidationError({
                'records': ['The first row is not a json object']
            })
        supplied_field_ids = records[0].keys()
        for field_id in supplied_field_ids:
            if not field_id in field_ids:
                extra_fields.append({
                    'id': field_id,
                    'type': _guess_type(records[0][field_id])
                })

    fields = datastore_fields + supplied_fields + extra_fields
    sql_fields = u", ".join([u'"{0}" {1}'.format(
        f['id'], f['type']) for f in fields])

    sql_string = u'CREATE TABLE "{0}" ({1});'.format(
        data_dict['resource_id'],
        sql_fields
    )

    context['connection'].execute(sql_string.replace('%', '%%'))


def _get_aliases(context, data_dict):
    '''Get a list of aliases for a resource.'''
    res_id = data_dict['resource_id']
    alias_sql = sqlalchemy.text(
        u'SELECT name FROM "_table_metadata" WHERE alias_of = :id')
    results = context['connection'].execute(alias_sql, id=res_id).fetchall()
    return [x[0] for x in results]


def _get_resources(context, alias):
    '''Get a list of resources for an alias. There could be more than one alias
    in a resource_dict.'''
    alias_sql = sqlalchemy.text(
        u'''SELECT alias_of FROM "_table_metadata"
        WHERE name = :alias AND alias_of IS NOT NULL''')
    results = context['connection'].execute(alias_sql, alias=alias).fetchall()
    return [x[0] for x in results]


def create_alias(context, data_dict):
    aliases = _get_list(data_dict.get('aliases'))
    if aliases is not None:
        # delete previous aliases
        previous_aliases = _get_aliases(context, data_dict)
        for alias in previous_aliases:
            sql_alias_drop_string = u'DROP VIEW "{0}"'.format(alias)
            context['connection'].execute(sql_alias_drop_string)

        try:
            for alias in aliases:
                sql_alias_string = u'''CREATE VIEW "{alias}"
                    AS SELECT * FROM "{main}"'''.format(
                    alias=alias,
                    main=data_dict['resource_id']
                )

                res_ids = _get_resources(context, alias)
                if res_ids:
                    raise ValidationError({
                        'alias': [(u'The alias "{0}" already exists.').format(
                            alias)]
                    })

                context['connection'].execute(sql_alias_string)
        except DBAPIError, e:
            if e.orig.pgcode in [_PG_ERR_CODE['duplicate_table'],
                                 _PG_ERR_CODE['duplicate_alias']]:
                raise ValidationError({
                    'alias': ['"{0}" already exists'.format(alias)]
                })


def create_indexes(context, data_dict):
    indexes = _get_list(data_dict.get('indexes'))
    # primary key is not a real primary key
    # it's just a unique key
    primary_key = _get_list(data_dict.get('primary_key'))

    # index and primary key could be [],
    # which means that indexes should be deleted
    if indexes is None and primary_key is None:
        return

    sql_index_tmpl = u'CREATE {unique} INDEX {name} ON "{res_id}"'
    sql_index_string_method = sql_index_tmpl + u' USING {method}({fields})'
    sql_index_string = sql_index_tmpl + u' ({fields})'
    sql_index_strings = []

    fields = _get_fields(context, data_dict)
    field_ids = _pluck('id', fields)
    json_fields = [x['id'] for x in fields if x['type'] == 'nested']

    def generate_index_name():
        # pg 9.0+ do not require an index name
        if _pg_version_is_at_least(context['connection'], '9.0'):
            return ''
        else:
            src = string.ascii_letters + string.digits
            random_string = ''.join([random.choice(src) for n in xrange(10)])
            return 'idx_' + random_string

    if indexes is not None:
        _drop_indexes(context, data_dict, False)

        # create index for faster full text search (indexes: gin or gist)
        sql_index_strings.append(sql_index_string_method.format(
            res_id=data_dict['resource_id'],
            unique='',
            name=generate_index_name(),
            method='gist', fields='_full_text'))
    else:
        indexes = []

    if primary_key is not None:
        _drop_indexes(context, data_dict, True)
        indexes.append(primary_key)

    for index in indexes:
        if not index:
            continue

        index_fields = _get_list(index)
        for field in index_fields:
            if field not in field_ids:
                raise ValidationError({
                    'index': [
                        ('The field "{0}" is not a valid column name.').format(
                            index)]
                })
        fields_string = u', '.join(
            ['(("{0}").json::text)'.format(field)
                if field in json_fields else
                '"%s"' % field
                for field in index_fields])
        sql_index_strings.append(sql_index_string.format(
            res_id=data_dict['resource_id'],
            unique='unique' if index == primary_key else '',
            name=generate_index_name(),
            fields=fields_string))

    sql_index_strings = map(lambda x: x.replace('%', '%%'), sql_index_strings)
    map(context['connection'].execute, sql_index_strings)


def _drop_indexes(context, data_dict, unique=False):
    sql_drop_index = u'DROP INDEX "{0}" CASCADE'
    sql_get_index_string = u"""
        SELECT
            i.relname AS index_name
        FROM
            pg_class t,
            pg_class i,
            pg_index idx
        WHERE
            t.oid = idx.indrelid
            AND i.oid = idx.indexrelid
            AND t.relkind = 'r'
            AND idx.indisunique = {unique}
            AND idx.indisprimary = false
            AND t.relname = %s
        """.format(unique='true' if unique else 'false')
    indexes_to_drop = context['connection'].execute(
        sql_get_index_string, data_dict['resource_id']).fetchall()
    for index in indexes_to_drop:
        context['connection'].execute(
            sql_drop_index.format(index[0]).replace('%', '%%'))


def alter_table(context, data_dict):
    '''alter table from combination of fields and first row of data
    return: all fields of the resource table'''
    supplied_fields = data_dict.get('fields', [])
    current_fields = _get_fields(context, data_dict)
    if not supplied_fields:
        supplied_fields = current_fields
    check_fields(context, supplied_fields)
    field_ids = _pluck('id', supplied_fields)
    records = data_dict.get('records')
    new_fields = []

    for num, field in enumerate(supplied_fields):
        # check to see if field definition is the same or and
        # extension of current fields
        if num < len(current_fields):
            if field['id'] != current_fields[num]['id']:
                raise ValidationError({
                    'fields': [('Supplied field "{0}" not '
                                'present or in wrong order').format(
                        field['id'])]
                })
            ## no need to check type as field already defined.
            continue

        if 'type' not in field:
            if not records or field['id'] not in records[0]:
                raise ValidationError({
                    'fields': ['"{0}" type not guessable'.format(field['id'])]
                })
            field['type'] = _guess_type(records[0][field['id']])
        new_fields.append(field)

    if records:
        # check record for sanity as they have not been
        # checked during validation
        if not isinstance(records, list):
            raise ValidationError({
                'records': ['Records has to be a list of dicts']
            })
        if not isinstance(records[0], dict):
            raise ValidationError({
                'records': ['The first row is not a json object']
            })
        supplied_field_ids = records[0].keys()
        for field_id in supplied_field_ids:
            if not field_id in field_ids:
                new_fields.append({
                    'id': field_id,
                    'type': _guess_type(records[0][field_id])
                })

    for field in new_fields:
        sql = 'ALTER TABLE "{0}" ADD "{1}" {2}'.format(
            data_dict['resource_id'],
            field['id'],
            field['type'])
        context['connection'].execute(sql.replace('%', '%%'))


def insert_data(context, data_dict):
    data_dict['method'] = _INSERT
    return upsert_data(context, data_dict)


def upsert_data(context, data_dict):
    '''insert all data from records'''
    if not data_dict.get('records'):
        return

    method = data_dict.get('method', _UPSERT)

    fields = _get_fields(context, data_dict)
    field_names = _pluck('id', fields)
    records = data_dict['records']
    sql_columns = ", ".join(['"%s"' % name.replace(
        '%', '%%') for name in field_names] + ['"_full_text"'])

    if method == _INSERT:
        rows = []
        for num, record in enumerate(records):
            _validate_record(record, num, field_names)

            row = []
            for field in fields:
                value = record.get(field['id'])
                if value and field['type'].lower() == 'nested':
                    ## a tuple with an empty second value
                    value = (json.dumps(value), '')
                row.append(value)
            row.append(_to_full_text(fields, record))
            rows.append(row)

        sql_string = u'''INSERT INTO "{res_id}" ({columns})
            VALUES ({values}, to_tsvector(%s));'''.format(
            res_id=data_dict['resource_id'],
            columns=sql_columns,
            values=', '.join(['%s' for field in field_names])
        )

        context['connection'].execute(sql_string, rows)

    elif method in [_UPDATE, _UPSERT]:
        unique_keys = _get_unique_key(context, data_dict)
        if len(unique_keys) < 1:
            raise ValidationError({
                'table': [u'table does not have a unique key defined']
            })

        for num, record in enumerate(records):
            # all key columns have to be defined
            missing_fields = [field for field in unique_keys
                              if field not in record]
            if missing_fields:
                raise ValidationError({
                    'key': [u'''fields "{fields}" are missing
                        but needed as key'''.format(
                            fields=', '.join(missing_fields))]
                })

            for field in fields:
                value = record.get(field['id'])
                if value and field['type'].lower() == 'nested':
                    ## a tuple with an empty second value
                    record[field['id']] = (json.dumps(value), '')

            non_existing_filed_names = [field for field in record
                                        if field not in field_names]
            if non_existing_filed_names:
                raise ValidationError({
                    'fields': [u'fields "{0}" do not exist'.format(
                        ', '.join(missing_fields))]
                })

            unique_values = [record[key] for key in unique_keys]

            used_fields = [field for field in fields
                           if field['id'] in record]

            used_field_names = _pluck('id', used_fields)

            used_values = [record[field] for field in used_field_names]

            full_text = _to_full_text(fields, record)

            if method == _UPDATE:
                sql_string = u'''
                    UPDATE "{res_id}"
                    SET ({columns}, "_full_text") = ({values}, to_tsvector(%s))
                    WHERE ({primary_key}) = ({primary_value});
                '''.format(
                    res_id=data_dict['resource_id'],
                    columns=u', '.join(
                        [u'"{0}"'.format(field)
                         for field in used_field_names]),
                    values=u', '.join(
                        ['%s' for _ in used_field_names]),
                    primary_key=u','.join(
                        [u'"{0}"'.format(part) for part in unique_keys]),
                    primary_value=u','.join(["%s"] * len(unique_keys))
                )
                results = context['connection'].execute(
                    sql_string, used_values + [full_text] + unique_values)

                # validate that exactly one row has been updated
                if results.rowcount != 1:
                    raise ValidationError({
                        'key': [u'key "{0}" not found'.format(unique_values)]
                    })

            elif method == _UPSERT:
                sql_string = u'''
                    UPDATE "{res_id}"
                    SET ({columns}, "_full_text") = ({values}, to_tsvector(%s))
                    WHERE ({primary_key}) = ({primary_value});
                    INSERT INTO "{res_id}" ({columns}, "_full_text")
                           SELECT {values}, to_tsvector(%s)
                           WHERE NOT EXISTS (SELECT 1 FROM "{res_id}"
                                    WHERE ({primary_key}) = ({primary_value}));
                '''.format(
                    res_id=data_dict['resource_id'],
                    columns=u', '.join([u'"{0}"'.format(field)
                                        for field in used_field_names]),
                    values=u', '.join(['%s::nested'
                                       if field['type'] == 'nested' else '%s'
                                       for field in used_fields]),
                    primary_key=u','.join([u'"{0}"'.format(part)
                                           for part in unique_keys]),
                    primary_value=u','.join(["%s"] * len(unique_keys))
                )
                context['connection'].execute(
                    sql_string,
                    (used_values + [full_text] + unique_values) * 2)


def _get_unique_key(context, data_dict):
    sql_get_unique_key = '''
    SELECT
        a.attname AS column_names
    FROM
        pg_class t,
        pg_index idx,
        pg_attribute a
    WHERE
        t.oid = idx.indrelid
        AND a.attrelid = t.oid
        AND a.attnum = ANY(idx.indkey)
        AND t.relkind = 'r'
        AND idx.indisunique = true
        AND idx.indisprimary = false
        AND t.relname = %s
    '''
    key_parts = context['connection'].execute(sql_get_unique_key,
                                              data_dict['resource_id'])
    return [x[0] for x in key_parts]


def _validate_record(record, num, field_names):
    # check record for sanity
    if not isinstance(record, dict):
        raise ValidationError({
            'records': [u'row "{0}" is not a json object'.format(num)]
        })
    ## check for extra fields in data
    extra_keys = set(record.keys()) - set(field_names)

    if extra_keys:
        raise ValidationError({
            'records': [u'row "{0}" has extra keys "{1}"'.format(
                num + 1,
                ', '.join(list(extra_keys))
            )]
        })


def _to_full_text(fields, record):
    full_text = []
    for field in fields:
        value = record.get(field['id'])
        if field['type'].lower() == 'nested' and value:
            full_text.extend(json_get_values(value))
        elif field['type'].lower() == 'text' and value:
            full_text.append(value)
    return ' '.join(full_text)


def _where(field_ids, data_dict):
    '''Return a SQL WHERE clause from data_dict filters and q'''
    filters = data_dict.get('filters', {})

    if not isinstance(filters, dict):
        raise ValidationError({
            'filters': ['Not a json object']}
        )

    where_clauses = []
    values = []

    for field, value in filters.iteritems():
        if field not in field_ids:
            raise ValidationError({
                'filters': ['field "{0}" not in table'.format(field)]}
            )
        where_clauses.append(u'"{0}" = %s'.format(field))
        values.append(value)

    # add full-text search where clause
    if data_dict.get('q'):
        where_clauses.append(u'_full_text @@ query')

    where_clause = u' AND '.join(where_clauses)
    if where_clause:
        where_clause = u'WHERE ' + where_clause
    return where_clause, values


def _textsearch_query(data_dict):
    q = data_dict.get('q')
    lang = data_dict.get(u'language', u'english')
    if q:
        if data_dict.get('plain', True):
            statement = u", plainto_tsquery('{lang}', '{query}') query"
        else:
            statement = u", to_tsquery('{lang}', '{query}') query"

        rank_column = u', ts_rank(_full_text, query, 32) AS rank'
        return statement.format(lang=lang, query=q), rank_column
    return '', ''


def _sort(context, data_dict, field_ids):
    sort = data_dict.get('sort')
    if not sort:
        if data_dict.get('q'):
            return u'ORDER BY rank'
        else:
            return u''

    clauses = _get_list(sort, False)

    clause_parsed = []

    for clause in clauses:
        clause = clause.encode('utf-8')
        clause_parts = shlex.split(clause)
        if len(clause_parts) == 1:
            field, sort = clause_parts[0], 'asc'
        elif len(clause_parts) == 2:
            field, sort = clause_parts
        else:
            raise ValidationError({
                'sort': ['not valid syntax for sort clause']
            })
        field, sort = unicode(field, 'utf-8'), unicode(sort, 'utf-8')

        if field not in field_ids:
            raise ValidationError({
                'sort': [u'field "{0}" not in table'.format(
                    field)]
            })
        if sort.lower() not in ('asc', 'desc'):
            raise ValidationError({
                'sort': ['sorting can only be asc or desc']
            })
        clause_parsed.append(u'"{0}" {1}'.format(
            field, sort)
        )

    if clause_parsed:
        return "order by " + ", ".join(clause_parsed)


def _insert_links(data_dict, limit, offset):
    '''Adds link to the next/prev part (same limit, offset=offset+limit)
    and the resource page.'''
    data_dict['_links'] = {}

    # get the url from the request
    try:
        urlstring = toolkit.request.environ['CKAN_CURRENT_URL']
    except TypeError:
        return  # no links required for local actions

    # change the offset in the url
    parsed = list(urlparse.urlparse(urlstring))
    query = urllib2.unquote(parsed[4])

    arguments = dict(urlparse.parse_qsl(query))
    arguments_start = dict(arguments)
    arguments_prev = dict(arguments)
    arguments_next = dict(arguments)
    if 'offset' in arguments_start:
        arguments_start.pop('offset')
    arguments_next['offset'] = int(offset) + int(limit)
    arguments_prev['offset'] = int(offset) - int(limit)

    parsed_start = parsed[:]
    parsed_prev = parsed[:]
    parsed_next = parsed[:]
    parsed_start[4] = urllib.urlencode(arguments_start)
    parsed_next[4] = urllib.urlencode(arguments_next)
    parsed_prev[4] = urllib.urlencode(arguments_prev)

    # add the links to the data dict
    data_dict['_links']['start'] = urlparse.urlunparse(parsed_start)
    data_dict['_links']['next'] = urlparse.urlunparse(parsed_next)
    if int(offset) - int(limit) > 0:
        data_dict['_links']['prev'] = urlparse.urlunparse(parsed_prev)


def delete_data(context, data_dict):
    fields = _get_fields(context, data_dict)
    field_ids = set([field['id'] for field in fields])
    where_clause, where_values = _where(field_ids, data_dict)

    context['connection'].execute(
        u'DELETE FROM "{0}" {1}'.format(
            data_dict['resource_id'],
            where_clause
        ),
        where_values
    )


def search_data(context, data_dict):
    all_fields = _get_fields(context, data_dict)
    all_field_ids = _pluck('id', all_fields)
    all_field_ids.insert(0, '_id')

    fields = data_dict.get('fields')

    if fields:
        field_ids = _get_list(fields)

        for field in field_ids:
            if not field in all_field_ids:
                raise ValidationError({
                    'fields': [u'field "{0}" not in table'.format(field)]}
                )
    else:
        field_ids = all_field_ids

    select_columns = ', '.join([u'"{0}"'.format(field_id)
                                for field_id in field_ids])
    ts_query, rank_column = _textsearch_query(data_dict)
    where_clause, where_values = _where(all_field_ids, data_dict)
    limit = data_dict.get('limit', 100)
    offset = data_dict.get('offset', 0)

    _validate_int(limit, 'limit', non_negative=True)
    _validate_int(offset, 'offset', non_negative=True)

    if 'limit' in data_dict:
        data_dict['limit'] = int(limit)
    if 'offset' in data_dict:
        data_dict['offset'] = int(offset)

    sort = _sort(context, data_dict, field_ids)

    sql_string = u'''SELECT {select}, count(*) over() AS "_full_count" {rank}
                    FROM "{resource}" {ts_query}
                    {where} {sort} LIMIT {limit} OFFSET {offset}'''.format(
        select=select_columns,
        rank=rank_column,
        resource=data_dict['resource_id'],
        ts_query=ts_query,
        where='{where}',
        sort=sort,
        limit=limit,
        offset=offset)
    sql_string = sql_string.replace('%', '%%')
    results = context['connection'].execute(
        sql_string.format(where=where_clause), [where_values])

    _insert_links(data_dict, limit, offset)
    return format_results(context, results, data_dict)


def format_results(context, results, data_dict):
    result_fields = []
    for field in results.cursor.description:
        result_fields.append({
            'id': field[0].decode('utf-8'),
            'type': _get_type(context, field[1])
        })
    if len(result_fields) and result_fields[-1]['id'] == '_full_count':
        result_fields.pop()  # remove _full_count

    records = []
    for row in results:
        converted_row = {}
        if '_full_count' in row:
            data_dict['total'] = row['_full_count']
        for field in result_fields:
            converted_row[field['id']] = convert(row[field['id']],
                                                 field['type'])
        records.append(converted_row)
    data_dict['records'] = records
    data_dict['fields'] = result_fields

    return _unrename_json_field(data_dict)


def _is_single_statement(sql):
    return not ';' in sql.strip(';')


def create(context, data_dict):
    '''
    The first row will be used to guess types not in the fields and the
    guessed types will be added to the headers permanently.
    Consecutive rows have to conform to the field definitions.

    rows can be empty so that you can just set the fields.

    fields are optional but needed if you want to do type hinting or
    add extra information for certain columns or to explicitly
    define ordering.

    eg: [{"id": "dob", "type": "timestamp"},
         {"id": "name", "type": "text"}]

    A header items values can not be changed after it has been defined
    nor can the ordering of them be changed. They can be extended though.

    Any error results in total failure! For now pass back the actual error.
    Should be transactional.
    '''
    engine = _get_engine(data_dict)
    context['connection'] = engine.connect()
    timeout = context.get('query_timeout', _TIMEOUT)
    _cache_types(context)

    _rename_json_field(data_dict)

    trans = context['connection'].begin()
    try:
        # check if table already existes
        context['connection'].execute(
            u'SET LOCAL statement_timeout TO {0}'.format(timeout))
        result = context['connection'].execute(
            u'SELECT * FROM pg_tables WHERE tablename = %s',
            data_dict['resource_id']
        ).fetchone()
        if not result:
            create_table(context, data_dict)
        else:
            alter_table(context, data_dict)
        insert_data(context, data_dict)
        create_indexes(context, data_dict)
        create_alias(context, data_dict)
        if data_dict.get('private'):
            _change_privilege(context, data_dict, 'REVOKE')
        trans.commit()
        return _unrename_json_field(data_dict)
    except IntegrityError, e:
        if e.orig.pgcode == _PG_ERR_CODE['unique_violation']:
            raise ValidationError({
                'constraints': ['Cannot insert records or create index because'
                                ' of uniqueness constraint'],
                'info': {
                    'orig': str(e.orig),
                    'pgcode': e.orig.pgcode
                }
            })
        raise
    except DataError, e:
        raise ValidationError({
            'data': e.message,
            'info': {
                'orig': [str(e.orig)]
            }})
    except DBAPIError, e:
        if e.orig.pgcode == _PG_ERR_CODE['query_canceled']:
            raise ValidationError({
                'query': ['Query took too long']
            })
        raise
    except Exception, e:
        trans.rollback()
        raise
    finally:
        context['connection'].close()


def upsert(context, data_dict):
    '''
    This method combines upsert insert and update on the datastore. The method
    that will be used is defined in the mehtod variable.

    Any error results in total failure! For now pass back the actual error.
    Should be transactional.
    '''
    engine = _get_engine(data_dict)
    context['connection'] = engine.connect()
    timeout = context.get('query_timeout', _TIMEOUT)

    trans = context['connection'].begin()
    try:
        # check if table already existes
        context['connection'].execute(
            u'SET LOCAL statement_timeout TO {0}'.format(timeout))
        upsert_data(context, data_dict)
        trans.commit()
        return _unrename_json_field(data_dict)
    except IntegrityError, e:
        if e.orig.pgcode == _PG_ERR_CODE['unique_violation']:
            raise ValidationError({
                'constraints': ['Cannot insert records or create index because'
                                ' of uniqueness constraint'],
                'info': {
                    'orig': str(e.orig),
                    'pgcode': e.orig.pgcode
                }
            })
        raise
    except DataError, e:
        raise ValidationError({
            'data': e.message,
            'info': {
                'orig': [str(e.orig)]
            }})
    except DBAPIError, e:
        if e.orig.pgcode == _PG_ERR_CODE['query_canceled']:
            raise ValidationError({
                'query': ['Query took too long']
            })
        raise
    except Exception, e:
        trans.rollback()
        raise
    finally:
        context['connection'].close()


def delete(context, data_dict):
    engine = _get_engine(data_dict)
    context['connection'] = engine.connect()
    _cache_types(context)

    trans = context['connection'].begin()
    try:
        # check if table exists
        if not 'filters' in data_dict:
            context['connection'].execute(
                u'DROP TABLE "{0}" CASCADE'.format(data_dict['resource_id'])
            )
        else:
            delete_data(context, data_dict)

        trans.commit()
        return _unrename_json_field(data_dict)
    except Exception:
        trans.rollback()
        raise
    finally:
        context['connection'].close()


def search(context, data_dict):
    engine = _get_engine(data_dict)
    context['connection'] = engine.connect()
    timeout = context.get('query_timeout', _TIMEOUT)
    _cache_types(context)

    try:
        context['connection'].execute(
            u'SET LOCAL statement_timeout TO {0}'.format(timeout))
        return search_data(context, data_dict)
    except DBAPIError, e:
        if e.orig.pgcode == _PG_ERR_CODE['query_canceled']:
            raise ValidationError({
                'query': ['Search took too long']
            })
        raise ValidationError({
            'query': ['Invalid query'],
            'info': {
                'statement': [e.statement],
                'params': [e.params],
                'orig': [str(e.orig)]
            }
        })
    finally:
        context['connection'].close()


def search_sql(context, data_dict):
    engine = _get_engine(data_dict)
    context['connection'] = engine.connect()
    timeout = context.get('query_timeout', _TIMEOUT)
    _cache_types(context)

    try:
        context['connection'].execute(
            u'SET LOCAL statement_timeout TO {0}'.format(timeout))
        results = context['connection'].execute(
            data_dict['sql'].replace('%', '%%')
        )
        return format_results(context, results, data_dict)

    except ProgrammingError, e:
        if e.orig.pgcode == _PG_ERR_CODE['permission_denied']:
            raise toolkit.NotAuthorized({
                'permissions': ['Not authorized to read resource.']
            })
        raise ValidationError({
            'query': [str(e)],
            'info': {
                'statement': [e.statement],
                'params': [e.params],
                'orig': [str(e.orig)]
            }
        })
    except DBAPIError, e:
        if e.orig.pgcode == _PG_ERR_CODE['query_canceled']:
            raise ValidationError({
                'query': ['Query took too long']
            })
        raise
    finally:
        context['connection'].close()


def _get_read_only_user(data_dict):
    parsed = cli.parse_db_config('ckan.datastore.read_url')
    return parsed['db_user']


def _change_privilege(context, data_dict, what):
    ''' We need a transaction for this code to work '''
    read_only_user = _get_read_only_user(data_dict)
    if what == 'REVOKE':
        sql = u'REVOKE SELECT ON TABLE "{0}" FROM "{1}"'.format(
            data_dict['resource_id'],
            read_only_user)
    elif what == 'GRANT':
        sql = u'GRANT SELECT ON TABLE "{0}" TO "{1}"'.format(
            data_dict['resource_id'],
            read_only_user)
    else:
        raise ValidationError({
            'privileges': 'Can only GRANT or REVOKE but not {0}'.format(what)})
    try:
        context['connection'].execute(sql)
    except ProgrammingError, e:
        log.critical("Error making resource private. {0}".format(e.message))
        raise ValidationError({
            'privileges': [u'cannot make "{0}" private'.format(
                           data_dict['resource_id'])],
            'info': {
                'orig': str(e.orig),
                'pgcode': e.orig.pgcode
            }
        })


def make_private(context, data_dict):
    log.info('Making resource {0} private'.format(
        data_dict['resource_id']))
    engine = _get_engine(data_dict)
    context['connection'] = engine.connect()
    trans = context['connection'].begin()
    try:
        _change_privilege(context, data_dict, 'REVOKE')
        trans.commit()
    finally:
        context['connection'].close()


def make_public(context, data_dict):
    log.info('Making resource {0} public'.format(
        data_dict['resource_id']))
    engine = _get_engine(data_dict)
    context['connection'] = engine.connect()
    trans = context['connection'].begin()
    try:
        _change_privilege(context, data_dict, 'GRANT')
        trans.commit()
    finally:
        context['connection'].close()

########NEW FILE########
__FILENAME__ = action
import logging

import pylons
import sqlalchemy

import ckan.lib.navl.dictization_functions
import ckan.logic as logic
import ckan.plugins as p
import ckanext.datastore.db as db
import ckanext.datastore.logic.schema as dsschema

log = logging.getLogger(__name__)
_get_or_bust = logic.get_or_bust
_validate = ckan.lib.navl.dictization_functions.validate

WHITELISTED_RESOURCES = ['_table_metadata']


def datastore_create(context, data_dict):
    '''Adds a new table to the DataStore.

    The datastore_create action allows you to post JSON data to be
    stored against a resource. This endpoint also supports altering tables,
    aliases and indexes and bulk insertion. This endpoint can be called multiple
    times to initially insert more data, add fields, change the aliases or indexes
    as well as the primary keys.

    To create an empty datastore resource and a CKAN resource at the same time,
    provide ``resource`` with a valid ``package_id`` and omit the ``resource_id``.

    If you want to create a datastore resource from the content of a file,
    provide ``resource`` with a valid ``url``.

    See :ref:`fields` and :ref:`records` for details on how to lay out records.

    :param resource_id: resource id that the data is going to be stored against.
    :type resource_id: string
    :param force: set to True to edit a read-only resource
    :type force: bool (optional, default: False)
    :param resource: resource dictionary that is passed to
        :meth:`~ckan.logic.action.create.resource_create`.
        Use instead of ``resource_id`` (optional)
    :type resource: dictionary
    :param aliases: names for read only aliases of the resource. (optional)
    :type aliases: list or comma separated string
    :param fields: fields/columns and their extra metadata. (optional)
    :type fields: list of dictionaries
    :param records: the data, eg: [{"dob": "2005", "some_stuff": ["a", "b"]}]  (optional)
    :type records: list of dictionaries
    :param primary_key: fields that represent a unique key (optional)
    :type primary_key: list or comma separated string
    :param indexes: indexes on table (optional)
    :type indexes: list or comma separated string

    Please note that setting the ``aliases``, ``indexes`` or ``primary_key`` replaces the exising
    aliases or constraints. Setting ``records`` appends the provided records to the resource.

    **Results:**

    :returns: The newly created data object.
    :rtype: dictionary

    See :ref:`fields` and :ref:`records` for details on how to lay out records.

    '''
    schema = context.get('schema', dsschema.datastore_create_schema())
    records = data_dict.pop('records', None)
    resource = data_dict.pop('resource', None)
    data_dict, errors = _validate(data_dict, schema, context)
    if records:
        data_dict['records'] = records
    if resource:
        data_dict['resource'] = resource
    if errors:
        raise p.toolkit.ValidationError(errors)

    p.toolkit.check_access('datastore_create', context, data_dict)

    if 'resource' in data_dict and 'resource_id' in data_dict:
        raise p.toolkit.ValidationError({
            'resource': ['resource cannot be used with resource_id']
        })

    if not 'resource' in data_dict and not 'resource_id' in data_dict:
        raise p.toolkit.ValidationError({
            'resource_id': ['resource_id or resource required']
        })

    if 'resource' in data_dict:
        has_url = 'url' in data_dict['resource']
        # A datastore only resource does not have a url in the db
        data_dict['resource'].setdefault('url', '_datastore_only_resource')
        res = p.toolkit.get_action('resource_create')(context,
                                                      data_dict['resource'])
        data_dict['resource_id'] = res['id']

        # create resource from file
        if has_url:
            if not p.plugin_loaded('datapusher'):
                raise p.toolkit.ValidationError({'resource': [
                    'The datapusher has to be enabled.']})
            p.toolkit.get_action('datapusher_submit')(context, {
                'resource_id': res['id'],
                'set_url_type': True
            })
            # since we'll overwrite the datastore resource anyway, we
            # don't need to create it here
            return

        # create empty resource
        else:
            # no need to set the full url because it will be set in before_show
            res['url_type'] = 'datastore'
            p.toolkit.get_action('resource_update')(context, res)
    else:
        _check_read_only(context, data_dict)

    data_dict['connection_url'] = pylons.config['ckan.datastore.write_url']

    # validate aliases
    aliases = db._get_list(data_dict.get('aliases', []))
    for alias in aliases:
        if not db._is_valid_table_name(alias):
            raise p.toolkit.ValidationError({
                'alias': [u'"{0}" is not a valid alias name'.format(alias)]
            })

    # create a private datastore resource, if necessary
    model = _get_or_bust(context, 'model')
    resource = model.Resource.get(data_dict['resource_id'])
    legacy_mode = 'ckan.datastore.read_url' not in pylons.config
    if not legacy_mode and resource.resource_group.package.private:
        data_dict['private'] = True

    result = db.create(context, data_dict)
    result.pop('id', None)
    result.pop('private', None)
    result.pop('connection_url')
    return result


def datastore_upsert(context, data_dict):
    '''Updates or inserts into a table in the DataStore

    The datastore_upsert API action allows you to add or edit records to
    an existing DataStore resource. In order for the *upsert* and *update*
    methods to work, a unique key has to be defined via the datastore_create
    action. The available methods are:

    *upsert*
        Update if record with same key already exists, otherwise insert.
        Requires unique key.
    *insert*
        Insert only. This method is faster that upsert, but will fail if any
        inserted record matches an existing one. Does *not* require a unique
        key.
    *update*
        Update only. An exception will occur if the key that should be updated
        does not exist. Requires unique key.


    :param resource_id: resource id that the data is going to be stored under.
    :type resource_id: string
    :param force: set to True to edit a read-only resource
    :type force: bool (optional, default: False)
    :param records: the data, eg: [{"dob": "2005", "some_stuff": ["a","b"]}] (optional)
    :type records: list of dictionaries
    :param method: the method to use to put the data into the datastore.
                   Possible options are: upsert, insert, update (optional, default: upsert)
    :type method: string

    **Results:**

    :returns: The modified data object.
    :rtype: dictionary

    '''
    schema = context.get('schema', dsschema.datastore_upsert_schema())
    records = data_dict.pop('records', None)
    data_dict, errors = _validate(data_dict, schema, context)
    if records:
        data_dict['records'] = records
    if errors:
        raise p.toolkit.ValidationError(errors)

    p.toolkit.check_access('datastore_upsert', context, data_dict)

    _check_read_only(context, data_dict)

    data_dict['connection_url'] = pylons.config['ckan.datastore.write_url']

    res_id = data_dict['resource_id']
    resources_sql = sqlalchemy.text(u'''SELECT 1 FROM "_table_metadata"
                                        WHERE name = :id AND alias_of IS NULL''')
    results = db._get_engine(data_dict).execute(resources_sql, id=res_id)
    res_exists = results.rowcount > 0

    if not res_exists:
        raise p.toolkit.ObjectNotFound(p.toolkit._(
            u'Resource "{0}" was not found.'.format(res_id)
        ))

    result = db.upsert(context, data_dict)
    result.pop('id', None)
    result.pop('connection_url')
    return result


def datastore_delete(context, data_dict):
    '''Deletes a table or a set of records from the DataStore.

    :param resource_id: resource id that the data will be deleted from. (optional)
    :type resource_id: string
    :param force: set to True to edit a read-only resource
    :type force: bool (optional, default: False)
    :param filters: filters to apply before deleting (eg {"name": "fred"}).
                   If missing delete whole table and all dependent views. (optional)
    :type filters: dictionary

    **Results:**

    :returns: Original filters sent.
    :rtype: dictionary

    '''
    schema = context.get('schema', dsschema.datastore_upsert_schema())
    filters = data_dict.pop('filters', None)
    data_dict, errors = _validate(data_dict, schema, context)
    if filters:
        data_dict['filters'] = filters
    if errors:
        raise p.toolkit.ValidationError(errors)

    p.toolkit.check_access('datastore_delete', context, data_dict)

    _check_read_only(context, data_dict)

    data_dict['connection_url'] = pylons.config['ckan.datastore.write_url']

    res_id = data_dict['resource_id']
    resources_sql = sqlalchemy.text(u'''SELECT 1 FROM "_table_metadata"
                                        WHERE name = :id AND alias_of IS NULL''')
    results = db._get_engine(data_dict).execute(resources_sql, id=res_id)
    res_exists = results.rowcount > 0

    if not res_exists:
        raise p.toolkit.ObjectNotFound(p.toolkit._(
            u'Resource "{0}" was not found.'.format(res_id)
        ))

    result = db.delete(context, data_dict)
    result.pop('id', None)
    result.pop('connection_url')
    return result


@logic.side_effect_free
def datastore_search(context, data_dict):
    '''Search a DataStore resource.

    The datastore_search action allows you to search data in a resource.
    DataStore resources that belong to private CKAN resource can only be
    read by you if you have access to the CKAN resource and send the appropriate
    authorization.

    :param resource_id: id or alias of the resource to be searched against
    :type resource_id: string
    :param filters: matching conditions to select, e.g {"key1": "a", "key2": "b"} (optional)
    :type filters: dictionary
    :param q: full text query (optional)
    :type q: string
    :param plain: treat as plain text query (optional, default: true)
    :type plain: bool
    :param language: language of the full text query (optional, default: english)
    :type language: string
    :param limit: maximum number of rows to return (optional, default: 100)
    :type limit: int
    :param offset: offset this number of rows (optional)
    :type offset: int
    :param fields: fields to return (optional, default: all fields in original order)
    :type fields: list or comma separated string
    :param sort: comma separated field names with ordering
                 e.g.: "fieldname1, fieldname2 desc"
    :type sort: string

    Setting the ``plain`` flag to false enables the entire PostgreSQL `full text search query language`_.

    A listing of all available resources can be found at the alias ``_table_metadata``.

    .. _full text search query language: http://www.postgresql.org/docs/9.1/static/datatype-textsearch.html#DATATYPE-TSQUERY

    If you need to download the full resource, read :ref:`dump`.

    **Results:**

    The result of this action is a dictionary with the following keys:

    :rtype: A dictionary with the following keys
    :param fields: fields/columns and their extra metadata
    :type fields: list of dictionaries
    :param offset: query offset value
    :type offset: int
    :param limit: query limit value
    :type limit: int
    :param filters: query filters
    :type filters: list of dictionaries
    :param total: number of total matching records
    :type total: int
    :param records: list of matching results
    :type records: list of dictionaries

    '''
    schema = context.get('schema', dsschema.datastore_search_schema())
    data_dict, errors = _validate(data_dict, schema, context)
    if errors:
        raise p.toolkit.ValidationError(errors)

    res_id = data_dict['resource_id']
    data_dict['connection_url'] = pylons.config['ckan.datastore.write_url']

    resources_sql = sqlalchemy.text(u'''SELECT alias_of FROM "_table_metadata"
                                        WHERE name = :id''')
    results = db._get_engine(data_dict).execute(resources_sql, id=res_id)

    # Resource only has to exist in the datastore (because it could be an alias)
    if not results.rowcount > 0:
        raise p.toolkit.ObjectNotFound(p.toolkit._(
            'Resource "{0}" was not found.'.format(res_id)
        ))

    if not data_dict['resource_id'] in WHITELISTED_RESOURCES:
        # Replace potential alias with real id to simplify access checks
        resource_id = results.fetchone()[0]
        if resource_id:
            data_dict['resource_id'] = resource_id

        p.toolkit.check_access('datastore_search', context, data_dict)

    result = db.search(context, data_dict)
    result.pop('id', None)
    result.pop('connection_url')
    return result


@logic.side_effect_free
def datastore_search_sql(context, data_dict):
    '''Execute SQL queries on the DataStore.

    The datastore_search_sql action allows a user to search data in a resource
    or connect multiple resources with join expressions. The underlying SQL
    engine is the
    `PostgreSQL engine <http://www.postgresql.org/docs/9.1/interactive/sql/.html>`_.
    There is an enforced timeout on SQL queries to avoid an unintended DOS.
    DataStore resource that belong to a private CKAN resource cannot be searched with
    this action. Use :meth:`~ckanext.datastore.logic.action.datastore_search` instead.

    .. note:: This action is only available when using PostgreSQL 9.X and using a read-only user on the database.
        It is not available in :ref:`legacy mode<legacy-mode>`.

    :param sql: a single SQL select statement
    :type sql: string

    **Results:**

    The result of this action is a dictionary with the following keys:

    :rtype: A dictionary with the following keys
    :param fields: fields/columns and their extra metadata
    :type fields: list of dictionaries
    :param records: list of matching results
    :type records: list of dictionaries

    '''
    sql = _get_or_bust(data_dict, 'sql')

    if not db._is_single_statement(sql):
        raise p.toolkit.ValidationError({
            'query': ['Query is not a single statement or contains semicolons.'],
            'hint': [('If you want to use semicolons, use character encoding'
                     '(; equals chr(59)) and string concatenation (||). ')]
        })

    p.toolkit.check_access('datastore_search_sql', context, data_dict)

    data_dict['connection_url'] = pylons.config['ckan.datastore.read_url']

    result = db.search_sql(context, data_dict)
    result.pop('id', None)
    result.pop('connection_url')
    return result


def datastore_make_private(context, data_dict):
    ''' Deny access to the DataStore table through
    :meth:`~ckanext.datastore.logic.action.datastore_search_sql`.

    This action is called automatically when a CKAN dataset becomes
    private or a new DataStore table is created for a CKAN resource
    that belongs to a private dataset.

    :param resource_id: id of resource that should become private
    :type resource_id: string
    '''
    if 'id' in data_dict:
        data_dict['resource_id'] = data_dict['id']
    res_id = _get_or_bust(data_dict, 'resource_id')

    data_dict['connection_url'] = pylons.config['ckan.datastore.write_url']

    if not _resource_exists(context, data_dict):
        raise p.toolkit.ObjectNotFound(p.toolkit._(
            u'Resource "{0}" was not found.'.format(res_id)
        ))

    p.toolkit.check_access('datastore_change_permissions', context, data_dict)

    db.make_private(context, data_dict)


def datastore_make_public(context, data_dict):
    ''' Allow access to the DataStore table through
    :meth:`~ckanext.datastore.logic.action.datastore_search_sql`.

    This action is called automatically when a CKAN dataset becomes
    public.

    :param resource_id: if of resource that should become public
    :type resource_id: string
    '''
    if 'id' in data_dict:
        data_dict['resource_id'] = data_dict['id']
    res_id = _get_or_bust(data_dict, 'resource_id')

    data_dict['connection_url'] = pylons.config['ckan.datastore.write_url']

    if not _resource_exists(context, data_dict):
        raise p.toolkit.ObjectNotFound(p.toolkit._(
            u'Resource "{0}" was not found.'.format(res_id)
        ))

    p.toolkit.check_access('datastore_change_permissions', context, data_dict)

    db.make_public(context, data_dict)


def _resource_exists(context, data_dict):
    ''' Returns true if the resource exists in CKAN and in the datastore '''
    model = _get_or_bust(context, 'model')
    res_id = _get_or_bust(data_dict, 'resource_id')
    if not model.Resource.get(res_id):
        return False

    resources_sql = sqlalchemy.text(u'''SELECT 1 FROM "_table_metadata"
                                        WHERE name = :id AND alias_of IS NULL''')
    results = db._get_engine(data_dict).execute(resources_sql, id=res_id)
    return results.rowcount > 0


def _check_read_only(context, data_dict):
    ''' Raises exception if the resource is read-only.
    Make sure the resource id is in resource_id
    '''
    if data_dict.get('force'):
        return
    res = p.toolkit.get_action('resource_show')(
        context, {'id': data_dict['resource_id']})
    if res.get('url_type') != 'datastore':
        raise p.toolkit.ValidationError({
            'read-only': ['Cannot edit read-only resource. Either pass'
                          '"force=True" or change url-type to "datastore"']
        })

########NEW FILE########
__FILENAME__ = auth
import ckan.plugins as p


def datastore_auth(context, data_dict, privilege='resource_update'):
    if not 'id' in data_dict:
        data_dict['id'] = data_dict.get('resource_id')
    user = context.get('user')

    authorized = p.toolkit.check_access(privilege, context, data_dict)

    if not authorized:
        return {
            'success': False,
            'msg': p.toolkit._('User {0} not authorized to update resource {1}'
                    .format(str(user), data_dict['id']))
        }
    else:
        return {'success': True}


def datastore_create(context, data_dict):
    return datastore_auth(context, data_dict)


def datastore_upsert(context, data_dict):
    return datastore_auth(context, data_dict)


def datastore_delete(context, data_dict):
    return datastore_auth(context, data_dict)


@p.toolkit.auth_allow_anonymous_access
def datastore_search(context, data_dict):
    return datastore_auth(context, data_dict, 'resource_show')


@p.toolkit.auth_allow_anonymous_access
def datastore_search_sql(context, data_dict):
    return {'success': True}


def datastore_change_permissions(context, data_dict):
    return datastore_auth(context, data_dict)

########NEW FILE########
__FILENAME__ = schema
import json

import ckan.plugins as p
import ckan.lib.navl.dictization_functions as df

get_validator = p.toolkit.get_validator

not_missing = get_validator('not_missing')
not_empty = get_validator('not_empty')
resource_id_exists = get_validator('resource_id_exists')
package_id_exists = get_validator('package_id_exists')
ignore_missing = get_validator('ignore_missing')
empty = get_validator('empty')
boolean_validator = get_validator('boolean_validator')
int_validator = get_validator('int_validator')
OneOf = get_validator('OneOf')


def rename(old, new):
    '''
    Rename a schema field from old to new.
    Should be used in __after or __before.
    '''
    def rename_field(key, data, errors, context):
        index = max([int(k[1]) for k in data.keys()
                     if len(k) == 3 and k[0] == new] + [-1])

        for field_name in data.keys():
            if field_name[0] == old and data.get(field_name):
                new_field_name = list(field_name)
                new_field_name[0] = new

                if len(new_field_name) > 1:
                    new_field_name[1] = int(new_field_name[1]) + index + 1

                data[tuple(new_field_name)] = data[field_name]
                data.pop(field_name)

    return rename_field


def list_of_strings_or_lists(key, data, errors, context):
    value = data.get(key)
    if not isinstance(value, list):
        raise df.Invalid('Not a list')
    for x in value:
        if not isinstance(x, basestring) and not isinstance(x, list):
            raise df.Invalid('%s: %s' % ('Neither a string nor a list', x))


def list_of_strings_or_string(key, data, errors, context):
    value = data.get(key)
    if isinstance(value, basestring):
        return
    list_of_strings_or_lists(key, data, errors, context)


def json_validator(value, context):
    if isinstance(value, dict) or isinstance(value, list):
        return value
    try:
        value = json.loads(value)
    except ValueError:
        raise df.Invalid('Cannot parse JSON')
    return value


def datastore_create_schema():
    schema = {
        'resource_id': [ignore_missing, unicode, resource_id_exists],
        'force': [ignore_missing, boolean_validator],
        'id': [ignore_missing],
        'aliases': [ignore_missing, list_of_strings_or_string],
        'fields': {
            'id': [not_empty, unicode],
            'type': [ignore_missing]
        },
        'primary_key': [ignore_missing, list_of_strings_or_string],
        'indexes': [ignore_missing, list_of_strings_or_string],
        '__junk': [empty],
        '__before': [rename('id', 'resource_id')]
    }
    return schema


def datastore_upsert_schema():
    schema = {
        'resource_id': [not_missing, not_empty, unicode],
        'force': [ignore_missing, boolean_validator],
        'id': [ignore_missing],
        'method': [ignore_missing, unicode, OneOf(
            ['upsert', 'insert', 'update'])],
        '__junk': [empty],
        '__before': [rename('id', 'resource_id')]
    }
    return schema


def datastore_delete_schema():
    schema = {
        'resource_id': [not_missing, not_empty, unicode],
        'force': [ignore_missing, boolean_validator],
        'id': [ignore_missing],
        '__junk': [empty],
        '__before': [rename('id', 'resource_id')]
    }
    return schema


def datastore_search_schema():
    schema = {
        'resource_id': [not_missing, not_empty, unicode],
        'id': [ignore_missing],
        'q': [ignore_missing, unicode],
        'plain': [ignore_missing, boolean_validator],
        'filters': [ignore_missing, json_validator],
        'language': [ignore_missing, unicode],
        'limit': [ignore_missing, int_validator],
        'offset': [ignore_missing, int_validator],
        'fields': [ignore_missing, list_of_strings_or_string],
        'sort': [ignore_missing, list_of_strings_or_string],
        '__junk': [empty],
        '__before': [rename('id', 'resource_id')]
    }
    return schema

########NEW FILE########
__FILENAME__ = plugin
import sys
import logging

import sqlalchemy.engine.url as sa_url

import ckan.plugins as p
import ckanext.datastore.logic.action as action
import ckanext.datastore.logic.auth as auth
import ckanext.datastore.db as db
import ckan.logic as logic
import ckan.model as model

log = logging.getLogger(__name__)
_get_or_bust = logic.get_or_bust

DEFAULT_FORMATS = []


class DatastoreException(Exception):
    pass


class DatastorePlugin(p.SingletonPlugin):
    p.implements(p.IConfigurable, inherit=True)
    p.implements(p.IActions)
    p.implements(p.IAuthFunctions)
    p.implements(p.IResourceUrlChange)
    p.implements(p.IDomainObjectModification, inherit=True)
    p.implements(p.IRoutes, inherit=True)
    p.implements(p.IResourceController, inherit=True)

    legacy_mode = False
    resource_show_action = None

    def configure(self, config):
        self.config = config
        # check for ckan.datastore.write_url and ckan.datastore.read_url
        if (not 'ckan.datastore.write_url' in config):
            error_msg = 'ckan.datastore.write_url not found in config'
            raise DatastoreException(error_msg)

        # Legacy mode means that we have no read url. Consequently sql search is not
        # available and permissions do not have to be changed. In legacy mode, the
        # datastore runs on PG prior to 9.0 (for example 8.4).
        self.legacy_mode = 'ckan.datastore.read_url' not in self.config

        datapusher_formats = config.get('datapusher.formats', '').split()
        self.datapusher_formats = datapusher_formats or DEFAULT_FORMATS

        # Check whether we are running one of the paster commands which means
        # that we should ignore the following tests.
        if sys.argv[0].split('/')[-1] == 'paster' and 'datastore' in sys.argv[1:]:
            log.warn('Omitting permission checks because you are '
                     'running paster commands.')
            return

        self.ckan_url = self.config['sqlalchemy.url']
        self.write_url = self.config['ckan.datastore.write_url']
        if self.legacy_mode:
            self.read_url = self.write_url
            log.warn('Legacy mode active. '
                     'The sql search will not be available.')
        else:
            self.read_url = self.config['ckan.datastore.read_url']

        self.read_engine = db._get_engine(
            {'connection_url': self.read_url})
        if not model.engine_is_pg(self.read_engine):
            log.warn('We detected that you do not use a PostgreSQL '
                     'database. The DataStore will NOT work and DataStore '
                     'tests will be skipped.')
            return

        if self._is_read_only_database():
            log.warn('We detected that CKAN is running on a read '
                     'only database. Permission checks and the creation '
                     'of _table_metadata are skipped.')
        else:
            self._check_urls_and_permissions()
            self._create_alias_table()


    def notify(self, entity, operation=None):
        if not isinstance(entity, model.Package) or self.legacy_mode:
            return
        # if a resource is new, it cannot have a datastore resource, yet
        if operation == model.domain_object.DomainObjectOperation.changed:
            context = {'model': model, 'ignore_auth': True}
            if entity.private:
                func = p.toolkit.get_action('datastore_make_private')
            else:
                func = p.toolkit.get_action('datastore_make_public')
            for resource in entity.resources:
                try:
                    func(context, {
                        'connection_url': self.write_url,
                        'resource_id': resource.id})
                except p.toolkit.ObjectNotFound:
                    pass

    def _log_or_raise(self, message):
        if self.config.get('debug'):
            log.critical(message)
        else:
            raise DatastoreException(message)

    def _check_urls_and_permissions(self):
        # Make sure that the right permissions are set
        # so that no harmful queries can be made

        if self._same_ckan_and_datastore_db():
            self._log_or_raise('CKAN and DataStore database '
                               'cannot be the same.')

        # in legacy mode, the read and write url are the same (both write url)
        # consequently the same url check and and write privilege check
        # don't make sense
        if not self.legacy_mode:
            if self._same_read_and_write_url():
                self._log_or_raise('The write and read-only database '
                                   'connection urls are the same.')

            if not self._read_connection_has_correct_privileges():
                self._log_or_raise('The read-only user has write privileges.')

    def _is_read_only_database(self):
        ''' Returns True if no connection has CREATE privileges on the public
        schema. This is the case if replication is enabled.'''
        for url in [self.ckan_url, self.write_url, self.read_url]:
            connection = db._get_engine({'connection_url': url}).connect()
            try:
                sql = u"SELECT has_schema_privilege('public', 'CREATE')"
                is_writable = connection.execute(sql).first()[0]
            finally:
                connection.close()
            if is_writable:
                return False
        return True

    def _same_ckan_and_datastore_db(self):
        '''Returns True if the CKAN and DataStore db are the same'''
        return self._get_db_from_url(self.ckan_url) == self._get_db_from_url(self.read_url)

    def _get_db_from_url(self, url):
        db_url = sa_url.make_url(url)
        return db_url.host, db_url.port, db_url.database

    def _same_read_and_write_url(self):
        return self.write_url == self.read_url

    def _read_connection_has_correct_privileges(self):
        ''' Returns True if the right permissions are set for the read
        only user. A table is created by the write user to test the
        read only user.
        '''
        write_connection = db._get_engine(
            {'connection_url': self.write_url}).connect()
        read_connection_user = sa_url.make_url(self.read_url).username

        drop_foo_sql = u'DROP TABLE IF EXISTS _foo'

        write_connection.execute(drop_foo_sql)

        try:
            write_connection.execute(u'CREATE TEMP TABLE _foo ()')
            for privilege in ['INSERT', 'UPDATE', 'DELETE']:
                test_privilege_sql = u"SELECT has_table_privilege(%s, '_foo', %s)"
                have_privilege = write_connection.execute(
                    test_privilege_sql, (read_connection_user, privilege)).first()[0]
                if have_privilege:
                    return False
        finally:
            write_connection.execute(drop_foo_sql)
            write_connection.close()
        return True

    def _create_alias_table(self):
        mapping_sql = '''
            SELECT DISTINCT
                substr(md5(dependee.relname || COALESCE(dependent.relname, '')), 0, 17) AS "_id",
                dependee.relname AS name,
                dependee.oid AS oid,
                dependent.relname AS alias_of
                -- dependent.oid AS oid
            FROM
                pg_class AS dependee
                LEFT OUTER JOIN pg_rewrite AS r ON r.ev_class = dependee.oid
                LEFT OUTER JOIN pg_depend AS d ON d.objid = r.oid
                LEFT OUTER JOIN pg_class AS dependent ON d.refobjid = dependent.oid
            WHERE
                (dependee.oid != dependent.oid OR dependent.oid IS NULL) AND
                (dependee.relname IN (SELECT tablename FROM pg_catalog.pg_tables)
                    OR dependee.relname IN (SELECT viewname FROM pg_catalog.pg_views)) AND
                dependee.relnamespace = (SELECT oid FROM pg_namespace WHERE nspname='public')
            ORDER BY dependee.oid DESC;
        '''
        create_alias_table_sql = u'CREATE OR REPLACE VIEW "_table_metadata" AS {0}'.format(mapping_sql)
        try:
            connection = db._get_engine(
                {'connection_url': self.write_url}).connect()
            connection.execute(create_alias_table_sql)
        finally:
            connection.close()

    def get_actions(self):
        actions = {'datastore_create': action.datastore_create,
                   'datastore_upsert': action.datastore_upsert,
                   'datastore_delete': action.datastore_delete,
                   'datastore_search': action.datastore_search,
                  }
        if not self.legacy_mode:
            actions.update({
                'datastore_search_sql': action.datastore_search_sql,
                'datastore_make_private': action.datastore_make_private,
                'datastore_make_public': action.datastore_make_public})
        return actions

    def get_auth_functions(self):
        return {'datastore_create': auth.datastore_create,
                'datastore_upsert': auth.datastore_upsert,
                'datastore_delete': auth.datastore_delete,
                'datastore_search': auth.datastore_search,
                'datastore_search_sql': auth.datastore_search_sql,
                'datastore_change_permissions': auth.datastore_change_permissions}

    def before_map(self, m):
        m.connect('/datastore/dump/{resource_id}',
                  controller='ckanext.datastore.controller:DatastoreController',
                  action='dump')
        return m

    def before_show(self, resource_dict):
        # Modify the resource url of datastore resources so that
        # they link to the datastore dumps.
        if resource_dict.get('url_type') == 'datastore':
            resource_dict['url'] = p.toolkit.url_for(
                controller='ckanext.datastore.controller:DatastoreController',
                action='dump', resource_id=resource_dict['id'])

        try:
            connection = self.read_engine.connect()
            result = connection.execute(
                'SELECT 1 FROM "_table_metadata" WHERE name = %s AND alias_of IS NULL',
                resource_dict['id']
            ).fetchone()
            if result:
                resource_dict['datastore_active'] = True
            else:
                resource_dict['datastore_active'] = False
        finally:
            connection.close()
        return resource_dict

########NEW FILE########
__FILENAME__ = helpers
import ckan.model as model
import ckan.lib.cli as cli

import ckan.plugins as p


def extract(d, keys):
    return dict((k, d[k]) for k in keys if k in d)


def clear_db(Session):
    drop_tables = u'''select 'drop table "' || tablename || '" cascade;'
                    from pg_tables where schemaname = 'public' '''
    c = Session.connection()
    results = c.execute(drop_tables)
    for result in results:
        c.execute(result[0])
    Session.commit()
    Session.remove()


def rebuild_all_dbs(Session):
    ''' If the tests are running on the same db, we have to make sure that
    the ckan tables are recrated.
    '''
    db_read_url_parts = cli.parse_db_config('ckan.datastore.write_url')
    db_ckan_url_parts = cli.parse_db_config('sqlalchemy.url')
    same_db = db_read_url_parts['db_name'] == db_ckan_url_parts['db_name']

    if same_db:
        model.repo.tables_created_and_initialised = False
    clear_db(Session)
    model.repo.rebuild_db()


def set_url_type(resources, user):
    context = {'user': user.name}
    for resource in resources:
        resource = p.toolkit.get_action('resource_show')(
            context, {'id': resource.id})
        resource['url_type'] = 'datastore'
        p.toolkit.get_action('resource_update')(context, resource)

########NEW FILE########
__FILENAME__ = test_configure
import unittest
import nose.tools
import pyutilib.component.core

import ckan.plugins
#import ckanext.datastore.plugin as plugin


class _TestConfiguration(unittest.TestCase):
    # FIXME This entire test class is broken and currently disabled.  A test
    # should not be changing the plugin itself WTF!  I'm not sure if these
    # tests have any value whatsoever.  Anyhow the plugin is not capable of
    # being so tested.  Also why do these test raise a custom exception?
    def setUp(self):
        self._original_plugin = ckan.plugins.unload('datastore')
        pyutilib.component.core.PluginGlobals.singleton_services()[plugin.DatastorePlugin] = True
        self.p = pyutilib.component.core.PluginGlobals.singleton_services()[plugin.DatastorePlugin] = ckan.plugins.load('datastore')

    def tearDown(self):
        ckan.plugins.unload('datastore')
        pyutilib.component.core.PluginGlobals.singleton_services()[plugin.DatastorePlugin] = self._original_plugin

    def test_set_legacy_mode(self):
        c = {
            'sqlalchemy.url': 'bar',
            'ckan.datastore.write_url': 'foo'
        }
        try:
            self.p.configure(c)
        except Exception:
            pass
        assert self.p.legacy_mode
        assert self.p.write_url == 'foo'
        assert self.p.read_url == 'foo'

    def test_check_separate_write_and_read_url(self):
        self.p.write_url = 'postgresql://u:pass@localhost/ds'
        self.p.read_url = 'postgresql://u:pass@localhost/ds'
        assert self.p._same_read_and_write_url()

        self.p.write_url = 'postgresql://u:pass@localhost/ds'
        self.p.read_url = 'postgresql://u2:pass@localhost/ds'
        assert not self.p._same_read_and_write_url()

    def test_same_ckan_and_datastore_db(self):
        self.p.read_url = 'postgresql://u2:pass@localhost/ckan'
        self.p.ckan_url = 'postgresql://u:pass@localhost/ckan'
        assert self.p._same_ckan_and_datastore_db()

        self.p.read_url = 'postgresql://u:pass@localhost/dt'
        self.p.ckan_url = 'postgresql://u:pass@localhost/ckan'
        assert not self.p._same_ckan_and_datastore_db()

    def test_setup_plugin_for_check_urls_and_permissions_tests_should_leave_the_plugin_in_a_valid_state(self):
        self.setUp_plugin_for_check_urls_and_permissions_tests()
        self.p._check_urls_and_permissions()  # Should be OK

    def test_check_urls_and_permissions_requires_different_ckan_and_datastore_dbs(self):
        self.setUp_plugin_for_check_urls_and_permissions_tests()

        self.p._same_ckan_and_datastore_db = lambda: False
        self.p._check_urls_and_permissions()  # Should be OK

        self.p._same_ckan_and_datastore_db = lambda: True
        nose.tools.assert_raises(InvalidUrlsOrPermissionsException, self.p._check_urls_and_permissions)

    def test_check_urls_and_permissions_requires_different_read_and_write_urls_when_not_in_legacy_mode(self):
        self.setUp_plugin_for_check_urls_and_permissions_tests()
        self.p.legacy_mode = False

        self.p._same_read_and_write_url = lambda: False
        self.p._check_urls_and_permissions()  # Should be OK

        self.p._same_read_and_write_url = lambda: True
        nose.tools.assert_raises(InvalidUrlsOrPermissionsException, self.p._check_urls_and_permissions)

    def test_check_urls_and_permissions_doesnt_require_different_read_and_write_urls_when_in_legacy_mode(self):
        self.setUp_plugin_for_check_urls_and_permissions_tests()
        self.p.legacy_mode = True

        self.p._same_read_and_write_url = lambda: False
        self.p._check_urls_and_permissions()  # Should be OK

        self.p._same_read_and_write_url = lambda: True
        self.p._check_urls_and_permissions()  # Should be OK

    def test_check_urls_and_permissions_requires_read_connection_with_correct_privileges_when_not_in_legacy_mode(self):
        self.setUp_plugin_for_check_urls_and_permissions_tests()
        self.p.legacy_mode = False

        self.p._read_connection_has_correct_privileges = lambda: True
        self.p._check_urls_and_permissions()  # Should be OK

        self.p._read_connection_has_correct_privileges = lambda: False
        nose.tools.assert_raises(InvalidUrlsOrPermissionsException, self.p._check_urls_and_permissions)

    def test_check_urls_and_permissions_doesnt_care_about_read_connection_privileges_when_in_legacy_mode(self):
        self.setUp_plugin_for_check_urls_and_permissions_tests()
        self.p.legacy_mode = True

        self.p._read_connection_has_correct_privileges = lambda: True
        self.p._check_urls_and_permissions()  # Should be OK

        self.p._read_connection_has_correct_privileges = lambda: False
        self.p._check_urls_and_permissions()  # Should be OK

    def setUp_plugin_for_check_urls_and_permissions_tests(self):
        def _raise_invalid_urls_or_permissions_exception(message):
            raise InvalidUrlsOrPermissionsException(message)

        self.p._same_ckan_and_datastore_db = lambda: False
        self.p.legacy_mode = True
        self.p._same_read_and_write_url = lambda: False
        self.p._read_connection_has_correct_privileges = lambda: True
        self.p._log_or_raise = _raise_invalid_urls_or_permissions_exception


class InvalidUrlsOrPermissionsException(Exception):
    pass

########NEW FILE########
__FILENAME__ = test_create
import json
import httpretty
import nose
import sys
import datetime
from nose.tools import assert_equal

import pylons
from pylons import config
import sqlalchemy.orm as orm
import paste.fixture

import ckan.plugins as p
import ckan.lib.create_test_data as ctd
import ckan.model as model
import ckan.tests as tests
import ckan.config.middleware as middleware

import ckanext.datastore.db as db
from ckanext.datastore.tests.helpers import rebuild_all_dbs, set_url_type


# avoid hanging tests https://github.com/gabrielfalcao/HTTPretty/issues/34
if sys.version_info < (2, 7, 0):
    import socket
    socket.setdefaulttimeout(1)


class TestDatastoreCreate(tests.WsgiAppCase):
    sysadmin_user = None
    normal_user = None

    @classmethod
    def setup_class(cls):

        wsgiapp = middleware.make_app(config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        p.load('datastore')
        ctd.CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        engine = db._get_engine(
            {'connection_url': pylons.config['ckan.datastore.write_url']})
        cls.Session = orm.scoped_session(orm.sessionmaker(bind=engine))
        set_url_type(
            model.Package.get('annakarenina').resources, cls.sysadmin_user)

    @classmethod
    def teardown_class(cls):
        rebuild_all_dbs(cls.Session)
        p.unload('datastore')

    def test_create_requires_auth(self):
        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id
        }
        postparams = '%s=1' % json.dumps(data)
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            status=403)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_create_empty_fails(self):
        postparams = '%s=1' % json.dumps({})
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_create_invalid_alias_name(self):
        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id,
            'aliases': u'foo"bar',
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': 'author', 'type': 'text'}]
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

        data = {
            'resource_id': resource.id,
            'aliases': u'fo%25bar',  # alias with percent
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': 'author', 'type': 'text'}]
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_create_duplicate_alias_name(self):
        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id,
            'aliases': u'myalias'
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=200)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        # try to create another table with the same alias
        resource = model.Package.get('annakarenina').resources[1]
        data = {
            'resource_id': resource.id,
            'aliases': u'myalias'
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

        # try to create an alias that is a resource id
        resource = model.Package.get('annakarenina').resources[1]
        data = {
            'resource_id': resource.id,
            'aliases': model.Package.get('annakarenina').resources[0].id
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_create_invalid_field_type(self):
        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id,
            'fields': [{'id': 'book', 'type': 'int['},  # this is invalid
                       {'id': 'author', 'type': 'INVALID'}]
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_create_invalid_field_name(self):
        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id,
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': '_author', 'type': 'text'}]
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

        data = {
            'resource_id': resource.id,
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': '"author', 'type': 'text'}]
        }
        postparams = '%s=1' % json.dumps(data)
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

        data = {
            'resource_id': resource.id,
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': '', 'type': 'text'}]
        }
        postparams = '%s=1' % json.dumps(data)
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_create_invalid_record_field(self):
        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id,
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': 'author', 'type': 'text'}],
            'records': [{'book': 'annakarenina', 'author': 'tolstoy'},
                        {'book': 'warandpeace', 'published': '1869'}]
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_bad_records(self):
        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id,
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': 'author', 'type': 'text'}],
            'records': ['bad']  # treat author as null
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False
        assert_equal(res_dict['error']['__type'], 'Validation Error')

        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id,
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': 'author', 'type': 'text'}],
            'records': [{'book': 'annakarenina', 'author': 'tolstoy'},
                        [],
                        {'book': 'warandpeace'}]  # treat author as null
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False
        assert_equal(res_dict['error']['__type'], 'Validation Error')

    def test_create_invalid_index(self):
        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id,
            'indexes': 'book, dummy',
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': 'author', 'type': 'text'}]
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_create_invalid_unique_index(self):
        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id,
            'primary_key': 'dummy',
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': 'author', 'type': 'text'}]
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_create_alias_twice(self):
        resource = model.Package.get('annakarenina').resources[1]
        data = {
            'resource_id': resource.id,
            'aliases': 'new_alias',
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': 'author', 'type': 'text'}]
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True, res_dict

        resource = model.Package.get('annakarenina').resources[0]
        data = {
            'resource_id': resource.id,
            'aliases': 'new_alias',
            'fields': [{'id': 'more books', 'type': 'text'}]
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False, res_dict

    def test_create_basic(self):
        resource = model.Package.get('annakarenina').resources[0]
        aliases = [u'great_list_of_books', u'another_list_of_b\xfcks']
        data = {
            'resource_id': resource.id,
            'aliases': aliases,
            'fields': [{'id': 'boo%k', 'type': 'text'},  # column with percent
                       {'id': 'author', 'type': 'json'}],
            'indexes': [['boo%k', 'author'], 'author'],
            'records': [{'boo%k': 'crime', 'author': ['tolstoy', 'dostoevsky']},
                        {'boo%k': 'annakarenina', 'author': ['tolstoy', 'putin']},
                        {'boo%k': 'warandpeace'}]  # treat author as null
        }
        ### Firstly test to see whether resource has no datastore table yet
        postparams = '%s=1' % json.dumps({'id': resource.id})
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/resource_show', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['result']['datastore_active'] is False

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True
        res = res_dict['result']
        assert res['resource_id'] == data['resource_id']
        assert res['fields'] == data['fields'], res['fields']
        assert res['records'] == data['records']

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(resource.id))

        assert results.rowcount == 3
        for i, row in enumerate(results):
            assert data['records'][i].get('boo%k') == row['boo%k']
            assert data['records'][i].get('author') == (
                json.loads(row['author'][0]) if row['author'] else None)

        results = c.execute('''
            select * from "{0}" where _full_text @@ to_tsquery('warandpeace')
            '''.format(resource.id))
        assert results.rowcount == 1, results.rowcount

        results = c.execute('''
            select * from "{0}" where _full_text @@ to_tsquery('tolstoy')
            '''.format(resource.id))
        assert results.rowcount == 2
        self.Session.remove()

        # check aliases for resource
        c = self.Session.connection()
        for alias in aliases:

            results = [row for row in c.execute(u'select * from "{0}"'.format(resource.id))]
            results_alias = [row for row in c.execute(u'select * from "{0}"'.format(alias))]

            assert results == results_alias

            sql = (u"select * from _table_metadata "
                "where alias_of='{0}' and name='{1}'").format(resource.id, alias)
            results = c.execute(sql)
            assert results.rowcount == 1
        self.Session.remove()

        # check to test to see if resource now has a datastore table
        postparams = '%s=1' % json.dumps({'id': resource.id})
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/resource_show', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['result']['datastore_active']

        #######  insert again simple
        data2 = {
            'resource_id': resource.id,
            'records': [{'boo%k': 'hagji murat', 'author': ['tolstoy']}]
        }

        postparams = '%s=1' % json.dumps(data2)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(resource.id))
        self.Session.remove()

        assert results.rowcount == 4

        all_data = data['records'] + data2['records']
        for i, row in enumerate(results):
            assert all_data[i].get('boo%k') == row['boo%k']
            assert all_data[i].get('author') == (
                json.loads(row['author'][0]) if row['author'] else None)

        c = self.Session.connection()
        results = c.execute('''
            select * from "{0}" where _full_text @@ 'tolstoy'
            '''.format(resource.id))
        self.Session.remove()
        assert results.rowcount == 3

        #######  insert again extra field
        data3 = {
            'resource_id': resource.id,
            'records': [{'boo%k': 'crime and punsihment',
                         'author': ['dostoevsky'], 'rating': 2}],
            'indexes': ['rating']
        }

        postparams = '%s=1' % json.dumps(data3)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(resource.id))

        assert results.rowcount == 5

        all_data = data['records'] + data2['records'] + data3['records']
        for i, row in enumerate(results):
            assert all_data[i].get('boo%k') == row['boo%k'], (i, all_data[i].get('boo%k'), row['boo%k'])
            assert all_data[i].get('author') == (json.loads(row['author'][0]) if row['author'] else None)

        results = c.execute('''select * from "{0}" where _full_text @@ to_tsquery('dostoevsky') '''.format(resource.id))
        self.Session.remove()
        assert results.rowcount == 2

        #######  insert again which will fail because of unique book name
        data4 = {
            'resource_id': resource.id,
            'records': [{'boo%k': 'warandpeace'}],
            'primary_key': 'boo%k'
        }

        postparams = '%s=1' % json.dumps(data4)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False
        assert 'constraints' in res_dict['error'], res_dict

        #######  insert again which should not fail because constraint is removed
        data5 = {
            'resource_id': resource.id,
            'aliases': 'another_alias',  # replaces aliases
            'records': [{'boo%k': 'warandpeace'}],
            'primary_key': ''
        }

        postparams = '%s=1' % json.dumps(data5)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, expect_errors=True)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True, res_dict

        # new aliases should replace old aliases
        c = self.Session.connection()
        for alias in aliases:
            sql = (u"select * from _table_metadata "
                "where alias_of='{0}' and name='{1}'").format(resource.id, alias)
            results = c.execute(sql)
            assert results.rowcount == 0

        sql = (u"select * from _table_metadata "
            "where alias_of='{0}' and name='{1}'").format(resource.id, 'another_alias')
        results = c.execute(sql)
        assert results.rowcount == 1
        self.Session.remove()

        #######  insert array type
        data6 = {
            'resource_id': resource.id,
            'fields': [{'id': 'boo%k', 'type': 'text'},
                       {'id': 'author', 'type': 'json'},
                       {'id': 'rating', 'type': 'int'},
                       {'id': 'characters', 'type': '_text'}],  # this is an array of strings
            'records': [{'boo%k': 'the hobbit',
                         'author': ['tolkien'], 'characters': ['Bilbo', 'Gandalf']}],
            'indexes': ['characters']
        }

        postparams = '%s=1' % json.dumps(data6)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, expect_errors=True)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True, res_dict

        #######  insert type that requires additional lookup
        data7 = {
            'resource_id': resource.id,
            'fields': [{'id': 'boo%k', 'type': 'text'},
                       {'id': 'author', 'type': 'json'},
                       {'id': 'rating', 'type': 'int'},
                       {'id': 'characters', 'type': '_text'},
                       {'id': 'location', 'type': 'int[2]'}],
            'records': [{'boo%k': 'lord of the rings',
                         'author': ['tolkien'], 'location': [3, -42]}],
            'indexes': ['characters']
        }

        postparams = '%s=1' % json.dumps(data7)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, expect_errors=True)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True, res_dict

        #######  insert with parameter id rather than resource_id which is a shortcut
        data8 = {
            'id': resource.id,
             # insert with percent
            'records': [{'boo%k': 'warandpeace', 'author': '99% good'}]
        }

        postparams = '%s=1' % json.dumps(data8)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, expect_errors=True)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True, res_dict

    def test_guess_types(self):
        resource = model.Package.get('annakarenina').resources[1]

        data = {
            'resource_id': resource.id
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_delete', params=postparams,
                            extra_environ=auth, status="*")  # ignore status
        res_dict = json.loads(res.body)

        data = {
            'resource_id': resource.id,
            'fields': [{'id': 'author', 'type': 'json'},
                       {'id': 'count'},
                       {'id': 'book'},
                       {'id': 'date'}],
            'records': [{'book': 'annakarenina', 'author': 'tolstoy',
                         'count': 1, 'date': '2005-12-01', 'count2': 0.5},
                        {'book': 'crime', 'author': ['tolstoy', 'dostoevsky']},
                        {'book': 'warandpeace'}]  # treat author as null
        }
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        c = self.Session.connection()
        results = c.execute('''select * from "{0}" '''.format(resource.id))

        types = [db._pg_types[field[1]] for field in results.cursor.description]

        assert types == [u'int4', u'tsvector', u'nested', u'int4', u'text', u'timestamp', u'float8'], types

        assert results.rowcount == 3
        for i, row in enumerate(results):
            assert data['records'][i].get('book') == row['book']
            assert data['records'][i].get('author') == (
                json.loads(row['author'][0]) if row['author'] else None)
        self.Session.remove()

        ### extend types

        data = {
            'resource_id': resource.id,
            'fields': [{'id': 'author', 'type': 'text'},
                       {'id': 'count'},
                       {'id': 'book'},
                       {'id': 'date'},
                       {'id': 'count2'},
                       {'id': 'extra', 'type':'text'},
                       {'id': 'date2'},
                      ],
            'records': [{'book': 'annakarenina', 'author': 'tolstoy',
                         'count': 1, 'date': '2005-12-01', 'count2': 2,
                         'nested': [1, 2], 'date2': '2005-12-01'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        c = self.Session.connection()
        results = c.execute('''select * from "{0}" '''.format(resource.id))
        self.Session.remove()

        types = [db._pg_types[field[1]] for field in results.cursor.description]

        assert types == [u'int4',  # id
                         u'tsvector',  # fulltext
                         u'nested',  # author
                         u'int4',  # count
                         u'text',  # book
                         u'timestamp',  # date
                         u'float8',  # count2
                         u'text',  # extra
                         u'timestamp',  # date2
                         u'nested',  # count3
                        ], types

        ### fields resupplied in wrong order

        data = {
            'resource_id': resource.id,
            'fields': [{'id': 'author', 'type': 'text'},
                       {'id': 'count'},
                       {'id': 'date'},  # date and book in wrong order
                       {'id': 'book'},
                       {'id': 'count2'},
                       {'id': 'extra', 'type':'text'},
                       {'id': 'date2'},
                      ],
            'records': [{'book': 'annakarenina', 'author': 'tolstoy',
                         'count': 1, 'date': '2005-12-01', 'count2': 2,
                         'count3': 432, 'date2': '2005-12-01'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False


########NEW FILE########
__FILENAME__ = test_delete
import json
import nose

import pylons
import sqlalchemy
import sqlalchemy.orm as orm

import ckan.plugins as p
import ckan.lib.create_test_data as ctd
import ckan.model as model
import ckan.tests as tests

import ckanext.datastore.db as db
from ckanext.datastore.tests.helpers import rebuild_all_dbs, set_url_type


class TestDatastoreDelete(tests.WsgiAppCase):
    sysadmin_user = None
    normal_user = None
    Session = None

    @classmethod
    def setup_class(cls):
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        p.load('datastore')
        ctd.CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        resource = model.Package.get('annakarenina').resources[0]
        cls.data = {
            'resource_id': resource.id,
            'aliases': u'b\xfck2',
            'fields': [{'id': 'book', 'type': 'text'},
                       {'id': 'author', 'type': 'text'},
                       {'id': 'rating with %', 'type': 'text'}],
            'records': [{'book': 'annakarenina', 'author': 'tolstoy',
                         'rating with %': '90%'},
                        {'book': 'warandpeace', 'author': 'tolstoy',
                         'rating with %': '42%'}]
        }

        engine = db._get_engine(
            {'connection_url': pylons.config['ckan.datastore.write_url']})
        cls.Session = orm.scoped_session(orm.sessionmaker(bind=engine))
        set_url_type(
            model.Package.get('annakarenina').resources, cls.sysadmin_user)

    @classmethod
    def teardown_class(cls):
        rebuild_all_dbs(cls.Session)
        p.unload('datastore')

    def _create(self):
        postparams = '%s=1' % json.dumps(self.data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        return res_dict

    def _delete(self):
        data = {'resource_id': self.data['resource_id']}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_delete', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        assert res_dict['result'] == data
        return res_dict

    def test_delete_basic(self):
        self._create()
        self._delete()
        resource_id = self.data['resource_id']
        c = self.Session.connection()

        # It's dangerous to build queries as someone could inject sql.
        # It's okay here as it is a test but don't use it anyhwere else!
        results = c.execute(u"select 1 from pg_views where viewname = '{0}'".format(self.data['aliases']))
        assert results.rowcount == 0

        try:
            # check that data was actually deleted: this should raise a
            # ProgrammingError as the table should not exist any more
            c.execute(u'select * from "{0}";'.format(resource_id))
            raise Exception("Data not deleted")
        except sqlalchemy.exc.ProgrammingError as e:
            expected_msg = 'relation "{0}" does not exist'.format(resource_id)
            assert expected_msg in str(e)

        self.Session.remove()

    def test_delete_invalid_resource_id(self):
        postparams = '%s=1' % json.dumps({'resource_id': 'bad'})
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_delete', params=postparams,
                            extra_environ=auth, status=404)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_delete_filters(self):
        self._create()
        resource_id = self.data['resource_id']

        # try and delete just the 'warandpeace' row
        data = {'resource_id': resource_id,
                'filters': {'book': 'warandpeace'}}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_delete', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        c = self.Session.connection()
        result = c.execute(u'select * from "{0}";'.format(resource_id))
        results = [r for r in result]
        assert len(results) == 1
        assert results[0].book == 'annakarenina'
        self.Session.remove()

        # shouldn't delete anything
        data = {'resource_id': resource_id,
                'filters': {'book': 'annakarenina', 'author': 'bad'}}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_delete', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        c = self.Session.connection()
        result = c.execute(u'select * from "{0}";'.format(resource_id))
        results = [r for r in result]
        assert len(results) == 1
        assert results[0].book == 'annakarenina'
        self.Session.remove()

        # delete the 'annakarenina' row and also only use id
        data = {'id': resource_id,
                'filters': {'book': 'annakarenina', 'author': 'tolstoy'}}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_delete', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        c = self.Session.connection()
        result = c.execute(u'select * from "{0}";'.format(resource_id))
        results = [r for r in result]
        assert len(results) == 0
        self.Session.remove()

        self._delete()

########NEW FILE########
__FILENAME__ = test_dump
import json

import nose
from nose.tools import assert_equals
from pylons import config
import sqlalchemy.orm as orm
import paste.fixture

import ckan.config.middleware as middleware
import ckan.plugins as p
import ckan.lib.create_test_data as ctd
import ckan.model as model
import ckan.tests as tests
import ckanext.datastore.db as db
import ckanext.datastore.tests.helpers as helpers


class TestDatastoreDump(object):
    sysadmin_user = None
    normal_user = None

    @classmethod
    def setup_class(cls):
        wsgiapp = middleware.make_app(config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        p.load('datastore')
        ctd.CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        resource = model.Package.get('annakarenina').resources[0]
        cls.data = {
            'resource_id': resource.id,
            'force': True,
            'aliases': 'books',
            'fields': [{'id': u'b\xfck', 'type': 'text'},
                       {'id': 'author', 'type': 'text'},
                       {'id': 'published'},
                       {'id': u'characters', u'type': u'_text'}],
            'records': [{u'b\xfck': 'annakarenina',
                        'author': 'tolstoy',
                        'published': '2005-03-01',
                        'nested': ['b', {'moo': 'moo'}],
                        u'characters': [u'Princess Anna', u'Sergius']},
                        {u'b\xfck': 'warandpeace', 'author': 'tolstoy',
                         'nested': {'a': 'b'}}]
        }
        postparams = '%s=1' % json.dumps(cls.data)
        auth = {'Authorization': str(cls.sysadmin_user.apikey)}
        res = cls.app.post('/api/action/datastore_create', params=postparams,
                           extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        engine = db._get_engine({
            'connection_url': config['ckan.datastore.write_url']})
        cls.Session = orm.scoped_session(orm.sessionmaker(bind=engine))

    @classmethod
    def teardown_class(cls):
        helpers.rebuild_all_dbs(cls.Session)
        p.unload('datastore')

    def test_dump_basic(self):
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.get('/datastore/dump/{0}'.format(str(
            self.data['resource_id'])), extra_environ=auth)
        content = res.body.decode('utf-8')
        expected = u'_id,b\xfck,author,published,characters,nested'
        assert_equals(content[:len(expected)], expected)
        assert 'warandpeace' in content
        assert "[u'Princess Anna', u'Sergius']" in content

        # get with alias instead of id
        res = self.app.get('/datastore/dump/{0}'.format(str(
            self.data['aliases'])), extra_environ=auth)

    def test_dump_does_not_exist_raises_404(self):
        auth = {'Authorization': str(self.normal_user.apikey)}
        self.app.get('/datastore/dump/{0}'.format(str(
            'does-not-exist')), extra_environ=auth, status=404)

    def test_dump_limit(self):
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.get('/datastore/dump/{0}?limit=1'.format(str(
            self.data['resource_id'])), extra_environ=auth)
        content = res.body.decode('utf-8')
        expected = u'_id,b\xfck,author,published,characters,nested'
        assert_equals(content[:len(expected)], expected)
        assert_equals(len(content), 148)

########NEW FILE########
__FILENAME__ = test_search
import json
import nose
import pprint

import pylons
import sqlalchemy.orm as orm

import ckan.plugins as p
import ckan.lib.create_test_data as ctd
import ckan.model as model
import ckan.tests as tests

import ckanext.datastore.db as db
from ckanext.datastore.tests.helpers import extract, rebuild_all_dbs


class TestDatastoreSearch(tests.WsgiAppCase):
    sysadmin_user = None
    normal_user = None

    @classmethod
    def setup_class(cls):
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        p.load('datastore')
        ctd.CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        cls.dataset = model.Package.get('annakarenina')
        cls.resource = cls.dataset.resources[0]
        cls.data = {
            'resource_id': cls.resource.id,
            'force': True,
            'aliases': 'books3',
            'fields': [{'id': u'b\xfck', 'type': 'text'},
                       {'id': 'author', 'type': 'text'},
                       {'id': 'published'},
                       {'id': u'characters', u'type': u'_text'},
                       {'id': 'rating with %'}],
            'records': [{u'b\xfck': 'annakarenina', 'author': 'tolstoy',
                        'published': '2005-03-01', 'nested': ['b', {'moo': 'moo'}],
                        u'characters': [u'Princess Anna', u'Sergius'],
                        'rating with %': '60%'},
                        {u'b\xfck': 'warandpeace', 'author': 'tolstoy',
                        'nested': {'a': 'b'}, 'rating with %': '99%'}
                       ]
        }
        postparams = '%s=1' % json.dumps(cls.data)
        auth = {'Authorization': str(cls.sysadmin_user.apikey)}
        res = cls.app.post('/api/action/datastore_create', params=postparams,
                           extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        # Make an organization, because private datasets must belong to one.
        cls.organization = tests.call_action_api(
            cls.app, 'organization_create',
            name='test_org',
            apikey=cls.sysadmin_user.apikey)

        cls.expected_records = [{u'published': u'2005-03-01T00:00:00',
                                 u'_id': 1,
                                 u'nested': [u'b', {u'moo': u'moo'}],
                                 u'b\xfck': u'annakarenina',
                                 u'author': u'tolstoy',
                                 u'characters': [u'Princess Anna', u'Sergius'],
                                 u'rating with %': u'60%'},
                                {u'published': None,
                                 u'_id': 2,
                                 u'nested': {u'a': u'b'},
                                 u'b\xfck': u'warandpeace',
                                 u'author': u'tolstoy',
                                 u'characters': None,
                                 u'rating with %': u'99%'}]

        engine = db._get_engine(
                {'connection_url': pylons.config['ckan.datastore.write_url']}
            )
        cls.Session = orm.scoped_session(orm.sessionmaker(bind=engine))

    @classmethod
    def teardown_class(cls):
        rebuild_all_dbs(cls.Session)
        p.unload('datastore')

    def test_search_basic(self):
        data = {'resource_id': self.data['resource_id']}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == len(self.data['records'])
        assert result['records'] == self.expected_records, result['records']

        # search with parameter id should yield the same results
        data = {'id': self.data['resource_id']}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == len(self.data['records'])
        assert result['records'] == self.expected_records, result['records']

    def test_search_private_dataset(self):
        group = self.dataset.get_groups()[0]
        context = {
            'user': self.sysadmin_user.name,
            'ignore_auth': True,
            'model': model}
        package = p.toolkit.get_action('package_create')(
            context,
            {'name': 'privatedataset',
             'private': True,
             'owner_org': self.organization['id'],
             'groups': [{
                 'id': group.id
             }]})
        resource = p.toolkit.get_action('resource_create')(
            context,
            {'name': 'privateresource',
             'url': 'https://www.example.com/',
             'package_id': package['id']})

        postparams = '%s=1' % json.dumps({
            'resource_id': resource['id'],
            'force': True
        })
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        data = {'resource_id': resource['id']}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth, status=403)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_search_alias(self):
        data = {'resource_id': self.data['aliases']}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict_alias = json.loads(res.body)
        result = res_dict_alias['result']
        assert result['total'] == len(self.data['records'])
        assert result['records'] == self.expected_records, result['records']

    def test_search_invalid_field(self):
        data = {'resource_id': self.data['resource_id'],
                'fields': [{'id': 'bad'}]}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_search_fields(self):
        data = {'resource_id': self.data['resource_id'],
                'fields': [u'b\xfck']}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == len(self.data['records'])
        assert result['records'] == [{u'b\xfck': 'annakarenina'},
                                     {u'b\xfck': 'warandpeace'}], result['records']

        data = {'resource_id': self.data['resource_id'],
                'fields': u'b\xfck, author'}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == len(self.data['records'])
        assert result['records'] == [{u'b\xfck': 'annakarenina', 'author': 'tolstoy'},
                    {u'b\xfck': 'warandpeace', 'author': 'tolstoy'}], result['records']

    def test_search_filters(self):
        data = {'resource_id': self.data['resource_id'],
                'filters': {u'b\xfck': 'annakarenina'}}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == 1
        assert result['records'] == [self.expected_records[0]]

    def test_search_array_filters(self):
        data = {'resource_id': self.data['resource_id'],
                'filters': {u'characters': [u'Princess Anna', u'Sergius']}}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == 1
        assert result['records'] == [self.expected_records[0]]

    def test_search_filters_get(self):
        filters = {u'b\xfck': 'annakarenina'}
        res = self.app.get('/api/action/datastore_search?resource_id={0}&filters={1}'.format(
                    self.data['resource_id'], json.dumps(filters)))
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == 1
        assert result['records'] == [self.expected_records[0]]

    def test_search_invalid_filter(self):
        data = {'resource_id': self.data['resource_id'],
                # invalid because author is not an array
                'filters': {u'author': [u'tolstoy']}}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_search_sort(self):
        data = {'resource_id': self.data['resource_id'],
                'sort': u'b\xfck asc, author desc'}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == 2

        assert result['records'] == self.expected_records, result['records']

        data = {'resource_id': self.data['resource_id'],
                'sort': [u'b\xfck desc', '"author" asc']}
        postparams = '%s=1' % json.dumps(data)
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == 2

        assert result['records'] == self.expected_records[::-1]

    def test_search_invalid(self):
        data = {'resource_id': self.data['resource_id'],
                'sort': u'f\xfc\xfc asc'}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False
        assert res_dict['error']['sort'][0] == u'field "f\xfc\xfc" not in table'

    def test_search_limit(self):
        data = {'resource_id': self.data['resource_id'],
                'limit': 1}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == 2
        assert result['records'] == [self.expected_records[0]]

    def test_search_invalid_limit(self):
        data = {'resource_id': self.data['resource_id'],
                'limit': 'bad'}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

        data = {'resource_id': self.data['resource_id'],
                'limit': -1}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_search_offset(self):
        data = {'resource_id': self.data['resource_id'],
                'limit': 1,
                'offset': 1}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == 2
        assert result['records'] == [self.expected_records[1]]

    def test_search_invalid_offset(self):
        data = {'resource_id': self.data['resource_id'],
                'offset': 'bad'}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

        data = {'resource_id': self.data['resource_id'],
                'offset': -1}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_search_full_text(self):
        data = {'resource_id': self.data['resource_id'],
                'q': 'annakarenina'}

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == 1

        results = [extract(result['records'][0], [
            u'_id', u'author', u'b\xfck', u'nested',
            u'published', u'characters', u'rating with %'])]
        assert results == [self.expected_records[0]], results['records']

        data = {'resource_id': self.data['resource_id'],
                'q': 'tolstoy'}
        postparams = '%s=1' % json.dumps(data)
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == 2
        results = [extract(
            record,
            [u'_id', u'author', u'b\xfck', u'nested',
             u'published', u'characters', u'rating with %']
        ) for record in result['records']]
        assert results == self.expected_records, result['records']

        expected_fields = [{u'type': u'int4', u'id': u'_id'},
                        {u'type': u'text', u'id': u'b\xfck'},
                        {u'type': u'text', u'id': u'author'},
                        {u'type': u'timestamp', u'id': u'published'},
                        {u'type': u'json', u'id': u'nested'},
                        {u'type': u'float4', u'id': u'rank'}]
        for field in expected_fields:
            assert field in result['fields'], field

        # test multiple word queries (connected with and)
        data = {'resource_id': self.data['resource_id'],
                'plain': True,
                'q': 'tolstoy annakarenina'}
        postparams = '%s=1' % json.dumps(data)
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['total'] == 1
        results = [extract(
            result['records'][0],
            [u'_id', u'author', u'b\xfck', u'nested', u'published',
             u'characters', u'rating with %'])]
        assert results == [self.expected_records[0]], results['records']

        for field in expected_fields:
            assert field in result['fields'], field

    def test_search_table_metadata(self):
        data = {'resource_id': "_table_metadata"}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True


class TestDatastoreFullTextSearch(tests.WsgiAppCase):
    @classmethod
    def setup_class(cls):
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        p.load('datastore')
        ctd.CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        resource = model.Package.get('annakarenina').resources[0]
        cls.data = dict(
            resource_id=resource.id,
            force=True,
            fields=[
              {'id': 'id'},
              {'id': 'date', 'type':'date'},
              {'id': 'x'},
              {'id': 'y'},
              {'id': 'z'},
              {'id': 'country'},
              {'id': 'title'},
              {'id': 'lat'},
              {'id': 'lon'}
            ],
            records=[
              {'id': 0, 'date': '2011-01-01', 'x': 1, 'y': 2, 'z': 3, 'country': 'DE', 'title': 'first', 'lat':52.56, 'lon':13.40},
              {'id': 1, 'date': '2011-02-02', 'x': 2, 'y': 4, 'z': 24, 'country': 'UK', 'title': 'second', 'lat':54.97, 'lon':-1.60},
              {'id': 2, 'date': '2011-03-03', 'x': 3, 'y': 6, 'z': 9, 'country': 'US', 'title': 'third', 'lat':40.00, 'lon':-75.5},
              {'id': 3, 'date': '2011-04-04', 'x': 4, 'y': 8, 'z': 6, 'country': 'UK', 'title': 'fourth', 'lat':57.27, 'lon':-6.20},
              {'id': 4, 'date': '2011-05-04', 'x': 5, 'y': 10, 'z': 15, 'country': 'UK', 'title': 'fifth', 'lat':51.58, 'lon':0},
              {'id': 5, 'date': '2011-06-02', 'x': 6, 'y': 12, 'z': 18, 'country': 'DE', 'title': 'sixth', 'lat':51.04, 'lon':7.9}
            ]
        )
        postparams = '%s=1' % json.dumps(cls.data)
        auth = {'Authorization': str(cls.normal_user.apikey)}
        res = cls.app.post('/api/action/datastore_create', params=postparams,
                           extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

    @classmethod
    def teardown_class(cls):
        model.repo.rebuild_db()
        p.unload('datastore')

    def test_search_full_text(self):
        data = {'resource_id': self.data['resource_id'],
                'q': 'DE'}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['result']['total'] == 2, pprint.pformat(res_dict)

    def test_advanced_search_full_text(self):
        data = {'resource_id': self.data['resource_id'],
                'plain': 'False',
                'q': 'DE | UK'}
        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['result']['total'] == 5, pprint.pformat(res_dict)


class TestDatastoreSQL(tests.WsgiAppCase):
    sysadmin_user = None
    normal_user = None

    @classmethod
    def setup_class(cls):
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        plugin = p.load('datastore')
        if plugin.legacy_mode:
            # make sure we undo adding the plugin
            p.unload('datastore')
            raise nose.SkipTest("SQL tests are not supported in legacy mode")
        ctd.CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        cls.dataset = model.Package.get('annakarenina')
        resource = cls.dataset.resources[0]
        cls.data = {
            'resource_id': resource.id,
            'force': True,
            'aliases': 'books4',
            'fields': [{'id': u'b\xfck', 'type': 'text'},
                       {'id': 'author', 'type': 'text'},
                       {'id': 'published'}],
            'records': [{u'b\xfck': 'annakarenina',
                        'author': 'tolstoy',
                        'published': '2005-03-01',
                        'nested': ['b', {'moo': 'moo'}]},
                        {u'b\xfck': 'warandpeace',
                        'author': 'tolstoy',
                        'nested': {'a': 'b'}}]
        }
        postparams = '%s=1' % json.dumps(cls.data)
        auth = {'Authorization': str(cls.sysadmin_user.apikey)}
        res = cls.app.post('/api/action/datastore_create', params=postparams,
                           extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        # Make an organization, because private datasets must belong to one.
        cls.organization = tests.call_action_api(
            cls.app, 'organization_create',
            name='test_org',
            apikey=cls.sysadmin_user.apikey)

        cls.expected_records = [{u'_full_text': u"'annakarenina':1 'b':3 'moo':4 'tolstoy':2",
                                 u'_id': 1,
                                 u'author': u'tolstoy',
                                 u'b\xfck': u'annakarenina',
                                 u'nested': [u'b', {u'moo': u'moo'}],
                                 u'published': u'2005-03-01T00:00:00'},
                                {u'_full_text': u"'b':3 'tolstoy':2 'warandpeac':1",
                                 u'_id': 2,
                                 u'author': u'tolstoy',
                                 u'b\xfck': u'warandpeace',
                                 u'nested': {u'a': u'b'},
                                 u'published': None}]
        cls.expected_join_results = [{u'first': 1, u'second': 1}, {u'first': 1, u'second': 2}]

        engine = db._get_engine(
            {'connection_url': pylons.config['ckan.datastore.write_url']})
        cls.Session = orm.scoped_session(orm.sessionmaker(bind=engine))

    @classmethod
    def teardown_class(cls):
        rebuild_all_dbs(cls.Session)
        p.unload('datastore')

    def test_is_single_statement(self):
        singles = ['SELECT * FROM footable',
            'SELECT * FROM "bartable"',
            'SELECT * FROM "bartable";',
            "select 'foo'||chr(59)||'bar'"]

        for single in singles:
            assert db._is_single_statement(single) is True

        multiples = ['SELECT * FROM abc; SET LOCAL statement_timeout to'
            'SET LOCAL statement_timeout to; SELECT * FROM abc',
            'SELECT * FROM "foo"; SELECT * FROM "abc"']

        for multiple in multiples:
            assert db._is_single_statement(multiple) is False

    def test_invalid_statement(self):
        query = 'SELECT ** FROM foobar'
        data = {'sql': query}
        postparams = json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search_sql', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_select_basic(self):
        query = 'SELECT * FROM "{0}"'.format(self.data['resource_id'])
        data = {'sql': query}
        postparams = json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search_sql', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['records'] == self.expected_records

        # test alias search
        query = 'SELECT * FROM "{0}"'.format(self.data['aliases'])
        data = {'sql': query}
        postparams = json.dumps(data)
        res = self.app.post('/api/action/datastore_search_sql', params=postparams,
                            extra_environ=auth)
        res_dict_alias = json.loads(res.body)

        assert result['records'] == res_dict_alias['result']['records']

    def test_select_where_like_with_percent(self):
        query = 'SELECT * FROM public."{0}" WHERE "author" LIKE \'tol%\''.format(self.data['resource_id'])
        data = {'sql': query}
        postparams = json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_search_sql', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['records'] == self.expected_records

    def test_self_join(self):
        query = '''
            select a._id as first, b._id as second
            from "{0}" AS a,
                 "{0}" AS b
            where a.author = b.author
            limit 2
            '''.format(self.data['resource_id'])
        data = {'sql': query}
        postparams = json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search_sql', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True
        result = res_dict['result']
        assert result['records'] == self.expected_join_results

    def test_read_private(self):
        context = {
            'user': self.sysadmin_user.name,
            'model': model}
        data_dict = {
            'resource_id': self.data['resource_id'],
            'connection_url': pylons.config['ckan.datastore.write_url']}
        p.toolkit.get_action('datastore_make_private')(context, data_dict)
        query = 'SELECT * FROM "{0}"'.format(self.data['resource_id'])
        data = {'sql': query}
        postparams = json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search_sql', params=postparams,
                            extra_environ=auth, status=403)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False
        assert res_dict['error']['__type'] == 'Authorization Error'

        # make it public for the other tests
        p.toolkit.get_action('datastore_make_public')(context, data_dict)

    def test_new_datastore_table_from_private_resource(self):
        # make a private CKAN resource
        group = self.dataset.get_groups()[0]
        context = {
            'user': self.sysadmin_user.name,
            'ignore_auth': True,
            'model': model}
        package = p.toolkit.get_action('package_create')(
            context,
            {'name': 'privatedataset',
             'private': True,
             'owner_org': self.organization['id'],
             'groups': [{
                 'id': group.id
             }]})
        resource = p.toolkit.get_action('resource_create')(
            context,
            {'name': 'privateresource',
             'url': 'https://www.example.com/',
             'package_id': package['id']})

        postparams = '%s=1' % json.dumps({
            'resource_id': resource['id'],
            'force': True
        })
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        # new resource should be private
        query = 'SELECT * FROM "{0}"'.format(resource['id'])
        data = {'sql': query}
        postparams = json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search_sql', params=postparams,
                            extra_environ=auth, status=403)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False
        assert res_dict['error']['__type'] == 'Authorization Error'

    def test_making_resource_private_makes_datastore_private(self):
        group = self.dataset.get_groups()[0]
        context = {
            'user': self.sysadmin_user.name,
            'ignore_auth': True,
            'model': model}
        package = p.toolkit.get_action('package_create')(
            context,
            {'name': 'privatedataset2',
             'private': False,
             'owner_org': self.organization['id'],
             'groups': [{
                 'id': group.id
             }]})
        resource = p.toolkit.get_action('resource_create')(
            context,
            {'name': 'privateresource2',
             'url': 'https://www.example.co.uk/',
             'package_id': package['id']})

        postparams = '%s=1' % json.dumps({
            'resource_id': resource['id'],
            'force': True
        })
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_create', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        # Test public resource
        query = 'SELECT * FROM "{0}"'.format(resource['id'])
        data = {'sql': query}
        postparams_sql = json.dumps(data)
        auth = {'Authorization': str(self.normal_user.apikey)}
        res = self.app.post('/api/action/datastore_search_sql', params=postparams_sql,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        # Make resource private
        package = p.toolkit.get_action('package_show')(
            context, {'id': package.get('id')})
        package['private'] = True
        package = p.toolkit.get_action('package_update')(context, package)

        # Test private
        res = self.app.post('/api/action/datastore_search_sql', params=postparams_sql,
                            extra_environ=auth, status=403)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False
        assert res_dict['error']['__type'] == 'Authorization Error'

        postparams = json.dumps({'resource_id': resource['id']})
        res = self.app.post('/api/action/datastore_search', params=postparams,
                            extra_environ=auth, status=403)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False
        assert res_dict['error']['__type'] == 'Authorization Error'

        # we should not be able to make the private resource it public
        postparams = json.dumps({'resource_id': resource['id']})
        res = self.app.post('/api/action/datastore_make_public', params=postparams,
                            extra_environ=auth, status=403)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False
        assert res_dict['error']['__type'] == 'Authorization Error'

        # Make resource public
        package = p.toolkit.get_action('package_show')(
            context, {'id': package.get('id')})
        package['private'] = False
        package = p.toolkit.get_action('package_update')(context, package)

        # Test public again
        res = self.app.post('/api/action/datastore_search_sql', params=postparams_sql,
                            extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

########NEW FILE########
__FILENAME__ = test_unit
import unittest
import pylons
import nose

import ckan.tests as tests
import ckanext.datastore.db as db


class TestTypeGetters(unittest.TestCase):
    def test_list(self):
        assert db._get_list(None) is None
        assert db._get_list([]) == []
        assert db._get_list('') == []
        assert db._get_list('foo') == ['foo']
        assert db._get_list('foo, bar') == ['foo', 'bar']
        assert db._get_list('foo_"bar, baz') == ['foo_"bar', 'baz']
        assert db._get_list('"foo", "bar"') == ['foo', 'bar']
        assert db._get_list(u'foo, bar') == ['foo', 'bar']
        assert db._get_list(['foo', 'bar']) == ['foo', 'bar']
        assert db._get_list([u'foo', u'bar']) == ['foo', 'bar']
        assert db._get_list(['foo', ['bar', 'baz']]) == ['foo', ['bar', 'baz']]

    def test_is_valid_field_name(self):
        assert db._is_valid_field_name("foo")
        assert db._is_valid_field_name("foo bar")
        assert db._is_valid_field_name("42")
        assert not db._is_valid_field_name('foo"bar')
        assert not db._is_valid_field_name('"')
        assert db._is_valid_field_name("'")
        assert not db._is_valid_field_name("")
        assert db._is_valid_field_name("foo%bar")

    def test_is_valid_table_name(self):
        assert db._is_valid_table_name("foo")
        assert db._is_valid_table_name("foo bar")
        assert db._is_valid_table_name("42")
        assert not db._is_valid_table_name('foo"bar')
        assert not db._is_valid_table_name('"')
        assert db._is_valid_table_name("'")
        assert not db._is_valid_table_name("")
        assert not db._is_valid_table_name("foo%bar")

    def test_pg_version_check(self):
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        engine = db._get_engine(
            {'connection_url': pylons.config['sqlalchemy.url']})
        connection = engine.connect()
        assert db._pg_version_is_at_least(connection, '8.0')
        assert not db._pg_version_is_at_least(connection, '10.0')

########NEW FILE########
__FILENAME__ = test_upsert
import json
import nose
import datetime

import pylons
import sqlalchemy.orm as orm

import ckan.plugins as p
import ckan.lib.create_test_data as ctd
import ckan.model as model
import ckan.tests as tests

import ckanext.datastore.db as db
from ckanext.datastore.tests.helpers import rebuild_all_dbs, set_url_type


class TestDatastoreUpsert(tests.WsgiAppCase):
    sysadmin_user = None
    normal_user = None

    @classmethod
    def setup_class(cls):
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        p.load('datastore')
        ctd.CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        set_url_type(
            model.Package.get('annakarenina').resources, cls.sysadmin_user)
        resource = model.Package.get('annakarenina').resources[0]
        cls.data = {
            'resource_id': resource.id,
            'fields': [{'id': u'b\xfck', 'type': 'text'},
                       {'id': 'author', 'type': 'text'},
                       {'id': 'nested', 'type': 'json'},
                       {'id': 'characters', 'type': 'text[]'},
                       {'id': 'published'}],
            'primary_key': u'b\xfck',
            'records': [{u'b\xfck': 'annakarenina', 'author': 'tolstoy',
                        'published': '2005-03-01', 'nested': ['b', {'moo': 'moo'}]},
                        {u'b\xfck': 'warandpeace', 'author': 'tolstoy',
                        'nested': {'a':'b'}}
                       ]
            }
        postparams = '%s=1' % json.dumps(cls.data)
        auth = {'Authorization': str(cls.sysadmin_user.apikey)}
        res = cls.app.post('/api/action/datastore_create', params=postparams,
                           extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        engine = db._get_engine(
            {'connection_url': pylons.config['ckan.datastore.write_url']})
        cls.Session = orm.scoped_session(orm.sessionmaker(bind=engine))

    @classmethod
    def teardown_class(cls):
        rebuild_all_dbs(cls.Session)
        p.unload('datastore')

    def test_upsert_requires_auth(self):
        data = {
            'resource_id': self.data['resource_id']
        }
        postparams = '%s=1' % json.dumps(data)
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            status=403)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_upsert_empty_fails(self):
        postparams = '%s=1' % json.dumps({})
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is False

    def test_upsert_basic(self):
        c = self.Session.connection()
        results = c.execute('select 1 from "{0}"'.format(self.data['resource_id']))
        assert results.rowcount == 2
        self.Session.remove()

        hhguide = u"hitchhiker's guide to the galaxy"

        data = {
            'resource_id': self.data['resource_id'],
            'method': 'upsert',
            'records': [{
                'author': 'adams',
                'nested': {'a': 2, 'b': {'c': 'd'}},
                'characters': ['Arthur Dent', 'Marvin'],
                'nested': {'foo': 'bar'},
                u'b\xfck': hhguide}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(self.data['resource_id']))
        assert results.rowcount == 3

        records = results.fetchall()
        assert records[2][u'b\xfck'] == hhguide
        assert records[2].author == 'adams'
        assert records[2].characters == ['Arthur Dent', 'Marvin']
        assert json.loads(records[2].nested.json) == {'foo': 'bar'}
        self.Session.remove()

        c = self.Session.connection()
        results = c.execute("select * from \"{0}\" where author='{1}'".format(self.data['resource_id'], 'adams'))
        assert results.rowcount == 1
        self.Session.remove()

        # upsert only the publish date
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'upsert',
            'records': [{'published': '1979-1-1', u'b\xfck': hhguide}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(self.data['resource_id']))
        assert results.rowcount == 3

        records = results.fetchall()
        assert records[2][u'b\xfck'] == hhguide
        assert records[2].author == 'adams'
        assert records[2].published == datetime.datetime(1979, 1, 1)
        self.Session.remove()

        # delete publish date
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'upsert',
            'records': [{u'b\xfck': hhguide, 'published': None}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(self.data['resource_id']))
        assert results.rowcount == 3

        records = results.fetchall()
        assert records[2][u'b\xfck'] == hhguide
        assert records[2].author == 'adams'
        assert records[2].published == None
        self.Session.remove()

        data = {
            'resource_id': self.data['resource_id'],
            'method': 'upsert',
            'records': [{'author': 'tolkien', u'b\xfck': 'the hobbit'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(self.data['resource_id']))
        assert results.rowcount == 4

        records = results.fetchall()
        assert records[3][u'b\xfck'] == 'the hobbit'
        assert records[3].author == 'tolkien'
        self.Session.remove()

        # test % in records
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'upsert',
            'records': [{'author': 'tol % kien', u'b\xfck': 'the % hobbit'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

    def test_upsert_missing_key(self):
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'upsert',
            'records': [{'author': 'tolkien'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False

    def test_upsert_non_existing_field(self):
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'upsert',
            'records': [{u'b\xfck': 'annakarenina', 'dummy': 'tolkien'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False


class TestDatastoreInsert(tests.WsgiAppCase):
    sysadmin_user = None
    normal_user = None

    @classmethod
    def setup_class(cls):
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        p.load('datastore')
        ctd.CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        set_url_type(
            model.Package.get('annakarenina').resources, cls.sysadmin_user)
        resource = model.Package.get('annakarenina').resources[0]
        cls.data = {
            'resource_id': resource.id,
            'fields': [{'id': u'b\xfck', 'type': 'text'},
                       {'id': 'author', 'type': 'text'},
                       {'id': 'nested', 'type': 'json'},
                       {'id': 'characters', 'type': 'text[]'},
                       {'id': 'published'}],
            'primary_key': u'b\xfck',
            'records': [{u'b\xfck': 'annakarenina', 'author': 'tolstoy',
                        'published': '2005-03-01', 'nested': ['b', {'moo': 'moo'}]},
                        {u'b\xfck': 'warandpeace', 'author': 'tolstoy',
                        'nested': {'a':'b'}}
                       ]
            }
        postparams = '%s=1' % json.dumps(cls.data)
        auth = {'Authorization': str(cls.sysadmin_user.apikey)}
        res = cls.app.post('/api/action/datastore_create', params=postparams,
                           extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        engine = db._get_engine(
            {'connection_url': pylons.config['ckan.datastore.write_url']})
        cls.Session = orm.scoped_session(orm.sessionmaker(bind=engine))

    @classmethod
    def teardown_class(cls):
        p.unload('datastore')
        rebuild_all_dbs(cls.Session)

    def test_insert_non_existing_field(self):
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'insert',
            'records': [{u'b\xfck': 'the hobbit', 'dummy': 'tolkien'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False

    def test_insert_with_index_violation(self):
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'insert',
            'records': [{u'b\xfck': 'annakarenina'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False

    def test_insert_basic(self):
        hhguide = u"hitchhiker's guide to the galaxy"
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'insert',
            'records': [{
                'author': 'adams',
                'characters': ['Arthur Dent', 'Marvin'],
                'nested': {'foo': 'bar', 'baz': 3},
                u'b\xfck': hhguide}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(self.data['resource_id']))
        self.Session.remove()

        assert results.rowcount == 3


class TestDatastoreUpdate(tests.WsgiAppCase):
    sysadmin_user = None
    normal_user = None

    @classmethod
    def setup_class(cls):
        if not tests.is_datastore_supported():
            raise nose.SkipTest("Datastore not supported")
        p.load('datastore')
        ctd.CreateTestData.create()
        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.normal_user = model.User.get('annafan')
        set_url_type(
            model.Package.get('annakarenina').resources, cls.sysadmin_user)
        resource = model.Package.get('annakarenina').resources[0]
        hhguide = u"hitchhiker's guide to the galaxy"
        cls.data = {
            'resource_id': resource.id,
            'fields': [{'id': u'b\xfck', 'type': 'text'},
                       {'id': 'author', 'type': 'text'},
                       {'id': 'nested', 'type': 'json'},
                       {'id': 'characters', 'type': 'text[]'},
                       {'id': 'published'}],
            'primary_key': u'b\xfck',
            'records': [{u'b\xfck': 'annakarenina', 'author': 'tolstoy',
                        'published': '2005-03-01', 'nested': ['b', {'moo': 'moo'}]},
                        {u'b\xfck': 'warandpeace', 'author': 'tolstoy',
                        'nested': {'a':'b'}},
                        {'author': 'adams',
                        'characters': ['Arthur Dent', 'Marvin'],
                        'nested': {'foo': 'bar'},
                        u'b\xfck': hhguide}
                       ]
            }
        postparams = '%s=1' % json.dumps(cls.data)
        auth = {'Authorization': str(cls.sysadmin_user.apikey)}
        res = cls.app.post('/api/action/datastore_create', params=postparams,
                           extra_environ=auth)
        res_dict = json.loads(res.body)
        assert res_dict['success'] is True

        engine = db._get_engine(
            {'connection_url': pylons.config['ckan.datastore.write_url']})
        cls.Session = orm.scoped_session(orm.sessionmaker(bind=engine))

    @classmethod
    def teardown_class(cls):
        p.unload('datastore')
        rebuild_all_dbs(cls.Session)

    def test_update_basic(self):
        c = self.Session.connection()
        results = c.execute('select 1 from "{0}"'.format(self.data['resource_id']))
        assert results.rowcount == 3, results.rowcount
        self.Session.remove()

        hhguide = u"hitchhiker's guide to the galaxy"
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'update',
            'records': [{
                'author': 'adams',
                'characters': ['Arthur Dent', 'Marvin'],
                'nested': {'baz': 3},
                u'b\xfck': hhguide}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(self.data['resource_id']))
        assert results.rowcount == 3

        records = results.fetchall()
        assert records[2][u'b\xfck'] == hhguide
        assert records[2].author == 'adams'
        self.Session.remove()

        c = self.Session.connection()
        results = c.execute("select * from \"{0}\" where author='{1}'".format(self.data['resource_id'], 'adams'))
        assert results.rowcount == 1
        self.Session.remove()

        # update only the publish date
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'update',
            'records': [{'published': '1979-1-1', u'b\xfck': hhguide}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(self.data['resource_id']))
        self.Session.remove()
        assert results.rowcount == 3

        records = results.fetchall()
        assert records[2][u'b\xfck'] == hhguide
        assert records[2].author == 'adams'
        assert records[2].published == datetime.datetime(1979, 1, 1)

        # delete publish date
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'update',
            'records': [{u'b\xfck': hhguide, 'published': None}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is True

        c = self.Session.connection()
        results = c.execute('select * from "{0}"'.format(self.data['resource_id']))
        self.Session.remove()
        assert results.rowcount == 3

        records = results.fetchall()
        assert records[2][u'b\xfck'] == hhguide
        assert records[2].author == 'adams'
        assert records[2].published == None

    def test_update_missing_key(self):
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'update',
            'records': [{'author': 'tolkien'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False

    def test_update_non_existing_key(self):
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'update',
            'records': [{u'b\xfck': '', 'author': 'tolkien'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False

    def test_update_non_existing_field(self):
        data = {
            'resource_id': self.data['resource_id'],
            'method': 'update',
            'records': [{u'b\xfck': 'annakarenina', 'dummy': 'tolkien'}]
        }

        postparams = '%s=1' % json.dumps(data)
        auth = {'Authorization': str(self.sysadmin_user.apikey)}
        res = self.app.post('/api/action/datastore_upsert', params=postparams,
                            extra_environ=auth, status=409)
        res_dict = json.loads(res.body)

        assert res_dict['success'] is False

########NEW FILE########
__FILENAME__ = plugin_v1
import ckan.plugins as plugins


class ExampleIAuthFunctionsPlugin(plugins.SingletonPlugin):
    pass

########NEW FILE########
__FILENAME__ = plugin_v2
import ckan.plugins as plugins


def group_create(context, data_dict=None):
    return {'success': False, 'msg': 'No one is allowed to create groups'}


class ExampleIAuthFunctionsPlugin(plugins.SingletonPlugin):
    plugins.implements(plugins.IAuthFunctions)

    def get_auth_functions(self):
        return {'group_create': group_create}

########NEW FILE########
__FILENAME__ = plugin_v3
import ckan.plugins as plugins
import ckan.plugins.toolkit as toolkit


def group_create(context, data_dict=None):

    # Get the user name of the logged-in user.
    user_name = context['user']

    # Get a list of the members of the 'curators' group.
    members = toolkit.get_action('member_list')(
        data_dict={'id': 'curators', 'object_type': 'user'})

    # 'members' is a list of (user_id, object_type, capacity) tuples, we're
    # only interested in the user_ids.
    member_ids = [member_tuple[0] for member_tuple in members]

    # We have the logged-in user's user name, get their user id.
    convert_user_name_or_id_to_id = toolkit.get_converter(
        'convert_user_name_or_id_to_id')
    user_id = convert_user_name_or_id_to_id(user_name, context)

    # Finally, we can test whether the user is a member of the curators group.
    if user_id in member_ids:
        return {'success': True}
    else:
        return {'success': False,
                'msg': 'Only curators are allowed to create groups'}


class ExampleIAuthFunctionsPlugin(plugins.SingletonPlugin):
    plugins.implements(plugins.IAuthFunctions)

    def get_auth_functions(self):
        return {'group_create': group_create}

########NEW FILE########
__FILENAME__ = plugin_v4
import ckan.plugins as plugins
import ckan.plugins.toolkit as toolkit


def group_create(context, data_dict=None):
    # Get the user name of the logged-in user.
    user_name = context['user']

    # Get a list of the members of the 'curators' group.
    try:
        members = toolkit.get_action('member_list')(
            data_dict={'id': 'curators', 'object_type': 'user'})
    except toolkit.ObjectNotFound:
        # The curators group doesn't exist.
        return {'success': False,
                'msg': "The curators groups doesn't exist, so only sysadmins "
                       "are authorized to create groups."}

    # 'members' is a list of (user_id, object_type, capacity) tuples, we're
    # only interested in the user_ids.
    member_ids = [member_tuple[0] for member_tuple in members]

    # We have the logged-in user's user name, get their user id.
    convert_user_name_or_id_to_id = toolkit.get_converter(
        'convert_user_name_or_id_to_id')
    try:
        user_id = convert_user_name_or_id_to_id(user_name, context)
    except toolkit.Invalid:
        # The user doesn't exist (e.g. they're not logged-in).
        return {'success': False,
                'msg': 'You must be logged-in as a member of the curators '
                       'group to create new groups.'}

    # Finally, we can test whether the user is a member of the curators group.
    if user_id in member_ids:
        return {'success': True}
    else:
        return {'success': False,
                'msg': 'Only curators are allowed to create groups'}


class ExampleIAuthFunctionsPlugin(plugins.SingletonPlugin):
    plugins.implements(plugins.IAuthFunctions)

    def get_auth_functions(self):
        return {'group_create': group_create}

########NEW FILE########
__FILENAME__ = plugin_v5_custom_config_setting
import pylons.config as config

import ckan.plugins as plugins
import ckan.plugins.toolkit as toolkit


def group_create(context, data_dict=None):

    # Get the value of the ckan.iauthfunctions.users_can_create_groups
    # setting from the CKAN config file as a string, or False if the setting
    # isn't in the config file.
    users_can_create_groups = config.get(
        'ckan.iauthfunctions.users_can_create_groups', False)

    # Convert the value from a string to a boolean.
    users_can_create_groups = toolkit.asbool(users_can_create_groups)

    if users_can_create_groups:
        return {'success': True}
    else:
        return {'success': False,
                'msg': 'Only sysadmins can create groups'}


class ExampleIAuthFunctionsPlugin(plugins.SingletonPlugin):
    plugins.implements(plugins.IAuthFunctions)

    def get_auth_functions(self):
        return {'group_create': group_create}

########NEW FILE########
__FILENAME__ = test_example_iauthfunctions
'''Tests for the ckanext.example_iauthfunctions extension.

'''
import paste.fixture
import pylons.test
import pylons.config as config
import webtest

import ckan.model as model
import ckan.tests as tests
import ckan.plugins
import ckan.new_tests.factories as factories


class TestExampleIAuthFunctionsCustomConfigSetting(object):
    '''Tests for the plugin_v5_custom_config_setting module.

    '''
    def _get_app(self, users_can_create_groups):

        # Set the custom config option in pylons.config.
        config['ckan.iauthfunctions.users_can_create_groups'] = (
            users_can_create_groups)

        # Return a test app with the custom config.
        app = ckan.config.middleware.make_app(config['global_conf'], **config)
        app = webtest.TestApp(app)

        ckan.plugins.load('example_iauthfunctions_v5_custom_config_setting')

        return app

    def teardown(self):

        # Remove the custom config option from pylons.config.
        del config['ckan.iauthfunctions.users_can_create_groups']

        # Delete any stuff that's been created in the db, so it doesn't
        # interfere with the next test.
        model.repo.rebuild_db()

    @classmethod
    def teardown_class(cls):
        ckan.plugins.unload('example_iauthfunctions_v5_custom_config_setting')

    def test_sysadmin_can_create_group_when_config_is_False(self):
        app = self._get_app(users_can_create_groups=False)
        sysadmin = factories.Sysadmin()

        tests.call_action_api(app, 'group_create', name='test-group',
                              apikey=sysadmin['apikey'])

    def test_user_cannot_create_group_when_config_is_False(self):
        app = self._get_app(users_can_create_groups=False)
        user = factories.User()

        tests.call_action_api(app, 'group_create', name='test-group',
                              apikey=user['apikey'], status=403)

    def test_visitor_cannot_create_group_when_config_is_False(self):
        app = self._get_app(users_can_create_groups=False)

        tests.call_action_api(app, 'group_create', name='test-group',
                              status=403)

    def test_sysadmin_can_create_group_when_config_is_True(self):
        app = self._get_app(users_can_create_groups=True)
        sysadmin = factories.Sysadmin()

        tests.call_action_api(app, 'group_create', name='test-group',
                              apikey=sysadmin['apikey'])

    def test_user_can_create_group_when_config_is_True(self):
        app = self._get_app(users_can_create_groups=True)
        user = factories.User()

        tests.call_action_api(app, 'group_create', name='test-group',
                              apikey=user['apikey'])

    def test_visitor_cannot_create_group_when_config_is_True(self):
        app = self._get_app(users_can_create_groups=True)

        tests.call_action_api(app, 'group_create', name='test-group',
                              status=403)


class TestExampleIAuthFunctionsPluginV4(object):
    '''Tests for the ckanext.example_iauthfunctions.plugin module.

    '''
    @classmethod
    def setup_class(cls):
        '''Nose runs this method once to setup our test class.'''

        # Make the Paste TestApp that we'll use to simulate HTTP requests to
        # CKAN.
        cls.app = paste.fixture.TestApp(pylons.test.pylonsapp)

        # Test code should use CKAN's plugins.load() function to load plugins
        # to be tested.
        ckan.plugins.load('example_iauthfunctions_v4')

    def teardown(self):
        '''Nose runs this method after each test method in our test class.'''

        # Rebuild CKAN's database after each test method, so that each test
        # method runs with a clean slate.
        model.repo.rebuild_db()

    @classmethod
    def teardown_class(cls):
        '''Nose runs this method once after all the test methods in our class
        have been run.

        '''
        # We have to unload the plugin we loaded, so it doesn't affect any
        # tests that run after ours.
        ckan.plugins.unload('example_iauthfunctions_v4')

    def _make_curators_group(self):
        '''This is a helper method for test methods to call when they want
        the 'curators' group to be created.

        '''
        sysadmin = factories.Sysadmin()

        # Create a user who will *not* be a member of the curators group.
        noncurator = factories.User()

        # Create a user who will be a member of the curators group.
        curator = factories.User()

        # Create the curators group, with the 'curator' user as a member.
        users = [{'name': curator['name'], 'capacity': 'member'}]
        curators_group = tests.call_action_api(self.app, 'group_create',
                                               apikey=sysadmin['apikey'],
                                               name='curators',
                                               users=users)

        return (noncurator, curator, curators_group)

    def test_group_create_with_no_curators_group(self):
        '''Test that group_create doesn't crash when there's no curators group.

        '''
        sysadmin = factories.Sysadmin()

        # Make sure there's no curators group.
        assert 'curators' not in tests.call_action_api(self.app, 'group_list')

        # Make our sysadmin user create a group. CKAN should not crash.
        tests.call_action_api(self.app, 'group_create', name='test-group',
                              apikey=sysadmin['apikey'])

    def test_group_create_with_visitor(self):
        '''A visitor (not logged in) should not be able to create a group.

        Note: this also tests that the group_create auth function doesn't
        crash when the user isn't logged in.

        '''
        noncurator, curator, curators_group = self._make_curators_group()
        result = tests.call_action_api(self.app, 'group_create',
                                       name='this_group_should_not_be_created',
                                       status=403)
        assert result['__type'] == 'Authorization Error'

    def test_group_create_with_non_curator(self):
        '''A user who isn't a member of the curators group should not be able
        to create a group.

        '''
        noncurator, curator, curators_group = self._make_curators_group()
        result = tests.call_action_api(self.app, 'group_create',
                                       name='this_group_should_not_be_created',
                                       apikey=noncurator['apikey'],
                                       status=403)
        assert result['__type'] == 'Authorization Error'

    def test_group_create_with_curator(self):
        '''A member of the curators group should be able to create a group.

        '''
        noncurator, curator, curators_group = self._make_curators_group()
        name = 'my-new-group'
        result = tests.call_action_api(self.app, 'group_create',
                                       name=name,
                                       apikey=curator['apikey'])
        assert result['name'] == name


class TestExampleIAuthFunctionsPluginV3(TestExampleIAuthFunctionsPluginV4):
    '''Tests for the ckanext.example_iauthfunctions.plugin_v3 module.

    '''
    @classmethod
    def setup_class(cls):
        cls.app = paste.fixture.TestApp(pylons.test.pylonsapp)
        ckan.plugins.load('example_iauthfunctions_v3')

    @classmethod
    def teardown_class(cls):
        ckan.plugins.unload('example_iauthfunctions_v3')

    def test_group_create_with_no_curators_group(self):
        '''Test that group_create returns a 404 when there's no curators group.

        With this version of the plugin group_create returns a spurious 404
        when a user _is_ logged-in but the site has no curators group.

        '''
        assert 'curators' not in tests.call_action_api(self.app, 'group_list')

        user = factories.User()

        response = tests.call_action_api(self.app, 'group_create',
                                         name='test_group',
                                         apikey=user['apikey'], status=404)
        assert response == {'__type': 'Not Found Error',
                            'message': 'Not found'}

    def test_group_create_with_visitor(self):
        '''Test that group_create returns 403 when no one is logged in.

        Since #1210 non-logged in requests are automatically rejected, unless
        the auth function has the appropiate decorator
        '''

        noncurator, curator, curators_group = self._make_curators_group()
        response = tests.call_action_api(self.app, 'group_create',
                                         name='this_group_shouldnt_be_created',
                                         status=403)
        assert response['__type'] == 'Authorization Error'


class TestExampleIAuthFunctionsPluginV2(TestExampleIAuthFunctionsPluginV4):
    '''Tests for the ckanext.example_iauthfunctions.plugin_v2 module.

    '''
    @classmethod
    def setup_class(cls):
        cls.app = paste.fixture.TestApp(pylons.test.pylonsapp)
        ckan.plugins.load('example_iauthfunctions_v2')

    @classmethod
    def teardown_class(cls):
        ckan.plugins.unload('example_iauthfunctions_v2')

    def test_group_create_with_curator(self):
        '''Test that a curator can*not* create a group.

        In this version of the plugin, even users who are members of the
        curators group cannot create groups.

        '''
        noncurator, curator, curators_group = self._make_curators_group()
        result = tests.call_action_api(self.app, 'group_create',
                                       name='this_group_should_not_be_created',
                                       apikey=curator['apikey'],
                                       status=403)
        assert result['__type'] == 'Authorization Error'

########NEW FILE########
__FILENAME__ = plugin
import logging

import ckan.plugins as plugins
import ckan.plugins.toolkit as tk


def create_country_codes():
    '''Create country_codes vocab and tags, if they don't exist already.

    Note that you could also create the vocab and tags using CKAN's API,
    and once they are created you can edit them (e.g. to add and remove
    possible dataset country code values) using the API.

    '''
    user = tk.get_action('get_site_user')({'ignore_auth': True}, {})
    context = {'user': user['name']}
    try:
        data = {'id': 'country_codes'}
        tk.get_action('vocabulary_show')(context, data)
        logging.info("Example genre vocabulary already exists, skipping.")
    except tk.ObjectNotFound:
        logging.info("Creating vocab 'country_codes'")
        data = {'name': 'country_codes'}
        vocab = tk.get_action('vocabulary_create')(context, data)
        for tag in (u'uk', u'ie', u'de', u'fr', u'es'):
            logging.info(
                    "Adding tag {0} to vocab 'country_codes'".format(tag))
            data = {'name': tag, 'vocabulary_id': vocab['id']}
            tk.get_action('tag_create')(context, data)


def country_codes():
    '''Return the list of country codes from the country codes vocabulary.'''
    create_country_codes()
    try:
        country_codes = tk.get_action('tag_list')(
                data_dict={'vocabulary_id': 'country_codes'})
        return country_codes
    except tk.ObjectNotFound:
        return None


class ExampleIDatasetFormPlugin(plugins.SingletonPlugin,
        tk.DefaultDatasetForm):
    '''An example IDatasetForm CKAN plugin.

    Uses a tag vocabulary to add a custom metadata field to datasets.

    '''
    plugins.implements(plugins.IConfigurer, inherit=False)
    plugins.implements(plugins.IDatasetForm, inherit=False)
    plugins.implements(plugins.ITemplateHelpers, inherit=False)

    # These record how many times methods that this plugin's methods are
    # called, for testing purposes.
    num_times_new_template_called = 0
    num_times_read_template_called = 0
    num_times_edit_template_called = 0
    num_times_search_template_called = 0
    num_times_history_template_called = 0
    num_times_package_form_called = 0
    num_times_check_data_dict_called = 0
    num_times_setup_template_variables_called = 0

    def update_config(self, config):
        # Add this plugin's templates dir to CKAN's extra_template_paths, so
        # that CKAN will use this plugin's custom templates.
        tk.add_template_directory(config, 'templates')

    def get_helpers(self):
        return {'country_codes': country_codes}

    def is_fallback(self):
        # Return True to register this plugin as the default handler for
        # package types not handled by any other IDatasetForm plugin.
        return True

    def package_types(self):
        # This plugin doesn't handle any special package types, it just
        # registers itself as the default (above).
        return []

    def _modify_package_schema(self, schema):
        # Add our custom country_code metadata field to the schema.
        schema.update({
                'country_code': [tk.get_validator('ignore_missing'),
                    tk.get_converter('convert_to_tags')('country_codes')]
                })
        # Add our custom_test metadata field to the schema, this one will use
        # convert_to_extras instead of convert_to_tags.
        schema.update({
                'custom_text': [tk.get_validator('ignore_missing'),
                    tk.get_converter('convert_to_extras')]
                })
        # Add our custom_resource_text metadata field to the schema
        schema['resources'].update({
                'custom_resource_text' : [ tk.get_validator('ignore_missing') ]
                })
        return schema

    def create_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).create_package_schema()
        schema = self._modify_package_schema(schema)
        return schema

    def update_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).update_package_schema()
        schema = self._modify_package_schema(schema)
        return schema

    def show_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).show_package_schema()

        # Don't show vocab tags mixed in with normal 'free' tags
        # (e.g. on dataset pages, or on the search page)
        schema['tags']['__extras'].append(tk.get_converter('free_tags_only'))

        # Add our custom country_code metadata field to the schema.
        schema.update({
            'country_code': [
                tk.get_converter('convert_from_tags')('country_codes'),
                tk.get_validator('ignore_missing')]
            })

        # Add our custom_text field to the dataset schema.
        schema.update({
            'custom_text': [tk.get_converter('convert_from_extras'),
                tk.get_validator('ignore_missing')]
            })

        schema['resources'].update({
                'custom_resource_text' : [ tk.get_validator('ignore_missing') ]
            })
        return schema

    # These methods just record how many times they're called, for testing
    # purposes.
    # TODO: It might be better to test that custom templates returned by
    # these methods are actually used, not just that the methods get
    # called.

    def setup_template_variables(self, context, data_dict):
        ExampleIDatasetFormPlugin.num_times_setup_template_variables_called += 1
        return super(ExampleIDatasetFormPlugin, self).setup_template_variables(
                context, data_dict)

    def new_template(self):
        ExampleIDatasetFormPlugin.num_times_new_template_called += 1
        return super(ExampleIDatasetFormPlugin, self).new_template()

    def read_template(self):
        ExampleIDatasetFormPlugin.num_times_read_template_called += 1
        return super(ExampleIDatasetFormPlugin, self).read_template()

    def edit_template(self):
        ExampleIDatasetFormPlugin.num_times_edit_template_called += 1
        return super(ExampleIDatasetFormPlugin, self).edit_template()

    def search_template(self):
        ExampleIDatasetFormPlugin.num_times_search_template_called += 1
        return super(ExampleIDatasetFormPlugin, self).search_template()

    def history_template(self):
        ExampleIDatasetFormPlugin.num_times_history_template_called += 1
        return super(ExampleIDatasetFormPlugin, self).history_template()

    def package_form(self):
        ExampleIDatasetFormPlugin.num_times_package_form_called += 1
        return super(ExampleIDatasetFormPlugin, self).package_form()

    # check_data_dict() is deprecated, this method is only here to test that
    # legacy support for the deprecated method works.
    def check_data_dict(self, data_dict, schema=None):
        ExampleIDatasetFormPlugin.num_times_check_data_dict_called += 1

########NEW FILE########
__FILENAME__ = plugin_v1
import ckan.plugins as p
import ckan.plugins.toolkit as tk


class ExampleIDatasetFormPlugin(p.SingletonPlugin, tk.DefaultDatasetForm):
    p.implements(p.IDatasetForm)

    def create_package_schema(self):
        # let's grab the default schema in our plugin
        schema = super(ExampleIDatasetFormPlugin, self).create_package_schema()
        #our custom field
        schema.update({
            'custom_text': [tk.get_validator('ignore_missing'),
                            tk.get_converter('convert_to_extras')]
        })
        return schema

    def update_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).update_package_schema()
        #our custom field
        schema.update({
            'custom_text': [tk.get_validator('ignore_missing'),
                            tk.get_converter('convert_to_extras')]
        })
        return schema

    def show_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).show_package_schema()
        schema.update({
            'custom_text': [tk.get_converter('convert_from_extras'),
                            tk.get_validator('ignore_missing')]
        })
        return schema

    def is_fallback(self):
        # Return True to register this plugin as the default handler for
        # package types not handled by any other IDatasetForm plugin.
        return True

    def package_types(self):
        # This plugin doesn't handle any special package types, it just
        # registers itself as the default (above).
        return []

########NEW FILE########
__FILENAME__ = plugin_v2
import ckan.plugins as p
import ckan.plugins.toolkit as tk


class ExampleIDatasetFormPlugin(p.SingletonPlugin, tk.DefaultDatasetForm):
    p.implements(p.IDatasetForm)
    p.implements(p.IConfigurer)

    def create_package_schema(self):
        # let's grab the default schema in our plugin
        schema = super(ExampleIDatasetFormPlugin, self).create_package_schema()
        #our custom field
        schema.update({
            'custom_text': [tk.get_validator('ignore_missing'),
                            tk.get_converter('convert_to_extras')]
        })
        return schema

    def update_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).update_package_schema()
        #our custom field
        schema.update({
            'custom_text': [tk.get_validator('ignore_missing'),
                            tk.get_converter('convert_to_extras')]
        })
        return schema

    def show_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).show_package_schema()
        schema.update({
            'custom_text': [tk.get_converter('convert_from_extras'),
                            tk.get_validator('ignore_missing')]
        })
        return schema

    #is fall back
    def is_fallback(self):
        # Return True to register this plugin as the default handler for
        # package types not handled by any other IDatasetForm plugin.
        return True

    def package_types(self):
        # This plugin doesn't handle any special package types, it just
        # registers itself as the default (above).
        return []

    def update_config(self, config):
        # Add this plugin's templates dir to CKAN's extra_template_paths, so
        # that CKAN will use this plugin's custom templates.
        tk.add_template_directory(config, 'templates')

########NEW FILE########
__FILENAME__ = plugin_v3
'''Example IDatasetFormPlugin'''
import ckan.plugins as p
import ckan.plugins.toolkit as tk


class ExampleIDatasetFormPlugin(p.SingletonPlugin, tk.DefaultDatasetForm):
    p.implements(p.IDatasetForm)

    def _modify_package_schema(self, schema):
        schema.update({
            'custom_text': [tk.get_validator('ignore_missing'),
                            tk.get_converter('convert_to_extras')]
        })
        return schema

    def create_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).create_package_schema()
        schema = self._modify_package_schema(schema)
        return schema

    def update_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).update_package_schema()
        schema = self._modify_package_schema(schema)
        return schema

    def show_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).show_package_schema()
        schema.update({
            'custom_text': [tk.get_converter('convert_from_extras'),
                            tk.get_validator('ignore_missing')]
        })
        return schema

    def is_fallback(self):
        # Return True to register this plugin as the default handler for
        # package types not handled by any other IDatasetForm plugin.
        return True

    def package_types(self):
        # This plugin doesn't handle any special package types, it just
        # registers itself as the default (above).
        return []

########NEW FILE########
__FILENAME__ = plugin_v4
import ckan.plugins as p
import ckan.plugins.toolkit as tk


def create_country_codes():
    user = tk.get_action('get_site_user')({'ignore_auth': True}, {})
    context = {'user': user['name']}
    try:
        data = {'id': 'country_codes'}
        tk.get_action('vocabulary_show')(context, data)
    except tk.ObjectNotFound:
        data = {'name': 'country_codes'}
        vocab = tk.get_action('vocabulary_create')(context, data)
        for tag in (u'uk', u'ie', u'de', u'fr', u'es'):
            data = {'name': tag, 'vocabulary_id': vocab['id']}
            tk.get_action('tag_create')(context, data)


def country_codes():
    create_country_codes()
    try:
        tag_list = tk.get_action('tag_list')
        country_codes = tag_list(data_dict={'vocabulary_id': 'country_codes'})
        return country_codes
    except tk.ObjectNotFound:
        return None


class ExampleIDatasetFormPlugin(p.SingletonPlugin, tk.DefaultDatasetForm):
    p.implements(p.IDatasetForm)
    p.implements(p.IConfigurer)
    p.implements(p.ITemplateHelpers)

    def get_helpers(self):
        return {'country_codes': country_codes}

    def _modify_package_schema(self, schema):
        schema.update({
            'custom_text': [tk.get_validator('ignore_missing'),
                            tk.get_converter('convert_to_extras')]
        })
        schema.update({
            'country_code': [
                tk.get_validator('ignore_missing'),
                tk.get_converter('convert_to_tags')('country_codes')
            ]
        })
        return schema

    def show_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).show_package_schema()
        schema.update({
            'custom_text': [tk.get_converter('convert_from_extras'),
                            tk.get_validator('ignore_missing')]
        })

        schema['tags']['__extras'].append(tk.get_converter('free_tags_only'))
        schema.update({
            'country_code': [
                tk.get_converter('convert_from_tags')('country_codes'),
                tk.get_validator('ignore_missing')]
            })
        return schema

    def create_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).create_package_schema()
        schema = self._modify_package_schema(schema)
        return schema

    def update_package_schema(self):
        schema = super(ExampleIDatasetFormPlugin, self).update_package_schema()
        schema = self._modify_package_schema(schema)
        return schema

    def is_fallback(self):
        # Return True to register this plugin as the default handler for
        # package types not handled by any other IDatasetForm plugin.
        return True

    def package_types(self):
        # This plugin doesn't handle any special package types, it just
        # registers itself as the default (above).
        return []

    #update config
    def update_config(self, config):
        # Add this plugin's templates dir to CKAN's extra_template_paths, so
        # that CKAN will use this plugin's custom templates.
        tk.add_template_directory(config, 'templates')

########NEW FILE########
__FILENAME__ = test_example_idatasetform
import nose.tools as nt

import pylons.config as config

import ckan.model as model
import ckan.plugins as plugins
import ckan.new_tests.helpers as helpers
import ckanext.example_idatasetform as idf
import ckan.lib.search


class ExampleIDatasetFormPluginBase(object):
    '''Version 1, 2 and 3 of the plugin are basically the same, so this class
    provides the tests that all three versions of the plugins will run'''
    @classmethod
    def setup_class(cls):
        cls.original_config = config.copy()

    def teardown(self):
        model.repo.rebuild_db()
        ckan.lib.search.clear()

    @classmethod
    def teardown_class(cls):
        helpers.reset_db()
        model.repo.rebuild_db()
        ckan.lib.search.clear()

        config.clear()
        config.update(cls.original_config)

    def test_package_create(self):
        result = helpers.call_action('package_create', name='test_package',
                                     custom_text='this is my custom text')
        nt.assert_equals('this is my custom text', result['custom_text'])

    def test_package_update(self):
        helpers.call_action('package_create', name='test_package',
                            custom_text='this is my custom text')
        result = helpers.call_action('package_update', name='test_package',
                                     custom_text='this is my updated text')
        nt.assert_equals('this is my updated text', result['custom_text'])

    def test_package_show(self):
        helpers.call_action('package_create', name='test_package',
                            custom_text='this is my custom text')
        result = helpers.call_action('package_show', name_or_id='test_package')
        nt.assert_equals('this is my custom text', result['custom_text'])


class TestVersion1(ExampleIDatasetFormPluginBase):
    @classmethod
    def setup_class(cls):
        super(TestVersion1, cls).setup_class()
        plugins.load('example_idatasetform_v1')

    @classmethod
    def teardown_class(cls):
        plugins.unload('example_idatasetform_v1')
        super(TestVersion1, cls).teardown_class()


class TestVersion2(ExampleIDatasetFormPluginBase):
    @classmethod
    def setup_class(cls):
        super(TestVersion2, cls).setup_class()
        plugins.load('example_idatasetform_v2')

    @classmethod
    def teardown_class(cls):
        plugins.unload('example_idatasetform_v2')
        super(TestVersion2, cls).teardown_class()


class TestVersion3(ExampleIDatasetFormPluginBase):
    @classmethod
    def setup_class(cls):
        super(TestVersion3, cls).setup_class()
        plugins.load('example_idatasetform_v3')

    @classmethod
    def teardown_class(cls):
        plugins.unload('example_idatasetform_v3')
        super(TestVersion3, cls).teardown_class()


class TestIDatasetFormPluginVersion4(object):
    @classmethod
    def setup_class(cls):
        cls.original_config = config.copy()
        plugins.load('example_idatasetform_v4')

    def teardown(self):
        model.repo.rebuild_db()

    @classmethod
    def teardown_class(cls):
        plugins.unload('example_idatasetform_v4')
        helpers.reset_db()
        ckan.lib.search.clear()

        config.clear()
        config.update(cls.original_config)

    def test_package_create(self):
        idf.plugin_v4.create_country_codes()
        result = helpers.call_action('package_create', name='test_package',
                                     custom_text='this is my custom text',
                                     country_code='uk')
        nt.assert_equals('this is my custom text', result['custom_text'])
        nt.assert_equals([u'uk'], result['country_code'])

    def test_package_create_wrong_country_code(self):
        idf.plugin_v4.create_country_codes()
        nt.assert_raises(plugins.toolkit.ValidationError,
                         helpers.call_action,
                         'package_create',
                         name='test_package',
                         custom_text='this is my custom text',
                         country_code='notcode')

    def test_package_update(self):
        idf.plugin_v4.create_country_codes()
        helpers.call_action('package_create', name='test_package',
                            custom_text='this is my custom text',
                            country_code='uk')
        result = helpers.call_action('package_update', name='test_package',
                                     custom_text='this is my updated text',
                                     country_code='ie')
        nt.assert_equals('this is my updated text', result['custom_text'])
        nt.assert_equals([u'ie'], result['country_code'])


class TestIDatasetFormPlugin(object):
    @classmethod
    def setup_class(cls):
        cls.original_config = config.copy()
        plugins.load('example_idatasetform')

    def teardown(self):
        model.repo.rebuild_db()
        ckan.lib.search.clear()

    @classmethod
    def teardown_class(cls):
        plugins.unload('example_idatasetform')
        helpers.reset_db()
        ckan.lib.search.clear()

        config.clear()
        config.update(cls.original_config)

    def test_package_create(self):
        idf.plugin.create_country_codes()
        result = helpers.call_action(
            'package_create', name='test_package',
            custom_text='this is my custom text', country_code='uk',
            resources=[{
                'url': 'http://test.com/',
                'custom_resource_text': 'my custom resource',
            }])
        nt.assert_equals('my custom resource',
                         result['resources'][0]['custom_resource_text'])

    def test_package_update(self):
        idf.plugin.create_country_codes()
        helpers.call_action(
            'package_create', name='test_package',
            custom_text='this is my custom text', country_code='uk',
            resources=[{
                'url': 'http://test.com/',
                'custom_resource_text': 'my custom resource',
            }])
        result = helpers.call_action(
            'package_update',
            name='test_package',
            custom_text='this is my updated text',
            country_code='ie',
            resources=[{
                'url': 'http://test.com/',
                'custom_resource_text': 'updated custom resource',
            }]
        )
        nt.assert_equals('this is my updated text', result['custom_text'])
        nt.assert_equals([u'ie'], result['country_code'])
        nt.assert_equals('updated custom resource',
                         result['resources'][0]['custom_resource_text'])

    def test_package_show(self):
        idf.plugin.create_country_codes()
        helpers.call_action(
            'package_create', name='test_package',
            custom_text='this is my custom text', country_code='uk',
            resources=[{
                'url': 'http://test.com/',
                'custom_resource_text': 'my custom resource',
            }]
        )
        result = helpers.call_action('package_show', name_or_id='test_package')
        nt.assert_equals('my custom resource',
                         result['resources'][0]['custom_resource_text'])
        nt.assert_equals('my custom resource',
                         result['resources'][0]['custom_resource_text'])


class TestCustomSearch(object):
    @classmethod
    def setup_class(cls):
        cls.original_config = config.copy()
        cls.app = helpers._get_test_app()
        plugins.load('example_idatasetform')

    def teardown(self):
        model.repo.rebuild_db()
        ckan.lib.search.clear()

    @classmethod
    def teardown_class(cls):
        plugins.unload('example_idatasetform')
        helpers.reset_db()
        ckan.lib.search.clear()

        config.clear()
        config.update(cls.original_config)

    def test_custom_search(self):
        helpers.call_action('package_create', name='test_package_a',
                            custom_text='z')
        helpers.call_action('package_create', name='test_package_b',
                            custom_text='y')

        response = self.app.get('/dataset')

        # change the sort by form to our custom_text ascending
        response.forms[1].fields['sort'][0].value = 'custom_text asc'
        response = response.forms[1].submit()
        # check that package_b appears before package a (y < z)
        a = response.body.index('test_package_a')
        b = response.body.index('test_package_b')
        nt.assert_true(b < a)

        response.forms[1].fields['sort'][0].value = 'custom_text desc'
        # check that package_a appears before package b (z is first in
        # descending order)
        response = response.forms[1].submit()
        a = response.body.index('test_package_a')
        b = response.body.index('test_package_b')
        nt.assert_true(a < b)

########NEW FILE########
__FILENAME__ = plugin
import ckan.plugins as plugins

# Our custom template helper function.
def example_helper():
    '''An example template helper function.'''

    # Just return some example text.
    return 'This is some example text.'

class ExampleITemplateHelpersPlugin(plugins.SingletonPlugin):
    '''An example that shows how to use the ITemplateHelpers plugin interface.

    '''
    plugins.implements(plugins.IConfigurer)
    plugins.implements(plugins.ITemplateHelpers)

    # Update CKAN's config settings, see the IConfigurer plugin interface.
    def update_config(self, config):

        # Tell CKAN to use the template files in
        # ckanext/example_itemplatehelpers/templates.
        plugins.toolkit.add_template_directory(config, 'templates')

    # Tell CKAN what custom template helper functions this plugin provides,
    # see the ITemplateHelpers plugin interface.
    def get_helpers(self):
        return {'example_helper': example_helper}

########NEW FILE########
__FILENAME__ = plugin
import pylons.config as config

import ckan.plugins as plugins
import ckan.plugins.toolkit as toolkit


def show_most_popular_groups():
    '''Return the value of the most_popular_groups config setting.

    To enable showing the most popular groups, add this line to the
    [app:main] section of your CKAN config file::

      ckan.example_theme.show_most_popular_groups = True

    Returns ``False`` by default, if the setting is not in the config file.

    :rtype: boolean

    '''
    value = config.get('ckan.example_theme.show_most_popular_groups', False)
    value = toolkit.asbool(value)
    return value


def most_popular_groups():
    '''Return a sorted list of the groups with the most datasets.'''

    # Get a list of all the site's groups from CKAN, sorted by number of
    # datasets.
    groups = toolkit.get_action('group_list')(
        data_dict={'sort': 'packages desc', 'all_fields': True})

    # Truncate the list to the 10 most popular groups only.
    groups = groups[:10]

    return groups


class ExampleThemePlugin(plugins.SingletonPlugin):
    '''An example theme plugin.

    '''
    plugins.implements(plugins.IConfigurer)

    # Declare that this plugin will implement ITemplateHelpers.
    plugins.implements(plugins.ITemplateHelpers)

    def update_config(self, config):

        # Add this plugin's templates dir to CKAN's extra_template_paths, so
        # that CKAN will use this plugin's custom templates.
        toolkit.add_template_directory(config, 'templates')

    def get_helpers(self):
        '''Register the most_popular_groups() function above as a template
        helper function.

        '''
        # Template helper function names should begin with the name of the
        # extension they belong to, to avoid clashing with functions from
        # other extensions.
        return {'example_theme_most_popular_groups': most_popular_groups,
                'example_theme_show_most_popular_groups':
                show_most_popular_groups,
                }

########NEW FILE########
__FILENAME__ = plugin
import ckan.plugins as plugins


class ExampleThemePlugin(plugins.SingletonPlugin):
    '''An example theme plugin.

    '''
    pass

########NEW FILE########
__FILENAME__ = plugin
'''plugin.py

'''
import ckan.plugins as plugins
import ckan.plugins.toolkit as toolkit


class ExampleThemePlugin(plugins.SingletonPlugin):
    '''An example theme plugin.

    '''
    # Declare that this class implements IConfigurer.
    plugins.implements(plugins.IConfigurer)

    def update_config(self, config):

        # Add this plugin's templates dir to CKAN's extra_template_paths, so
        # that CKAN will use this plugin's custom templates.
        # 'templates' is the path to the templates dir, relative to this
        # plugin.py file.
        toolkit.add_template_directory(config, 'templates')

########NEW FILE########
__FILENAME__ = plugin
../v02_empty_template/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v03_jinja/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v04_ckan_extends/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v05_block/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v06_super/plugin.py
########NEW FILE########
__FILENAME__ = plugin
import ckan.plugins as plugins
import ckan.plugins.toolkit as toolkit


def most_popular_groups():
    '''Return a sorted list of the groups with the most datasets.'''

    # Get a list of all the site's groups from CKAN, sorted by number of
    # datasets.
    groups = toolkit.get_action('group_list')(
        data_dict={'sort': 'packages desc', 'all_fields': True})

    # Truncate the list to the 10 most popular groups only.
    groups = groups[:10]

    return groups


class ExampleThemePlugin(plugins.SingletonPlugin):
    '''An example theme plugin.

    '''
    plugins.implements(plugins.IConfigurer)

    # Declare that this plugin will implement ITemplateHelpers.
    plugins.implements(plugins.ITemplateHelpers)

    def update_config(self, config):

        # Add this plugin's templates dir to CKAN's extra_template_paths, so
        # that CKAN will use this plugin's custom templates.
        toolkit.add_template_directory(config, 'templates')

    def get_helpers(self):
        '''Register the most_popular_groups() function above as a template
        helper function.

        '''
        # Template helper function names should begin with the name of the
        # extension they belong to, to avoid clashing with functions from
        # other extensions.
        return {'example_theme_most_popular_groups': most_popular_groups}

########NEW FILE########
__FILENAME__ = plugin
../v08_custom_helper_function/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v09_snippet/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v10_custom_snippet/plugin.py
########NEW FILE########
__FILENAME__ = plugin
import ckan.plugins as plugins
import ckan.plugins.toolkit as toolkit


def most_popular_groups():
    '''Return a sorted list of the groups with the most datasets.'''

    # Get a list of all the site's groups from CKAN, sorted by number of
    # datasets.
    groups = toolkit.get_action('group_list')(
        data_dict={'sort': 'packages desc', 'all_fields': True})

    # Truncate the list to the 10 most popular groups only.
    groups = groups[:10]

    return groups


class ExampleThemePlugin(plugins.SingletonPlugin):
    '''An example theme plugin.

    '''
    plugins.implements(plugins.IConfigurer)

    # Declare that this plugin will implement ITemplateHelpers.
    plugins.implements(plugins.ITemplateHelpers)

    def update_config(self, config):

        # Add this plugin's templates dir to CKAN's extra_template_paths, so
        # that CKAN will use this plugin's custom templates.
        toolkit.add_template_directory(config, 'templates')

        # Add this plugin's public dir to CKAN's extra_public_paths, so
        # that CKAN will use this plugin's custom static files.
        toolkit.add_public_directory(config, 'public')

    def get_helpers(self):
        '''Register the most_popular_groups() function above as a template
        helper function.

        '''
        # Template helper function names should begin with the name of the
        # extension they belong to, to avoid clashing with functions from
        # other extensions.
        return {'example_theme_most_popular_groups': most_popular_groups}

########NEW FILE########
__FILENAME__ = plugin
../v12_extra_public_dir/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v13_custom_css/plugin.py
########NEW FILE########
__FILENAME__ = plugin
import ckan.plugins as plugins
import ckan.plugins.toolkit as toolkit


def most_popular_groups():
    '''Return a sorted list of the groups with the most datasets.'''

    # Get a list of all the site's groups from CKAN, sorted by number of
    # datasets.
    groups = toolkit.get_action('group_list')(
        data_dict={'sort': 'packages desc', 'all_fields': True})

    # Truncate the list to the 10 most popular groups only.
    groups = groups[:10]

    return groups


class ExampleThemePlugin(plugins.SingletonPlugin):
    '''An example theme plugin.

    '''
    plugins.implements(plugins.IConfigurer)

    # Declare that this plugin will implement ITemplateHelpers.
    plugins.implements(plugins.ITemplateHelpers)

    def update_config(self, config):

        # Add this plugin's templates dir to CKAN's extra_template_paths, so
        # that CKAN will use this plugin's custom templates.
        toolkit.add_template_directory(config, 'templates')

        # Add this plugin's public dir to CKAN's extra_public_paths, so
        # that CKAN will use this plugin's custom static files.
        toolkit.add_public_directory(config, 'public')

        # Register this plugin's fanstatic directory with CKAN.
        # Here, 'fanstatic' is the path to the fanstatic directory
        # (relative to this plugin.py file), and 'example_theme' is the name
        # that we'll use to refer to this fanstatic directory from CKAN
        # templates.
        toolkit.add_resource('fanstatic', 'example_theme')

    def get_helpers(self):
        '''Register the most_popular_groups() function above as a template
        helper function.

        '''
        # Template helper function names should begin with the name of the
        # extension they belong to, to avoid clashing with functions from
        # other extensions.
        return {'example_theme_most_popular_groups': most_popular_groups}

########NEW FILE########
__FILENAME__ = plugin
import ckan.plugins as plugins
import ckan.plugins.toolkit as toolkit


class ExampleThemePlugin(plugins.SingletonPlugin):
    '''An example theme plugin.

    '''
    plugins.implements(plugins.IConfigurer)

    def update_config(self, config):

        toolkit.add_template_directory(config, 'templates')
        toolkit.add_resource('fanstatic', 'example_theme')

########NEW FILE########
__FILENAME__ = plugin
../v16_initialize_a_javascript_module/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v17_popover/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v18_snippet_api/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v19_01_error/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v19_02_error_handling/plugin.py
########NEW FILE########
__FILENAME__ = plugin
../v20_pubsub/plugin.py
########NEW FILE########
__FILENAME__ = plugin
import sets
import ckan
from ckan.plugins import SingletonPlugin, implements, IPackageController
from ckan.plugins import IGroupController, IOrganizationController, ITagController
import pylons
import ckan.logic.action.get as action_get
from pylons import config

LANGS = ['en', 'fr', 'de', 'es', 'it', 'nl', 'ro', 'pt', 'pl']

def translate_data_dict(data_dict):
    '''Return the given dict (e.g. a dataset dict) with as many of its fields
    as possible translated into the desired or the fallback language.

    '''
    desired_lang_code = pylons.request.environ['CKAN_LANG']
    fallback_lang_code = pylons.config.get('ckan.locale_default', 'en')

    # Get a flattened copy of data_dict to do the translation on.
    flattened = ckan.lib.navl.dictization_functions.flatten_dict(
            data_dict)

    # Get a simple flat list of all the terms to be translated, from the
    # flattened data dict.
    terms = sets.Set()
    for (key, value) in flattened.items():
        if value in (None, True, False):
            continue
        elif isinstance(value, basestring):
            terms.add(value)
        elif isinstance(value, (int, long)):
            continue
        else:
            for item in value:
                terms.add(item)

    # Get the translations of all the terms (as a list of dictionaries).
    translations = ckan.logic.action.get.term_translation_show(
            {'model': ckan.model},
            {'terms': terms,
                'lang_codes': (desired_lang_code, fallback_lang_code)})

    # Transform the translations into a more convenient structure.
    desired_translations = {}
    fallback_translations = {}
    for translation in translations:
        if translation['lang_code'] == desired_lang_code:
            desired_translations[translation['term']] = (
                    translation['term_translation'])
        else:
            assert translation['lang_code'] == fallback_lang_code
            fallback_translations[translation['term']] = (
                    translation['term_translation'])

    # Make a copy of the flattened data dict with all the terms replaced by
    # their translations, where available.
    translated_flattened = {}
    for (key, value) in flattened.items():

        # Don't translate names that are used for form URLs.
        if key == ('name',):
            translated_flattened[key] = value
        elif (key[0] in ('tags', 'groups') and len(key) == 3
                and key[2] == 'name'):
            translated_flattened[key] = value

        elif value in (None, True, False):
            # Don't try to translate values that aren't strings.
            translated_flattened[key] = value

        elif isinstance(value, basestring):
            if value in desired_translations:
                translated_flattened[key] = desired_translations[value]
            else:
                translated_flattened[key] = fallback_translations.get(
                        value, value)

        elif isinstance(value, (int, long, dict)):
            translated_flattened[key] = value

        else:
            translated_value = []
            for item in value:
                if item in desired_translations:
                    translated_value.append(desired_translations[item])
                else:
                    translated_value.append(
                        fallback_translations.get(item, item)
                    )
            translated_flattened[key] = translated_value

    # Finally unflatten and return the translated data dict.
    translated_data_dict = (ckan.lib.navl.dictization_functions
            .unflatten(translated_flattened))
    return translated_data_dict

KEYS_TO_IGNORE = ['state', 'revision_id', 'id', #title done seperately
                  'metadata_created', 'metadata_modified', 'site_id']

class MultilingualDataset(SingletonPlugin):
    implements(IPackageController, inherit=True)

    def before_index(self, search_data):

        default_lang = search_data.get(
            'lang_code', 
             pylons.config.get('ckan.locale_default', 'en')
        )

        ## translate title
        title = search_data.get('title')
        search_data['title_' + default_lang] = title 
        title_translations = action_get.term_translation_show(
                          {'model': ckan.model},
                          {'terms': [title],
                              'lang_codes': LANGS})

        for translation in title_translations:
            title_field = 'title_' + translation['lang_code']
            search_data[title_field] = translation['term_translation']

        ## translate rest
        all_terms = []
        for key, value in search_data.iteritems():
            if key in KEYS_TO_IGNORE or key.startswith('title'):
                continue
            if not isinstance(value, list):
                value = [value]
            for item in value:
                if isinstance(item, basestring):
                    all_terms.append(item)

        field_translations = action_get.term_translation_show(
                          {'model': ckan.model},
                          {'terms': all_terms,
                              'lang_codes': LANGS})

        text_field_items = dict(('text_' + lang, []) for lang in LANGS)
        
        text_field_items['text_' + default_lang].extend(all_terms)

        for translation in sorted(field_translations):
            lang_field = 'text_' + translation['lang_code']
            text_field_items[lang_field].append(translation['term_translation'])

        for key, value in text_field_items.iteritems():
            search_data[key] = ' '.join(value)
        
        return search_data

    def before_search(self, search_params):
        lang_set = set(LANGS)
        current_lang = pylons.request.environ['CKAN_LANG']
        # fallback to default locale if locale not in suported langs
        if not current_lang in lang_set:
            current_lang = config.get('ckan.locale_default')
        # fallback to english if default locale is not supported
        if not current_lang in lang_set:
            current_lang = 'en'
        # treat current lang differenly so remove from set
        lang_set.remove(current_lang)

        # weight current lang more highly
        query_fields = 'title_%s^8 text_%s^4' % (current_lang, current_lang)

        for lang in lang_set:
            query_fields += ' title_%s^2 text_%s' % (lang, lang)

        search_params['qf'] = query_fields

        return search_params

    def after_search(self, search_results, search_params):

        # Translate the unselected search facets.
        facets = search_results.get('search_facets')
        if not facets:
            return search_results

        desired_lang_code = pylons.request.environ['CKAN_LANG']
        fallback_lang_code = pylons.config.get('ckan.locale_default', 'en')

        # Look up translations for all of the facets in one db query.
        terms = sets.Set()
        for facet in facets.values():
            for item in facet['items']:
                terms.add(item['display_name'])
        translations = ckan.logic.action.get.term_translation_show(
                {'model': ckan.model},
                {'terms': terms,
                    'lang_codes': (desired_lang_code, fallback_lang_code)})

        # Replace facet display names with translated ones.
        for facet in facets.values():
            for item in facet['items']:
                matching_translations = [translation for
                        translation in translations
                        if translation['term'] == item['display_name']
                        and translation['lang_code'] == desired_lang_code]
                if not matching_translations:
                    matching_translations = [translation for
                            translation in translations
                            if translation['term'] == item['display_name']
                            and translation['lang_code'] == fallback_lang_code]
                if matching_translations:
                    assert len(matching_translations) == 1
                    item['display_name'] = (
                        matching_translations[0]['term_translation'])

        return search_results

    def before_view(self, dataset_dict):

        # Translate any selected search facets (e.g. if we are rendering a
        # group read page or the dataset index page): lookup translations of
        # all the terms in c.fields (c.fields contains the selected facets)
        # and save them in c.translated_fields where the templates can
        # retrieve them later.
        c = pylons.c
        desired_lang_code = pylons.request.environ['CKAN_LANG']
        fallback_lang_code = pylons.config.get('ckan.locale_default', 'en')
        terms = [value for param, value in c.fields]
        translations = ckan.logic.action.get.term_translation_show(
                {'model': ckan.model},
                {'terms': terms,
                 'lang_codes': (desired_lang_code, fallback_lang_code)})
        c.translated_fields = {}
        for param, value in c.fields:
            matching_translations = [translation for translation in
                    translations if translation['term'] == value and
                    translation['lang_code'] == desired_lang_code]
            if not matching_translations:
                matching_translations = [translation for translation in
                        translations if translation['term'] == value and
                        translation['lang_code'] == fallback_lang_code]
            if matching_translations:
                assert len(matching_translations) == 1
                translation = matching_translations[0]['term_translation']
                c.translated_fields[(param, value)] = translation

        # Now translate the fields of the dataset itself.
        return translate_data_dict(dataset_dict)

class MultilingualGroup(SingletonPlugin):
    '''The MultilingualGroup plugin translates group names and other group
    fields on group read pages and on the group index page.

    For example on the page /de/group/david the title "Dave's Books" at the
    top of the page might be translated to "Dave's Bucher".

    Datasets are also shown on group pages, but these are translated by the
    MultilingualDataset plugin.

    '''
    implements(IGroupController, inherit=True)
    implements(IOrganizationController, inherit=True)

    def before_view(self, data_dict):
        translated_data_dict = translate_data_dict(data_dict)
        return translated_data_dict

class MultilingualTag(SingletonPlugin):
    '''The MultilingualTag plugin translates tag names on tag read pages and
    on the tag index page.

    For example on the page /de/tag/tolstoy the title "Tag: tolstoy" at the
    top of the page might be translated to "Tag: Tolstoi".

    Datasets are also shown on tag pages, but these are translated by the
    MultilingualDataset plugin.

    '''
    implements(ITagController, inherit=True)

    def before_view(self, data_dict):
        translated_data_dict = translate_data_dict(data_dict)
        return translated_data_dict

########NEW FILE########
__FILENAME__ = test_multilingual_plugin
import ckan.plugins
import ckanext.multilingual.plugin as mulilingual_plugin
import ckan.lib.helpers
import ckan.lib.create_test_data
import ckan.logic.action.update
import ckan.model as model
import ckan.tests
import ckan.tests.html_check
import routes
import paste.fixture
import pylons.test

_create_test_data = ckan.lib.create_test_data


class TestDatasetTermTranslation(ckan.tests.html_check.HtmlCheckMethods):
    'Test the translation of datasets by the multilingual_dataset plugin.'
    @classmethod
    def setup(cls):
        cls.app = paste.fixture.TestApp(pylons.test.pylonsapp)
        ckan.plugins.load('multilingual_dataset')
        ckan.plugins.load('multilingual_group')
        ckan.plugins.load('multilingual_tag')
        ckan.tests.setup_test_search_index()
        _create_test_data.CreateTestData.create_translations_test_data()

        cls.sysadmin_user = model.User.get('testsysadmin')
        cls.org = {'name': 'test_org',
                   'title': 'russian',
                   'description': 'Roger likes these books.'}
        ckan.tests.call_action_api(cls.app, 'organization_create',
                                   apikey=cls.sysadmin_user.apikey,
                                   **cls.org)
        dataset = {'name': 'test_org_dataset',
                   'title': 'A Novel By Tolstoy',
                   'owner_org': cls.org['name']}
        ckan.tests.call_action_api(cls.app, 'package_create',
                                   apikey=cls.sysadmin_user.apikey,
                                   **dataset)

        # Add translation terms that match a couple of group names and package
        # names. Group names and package names should _not_ get translated even
        # if there are terms matching them, because they are used to form URLs.
        for term in ('roger', 'david', 'annakarenina', 'warandpeace'):
            for lang_code in ('en', 'de', 'fr'):
                data_dict = {'term': term,
                             'term_translation': 'this should not be rendered',
                             'lang_code': lang_code}
                context = {'model': ckan.model,
                           'session': ckan.model.Session,
                           'user': 'testsysadmin'}
                ckan.logic.action.update.term_translation_update(
                    context, data_dict)

    @classmethod
    def teardown(cls):
        ckan.plugins.unload('multilingual_dataset')
        ckan.plugins.unload('multilingual_group')
        ckan.plugins.unload('multilingual_tag')
        ckan.model.repo.rebuild_db()
        ckan.lib.search.clear()

    def test_dataset_read_translation(self):
        '''Test the translation of dataset view pages by the
        multilingual_dataset plugin.

        '''
        # Fetch the dataset view page for a number of different languages and
        # test for the presence of translated and not translated terms.
        offset = routes.url_for(
            controller='package', action='read', id='annakarenina')
        for (lang_code, translations) in (
                ('de', _create_test_data.german_translations),
                ('fr', _create_test_data.french_translations),
                ('en', _create_test_data.english_translations),
                ('pl', {})):
            response = self.app.get(offset, status=200,
                                    extra_environ={'CKAN_LANG': lang_code,
                                                   'CKAN_CURRENT_URL': offset})
            terms = ('A Novel By Tolstoy',
                     'Index of the novel',
                     'russian',
                     'tolstoy',
                     "Dave's books",
                     "Roger's books",
                     'romantic novel',
                     'book',
                     '123',
                     '456',
                     '789',
                     'plain text',)
            for term in terms:
                if term in translations:
                    assert translations[term] in response
                elif term in _create_test_data.english_translations:
                    assert (_create_test_data.english_translations[term]
                            in response)
                else:
                    assert term in response
            for tag_name in ('123', '456', '789', 'russian', 'tolstoy'):
                assert '<a href="/tag/%s">' % tag_name in response
            for group_name in ('david', 'roger'):
                assert '<a href="/group/%s">' % group_name in response
            assert 'this should not be rendered' not in response

    def test_tag_read_translation(self):
        '''Test the translation of tag view pages by the multilingual_tag
        plugin.

        '''
        for tag_name in ('123', '456', '789', 'russian', 'tolstoy'):
            offset = routes.url_for(
                controller='tag', action='read', id=tag_name)
            for (lang_code, translations) in (
                    ('de', _create_test_data.german_translations),
                    ('fr', _create_test_data.french_translations),
                    ('en', _create_test_data.english_translations),
                    ('pl', {})):
                response = self.app.get(
                    offset,
                    status=200,
                    extra_environ={'CKAN_LANG': lang_code,
                                   'CKAN_CURRENT_URL': offset})
                terms = ('A Novel By Tolstoy', tag_name, 'plain text', 'json')
                for term in terms:
                    if term in translations:
                        assert translations[term] in response
                    elif term in _create_test_data.english_translations:
                        assert (_create_test_data.english_translations[term]
                                in response)
                    else:
                        assert term in response
                assert 'this should not be rendered' not in response

    def test_user_read_translation(self):
        '''Test the translation of datasets on user view pages by the
        multilingual_dataset plugin.

        '''
        for user_name in ('annafan',):
            offset = routes.url_for(
                controller='user', action='read', id=user_name)
            for (lang_code, translations) in (
                    ('de', _create_test_data.german_translations),
                    ('fr', _create_test_data.french_translations),
                    ('en', _create_test_data.english_translations),
                    ('pl', {})):
                response = self.app.get(
                    offset,
                    status=200,
                    extra_environ={'CKAN_LANG': lang_code,
                                   'CKAN_CURRENT_URL': offset})
                terms = ('A Novel By Tolstoy', 'plain text', 'json')
                for term in terms:
                    if term in translations:
                        assert translations[term] in response
                    elif term in _create_test_data.english_translations:
                        assert (_create_test_data.english_translations[term]
                                in response)
                    else:
                        assert term in response
                assert 'this should not be rendered' not in response

    def test_group_read_translation(self):
        for (lang_code, translations) in (
                ('de', _create_test_data.german_translations),
                ('fr', _create_test_data.french_translations),
                ('en', _create_test_data.english_translations),
                ('pl', {})):
            offset = '/%s/group/roger' % lang_code
            response = self.app.get(offset, status=200)
            terms = ('A Novel By Tolstoy',
                     'Index of the novel',
                     'russian',
                     'tolstoy',
                     "Roger's books",
                     '123',
                     '456',
                     '789',
                     'plain text',
                     'Roger likes these books.',)
            for term in terms:
                if term in translations:
                    assert translations[term] in response
                elif term in _create_test_data.english_translations:
                    assert (_create_test_data.english_translations[term]
                            in response)
                else:
                    assert term in response
            for tag_name in ('123', '456', '789', 'russian', 'tolstoy'):
                assert '%s?tags=%s' % (offset, tag_name) in response
            assert 'this should not be rendered' not in response

    def test_org_read_translation(self):
        for (lang_code, translations) in (
                ('de', _create_test_data.german_translations),
                ('fr', _create_test_data.french_translations),
                ('en', _create_test_data.english_translations),
                ('pl', {})):
            offset = '/{0}/organization/{1}'.format(
                lang_code, self.org['name'])
            response = self.app.get(offset, status=200)
            terms = ('A Novel By Tolstoy',
                     'russian',
                     'Roger likes these books.')
            for term in terms:
                if term in translations:
                    assert translations[term] in response
                elif term in _create_test_data.english_translations:
                    assert (_create_test_data.english_translations[term]
                            in response)
                else:
                    assert term in response
            assert 'this should not be rendered' not in response

    def test_dataset_index_translation(self):
        for (lang_code, translations) in (
                ('de', _create_test_data.german_translations),
                ('fr', _create_test_data.french_translations),
                ('en', _create_test_data.english_translations),
                ('pl', {})):
            offset = '/%s/dataset' % lang_code
            response = self.app.get(offset, status=200)
            for term in ('Index of the novel', 'russian', 'tolstoy',
                         "Dave's books", "Roger's books", 'plain text'):
                if term in translations:
                    assert translations[term] in response
                elif term in _create_test_data.english_translations:
                    assert (_create_test_data.english_translations[term]
                            in response)
                else:
                    assert term in response
            for tag_name in ('123', '456', '789', 'russian', 'tolstoy'):
                assert ('/%s/dataset?tags=%s' % (lang_code, tag_name)
                        in response)
            for group_name in ('david', 'roger'):
                assert ('/%s/dataset?groups=%s' % (lang_code, group_name)
                        in response)
            assert 'this should not be rendered' not in response

    def test_group_index_translation(self):
        for (lang_code, translations) in (
                ('de', _create_test_data.german_translations),
                ('fr', _create_test_data.french_translations),
                ('en', _create_test_data.english_translations),
                ('pl', {})):
            offset = '/%s/group' % lang_code
            response = self.app.get(offset, status=200)
            terms = (
                "Dave's books",
                "Roger's books",
                'Roger likes these books.',
                "These are books that David likes.",
            )
            for term in terms:
                if term in translations:
                    assert translations[term] in response
                elif term in _create_test_data.english_translations:
                    assert (_create_test_data.english_translations[term]
                            in response)
                else:
                    assert term in response
            for group_name in ('david', 'roger'):
                assert '/%s/group/%s' % (lang_code, group_name) in response
            assert 'this should not be rendered' not in response

    def test_org_index_translation(self):
        for (lang_code, translations) in (
                ('de', _create_test_data.german_translations),
                ('fr', _create_test_data.french_translations),
                ('en', _create_test_data.english_translations),
                ('pl', {})):
            offset = '/{0}/organization'.format(lang_code)
            response = self.app.get(offset, status=200)
            for term in ('russian', 'Roger likes these books.'):
                if term in translations:
                    assert translations[term] in response
                elif term in _create_test_data.english_translations:
                    assert (_create_test_data.english_translations[term]
                            in response)
                else:
                    assert term in response, response
            assert ('/{0}/organization/{1}'.format(lang_code, self.org['name'])
                    in response)
            assert 'this should not be rendered' not in response

    def test_tag_index_translation(self):
        for (lang_code, translations) in (
                ('de', _create_test_data.german_translations),
                ('fr', _create_test_data.french_translations),
                ('en', _create_test_data.english_translations),
                ('pl', {})):
            offset = '/%s/tag' % lang_code
            response = self.app.get(offset, status=200)
            terms = (
                "123",
                "456",
                '789',
                "russian",
                "tolstoy",
            )
            for term in terms:
                if term in translations:
                    assert translations[term] in response
                elif term in _create_test_data.english_translations:
                    assert (_create_test_data.english_translations[term]
                            in response)
                else:
                    assert term in response
                assert '/%s/tag/%s' % (lang_code, term) in response
            assert 'this should not be rendered' not in response


class TestDatasetSearchIndex():

    @classmethod
    def setup_class(cls):
        ckan.plugins.load('multilingual_dataset')
        ckan.plugins.load('multilingual_group')

        data_dicts = [
            {'term': 'moo',
             'term_translation': 'french_moo',
             'lang_code': 'fr'},
            {'term': 'moo',
             'term_translation': 'this should not be rendered',
             'lang_code': 'fsdas'},
            {'term': 'an interesting note',
             'term_translation': 'french note',
             'lang_code': 'fr'},
            {'term': 'moon',
             'term_translation': 'french moon',
             'lang_code': 'fr'},
            {'term': 'boon',
             'term_translation': 'french boon',
             'lang_code': 'fr'},
            {'term': 'boon',
             'term_translation': 'italian boon',
             'lang_code': 'it'},
            {'term': 'david',
             'term_translation': 'french david',
             'lang_code': 'fr'},
            {'term': 'david',
             'term_translation': 'italian david',
             'lang_code': 'it'}
        ]

        context = {
            'model': ckan.model,
            'session': ckan.model.Session,
            'user': 'testsysadmin',
            'ignore_auth': True,
        }
        for data_dict in data_dicts:
            ckan.logic.action.update.term_translation_update(
                context, data_dict)

    @classmethod
    def teardown(cls):
        ckan.plugins.unload('multilingual_dataset')
        ckan.plugins.unload('multilingual_group')

    def test_translate_terms(self):

        sample_index_data = {
            'download_url': u'moo',
            'notes': u'an interesting note',
            'tags': [u'moon', 'boon'],
            'title': u'david',
        }

        result = mulilingual_plugin.MultilingualDataset().before_index(
            sample_index_data)

        assert result == {
            'text_pl': '',
            'text_de': '',
            'text_ro': '',
            'title': u'david',
            'notes': u'an interesting note',
            'tags': [u'moon', 'boon'],
            'title_en': u'david',
            'download_url': u'moo',
            'text_it': u'italian boon',
            'text_es': '',
            'text_en': u'an interesting note moon boon moo',
            'text_nl': '',
            'title_it': u'italian david',
            'text_pt': '',
            'title_fr': u'french david',
            'text_fr': u'french note french boon french_moo french moon'
        }, result

########NEW FILE########
__FILENAME__ = plugin
import logging

import ckan.plugins as p

log = logging.getLogger(__name__)

try:
    import ckanext.resourceproxy.plugin as proxy
except ImportError:
    pass


class PdfPreview(p.SingletonPlugin):
    '''This extension previews PDFs. '''
    p.implements(p.IConfigurer, inherit=True)
    p.implements(p.IConfigurable, inherit=True)
    p.implements(p.IResourcePreview, inherit=True)

    PDF = ['pdf', 'x-pdf', 'acrobat', 'vnd.pdf']
    proxy_is_enabled = False

    def update_config(self, config):
        p.toolkit.add_public_directory(config, 'theme/public')
        p.toolkit.add_template_directory(config, 'theme/templates')
        p.toolkit.add_resource('theme/public', 'ckanext-pdfpreview')

    def configure(self, config):
        enabled = config.get('ckan.resource_proxy_enabled', False)
        self.proxy_is_enabled = enabled

    def can_preview(self, data_dict):
        resource = data_dict['resource']
        format_lower = resource['format'].lower()
        if format_lower in self.PDF:
            if resource['on_same_domain'] or self.proxy_is_enabled:
                return {'can_preview': True, 'quality': 2}
            else:
                return {'can_preview': False,
                        'fixable': 'Enable resource_proxy',
                        'quality': 2}
        return {'can_preview': False}

    def setup_template_variables(self, context, data_dict):
        if (self.proxy_is_enabled
                and not data_dict['resource']['on_same_domain']):
            url = proxy.get_proxified_resource_url(data_dict)
            p.toolkit.c.resource['url'] = url

    def preview_template(self, context, data_dict):
        return 'pdf.html'

########NEW FILE########
__FILENAME__ = test_preview
import pylons
import paste.fixture

import pylons.config as config

import ckan.logic as logic
import ckan.model as model
import ckan.tests as tests
import ckan.plugins as plugins
import ckan.lib.helpers as h
import ckanext.pdfpreview.plugin as previewplugin
import ckan.lib.create_test_data as create_test_data
import ckan.config.middleware as middleware


class TestPdfPreview(tests.WsgiAppCase):

    @classmethod
    def setup_class(cls):
        wsgiapp = middleware.make_app(config['global_conf'], **config)
        plugins.load('pdf_preview')
        cls.app = paste.fixture.TestApp(wsgiapp)

        cls.p = previewplugin.PdfPreview()
        cls.p.proxy_is_enabled = False

        create_test_data.CreateTestData.create()

        context = {
            'model': model,
            'session': model.Session,
            'user': model.User.get('testsysadmin').name
        }

        cls.package = model.Package.get('annakarenina')
        cls.resource = logic.get_action('resource_show')(
            context, {'id': cls.package.resources[1].id})
        cls.resource['url'] = pylons.config.get(
            'ckan.site_url', '//localhost:5000')
        cls.resource['format'] = 'pdf'
        logic.action.update.resource_update(context, cls.resource)

    @classmethod
    def teardown_class(cls):
        plugins.unload('pdf_preview')
        create_test_data.CreateTestData.delete()

    def test_can_preview(self):
        data_dict = {
            'resource': {
                'format': 'pdf',
                'on_same_domain': True
            }
        }
        assert self.p.can_preview(data_dict)['can_preview']

        data_dict = {
            'resource': {
                'format': 'x-pdf',
                'on_same_domain': True
            }
        }
        assert self.p.can_preview(data_dict)['can_preview']

        data_dict = {
            'resource': {
                'format': 'pdf',
                'on_same_domain': True
            }
        }
        assert self.p.can_preview(data_dict)['can_preview']

        data_dict = {
            'resource': {
                'format': 'pdf',
                'on_same_domain': False
            }
        }
        assert not self.p.can_preview(data_dict)['can_preview']

    def test_js_included(self):
        res_id = self.resource['id']
        pack_id = self.package.name
        url = '/dataset/{0}/resource/{1}/preview'.format(pack_id, res_id)
        result = self.app.get(url, status='*')

        assert result.status == 200, result.status
        assert (('preview_pdf.js' in result.body) or (
            'preview_pdf.min.js' in result.body))
        assert 'preload_resource' in result.body
        assert 'data-module="pdfpreview"' in result.body

    def test_iframe_is_shown(self):
        url = h.url_for(controller='package', action='resource_read',
                        id=self.package.name, resource_id=self.resource['id'])
        result = self.app.get(url)
        assert 'data-module="data-viewer"' in result.body
        assert '<iframe' in result.body

########NEW FILE########
__FILENAME__ = plugin
from logging import getLogger

import ckan.plugins as p
import ckan.plugins.toolkit as toolkit

log = getLogger(__name__)


class ReclinePreview(p.SingletonPlugin):
    """This extension previews resources using recline

    This extension implements two interfaces

      - ``IConfigurer`` allows to modify the configuration
      - ``IResourcePreview`` allows to add previews
    """
    p.implements(p.IConfigurer, inherit=True)
    p.implements(p.IResourcePreview, inherit=True)

    def update_config(self, config):
        ''' Set up the resource library, public directory and
        template directory for the preview
        '''
        toolkit.add_public_directory(config, 'theme/public')
        toolkit.add_template_directory(config, 'theme/templates')
        toolkit.add_resource('theme/public', 'ckanext-reclinepreview')

    def can_preview(self, data_dict):
        # if the resource is in the datastore then we can preview it with recline
        if data_dict['resource'].get('datastore_active'):
            return True
        format_lower = data_dict['resource']['format'].lower()
        return format_lower in ['csv', 'xls', 'tsv']

    def preview_template(self, context, data_dict):
        return 'recline.html'

########NEW FILE########
__FILENAME__ = test_preview
import pylons
import paste.fixture

import pylons.config as config

import ckan.logic as logic
import ckan.model as model
import ckan.tests as tests
import ckan.plugins as plugins
import ckan.lib.helpers as h
import ckanext.reclinepreview.plugin as previewplugin
from ckan.lib.create_test_data import CreateTestData
from ckan.config.middleware import make_app


class TestJsonPreview(tests.WsgiAppCase):

    @classmethod
    def setup_class(cls):
        wsgiapp = make_app(config['global_conf'], **config)
        plugins.load('recline_preview')
        cls.app = paste.fixture.TestApp(wsgiapp)

        cls.p = previewplugin.ReclinePreview()

        # create test resource
        CreateTestData.create()

        context = {
            'model': model,
            'session': model.Session,
            'user': model.User.get('testsysadmin').name
        }

        cls.package = model.Package.get('annakarenina')
        cls.resource = logic.get_action('resource_show')(context, {'id': cls.package.resources[1].id})
        cls.resource['url'] = pylons.config.get('ckan.site_url', '//localhost:5000')
        cls.resource['format'] = 'csv'
        logic.action.update.resource_update(context, cls.resource)

    @classmethod
    def teardown_class(cls):
        plugins.unload('recline_preview')
        CreateTestData.delete()

    def test_can_preview(self):
        data_dict = {
            'resource': {
                'format': 'csv'
            }
        }
        assert self.p.can_preview(data_dict)

        data_dict = {
            'resource': {
                'format': 'tsv'
            }
        }
        assert self.p.can_preview(data_dict)

        data_dict = {
            'resource': {
                'format': 'xls'
            }
        }
        assert self.p.can_preview(data_dict)

        data_dict = {
            'resource': {
                'format': 'csv',
                'on_same_domain': True
            }
        }
        assert self.p.can_preview(data_dict)

        data_dict = {
            'resource': {
                'format': 'csv',
                'on_same_domain': False
            }
        }
        assert self.p.can_preview(data_dict)

        data_dict = {
            'resource': {
                'format': 'foo',
            }
        }
        assert not self.p.can_preview(data_dict)

        data_dict = {
            'resource': {
                'format': 'foo',
                'datastore_active': True
            }
        }
        assert self.p.can_preview(data_dict)

        data_dict = {
            'resource': {
                'format': 'foo',
                'datastore_active': False
            }
        }
        assert not self.p.can_preview(data_dict)


    def test_js_included(self):
        res_id = self.resource['id']
        pack_id = self.package.name
        url = '/dataset/{0}/resource/{1}/preview'.format(pack_id, res_id)
        result = self.app.get(url, status='*')

        assert result.status == 200, result.status
        assert (('preview_recline.js' in result.body) or ('preview_recline.min.js' in result.body))
        assert 'preload_resource' in result.body
        assert 'data-module="reclinepreview"' in result.body

    def test_iframe_is_shown(self):
        url = h.url_for(controller='package', action='resource_read', id=self.package.name, resource_id=self.resource['id'])
        result = self.app.get(url)
        assert 'data-module="data-viewer"' in result.body
        assert '<iframe' in result.body

########NEW FILE########
__FILENAME__ = controller
from logging import getLogger
import urlparse

import requests

import ckan.logic as logic
import ckan.lib.base as base
from ckan.common import _

log = getLogger(__name__)

MAX_FILE_SIZE = 1024 * 1024  # 1MB
CHUNK_SIZE = 512


def proxy_resource(context, data_dict):
    ''' Chunked proxy for resources. To make sure that the file is not too
    large, first, we try to get the content length from the headers.
    If the headers to not contain a content length (if it is a chinked
    response), we only transfer as long as the transferred data is less
    than the maximum file size. '''
    resource_id = data_dict['resource_id']
    log.info('Proxify resource {id}'.format(id=resource_id))
    try:
        resource = logic.get_action('resource_show')(context, {'id':
                                                     resource_id})
    except logic.NotFound:
            base.abort(404, _('Resource not found'))
    url = resource['url']

    parts = urlparse.urlsplit(url)
    if not parts.scheme or not parts.netloc:
        base.abort(409, detail='Invalid URL.')

    try:
        # first we try a HEAD request which may not be supported
        did_get = False
        r = requests.head(url)
        if r.status_code == 405:
            r = requests.get(url, stream=True)
            did_get = True
        r.raise_for_status()

        cl = r.headers['content-length']
        if cl and int(cl) > MAX_FILE_SIZE:
            base.abort(409, '''Content is too large to be proxied. Allowed
                file size: {allowed}, Content-Length: {actual}.'''.format(
                allowed=MAX_FILE_SIZE, actual=cl))

        if not did_get:
            r = requests.get(url, stream=True)

        base.response.content_type = r.headers['content-type']
        base.response.charset = r.encoding

        length = 0
        for chunk in r.iter_content(chunk_size=CHUNK_SIZE):
            base.response.body_file.write(chunk)
            length += len(chunk)

            if length >= MAX_FILE_SIZE:
                base.abort(409, headers={'content-encoding': ''},
                           detail='Content is too large to be proxied.')

    except requests.exceptions.HTTPError, error:
        details = 'Could not proxy resource. Server responded with %s %s' % (
            error.response.status_code, error.response.reason)
        base.abort(409, detail=details)
    except requests.exceptions.ConnectionError, error:
        details = '''Could not proxy resource because a
                            connection error occurred. %s''' % error
        base.abort(502, detail=details)
    except requests.exceptions.Timeout, error:
        details = 'Could not proxy resource because the connection timed out.'
        base.abort(504, detail=details)


class ProxyController(base.BaseController):
    def proxy_resource(self, resource_id):
        data_dict = {'resource_id': resource_id}
        context = {'model': base.model, 'session': base.model.Session,
                   'user': base.c.user or base.c.author}
        return proxy_resource(context, data_dict)

########NEW FILE########
__FILENAME__ = plugin
from logging import getLogger

import ckan.lib.helpers as h
import ckan.plugins as p

log = getLogger(__name__)


def get_proxified_resource_url(data_dict):
    '''
    :param data_dict: contains a resource and package dict
    :type data_dict: dictionary
    '''
    url = h.url_for(
        action='proxy_resource',
        controller='ckanext.resourceproxy.controller:ProxyController',
        id=data_dict['package']['name'],
        resource_id=data_dict['resource']['id'])
    log.info('Proxified url is {0}'.format(url))
    return url


class ResourceProxy(p.SingletonPlugin):
    """A proxy for CKAN resources to get around the same
    origin policy for previews

    This extension implements the IRoute interface
      - ``IRoutes`` allows to add a route to the proxy action


    Instructions on how to use the extension:

    1. Import the proxy plugin if it exists
        ``import ckanext.resourceproxy.plugin as proxy``

    2. In you extension, make sure that the proxy plugin is
        enabled by checking the ``ckan.resource_proxy_enabled`` config variable.
        ``config.get('ckan.resource_proxy_enabled', False)``
    """
    p.implements(p.IRoutes, inherit=True)
    p.implements(p.IConfigurer, inherit=True)

    def update_config(self, config):
        config['ckan.resource_proxy_enabled'] = True

    def before_map(self, m):
        m.connect('/dataset/{id}/resource/{resource_id}/proxy',
                    controller='ckanext.resourceproxy.controller:ProxyController',
                    action='proxy_resource')
        return m

########NEW FILE########
__FILENAME__ = test_proxy
import requests
import unittest
import json
import httpretty

import paste.fixture
from pylons import config

import ckan.logic as logic
import ckan.model as model
import ckan.tests as tests
import ckan.plugins as plugins
import ckan.lib.create_test_data as create_test_data
import ckan.config.middleware as middleware
import ckanext.resourceproxy.controller as controller

import ckanext.resourceproxy.plugin as proxy


JSON_STRING = json.dumps({
    "a": "foo",
    "bar": "yes, I'm proxied",
    "b": 42})


def set_resource_url(url):
    testpackage = model.Package.get('annakarenina')

    context = {
        'model': model,
        'session': model.Session,
        'user': model.User.get('testsysadmin').name
    }
    resource = logic.get_action('resource_show')(context, {'id': testpackage.resources[0].id})
    package = logic.get_action('package_show')(context, {'id': testpackage.id})

    resource['url'] = url
    logic.action.update.resource_update(context, resource)

    testpackage = model.Package.get('annakarenina')
    assert testpackage.resources[0].url == resource['url'], testpackage.resources[0].url

    return {'resource': resource, 'package': package}


class TestProxyPrettyfied(tests.WsgiAppCase, unittest.TestCase):

    serving = False

    @classmethod
    def setup_class(cls):
        cls._original_config = config.copy()
        config['ckan.plugins'] = 'resource_proxy'
        wsgiapp = middleware.make_app(config['global_conf'], **config)
        cls.app = paste.fixture.TestApp(wsgiapp)

        # create test resource
        create_test_data.CreateTestData.create()

    @classmethod
    def teardown_class(cls):
        config.clear()
        config.update(cls._original_config)
        model.repo.rebuild_db()

    def setUp(self):
        self.url = 'http://www.ckan.org/static/example.json'
        self.data_dict = set_resource_url(self.url)

    def register(self, *args, **kwargs):
        httpretty.HTTPretty.register_uri(httpretty.HTTPretty.GET, *args, **kwargs)
        httpretty.HTTPretty.register_uri(httpretty.HTTPretty.HEAD, *args, **kwargs)

    @httpretty.activate
    def test_resource_proxy_on_200(self):
        self.register(
            self.url,
            content_type='application/json',
            body=JSON_STRING)

        url = self.data_dict['resource']['url']
        result = requests.get(url)
        assert result.status_code == 200, result.status_code
        assert "yes, I'm proxied" in result.content, result.content

    @httpretty.activate
    def test_resource_proxy_on_404(self):
        self.register(
            self.url,
            body="I'm not here",
            content_type='application/json',
            status=404)

        url = self.data_dict['resource']['url']
        result = requests.get(url)
        assert result.status_code == 404, result.status_code

        proxied_url = proxy.get_proxified_resource_url(self.data_dict)
        result = self.app.get(proxied_url, status='*')
        # we expect a 409 because the resourceproxy got an error (404)
        # from the server
        assert result.status == 409, result.status
        assert '404' in result.body

    @httpretty.activate
    def test_large_file(self):
        cl = controller.MAX_FILE_SIZE + 1
        self.register(
            self.url,
            content_length=cl,
            body='c' * cl)

        proxied_url = proxy.get_proxified_resource_url(self.data_dict)
        result = self.app.get(proxied_url, status='*')
        assert result.status == 409, result.status
        assert 'too large' in result.body, result.body

    @httpretty.activate
    def test_large_file_streaming(self):
        cl = controller.MAX_FILE_SIZE + 1
        self.register(
            self.url,
            streaming=True,
            body='c' * cl)

        proxied_url = proxy.get_proxified_resource_url(self.data_dict)
        result = self.app.get(proxied_url, status='*')
        assert result.status == 409, result.status
        assert 'too large' in result.body, result.body

    @httpretty.activate
    def test_invalid_url(self):
        self.data_dict = set_resource_url('javascript:downloadFile(foo)')

        proxied_url = proxy.get_proxified_resource_url(self.data_dict)
        result = self.app.get(proxied_url, status='*')
        assert result.status == 409, result.status
        assert 'Invalid URL' in result.body, result.body

    def test_non_existent_url(self):
        self.data_dict = set_resource_url('http://foo.bar')

        def f1():
            url = self.data_dict['resource']['url']
            requests.get(url)
        self.assertRaises(requests.ConnectionError, f1)

        proxied_url = proxy.get_proxified_resource_url(self.data_dict)
        result = self.app.get(proxied_url, status='*')
        assert result.status == 502, result.status
        assert 'connection error' in result.body, result.body

    def test_non_existent_resource(self):
        self.data_dict = {'package': {'name': 'doesnotexist'},
                          'resource': {'id': 'doesnotexist'}}

        proxied_url = proxy.get_proxified_resource_url(self.data_dict)
        result = self.app.get(proxied_url, status='*')
        assert result.status == 404, result.status
        assert 'Resource not found' in result.body, result.body

########NEW FILE########
__FILENAME__ = controller
import ckan.plugins as p
from ckan.lib.base import BaseController, config
import stats as stats_lib
import ckan.lib.helpers as h

class StatsController(BaseController):

    def index(self):
        c = p.toolkit.c
        stats = stats_lib.Stats()
        rev_stats = stats_lib.RevisionStats()
        c.top_rated_packages = stats.top_rated_packages()
        c.most_edited_packages = stats.most_edited_packages()
        c.largest_groups = stats.largest_groups()
        c.top_tags = stats.top_tags()
        c.top_package_owners = stats.top_package_owners()
        c.new_packages_by_week = rev_stats.get_by_week('new_packages')
        c.deleted_packages_by_week = rev_stats.get_by_week('deleted_packages')
        c.num_packages_by_week = rev_stats.get_num_packages_by_week()
        c.package_revisions_by_week = rev_stats.get_by_week('package_revisions')

        # Used in the legacy CKAN templates.
        c.packages_by_week = []

        # Used in new CKAN templates gives more control to the templates for formatting.
        c.raw_packages_by_week = []
        for week_date, num_packages, cumulative_num_packages in c.num_packages_by_week:
            c.packages_by_week.append('[new Date(%s), %s]' % (week_date.replace('-', ','), cumulative_num_packages))
            c.raw_packages_by_week.append({'date': h.date_str_to_datetime(week_date), 'total_packages': cumulative_num_packages})

        c.all_package_revisions = []
        c.raw_all_package_revisions = []
        for week_date, revs, num_revisions, cumulative_num_revisions in c.package_revisions_by_week:
            c.all_package_revisions.append('[new Date(%s), %s]' % (week_date.replace('-', ','), num_revisions))
            c.raw_all_package_revisions.append({'date': h.date_str_to_datetime(week_date), 'total_revisions': num_revisions})

        c.new_datasets = []
        c.raw_new_datasets = []
        for week_date, pkgs, num_packages, cumulative_num_packages in c.new_packages_by_week:
            c.new_datasets.append('[new Date(%s), %s]' % (week_date.replace('-', ','), num_packages))
            c.raw_new_datasets.append({'date': h.date_str_to_datetime(week_date), 'new_packages': num_packages})

        return p.toolkit.render('ckanext/stats/index.html')

    def leaderboard(self, id=None):
        c = p.toolkit.c
        c.solr_core_url = config.get('ckanext.stats.solr_core_url',
                'http://solr.okfn.org/solr/ckan')
        return p.toolkit.render('ckanext/stats/leaderboard.html')


########NEW FILE########
__FILENAME__ = plugin
from logging import getLogger

import ckan.plugins as p

log = getLogger(__name__)

class StatsPlugin(p.SingletonPlugin):
    '''Stats plugin.'''

    p.implements(p.IRoutes, inherit=True)
    p.implements(p.IConfigurer, inherit=True)

    def after_map(self, map):
        map.connect('stats', '/stats',
            controller='ckanext.stats.controller:StatsController',
            action='index')
        map.connect('stats_action', '/stats/{action}',
            controller='ckanext.stats.controller:StatsController')
        return map

    def update_config(self, config):
        templates = 'templates'
        if p.toolkit.asbool(config.get('ckan.legacy_templates', False)):
                templates = 'templates_legacy'
        p.toolkit.add_template_directory(config, templates)
        p.toolkit.add_public_directory(config, 'public')
        p.toolkit.add_resource('public/ckanext/stats', 'ckanext_stats')

########NEW FILE########
__FILENAME__ = stats
import datetime

from pylons import config
from sqlalchemy import Table, select, func, and_

import ckan.plugins as p
import ckan.model as model

cache_enabled = p.toolkit.asbool(config.get('ckanext.stats.cache_enabled', 'True'))

if cache_enabled:
    from pylons import cache
    our_cache = cache.get_cache('stats', type='dbm')

DATE_FORMAT = '%Y-%m-%d'

def table(name):
    return Table(name, model.meta.metadata, autoload=True)

def datetime2date(datetime_):
    return datetime.date(datetime_.year, datetime_.month, datetime_.day)


class Stats(object):
    @classmethod
    def top_rated_packages(cls, limit=10):
        # NB Not using sqlalchemy as sqla 0.4 doesn't work using both group_by
        # and apply_avg
        package = table('package')
        rating = table('rating')
        sql = select([package.c.id, func.avg(rating.c.rating), func.count(rating.c.rating)], from_obj=[package.join(rating)]).\
              group_by(package.c.id).\
              order_by(func.avg(rating.c.rating).desc(), func.count(rating.c.rating).desc()).\
              limit(limit)
        res_ids = model.Session.execute(sql).fetchall()
        res_pkgs = [(model.Session.query(model.Package).get(unicode(pkg_id)), avg, num) for pkg_id, avg, num in res_ids]
        return res_pkgs

    @classmethod
    def most_edited_packages(cls, limit=10):
        package_revision = table('package_revision')
        s = select([package_revision.c.id, func.count(package_revision.c.revision_id)]).\
            group_by(package_revision.c.id).\
            order_by(func.count(package_revision.c.revision_id).desc()).\
            limit(limit)
        res_ids = model.Session.execute(s).fetchall()
        res_pkgs = [(model.Session.query(model.Package).get(unicode(pkg_id)), val) for pkg_id, val in res_ids]
        return res_pkgs

    @classmethod
    def largest_groups(cls, limit=10):
        member = table('member')
        s = select([member.c.group_id, func.count(member.c.table_id)]).\
            group_by(member.c.group_id).\
            where(and_(member.c.group_id!=None, member.c.table_name=='package')).\
            order_by(func.count(member.c.table_id).desc()).\
            limit(limit)

        res_ids = model.Session.execute(s).fetchall()
        res_groups = [(model.Session.query(model.Group).get(unicode(group_id)), val) for group_id, val in res_ids]
        return res_groups

    @classmethod
    def top_tags(cls, limit=10, returned_tag_info='object'): # by package
        assert returned_tag_info in ('name', 'id', 'object')
        tag = table('tag')
        package_tag = table('package_tag')
        #TODO filter out tags with state=deleted
        if returned_tag_info == 'name':
            from_obj = [package_tag.join(tag)]
            tag_column = tag.c.name
        else:
            from_obj = None
            tag_column = package_tag.c.tag_id
        s = select([tag_column, func.count(package_tag.c.package_id)],
                    from_obj=from_obj)
        s = s.group_by(tag_column).\
            order_by(func.count(package_tag.c.package_id).desc()).\
            limit(limit)
        res_col = model.Session.execute(s).fetchall()
        if returned_tag_info in ('id', 'name'):
            return res_col
        elif returned_tag_info == 'object':
            res_tags = [(model.Session.query(model.Tag).get(unicode(tag_id)), val) for tag_id, val in res_col]
            return res_tags

    @classmethod
    def top_package_owners(cls, limit=10):
        package_role = table('package_role')
        user_object_role = table('user_object_role')
        s = select([user_object_role.c.user_id, func.count(user_object_role.c.role)], from_obj=[user_object_role.join(package_role)]).\
            where(user_object_role.c.role==model.authz.Role.ADMIN).\
            where(user_object_role.c.user_id!=None).\
            group_by(user_object_role.c.user_id).\
            order_by(func.count(user_object_role.c.role).desc()).\
            limit(limit)
        res_ids = model.Session.execute(s).fetchall()
        res_users = [(model.Session.query(model.User).get(unicode(user_id)), val) for user_id, val in res_ids]
        return res_users

class RevisionStats(object):
    @classmethod
    def package_addition_rate(cls, weeks_ago=0):
        week_commenced = cls.get_date_weeks_ago(weeks_ago)
        return cls.get_objects_in_a_week(week_commenced,
                                          type_='package_addition_rate')

    @classmethod
    def package_revision_rate(cls, weeks_ago=0):
        week_commenced = cls.get_date_weeks_ago(weeks_ago)
        return cls.get_objects_in_a_week(week_commenced,
                                          type_='package_revision_rate')

    @classmethod
    def get_date_weeks_ago(cls, weeks_ago):
        '''
        @param weeks_ago: specify how many weeks ago to give count for
                          (0 = this week so far)
        '''
        date_ = datetime.date.today()
        return date_ - datetime.timedelta(days=
                             datetime.date.weekday(date_) + 7 * weeks_ago)

    @classmethod
    def get_week_dates(cls, weeks_ago):
        '''
        @param weeks_ago: specify how many weeks ago to give count for
                          (0 = this week so far)
        '''
        package_revision = table('package_revision')
        revision = table('revision')
        today = datetime.date.today()
        date_from = datetime.datetime(today.year, today.month, today.day) -\
                    datetime.timedelta(days=datetime.date.weekday(today) + \
                                       7 * weeks_ago)
        date_to = date_from + datetime.timedelta(days=7)
        return (date_from, date_to)

    @classmethod
    def get_date_week_started(cls, date_):
        assert isinstance(date_, datetime.date)
        if isinstance(date_, datetime.datetime):
            date_ = datetime2date(date_)
        return date_ - datetime.timedelta(days=datetime.date.weekday(date_))

    @classmethod
    def get_package_revisions(cls):
        '''
        @return: Returns list of revisions and date of them, in
                 format: [(id, date), ...]
        '''
        package_revision = table('package_revision')
        revision = table('revision')
        s = select([package_revision.c.id, revision.c.timestamp], from_obj=[package_revision.join(revision)]).order_by(revision.c.timestamp)
        res = model.Session.execute(s).fetchall() # [(id, datetime), ...]
        return res

    @classmethod
    def get_new_packages(cls):
        '''
        @return: Returns list of new pkgs and date when they were created, in
                 format: [(id, date_ordinal), ...]
        '''
        def new_packages():
            # Can't filter by time in select because 'min' function has to
            # be 'for all time' else you get first revision in the time period.
            package_revision = table('package_revision')
            revision = table('revision')
            s = select([package_revision.c.id, func.min(revision.c.timestamp)], from_obj=[package_revision.join(revision)]).group_by(package_revision.c.id).order_by(func.min(revision.c.timestamp))
            res = model.Session.execute(s).fetchall() # [(id, datetime), ...]
            res_pickleable = []
            for pkg_id, created_datetime in res:
                res_pickleable.append((pkg_id, created_datetime.toordinal()))
            return res_pickleable
        if cache_enabled:
            week_commences = cls.get_date_week_started(datetime.date.today())
            key = 'all_new_packages_%s' + week_commences.strftime(DATE_FORMAT)
            new_packages = our_cache.get_value(key=key,
                                               createfunc=new_packages)
        else:
            new_packages = new_packages()
        return new_packages

    @classmethod
    def get_deleted_packages(cls):
        '''
        @return: Returns list of deleted pkgs and date when they were deleted, in
                 format: [(id, date_ordinal), ...]
        '''
        def deleted_packages():
            # Can't filter by time in select because 'min' function has to
            # be 'for all time' else you get first revision in the time period.
            package_revision = table('package_revision')
            revision = table('revision')
            s = select([package_revision.c.id, func.min(revision.c.timestamp)], from_obj=[package_revision.join(revision)]).\
                where(package_revision.c.state==model.State.DELETED).\
                group_by(package_revision.c.id).\
                order_by(func.min(revision.c.timestamp))
            res = model.Session.execute(s).fetchall() # [(id, datetime), ...]
            res_pickleable = []
            for pkg_id, deleted_datetime in res:
                res_pickleable.append((pkg_id, deleted_datetime.toordinal()))
            return res_pickleable
        if cache_enabled:
            week_commences = cls.get_date_week_started(datetime.date.today())
            key = 'all_deleted_packages_%s' + week_commences.strftime(DATE_FORMAT)
            deleted_packages = our_cache.get_value(key=key,
                                                   createfunc=deleted_packages)
        else:
            deleted_packages = deleted_packages()
        return deleted_packages

    @classmethod
    def get_num_packages_by_week(cls):
        def num_packages():
            new_packages_by_week = cls.get_by_week('new_packages')
            deleted_packages_by_week = cls.get_by_week('deleted_packages')
            first_date = (min(datetime.datetime.strptime(new_packages_by_week[0][0], DATE_FORMAT),
                              datetime.datetime.strptime(deleted_packages_by_week[0][0], DATE_FORMAT))).date()
            cls._cumulative_num_pkgs = 0
            new_pkgs = []
            deleted_pkgs = []
            def build_weekly_stats(week_commences, new_pkg_ids, deleted_pkg_ids):
                num_pkgs = len(new_pkg_ids) - len(deleted_pkg_ids)
                new_pkgs.extend([model.Session.query(model.Package).get(id).name for id in new_pkg_ids])
                deleted_pkgs.extend([model.Session.query(model.Package).get(id).name for id in deleted_pkg_ids])
                cls._cumulative_num_pkgs += num_pkgs
                return (week_commences.strftime(DATE_FORMAT),
                        num_pkgs, cls._cumulative_num_pkgs)
            week_ends = first_date
            today = datetime.date.today()
            new_package_week_index = 0
            deleted_package_week_index = 0
            weekly_numbers = [] # [(week_commences, num_packages, cumulative_num_pkgs])]
            while week_ends <= today:
                week_commences = week_ends
                week_ends = week_commences + datetime.timedelta(days=7)
                if datetime.datetime.strptime(new_packages_by_week[new_package_week_index][0], DATE_FORMAT).date() == week_commences:
                    new_pkg_ids = new_packages_by_week[new_package_week_index][1]
                    new_package_week_index += 1
                else:
                    new_pkg_ids = []
                if datetime.datetime.strptime(deleted_packages_by_week[deleted_package_week_index][0], DATE_FORMAT).date() == week_commences:
                    deleted_pkg_ids = deleted_packages_by_week[deleted_package_week_index][1]
                    deleted_package_week_index += 1
                else:
                    deleted_pkg_ids = []
                weekly_numbers.append(build_weekly_stats(week_commences, new_pkg_ids, deleted_pkg_ids))
            # just check we got to the end of each count
            assert new_package_week_index == len(new_packages_by_week)
            assert deleted_package_week_index == len(deleted_packages_by_week)
            return weekly_numbers
        if cache_enabled:
            week_commences = cls.get_date_week_started(datetime.date.today())
            key = 'number_packages_%s' + week_commences.strftime(DATE_FORMAT)
            num_packages = our_cache.get_value(key=key,
                                               createfunc=num_packages)
        else:
            num_packages = num_packages()
        return num_packages

    @classmethod
    def get_by_week(cls, object_type):
        cls._object_type = object_type
        def objects_by_week():
            if cls._object_type == 'new_packages':
                objects = cls.get_new_packages()
                def get_date(object_date):
                    return datetime.date.fromordinal(object_date)
            elif cls._object_type == 'deleted_packages':
                objects = cls.get_deleted_packages()
                def get_date(object_date):
                    return datetime.date.fromordinal(object_date)
            elif cls._object_type == 'package_revisions':
                objects = cls.get_package_revisions()
                def get_date(object_date):
                    return datetime2date(object_date)
            else:
                raise NotImplementedError()
            first_date = get_date(objects[0][1]) if objects else datetime.date.today()
            week_commences = cls.get_date_week_started(first_date)
            week_ends = week_commences + datetime.timedelta(days=7)
            week_index = 0
            weekly_pkg_ids = [] # [(week_commences, [pkg_id1, pkg_id2, ...])]
            pkg_id_stack = []
            cls._cumulative_num_pkgs = 0
            def build_weekly_stats(week_commences, pkg_ids):
                num_pkgs = len(pkg_ids)
                cls._cumulative_num_pkgs += num_pkgs
                return (week_commences.strftime(DATE_FORMAT),
                        pkg_ids, num_pkgs, cls._cumulative_num_pkgs)
            for pkg_id, date_field in objects:
                date_ = get_date(date_field)
                if date_ >= week_ends:
                    weekly_pkg_ids.append(build_weekly_stats(week_commences, pkg_id_stack))
                    pkg_id_stack = []
                    week_commences = week_ends
                    week_ends = week_commences + datetime.timedelta(days=7)
                pkg_id_stack.append(pkg_id)
            weekly_pkg_ids.append(build_weekly_stats(week_commences, pkg_id_stack))
            today = datetime.date.today()
            while week_ends <= today:
                week_commences = week_ends
                week_ends = week_commences + datetime.timedelta(days=7)
                weekly_pkg_ids.append(build_weekly_stats(week_commences, []))
            return weekly_pkg_ids
        if cache_enabled:
            week_commences = cls.get_date_week_started(datetime.date.today())
            key = '%s_by_week_%s' % (cls._object_type, week_commences.strftime(DATE_FORMAT))
            objects_by_week_ = our_cache.get_value(key=key,
                                    createfunc=objects_by_week)
        else:
            objects_by_week_ = objects_by_week()
        return objects_by_week_

    @classmethod
    def get_objects_in_a_week(cls, date_week_commences,
                                 type_='new-package-rate'):
        '''
        @param type: Specifies what to return about the specified week:
                     "package_addition_rate" number of new packages
                     "package_revision_rate" number of package revisions
                     "new_packages" a list of the packages created
                     in a tuple with the date.
                     "deleted_packages" a list of the packages deleted
                     in a tuple with the date.
        @param dates: date range of interest - a tuple:
                     (start_date, end_date)
        '''
        assert isinstance(date_week_commences, datetime.date)
        if type_ in ('package_addition_rate', 'new_packages'):
            object_type = 'new_packages'
        elif type_ == 'deleted_packages':
            object_type = 'deleted_packages'
        elif type_ == 'package_revision_rate':
            object_type = 'package_revisions'
        else:
            raise NotImplementedError()
        objects_by_week = cls.get_by_week(object_type)
        date_wc_str = date_week_commences.strftime(DATE_FORMAT)
        object_ids = None
        for objects_in_a_week in objects_by_week:
            if objects_in_a_week[0] == date_wc_str:
                object_ids = objects_in_a_week[1]
                break
        if object_ids is None:
            raise TypeError('Week specified is outside range')
        assert isinstance(object_ids, list)
        if type_ in ('package_revision_rate', 'package_addition_rate'):
            return len(object_ids)
        elif type_ in ('new_packages', 'deleted_packages'):
            return [ model.Session.query(model.Package).get(pkg_id) \
                     for pkg_id in object_ids ]

########NEW FILE########
__FILENAME__ = test_stats_lib
import datetime
from nose.tools import assert_equal

from ckan.lib.create_test_data import CreateTestData
from ckan import model

from ckanext.stats.stats import Stats, RevisionStats
from ckanext.stats.tests import StatsFixture

class TestStatsPlugin(StatsFixture):
    @classmethod
    def setup_class(cls):
        super(TestStatsPlugin, cls).setup_class()

        CreateTestData.create_arbitrary([
            {'name':'test1', 'groups':['grp1'], 'tags':['tag1']},
            {'name':'test2', 'groups':['grp1', 'grp2'], 'tags':['tag1']},
            {'name':'test3', 'groups':['grp1', 'grp2'], 'tags':['tag1', 'tag2']},
            {'name':'test4'},
            ],
            extra_user_names=['bob'],
            admins=['bob'],
            )
        # hack revision timestamps to be this date
        week1 = datetime.datetime(2011, 1, 5)
        for rev in model.Session.query(model.Revision):
            rev.timestamp = week1 + datetime.timedelta(seconds=1)

        # week 2
        rev = model.repo.new_revision() 
        rev.author = 'bob'
        rev.timestamp = datetime.datetime(2011, 1, 12)
        model.Package.by_name(u'test2').delete()
        model.repo.commit_and_remove()

        # week 3
        rev = model.repo.new_revision() 
        rev.author = 'sandra'
        rev.timestamp = datetime.datetime(2011, 1, 19)
        model.Package.by_name(u'test3').title = 'Test 3'
        model.repo.commit_and_remove()
        rev = model.repo.new_revision() 
        rev.author = 'sandra'
        rev.timestamp = datetime.datetime(2011, 1, 20)
        model.Package.by_name(u'test4').title = 'Test 4'
        model.repo.commit_and_remove()

        # week 4
        rev = model.repo.new_revision() 
        rev.author = 'bob'
        rev.timestamp = datetime.datetime(2011, 1, 26)
        model.Package.by_name(u'test3').notes = 'Test 3 notes'
        model.repo.commit_and_remove()

    @classmethod
    def teardown_class(cls):
        CreateTestData.delete()
        
    def test_top_rated_packages(self):
        pkgs = Stats.top_rated_packages()
        assert pkgs == []

    def test_most_edited_packages(self):
        pkgs = Stats.most_edited_packages()
        pkgs = [(pkg.name, count) for pkg, count in pkgs]
        assert_equal(pkgs[0], ('test3', 3))
        assert_equal(pkgs[1][1], 2) 
        assert_equal(pkgs[2][1], 2) 
        assert_equal(pkgs[3], ('test1', 1)) 

    def test_largest_groups(self):
        grps = Stats.largest_groups()
        grps = [(grp.name, count) for grp, count in grps]
        assert_equal(grps, [('grp1', 3),
                            ('grp2', 2)])

    def test_top_tags(self):
        tags = Stats.top_tags()
        tags = [(tag.name, count) for tag, count in tags]
        assert_equal(tags, [('tag1', 3),
                            ('tag2', 1)])

    def test_top_package_owners(self):
        owners = Stats.top_package_owners()
        owners = [(owner.name, count) for owner, count in owners]
        assert_equal(owners, [('bob', 4)])

    def test_new_packages_by_week(self):
        new_packages_by_week = RevisionStats.get_by_week('new_packages')
        def get_results(week_number):
            date, ids, num, cumulative = new_packages_by_week[week_number]
            return (date, set([model.Session.query(model.Package).get(id).name for id in ids]), num, cumulative)
        assert_equal(get_results(0),
                     ('2011-01-03', set((u'test1', u'test2', u'test3', u'test4')), 4, 4))
        assert_equal(get_results(1),
                     ('2011-01-10', set([]), 0, 4))
        assert_equal(get_results(2),
                     ('2011-01-17', set([]), 0, 4))
        assert_equal(get_results(3),
                     ('2011-01-24', set([]), 0, 4))
        
    def test_deleted_packages_by_week(self):
        deleted_packages_by_week = RevisionStats.get_by_week('deleted_packages')
        def get_results(week_number):
            date, ids, num, cumulative = deleted_packages_by_week[week_number]
            return (date, [model.Session.query(model.Package).get(id).name for id in ids], num, cumulative)
        assert_equal(get_results(0),
                     ('2011-01-10', [u'test2'], 1, 1))
        assert_equal(get_results(1),
                     ('2011-01-17', [], 0, 1))
        assert_equal(get_results(2),
                     ('2011-01-24', [], 0, 1))
        assert_equal(get_results(3),
                     ('2011-01-31', [], 0, 1))

    def test_revisions_by_week(self):
        revisions_by_week = RevisionStats.get_by_week('package_revisions')
        def get_results(week_number):
            date, ids, num, cumulative = revisions_by_week[week_number]
            return (date, num, cumulative)
        num_setup_revs = revisions_by_week[0][2]
        assert 6 > num_setup_revs > 2, num_setup_revs
        assert_equal(get_results(0),
                     ('2011-01-03', num_setup_revs, num_setup_revs))
        assert_equal(get_results(1),
                     ('2011-01-10', 1, num_setup_revs+1))
        assert_equal(get_results(2),
                     ('2011-01-17', 2, num_setup_revs+3))
        assert_equal(get_results(3),
                     ('2011-01-24', 1, num_setup_revs+4))

    def test_num_packages_by_week(self):
        num_packages_by_week = RevisionStats.get_num_packages_by_week()
        # e.g. [('2011-05-30', 3, 3)]
        assert_equal(num_packages_by_week[0], ('2011-01-03', 4, 4))
        assert_equal(num_packages_by_week[1], ('2011-01-10', -1, 3))
        assert_equal(num_packages_by_week[2], ('2011-01-17', 0, 3))
        assert_equal(num_packages_by_week[3], ('2011-01-24', 0, 3))

########NEW FILE########
__FILENAME__ = test_stats_plugin
import os

from ckan.tests import url_for

from ckanext.stats.tests import StatsFixture

class TestStatsPlugin(StatsFixture):

    def test_01_config(self):
        from pylons import config
        paths = config['extra_public_paths']
        publicdir = os.path.join(os.path.dirname(os.path.dirname(__file__)),
            'public')
        assert paths.startswith(publicdir), (publicdir, paths)

    def test_02_index(self):
        url = url_for('stats')
        out = self.app.get(url)
        assert 'Total number of Datasets' in out, out
        assert 'Most Edited Datasets' in out, out

    def test_03_leaderboard(self):
        url = url_for('stats_action', action='leaderboard')
        out = self.app.get(url)
        assert 'Leaderboard' in out, out


########NEW FILE########
__FILENAME__ = test_tag_vocab_plugin
''' THIS PLUGIN IS FOR TESTING PURPOSES ONLY.
Currently this is used in tests/functional/test_tag_vocab.py'''


from pylons import request, tmpl_context as c
from genshi.input import HTML
from genshi.filters import Transformer
from ckan.logic import get_action
from ckan.logic.converters import convert_to_tags, convert_from_tags, free_tags_only
from ckan.logic.schema import default_create_package_schema, default_update_package_schema, default_show_package_schema
from ckan.lib.navl.validators import ignore_missing, keep_extras
from ckan import plugins

TEST_VOCAB_NAME = 'test-vocab'

class MockVocabTagsPlugin(plugins.SingletonPlugin):
    plugins.implements(plugins.IDatasetForm, inherit=True)
    plugins.implements(plugins.IGenshiStreamFilter)

    def is_fallback(self):
        return False

    def package_types(self):
        return ["mock_vocab_tags_plugin"]

    def new_template(self):
        return 'package/new.html'

    def edit_template(self):
        return 'package/edit.html'

    def search_template(self):
        return 'package/search.html'

    def read_template(self):
        return 'package/read.html'

    def history_template(self):
        return 'package/history.html'

    def package_form(self):
        return 'package/new_package_form.html'

    def setup_template_variables(self, context, data_dict=None):
        c.vocab_tags = get_action('tag_list')(context, {'vocabulary_id': TEST_VOCAB_NAME})

    def create_package_schema(self):
        schema = default_create_package_schema()
        schema.update({
            'vocab_tags': [ignore_missing, convert_to_tags(TEST_VOCAB_NAME)],
        })
        return schema

    def update_package_schema(self):
        schema = default_update_package_schema()
        schema.update({
            'vocab_tags': [ignore_missing, convert_to_tags(TEST_VOCAB_NAME)],
        })
        return schema

    def show_package_schema(self):
        schema = default_show_package_schema()
        schema.update({
            'tags': {
                '__extras': [keep_extras, free_tags_only]
            },
            'vocab_tags_selected': [convert_from_tags(TEST_VOCAB_NAME), ignore_missing],
        })
        return schema

    def filter(self, stream):
        routes = request.environ.get('pylons.routes_dict')
        if routes.get('controller') == 'package' \
            and routes.get('action') == 'read':
                # add vocab tags to the bottom of the page
                tags = c.pkg_dict.get('vocab_tags_selected', [])
                for tag in tags:
                    stream = stream | Transformer('body')\
                        .append(HTML('<p>%s</p>' % tag))
        if routes.get('controller') == 'package' \
            and routes.get('action') == 'edit':
                # add vocabs tag select box to edit page
                html = '<select id="vocab_tags" name="vocab_tags" size="60" multiple="multiple">'
                selected_tags = c.pkg_dict.get('vocab_tags_selected', [])
                for tag in c.vocab_tags:
                    if tag in selected_tags:
                        html += '<option selected="selected" value="%s">%s</option>' % (tag, tag)
                    else:
                        html += '<option value="%s">%s</option>' % (tag, tag)
                html += '</select>'
                stream = stream | Transformer('fieldset[@id="basic-information"]').append(HTML(html))
        return stream

########NEW FILE########
__FILENAME__ = plugin
import logging

import ckan.plugins as p

from ckan.common import json

log = logging.getLogger(__name__)

try:
    import ckanext.resourceproxy.plugin as proxy
except ImportError:
    pass


DEFAULT_TEXT_FORMATS = ['text/plain', 'txt', 'plain']
DEFAULT_XML_FORMATS = ['xml', 'rdf', 'rdf+xm', 'owl+xml', 'atom', 'rss']
DEFAULT_JSON_FORMATS = ['json', 'gjson', 'geojson']
DEFAULT_JSONP_FORMATS = ['jsonp']

# returned preview quality will be one but can be overridden here
QUALITY = {
    'text/plain': 2,
    'txt': 2,
    'plain': 2,
    'xml': 2,
    'json': 2,
    'jsonp': 2,
}


class TextPreview(p.SingletonPlugin):
    '''This extension previews JSON(P).'''

    p.implements(p.IConfigurer, inherit=True)
    p.implements(p.IConfigurable, inherit=True)
    p.implements(p.IResourcePreview, inherit=True)

    proxy_is_enabled = False

    def update_config(self, config):
        text_formats = config.get('ckan.preview.text_formats', '').split()
        self.text_formats = text_formats or DEFAULT_TEXT_FORMATS

        xml_formats = config.get('ckan.preview.xml_formats', '').split()
        self.xml_formats = xml_formats or DEFAULT_XML_FORMATS

        json_formats = config.get('ckan.preview.json_formats', '').split()
        self.json_formats = json_formats or DEFAULT_JSON_FORMATS

        jsonp_formats = config.get('ckan.preview.jsonp_formats', '').split()
        self.jsonp_formats = jsonp_formats or DEFAULT_JSONP_FORMATS

        self.no_jsonp_formats = (self.text_formats +
                                 self.xml_formats +
                                 self.json_formats)

        p.toolkit.add_public_directory(config, 'theme/public')
        p.toolkit.add_template_directory(config, 'theme/templates')
        p.toolkit.add_resource('theme/public', 'ckanext-textpreview')

    def configure(self, config):
        self.proxy_is_enabled = config.get('ckan.resource_proxy_enabled')

    def can_preview(self, data_dict):
        resource = data_dict['resource']
        format_lower = resource['format'].lower()

        quality = QUALITY.get(format_lower, 1)

        if format_lower in self.jsonp_formats:
            return {'can_preview': True, 'quality': quality}
        elif format_lower in self.no_jsonp_formats:
            if self.proxy_is_enabled or resource['on_same_domain']:
                return {'can_preview': True, 'quality': quality}
            else:
                return {'can_preview': False,
                        'fixable': 'Enable resource_proxy',
                        'quality': quality}
        return {'can_preview': False}

    def setup_template_variables(self, context, data_dict):
        assert self.can_preview(data_dict)
        p.toolkit.c.preview_metadata = json.dumps({
            'text_formats': self.text_formats,
            'json_formats': self.json_formats,
            'jsonp_formats': self.jsonp_formats,
            'xml_formats': self.xml_formats
        })
        resource = data_dict['resource']
        format_lower = resource['format'].lower()
        if (format_lower in self.no_jsonp_formats and
                self.proxy_is_enabled and not resource['on_same_domain']):
            url = proxy.get_proxified_resource_url(data_dict)
            p.toolkit.c.resource['url'] = url

    def preview_template(self, context, data_dict):
        return 'text.html'

########NEW FILE########
__FILENAME__ = test_preview
import pylons
import paste.fixture

import pylons.config as config

import ckan.logic as logic
import ckan.model as model
import ckan.tests as tests
import ckan.plugins as plugins
import ckan.lib.helpers as h
import ckanext.textpreview.plugin as previewplugin
import ckan.lib.create_test_data as create_test_data
import ckan.config.middleware as middleware


class TestTextPreview(tests.WsgiAppCase):

    @classmethod
    def setup_class(cls):
        wsgiapp = middleware.make_app(config['global_conf'], **config)
        plugins.load('text_preview')
        cls.app = paste.fixture.TestApp(wsgiapp)

        cls.p = previewplugin.TextPreview()
        #cls.p.proxy_is_enabled = False

        # create test resource
        create_test_data.CreateTestData.create()

        context = {
            'model': model,
            'session': model.Session,
            'user': model.User.get('testsysadmin').name
        }

        cls.package = model.Package.get('annakarenina')
        cls.resource = logic.get_action('resource_show')(
            context, {'id': cls.package.resources[1].id})
        cls.resource['url'] = pylons.config.get(
            'ckan.site_url', '//localhost:5000')
        logic.action.update.resource_update(context, cls.resource)

    @classmethod
    def teardown_class(cls):
        plugins.unload('text_preview')
        create_test_data.CreateTestData.delete()

    def test_can_preview(self):
        data_dict = {
            'resource': {
                'format': 'jsonp'
            }
        }
        assert self.p.can_preview(data_dict)['can_preview']

        data_dict = {
            'resource': {
                'format': 'json',
                'on_same_domain': True
            }
        }
        assert self.p.can_preview(data_dict)['can_preview']

        data_dict = {
            'resource': {
                'format': 'xml',
                'on_same_domain': True
            }
        }
        assert self.p.can_preview(data_dict)['can_preview']

        data_dict = {
            'resource': {
                'format': 'txt',
                'on_same_domain': True
            }
        }
        assert self.p.can_preview(data_dict)['can_preview']

        data_dict = {
            'resource': {
                'format': 'foo',
                'on_same_domain': True
            }
        }
        assert not self.p.can_preview(data_dict)['can_preview']

        data_dict = {
            'resource': {
                'format': 'json',
                'on_same_domain': False
            }
        }
        assert not self.p.can_preview(data_dict)['can_preview']

    def test_js_included(self):
        res_id = self.resource['id']
        pack_id = self.package.name
        url = '/dataset/{0}/resource/{1}/preview'.format(pack_id, res_id)
        result = self.app.get(url, status='*')

        assert result.status == 200, result.status
        assert ((('preview_text.js' in result.body)
                or ('preview_text.min.js' in result.body))), result.body
        assert ((('highlight.pack.js' in result.body)
                or ('highlight.pack.js' in result.body))), result.body
        assert 'preload_resource' in result.body, result.body
        assert 'data-module="textpreview"' in result.body, result.body

    def test_css_included(self):
        res_id = self.resource['id']
        pack_id = self.package.name
        url = '/dataset/{0}/resource/{1}/preview'.format(pack_id, res_id)
        result = self.app.get(url, status='*')

        assert result.status == 200, result.status
        assert (('text.css' in result.body)
                or ('text.min.css' in result.body)), result.body
        assert (('github.css' in result.body)
                or ('github.min.css' in result.body)), result.body

    def test_iframe_is_shown(self):
        url = h.url_for(controller='package', action='resource_read',
                        id=self.package.name, resource_id=self.resource['id'])
        result = self.app.get(url)
        assert 'data-module="data-viewer"' in result.body
        assert '<iframe' in result.body

########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# CKAN documentation build configuration file, created by
# sphinx-quickstart on Sun Oct 25 16:47:17 2009.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed automatically).
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys
import os
import subprocess

# If your extensions (or modules documented by autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.append(os.path.abspath('.'))

# General configuration
# ---------------------

rst_epilog = '''

.. |virtualenv_parent_dir| replace:: /usr/lib/ckan
.. |virtualenv| replace:: |virtualenv_parent_dir|/default
.. |activate| replace:: . |virtualenv|/bin/activate
.. |config_parent_dir| replace:: /etc/ckan
.. |config_dir| replace:: |config_parent_dir|/default
.. |production.ini| replace:: |config_dir|/production.ini
.. |development.ini| replace:: |config_dir|/development.ini
.. |git_url| replace:: \https://github.com/ckan/ckan.git
.. |postgres| replace:: PostgreSQL
.. |database| replace:: ckan_default
.. |database_user| replace:: ckan_default
.. |datastore| replace:: datastore_default
.. |datastore_user| replace:: datastore_default
.. |test_database| replace:: ckan_test
.. |test_datastore| replace:: datastore_test
.. |apache_config_file| replace:: /etc/apache2/sites-available/ckan_default
.. |apache.wsgi| replace:: |config_dir|/apache.wsgi
.. |data_dir| replace:: |config_dir|/data
.. |sstore| replace:: |config_dir|/sstore
.. |storage_parent_dir| replace:: /var/lib/ckan
.. |storage_dir| replace:: |storage_parent_dir|/default
.. |storage_path| replace:: |storage_parent_dir|/default
.. |reload_apache| replace:: sudo service apache2 reload
.. |restart_apache| replace:: sudo service apache2 restart
.. |restart_solr| replace:: sudo service jetty restart
.. |solr| replace:: Solr
.. |restructuredtext| replace:: reStructuredText
.. |nginx| replace:: Nginx
.. |sqlite| replace:: SQLite
.. |python| replace:: Python
.. |sqlalchemy| replace:: SQLAlchemy
.. |javascript| replace:: JavaScript
.. |apache| replace:: Apache
.. |nginx_config_file| replace:: /etc/nginx/sites-available/ckan_default
.. |reload_nginx| replace:: sudo service nginx reload
.. |jquery| replace:: jQuery

.. _Jinja2: http://jinja.pocoo.org/
.. _CKAN front page: http://127.0.0.1:5000
.. _bootstrap: http://getbootstrap.com/2.3.2/
.. _CKAN issue tracker: https://github.com/ckan/ckan/issues

'''

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.todo',
    'sphinx.ext.autosummary', 'ckan.plugins.toolkit_sphinx_extension']
autodoc_member_order = 'bysource'
todo_include_todos = True

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8'

# The master toctree document.
master_doc = 'contents'

# General information about the project.
project = u'CKAN'
project_short_name = u'CKAN'
copyright = u'''&copy; 2009-2013, <a href="http://okfn.org/">Open Knowledge Foundation</a>.
    Licensed under <a
    href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons
    Attribution ShareAlike (Unported) v3.0 License</a>.<br />
    <img src="http://i.creativecommons.org/l/by-sa/3.0/80x15.png" alt="CC License Logo" />
    <a href="http://opendefinition.org/"><img src="http://assets.okfn.org/images/ok_buttons/oc_80x15_blue.png" border="0"
      alt="{{ _('Open Content') }}" /></a>
  '''
html_show_sphinx = False

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
import ckan
version = ckan.__version__.rstrip('abcdefgh')
# The full version, including alpha/beta/rc tags.
release = ckan.__version__


def latest_release_tag():
    '''Return the name of the git tag for the latest stable release.

    e.g.: "ckan-2.1.1"

    This requires git to be installed.

    '''
    git_tags = subprocess.check_output(['git', 'tag', '-l']).split()

    # FIXME: We could do more careful pattern matching against ckan-X.Y.Z here.
    release_tags = [tag for tag in git_tags if tag.startswith('ckan-')]

    # git tag -l prints out the tags in the right order anyway, but don't rely
    # on that, sort them again here for good measure.
    release_tags.sort()

    return release_tags[-1]


def latest_release_version():
    '''Return the version number of the latest stable release.

    e.g. "2.1.1"

    '''
    version = latest_release_tag()[len('ckan-'):]

    # TODO: We could assert here that latest_version matches X.Y.Z.

    return version


def latest_package_name():
    '''Return the filename of the Ubuntu package for the latest stable release.

    e.g. "python-ckan_2.1_amd64.deb"

    '''
    # We don't create a new package file name for a patch release like 2.1.1,
    # instead we just update the existing 2.1 package. So package names only
    # have the X.Y part of the version number in them, not X.Y.Z.
    latest_minor_version = latest_release_version()[:3]

    return 'python-ckan_{version}_amd64.deb'.format(
        version=latest_minor_version)


def write_latest_release_file():
    '''Write a file in the doc/ dir containing reStructuredText substitutions
    for the latest release tag name and version number.

    '''
    filename = '_latest_release.rst'
    template = ''':orphan:

.. Some common reStructuredText substitutions.

   **This file is autogenerated!** So don't edit it by hand.

   You can include this file at the top of your ``*.rst`` file with a line
   like::

     .. include:: {filename}

   Then use the substitutions in this file, e.g.::

     |latest_release_version|

.. |latest_release_tag| replace:: {latest_tag}
.. |latest_release_version| replace:: {latest_version}
.. |latest_package_name| replace:: {package_name}

'''
    open(filename, 'w').write(template.format(
        filename=filename,
        latest_tag=latest_release_tag(),
        latest_version=latest_release_version(),
        package_name=latest_package_name(),
        ))


write_latest_release_file()


# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
#unused_docs = []

# List of directories, relative to source directory, that shouldn't be searched
# for source files.
exclude_trees = ['.build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'


# Options for HTML output
# -----------------------
on_rtd = os.environ.get('READTHEDOCS', None) == 'True'
if not on_rtd:
    import sphinx_rtd_theme
    html_theme = 'sphinx_rtd_theme'
    html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

html_sidebars = {
    '**':  ['globaltoc.html'],
}

# The style sheet to use for HTML and HTML Help pages. A file of that name
# must exist either in Sphinx' static/ path, or in one of the custom paths
# given in html_static_path.
#html_style = 'default.css'

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
# html_title = "%s v%s Guide" % (project, release)

# A shorter title for the navigation bar.  Default is the same as html_title.
# html_short_title = "%s Admin Guide" % (project_short_name)

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
# html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = 'images/favicon.ico'

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_use_modindex = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, the reST sources are included in the HTML build as _sources/<name>.
#html_copy_source = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = ''

# Output file base name for HTML help builder.
htmlhelp_basename = 'CKANdoc'


# Options for LaTeX output
# ------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, document class [howto/manual]).
latex_documents = [
  ('contents', 'CKAN.tex', ur'CKAN documentation',
   ur'Open Knowledge Foundation', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_use_modindex = True

########NEW FILE########
__FILENAME__ = profile_tests
# Runs all the tests and save a speed profile to ckan.tests.profile
import nose
import cProfile
command = """nose.main(argv=['--ckan','--with-pylons=test-core.ini', 'ckan/tests', '-x', '-v'])"""
cProfile.runctx( command, globals(), locals(), filename="ckan.tests.profile" )

########NEW FILE########
