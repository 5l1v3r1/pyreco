Run scripts or jobs on a periodic basis
=======================================
Any scripts or jobs added to the minutely, hourly, daily, weekly or monthly
directories will be run on a scheduled basis (frequency is as indicated by the
name of the directory) using run-parts.

run-parts ignores any files that are hidden or dotfiles (.*) or backup
files (*~ or *,)  or named *.{rpmsave,rpmorig,rpmnew,swp,cfsaved}

The presence of two specially named files jobs.deny and jobs.allow controls
how run-parts executes your scripts/jobs.
   jobs.deny  ===> Prevents specific scripts or jobs from being executed.
   jobs.allow ===> Only execute the named scripts or jobs (all other/non-named
                   scripts that exist in this directory are ignored).

The principles of jobs.deny and jobs.allow are the same as those of cron.deny
and cron.allow and are described in detail at: 
   http://docs.redhat.com/docs/en-US/Red_Hat_Enterprise_Linux/6/html/Deployment_Guide/ch-Automating_System_Tasks.html#s2-autotasks-cron-access

See: man crontab or above link for more details and see the the weekly/
     directory for an example.

PLEASE NOTE: The Cron cartridge must be installed in order to run the configured jobs.

Run scripts or jobs on a weekly basis
=====================================
Any scripts or jobs added to this directory will be run on a scheduled basis
(weekly) using run-parts.

run-parts ignores any files that are hidden or dotfiles (.*) or backup
files (*~ or *,)  or named *.{rpmsave,rpmorig,rpmnew,swp,cfsaved} and handles
the files named jobs.deny and jobs.allow specially.

In this specific example, the chronograph script is the only script or job file
executed on a weekly basis (due to white-listing it in jobs.allow). And the
README and chrono.dat file are ignored either as a result of being black-listed
in jobs.deny or because they are NOT white-listed in the jobs.allow file.

For more details, please see ../README.cron file.


Copyright 2013 cloudaice
cloudaice@gmail.com

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Test coverage is almost non-existent, but it's a start.  Be sure to
set PYTHONPATH apprioriately (generally to the root directory of your
tornado checkout) when running tests to make sure you're getting the
version of the tornado package that you expect.
PycURL: Python interface to libcurl
====================================

PycURL is a Python interface to `libcurl`_. PycURL can be used to fetch objects
identified by a URL from a Python program, similar to the `urllib`_ Python module.
PycURL is mature, very fast, and supports a lot of features.

Overview
--------

- libcurl is a free and easy-to-use client-side URL transfer library, supporting
  FTP, FTPS, HTTP, HTTPS, SCP, SFTP, TFTP, TELNET, DICT, LDAP, LDAPS, FILE, IMAP,
  SMTP, POP3 and RTSP. libcurl supports SSL certificates, HTTP POST, HTTP PUT,
  FTP uploading, HTTP form based upload, proxies, cookies, user+password
  authentication  (Basic, Digest, NTLM, Negotiate, Kerberos4), file transfer
  resume, http proxy tunneling and more!

- libcurl is highly portable, it builds and works identically on numerous
  platforms, including Solaris, NetBSD, FreeBSD, OpenBSD, Darwin, HPUX, IRIX,
  AIX, Tru64, Linux, UnixWare, HURD, Windows, Amiga, OS/2, BeOs, Mac OS X,
  Ultrix, QNX, OpenVMS, RISC OS, Novell NetWare, DOS and more...

- libcurl is `free`_, `thread-safe`_, `IPv6 compatible`_, `feature rich`_,
  `well supported`_, `fast`_, `thoroughly documented`_ and is already used by
  many known, big and successful `companies`_ and numerous `applications`_.

.. _free: http://curl.haxx.se/docs/copyright.html
.. _thread-safe: http://curl.haxx.se/libcurl/features.html#thread
.. _`IPv6 compatible`: http://curl.haxx.se/libcurl/features.html#ipv6
.. _`feature rich`: http://curl.haxx.se/libcurl/features.html#features
.. _`well supported`: http://curl.haxx.se/libcurl/features.html#support
.. _`fast`: http://curl.haxx.se/libcurl/features.html#fast
.. _`thoroughly documented`: http://curl.haxx.se/libcurl/features.html#docs
.. _companies: http://curl.haxx.se/docs/companies.html
.. _applications: http://curl.haxx.se/libcurl/using/apps.html

Installation
------------

You can install the most recent PycURL version using `easy_install`_::

    easy_install pycurl

or `pip`_::

    pip install pycurl


.. _easy_install: http://peak.telecommunity.com/DevCenter/EasyInstall
.. _pip: http://pypi.python.org/pypi/pip

Automated Tests
---------------

PycURL comes with an automated test suite. To run the tests, execute::

    make test

The suite depends on packages `nose`_, `bottle`_ and `cherrypy`_.

Some tests use vsftpd configured to accept anonymous uploads. These tests
are not run by default. As configured, vsftpd will allow reads and writes to
anything the user running the tests has read and write access. To run
vsftpd tests you must explicitly set PYCURL_VSFTPD_PATH variable like so::

    # use vsftpd in PATH
    export PYCURL_VSFTPD_PATH=vsftpd

    # specify full path to vsftpd
    export PYCURL_VSFTPD_PATH=/usr/local/libexec/vsftpd

.. _nose: https://nose.readthedocs.org/
.. _bottle: http://bottlepy.org/
.. _cherrypy: http://www.cherrypy.org/

Contribute
----------

For smaller changes:

#. Fork `the repository`_ on Github.
#. Create a branch off **master**.
#. Make your changes.
#. Write a test which shows that the bug was fixed or that the feature
   works as expected.
#. Send a pull request.

For larger changes:

#. Join the `mailing list`_.
#. Discuss your proposal on the mailing list.
#. When consensus is reached, implement it as described above.

.. image:: https://api.travis-ci.org/pycurl/pycurl.png
	   :target: https://travis-ci.org/pycurl/pycurl

License
-------

::

    Copyright (C) 2001-2008 by Kjetil Jacobsen <kjetilja at gmail.com>
    Copyright (C) 2001-2008 by Markus F.X.J. Oberhumer <markus at oberhumer.com>

    All rights reserved.

    PycURL is dual licensed under the LGPL and an MIT/X derivative license
    based on the cURL license.  A full copy of the LGPL license is included
    in the file COPYING.  A full copy of the MIT/X derivative license is
    included in the file COPYING2.  You can redistribute and/or modify PycURL
    according to the terms of either license.

.. _PycURL: http://pycurl.sourceforge.net/
.. _libcurl: http://curl.haxx.se/libcurl/
.. _urllib: http://docs.python.org/library/urllib.html
.. _`the repository`: https://github.com/pycurl/pycurl
.. _`mailing list`: http://cool.haxx.se/mailman/listinfo/curl-and-python

Make Data Simple Beautiful
==========================


Github用户活跃度排名
--------------------

+ 中国大陆地区Github用户分布地图 

+ 世界范围内的Github用户分布地图

+ 中国大陆地区Github用户活跃度排名

+ 世界范围内Github用户活跃度排名



实现
----

+ Python Tornado 框架，利用gen模块的coroune异步抓取数据

+ 使用`Github API`搜索followers前1000的用户, 结合网页抓取获取用户信息。

+ 部署在heroku上



排名计算
-------

Formula:

    Formula = lambda x: 2 ** 10 / (1 + pow(exp(1), -(x - 2 ** 7) / 2 ** 5))

![formula](http://data.cloudaice.com/static/img/formula.jpg)


Score:

    Score = Formula(followers) + Contributions

首先抓取followers排名前1000的用户，然后再使用公式计算Score值。
因此followers排名进不了前1000，根本不会进入到score计算阶段，
设计这样的计算公式的原因是考虑到followers在前期的增长含金量比较高，
而之后的增加主要是影响力因素，因此，如果你在github初露锋芒，
那么folloers的增加会导致score疯狂上涨。


地名匹配
--------

这是一个比较头痛的事情，也是花费时间最长的步骤。因为每个用户的地名都不一定提到关键省份，
例如在`hangzhou`的用户就习惯直接写`hangzhou`，而不会提及`zhejiang`。
因此这里需要能够模糊匹配的库。
后来在`http://www.geonames.org/`上找到开放接口，通过查询API可以得到简单的模糊匹配结果。
然后在内存中建立缓存，将匹配成功的地名分别update到Github的`gists`文件夹中。

+ [china_location_map](https://gist.github.com/cloudaice/5677947) 
+ [world_location_map](https://gist.github.com/cloudaice/5681176)


匹配不到的再通过手动添加映射。


运行
---

clone该项目，在项目的根目录下创建config.py文件，编辑内容如下:

    from tornado.options import define

    define("username", "your-github-username")
    define("password", "your-github-password")

在根目录下执行 `python app.py`，然后访问浏览器`localhost:8000`


TODO
----

+ ~~完善Github用户所在地分析~~ (#已完成)

+ ~~增加世界范围内用户分布地图~~ (#已完成)

+ 点击地图某一块区域显示该区域的成员列表

+ 迁移到openshift平台



Demo
--------

+ 中国用户分布图

![Github-china](http://cloudaice.com/images/Github-china.png)



+ 世界用户分布图

![Github-world](http://cloudaice.com/images/Github-world.png)


+ 应用地址

[data.cloudaice.com](http://data.cloudaice.com)。


**注**: 由于heroku不支持websocket，因此在线服务版本为ajax轮询版本。
目前在寻找免费的支持websocket的云平台。

另外如果网站打不开，请使用梯子。



更新日志
-------

####2013-05-25

+ 替换原来的ajax，使用websocket传输数据
+ 修改部分页面显示

####2013-05-26

+ 使用`geonames.org`进行模糊地名匹配
+ 修复没有`name`显示为空的bug

####2013-05-31

+ 增加了世界范围内的分布显示
+ 增加模糊匹配缓存文件
+ 修改默认china匹配到上海的bug

