__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# huey documentation build configuration file, created by
# sphinx-quickstart on Wed Nov 16 12:48:28 2011.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = []

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'huey'
copyright = u'2013, charles leifer'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.4.2'
# The full version, including alpha/beta/rc tags.
release = '0.4.2'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
#html_theme = 'flask'
html_theme = 'nature'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {
#    'index_logo': 'logo.jpg',
#}
#
## Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = ['_themes']

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'hueydoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'huey.tex', u'huey Documentation',
   u'charles leifer', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'huey', u'huey Documentation',
     [u'charles leifer'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'huey', u'huey Documentation',
   u'charles leifer', 'huey', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = manage
#!/usr/bin/env python
from django.core.management import execute_manager
import imp
try:
    imp.find_module('settings') # Assumed to be in the same directory.
except ImportError:
    import sys
    sys.stderr.write("Error: Can't find the file 'settings.py' in the directory containing %r. It appears you've customized things.\nYou'll have to run django-admin.py, passing it your settings module.\n" % __file__)
    sys.exit(1)

import settings

if __name__ == "__main__":
    execute_manager(settings)

########NEW FILE########
__FILENAME__ = settings
import logging

INSTALLED_APPS = [
    'huey.djhuey',
    'test_app',
]

HUEY = {
    'name': 'test-django',
    'backend': 'huey.backends.redis_backend',
    'consumer_options': {
        'loglevel': logging.DEBUG,
        'workers': 2,
    }
}

SECRET_KEY = 'foo'

########NEW FILE########
__FILENAME__ = models

########NEW FILE########
__FILENAME__ = tasks
import random
from huey.djhuey import task, periodic_task, crontab, db_task


@task()
def count_beans(number):
    print('-- counted %s beans --' % number)
    return 'Counted %s beans' % number

@periodic_task(crontab(minute='*/5'))
def every_five_mins():
    print('Every five minutes this will be printed by the consumer')

@task(retries=3, retry_delay=10)
def try_thrice():
    if random.randint(1, 3) == 1:
        print('OK')
    else:
        print('About to fail, will retry in 10 seconds')
        raise Exception('Crap something went wrong')

@db_task()
def foo(number):
    print('foo(%s)' % number)

########NEW FILE########
__FILENAME__ = urls
from django.conf.urls.defaults import patterns, include, url

urlpatterns = patterns('',
)

########NEW FILE########
__FILENAME__ = config
from huey import RedisHuey

huey = RedisHuey('testing')

########NEW FILE########
__FILENAME__ = main
from config import huey
from tasks import count_beans


if __name__ == '__main__':
    beans = raw_input('How many beans? ')
    count_beans(int(beans))
    print('Enqueued job to count %s beans' % beans)

########NEW FILE########
__FILENAME__ = tasks
import random
import time
from huey import crontab

from config import huey


@huey.task()
def count_beans(num):
    print('-- counted %s beans --' % num)
    return 'Counted %s beans' % num

@huey.periodic_task(crontab(minute='*/5'))
def every_five_mins():
    print('Consumer prints this every 5 mins')

@huey.task(retries=3, retry_delay=10)
def try_thrice():
    if random.randint(1, 3) == 1:
        print('OK')
    else:
        print('About to fail, will retry in 10 seconds')
        raise Exception('Crap something went wrong')

@huey.task()
def slow(n):
    time.sleep(n)
    print('slept %s' % n)

########NEW FILE########
__FILENAME__ = api
import datetime
import json
import pickle
import re
import time
import traceback
import uuid
from functools import wraps

from huey.backends.dummy import DummySchedule
from huey.exceptions import DataStoreGetException
from huey.exceptions import DataStorePutException
from huey.exceptions import DataStoreTimeout
from huey.exceptions import QueueException
from huey.exceptions import QueueReadException
from huey.exceptions import QueueRemoveException
from huey.exceptions import QueueWriteException
from huey.exceptions import ScheduleAddException
from huey.exceptions import ScheduleReadException
from huey.registry import registry
from huey.utils import EmptyData
from huey.utils import local_to_utc
from huey.utils import wrap_exception


class Huey(object):
    """
    Huey executes tasks by exposing function decorators that cause the function
    call to be enqueued for execution by the consumer.

    Typically your application will only need one Huey instance, but you can
    have as many as you like -- the only caveat is that one consumer process
    must be executed for each Huey instance.

    :param queue: a queue instance, e.g. ``RedisQueue()``
    :param result_store: a place to store results, e.g. ``RedisResultStore()``
    :param schedule: a place to store pending tasks, e.g. ``RedisSchedule()``
    :param events: channel to send events on, e.g. ``RedisEventEmitter()``
    :param store_none: Flag to indicate whether tasks that return ``None``
        should store their results in the result store.
    :param always_eager: Useful for testing, this will execute all tasks
        immediately, without enqueueing them.

    Example usage::

        from huey.api import Huey, crontab
        from huey.backends.redis_backend import RedisQueue, RedisDataStore, RedisSchedule

        queue = RedisQueue('my-app')
        result_store = RedisDataStore('my-app')
        schedule = RedisSchedule('my-app')
        huey = Huey(queue, result_store, schedule)

        # This is equivalent to the previous 4 lines:
        # huey = RedisHuey('my-app', {'host': 'localhost', 'port': 6379})

        @huey.task()
        def slow_function(some_arg):
            # ... do something ...
            return some_arg

        @huey.periodic_task(crontab(minute='0', hour='3'))
        def backup():
            # do a backup every day at 3am
            return
    """
    def __init__(self, queue, result_store=None, schedule=None, events=None,
                 store_none=False, always_eager=False):
        self.queue = queue
        self.result_store = result_store
        self.schedule = schedule or DummySchedule(self.queue.name)
        self.events = events
        self.blocking = self.queue.blocking
        self.store_none = store_none
        self.always_eager = always_eager

    def task(self, retries=0, retry_delay=0, retries_as_argument=False,
             name=None):
        def decorator(func):
            """
            Decorator to execute a function out-of-band via the consumer.
            """
            klass = create_task(QueueTask, func, retries_as_argument, name)

            def schedule(args=None, kwargs=None, eta=None, delay=None,
                         convert_utc=True):
                if delay and eta:
                    raise ValueError('Both a delay and an eta cannot be '
                                     'specified at the same time')
                if delay:
                    eta = (datetime.datetime.now() +
                           datetime.timedelta(seconds=delay))
                if convert_utc and eta:
                    eta = local_to_utc(eta)
                cmd = klass(
                    (args or (), kwargs or {}),
                    execute_time=eta,
                    retries=retries,
                    retry_delay=retry_delay)
                return self.enqueue(cmd)

            func.schedule = schedule
            func.task_class = klass

            @wraps(func)
            def inner_run(*args, **kwargs):
                cmd = klass(
                    (args, kwargs),
                    retries=retries,
                    retry_delay=retry_delay)
                return self.enqueue(cmd)
            return inner_run
        return decorator

    def periodic_task(self, validate_datetime, name=None):
        """
        Decorator to execute a function on a specific schedule.
        """
        def decorator(func):
            def method_validate(self, dt):
                return validate_datetime(dt)

            klass = create_task(
                PeriodicQueueTask,
                func,
                task_name=name,
                validate_datetime=method_validate,
            )

            func.task_class = klass

            def _revoke(revoke_until=None, revoke_once=False):
                self.revoke(klass(), revoke_until, revoke_once)
            func.revoke = _revoke

            def _is_revoked(dt=None, peek=True):
                return self.is_revoked(klass(), dt, peek)
            func.is_revoked = _is_revoked

            def _restore():
                return self.restore(klass())
            func.restore = _restore

            return func
        return decorator

    def _wrapped_operation(exc_class):
        def decorator(fn):
            def inner(*args, **kwargs):
                try:
                    return fn(*args, **kwargs)
                except:
                    wrap_exception(exc_class)
            return inner
        return decorator

    @_wrapped_operation(QueueWriteException)
    def _write(self, msg):
        self.queue.write(msg)

    @_wrapped_operation(QueueReadException)
    def _read(self):
        return self.queue.read()

    @_wrapped_operation(QueueRemoveException)
    def _remove(self, msg):
        return self.queue.remove(msg)

    @_wrapped_operation(DataStoreGetException)
    def _get(self, key, peek=False):
        if peek:
            return self.result_store.peek(key)
        else:
            return self.result_store.get(key)

    @_wrapped_operation(DataStorePutException)
    def _put(self, key, value):
        return self.result_store.put(key, value)

    @_wrapped_operation(ScheduleAddException)
    def _add_schedule(self, data, ts):
        if self.schedule is None:
            raise AttributeError('Schedule not specified.')
        self.schedule.add(data, ts)

    @_wrapped_operation(ScheduleReadException)
    def _read_schedule(self, ts):
        if self.schedule is None:
            raise AttributeError('Schedule not specified.')
        return self.schedule.read(ts)

    def emit(self, message):
        """Events should always fail silently."""
        try:
            self.events.emit(message)
        except:
            pass

    def enqueue(self, task):
        if self.always_eager:
            return task.execute()

        self._write(registry.get_message_for_task(task))

        if self.result_store:
            return AsyncData(self, task)

    def dequeue(self):
        message = self._read()
        if message:
            return registry.get_task_for_message(message)

    def _format_time(self, dt):
        if dt is None:
            return None
        return time.mktime(dt.timetuple())

    def emit_task(self, status, task, error=False):
        if self.events:
            message_data = {'status': status}
            message_data.update({
                'id': task.task_id,
                'task': type(task).__name__,
                'retries': task.retries,
                'retry_delay': task.retry_delay,
                'execute_time': self._format_time(task.execute_time),
                'error': error})
            if error:
                message_data['traceback'] = traceback.format_exc()
            self.emit(json.dumps(message_data))

    def execute(self, task):
        if not isinstance(task, QueueTask):
            raise TypeError('Unknown object: %s' % task)

        result = task.execute()

        if result is None and not self.store_none:
            return

        if self.result_store and not isinstance(task, PeriodicQueueTask):
            self._put(task.task_id, pickle.dumps(result))

        return result

    def revoke(self, task, revoke_until=None, revoke_once=False):
        if not self.result_store:
            raise QueueException('A DataStore is required to revoke task')

        serialized = pickle.dumps((revoke_until, revoke_once))
        self._put(task.revoke_id, serialized)

    def restore(self, task):
        self._get(task.revoke_id)  # simply get and delete if there

    def is_revoked(self, task, dt=None, peek=True):
        if not self.result_store:
            return False
        res = self._get(task.revoke_id, peek=True)
        if res is EmptyData:
            return False
        revoke_until, revoke_once = pickle.loads(res)
        if revoke_once:
            # This task *was* revoked for one run, but now it should be
            # restored to normal execution.
            if not peek:
                self.restore(task)
            return True
        return revoke_until is None or revoke_until > dt

    def add_schedule(self, task):
        msg = registry.get_message_for_task(task)
        ex_time = task.execute_time or datetime.datetime.fromtimestamp(0)
        self._add_schedule(msg, ex_time)

    def read_schedule(self, ts):
        return [
            registry.get_task_for_message(m) for m in self._read_schedule(ts)]

    def flush(self):
        self.queue.flush()

    def ready_to_run(self, cmd, dt=None):
        dt = dt or datetime.datetime.utcnow()
        return cmd.execute_time is None or cmd.execute_time <= dt


class AsyncData(object):
    def __init__(self, huey, task):
        self.huey = huey
        self.task = task

        self._result = EmptyData

    def _get(self):
        task_id = self.task.task_id
        if self._result is EmptyData:
            res = self.huey._get(task_id)

            if res is not EmptyData:
                self._result = pickle.loads(res)
                return self._result
            else:
                return res
        else:
            return self._result

    def get(self, blocking=False, timeout=None, backoff=1.15, max_delay=1.0,
            revoke_on_timeout=False):
        if not blocking:
            res = self._get()
            if res is not EmptyData:
                return res
        else:
            start = time.time()
            delay = .1
            while self._result is EmptyData:
                if timeout and time.time() - start >= timeout:
                    if revoke_on_timeout:
                        self.revoke()
                    raise DataStoreTimeout
                if delay > max_delay:
                    delay = max_delay
                if self._get() is EmptyData:
                    time.sleep(delay)
                    delay *= backoff

            return self._result

    def revoke(self):
        self.huey.revoke(self.task)

    def restore(self):
        self.huey.restore(self.task)


def with_metaclass(meta, base=object):
    return meta("NewBase", (base,), {})


class QueueTaskMetaClass(type):
    def __init__(cls, name, bases, attrs):
        """
        Metaclass to ensure that all task classes are registered
        """
        registry.register(cls)


class QueueTask(with_metaclass(QueueTaskMetaClass)):
    """
    A class that encapsulates the logic necessary to 'do something' given some
    arbitrary data.  When enqueued with the :class:`Huey`, it will be
    stored in a queue for out-of-band execution via the consumer.  See also
    the :meth:`task` decorator, which can be used to automatically
    execute any function out-of-band.

    Example::

    class SendEmailTask(QueueTask):
        def execute(self):
            data = self.get_data()
            send_email(data['recipient'], data['subject'], data['body'])

    huey.enqueue(
        SendEmailTask({
            'recipient': 'somebody@spam.com',
            'subject': 'look at this awesome website',
            'body': 'http://youtube.com'
        })
    )
    """

    def __init__(self, data=None, task_id=None, execute_time=None, retries=0,
                 retry_delay=0):
        self.set_data(data)
        self.task_id = task_id or self.create_id()
        self.revoke_id = 'r:%s' % self.task_id
        self.execute_time = execute_time
        self.retries = retries
        self.retry_delay = retry_delay

    def create_id(self):
        return str(uuid.uuid4())

    def get_data(self):
        return self.data

    def set_data(self, data):
        self.data = data

    def execute(self):
        """Execute any arbitary code here"""
        raise NotImplementedError

    def __eq__(self, rhs):
        return (
            self.task_id == rhs.task_id and
            self.execute_time == rhs.execute_time and
            type(self) == type(rhs))


class PeriodicQueueTask(QueueTask):
    def create_id(self):
        return registry.task_to_string(type(self))

    def validate_datetime(self, dt):
        """Validate that the task should execute at the given datetime"""
        return False


def create_task(task_class, func, retries_as_argument=False, task_name=None,
                **kwargs):
    def execute(self):
        args, kwargs = self.data or ((), {})
        if retries_as_argument:
            kwargs['retries'] = self.retries
        return func(*args, **kwargs)

    attrs = {
        'execute': execute,
        '__module__': func.__module__,
        '__doc__': func.__doc__
    }
    attrs.update(kwargs)

    klass = type(
        task_name or 'queuecmd_%s' % (func.__name__),
        (task_class,),
        attrs
    )

    return klass

dash_re = re.compile('(\d+)-(\d+)')
every_re = re.compile('\*\/(\d+)')

def crontab(month='*', day='*', day_of_week='*', hour='*', minute='*'):
    """
    Convert a "crontab"-style set of parameters into a test function that will
    return True when the given datetime matches the parameters set forth in
    the crontab.

    Acceptable inputs:
    * = every distinct value
    */n = run every "n" times, i.e. hours='*/4' == 0, 4, 8, 12, 16, 20
    m-n = run every time m..n
    m,n = run on m and n
    """
    validation = (
        ('m', month, range(1, 13)),
        ('d', day, range(1, 32)),
        ('w', day_of_week, range(7)),
        ('H', hour, range(24)),
        ('M', minute, range(60))
    )
    cron_settings = []

    for (date_str, value, acceptable) in validation:
        settings = set([])

        if isinstance(value, int):
            value = str(value)

        for piece in value.split(','):
            if piece == '*':
                settings.update(acceptable)
                continue

            if piece.isdigit():
                piece = int(piece)
                if piece not in acceptable:
                    raise ValueError('%d is not a valid input' % piece)
                settings.add(piece)

            else:
                dash_match = dash_re.match(piece)
                if dash_match:
                    lhs, rhs = map(int, dash_match.groups())
                    if lhs not in acceptable or rhs not in acceptable:
                        raise ValueError('%s is not a valid input' % piece)
                    settings.update(range(lhs, rhs+1))
                    continue

                every_match = every_re.match(piece)
                if every_match:
                    interval = int(every_match.groups()[0])
                    settings.update(acceptable[::interval])

        cron_settings.append(sorted(list(settings)))

    def validate_date(dt):
        _, m, d, H, M, _, w, _, _ = dt.timetuple()

        # fix the weekday to be sunday=0
        w = (w + 1) % 7

        for (date_piece, selection) in zip([m, d, w, H, M], cron_settings):
            if date_piece not in selection:
                return False

        return True

    return validate_date

########NEW FILE########
__FILENAME__ = base
class BaseQueue(object):
    """
    Base implementation for a Queue, all backends should subclass
    """

    # whether this backend blocks while waiting for new results or should be
    # polled by the consumer
    blocking = False

    def __init__(self, name, **connection):
        """
        Initialize the Queue - this happens once when the module is loaded

        :param name: A string representation of the name for this queue
        :param connection: Connection parameters for the queue
        """
        self.name = name
        self.connection = connection

    def write(self, data):
        """
        Push 'data' onto the queue
        """
        raise NotImplementedError

    def read(self):
        """
        Pop 'data' from the queue, returning None if no data is available --
        an empty queue should not raise an Exception!
        """
        raise NotImplementedError

    def remove(self, data):
        """
        Remove the given data from the queue
        """
        raise NotImplementedError

    def flush(self):
        """
        Delete everything from the queue
        """
        raise NotImplementedError

    def __len__(self):
        """
        Used primarily in tests, but return the number of items in the queue
        """
        raise NotImplementedError


class BaseSchedule(object):
    def __init__(self, name, **connection):
        """
        Initialize the Queue - this happens once when the module is loaded

        :param name: A string representation of the name for this queue
        :param connection: Connection parameters for the queue
        """
        self.name = name
        self.connection = connection

    def add(self, data, ts):
        """
        Add the timestamped data to the task schedule.
        """
        raise NotImplementedError

    def read(self, ts):
        """
        Read scheduled items for the given timestamp
        """
        raise NotImplementedError

    def flush(self):
        """Delete all items in schedule."""
        raise NotImplementedError


class BaseDataStore(object):
    """
    Base implementation for a data store
    """
    def __init__(self, name, **connection):
        """
        Initialize the data store
        """
        self.name = name
        self.connection = connection

    def put(self, key, value):
        raise NotImplementedError

    def peek(self, key):
        raise NotImplementedError

    def get(self, key):
        raise NotImplementedError

    def flush(self):
        raise NotImplementedError


class BaseEventEmitter(object):
    def __init__(self, channel, **connection):
        self.channel = channel
        self.connection = connection

    def emit(self, message):
        raise NotImplementedError


Components = (BaseQueue, BaseDataStore, BaseSchedule, BaseEventEmitter)

########NEW FILE########
__FILENAME__ = dummy
"""
Test-only implementations of Queue and DataStore.  These will not work for
real applications because they only store tasks/results in memory.
"""
from collections import deque
import heapq

from huey.backends.base import BaseDataStore
from huey.backends.base import BaseEventEmitter
from huey.backends.base import BaseQueue
from huey.backends.base import BaseSchedule
from huey.utils import EmptyData


class DummyQueue(BaseQueue):
    def __init__(self, *args, **kwargs):
        super(DummyQueue, self).__init__(*args, **kwargs)
        self._queue = []

    def write(self, data):
        self._queue.insert(0, data)

    def read(self):
        try:
            return self._queue.pop()
        except IndexError:
            return None

    def flush(self):
        self._queue = []

    def remove(self, data):
        clone = []
        ct = 0
        for elem in self._queue:
            if elem == data:
                ct += 1
            else:
                clone.append(elem)
        self._queue = clone
        return ct

    def __len__(self):
        return len(self._queue)


class DummySchedule(BaseSchedule):
    def __init__(self, *args, **kwargs):
        super(DummySchedule, self).__init__(*args, **kwargs)
        self._schedule = []

    def add(self, data, ts):
        heapq.heappush(self._schedule, (ts, data))

    def read(self, ts):
        res = []
        while len(self._schedule):
            sts, data = heapq.heappop(self._schedule)
            if sts <= ts:
                res.append(data)
            else:
                self.add(data, sts)
                break
        return res

    def flush(self):
        self._schedule = []


class DummyDataStore(BaseDataStore):
    def __init__(self, *args, **kwargs):
        super(DummyDataStore, self).__init__(*args, **kwargs)
        self._results = {}

    def put(self, key, value):
        self._results[key] = value

    def peek(self, key):
        return self._results.get(key, EmptyData)

    def get(self, key):
        return self._results.pop(key, EmptyData)

    def flush(self):
        self._results = {}


class DummyEventEmitter(BaseEventEmitter):
    def __init__(self, *args, **kwargs):
        super(DummyEventEmitter, self).__init__(*args, **kwargs)
        self._events = deque()
        self.__size = 100

    def emit(self, message):
        self._events.appendleft(message)
        num_events = len(self._events)
        if num_events > self.__size * 1.5:
            while num_events > self.__size:
                self._events.popright()
                num_events -= 1


Components = (DummyQueue, DummyDataStore, DummySchedule, DummyEventEmitter)

########NEW FILE########
__FILENAME__ = redis_backend
import re
import time

import redis
from redis.exceptions import ConnectionError

from huey.backends.base import BaseDataStore
from huey.backends.base import BaseEventEmitter
from huey.backends.base import BaseQueue
from huey.backends.base import BaseSchedule
from huey.utils import EmptyData


def clean_name(name):
    return re.sub('[^a-z0-9]', '', name)


class RedisQueue(BaseQueue):
    """
    A simple Queue that uses the redis to store messages
    """
    def __init__(self, name, **connection):
        """
        connection = {
            'host': 'localhost',
            'port': 6379,
            'db': 0,
        }
        """
        super(RedisQueue, self).__init__(name, **connection)

        self.queue_name = 'huey.redis.%s' % clean_name(name)
        self.conn = redis.Redis(**connection)

    def write(self, data):
        self.conn.lpush(self.queue_name, data)

    def read(self):
        return self.conn.rpop(self.queue_name)

    def remove(self, data):
        return self.conn.lrem(self.queue_name, data)

    def flush(self):
        self.conn.delete(self.queue_name)

    def __len__(self):
        return self.conn.llen(self.queue_name)


class RedisBlockingQueue(RedisQueue):
    """
    Use the blocking right pop, should result in messages getting
    executed close to immediately by the consumer as opposed to
    being polled for
    """
    blocking = True

    def read(self):
        try:
            return self.conn.brpop(self.queue_name)[1]
        except ConnectionError:
            # unfortunately, there is no way to differentiate a socket timing
            # out and a host being unreachable
            return None


class RedisSchedule(BaseSchedule):
    def __init__(self, name, **connection):
        super(RedisSchedule, self).__init__(name, **connection)

        self.key = 'huey.schedule.%s' % clean_name(name)
        self.conn = redis.Redis(**connection)

    def convert_ts(self, ts):
        return time.mktime(ts.timetuple())

    def add(self, data, ts):
        self.conn.zadd(self.key, data, self.convert_ts(ts))

    def read(self, ts):
        unix_ts = self.convert_ts(ts)
        tasks = self.conn.zrangebyscore(self.key, 0, unix_ts)
        if len(tasks):
            self.conn.zremrangebyscore(self.key, 0, unix_ts)
        return tasks

    def flush(self):
        self.conn.delete(self.key)


class RedisDataStore(BaseDataStore):
    def __init__(self, name, **connection):
        super(RedisDataStore, self).__init__(name, **connection)

        self.storage_name = 'huey.results.%s' % clean_name(name)
        self.conn = redis.Redis(**connection)

    def put(self, key, value):
        self.conn.hset(self.storage_name, key, value)

    def peek(self, key):
        if self.conn.hexists(self.storage_name, key):
            return self.conn.hget(self.storage_name, key)
        return EmptyData

    def get(self, key):
        val = self.peek(key)
        if val is not EmptyData:
            self.conn.hdel(self.storage_name, key)
        return val

    def flush(self):
        self.conn.delete(self.storage_name)


class RedisEventEmitter(BaseEventEmitter):
    def __init__(self, channel, **connection):
        super(RedisEventEmitter, self).__init__(channel, **connection)
        self.conn = redis.Redis(**connection)

    def emit(self, message):
        self.conn.publish(self.channel, message)


Components = (RedisBlockingQueue, RedisDataStore, RedisSchedule,
              RedisEventEmitter)

########NEW FILE########
__FILENAME__ = sqlite_backend
""" SQLite backend for Huey.

Inspired from a snippet by Thiago Arruda [1]

[1] http://flask.pocoo.org/snippets/88/
"""
import json
import sqlite3
import time
try:
    from thread import get_ident
except ImportError:  # Python 3
    try:
        from threading import get_ident
    except ImportError:
        from _thread import get_ident
    buffer = memoryview

from huey.backends.base import BaseDataStore
from huey.backends.base import BaseEventEmitter
from huey.backends.base import BaseQueue
from huey.backends.base import BaseSchedule
from huey.utils import EmptyData


class _SqliteDatabase(object):
    def __init__(self, location):
        if location == ':memory:':
            raise ValueError("Database location has to be a file path, "
                             "in-memory databases are not supported.")
        self.location = location
        self._conn_cache = {}
        with self.get_connection() as conn:
            # Enable write-ahead logging
            conn.execute("PRAGMA journal_mode=WAL;")
            # Hand over syncing responsibility to OS
            conn.execute("PRAGMA synchronous=OFF;")
            # Store temporary tables and indices in memory
            conn.execute("PRAGMA temp_store=MEMORY;")

    def get_connection(self, immediate=False):
        """ Obtain a sqlite3.Connection instance for the database.

        Connections are cached on a by-thread basis, i.e. every calling thread
        will always get the same Connection object back.
        """
        if immediate:
            return sqlite3.Connection(self.location, timeout=60,
                                      isolation_level="IMMEDIATE")
        id = get_ident()
        if id not in self._conn_cache:
            self._conn_cache[id] = sqlite3.Connection(
                self.location, timeout=60)
        return self._conn_cache[id]


class SqliteQueue(BaseQueue):
    """
    A simple Queue that uses SQLite to store messages
    """
    _create = """
        CREATE TABLE IF NOT EXISTS {0}
        (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          item BLOB
        )
    """
    _count = "SELECT COUNT(*) FROM {0}"
    _append = "INSERT INTO {0} (item) VALUES (?)"
    _get = "SELECT id, item FROM {0} ORDER BY id LIMIT 1"
    _remove_by_value = "DELETE FROM {0} WHERE item = ?"
    _remove_by_id = "DELETE FROM {0} WHERE id = ?"
    _flush = "DELETE FROM {0}"

    def __init__(self, name, location):
        super(SqliteQueue, self).__init__(name, location=location)
        self.queue_name = 'huey_queue_{0}'.format(name)
        self._db = _SqliteDatabase(location)
        with self._db.get_connection() as conn:
            conn.execute(self._create.format(self.queue_name))

    def write(self, data):
        with self._db.get_connection() as conn:
            conn.execute(self._append.format(self.queue_name), (data,))

    def read(self):
        with self._db.get_connection(immediate=True) as conn:
            cursor = conn.execute(self._get.format(self.queue_name))
            try:
                id, data = next(cursor)
            except StopIteration:
                return None
            if id:
                conn.execute(self._remove_by_id.format(self.queue_name), (id,))
                return data

    def remove(self, data):
        with self._db.get_connection() as conn:
            return conn.execute(self._remove_by_value.format(self.queue_name),
                                (data,)).rowcount

    def flush(self):
        with self._db.get_connection() as conn:
            conn.execute(self._flush.format(self.queue_name,))

    def __len__(self):
        with self._db.get_connection() as conn:
            return next(conn.execute(self._count.format(self.queue_name)))[0]


class SqliteSchedule(BaseSchedule):
    _create = """
        CREATE TABLE IF NOT EXISTS {0}
        (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          item BLOB,
          timestamp INTEGER
        )
    """
    _read_items = """
        SELECT item, timestamp FROM {0} WHERE timestamp <= ?
        ORDER BY timestamp
    """
    _delete_items = "DELETE FROM {0} WHERE timestamp <= ?"
    _add_item = "INSERT INTO {0} (item, timestamp) VALUES (?, ?)"
    _flush = "DELETE FROM {0}"

    def __init__(self, name, location):
        super(SqliteSchedule, self).__init__(name, location=location)
        self._db = _SqliteDatabase(location)
        self.name = 'huey_schedule_{0}'.format(name)
        with self._db.get_connection() as conn:
            conn.execute(self._create.format(self.name))

    def convert_ts(self, ts):
        return time.mktime(ts.timetuple())

    def add(self, data, ts):
        with self._db.get_connection() as conn:
            conn.execute(self._add_item.format(self.name),
                         (data, self.convert_ts(ts)))

    def read(self, ts):
        with self._db.get_connection() as conn:
            results = conn.execute(self._read_items.format(self.name),
                                   (self.convert_ts(ts),)).fetchall()
            conn.execute(self._delete_items.format(self.name),
                         (self.convert_ts(ts),))
        return [data for data, _ in results]

    def flush(self):
        with self._db.get_connection() as conn:
            conn.execute(self._flush.format(self.name))


class SqliteDataStore(BaseDataStore):
    _create = """
        CREATE TABLE IF NOT EXISTS {0}
        (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          key TEXT,
          result BLOB
        )
    """
    _put = "INSERT INTO {0} (key, result) VALUES (?, ?)"
    _peek = "SELECT result FROM {0} WHERE key = ?"
    _remove = "DELETE FROM {0} WHERE key = ?"
    _flush = "DELETE FROM {0}"

    def __init__(self, name, location):
        super(SqliteDataStore, self).__init__(name, location=location)
        self._db = _SqliteDatabase(location)
        self.name = 'huey_results_{0}'.format(name)
        with self._db.get_connection() as conn:
            conn.execute(self._create.format(self.name))

    def put(self, key, value):
        with self._db.get_connection() as conn:
            conn.execute(self._remove.format(self.name), (key,))
            conn.execute(self._put.format(self.name), (key, value))

    def peek(self, key):
        with self._db.get_connection() as conn:
            try:
                return next(conn.execute(self._peek.format(self.name),
                                         (key,)))[0]
            except StopIteration:
                return EmptyData

    def get(self, key):
        with self._db.get_connection() as conn:
            try:
                data = next(conn.execute(self._peek.format(self.name),
                                         (key,)))[0]
                conn.execute(self._remove.format(self.name), (key,))
                return data
            except StopIteration:
                return EmptyData

    def flush(self):
        with self._db.get_connection() as conn:
            conn.execute(self._flush.format(self.name))


class SqliteEventEmitter(BaseEventEmitter):
    _create = """
        CREATE TABLE IF NOT EXISTS {0}
        (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          message TEXT
        )
    """
    _purge_old = """
        DELETE FROM {0} WHERE id IN
        (SELECT id FROM {0} ORDER BY id ASC LIMIT ?)
    """
    _emit = "INSERT INTO {0} (message) VALUES (?)"
    _get = "SELECT id, message FROM {0} ORDER BY id DESC LIMIT ?"
    _count = "SELECT COUNT(*) FROM {0}"

    def __init__(self, channel, location, size=500):
        super(SqliteEventEmitter, self).__init__(channel, location=location)
        self._size = size
        self._db = _SqliteDatabase(location)
        self.name = 'huey_events_{0}'.format(channel)
        with self._db.get_connection() as conn:
            conn.execute(self._create.format(self.name))

    def emit(self, message):
        with self._db.get_connection() as conn:
            conn.execute(self._emit.format(self.name), (message,))
            size = next(conn.execute(self._count.format(self.name)))[0]
            if size > self._size:
                conn.execute(self._purge_old.format(self.name),
                             (self._size-200,))

    def read(self):
        wait = 0.1  # Initial wait period
        max_wait = 2  # Maximum wait duration
        tries = 0
        with self._db.get_connection() as conn:
            try:
                last_id = next(
                    conn.execute(self._get.format(self.name), (1,)))[0]
            except StopIteration:
                last_id = 0

            while True:
                try:
                    recent_id = next(
                        conn.execute(self._get.format(self.name), (1,)))[0]
                except StopIteration:
                    recent_id = 0
                if recent_id != last_id:
                    cursor = conn.execute(
                        self._get.format(self.name), (recent_id-last_id,))
                    return (json.loads(msg) for id, msg in cursor)
                else:
                    tries += 1
                    time.sleep(wait)
                    # Increase the wait period
                    wait = min(max_wait, tries/10 + wait)


Components = (SqliteQueue, SqliteDataStore, SqliteSchedule, SqliteEventEmitter)

########NEW FILE########
__FILENAME__ = huey_consumer
#!/usr/bin/env python

import logging
import optparse
import sys
from logging.handlers import RotatingFileHandler

from huey.consumer import Consumer
from huey.utils import load_class


def err(s):
    sys.stderr.write('\033[91m%s\033[0m\n' % s)


def get_loglevel(verbose=None):
    if verbose is None:
        return logging.INFO
    elif verbose:
        return logging.DEBUG
    return logging.ERROR


def setup_logger(loglevel, logfile):
    log_format = ('%(threadName)s %(asctime)s %(name)s '
                  '%(levelname)s %(message)s')
    logging.basicConfig(level=loglevel, format=log_format)

    if logfile:
        handler = RotatingFileHandler(
            logfile, maxBytes=1024*1024, backupCount=3)
        handler.setFormatter(logging.Formatter(log_format))
        logging.getLogger().addHandler(handler)


def get_option_parser():
    parser = optparse.OptionParser(
        'Usage: %prog [options] path.to.huey_instance')
    parser.add_option('-l', '--logfile', dest='logfile',
                      help='write logs to FILE', metavar='FILE')
    parser.add_option('-v', '--verbose', dest='verbose',
                      help='verbose logging', action='store_true')
    parser.add_option('-q', '--quiet', dest='verbose',
                      help='log exceptions only', action='store_false')
    parser.add_option('-w', '--workers', dest='workers', type='int',
                      help='worker threads (default=1)', default=1)
    parser.add_option('-t', '--threads', dest='workers', type='int',
                      help='same as "workers"', default=1)
    parser.add_option('-p', '--periodic', dest='periodic', default=True,
                      help='execute periodic tasks (default=True)',
                      action='store_true')
    parser.add_option('-n', '--no-periodic', dest='periodic',
                      help='do NOT execute periodic tasks',
                      action='store_false')
    parser.add_option('-d', '--delay', dest='initial_delay', type='float',
                      help='initial delay in seconds (default=0.1)',
                      default=0.1)
    parser.add_option('-m', '--max-delay', dest='max_delay', type='float',
                      help='maximum time to wait between polling the queue '
                           '(default=10)',
                      default=10)
    parser.add_option('-b', '--backoff', dest='backoff', type='float',
                      help='amount to backoff delay when no results present '
                           '(default=1.15)',
                      default=1.15)
    parser.add_option('-u', '--utc', dest='utc', action='store_true',
                      help='use UTC time for all tasks (default=True)',
                      default=True)
    parser.add_option('--localtime', dest='utc', action='store_false',
                      help='use local time for all tasks')
    return parser


if __name__ == '__main__':
    parser = get_option_parser()
    options, args = parser.parse_args()

    setup_logger(get_loglevel(options.verbose), options.logfile)

    if len(args) == 0:
        err('Error:   missing import path to `Huey` instance')
        err('Example: huey_consumer.py app.queue.huey_instance')
        sys.exit(1)

    try:
        huey_instance = load_class(args[0])
    except:
        err('Error importing %s' % args[0])
        raise

    consumer = Consumer(
        huey_instance,
        options.workers,
        options.periodic,
        options.initial_delay,
        options.backoff,
        options.max_delay,
        options.utc)
    consumer.run()

########NEW FILE########
__FILENAME__ = consumer
import datetime
import logging
import signal
import threading
import time

from huey.exceptions import DataStoreGetException
from huey.exceptions import QueueException
from huey.exceptions import QueueReadException
from huey.exceptions import DataStorePutException
from huey.exceptions import QueueWriteException
from huey.exceptions import ScheduleAddException
from huey.exceptions import ScheduleReadException
from huey.registry import registry


class ConsumerThread(threading.Thread):
    def __init__(self, huey, utc, shutdown):
        self.huey = huey
        self.utc = utc
        self.shutdown = shutdown
        self._logger = logging.getLogger('huey.consumer.ConsumerThread')
        super(ConsumerThread, self).__init__()

    def get_now(self):
        if self.utc:
            return datetime.datetime.utcnow()
        return datetime.datetime.now()

    def on_shutdown(self):
        pass

    def loop(self, now):
        raise NotImplementedError

    def run(self):
        while not self.shutdown.is_set():
            self.loop()
        self._logger.debug('Thread shutting down')
        self.on_shutdown()

    def enqueue(self, task):
        try:
            self.huey.enqueue(task)
            self.huey.emit_task('enqueued', task)
        except QueueWriteException:
            self._logger.error('Error enqueueing task: %s' % task)

    def add_schedule(self, task):
        try:
            self.huey.add_schedule(task)
            self.huey.emit_task('scheduled', task)
        except ScheduleAddException:
            self._logger.error('Error adding task to schedule: %s' % task)

    def is_revoked(self, task, ts):
        try:
            if self.huey.is_revoked(task, ts, peek=False):
                self.huey.emit_task('revoked', task)
                return True
            return False
        except DataStoreGetException:
            self._logger.error('Error checking if task is revoked: %s' % task)
            return True


class PeriodicTaskThread(ConsumerThread):
    def loop(self, now=None):
        now = now or self.get_now()
        self._logger.debug('Checking periodic command registry')
        start = time.time()
        for task in registry.get_periodic_tasks():
            if task.validate_datetime(now):
                self._logger.info('Scheduling %s for execution' % task)
                self.enqueue(task)
        time.sleep(60 - (time.time() - start))


class SchedulerThread(ConsumerThread):
    def read_schedule(self, ts):
        try:
            return self.huey.read_schedule(ts)
        except ScheduleReadException:
            self._logger.error('Error reading schedule', exc_info=1)
            return []

    def loop(self, now=None):
        now = now or self.get_now()
        start = time.time()

        for task in self.read_schedule(now):
            self._logger.info('Scheduling %s for execution' % task)
            self.enqueue(task)

        delta = time.time() - start
        if delta < 1:
            time.sleep(1 - (time.time() - start))


class WorkerThread(ConsumerThread):
    def __init__(self, huey, default_delay, max_delay, backoff, utc,
                 shutdown):
        self.delay = self.default_delay = default_delay
        self.max_delay = max_delay
        self.backoff = backoff
        self._logger = logging.getLogger('huey.consumer.WorkerThread')
        super(WorkerThread, self).__init__(huey, utc, shutdown)

    def loop(self):
        self.check_message()

    def check_message(self):
        self._logger.debug('Checking for message')
        task = exc_raised = None
        try:
            task = self.huey.dequeue()
        except QueueReadException:
            self._logger.error('Error reading from queue', exc_info=1)
            exc_raised = True
        except QueueException:
            self._logger.error('Queue exception', exc_info=1)
            exc_raised = True
        except:
            self._logger.error('Unknown exception', exc_info=1)
            exc_raised = True

        if task:
            self.delay = self.default_delay
            self.handle_task(task, self.get_now())
        elif exc_raised or not self.huey.blocking:
            self.sleep()

    def sleep(self):
        if self.delay > self.max_delay:
            self.delay = self.max_delay

        self._logger.debug('No messages, sleeping for: %s' % self.delay)
        time.sleep(self.delay)
        self.delay *= self.backoff

    def handle_task(self, task, ts):
        if not self.huey.ready_to_run(task, ts):
            self._logger.info('Adding %s to schedule' % task)
            self.add_schedule(task)
        elif not self.is_revoked(task, ts):
            self.process_task(task, ts)

    def process_task(self, task, ts):
        try:
            self._logger.info('Executing %s' % task)
            self.huey.emit_task('started', task)
            self.huey.execute(task)
            self.huey.emit_task('finished', task)
        except DataStorePutException:
            self._logger.warn('Error storing result', exc_info=1)
        except:
            self._logger.error('Unhandled exception in worker thread',
                               exc_info=1)
            self.huey.emit_task('error', task, error=True)
            if task.retries:
                self.huey.emit_task('retrying', task)
                self.requeue_task(task, self.get_now())

    def requeue_task(self, task, ts):
        task.retries -= 1
        self._logger.info('Re-enqueueing task %s, %s tries left' %
                          (task.task_id, task.retries))
        if task.retry_delay:
            delay = datetime.timedelta(seconds=task.retry_delay)
            task.execute_time = ts + delay
            self._logger.debug('Execute %s at: %s' % (task, task.execute_time))
            self.add_schedule(task)
        else:
            self.enqueue(task)


class Consumer(object):
    def __init__(self, huey, workers=1, periodic=True, initial_delay=0.1,
                 backoff=1.15, max_delay=10.0, utc=True):

        self._logger = logging.getLogger('huey.consumer.ConsumerThread')
        self.huey = huey
        self.workers = workers
        self.periodic = periodic
        self.default_delay = initial_delay
        self.backoff = backoff
        self.max_delay = max_delay
        self.utc = utc

        self.delay = self.default_delay

        self._shutdown = threading.Event()

    def run(self):
        try:
            self.start()
            # it seems that calling self._shutdown.wait() here prevents the
            # signal handler from executing
            while not self._shutdown.is_set():
                self._shutdown.wait(.1)
        except:
            self._logger.error('Error', exc_info=1)
            self.shutdown()

    def start(self):
        self._logger.info('%d worker threads' % self.workers)

        self._set_signal_handler()
        self._log_registered_commands()
        self._create_threads()

        self._logger.info('Starting scheduler thread')
        self.scheduler_t.start()

        self._logger.info('Starting worker threads')
        for worker in self.worker_threads:
            worker.start()

        if self.periodic:
            self._logger.info('Starting periodic task scheduler thread')
            self.periodic_t.start()

    def shutdown(self):
        self._logger.info('Shutdown initiated')
        self._shutdown.set()

    def _handle_signal(self, sig_num, frame):
        self._logger.info('Received SIGTERM')
        self.shutdown()

    def _set_signal_handler(self):
        self._logger.info('Setting signal handler')
        signal.signal(signal.SIGTERM, self._handle_signal)

    def _log_registered_commands(self):
        msg = ['Huey consumer initialized with following commands']
        for command in registry._registry:
            msg.append('+ %s' % command.replace('queuecmd_', ''))
        self._logger.info('\n'.join(msg))

    def _create_threads(self):
        self.scheduler_t = SchedulerThread(self.huey, self.utc, self._shutdown)
        self.scheduler_t.name = 'Scheduler'

        self.worker_threads = []
        for i in range(self.workers):
            worker_t = WorkerThread(
                self.huey,
                self.default_delay,
                self.max_delay,
                self.backoff,
                self.utc,
                self._shutdown)
            worker_t.daemon = True
            worker_t.name = 'Worker %d' % (i + 1)
            self.worker_threads.append(worker_t)

        if self.periodic:
            self.periodic_t = PeriodicTaskThread(
                self.huey, self.utc, self._shutdown)
            self.periodic_t.daemon = True
            self.periodic_t.name = 'Periodic Task'
        else:
            self.periodic_t = None

########NEW FILE########
__FILENAME__ = run_huey
import imp
import sys
from optparse import make_option

from django.conf import settings
from django.core.management.base import BaseCommand
from django.utils.importlib import import_module

from huey.consumer import Consumer
from huey.bin.huey_consumer import get_loglevel
from huey.bin.huey_consumer import setup_logger


class Command(BaseCommand):
    """
    Queue consumer.  Example usage::

    To start the consumer (note you must export the settings module):

    django-admin.py run_huey
    """
    help = "Run the queue consumer"

    option_list = BaseCommand.option_list + (
        make_option('--periodic', '-p',
            dest='periodic',
            action='store_true',
            help='Enqueue periodic commands'
        ),
        make_option('--no-periodic', '-n',
            dest='periodic',
            action='store_false',
            help='Do not enqueue periodic commands'
        ),
        make_option('--workers', '-w',
            dest='workers',
            type='int',
            help='Number of worker threads'
        ),
        make_option('--delay', '-d',
            dest='initial_delay',
            type='float',
            help='Delay between polling requests'
        ),
        make_option('--max_delay', '-m',
            dest='max_delay',
            type='float',
            help='Maximum delay between polling requests'
        ),
    )

    def autodiscover(self):
        # this is to find modules named <commands.py> in a django project's
        # installed apps directories
        module_name = 'tasks'

        for app in settings.INSTALLED_APPS:
            try:
                import_module(app)
                app_path = sys.modules[app].__path__
            except AttributeError:
                continue
            try:
                imp.find_module(module_name, app_path)
            except ImportError:
                continue
            import_module('%s.%s' % (app, module_name))
            app_path = sys.modules['%s.%s' % (app, module_name)]

    def handle(self, *args, **options):
        from huey.djhuey import HUEY
        try:
            consumer_options = settings.HUEY['consumer_options']
        except:
            consumer_options = {}

        if options['workers'] is not None:
            consumer_options['workers'] = options['workers']

        if options['periodic'] is not None:
            consumer_options['periodic'] = options['periodic']

        if options['initial_delay'] is not None:
            consumer_options['initial_delay'] = options['initial_delay']

        if options['max_delay'] is not None:
            consumer_options['max_delay'] = options['max_delay']

        self.autodiscover()

        loglevel = get_loglevel(consumer_options.pop('loglevel', None))
        logfile = consumer_options.pop('logfile', None)
        setup_logger(loglevel, logfile)

        consumer = Consumer(HUEY, **consumer_options)
        consumer.run()

########NEW FILE########
__FILENAME__ = models

########NEW FILE########
__FILENAME__ = exceptions
class QueueException(Exception):
    pass

class QueueWriteException(QueueException):
    pass

class QueueReadException(QueueException):
    pass

class QueueRemoveException(QueueException):
    pass

class DataStoreGetException(QueueException):
    pass

class DataStorePutException(QueueException):
    pass

class DataStoreTimeout(QueueException):
    pass

class ScheduleAddException(QueueException):
    pass

class ScheduleReadException(QueueException):
    pass

########NEW FILE########
__FILENAME__ = registry
import pickle

from huey.exceptions import QueueException


class TaskRegistry(object):
    """
    A simple Registry used to track subclasses of :class:`QueueTask` - the
    purpose of this registry is to allow translation from queue messages to
    task classes, and vice-versa.
    """
    _ignore = ['QueueTask', 'PeriodicQueueTask']

    _registry = {}
    _periodic_tasks = []

    def task_to_string(self, task):
        return '%s' % (task.__name__)

    def register(self, task_class):
        klass_str = self.task_to_string(task_class)
        if klass_str in self._ignore:
            return

        if klass_str not in self._registry:
            self._registry[klass_str] = task_class

            # store an instance in a separate list of periodic tasks
            if hasattr(task_class, 'validate_datetime'):
                self._periodic_tasks.append(task_class())

    def unregister(self, task_class):
        klass_str = self.task_to_string(task_class)

        if klass_str in self._registry:
            del(self._registry[klass_str])

            for task in self._periodic_tasks:
                if isinstance(task, task_class):
                    self._periodic_tasks.remove(task)

    def __contains__(self, klass_str):
        return klass_str in self._registry

    def get_message_for_task(self, task):
        """Convert a task object to a message for storage in the queue"""
        return pickle.dumps((
            task.task_id,
            self.task_to_string(type(task)),
            task.execute_time,
            task.retries,
            task.retry_delay,
            task.get_data(),
        ))

    def get_task_class(self, klass_str):
        klass = self._registry.get(klass_str)

        if not klass:
            raise QueueException('%s not found in TaskRegistry' % klass_str)

        return klass

    def get_task_for_message(self, msg):
        """Convert a message from the queue into a task"""
        # parse out the pieces from the enqueued message
        raw = pickle.loads(msg)
        task_id, klass_str, execute_time, retries, delay, data = raw

        klass = self.get_task_class(klass_str)
        return klass(data, task_id, execute_time, retries, delay)

    def get_periodic_tasks(self):
        return self._periodic_tasks


registry = TaskRegistry()

########NEW FILE########
__FILENAME__ = backends
from collections import deque
import datetime
import os
import sys
import tempfile
import unittest

from huey.backends.dummy import DummyDataStore
from huey.backends.dummy import DummyEventEmitter
from huey.backends.dummy import DummyQueue
from huey.backends.dummy import DummySchedule
from huey.utils import EmptyData
from huey.backends.sqlite_backend import SqliteDataStore
from huey.backends.sqlite_backend import SqliteEventEmitter
from huey.backends.sqlite_backend import SqliteQueue
from huey.backends.sqlite_backend import SqliteSchedule
try:
    from huey.backends.redis_backend import RedisDataStore
    from huey.backends.redis_backend import RedisEventEmitter
    from huey.backends.redis_backend import RedisQueue
    from huey.backends.redis_backend import RedisSchedule
except ImportError:
    RedisQueue = RedisDataStore = RedisSchedule = RedisEventEmitter = None


if sys.version_info[0] == 2:
    redis_kwargs = {}
else:
    redis_kwargs = {'decode_responses': True}


QUEUES = (DummyQueue, RedisQueue, SqliteQueue)
DATA_STORES = (DummyDataStore, RedisDataStore, SqliteDataStore)
SCHEDULES = (DummySchedule, RedisSchedule, SqliteSchedule)
EVENTS = (DummyEventEmitter, RedisEventEmitter, SqliteEventEmitter)


class HueyBackendTestCase(unittest.TestCase):
    def setUp(self):
        self.sqlite_location = tempfile.mkstemp(prefix='hueytest.')[1]

    def tearDown(self):
        os.unlink(self.sqlite_location)

    def test_queues(self):
        for q in QUEUES:
            if not q:
                continue
            if issubclass(q, SqliteQueue):
                queue = q('test', location=self.sqlite_location)
            elif issubclass(q, RedisQueue):
                queue = q('test', **redis_kwargs)
            else:
                queue = q('test')
            queue.flush()
            queue.write('a')
            queue.write('b')
            self.assertEqual(len(queue), 2)
            self.assertEqual(queue.read(), 'a')
            self.assertEqual(queue.read(), 'b')
            self.assertEqual(queue.read(), None)

            queue.write('c')
            queue.write('d')
            queue.write('c')
            queue.write('x')
            queue.write('d')
            self.assertEqual(len(queue), 5)
            self.assertEqual(queue.remove('c'), 2)
            self.assertEqual(len(queue), 3)
            self.assertEqual(queue.read(), 'd')
            self.assertEqual(queue.read(), 'x')
            self.assertEqual(queue.read(), 'd')

    def test_data_stores(self):
        for d in DATA_STORES:
            if not d:
                continue
            if issubclass(d, SqliteDataStore):
                data_store = d('test', location=self.sqlite_location)
            elif issubclass(d, RedisDataStore):
                data_store = d('test', **redis_kwargs)
            else:
                data_store = d('test')
            data_store.put('k1', 'v1')
            data_store.put('k2', 'v2')
            data_store.put('k3', 'v3')
            self.assertEqual(data_store.peek('k2'), 'v2')
            self.assertEqual(data_store.get('k2'), 'v2')
            self.assertEqual(data_store.peek('k2'), EmptyData)
            self.assertEqual(data_store.get('k2'), EmptyData)

            self.assertEqual(data_store.peek('k3'), 'v3')
            data_store.put('k3', 'v3-2')
            self.assertEqual(data_store.peek('k3'), 'v3-2')

    def test_schedules(self):
        for s in SCHEDULES:
            if not s:
                continue
            if issubclass(s, SqliteSchedule):
                schedule = s('test', location=self.sqlite_location)
            elif issubclass(s, RedisSchedule):
                schedule = s('test', **redis_kwargs)
            else:
                schedule = s('test')
            dt1 = datetime.datetime(2013, 1, 1, 0, 0)
            dt2 = datetime.datetime(2013, 1, 2, 0, 0)
            dt3 = datetime.datetime(2013, 1, 3, 0, 0)
            dt4 = datetime.datetime(2013, 1, 4, 0, 0)

            # Add to schedule out-of-order to ensure sorting is performed by
            # the schedule.
            schedule.add('s2', dt2)
            schedule.add('s1', dt1)
            schedule.add('s4', dt4)
            schedule.add('s3', dt3)

            # Ensure that asking for a timestamp previous to any item in the
            # schedule returns empty list.
            self.assertEqual(
                schedule.read(dt1 - datetime.timedelta(days=1)),
                [])

            # Ensure the upper boundary is inclusive of whatever timestamp
            # is passed in.
            self.assertEqual(schedule.read(dt3), ['s1', 's2', 's3'])
            self.assertEqual(schedule.read(dt3), [])

            # Ensure the schedule is flushed and an empty schedule returns an
            # empty list.
            self.assertEqual(schedule.read(dt4), ['s4'])
            self.assertEqual(schedule.read(dt4), [])

    def test_events(self):
        for e in EVENTS:
            if not e:
                continue
            if issubclass(e, SqliteEventEmitter):
                e = e('test', location=self.sqlite_location)
            else:
                e = e('test')

            messages = ['a', 'b', 'c', 'd']
            for message in messages:
                e.emit(message)

            if hasattr(e, '_events'):
                self.assertEqual(e._events, deque(['d', 'c', 'b', 'a']))

########NEW FILE########
__FILENAME__ = consumer
from collections import deque
import datetime
import json
import logging
import threading
import time
import unittest

from huey import crontab
from huey import Huey
from huey.backends.dummy import DummyDataStore
from huey.backends.dummy import DummyEventEmitter
from huey.backends.dummy import DummyQueue
from huey.backends.dummy import DummySchedule
from huey.consumer import Consumer
from huey.consumer import WorkerThread
from huey.registry import registry

# Logger used by the consumer.
logger = logging.getLogger('huey.consumer')

# Store some global state.
state = {}

# Create a queue, result store, schedule and event emitter, then attach them
# to a test-only Huey instance.
test_queue = DummyQueue('test-queue')
test_result_store = DummyDataStore('test-queue')
test_schedule = DummySchedule('test-queue')
test_events = DummyEventEmitter('test-queue')
test_huey = Huey(test_queue, test_result_store, test_schedule, test_events)

# Create some test tasks.
@test_huey.task()
def modify_state(k, v):
    state[k] = v
    return v

@test_huey.task()
def blow_up():
    raise Exception('blowed up')

@test_huey.task(retries=3)
def retry_command(k, always_fail=True):
    if k not in state:
        if not always_fail:
            state[k] = 'fixed'
        raise Exception('fappsk')
    return state[k]

@test_huey.task(retries=3, retry_delay=10)
def retry_command_slow(k, always_fail=True):
    if k not in state:
        if not always_fail:
            state[k] = 'fixed'
        raise Exception('fappsk')
    return state[k]

@test_huey.periodic_task(crontab(minute='0'))
def every_hour():
    state['p'] = 'y'


# Create a log handler that will track messages generated by the consumer.
class TestLogHandler(logging.Handler):
    def __init__(self, *args, **kwargs):
        self.messages = []
        logging.Handler.__init__(self, *args, **kwargs)

    def emit(self, record):
        self.messages.append(record.getMessage())


class ConsumerTestCase(unittest.TestCase):
    def setUp(self):
        global state
        state = {}

        self.orig_pc = registry._periodic_tasks
        registry._periodic_commands = [every_hour.task_class()]

        self.orig_sleep = time.sleep
        time.sleep = lambda x: None

        test_huey.queue.flush()
        test_huey.result_store.flush()
        test_huey.schedule.flush()
        test_events._events = deque()

        self.consumer = Consumer(test_huey, workers=2)
        self.consumer._create_threads()

        self.handler = TestLogHandler()
        logger.addHandler(self.handler)
        logger.setLevel(logging.INFO)

    def tearDown(self):
        self.consumer.shutdown()
        logger.removeHandler(self.handler)
        registry._periodic_tasks = self.orig_pc
        time.sleep = self.orig_sleep

    def assertStatusTask(self, status_task):
        parsed = []
        i = 0
        while i < len(status_task):
            event = json.loads(test_events._events[i])
            status, task, extra = status_task[i]
            self.assertEqual(event['status'], status)
            self.assertEqual(event['id'], task.task_id)
            for k, v in extra.items():
                self.assertEqual(event[k], v)
            i += 1

    def spawn(self, func, *args, **kwargs):
        t = threading.Thread(target=func, args=args, kwargs=kwargs)
        t.start()
        return t

    def run_worker(self, task, ts=None):
        worker_t = WorkerThread(
            test_huey,
            self.consumer.default_delay,
            self.consumer.max_delay,
            self.consumer.backoff,
            self.consumer.utc,
            self.consumer._shutdown)
        ts = ts or datetime.datetime.utcnow()
        worker_t.handle_task(task, ts)

    def test_message_processing(self):
        self.consumer.worker_threads[0].start()

        self.assertFalse('k' in state)

        res = modify_state('k', 'v')
        res.get(blocking=True)

        self.assertTrue('k' in state)
        self.assertEqual(res.get(), 'v')

        self.assertEqual(len(test_events._events), 2)
        self.assertStatusTask([
            ('finished', res.task, {}),
            ('started', res.task, {}),
        ])

    def test_worker(self):
        modify_state('k', 'w')
        task = test_huey.dequeue()
        self.run_worker(task)
        self.assertEqual(state, {'k': 'w'})

    def test_worker_exception(self):
        blow_up()
        task = test_huey.dequeue()

        self.run_worker(task)
        self.assertTrue(
            'Unhandled exception in worker thread' in self.handler.messages)

        self.assertEqual(len(test_events._events), 2)
        self.assertStatusTask([
            ('error', task, {'error': True}),
            ('started', task, {}),
        ])

    def test_retries_and_logging(self):
        # this will continually fail
        retry_command('blampf')

        for i in reversed(range(4)):
            task = test_huey.dequeue()
            self.assertEqual(task.retries, i)
            self.run_worker(task)
            if i > 0:
                self.assertEqual(
                    self.handler.messages[-1],
                    'Re-enqueueing task %s, %s tries left' % (
                        task.task_id, i - 1))
                self.assertStatusTask([
                    ('enqueued', task, {}),
                    ('retrying', task, {}),
                    ('error', task,{}),
                    ('started', task, {}),
                ])
                last_idx = -2
            else:
                self.assertStatusTask([
                    ('error', task,{}),
                    ('started', task, {}),
                ])
                last_idx = -1
            self.assertEqual(self.handler.messages[last_idx],
                             'Unhandled exception in worker thread')

        self.assertEqual(test_huey.dequeue(), None)

    def test_retries_with_success(self):
        # this will fail once, then succeed
        retry_command('blampf', False)
        self.assertFalse('blampf' in state)

        task = test_huey.dequeue()
        self.run_worker(task)
        self.assertEqual(self.handler.messages, [
            'Executing %s' % task,
            'Unhandled exception in worker thread',
            'Re-enqueueing task %s, 2 tries left' % task.task_id])

        task = test_huey.dequeue()
        self.assertEqual(task.retries, 2)
        self.run_worker(task)

        self.assertEqual(state['blampf'], 'fixed')
        self.assertEqual(test_huey.dequeue(), None)

        self.assertStatusTask([
            ('finished', task, {}),
            ('started', task, {}),
            ('enqueued', task, {'retries': 2}),
            ('retrying', task, {'retries': 3}),
            ('error', task, {'error': True}),
            ('started', task, {}),
        ])

    def test_scheduling(self):
        dt = datetime.datetime(2011, 1, 1, 0, 0)
        dt2 = datetime.datetime(2037, 1, 1, 0, 0)
        ad1 = modify_state.schedule(args=('k', 'v'), eta=dt, convert_utc=False)
        ad2 = modify_state.schedule(args=('k2', 'v2'), eta=dt2, convert_utc=False)

        # dequeue the past-timestamped task and run it.
        worker = self.consumer.worker_threads[0]
        worker.check_message()

        self.assertTrue('k' in state)

        # dequeue the future-timestamped task.
        worker.check_message()

        # verify the task got stored in the schedule instead of executing
        self.assertFalse('k2' in state)

        self.assertStatusTask([
            ('scheduled', ad2.task, {}),
            ('finished', ad1.task, {}),
            ('started', ad1.task, {}),
        ])

        # run through an iteration of the scheduler
        self.consumer.scheduler_t.loop(dt)

        # our command was not enqueued and no events were emitted.
        self.assertEqual(len(test_queue._queue), 0)
        self.assertEqual(len(test_events._events), 3)

        # run through an iteration of the scheduler
        self.consumer.scheduler_t.loop(dt2)

        # our command was enqueued
        self.assertEqual(len(test_queue._queue), 1)
        self.assertEqual(len(test_events._events), 4)
        self.assertStatusTask([
            ('enqueued', ad2.task, {}),
        ])

    def test_retry_scheduling(self):
        # this will continually fail
        retry_command_slow('blampf')
        cur_time = datetime.datetime.utcnow()

        task = test_huey.dequeue()
        self.run_worker(task, ts=cur_time)
        self.assertEqual(self.handler.messages, [
            'Executing %s' % task,
            'Unhandled exception in worker thread',
            'Re-enqueueing task %s, 2 tries left' % task.task_id,
        ])

        in_11 = cur_time + datetime.timedelta(seconds=11)
        tasks_from_sched = test_huey.read_schedule(in_11)
        self.assertEqual(tasks_from_sched, [task])

        task = tasks_from_sched[0]
        self.assertEqual(task.retries, 2)
        exec_time = task.execute_time

        self.assertEqual((exec_time - cur_time).seconds, 10)
        self.assertStatusTask([
            ('scheduled', task, {
                'retries': 2,
                'retry_delay': 10,
                'execute_time': time.mktime(exec_time.timetuple())}),
            ('retrying', task, {
                'retries': 3,
                'retry_delay': 10,
                'execute_time': None}),
            ('error', task, {}),
            ('started', task, {}),
        ])

    def test_revoking_normal(self):
        # enqueue 2 normal commands
        r1 = modify_state('k', 'v')
        r2 = modify_state('k2', 'v2')

        # revoke the first *before it has been checked*
        r1.revoke()
        self.assertTrue(test_huey.is_revoked(r1.task))
        self.assertFalse(test_huey.is_revoked(r2.task))

        # dequeue a *single* message (r1)
        task = test_huey.dequeue()
        self.run_worker(task)

        self.assertEqual(len(test_events._events), 1)
        self.assertStatusTask([
            ('revoked', r1.task, {}),
        ])

        # no changes and the task was not added to the schedule
        self.assertFalse('k' in state)

        # dequeue a *single* message
        task = test_huey.dequeue()
        self.run_worker(task)

        self.assertTrue('k2' in state)

    def test_revoking_schedule(self):
        global state
        dt = datetime.datetime(2011, 1, 1)
        dt2 = datetime.datetime(2037, 1, 1)

        r1 = modify_state.schedule(args=('k', 'v'), eta=dt, convert_utc=False)
        r2 = modify_state.schedule(args=('k2', 'v2'), eta=dt, convert_utc=False)
        r3 = modify_state.schedule(args=('k3', 'v3'), eta=dt2, convert_utc=False)
        r4 = modify_state.schedule(args=('k4', 'v4'), eta=dt2, convert_utc=False)

        # revoke r1 and r3
        r1.revoke()
        r3.revoke()
        self.assertTrue(test_huey.is_revoked(r1.task))
        self.assertFalse(test_huey.is_revoked(r2.task))
        self.assertTrue(test_huey.is_revoked(r3.task))
        self.assertFalse(test_huey.is_revoked(r4.task))

        expected = [
            #state,        schedule
            ({},           0),
            ({'k2': 'v2'}, 0),
            ({'k2': 'v2'}, 1),
            ({'k2': 'v2'}, 2),
        ]

        for i in range(4):
            estate, esc = expected[i]

            # dequeue a *single* message
            task = test_huey.dequeue()
            self.run_worker(task)

            self.assertEqual(state, estate)
            self.assertEqual(len(test_huey.schedule._schedule), esc)

        # lets pretend its 2037
        future = dt2 + datetime.timedelta(seconds=1)
        self.consumer.scheduler_t.loop(future)
        self.assertEqual(len(test_huey.schedule._schedule), 0)

        # There are two tasks in the queue now (r3 and r4) -- process both.
        for i in range(2):
            task = test_huey.dequeue()
            self.run_worker(task, future)

        self.assertEqual(state, {'k2': 'v2', 'k4': 'v4'})

    def test_revoking_periodic(self):
        global state
        def loop_periodic(ts):
            self.consumer.periodic_t.loop(ts)
            for i in range(len(test_queue._queue)):
                task = test_huey.dequeue()
                self.run_worker(task, ts)

        # revoke the command once
        every_hour.revoke(revoke_once=True)
        self.assertTrue(every_hour.is_revoked())

        # it will be skipped the first go-round
        dt = datetime.datetime(2011, 1, 1, 0, 0)
        loop_periodic(dt)

        # it has not been run
        self.assertEqual(state, {})

        # the next go-round it will be enqueued
        loop_periodic(dt)

        # our command was run
        self.assertEqual(state, {'p': 'y'})

        # reset state
        state = {}

        # revoke the command
        every_hour.revoke()
        self.assertTrue(every_hour.is_revoked())

        # it will no longer be enqueued
        loop_periodic(dt)
        loop_periodic(dt)
        self.assertEqual(state, {})

        # restore
        every_hour.restore()
        self.assertFalse(every_hour.is_revoked())

        # it will now be enqueued
        loop_periodic(dt)
        self.assertEqual(state, {'p': 'y'})

        # reset
        state = {}

        # revoke for an hour
        td = datetime.timedelta(seconds=3600)
        every_hour.revoke(revoke_until=dt + td)

        loop_periodic(dt)
        self.assertEqual(state, {})

        # after an hour it is back
        loop_periodic(dt + td)
        self.assertEqual(state, {'p': 'y'})

        # our data store should reflect the delay
        task_obj = every_hour.task_class()
        self.assertEqual(len(test_huey.result_store._results), 1)
        self.assertTrue(task_obj.revoke_id in test_huey.result_store._results)

########NEW FILE########
__FILENAME__ = crontab
import datetime
import unittest

from huey import crontab


class CrontabTestCase(unittest.TestCase):
    def test_crontab_month(self):
        # validates the following months, 1, 4, 7, 8, 9
        valids = [1, 4, 7, 8, 9]
        validate_m = crontab(month='1,4,*/6,8-9')

        for x in range(1, 13):
            res = validate_m(datetime.datetime(2011, x, 1))
            self.assertEqual(res, x in valids)

    def test_crontab_day(self):
        # validates the following days
        valids = [1, 4, 7, 8, 9, 13, 19, 25, 31]
        validate_d = crontab(day='*/6,1,4,8-9')

        for x in range(1, 32):
            res = validate_d(datetime.datetime(2011, 1, x))
            self.assertEqual(res, x in valids)

    def test_crontab_hour(self):
        # validates the following hours
        valids = [0, 1, 4, 6, 8, 9, 12, 18]
        validate_h = crontab(hour='8-9,*/6,1,4')

        for x in range(24):
            res = validate_h(datetime.datetime(2011, 1, 1, x))
            self.assertEqual(res, x in valids)

        edge = crontab(hour=0)
        self.assertTrue(edge(datetime.datetime(2011, 1, 1, 0, 0)))
        self.assertFalse(edge(datetime.datetime(2011, 1, 1, 12, 0)))

    def test_crontab_minute(self):
        # validates the following minutes
        valids = [0, 1, 4, 6, 8, 9, 12, 18, 24, 30, 36, 42, 48, 54]
        validate_m = crontab(minute='4,8-9,*/6,1')

        for x in range(60):
            res = validate_m(datetime.datetime(2011, 1, 1, 1, x))
            self.assertEqual(res, x in valids)

    def test_crontab_day_of_week(self):
        # validates the following days of week
        # jan, 1, 2011 is a saturday
        valids = [2, 4, 9, 11, 16, 18, 23, 25, 30]
        validate_dow = crontab(day_of_week='0,2')

        for x in range(1, 32):
            res = validate_dow(datetime.datetime(2011, 1, x))
            self.assertEqual(res, x in valids)

    def test_crontab_all_together(self):
        # jan 1, 2011 is a saturday
        # may 1, 2011 is a sunday
        validate = crontab(
            month='1,5',
            day='1,4,7',
            day_of_week='0,6',
            hour='*/4',
            minute='1-5,10-15,50'
        )

        self.assertTrue(validate(datetime.datetime(2011, 5, 1, 4, 11)))
        self.assertTrue(validate(datetime.datetime(2011, 5, 7, 20, 50)))
        self.assertTrue(validate(datetime.datetime(2011, 1, 1, 0, 1)))

        # fails validation on month
        self.assertFalse(validate(datetime.datetime(2011, 6, 4, 4, 11)))

        # fails validation on day
        self.assertFalse(validate(datetime.datetime(2011, 1, 6, 4, 11)))

        # fails validation on day_of_week
        self.assertFalse(validate(datetime.datetime(2011, 1, 4, 4, 11)))

        # fails validation on hour
        self.assertFalse(validate(datetime.datetime(2011, 1, 1, 1, 11)))

        # fails validation on minute
        self.assertFalse(validate(datetime.datetime(2011, 1, 1, 4, 6)))

    def test_invalid_crontabs(self):
        # check invalid configurations are detected and reported
        self.assertRaises(ValueError, crontab, minute='61')
        self.assertRaises(ValueError, crontab, minute='0-61')

########NEW FILE########
__FILENAME__ = peewee_tests
from contextlib import contextmanager
import unittest

from huey import Huey
from huey.backends.dummy import DummyDataStore
from huey.backends.dummy import DummyQueue
from huey.backends.dummy import DummySchedule
from huey.peewee_helpers import db_periodic_task
from huey.peewee_helpers import db_task
from peewee import *


queue = DummyQueue('test-queue')
schedule = DummySchedule('test-queue')
data_store = DummyDataStore('test-queue')
huey = Huey(queue, data_store, schedule=schedule)

STATE = []

class MockSqliteDatabase(SqliteDatabase):
    def record_call(fn):
        def inner(*args, **kwargs):
            STATE.append(fn.__name__)
            return fn(*args, **kwargs)
        return inner
    connect = record_call(SqliteDatabase.connect)
    close = record_call(SqliteDatabase.close)
    transaction = record_call(SqliteDatabase.transaction)

db = MockSqliteDatabase('test.huey.db')

class Value(Model):
    data = CharField()

    class Meta:
        database = db

    @classmethod
    def create(cls, *args, **kwargs):
        STATE.append('create')
        return super(Value, cls).create(*args, **kwargs)

@db_task(huey, db)
def test_db_task(val):
    return Value.create(data=val)

class TestPeeweeHelpers(unittest.TestCase):
    def setUp(self):
        global STATE
        STATE = []
        queue.flush()
        data_store.flush()
        schedule.flush()
        Value.drop_table(True)
        Value.create_table()

    def test_helper(self):
        test_db_task('foo')
        self.assertEqual(STATE, ['connect'])
        huey.execute(huey.dequeue())
        self.assertEqual(STATE, ['connect', 'transaction', 'create', 'close'])
        self.assertEqual(Value.select().count(), 1)

########NEW FILE########
__FILENAME__ = queue
import datetime
import unittest

from huey import crontab
from huey import Huey
from huey.api import QueueTask
from huey.backends.dummy import DummyDataStore
from huey.backends.dummy import DummyQueue
from huey.backends.dummy import DummySchedule
from huey.registry import registry
from huey.utils import EmptyData
from huey.utils import local_to_utc


queue_name = 'test-queue'
queue = DummyQueue(queue_name)
schedule = DummySchedule(queue_name)
huey = Huey(queue, schedule=schedule)

res_queue_name = 'test-queue-2'
res_queue = DummyQueue(res_queue_name)
res_store = DummyDataStore(res_queue_name)

res_huey = Huey(res_queue, res_store, schedule)
res_huey_nones = Huey(res_queue, res_store, store_none=True)

# store some global state
state = {}

# create a decorated queue command
@huey.task()
def add(key, value):
    state[key] = value

# create a periodic queue command
@huey.periodic_task(crontab(minute='0'))
def add_on_the_hour():
    state['periodic'] = 'x'

# define a command using the class
class AddTask(QueueTask):
    def execute(self):
        k, v = self.data
        state[k] = v

# create a command that raises an exception
class BampfException(Exception):
    pass

@huey.task()
def throw_error():
    raise BampfException('bampf')

@res_huey.task()
def add2(a, b):
    return a + b

@res_huey.periodic_task(crontab(minute='0'))
def add_on_the_hour2():
    state['periodic'] = 'x'

@res_huey.task()
def returns_none():
    return None

@res_huey_nones.task()
def returns_none2():
    return None


class HueyTestCase(unittest.TestCase):
    def setUp(self):
        global state
        queue.flush()
        res_queue.flush()
        schedule.flush()
        state = {}

    def test_registration(self):
        self.assertTrue('queuecmd_add' in registry)
        self.assertTrue('queuecmd_add_on_the_hour' in registry)
        self.assertTrue('AddTask' in registry)

    def test_enqueue(self):
        # sanity check
        self.assertEqual(len(queue), 0)

        # initializing the command does not enqueue it
        ac = AddTask(('k', 'v'))
        self.assertEqual(len(queue), 0)

        # ok, enqueue it, then check that it was enqueued
        huey.enqueue(ac)
        self.assertEqual(len(queue), 1)

        # it can be enqueued multiple times
        huey.enqueue(ac)
        self.assertEqual(len(queue), 2)

        # no changes to state
        self.assertFalse('k' in state)

    def test_enqueue_decorator(self):
        # sanity check
        self.assertEqual(len(queue), 0)

        add('k', 'v')
        self.assertEqual(len(queue), 1)

        add('k', 'v')
        self.assertEqual(len(queue), 2)

        # no changes to state
        self.assertFalse('k' in state)

    def test_schedule(self):
        dt = datetime.datetime(2011, 1, 1, 0, 1)
        add('k', 'v')
        self.assertEqual(len(queue), 1)

        task = huey.dequeue()
        self.assertEqual(task.execute_time, None)

        add.schedule(args=('k2', 'v2'), eta=dt)
        self.assertEqual(len(queue), 1)
        task = huey.dequeue()
        self.assertEqual(task.execute_time, local_to_utc(dt))

        add.schedule(args=('k3', 'v3'), eta=dt, convert_utc=False)
        self.assertEqual(len(queue), 1)
        task = huey.dequeue()
        self.assertEqual(task.execute_time, dt)

    def test_error_raised(self):
        throw_error()

        # no error
        task = huey.dequeue()

        # error
        self.assertRaises(BampfException, huey.execute, task)

    def test_dequeueing(self):
        res = huey.dequeue() # no error raised if queue is empty
        self.assertEqual(res, None)

        add('k', 'v')
        task = huey.dequeue()

        self.assertTrue(isinstance(task, QueueTask))
        self.assertEqual(task.get_data(), (('k', 'v'), {}))

    def test_execution(self):
        self.assertFalse('k' in state)
        add('k', 'v')

        task = huey.dequeue()
        self.assertFalse('k' in state)

        huey.execute(task)
        self.assertEqual(state['k'], 'v')

        add('k', 'X')
        self.assertEqual(state['k'], 'v')

        huey.execute(huey.dequeue())
        self.assertEqual(state['k'], 'X')

        self.assertRaises(TypeError, huey.execute, huey.dequeue())

    def test_revoke(self):
        ac = AddTask(('k', 'v'))
        ac2 = AddTask(('k2', 'v2'))
        ac3 = AddTask(('k3', 'v3'))

        res_huey.enqueue(ac)
        res_huey.enqueue(ac2)
        res_huey.enqueue(ac3)
        res_huey.enqueue(ac2)
        res_huey.enqueue(ac)

        self.assertEqual(len(res_queue), 5)
        res_huey.revoke(ac2)

        while res_queue:
            task = res_huey.dequeue()
            if not res_huey.is_revoked(task):
                res_huey.execute(task)

        self.assertEqual(state, {'k': 'v', 'k3': 'v3'})

    def test_revoke_periodic(self):
        add_on_the_hour2.revoke()
        self.assertTrue(add_on_the_hour2.is_revoked())

        # it is still revoked
        self.assertTrue(add_on_the_hour2.is_revoked())

        add_on_the_hour2.restore()
        self.assertFalse(add_on_the_hour2.is_revoked())

        add_on_the_hour2.revoke(revoke_once=True)
        self.assertTrue(add_on_the_hour2.is_revoked()) # it is revoked once, but we are preserving that state
        self.assertTrue(add_on_the_hour2.is_revoked(peek=False)) # is revoked once, but clear state
        self.assertFalse(add_on_the_hour2.is_revoked()) # no longer revoked

        d = datetime.datetime
        add_on_the_hour2.revoke(revoke_until=d(2011, 1, 1, 11, 0))
        self.assertTrue(add_on_the_hour2.is_revoked(dt=d(2011, 1, 1, 10, 0)))
        self.assertTrue(add_on_the_hour2.is_revoked(dt=d(2011, 1, 1, 10, 59)))
        self.assertFalse(add_on_the_hour2.is_revoked(dt=d(2011, 1, 1, 11, 0)))

        add_on_the_hour2.restore()
        self.assertFalse(add_on_the_hour2.is_revoked())

    def test_result_store(self):
        res = add2(1, 2)
        res2 = add2(4, 5)
        res3 = add2(0, 0)

        # none have been executed as yet
        self.assertEqual(res.get(), None)
        self.assertEqual(res2.get(), None)
        self.assertEqual(res3.get(), None)

        # execute the first task
        res_huey.execute(res_huey.dequeue())
        self.assertEqual(res.get(), 3)
        self.assertEqual(res2.get(), None)
        self.assertEqual(res3.get(), None)

        # execute the second task
        res_huey.execute(res_huey.dequeue())
        self.assertEqual(res.get(), 3)
        self.assertEqual(res2.get(), 9)
        self.assertEqual(res3.get(), None)

        # execute the 3rd, which returns a zero value
        res_huey.execute(res_huey.dequeue())
        self.assertEqual(res.get(), 3)
        self.assertEqual(res2.get(), 9)
        self.assertEqual(res3.get(), 0)

        # check that it returns None when nothing is present
        res = returns_none()
        self.assertEqual(res.get(), None)

        # execute, it will still return None, but underneath it is an EmptyResult
        # indicating its actual result was not persisted
        res_huey.execute(res_huey.dequeue())
        self.assertEqual(res.get(), None)
        self.assertEqual(res._result, EmptyData)

        # execute again, this time note that we're pointing at the invoker
        # that *does* accept None as a store-able result
        res = returns_none2()
        self.assertEqual(res.get(), None)

        # it stores None
        res_huey_nones.execute(res_huey_nones.dequeue())
        self.assertEqual(res.get(), None)
        self.assertEqual(res._result, None)

    def test_task_store(self):
        dt1 = datetime.datetime(2011, 1, 1, 0, 0)
        dt2 = datetime.datetime(2035, 1, 1, 0, 0)

        add2.schedule(args=('k', 'v'), eta=dt1, convert_utc=False)
        task1 = res_huey.dequeue()

        add2.schedule(args=('k2', 'v2'), eta=dt2, convert_utc=False)
        task2 = res_huey.dequeue()

        add2('k3', 'v3')
        task3 = res_huey.dequeue()

        # add the command to the schedule
        res_huey.add_schedule(task1)
        self.assertEqual(len(res_huey.schedule._schedule), 1)

        # add a future-dated command
        res_huey.add_schedule(task2)
        self.assertEqual(len(res_huey.schedule._schedule), 2)

        res_huey.add_schedule(task3)

        tasks = res_huey.read_schedule(dt1)
        self.assertEqual(tasks, [task3, task1])

        tasks = res_huey.read_schedule(dt1)
        self.assertEqual(tasks, [])

        tasks = res_huey.read_schedule(dt2)
        self.assertEqual(tasks, [task2])

    def test_ready_to_run_method(self):
        dt1 = datetime.datetime(2011, 1, 1, 0, 0)
        dt2 = datetime.datetime(2035, 1, 1, 0, 0)

        add2.schedule(args=('k', 'v'), eta=dt1)
        task1 = res_huey.dequeue()

        add2.schedule(args=('k2', 'v2'), eta=dt2)
        task2 = res_huey.dequeue()

        add2('k3', 'v3')
        task3 = res_huey.dequeue()

        # sanity check what should be run
        self.assertTrue(res_huey.ready_to_run(task1))
        self.assertFalse(res_huey.ready_to_run(task2))
        self.assertTrue(res_huey.ready_to_run(task3))

    def test_task_delay(self):
        curr = datetime.datetime.utcnow()
        curr50 = curr + datetime.timedelta(seconds=50)
        curr70 = curr + datetime.timedelta(seconds=70)

        add2.schedule(args=('k', 'v'), delay=60)
        task1 = res_huey.dequeue()

        add2.schedule(args=('k2', 'v2'), delay=600)
        task2 = res_huey.dequeue()

        add2('k3', 'v3')
        task3 = res_huey.dequeue()

        # add the command to the schedule
        res_huey.add_schedule(task1)
        res_huey.add_schedule(task2)
        res_huey.add_schedule(task3)

        # sanity check what should be run
        self.assertFalse(res_huey.ready_to_run(task1))
        self.assertFalse(res_huey.ready_to_run(task2))
        self.assertTrue(res_huey.ready_to_run(task3))

        self.assertFalse(res_huey.ready_to_run(task1, curr50))
        self.assertFalse(res_huey.ready_to_run(task2, curr50))
        self.assertTrue(res_huey.ready_to_run(task3, curr50))

        self.assertTrue(res_huey.ready_to_run(task1, curr70))
        self.assertFalse(res_huey.ready_to_run(task2, curr70))
        self.assertTrue(res_huey.ready_to_run(task3, curr70))

########NEW FILE########
__FILENAME__ = utils
import datetime
import sys
import time


class EmptyData(object):
    pass


def load_class(s):
    path, klass = s.rsplit('.', 1)
    __import__(path)
    mod = sys.modules[path]
    return getattr(mod, klass)

def wrap_exception(exc_class):
    exc_class, exc, tb = sys.exc_info()
    raise exc_class(exc.message)

def local_to_utc(dt):
    return datetime.datetime(*time.gmtime(time.mktime(dt.timetuple()))[:6])

########NEW FILE########
__FILENAME__ = runtests
#!/usr/bin/env python
import sys
import unittest

from huey import tests

def runtests(*test_args):
    suite = unittest.TestLoader().loadTestsFromModule(tests)
    result = unittest.TextTestRunner(verbosity=2).run(suite)
    if result.failures:
        sys.exit(1)
    elif result.errors:
        sys.exit(2)
    sys.exit(0)

if __name__ == '__main__':
    runtests(*sys.argv[1:])

########NEW FILE########
