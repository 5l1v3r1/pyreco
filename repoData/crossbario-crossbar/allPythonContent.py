__FILENAME__ = checkconfig
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['check_config',
           'check_config_file',
           'check_guest']

import os
import json
import re
import six

from pprint import pformat

from autobahn.websocket.protocol import parseWsUrl

from autobahn.wamp.message import _URI_PAT_STRICT_NON_EMPTY, \
                                  _URI_PAT_LOOSE_NON_EMPTY



def check_dict_args(spec, config, msg):
   for k in config:
      if not k in spec:
         raise Exception("{} - encountered unknown attribute '{}'".format(msg, k))
      if spec[k][1] and type(config[k]) not in spec[k][1]:
         raise Exception("{} - invalid {} encountered for attribute '{}'".format(msg, type(config[k]), k))
   mandatory_keys = [k for k in spec if spec[k][0]]
   for k in mandatory_keys:
      if not k in config:
         raise Exception("{} - missing mandatory attribute '{}'".format(msg, k))



def check_or_raise_uri(value, message):
   if type(value) != six.text_type:
      raise Exception("{}: invalid type {} for URI".format(message, type(value)))
   #if not _URI_PAT_LOOSE_NON_EMPTY.match(value):
   if not _URI_PAT_STRICT_NON_EMPTY.match(value):
      raise Exception("{}: invalid value '{}' for URI".format(message, value))
   return value



def check_endpoint_backlog(backlog):
   if type(backlog) not in six.integer_types:
      raise Exception("'backlog' attribute in endpoint must be int ({} encountered)".format(type(backlog)))
   if backlog < 1 or backlog > 65535:
      raise Exception("invalid value {} for 'backlog' attribute in endpoint (must be from [1, 65535])".format(backlog))



def check_endpoint_port(port):
   if type(port) not in six.integer_types:
      raise Exception("'port' attribute in endpoint must be integer ({} encountered)".format(type(port)))
   if port < 1 or port > 65535:
      raise Exception("invalid value {} for 'port' attribute in endpoint".format(port))



def check_endpoint_timeout(timeout):
   if type(timeout) not in six.integer_types:
      raise Exception("'timeout' attribute in endpoint must be integer ({} encountered)".format(type(timeout)))
   if port < 0 or port > 600:
      raise Exception("invalid value {} for 'timeout' attribute in endpoint".format(timeout))



def check_endpoint_listen_tls(tls):
   if type(tls) != dict:
      raise Exception("'tls' in endpoint must be dictionary ({} encountered)".format(type(tls)))

   for k in tls:
      if k not in ['key', 'certificate', 'dhparam', 'ciphers']:
         raise Exception("encountered unknown attribute '{}' in listening endpoint TLS configuration".format(k))

   for k in [('key', True), ('certificate', True), ('dhparam', False), ('ciphers', False)]:

      if k[1] and not k[0] in tls:
         raise Exception("missing mandatory attribute '{}' in listening endpoint TLS configuration".format(k[0]))

      if k[0] in tls:
         if type(k[0]) != six.text_type:
            raise Exception("'{}' in listening endpoint TLS configuration must be string ({} encountered)".format(k[0], type(k[0])))



def check_endpoint_connect_tls(tls):
   if type(tls) != dict:
      raise Exception("'tls' in endpoint must be dictionary ({} encountered)".format(type(tls)))

   for k in tls:
      if k not in []:
         raise Exception("encountered unknown attribute '{}' in listening endpoint TLS configuration".format(k))



def check_endpoint_listen_tcp(endpoint):
   for k in endpoint:
      if k not in ['type', 'port', 'shared', 'interface', 'backlog', 'tls']:
         raise Exception("encountered unknown attribute '{}' in listening endpoint".format(k))

   if not 'port' in endpoint:
      raise Exception("missing mandatory attribute 'port' in listening endpoint item\n\n{}".format(pformat(endpoint)))

   check_endpoint_port(endpoint['port'])

   if 'shared' in endpoint:
      shared = endpoint['shared']
      if type(shared) != bool:
         raise Exception("'shared' attribute in endpoint must be bool ({} encountered)".format(type(shared)))

   if 'tls' in endpoint:
      check_endpoint_listen_tls(endpoint['tls'])

   if 'interface' in endpoint:
      interface = endpoint['interface']
      if type(interface) != six.text_type:
         raise Exception("'interface' attribute in endpoint must be string ({} encountered)".format(type(interface)))

   if 'backlog' in endpoint:
      check_endpoint_backlog(endpoint['backlog'])



def check_endpoint_listen_unix(endpoint):
   for k in endpoint:
      if k not in ['type', 'path', 'backlog']:
         raise Exception("encountered unknown attribute '{}' in listening endpoint".format(k))

   if not 'path' in endpoint:
      raise Exception("missing mandatory attribute 'path' in Unix domain socket endpoint item\n\n{}".format(pformat(endpoint)))

   path = endpoint['path']
   if type(path) != six.text_type:
      raise Exception("'path' attribute in Unix domain socket endpoint must be str ({} encountered)".format(type(path)))

   if 'backlog' in endpoint:
      check_endpoint_backlog(endpoint['backlog'])



def check_endpoint_connect_tcp(endpoint):
   for k in endpoint:
      if k not in ['type', 'host', 'port', 'timeout', 'tls']:
         raise Exception("encountered unknown attribute '{}' in connecting endpoint".format(k))

   if not 'host' in endpoint:
      raise Exception("missing mandatory attribute 'host' in connecting endpoint item\n\n{}".format(pformat(endpoint)))

   if not 'port' in endpoint:
      raise Exception("missing mandatory attribute 'port' in connecting endpoint item\n\n{}".format(pformat(endpoint)))

   check_endpoint_port(endpoint['port'])

   if 'tls' in endpoint:
      check_endpoint_connect_tls(endpoint['tls'])

   if 'timeout' in endpoint:
      check_endpoint_timeout(endpoint['timeout'])



def check_endpoint_connect_unix(endpoint):
   for k in endpoint:
      if k not in ['type', 'path', 'timeout']:
         raise Exception("encountered unknown attribute '{}' in connecting endpoint".format(k))

   if not 'path' in endpoint:
      raise Exception("missing mandatory attribute 'path' in Unix domain socket endpoint item\n\n{}".format(pformat(endpoint)))

   path = endpoint['path']
   if type(path) != six.text_type:
      raise Exception("'path' attribute in Unix domain socket endpoint must be str ({} encountered)".format(type(path)))

   if 'timeout' in endpoint:
      check_endpoint_timeout(endpoint['timeout'])



def check_endpoint_listen(endpoint):
   if type(endpoint) != dict:
      raise Exception("'endpoint' items must be dictionaries ({} encountered)\n\n{}".format(type(endpoint)))

   if not 'type' in endpoint:
      raise Exception("missing mandatory attribute 'type' in endpoint item\n\n{}".format(pformat(endpoint)))

   etype = endpoint['type']
   if etype not in ['tcp', 'unix']:
      raise Exception("invalid attribute value '{}' for attribute 'type' in endpoint item\n\n{}".format(etype, pformat(endpoint)))

   if etype == 'tcp':
      check_endpoint_listen_tcp(endpoint)
   elif etype == 'unix':
      check_endpoint_listen_unix(endpoint)
   else:
      raise Exception("logic error")



def check_endpoint_connect(endpoint):
   if type(endpoint) != dict:
      raise Exception("'endpoint' items must be dictionaries ({} encountered)\n\n{}".format(type(endpoint)))

   if not 'type' in endpoint:
      raise Exception("missing mandatory attribute 'type' in endpoint item\n\n{}".format(pformat(endpoint)))

   etype = endpoint['type']
   if etype not in ['tcp', 'unix']:
      raise Exception("invalid attribute value '{}' for attribute 'type' in endpoint item\n\n{}".format(etype, pformat(endpoint)))

   if etype == 'tcp':
      check_endpoint_connect_tcp(endpoint)
   elif etype == 'unix':
      check_endpoint_connect_unix(endpoint)
   else:
      raise Exception("logic error")



def check_websocket_options(options):
   if type(options) != dict:
      raise Exception("WebSocket options must be a dictionary ({} encountered)".format(type(options)))

   for k in options:
      if k not in [
                   ## WebSocket options
                   'external_port',
                   'enable_hixie76',
                   'enable_hybi10',
                   'enable_rfc6455',
                   'open_handshake_timeout',
                   'close_handshake_timeout',
                   'enable_webstatus',
                   'validate_utf8',
                   'mask_server_frames',
                   'require_masked_client_frames',
                   'apply_mask',
                   'max_frame_size',
                   'max_message_size',
                   'auto_fragment_size',
                   'fail_by_drop',
                   'echo_close_codereason',
                   'tcp_nodelay',
                   'compression',

                   ## WAMP-WebSocket options
                   'serializers'
                   ]:
         raise Exception("encountered unknown attribute '{}' in WebSocket options".format(k))

   ## FIXME: more complete checking ..



def check_transport_web_path_service_websocket(config):
   if 'options' in config:
      check_websocket_options(config['options'])

   if 'debug' in config:
      debug = config['debug']
      if type(debug) != bool:
         raise Exception("'debug' in WebSocket configuration must be boolean ({} encountered)".format(type(debug)))

   if 'url' in config:
      url = config['url']
      if type(url) != six.text_type:
         raise Exception("'url' in WebSocket configuration must be str ({} encountered)".format(type(url)))
      try:
         u = parseWsUrl(url)
      except Exception as e:
         raise Exception("invalid 'url' in WebSocket configuration : {}".format(e))



def check_transport_web_path_service_static(config):
   check_dict_args({
      'type': (True, [six.text_type]),
      'directory': (False, [six.text_type]),
      'module': (False, [six.text_type]),
      'resource': (False, [six.text_type]),
      'enable_directory_listing': (False, [bool])
      }, config, "Web transport 'static' path service")

   if 'directory' in config:
      if 'module' in config or 'resource' in config:
         raise Exception("Web transport 'static' path service: either 'directory' OR 'module' + 'resource' must be given, not both")
   else:
      if not 'module' in config or not 'resource' in config:
         raise Exception("Web transport 'static' path service: either 'directory' OR 'module' + 'resource' must be given, not both")



def check_transport_web_path_service_wsgi(config):
   check_dict_args({
      'type': (True, [six.text_type]),
      'module': (True, [six.text_type]),
      'object': (True, [six.text_type])
      }, config, "Web transport 'wsgi' path service")



def check_transport_web_path_service_redirect(config):
   check_dict_args({
      'type': (True, [six.text_type]),
      'url': (True, [six.text_type])
      }, config, "Web transport 'redirect' path service")



def check_transport_web_path_service_json(config):
   check_dict_args({
      'type': (True, [six.text_type]),
      'value': (True, None)
      }, config, "Web transport 'json' path service")



def check_transport_web_path_service_cgi(config):
   check_dict_args({
      'type': (True, [six.text_type]),
      'directory': (True, [six.text_type]),
      'processor': (True, [six.text_type]),
      }, config, "Web transport 'cgi' path service")



def check_transport_web_path_service_longpoll(config):
   raise Exception("Web transport 'longpoll' path service : not yet implemented")



def check_transport_web_path_service(path, config):
   if not 'type' in config:
      raise Exception("missing mandatory attribute 'type' in Web transport path '{}' configuration\n\n{}".format(path, config))

   ptype = config['type']
   if path == '/':
      if ptype not in ['static', 'wsgi', 'redirect']:
         raise Exception("invalid type '{}' for root-path service in Web transport path '{}' configuration\n\n{}".format(ptype, path, config))
   else:
      if ptype not in ['websocket', 'static', 'wsgi', 'redirect', 'json', 'cgi', 'longpoll']:
         raise Exception("invalid type '{}' for sub-path service in Web transport path '{}' configuration\n\n{}".format(ptype, path, config))

   checkers = {
      'websocket': check_transport_web_path_service_websocket,
      'static': check_transport_web_path_service_static,
      'wsgi': check_transport_web_path_service_wsgi,
      'redirect': check_transport_web_path_service_redirect,
      'json': check_transport_web_path_service_json,
      'cgi': check_transport_web_path_service_cgi,
      'longpoll': check_transport_web_path_service_longpoll
   }

   checkers[ptype](config)



def check_transport_web(transport):
   for k in transport:
      if k not in ['type', 'endpoint', 'paths', 'options']:
         raise Exception("encountered unknown attribute '{}' in Web transport configuration".format(k))

   if not 'endpoint' in transport:
      raise Exception("missing mandatory attribute 'endpoint' in Web transport item\n\n{}".format(pformat(transport)))

   check_endpoint_listen(transport['endpoint'])

   if not 'paths' in transport:
      raise Exception("missing mandatory attribute 'paths' in Web transport item\n\n{}".format(pformat(transport)))

   paths = transport['paths']
   if type(paths) != dict:
      raise Exception("'paths' attribute in Web transport configuration must be dictionary ({} encountered)".format(type(paths)))

   if not '/' in paths:
      raise Exception("missing mandatory path '/' in 'paths' in Web transport configuration")

   pat = re.compile("^([a-z0-9A-Z]+|/)$")

   for p in paths:
      if type(p) != six.text_type:
         raise Exception("keys in 'paths' in Web transport configuration must be strings ({} encountered)".format(type(p)))

      if not pat.match(p):
         raise Exception("invalid value '{}' for path in Web transport configuration".format(p))

      check_transport_web_path_service(p, paths[p])

   if 'options' in transport:
      options = transport['options']
      if type(options) != dict:
         raise Exception("'options' in Web transport must be dictionary ({} encountered)".format(type(options)))

      if 'access_log' in options:
         access_log = options['access_log']
         if type(access_log) != bool:
            raise Exception("'access_log' attribute in 'options' in Web transport must be bool ({} encountered)".format(type(access_log)))

      if 'hsts' in options:
         hsts = options['hsts']
         if type(hsts) != bool:
            raise Exception("'hsts' attribute in 'options' in Web transport must be bool ({} encountered)".format(type(hsts)))

      if 'hsts_max_age' in options:
         hsts_max_age = options['hsts_max_age']
         if type(hsts_max_age) not in six.integer_types:
            raise Exception("'hsts_max_age' attribute in 'options' in Web transport must be integer ({} encountered)".format(type(hsts_max_age)))
         if hsts_max_age < 0:
            raise Exception("'hsts_max_age' attribute in 'options' in Web transport must be non-negative ({} encountered)".format(hsts_max_age))



def check_transport_websocket(transport):
   for k in transport:
      if k not in ['type', 'endpoint', 'url', 'debug', 'debug_traffic', 'options']:
#      if k not in ['type', 'endpoint', 'url', 'debug', 'options']:
         raise Exception("encountered unknown attribute '{}' in WebSocket transport configuration".format(k))

   if not 'endpoint' in transport:
      raise Exception("missing mandatory attribute 'endpoint' in WebSocket transport item\n\n{}".format(pformat(transport)))

   check_endpoint_listen(transport['endpoint'])

   if 'options' in transport:
      check_websocket_options(transport[options])

   if 'debug' in transport:
      debug = transport['debug']
      if type(debug) != bool:
         raise Exception("'debug' in WebSocket transport configuration must be boolean ({} encountered)".format(type(debug)))

   if 'url' in transport:
      url = transport['url']
      if type(url) != six.text_type:
         raise Exception("'url' in WebSocket transport configuration must be str ({} encountered)".format(type(url)))
      try:
         u = parseWsUrl(url)
      except Exception as e:
         raise Exception("invalid 'url' in WebSocket transport configuration : {}".format(e))



def check_transport_rawsocket(transport):
   for k in transport:
      if k not in ['type', 'endpoint', 'serializer', 'debug']:
         raise Exception("encountered unknown attribute '{}' in RawSocket transport configuration".format(k))

   if not 'endpoint' in transport:
      raise Exception("missing mandatory attribute 'endpoint' in RawSocket transport item\n\n{}".format(pformat(transport)))

   check_endpoint_listen(transport['endpoint'])

   if not 'serializer' in transport:
      raise Exception("missing mandatory attribute 'serializer' in RawSocket transport item\n\n{}".format(pformat(transport)))

   serializer = transport['serializer']
   if type(serializer) != six.text_type:
      raise Exception("'serializer' in RawSocket transport configuration must be a string ({} encountered)".format(type(serializer)))

   if serializer not in ['json', 'msgpack']:
      raise Exception("invalid value {} for 'serializer' in RawSocket transport configuration - must be one of ['json', 'msgpack']".format(serializer))

   if 'debug' in transport:
      debug = transport['debug']
      if type(debug) != bool:
         raise Exception("'debug' in RawSocket transport configuration must be boolean ({} encountered)".format(type(debug)))



def check_transport(transport):
   if type(transport) != dict:
      raise Exception("'transport' items must be dictionaries ({} encountered)\n\n{}".format(type(transport), pformat(transport)))

   if not 'type' in transport:
      raise Exception("missing mandatory attribute 'type' in component")

   ttype = transport['type']
   if ttype not in ['web', 'websocket', 'websocket.testee', 'rawsocket']:
      raise Exception("invalid attribute value '{}' for attribute 'type' in transport item\n\n{}".format(ttype, pformat(transport)))

   if ttype in ['websocket', 'websocket.testee']:
      check_transport_websocket(transport)
   elif ttype == 'rawsocket':
      check_transport_rawsocket(transport)
   elif ttype == 'web':
      check_transport_web(transport)
   else:
      raise Exception("logic error")



def check_component(component):
   if type(component) != dict:
      raise Exception("components must be dictionaries ({} encountered)".format(type(component)))

   if not 'type' in component:
      raise Exception("missing mandatory attribute 'type' in component")

   ctype = component['type']
   if ctype not in ['wamplet', 'class']:
      raise Exception("invalid value '{}' for component type".format(ctype))

   if ctype == 'wamplet':
      check_dict_args({
         'type': (True, [six.text_type]),
         'dist': (True, [six.text_type]),
         'entry': (True, [six.text_type]),
         'extra': (False, None),
         }, component, "invalid component configuration")

   elif ctype == 'class':
      check_dict_args({
         'type': (True, [six.text_type]),
         'name': (True, [six.text_type]),
         'extra': (False, None),
         }, component, "invalid component configuration")

   else:
      raise Exception("logic error")



def check_container_component(component):
   print("FIXME: check_container_component")



def check_realm(realm, silence = False):
   ## permissions
   ##
   if 'permissions' in realm:
      permissions = realm['permissions']
      if type(permissions) != dict:
         raise Exception("'permissions' in 'realm' must be a dictionary ({} encountered)\n\n{}".format(type(components), realm))

      for role in sorted(permissions):
         check_or_raise_uri(role, "invalid role URI '{}' in realm permissions".format(role))
         check_dict_args({
            'create': (False, [bool]),
            'join': (False, [bool]),
            'access': (False, [dict]),
            }, permissions[role], "invalid grant in realm permissions")

         if 'access' in permissions[role]:
            access = permissions[role]['access']
            if type(access) != dict:
               raise Exception("'access' attribute in realm-role permissions must be a dictionary ({} encountered)".format(type(access)))

            for uri in sorted(access.keys()):
               if len(uri) > 0 and uri[-1] == '*':
                  check_uri = uri[:-1]
               else:
                  check_uri = uri
               check_or_raise_uri(check_uri, "invalid role URI '{}' in realm-role access grants".format(uri))

               grants = access[uri]

               check_dict_args({
                  'publish': (False, [bool]),
                  'subscribe': (False, [bool]),
                  'call': (False, [bool]),
                  'register': (False, [bool]),
                  }, grants, "invalid grant in realm permissions")

   ## components
   ##
   if 'components' in realm:
      components = realm['components']
      if type(components) != list:
         raise Exception("'components' in 'realm' must be a list ({} encountered)\n\n{}".format(type(components), realm))

      i = 1
      for component in components:
         if not silence:
            print("Checking component item {} ..".format(i))
            check_component(component)
            i += 1



def check_router(router, silence = False):
   for k in router:
      if k not in ['type', 'realms', 'transports']:
         raise Exception("encountered unknown attribute '{}' in router configuration".format(k))

   ## realms
   ##
   if not 'realms' in router:
      raise Exception("missing mandatory attribute 'realms' in router item\n\n{}".format(pformat(router)))

   realms = router['realms']

   if type(realms) != dict:
      raise Exception("'realms' items must be dictionaries ({} encountered)\n\n{}".format(type(realms), pformat(router)))

   i = 1
   for r in sorted(realms.keys()):
      if not silence:
         print("Checking realm item {} ('{}') ..".format(i, r))
      check_or_raise_uri(r, "realm keys must be valid WAMP URIs")
      check_realm(realms[r], silence)
      i += 1

   ## transports
   ##
   if not 'transports' in router:
      raise Exception("missing mandatory attribute 'transports' in router item\n\n{}".format(pformat(router)))

   transports = router['transports']

   if type(transports) != list:
      raise Exception("'transports' items must be lists ({} encountered)\n\n{}".format(type(transports), pformat(router)))

   i = 1
   for transport in transports:
      if not silence:
         print("Checking transport item {} ..".format(i))
      check_transport(transport)
      i += 1



def check_container(container, silence = False):
   print("FIXME: check_container")



def check_router_options(router_options):
   print("FIXME: implement check_router_options")



def check_container_options(container_options):
   print("FIXME: implement check_container_options")



def check_module(module, silence = False):
   if type(module) != dict:
      raise Exception("'module' items must be dictionaries ({} encountered)\n\n{}".format(type(module), pformat(module)))

   if not 'type' in module:
      raise Exception("missing mandatory attribute 'type' in module item\n\n{}".format(pformat(module)))

   mtype = module['type']
   if mtype not in ['router', 'container']:
      raise Exception("invalid attribute value '{}' for attribute 'type' in module item\n\n{}".format(mtype, pformat(module)))

   if mtype == 'router':
      check_router(module, silence)
   elif mtype == 'container':
      check_container(module, silence)
   else:
      raise Exception("logic error")



def check_manhole(manhole, silence = False):
   if type(manhole) != dict:
      raise Exception("'manhole' items must be dictionaries ({} encountered)\n\n{}".format(type(manhole), pformat(manhole)))

   for k in manhole:
      if k not in ['endpoint', 'users']:
         raise Exception("encountered unknown attribute '{}' in Manhole configuration".format(k))

   if not 'endpoint' in manhole:
      raise Exception("missing mandatory attribute 'endpoint' in Manhole item\n\n{}".format(pformat(manhole)))

   check_endpoint_listen(manhole['endpoint'])

   if not 'users' in manhole:
      raise Exception("missing mandatory attribute 'users' in Manhole item\n\n{}".format(pformat(manhole)))

   users = manhole['users']
   if type(users) != list:
      raise Exception("'manhole.users' items must be lists ({} encountered)\n\n{}".format(type(users), pformat(users)))

   for user in users:
      if type(user) != dict:
         raise Exception("'manhole.users.user' items must be dictionaries ({} encountered)\n\n{}".format(type(user), pformat(user)))

      for k in user:
         if k not in ['user', 'password']:
            raise Exception("encountered unknown attribute '{}' in manhole.users.user".format(k))

      if not 'user' in user:
         raise Exception("missing mandatory attribute 'user' in Manhole user item\n\n{}".format(pformat(user)))

      if not 'password' in user:
         raise Exception("missing mandatory attribute 'password' in Manhole user item\n\n{}".format(pformat(user)))



def check_process_env(env, silence = False):
   if type(env) != dict:
      raise Exception("'env' in 'options' in worker/guest configuration must be dict ({} encountered)".format(type(env)))

   for k in env:
      if k not in ['inherit', 'vars']:
         raise Exception("encountered unknown attribute '{}' in 'options.env' in worker/guest configuration".format(k))

   if 'inherit' in env:
      inherit = env['inherit']
      if type(inherit) == bool:
         pass
      elif type(inherit) == list:
         for v in inherit:
            if type(v) != six.text_type:
               raise Exception("invalid type for inherited env var name in 'inherit' in 'options.env' in worker/guest configuration - must be a string ({} encountered)".format(type(v)))
      else:
         raise Exception("'inherit' in 'options.env' in worker/guest configuration must be bool or list ({} encountered)".format(type(inherit)))

   if 'vars' in env:
      envvars = env['vars']
      if type(envvars) != dict:
         raise Exception("'options.env.vars' in worker/guest configuration must be dict ({} encountered)".format(type(envvars)))

      for k, v in envvars.items():
         if type(k) != six.text_type:
            raise Exception("invalid type for environment variable key '{}' in 'options.env.vars' - must be a string ({} encountered)".format(k, type(k)))
         if type(v) != six.text_type:
            raise Exception("invalid type for environment variable value '{}' in 'options.env.vars' - must be a string ({} encountered)".format(v, type(v)))



def check_worker(worker, silence = False):
   for k in worker:
      if k not in ['type', 'options', 'modules', 'manhole']:
         raise Exception("encountered unknown attribute '{}' in worker configuration".format(k))


   if 'manhole' in worker:
      check_manhole(worker['manhole'])


   if 'options' in worker:
      options = worker['options']
      if type(options) != dict:
         raise Exception("options must be dictionaries ({} encountered)\n\n{}".format(type(options), pformat(worker)))

      for k in options:
         if k not in ['pythonpath', 'cpu_affinity', 'env', 'title']:
            raise Exception("encountered unknown attribute '{}' in 'options' in worker configuration".format(k))

      if 'title' in options:
         title = options['title']
         if type(title) != six.text_type:
            raise Exception("'title' in 'options' in worker configuration must be a string ({} encountered)".format(type(title)))

      if 'pythonpath' in options:
         pythonpath = options['pythonpath']
         if type(pythonpath) != list:
            raise Exception("'pythonpath' in 'options' in worker configuration must be lists ({} encountered)".format(type(pythonpath)))
         for p in pythonpath:
            if type(p) != six.text_type:
               raise Exception("paths in 'pythonpath' in 'options' in worker configuration must be strings ({} encountered)".format(type(p)))

      if 'cpu_affinity' in options:
         cpu_affinity = options['cpu_affinity']
         if type(cpu_affinity) != list:
            raise Exception("'cpu_affinity' in 'options' in worker configuration must be lists ({} encountered)".format(type(cpu_affinity)))
         for a in cpu_affinity:
            if type(a) not in six.integer_types:
               raise Exception("CPU affinities in 'cpu_affinity' in 'options' in worker configuration must be integers ({} encountered)".format(type(a)))

      if 'env' in options:
         check_process_env(options['env'])

   if not 'modules' in worker:
      raise Exception("missing mandatory attribute 'modules' in worker item\n\n{}".format(pformat(worker)))

   modules = worker['modules']

   if type(modules) != list:
      raise Exception("'modules' attribute in worker item must be a list ({} encountered)\n\n{}".format(type(modules), pformat(worker)))

   i = 1
   for module in modules:
      if not silence:
         print("Checking module item {} ..".format(i))
      check_module(module, silence)
      i += 1



def check_guest(guest, silence = False):
   """
   Check a guest worker configuration.
   """
   for k in guest:
      if k not in ['type',
                   'executable',
                   'arguments',
                   'stdin',
                   'stdout',
                   'stderr',
                   'workdir',
                   'options']:
         raise Exception("encountered unknown attribute '{}' in guest worker configuration".format(k))

   check_dict_args({
      'type': (True, [six.text_type]),
      'executable': (True, [six.text_type]),
      'stdin': (False, [six.text_type, dict]),
      'stdout': (False, [six.text_type]),
      'stderr': (False, [six.text_type]),
      'arguments': (False, [list]),
      'workdir': (False, [six.text_type]),
      'options': (False, [dict])
      }, guest, "Guest process configuration")

   if guest['type'] != 'guest':
      raise Exception("invalid value '{}' for type in guest worker configuration".format(guest['type']))

   for s in ['stdout', 'stderr']:
      if s in guest:
         if guest[s] not in ['close', 'log', 'drop']:
            raise Exception("invalid value '{}' for '{}' in guest worker configuration".format(guest[s], s))

   if 'stdin' in guest:
      if type(guest['stdin']) == dict:
         check_dict_args({
            'type': (True, [six.text_type]),
            'value': (True, None),
            'close': (False, [bool]),
            }, guest['stdin'], "Guest process 'stdin' configuration")
      else:
         if guest['stdin'] not in ['close']:
            raise Exception("invalid value '{}' for 'stdin' in guest worker configuration".format(guest['stdin']))

   if 'arguments' in guest:
      for arg in guest['arguments']:
         if type(arg) != six.text_type:
            raise Exception("invalid type {} for argument in 'arguments' in guest worker configuration".format(type(arg)))

   if 'options' in guest:
      options = guest['options']
      if type(options) != dict:
         raise Exception("options must be dictionaries ({} encountered)\n\n{}".format(type(options), pformat(worker)))

      for k in options:
         if k not in ['env']:
            raise Exception("encountered unknown attribute '{}' in 'options' in guest worker configuration".format(k))

      if 'env' in options:
         check_process_env(options['env'])



def check_process(process, silence = False):
   if type(process) != dict:
      raise Exception("process items must be dictionaries ({} encountered)\n\n{}".format(type(process), pformat(process)))

   if not 'type' in process:
      raise Exception("missing mandatory attribute 'type' in process item\n\n{}".format(pformat(process)))

   ptype = process['type']

   if ptype not in ['worker', 'guest']:
      raise Exception("invalid attribute value '{}' for attribute 'type' in process item\n\n{}".format(ptype, pformat(process)))

   if ptype == 'worker':
      check_worker(process, silence)
   elif ptype == 'guest':
      check_guest(process, silence)
   else:
      raise Exception("logic error")



def check_config(config, silence = False):
   if type(config) != dict:
      raise Exception("top-level configuration item must be a dictionary ({} encountered)".format(type(config)))

   for k in config:
      if k not in ['processes']:
         raise Exception("encountered unknown attribute '{}' in top-level configuration".format(k))

   if not 'processes' in config:
      raise Exception("missing 'processes' attribute in top-level configuration item")

   processes = config['processes']

   if type(processes) != list:
      raise Exception("'processes' attribute in top-level configuration must be a list ({} encountered)".format(type(processes)))

   i = 1
   for process in processes:
      if not silence:
         print("Checking process item {} ..".format(i))
      check_process(process, silence)
      i += 1



def check_config_file(configfile, silence = False):
   configfile = os.path.abspath(configfile)

   with open(configfile, 'rb') as infile:
      try:
         config = json.load(infile)
      except ValueError as e:
         raise Exception("configuration file does not seem to be proper JSON ('{}'')".format(e))

   check_config(config, silence)

   return config

########NEW FILE########
__FILENAME__ = process
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['NativeProcessSession']


import gc

from datetime import datetime

from twisted.python import log
from twisted.internet import reactor
from twisted.internet.defer import Deferred, \
                                   DeferredList, \
                                   inlineCallbacks, \
                                   returnValue

from twisted.internet.task import LoopingCall


try:
   ## Manhole support needs a couple of packages optional for Crossbar.
   ## So we catch import errors and note those.
   ##
   import Crypto # twisted.conch.manhole_ssh will import even without, but we _need_ SSH
   import pyasn1
   from twisted.cred import checkers, portal
   from twisted.conch.manhole import ColoredManhole
   from twisted.conch.manhole_ssh import ConchFactory, \
                                         TerminalRealm, \
                                         TerminalSession
except ImportError as e:
   _HAS_MANHOLE = False
   _MANHOLE_MISSING_REASON = str(e)
else:
   _HAS_MANHOLE = True
   _MANHOLE_MISSING_REASON = None


from autobahn.util import utcnow, utcstr, rtime
from autobahn.twisted.wamp import ApplicationSession
from autobahn.wamp.exception import ApplicationError
from autobahn.wamp.types import PublishOptions, \
                                RegisterOptions

from crossbar.common.processinfo import _HAS_PSUTIL
if _HAS_PSUTIL:
   from crossbar.common.processinfo import ProcessInfo, SystemInfo

from crossbar.common import checkconfig
from crossbar.twisted.endpoint import create_listening_port_from_config




if _HAS_MANHOLE:
   class ManholeService:
      """
      Manhole service running inside a native processes (controller, router, container).

      This class is for _internal_ use within NativeProcessSession.
      """

      def __init__(self, config, who):
         """
         Ctor.

         :param config: The configuration the manhole service was started with.
         :type config: dict
         :param who: Who triggered creation of this service.
         :type who: str
         """
         self.config = config
         self.who = who
         self.status = 'starting'
         self.created = datetime.utcnow()
         self.started = None
         self.port = None


      def marshal(self):
         """
         Marshal object information for use with WAMP calls/events.

         :returns: dict -- The marshalled information.
         """
         now = datetime.utcnow()
         return {
            'created': utcstr(self.created),
            'status': self.status,
            'started': utcstr(self.started) if self.started else None,
            'uptime': (now - self.started).total_seconds() if self.started else None,
            'config': self.config
         }



class NativeProcessSession(ApplicationSession):
   """
   A native Crossbar.io process (currently: controller, router or container).
   """

   def onConnect(self, do_join = True):
      """
      """
      if not hasattr(self, 'debug'):
         self.debug = self.config.extra.debug

      if not hasattr(self, 'cbdir'):
         self.cbdir = self.config.extra.cbdir

      if not hasattr(self, '_uri_prefix'):
         self._uri_prefix = 'crossbar.node.{}'.format(self.config.extra.node)

      if self.debug:
         log.msg("Session connected to management router")

      self._started = datetime.utcnow()

      ## see: BaseSession
      self.include_traceback = False
      self.debug_app = True

      self._manhole_service = None

      if _HAS_PSUTIL:
         self._pinfo = ProcessInfo()
         self._pinfo_monitor = None
         self._pinfo_monitor_seq = 0
      else:
         self._pinfo = None
         self._pinfo_monitor = None
         self._pinfo_monitor_seq = None
         log.msg("Warning: process utilities not available")

      if do_join:
         self.join(self.config.realm)



   @inlineCallbacks
   def onJoin(self, details):
      """
      Called when process has joined the node's management realm.
      """
      procs = [
         'start_manhole',
         'stop_manhole',
         'get_manhole',
         'trigger_gc',
         'utcnow',
         'started',
         'uptime',
         'get_process_info',
         'get_process_stats',
         'set_process_stats_monitoring'
      ]

      dl = []
      for proc in procs:
         uri = '{}.{}'.format(self._uri_prefix, proc)
         if self.debug:
            log.msg("Registering procedure '{}'".format(uri))
         dl.append(self.register(getattr(self, proc), uri, options = RegisterOptions(details_arg = 'details', discloseCaller = True)))

      regs = yield DeferredList(dl)

      if self.debug:
         log.msg("{} registered {} procedures".format(self.__class__.__name__, len(regs)))



   def get_process_info(self, details = None):
      """
      Get process information (open files, sockets, ...).

      :returns: dict -- Dictionary with process information.
      """
      if self.debug:
         log.msg("{}.get_process_info".format(self.__class__.__name__))

      if self._pinfo:
         return self._pinfo.get_info()
      else:
         emsg = "ERROR: could not retrieve process statistics - required packages not installed"
         raise ApplicationError("crossbar.error.feature_unavailable", emsg)



   def get_process_stats(self, details = None):
      """
      Get process statistics (CPU, memory, I/O).

      :returns: dict -- Dictionary with process statistics.
      """
      if self.debug:
         log.msg("{}.get_process_stats".format(self.__class__.__name__))

      if self._pinfo:
         return self._pinfo.get_stats()
      else:
         emsg = "ERROR: could not retrieve process statistics - required packages not installed"
         raise ApplicationError("crossbar.error.feature_unavailable", emsg)



   def set_process_stats_monitoring(self, interval, details = None):
      """
      Enable/disable periodic publication of process statistics.

      :param interval: The monitoring interval in seconds. Set to 0 to disable monitoring.
      :type interval: float
      """
      if self.debug:
         log.msg("{}.set_process_stats_monitoring".format(self.__class__.__name__), interval)

      if self._pinfo:

         stats_monitor_set_topic = '{}.on_process_stats_monitoring_set'.format(self._uri_prefix)

         ## stop and remove any existing monitor
         if self._pinfo_monitor:
            self._pinfo_monitor.stop()
            self._pinfo_monitor = None

            self.publish(stats_monitor_set_topic, 0, options = PublishOptions(exclude = [details.caller]))

         ## possibly start a new monitor
         if interval > 0:
            stats_topic = '{}.on_process_stats'.format(self._uri_prefix)

            def publish_stats():
               stats = self._pinfo.get_stats()
               self._pinfo_monitor_seq += 1
               stats['seq'] = self._pinfo_monitor_seq
               self.publish(stats_topic, stats)

            self._pinfo_monitor = LoopingCall(publish_stats)
            self._pinfo_monitor.start(interval)

            self.publish(stats_monitor_set_topic, interval, options = PublishOptions(exclude = [details.caller]))
      else:
         emsg = "ERROR: cannot setup process statistics monitor - required packages not installed"
         raise ApplicationError("crossbar.error.feature_unavailable", emsg)



   def trigger_gc(self, details = None):
      """
      Triggers a garbage collection.

      :returns: float -- Time consumed for GC in ms.
      """
      if self.debug:
         log.msg("{}.trigger_gc".format(self.__class__.__name__))

      started = rtime()
      gc.collect()
      return 1000. * (rtime() - started)



   @inlineCallbacks
   def start_manhole(self, config, details = None):
      """
      Start a manhole (SSH) within this worker.

      :param config: Manhole configuration.
      :type config: obj
      """
      if self.debug:
         log.msg("{}.start_manhole".format(self.__class__.__name__), config)

      if not _HAS_MANHOLE:
         emsg = "ERROR: could not start manhole - required packages are missing ({})".format(_MANHOLE_MISSING_REASON)
         log.msg(emsg)
         raise ApplicationError("crossbar.error.feature_unavailable", emsg)

      if self._manhole_service:
         emsg = "ERROR: could not start manhole - already running (or starting)"
         log.msg(emsg)
         raise ApplicationError("crossbar.error.already_started", emsg)

      try:
         checkconfig.check_manhole(config)
      except Exception as e:
         emsg = "ERROR: could not start manhole - invalid configuration ({})".format(e)
         log.msg(emsg)
         raise ApplicationError('crossbar.error.invalid_configuration', emsg)

      ## setup user authentication
      ##
      checker = checkers.InMemoryUsernamePasswordDatabaseDontUse()
      for user in config['users']:
         checker.addUser(user['user'], user['password'])

      ## setup manhole namespace
      ##
      namespace = {'session': self}

      class PatchedTerminalSession(TerminalSession):
         ## get rid of
         ## exceptions.AttributeError: TerminalSession instance has no attribute 'windowChanged'
         def windowChanged(self, winSize):
            pass

      rlm = TerminalRealm()
      rlm.sessionFactory = PatchedTerminalSession # monkey patch
      rlm.chainedProtocolFactory.protocolFactory = lambda _: ColoredManhole(namespace)

      ptl = portal.Portal(rlm, [checker])

      factory = ConchFactory(ptl)
      factory.noisy = False

      self._manhole_service = ManholeService(config, details.authid)

      starting_topic = '{}.on_manhole_starting'.format(self._uri_prefix)
      starting_info = self._manhole_service.marshal()

      ## the caller gets a progressive result ..
      if details.progress:
         details.progress(starting_info)

      ## .. while all others get an event
      self.publish(starting_topic, starting_info, options = PublishOptions(exclude = [details.caller]))

      try:
         self._manhole_service.port = yield create_listening_port_from_config(config['endpoint'], factory, self.cbdir, reactor)
      except Exception as e:
         self._manhole_service = None
         emsg = "ERROR: manhole service endpoint cannot listen - {}".format(e)
         log.msg(emsg)
         raise ApplicationError("crossbar.error.cannot_listen", emsg)

      ## alright, manhole has started
      self._manhole_service.started = datetime.utcnow()
      self._manhole_service.status = 'started'

      started_topic = '{}.on_manhole_started'.format(self._uri_prefix)
      started_info = self._manhole_service.marshal()
      self.publish(started_topic, started_info, options = PublishOptions(exclude = [details.caller]))

      returnValue(started_info)



   @inlineCallbacks
   def stop_manhole(self, details = None):
      """
      Stop Manhole.
      """
      if self.debug:
         log.msg("{}.stop_manhole".format(self.__class__.__name__))

      if not _HAS_MANHOLE:
         emsg = "ERROR: could not start manhole - required packages are missing ({})".format(_MANHOLE_MISSING_REASON)
         log.msg(emsg)
         raise ApplicationError("crossbar.error.feature_unavailable", emsg)

      if not self._manhole_service or self._manhole_service.status != 'started':
         emsg = "ERROR: cannot stop manhole - not running (or already shutting down)"
         raise ApplicationError("crossbar.error.not_started", emsg)

      self._manhole_service.status = 'stopping'

      stopping_topic = '{}.on_manhole_stopping'.format(self._uri_prefix)
      stopping_info = None

      ## the caller gets a progressive result ..
      if details.progress:
         details.progress(stopping_info)

      ## .. while all others get an event
      self.publish(stopping_topic, stopping_info, options = PublishOptions(exclude = [details.caller]))

      try:
         yield self._manhole_service.port.stopListening()
      except Exception as e:
         raise Exception("INTERNAL ERROR: don't know how to handle a failed called to stopListening() - {}".format(e))

      self._manhole_service = None

      stopped_topic = '{}.on_manhole_stopped'.format(self._uri_prefix)
      stopped_info = None
      self.publish(stopped_topic, stopped_info, options = PublishOptions(exclude = [details.caller]))

      returnValue(stopped_info)



   def get_manhole(self, details = None):
      """
      Get current manhole service information.

      :returns: dict -- A dict with service information or `None` if the service is not running.
      """
      if self.debug:
         log.msg("{}.get_manhole".format(self.__class__.__name__))

      if not _HAS_MANHOLE:
         emsg = "ERROR: could not start manhole - required packages are missing ({})".format(_MANHOLE_MISSING_REASON)
         log.msg(emsg)
         raise ApplicationError("crossbar.error.feature_unavailable", emsg)

      if not self._manhole_service:
         return None
      else:
         return self._manhole_service.marshal()



   def utcnow(self, details = None):
      """
      Return current time as determined from within this process.

      :returns str -- Current time (UTC) in UTC ISO 8601 format.
      """
      if self.debug:
         log.msg("{}.utcnow".format(self.__class__.__name__))

      return utcnow()



   def started(self, details = None):
      """
      Return start time of this process.

      :returns str -- Start time (UTC) in UTC ISO 8601 format.
      """
      if self.debug:
         log.msg("{}.started".format(self.__class__.__name__))

      return utcstr(self._started)



   def uptime(self, details = None):
      """
      Uptime of this process.

      :returns float -- Uptime in seconds.
      """
      if self.debug:
         log.msg("{}.uptime".format(self.__class__.__name__))

      now = datetime.utcnow()
      return (now - self._started).total_seconds()

########NEW FILE########
__FILENAME__ = processinfo
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['SystemInfo', 'ProcessInfo']

import sys
import socket

from autobahn.util import utcnow

try:
   import psutil
except ImportError:
   _HAS_PSUTIL = False
else:
   _HAS_PSUTIL = True


## http://pythonhosted.org/psutil/
## http://linux.die.net/man/5/proc


if _HAS_PSUTIL:

   class SystemInfo:
      """
      Access system global information and statistics.     
      """

      def __init__(self):
         """
         """

      def cpu(self):
         return {
            'physical_count': psutil.cpu_count(logical = False),
            'logical_count': psutil.cpu_count(logical = True)
         }


      def stats(self):
         """
         """
         res = {}
         res['ts'] = utcnow()
         res['cpu'] = self.cpu_stats()
         res['mem'] = self.mem_stats()
         res['net'] = self.net_stats()
         res['disk'] = self.disk_stats()
         return res


      def cpu_stats(self):
         """
         Returns CPU times per (logical) CPU.
         """
         res = {}
         i = 0
         for c in psutil.cpu_times(percpu = True):
            res[i] = {
               'user': c.user,
               'system': c.system,
               'idle': c.idle
            }
            i += 1
         return res


      def mem_stats(self):
         res = {}
         m = psutil.virtual_memory()
         res['total'] = m.total
         res['available'] = m.available
         return res


      def net_stats(self):
         """
         Returns network I/O statistics per network interface.
         """
         res = {}
         ns = psutil.net_io_counters(pernic = True)
         for nic in ns.keys():
            stats = ns[nic]
            res[nic] = {
               'out': {
                  'bytes': stats.bytes_sent,
                  'packets': stats.packets_sent,
                  'errors': stats.errout,
                  'dropped': stats.dropout
               },
               'in': {
                  'bytes': stats.bytes_recv,
                  'packets': stats.packets_recv,
                  'errors': stats.errin,
                  'dropped': stats.dropin
               }
            }
         return res


      def disk_stats(self):
         """
         Returns disk I/O statistics per disk.
         """
         res = {}
         ds = psutil.disk_io_counters(perdisk = True)
         for disk in ds.keys():
            stats = ds[disk]
            res[disk] = {
               'read': {
                  'ops': stats.read_count,
                  'bytes': stats.read_bytes,
                  'time': stats.read_time
               },
               'write': {
                  'ops': stats.write_count,
                  'bytes': stats.write_bytes,
                  'time': stats.write_time
               }
            }
         return res



   class ProcessInfo:
      """
      Access process related information and statistics
      """

      _ADDRESS_TYPE_FAMILY_MAP = {
         (socket.AF_INET, socket.SOCK_STREAM): 'tcp4',
         (socket.AF_INET6, socket.SOCK_STREAM): 'tcp6',
         (socket.AF_INET, socket.SOCK_DGRAM): 'udp4',
         (socket.AF_INET6, socket.SOCK_DGRAM): 'udp6',
         (socket.AF_UNIX, socket.SOCK_STREAM): 'unix',
         (socket.AF_UNIX, socket.SOCK_DGRAM): 'unix'
      }

      def __init__(self):
         """
         Ctor.
         """
         self._p = psutil.Process()


      def get_stats(self):
         """
         Get process statistics.
         """
         res = {}
         res['ts'] = utcnow()

         s = self._p.num_ctx_switches()

         c = self._p.cpu_times()
         c_perc = self._p.cpu_percent()

         m = self._p.memory_info()
         m_perc = self._p.memory_percent()

         f = self._p.io_counters()

         ## process status
         res['status'] = self._p.status()

         ## context switches
         res['voluntary'] = s[0]
         res['nonvoluntary'] = s[1]

         ## cpu
         res['user'] = c.user
         res['system'] = c.system
         res['cpu_percent'] = c_perc

         ## memory
         res['resident'] = m.rss
         res['virtual'] = m.vms
         res['mem_percent'] = m_perc

         ## disk
         res['reads'] = f.read_count
         res['writes'] = f.write_count
         return res


      def get_info(self):
         """
         Gets process information.
         """
         descriptors = None
         try:
            if sys.platform.startswith('win'):
               descriptors = self._p.num_handles()
            else:
               descriptors = self._p.num_fds()
         except:
            pass
         cnt_threads = self._p.num_threads()
         res = {
            'descriptors': descriptors,
            'threads': cnt_threads,
            'files': self.open_files(),
            'sockets': self.open_sockets()
         }
         return res



      def open_files(self):
         """
         Returns list of files currently opened by this process.

         :returns: list -- List of files (sorted by path ascending).
         """
         res = [f.path for f in self._p.open_files()]
         return sorted(res)



      def open_sockets(self):
         """
         Returns list of open sockets currently opened by this process.

         :returns: list -- List of dicts with socket information.
         """
         res = []

         for c in self._p.connections(kind = 'all'):
            socket_type = ProcessInfo._ADDRESS_TYPE_FAMILY_MAP.get((c.family, c.type))
            if c.family == socket.AF_UNIX:
               laddr = c.laddr
               raddr = ""
            else:
               laddr = "{}:{}".format(c.laddr[0], c.laddr[1])
               if c.raddr and len(c.raddr) == 2:
                  raddr = "{}:{}".format(c.raddr[0], c.raddr[1])
               else:
                  raddr = ""
            status = str(c.status)
            res.append({
               'type': socket_type,
               'local': laddr,
               'remote': raddr,
               'status': status
            })
         return res

########NEW FILE########
__FILENAME__ = reloader
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['TrackingModuleReloader']

import os
import sys

try:
   reload
except NameError:
   # Python 3
   from imp import reload



def get_module_path_and_mtime(m):
   """
   Given a Python module, returns a pair (source file, source file mtime).

   :param m: A Python module instance.
   :type m: obj
   """
   res = (None, None)
   if m and hasattr(m, '__file__') and (m.__file__.endswith('.py') or m.__file__.endswith('.pyc')):
      f = m.__file__
      if f.endswith('.pyc'):
         f = f[:-1]
      try:
         mtime = os.stat(f)[8]
      except:
         res = (f, None)
      else:
         res = (f, mtime)
   return res



class TrackingModuleReloader:
   """
   A tracking module reloader.

   This will track modules loaded _after_ a snapshot (point in time), and
   later allow to force reload of exactly those modules that have been (first)
   loaded after that point in time.
   """

   def __init__(self, use_mtimes = True, debug = False):
      """
      Ctor.

      :param silence: Disable any log messages.
      :type silence: bool
      :param use_mtimes: If `True`, try to use file modification times to limit
                         module reloading to actually changed files.
      :type use_mtimes: bool
      """
      self._use_mtimes = use_mtimes
      self._debug = debug
      self.snapshot()


   def snapshot(self):
      """
      Establish a snapshot - that is, remember which modules are currently
      loaded. Later, when reload() is called, only modules imported later
      will be (forcefully) reloaded.
      """
      self._modules = sys.modules.copy()

      ## do mtime tracking ..
      if self._use_mtimes:
         self._module_mtimes = {}
         for mod_name, mod in self._modules.items():
            self._module_mtimes[mod_name] = get_module_path_and_mtime(mod)


   def reload(self):
      """
      Trigger reloading of all modules imported later than the last snapshot
      established.

      :returns int -- Number of modules reloaded.
      """
      current_modules = sys.modules
      maybe_dirty_modules = set(current_modules.keys()) - set(self._modules.keys())
      reload_modules = []

      ## use tracked mtimes to restrict set of actually reloaded modules, while
      ## trying to be conservative (if stuff fails or cannot be determined, opt
      ## for reloading the module -- even if it actually hasn't changed)
      ##
      if self._use_mtimes:
         for mod_name in maybe_dirty_modules:
            m = current_modules[mod_name]

            if mod_name in self._module_mtimes:

               f, new_mtime = get_module_path_and_mtime(m)
               _, old_mtime = self._module_mtimes[mod_name]

               if new_mtime == old_mtime:
                  if self._debug:
                     print("Module {} unchanged".format(mod_name))
               else:
                  self._module_mtimes[mod_name] = (f, new_mtime)
                  reload_modules.append(mod_name)
                  if self._debug:
                     print("Change of module {} detected (file {}).".format(mod_name, f))
            else:
               self._module_mtimes[mod_name] = get_module_path_and_mtime(m)
               reload_modules.append(mod_name)
               if self._debug:
                  print("Tracking new module {}".format(mod_name))
      else:
         reload_modules = maybe_dirty_modules


      if len(reload_modules):
         if self._debug:
            print("Reloading {} possibly changed modules".format(len(reload_modules)))
         for module in reload_modules:
            print("Reloading module {}".format(module))

            ## this is doing the actual work
            ##
            reload(current_modules[module])
      else:
         if self._debug:
            print("No modules to reload")

      return reload_modules

########NEW FILE########
__FILENAME__ = cli
###############################################################################
##
##  Copyright (C) 2011-2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['run']

import os
import sys
import json
import argparse
import pkg_resources
import platform
import shutil
import traceback

from twisted.python import log
from twisted.python.reflect import qual
from twisted.internet.defer import inlineCallbacks

from autobahn.twisted.choosereactor import install_reactor




def run_command_version(options):
   """
   Subcommand "crossbar version".
   """
   reactor = install_reactor(options.reactor, options.debug)

   ## Python
   ##
   py_ver = '.'.join([str(x) for x in list(sys.version_info[:3])])
   if options.debug:
      py_ver += " [%s]" % sys.version.replace('\n', ' ')

   ## Twisted / Reactor
   ##
   tx_ver = "%s-%s" % (pkg_resources.require("Twisted")[0].version, reactor.__class__.__name__)
   if options.debug:
      tx_ver += " [%s]" % qual(reactor.__class__)

   ## Autobahn
   ##
   import autobahn
   from autobahn.websocket.protocol import WebSocketProtocol
   ab_ver = pkg_resources.require("autobahn")[0].version
   if options.debug:
      ab_ver += " [%s]" % qual(WebSocketProtocol)

   ## UTF8 Validator
   ##
   from autobahn.websocket.utf8validator import Utf8Validator
   s = str(Utf8Validator)
   if 'wsaccel' in s:
      utf8_ver = 'wsaccel-%s' % pkg_resources.require('wsaccel')[0].version
   elif s.startswith('autobahn'):
      utf8_ver = 'autobahn'
   else:
      raise Exception("could not detect UTF8 validator type/version")
   if options.debug:
      utf8_ver += " [%s]" % qual(Utf8Validator)

   ## XOR Masker
   ##
   from autobahn.websocket.xormasker import XorMaskerNull
   s = str(XorMaskerNull)
   if 'wsaccel' in s:
      xor_ver = 'wsaccel-%s' % pkg_resources.require('wsaccel')[0].version
   elif s.startswith('autobahn'):
      xor_ver = 'autobahn'
   else:
      raise Exception("could not detect XOR masker type/version")
   if options.debug:
      xor_ver += " [%s]" % qual(XorMaskerNull)

   import crossbar

   print("")
   print("Crossbar.io software versions:")
   print("")
   print("Crossbar.io     : {0}".format(crossbar.__version__))
   print("Autobahn        : {0}".format(ab_ver))
   print("Twisted         : {0}".format(tx_ver))
   print("Python          : {0}".format(py_ver))
   print("UTF8 Validator  : {0}".format(utf8_ver))
   print("XOR Masker      : {0}".format(xor_ver))
   print("")



def run_command_templates(options):
   """
   Subcommand "crossbar templates".
   """
   from crossbar.controller.template import print_templates_help
   print_templates_help()



def run_command_init(options):
   """
   Subcommand "crossbar init".
   """
   from crossbar.controller.template import Templates

   templates = Templates()

   if not options.template in templates:
      raise Exception("no node template '{}' - use the command 'crossbar templates' to list templates available".format(options.template))

   if os.path.exists(options.cbdir):
      raise Exception("node directory '{}' already exists".format(options.cbdir))

   # try:
   #    os.mkdir(options.cbdir)
   # except Exception as e:
   #    raise Exception("could not create node directory '{}' ({})".format(options.cbdir, e))
   # else:
   #    print("Node directory '{}' created".format(options.cbdir))

   try:
      templates.init(options.cbdir, options.template)
   except Exception as e:
      try:
         shutil.rmtree(options.cbdir)
      except:
         pass
      raise e

   print("Node initialized")
   print("\nTo start your node, run 'crossbar start'")




def run_command_start(options):
   """
   Subcommand "crossbar start".
   """
   ## start Twisted logging
   ##
   if not options.logdir:
      logfd = sys.stderr
   else:
      from twisted.python.logfile import DailyLogFile
      logfd = DailyLogFile.fromFullPath(os.path.join(options.logdir, 'node.log'))

   from crossbar.twisted.process import DefaultSystemFileLogObserver
   flo = DefaultSystemFileLogObserver(logfd, system = "{:<10} {:>6}".format("Controller", os.getpid()))
   log.startLoggingWithObserver(flo.emit)

   log.msg("=" * 30 + " Crossbar.io " + "=" * 30 + "\n")

   import crossbar
   log.msg("Crossbar.io {} starting".format(crossbar.__version__))

   ## we use an Autobahn utility to import the "best" available Twisted reactor
   ##
   reactor = install_reactor(options.reactor, options.debug)

   from twisted.python.reflect import qual
   log.msg("Running on {} using {} reactor".format(platform.python_implementation(), qual(reactor.__class__).split('.')[-1]))
   log.msg("Starting from node directory {}".format(options.cbdir))


   ## create and start Crossbar.io node
   ##
   from crossbar.controller.node import Node
   node = Node(reactor, options)
   node.start()

   reactor.run()



def run_command_check(options):
   """
   Subcommand "crossbar check".
   """
   from crossbar.controller.config import check_config_file
   configfile = os.path.join(options.cbdir, options.config)

   print("Checking local configuration file {}".format(configfile))

   try:
      check_config_file(configfile)
   except Exception as e:
      print("Error encountered:")
      print()
      print(e)
      print()
   else:
      print("Ok, configuration file looks good.")



def run():
   """
   Entry point of Crossbar.io CLI.
   """
   ## create the top-level parser
   ##
   parser = argparse.ArgumentParser(prog = 'crossbar',
                                    description = "Crossbar.io - Polyglot application router - http://crossbar.io")

   ## top-level options
   ##
   parser.add_argument('-d',
                       '--debug',
                       action = 'store_true',
                       help = 'Debug on.')

   parser.add_argument('--reactor',
                       default = None,
                       choices = ['select', 'poll', 'epoll', 'kqueue', 'iocp'],
                       help = 'Explicit Twisted reactor selection')

   ## create subcommand parser
   ##
   subparsers = parser.add_subparsers(dest = 'command',
                                      title = 'commands',
                                      help = 'Crossbar.io command to run')

   ## "version" command
   ##
   parser_version = subparsers.add_parser('version',
                                          help = 'Print software versions.')

   parser_version.set_defaults(func = run_command_version)


   ## "init" command
   ##
   parser_init = subparsers.add_parser('init',
                                        help = 'Initialize a new Crossbar.io node.')

   parser_init.set_defaults(func = run_command_init)

   parser_init.add_argument('--template',
                             type = str,
                             default = 'default',
                             help = "Template for initialization")

   parser_init.add_argument('--cbdir',
                             type = str,
                             default = None,
                             help = "Crossbar.io node directory (overrides ${CROSSBAR_DIR} and the default ./.crossbar)")

   parser_init.add_argument('--config',
                            type = str,
                            default = None,
                            help = "Crossbar.io configuration file (overrides default CBDIR/config.json)")


   ## "templates" command
   ##
   parser_templates = subparsers.add_parser('templates',
                                            help = 'List templates available for initializing a new Crossbar.io node.')

   parser_templates.set_defaults(func = run_command_templates)



   ## "start" command
   ##
   parser_start = subparsers.add_parser('start',
                                        help = 'Start a Crossbar.io node.')

   parser_start.set_defaults(func = run_command_start)

   parser_start.add_argument('--cbdir',
                             type = str,
                             default = None,
                             help = "Crossbar.io node directory (overrides ${CROSSBAR_DIR} and the default ./.crossbar)")

   parser_start.add_argument('--config',
                             type = str,
                             default = 'config.json',
                             help = "Crossbar.io configuration file (overrides default CBDIR/config.json)")

   parser_start.add_argument('--logdir',
                             type = str,
                             default = None,
                             help = "Crossbar.io log directory (default: <Crossbar Node Directory>/log)")

   parser_start.add_argument('--loglevel',
                              type = str,
                              default = 'info',
                              choices = ['trace', 'debug', 'info', 'warn', 'error', 'fatal'],
                              help = "Server log level (overrides default 'info')")


   ## "check" command
   ##
   parser_check = subparsers.add_parser('check',
                                        help = 'Check a Crossbar.io node`s local configuration file.')

   parser_check.set_defaults(func = run_command_check)

   parser_check.add_argument('--cbdir',
                             type = str,
                             default = None,
                             help = "Crossbar.io node directory (overrides ${CROSSBAR_DIR} and the default ./.crossbar)")

   parser_check.add_argument('--config',
                             type = str,
                             default = None,
                             help = "Crossbar.io configuration file (overrides default CBDIR/config.json)")


   ## parse cmd line args
   ##
   options = parser.parse_args()


   ## Crossbar.io node directory
   ##
   if hasattr(options, 'cbdir'):
      if not options.cbdir:
         if "CROSSBAR_DIR" in os.environ:
            options.cbdir = os.environ['CROSSBAR_DIR']
         else:
            options.cbdir = '.crossbar'
      options.cbdir = os.path.abspath(options.cbdir)


   ## Crossbar.io node configuration file
   ##
   if hasattr(options, 'config'):
      if not options.config:
         options.config = 'config.json'
      options.config = os.path.join(options.cbdir, options.config)


   ## Log directory
   ##
   if hasattr(options, 'logdir'):
      if options.logdir:
         options.logdir = os.path.abspath(os.path.join(options.cbdir, options.logdir))
         if not os.path.isdir(options.logdir):
            try:
               os.mkdir(options.logdir)
            except Exception as e:
               print("Could not create log directory: {}".format(e))
               sys.exit(1)


   ## run the subcommand selected
   ##
   options.func(options)



if __name__ == '__main__':
   try:
      run()
   except Exception as e:
      print("\nError: {}\n".format(e))
      traceback.print_exc()
      sys.exit(1)
   else:
      sys.exit(0)

########NEW FILE########
__FILENAME__ = guest
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from __future__ import absolute_import

__all__ = ['create_guest_worker_client_factory']

from twisted.python import log
from twisted.internet import protocol
from twisted.internet.error import ProcessDone, \
                                   ProcessTerminated, \
                                   ConnectionDone, \
                                   ConnectionClosed, \
                                   ConnectionLost, \
                                   ConnectionAborted



class GuestWorkerClientProtocol(protocol.ProcessProtocol):

   def __init__(self):
      self._pid = None
      self._name = None

   def _log(self, data):
      for msg in data.split('\n'):
         msg = msg.strip()
         if msg != "":
            log.msg(msg, system = "{:<10} {:>6}".format(self._name, self._pid))

   def connectionMade(self):

      config = self.factory._config

      if 'stdout' in config and config['stdout'] == 'close':
         self.transport.closeStdout()

      if 'stderr' in config and config['stderr'] == 'close':
         self.transport.closeStderr()

      if 'stdin' in config:
         if config['stdin'] == 'close':
            self.transport.closeStdin()
         else:
            if config['stdin']['type'] == 'json':
               self.transport.write(json.dumps(config['stdin']['value']))
            elif config['stdin']['type'] == 'msgpack':
               pass ## FIXME
            else:
               raise Exception("logic error")

            if config['stdin'].get('close', True):
               self.transport.closeStdin()

   def outReceived(self, data):
      config = self.factory._config
      if config.get('stdout', None) == 'log':
         self._log(data)

   def errReceived(self, data):
      config = self.factory._config
      if config.get('stderr', None) == 'log':
         self._log(data)

   def inConnectionLost(self):
      pass

   def outConnectionLost(self):
      pass

   def errConnectionLost(self):
      pass

   def processExited(self, reason):
      pass

   def processEnded(self, reason):
      try:
         if isinstance(reason.value,  ProcessDone):
            #log.msg("Guest {}: Ended cleanly.".format(self._pid))
            self.factory._on_exit.callback(None)
         elif isinstance(reason.value, ProcessTerminated):
            #log.msg("Guest {}: Ended with error {}".format(self._pid, reason.value.exitCode))
#            self.factory._on_exit.errback(reason.value.exitCode)
            self.factory._on_exit.errback(reason)
         else:
            ## should not arrive here
            pass
      except Exception as e:
         print(e)



class GuestWorkerClientFactory(protocol.Factory):

   def buildProtocol(self, addr):
      self.proto = GuestWorkerClientProtocol()
      self.proto.factory = self
      return self.proto



def create_guest_worker_client_factory(config, on_ready, on_exit):
   factory = GuestWorkerClientFactory()
   factory._config = config
   factory._on_ready = on_ready
   factory._on_exit = on_exit
   return factory

########NEW FILE########
__FILENAME__ = management
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['NodeSession']


from twisted.python import log
from twisted.internet.defer import Deferred, DeferredList, returnValue, inlineCallbacks

from twisted.internet.error import ProcessDone, \
                                   ProcessTerminated, \
                                   ConnectionDone, \
                                   ConnectionClosed, \
                                   ConnectionLost, \
                                   ConnectionAborted


from autobahn.twisted.wamp import ApplicationSession

import os, sys
import json

from autobahn.wamp.router import RouterFactory
from autobahn.twisted.wamp import RouterSessionFactory
from autobahn.twisted.websocket import WampWebSocketClientFactory, WampWebSocketClientProtocol
from twisted.internet.endpoints import ProcessEndpoint, StandardErrorBehavior

import pkg_resources
from sys import argv, executable

from autobahn.twisted.wamp import ApplicationSessionFactory
from twisted.internet.endpoints import clientFromString

from autobahn.wamp.exception import ApplicationError
from autobahn.wamp import types

from autobahn.util import utcnow

import socket
import os

from twisted.internet.protocol import ProcessProtocol
from crossbar.process import CustomProcessEndpoint

from twisted.internet import protocol
import re, json





class NodeManagementSession(ApplicationSession):
   """
   """
   def __init__(self):
      ApplicationSession.__init__(self)


   def onConnect(self):
      self.join("crossbar.cloud")


   def is_paired(self):
      return False


   @inlineCallbacks
   def onJoin(self, details):
      log.msg("Connected to Crossbar.io Management Cloud.")

      from twisted.internet import reactor

      self.factory.node_session.setControllerSession(self)

      if not self.is_paired():
         try:
            node_info = {}
            node_publickey = "public key"
            activation_code = yield self.call('crossbar.cloud.get_activation_code', node_info, node_publickey)
         except Exception as e:
            log.msg("internal error: {}".format(e))
         else:
            log.msg("Log into https://console.crossbar.io to configure your instance using the activation code: {}".format(activation_code))

            reg = None

            def activate(node_id, certificate):
               ## check if certificate was issued by Tavendo
               ## check if certificate matches node key
               ## persist node_id
               ## persist certificate
               ## restart node
               reg.unregister()

               self.publish('crossbar.node.onactivate', node_id)

               log.msg("Restarting node in 5 seconds ...")
               reactor.callLater(5, self.factory.node_controller_session.restart_node)

            reg = yield self.register(activate, 'crossbar.node.activate.{}'.format(activation_code))
      else:
         pass

      res = yield self.register(self.factory.node_controller_session.get_node_worker_processes, 'crossbar.node.get_node_worker_processes')

      self.publish('com.myapp.topic1', os.getpid())


########NEW FILE########
__FILENAME__ = native
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from __future__ import absolute_import

__all__ = ['create_native_worker_client_factory']

from twisted.python import log

from autobahn.twisted.websocket import WampWebSocketClientFactory, \
                                       WampWebSocketClientProtocol

from twisted.internet.error import ProcessDone, \
                                   ProcessTerminated, \
                                   ConnectionDone, \
                                   ConnectionClosed, \
                                   ConnectionLost, \
                                   ConnectionAborted



class NativeWorkerClientProtocol(WampWebSocketClientProtocol):

   def connectionMade(self):
      WampWebSocketClientProtocol.connectionMade(self)
      self._pid = self.transport.pid
      self.factory.proto = self


   def connectionLost(self, reason):
      log.msg("Worker {}: Process connection gone ({})".format(self._pid, reason.value))

      WampWebSocketClientProtocol.connectionLost(self, reason)
      self.factory.proto = None


      if isinstance(reason.value, ProcessTerminated):
         if not self.factory._on_ready.called:
            ## the worker was never ready in the first place ..
            self.factory._on_ready.errback(reason)
         else:
            ## the worker _did_ run (was ready before), but now exited with error
            if not self.factory._on_exit.called:
               self.factory._on_exit.errback(reason)
            else:
               log.msg("FIXME: unhandled code path (1) in WorkerClientProtocol.connectionLost", reason.value)
      elif isinstance(reason.value, ProcessDone) or isinstance(reason.value, ConnectionDone):
         ## the worker exited cleanly
         if not self.factory._on_exit.called:
            self.factory._on_exit.callback(None)
         else:
            log.msg("FIXME: unhandled code path (2) in WorkerClientProtocol.connectionLost", reason.value)
      else:
         ## should not arrive here
         log.msg("FIXME: unhandled code path (3) in WorkerClientProtocol.connectionLost", reason.value)



class NativeWorkerClientFactory(WampWebSocketClientFactory):

   def __init__(self, *args, **kwargs):
      WampWebSocketClientFactory.__init__(self, *args, **kwargs)
      self.proto = None

   def buildProtocol(self, addr):
      self.proto = NativeWorkerClientProtocol()
      self.proto.factory = self
      return self.proto

   def stopFactory(self):
      WampWebSocketClientFactory.stopFactory(self)
      if self.proto:
         self.proto.close()
         #self.proto.transport.loseConnection()



def create_native_worker_client_factory(router_session_factory, on_ready, on_exit):
   """
   Create a transport factory for talking to native workers.

   The node controller talks WAMP-WebSocket-over-STDIO with spawned (native) workers.

   The node controller runs a client transport factory, and the native worker
   runs a server transport factory. This is a little non-intuitive, but just the
   way that Twisted works when using STDIO transports.

   :param router_session_factory: Router session factory to attach to.
   :type router_session_factory: obj
   """
   factory = NativeWorkerClientFactory(router_session_factory, "ws://localhost", debug = False)

   ## we need to increase the opening handshake timeout in particular, since starting up a worker
   ## on PyPy will take a little (due to JITting)
   factory.setProtocolOptions(failByDrop = False, openHandshakeTimeout = 30, closeHandshakeTimeout = 5)
   factory._on_ready = on_ready
   factory._on_exit = on_exit

   return factory

########NEW FILE########
__FILENAME__ = node
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['Node']


import os
import sys
import json
import traceback

from twisted.python import log
from twisted.internet.defer import Deferred, \
                                   DeferredList, \
                                   returnValue, \
                                   inlineCallbacks

from autobahn import wamp
from autobahn.wamp.types import CallDetails
from autobahn.wamp.router import RouterFactory
from autobahn.twisted.wamp import RouterSessionFactory

from crossbar.common import checkconfig
from crossbar.controller.process import NodeControllerSession


from autobahn.wamp.types import ComponentConfig




class Node:
   """
   A Crossbar.io node is the running a controller process
   and one or multiple worker processes.

   A single Crossbar.io node runs exactly one instance of
   this class, hence this class can be considered a system
   singleton.
   """

   def __init__(self, reactor, options):
      """
      Ctor.

      :param reactor: Reactor to run on.
      :type reactor: obj
      :param options: Options from command line.
      :type options: obj
      """
      self._reactor = reactor

      self._cbdir = options.cbdir

      with open(options.config) as config_file:
         self._config = json.load(config_file)

      self._reactor_shortname = options.reactor

      self.debug = False

      self._worker_workers = {}

      ## the node's name (must be unique within the management realm)
      self._node_id = self._config['controller']['id']

      ## the node's management realm
      self._realm = self._config['controller'].get('realm', 'crossbar')

      ## node controller session (a singleton ApplicationSession embedded
      ## in the node's management router)
      self._controller = None



   def start(self):
      """
      Starts this node. This will start a node controller
      and then spawn new worker processes as needed.

      The node controller will watch spawned processes,
      communicate via stdio with the worker, and start
      and restart the worker processes as needed.
      """
      try:
         import setproctitle
      except ImportError:
         log.msg("Warning, could not set process title (setproctitle not installed)")
      else:
         setproctitle.setproctitle("crossbar-controller")

      ## the node controller singleton WAMP application session
      ##
      #session_config = ComponentConfig(realm = options.realm, extra = options)

      self._controller = NodeControllerSession(self)

      ## router and factory that creates router sessions
      ##
      self._router_factory = RouterFactory(
         options = wamp.types.RouterOptions(uri_check = wamp.types.RouterOptions.URI_CHECK_LOOSE),
         debug = False)
      self._router_session_factory = RouterSessionFactory(self._router_factory)

      ## add the node controller singleton session to the router
      ##
      self._router_session_factory.add(self._controller)

      ## Detect WAMPlets
      ##
      wamplets = self._controller._get_wamplets()
      if len(wamplets) > 0:
         log.msg("Detected {} WAMPlets in environment:".format(len(wamplets)))
         for wpl in wamplets:
            log.msg("WAMPlet {}.{}".format(wpl['dist'], wpl['name']))
      else:
         log.msg("No WAMPlets detected in enviroment.")


#      self._start_from_local_config(configfile = os.path.join(self._cbdir, self._options.config))
      self.run_node_config(self._config)

      self.start_local_management_transport(endpoint_descriptor = "tcp:9000")



   def start_local_management_transport(self, endpoint_descriptor):
      ## create a WAMP-over-WebSocket transport server factory
      ##
      from autobahn.twisted.websocket import WampWebSocketServerFactory
      from twisted.internet.endpoints import serverFromString

      self._router_server_transport_factory = WampWebSocketServerFactory(self._router_session_factory, debug = self.debug)
      self._router_server_transport_factory.setProtocolOptions(failByDrop = False)
      self._router_server_transport_factory.noisy = False


      ## start the WebSocket server from an endpoint
      ##
      self._router_server = serverFromString(self._reactor, endpoint_descriptor)
      ## FIXME: the following spills out log noise: "WampWebSocketServerFactory starting on 9000"
      self._router_server.listen(self._router_server_transport_factory)



   def _start_from_local_config(self, configfile):
      """
      Start Crossbar.io node from local configuration file.
      """
      configfile = os.path.abspath(configfile)
      log.msg("Starting from local config file '{}'".format(configfile))

      try:
         #config = controller.config.check_config_file(configfile, silence = True)
         config = json.loads(open(configfile, 'rb').read())
      except Exception as e:
         log.msg("Fatal: {}".format(e))
         sys.exit(1)
      else:
         self.run_node_config(config)


   @inlineCallbacks
   def run_node_config(self, config):
      try:
         yield self._run_node_config(config)
      except:
         traceback.print_exc()
         self._reactor.stop()


   @inlineCallbacks
   def _run_node_config(self, config):
      """
      Setup node according to config provided.
      """

      ## fake call details information when calling into
      ## remoted procedure locally
      ##
      call_details = CallDetails(caller = 0, authid = 'node')

      for worker in config.get('workers', []):

         worker_id = worker['id']
         worker_type = worker['type']
         worker_options = worker.get('options', {})

         if worker_type == 'router':
            worker_logname = "Router '{}'".format(worker_id)

         elif worker_type == 'container':
            worker_logname = "Container '{}'".format(worker_id)

         elif worker_type == 'guest':
            worker_logname = "Guest '{}'".format(worker_id)

         else:
            raise Exception("logic error")

         ## router/container
         ##
         if worker_type in ['router', 'container']:

            ## start a new worker process ..
            ##
            if worker_type == 'router':
               yield self._controller.start_router(worker_id, worker_options, details = call_details)

            elif worker_type == 'container':
               yield self._controller.start_container(worker_id, worker_options, details = call_details)

            else:
               raise Exception("logic error")

            ## setup worker generic stuff
            ##
            if 'pythonpath' in worker_options:
               added_paths = yield self._controller.call('crossbar.node.{}.worker.{}.add_pythonpath'.format(self._node_id, worker_id), worker_options['pythonpath'])
               log.msg("{}: PYTHONPATH extended for {}".format(worker_logname, added_paths))

            if 'cpu_affinity' in worker_options:
               new_affinity = yield self._controller.call('crossbar.node.{}.worker.{}.set_cpu_affinity'.format(self._node_id, worker_id), worker_options['cpu_affinity'])
               log.msg("{}: CPU affinity set to {}".format(worker_logname, new_affinity))

            ## manhole within worker
            ##
            if 'manhole' in worker:
               yield self._controller.call('crossbar.node.{}.worker.{}.start_manhole'.format(self._node_id, worker_id), worker['manhole'])
               log.msg("{}: manhole started".format(worker_logname))

            ## setup router worker
            ##
            if worker_type == 'router':

               ## start realms
               ##
               for realm in worker.get('realms', []):

                  #yield self._controller.call('crossbar.node.{}.worker.{}.start_router_realm'.format(self._node_id, worker_id), realm['id'], realm)
                  log.msg("{}: realm '{}' started".format(worker_logname, realm['id']))

               ## start components to run embedded in the router
               ##
               for component in worker.get('components', []):

                  yield self._controller.call('crossbar.node.{}.worker.{}.start_router_component'.format(self._node_id, worker_id), component['id'], component)
                  log.msg("{}: component '{}' started".format(worker_logname, component['id']))

               ## start transports on router
               ##
               for transport in worker['transports']:

                  yield self._controller.call('crossbar.node.{}.worker.{}.start_router_transport'.format(self._node_id, worker_id), transport['id'], transport)
                  log.msg("{}: transport '{}' started".format(worker_logname, transport['id']))

            ## setup container worker
            ##
            elif worker_type == 'container':

               for component in worker.get('components', []):

                  yield self._controller.call('crossbar.node.{}.worker.{}.start_container_component'.format(self._node_id, worker_id), component['id'], component)
                  log.msg("{}: component '{}' started".format(worker_logname, component['id']))

            else:
               raise Exception("logic error")


         elif worker_type == 'guest':

            ## start guest worker
            ##
            yield self._controller.start_guest(worker_id, worker, details = call_details)
            log.msg("{}: started".format(worker_logname))

         else:
            raise Exception("logic error")

########NEW FILE########
__FILENAME__ = process
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from __future__ import absolute_import

__all__ = ['NodeControllerSession', 'create_process_env']


import os
import sys
import pkg_resources
from datetime import datetime, timedelta

from twisted.python import log
from twisted.internet.defer import Deferred, \
                                   DeferredList, \
                                   returnValue, \
                                   inlineCallbacks


from autobahn.util import utcnow, utcstr
from autobahn.wamp.exception import ApplicationError
from autobahn.wamp.types import PublishOptions, \
                                RegisterOptions, \
                                CallDetails

from autobahn.twisted.util import sleep
from autobahn.twisted.wamp import ApplicationSession

from crossbar.common import checkconfig
from crossbar.twisted.process import WorkerProcessEndpoint
from crossbar.controller.native import create_native_worker_client_factory
from crossbar.controller.guest import create_guest_worker_client_factory

from crossbar.controller.types import *
from crossbar.common.process import NativeProcessSession




class NodeControllerSession(NativeProcessSession):
   """
   Singleton node WAMP session hooked up to the node management router.

   This class exposes the node's management API.
   """

   def __init__(self, node):
      """
      :param node: The node singleton for this node controller session.
      :type node: obj
      """
      ApplicationSession.__init__(self)
      #self.debug = node.debug
      self.debug = True
      self.debug_app = True

      ## associated node
      self._node = node
      self._node_id = node._node_id
      self._realm = node._realm

      self.cbdir = self._node._cbdir

      self._created = utcnow()
      self._pid = os.getpid()

      ## map of worker processes: worker_id -> NativeWorkerProcess
      self._workers = {}

      exit = Deferred()



   def onConnect(self):
      #self._uri_prefix = 'crossbar.node.{}'.format(self.config.extra.node)
      self._uri_prefix = 'crossbar.node.{}'.format(self._node_id)

      NativeProcessSession.onConnect(self, False)

      #self.join(self.config.realm)
      self.join(self._realm)



   @inlineCallbacks
   def onJoin(self, details):

      ## When a (native) worker process has connected back to the router of
      ## the node controller, the worker will publish this event
      ## to signal it's readyness.
      ##
      def on_worker_ready(res):
         id = res['id']
         if id in self._workers:
            ready = self._workers[id].ready
            if not ready.called:
               ## fire the Deferred previously stored for
               ## signaling "worker ready"
               ready.callback(id)
            else:
               log.msg("INTERNAL ERROR: on_worker_ready() fired for process {} - ready already called".format(id))
         else:
            log.msg("INTERNAL ERROR: on_worker_ready() fired for process {} - no process with that ID".format(id))

      self.subscribe(on_worker_ready, 'crossbar.node.{}.on_worker_ready'.format(self._node_id))

      yield NativeProcessSession.onJoin(self, details)

      ## register node controller procedures: 'crossbar.node.<ID>.<PROCEDURE>'
      ##
      procs = [
         'shutdown',
         'get_info',
         'get_workers',
         'get_worker_log',
         'start_router',
         'stop_router',
         'start_container',
         'stop_container',
         'start_guest',
         'stop_guest',
      ]

      dl = []
      for proc in procs:
         uri = '{}.{}'.format(self._uri_prefix, proc)
         if self.debug:
            log.msg("Registering procedure '{}'".format(uri))
         dl.append(self.register(getattr(self, proc), uri, options = RegisterOptions(details_arg = 'details', discloseCaller = True)))

      regs = yield DeferredList(dl)

      if self.debug:
         log.msg("{} registered {} procedures".format(self.__class__.__name__, len(regs)))

      ## FIXME: publish node ready event



   @inlineCallbacks
   def shutdown(self, restart = False, details = None):
      """
      Stop this node.
      """
      log.msg("Shutting down node ..")

      shutdown_topic = 'crossbar.node.{}.on_shutdown'.format(self._node_id)

      shutdown_info = {
      }

      yield self.publish(shutdown_topic, shutdown_info, options = PublishOptions(acknowledge = True))
      yield sleep(3)

      self._node._reactor.stop()



   def get_info(self, details = None):
      """
      Return node information.
      """
      return {
         'created': self._created,
         'pid': self._pid,
         'workers': len(self._workers),
         'directory': self.cbdir,
         'wamplets': self._get_wamplets()
      }



   def _get_wamplets(self):
      """
      List installed WAMPlets.
      """
      res = []

      for entrypoint in pkg_resources.iter_entry_points('autobahn.twisted.wamplet'):
         try:
            e = entrypoint.load()
         except Exception as e:
            pass
         else:
            ep = {}
            ep['dist'] = entrypoint.dist.key
            ep['version'] = entrypoint.dist.version
            ep['location'] = entrypoint.dist.location
            ep['name'] = entrypoint.name
            ep['module_name'] = entrypoint.module_name
            ep['entry_point'] = str(entrypoint)

            if hasattr(e, '__doc__') and e.__doc__:
               ep['doc'] = e.__doc__.strip()
            else:
               ep['doc'] = None

            ep['meta'] = e(None)

            res.append(ep)

      return sorted(res)



   def get_workers(self, details = None):
      """
      Returns the list of processes currently running on this node.

      :returns: list -- List of worker processes.
      """
      now = datetime.utcnow()
      res = []
      for worker in sorted(self._workers.values(), key = lambda w: w.created):
         res.append({
            'id': worker.id,
            'pid': worker.pid,
            'type': worker.TYPE,
            'status': worker.status,
            'created': utcstr(worker.created),
            'started': utcstr(worker.started),
            'startup_time': (worker.started - worker.created).total_seconds() if worker.started else None,
            'uptime': (now - worker.started).total_seconds() if worker.started else None,
         })
      return res



   def get_worker_log(self, id, limit = None, details = None):
      """
      Get buffered worker log.

      :param limit: Optionally, limit the amount of log entries returned
         to the last N entries.
      :type limit: None or int

      :returns: list -- Buffered log.
      """
      if id not in self._workers:
         emsg = "ERROR: no worker with ID '{}'".format(id)
         raise ApplicationError('crossbar.error.no_such_worker', emsg)

      return self._workers[id].getlog(limit)



   def start_router(self, id, options = {}, details = None):
      """
      Start a new router worker: a Crossbar.io native worker process
      that runs a WAMP router.

      crossbar.node.<node_id>.on_router_starting
      crossbar.node.<node_id>.on_router_started

      crossbar.node.<node_id>.on_router_stopping
      crossbar.node.<node_id>.on_router_stopped

      :param id: The worker ID to start this router with.
      :type id: str
      :param options: The router worker options.
      :type options: dict
      """
      if self.debug:
         log.msg("NodeControllerSession.start_router", id, options)

      return self._start_native_worker('router', id, options, details = details)



   def start_container(self, id, options = {}, details = None):
      """
      Start a new container worker: a Crossbar.io native worker process
      that can host WAMP application components written in Python.

      :param id: The worker ID to start this container with.
      :type id: str
      :param options: The container worker options.
      :type options: dict
      """
      if self.debug:
         log.msg("NodeControllerSession.start_container", id, options)

      return self._start_native_worker('container', id, options, details = details)



   def _start_native_worker(self, wtype, id, options, details = None):

      assert(wtype in ['router', 'container'])

      ## prohibit starting a worker twice
      ##
      if id in self._workers:
         emsg = "ERROR: could not start worker - a worker with ID '{}'' is already running (or starting)".format(id)
         log.msg(emsg)
         raise ApplicationError('crossbar.error.worker_already_running', emsg)

      ## check worker options
      ##
      try:
         if wtype == 'router':
            checkconfig.check_router_options(options)
         elif wtype == 'container':
            checkconfig.check_container_options(options)
         else:
            raise Exception("logic error")
      except Exception as e:
         emsg = "ERROR: could not start router - invalid configuration ({})".format(e)
         log.msg(emsg)
         raise ApplicationError('crossbar.error.invalid_configuration', emsg)

      ## allow override Python executable from options
      ##
      if 'python' in options:
         exe = options['python']

         ## the executable must be an absolute path, e.g. /home/oberstet/pypy-2.2.1-linux64/bin/pypy
         ##
         if not os.path.isabs(exe):
            emsg = "ERROR: python '{}' from worker options must be an absolute path".format(exe)
            log.msg(emsg)
            raise ApplicationError('crossbar.error.invalid_configuration', emsg)

         ## of course the path must exist and actually be executable
         ##
         if not (os.path.isfile(exe) and os.access(exe, os.X_OK)):
            emsg = "ERROR: python '{}' from worker options does not exist or isn't an executable".format(exe)
            log.msg(emsg)
            raise ApplicationError('crossbar.error.invalid_configuration', emsg)
      else:
         exe = sys.executable

      ## all native workers (routers and containers for now) start from the same script
      ##
      filename = pkg_resources.resource_filename('crossbar', 'worker/process.py')

      ## assemble command line for forking the worker
      ##
      args = [exe, "-u", filename]
      args.extend(["--cbdir", self._node._cbdir])
      args.extend(["--node", str(self._node_id)])
      args.extend(["--worker", str(id)])
      args.extend(["--realm", self._realm])
      args.extend(["--type", wtype])

      ## allow override worker process title from options
      ##
      if options.get('title', None):
         args.extend(['--title', options['title']])

      ## allow overriding debug flag from options
      ##
      if options.get('debug', self.debug):
         args.append('--debug')

      ## forward explicit reactor selection
      ##
      if self._node._reactor_shortname:
         args.extend(['--reactor', self._node._reactor_shortname])

      ## create worker process environment
      ##
      worker_env = create_process_env(options)

      ## log name of worker
      ##
      worker_logname = {'router': 'Router', 'container': 'Container'}.get(wtype, 'Worker')

      ## topic URIs used (later)
      ##
      if wtype == 'router':
         starting_topic = 'crossbar.node.{}.on_router_starting'.format(self._node_id)
         started_topic = 'crossbar.node.{}.on_router_started'.format(self._node_id)
      elif wtype == 'container':
         starting_topic = 'crossbar.node.{}.on_container_starting'.format(self._node_id)
         started_topic = 'crossbar.node.{}.on_container_started'.format(self._node_id)
      else:
         raise Exception("logic error")

      ## add worker tracking instance to the worker map ..
      ##
      if wtype == 'router':
         worker = RouterWorkerProcess(self, id, details.authid, keeplog = options.get('traceback', None))
      elif wtype == 'container':
         worker = ContainerWorkerProcess(self, id, details.authid, keeplog = options.get('traceback', None))
      else:
         raise Exception("logic error")

      self._workers[id] = worker

      ## create a (custom) process endpoint
      ##
      ep = WorkerProcessEndpoint(self._node._reactor, exe, args, env = worker_env, worker = worker)

      ## ready handling
      ##
      def on_ready_success(id):
         log.msg("{} with ID '{}' and PID {} started".format(worker_logname, worker.id, worker.pid))

         worker.status = 'started'
         worker.started = datetime.utcnow()

         started_info = {
            'id': worker.id,
            'status': worker.status,
            'started': utcstr(worker.started),
            'who': worker.who
         }

         self.publish(started_topic, started_info, options = PublishOptions(exclude = [details.caller]))

         return started_info

      def on_ready_error(err):
         del self._workers[worker.id]

         emsg = 'ERROR: failed to start native worker - {}'.format(err.value)
         log.msg(emsg)
         raise ApplicationError("crossbar.error.cannot_start", emsg, worker.getlog())

      worker.ready.addCallbacks(on_ready_success, on_ready_error)


      def on_exit_success(res):
         del self._workers[worker.id]

      def on_exit_error(err):
         del self._workers[worker.id]

      worker.exit.addCallbacks(on_exit_success, on_exit_error)


      ## create a transport factory for talking WAMP to the native worker
      ##
      transport_factory = create_native_worker_client_factory(self._node._router_session_factory, worker.ready, worker.exit)
      transport_factory.noisy = False
      self._workers[id].factory = transport_factory

      ## now (immediately before actually forking) signal the starting of the worker
      ##
      starting_info = {
         'id': id,
         'status': worker.status,
         'created': utcstr(worker.created),
         'who': worker.who
      }

      ## the caller gets a progressive result ..
      if details.progress:
         details.progress(starting_info)

      ## .. while all others get an event
      self.publish(starting_topic, starting_info, options = PublishOptions(exclude = [details.caller]))

      ## now actually fork the worker ..
      ##
      if True or self.debug:
         log.msg("Starting {} with ID '{}' using command line '{}' ..".format(worker_logname, id, ' '.join(args)))
      else:
         log.msg("Starting {} with ID '{}' ..".format(worker_logname, id))

      d = ep.connect(transport_factory)


      def on_connect_success(proto):

         ## this seems to be called immediately when the child process
         ## has been forked. even if it then immediately fails because
         ## e.g. the executable doesn't even exist. in other words,
         ## I'm not sure under what conditions the deferred will errback ..

         pid = proto.transport.pid
         if self.debug:
            log.msg("Native worker process connected with PID {}".format(pid))

         ## note the PID of the worker
         worker.pid = pid

         ## proto is an instance of NativeWorkerClientProtocol
         worker.proto = proto

         worker.status = 'connected'
         worker.connected = datetime.utcnow()


      def on_connect_error(err):

         ## not sure when this errback is triggered at all ..
         if self.debug:
            log.msg("ERROR: Connecting forked native worker failed - {}".format(err))

         ## in any case, forward the error ..
         worker.ready.errback(err)

      d.addCallbacks(on_connect_success, on_connect_error)

      return worker.ready



   def stop_router(self, id, kill = False, details = None):
      """
      Stops a currently running router worker.

      :param id: The ID of the router worker to stop.
      :type id: str
      :param kill: If `True`, kill the process. Otherwise, gracefully
                   shut down the worker.
      :type kill: bool
      """
      if self.debug:
         log.msg("NodeControllerSession.start_router", id, kill, options)

      return self._stop_native_worker('router', id, kill, details = details)



   def stop_container(self, id, kill = False, details = None):
      """
      Stops a currently running container worker.

      :param id: The ID of the container worker to stop.
      :type id: str
      :param kill: If `True`, kill the process. Otherwise, gracefully
                   shut down the worker.
      :type kill: bool
      """
      if self.debug:
         log.msg("NodeControllerSession.stop_container", id, kill, options)

      return self._stop_native_worker('container', id, kill, details = details)



   def _stop_native_worker(self, wtype, id, kill, details = None):

      assert(wtype in ['router', 'container'])

      if id not in self._workers or self._workers[id].TYPE != wtype:
         emsg = "ERROR: no {} worker with ID '{}' currently running".format(wtype, id)
         raise ApplicationError('crossbar.error.worker_not_running', emsg)

      worker = self._workers[id]

      if worker.status != 'started':
         emsg = "ERROR: worker with ID '{}' is not in 'started' status (current status: '{}')".format(id, worker.status)
         raise ApplicationError('crossbar.error.worker_not_running', emsg)

      if kill:
         log.msg("Killing {} worker with ID '{}'".format(wtype, id))
         self._workers[id].proto.transport.signalProcess("KILL")
      else:
         log.msg("Stopping {} worker with ID '{}'".format(wtype, id))
         self._workers[id].factory.stopFactory()
         #self._workers[id].proto._session.leave()



   def start_guest(self, id, config, details = None):
      """
      Start a new guest process on this node.

      :param config: The guest process configuration.
      :type config: obj

      :returns: int -- The PID of the new process.
      """
      ## prohibit starting a worker twice
      ##
      if id in self._workers:
         emsg = "ERROR: could not start worker - a worker with ID '{}'' is already running (or starting)".format(id)
         log.msg(emsg)
         raise ApplicationError('crossbar.error.worker_already_running', emsg)

      try:
         checkconfig.check_guest(config)
      except Exception as e:
         raise ApplicationError('crossbar.error.invalid_configuration', 'invalid guest worker configuration: {}'.format(e))

      ## guest process executable and command line arguments
      ##
      exe = config['executable']
      args = [exe]
      args.extend(config.get('arguments', []))

      ## guest process working directory
      ##
      workdir = self._node._cbdir
      if 'workdir' in config:
         workdir = os.path.join(workdir, config['workdir'])
      workdir = os.path.abspath(workdir)

      ## guest process environment
      ##
      penv = create_process_env(config.get('options', {}))

      ## log name of worker
      ##
      worker_logname = 'Guest'

      ## topic URIs used (later)
      ##
      starting_topic = 'crossbar.node.{}.on_guest_starting'.format(self._node_id)
      started_topic = 'crossbar.node.{}.on_guest_started'.format(self._node_id)

      ## create a (custom) process endpoint
      ##
      ep = CustomProcessEndpoint(self._node._reactor, exe, args, env = penv,
         name = worker_logname, keeplog = options.get('traceback', None))

      ## add worker tracking instance to the worker map ..
      ##
      worker = GuestWorkerProcess(id, details.authid)

      self._workers[id] = worker

      ## ready handling
      ##
      def on_ready_success(id):
         log.msg("{} with ID '{}' and PID {} started".format(worker_logname, worker.id, worker.pid))

         worker.status = 'started'
         worker.started = datetime.utcnow()

         started_info = {
            'id': worker.id,
            'status': worker.status,
            'started': utcstr(worker.started),
            'who': worker.who
         }

         self.publish(started_topic, started_info, options = PublishOptions(exclude = [details.caller]))

         return started_info

      def on_ready_error(err):
         del self._workers[worker.id]

         emsg = 'ERROR: failed to start guest worker - {}'.format(err.value)
         log.msg(emsg)
         raise ApplicationError("crossbar.error.cannot_start", emsg, ep.getlog())

      worker.ready.addCallbacks(on_ready_success, on_ready_error)


      def on_exit_success(res):
         del self._workers[worker.id]

      def on_exit_error(err):
         del self._workers[worker.id]

      worker.exit.addCallbacks(on_exit_success, on_exit_error)


      ## create a transport factory for talking WAMP to the native worker
      ##
      transport_factory = create_guest_worker_client_factory(config, worker.ready, worker.exit)
      transport_factory.noisy = False
      self._workers[id].factory = transport_factory

      ## now (immediately before actually forking) signal the starting of the worker
      ##
      starting_info = {
         'id': id,
         'status': worker.status,
         'created': utcstr(worker.created),
         'who': worker.who
      }

      ## the caller gets a progressive result ..
      if details.progress:
         details.progress(starting_info)

      ## .. while all others get an event
      self.publish(starting_topic, starting_info, options = PublishOptions(exclude = [details.caller]))

      ## now actually fork the worker ..
      ##
      if True or self.debug:
         log.msg("Starting {} with ID '{}' using command line '{}' ..".format(worker_logname, id, ' '.join(args)))
      else:
         log.msg("Starting {} with ID '{}' ..".format(worker_logname, id))

      d = ep.connect(transport_factory)


      def on_connect_success(proto):

         ## this seems to be called immediately when the child process
         ## has been forked. even if it then immediately fails because
         ## e.g. the executable doesn't even exist. in other words,
         ## I'm not sure under what conditions the deferred will errback ..

         pid = proto.transport.pid
         if self.debug:
            log.msg("Guest worker process connected with PID {}".format(pid))

         worker.pid = pid

         ## proto is an instance of GuestWorkerClientProtocol
         worker.proto = proto

         worker.status = 'connected'
         worker.connected = datetime.utcnow()


      def on_connect_error(err):

         ## not sure when this errback is triggered at all ..
         if self.debug:
            log.msg("ERROR: Connecting forked guest worker failed - {}".format(err))

         ## in any case, forward the error ..
         worker.ready.errback(err)

      d.addCallbacks(on_connect_success, on_connect_error)

      return worker.ready



   def stop_guest(self, id, kill = False, details = None):
      """
      Stops a currently running guest worker.

      :param id: The ID of the guest worker to stop.
      :type id: str
      """
      if self.debug:
         log.msg("NodeControllerSession.stop_guest", id, kill)

      if id not in self._workers or self._workers[id].worker_type != 'guest':
         emsg = "ERROR: no guest worker with ID '{}' currently running".format(id)
         raise ApplicationError('crossbar.error.worker_not_running', emsg)

      try:
         if kill:
            self._workers[id].proto.transport.signalProcess("KILL")
         else:
            self._workers[id].proto.transport.loseConnection()
      except Exception as e:
         emsg = "ERROR: could not stop guest worker '{}' - {}".format(id, e)
         raise ApplicationError('crossbar.error.stop_worker_failed', emsg)
      else:
         del self._workers[id]



def create_process_env(options):
   """
   Create worker process environment dictionary.
   """
   penv = {}

   ## by default, a worker/guest process inherits
   ## complete environment
   inherit_all = True

   ## check/inherit parent process environment
   if 'env' in options and 'inherit' in options['env']:
      inherit = options['env']['inherit']
      if type(inherit) == bool:
         inherit_all = inherit
      elif type(inherit) == list:
         inherit_all = False
         for v in inherit:
            if v in os.environ:
               penv[v] = os.environ[v]

   if inherit_all:
      ## must do deepcopy like this (os.environ is a "special" thing ..)
      for k, v in os.environ.items():
         penv[k] = v

   ## explicit environment vars from config
   if 'env' in options and 'vars' in options['env']:
      for k, v in options['env']['vars'].items():
         penv[k] = v

   return penv

########NEW FILE########
__FILENAME__ = template
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

__all__ = ['CONFIG_TEMPLATES']


import os


CONFIG_DEFAULT = """{
   "processes": [
      {
         "type": "worker",
         "modules": [
            {
               "type": "router",
               "realms": {
                  "realm1": {
                     "permissions": {
                        "anonymous": {
                           "create": true,
                           "join": true,
                           "access": {
                              "*": {
                                 "publish": true,
                                 "subscribe": true,
                                 "call": true,
                                 "register": true
                              }
                           }
                        }
                     }
                  }
               },
               "transports": [
                  {
                     "type": "web",
                     "endpoint": {
                        "type": "tcp",
                        "port": 8080
                     },
                     "paths": {
                        "/": {
                           "type": "static",
                           "directory": ".."
                        },
                        "ws": {
                           "type": "websocket",
                           "url": "ws://localhost:8080/ws"
                        }
                     }
                  }
               ]
            }
         ]
      }
   ]
}
"""

CONFIG_DEFAULT = """
{
   "controller": {
      "id": "node1"
   },
   "workers": [
      {
         "id": "router1",
         "type": "router",
         "realms": [
            {
               "id": "realm1",
               "name": "realm1",
               "roles": [
                  {
                     "id": "anonymous",
                     "permissions": [
                        {
                           "id": "perm1",
                           "uri": "*",
                           "publish": true,
                           "subscribe": true,
                           "call": true,
                           "register": true
                        }
                     ]
                  }
               ]
            }
         ],
         "transports": [
            {
               "id": "transport1",
               "type": "web",
               "endpoint": {
                  "type": "tcp",
                  "port": 8080
               },
               "paths": {
                  "/": {
                     "type": "static",
                     "directory": ".."
                  },
                  "ws": {
                     "type": "websocket"
                  }
               }
            }
         ]
      }
   ]
}
"""


CONFIG_DEMOS = """{
   "processes": [
      {
         "type": "worker",
         "options": {
            "pythonpath": [".."]
         },
         "modules": [
            {
               "type": "router",
               "realms": {
                  "realm1": {
                     "permissions": {
                        "anonymous": {
                           "create": true,
                           "join": true,
                           "access": {
                              "*": {
                                 "publish": true,
                                 "subscribe": true,
                                 "call": true,
                                 "register": true
                              }
                           }
                        }
                     },
                     "components": [
                        {
                           "type": "class",
                           "name": "crossbardemo.basic.TimeService"
                        },
                        {
                           "type": "class",
                           "name": "crossbardemo.basic.TickService"
                        },
                        {
                           "type": "class",
                           "name": "crossbardemo.basic.MathService"
                        }
                     ]
                  }
               },
               "transports": [
                  {
                     "type": "web",
                     "endpoint": {
                        "type": "tcp",
                        "port": 8080
                     },
                     "paths": {
                        "/": {
                           "type": "static",
                           "module": "crossbardemo",
                           "resource": "web"
                        },
                        "ws": {
                           "type": "websocket",
                           "url": "ws://localhost:8080/ws"
                        }
                     }
                  }
               ]
            }
         ]
      }
   ]
}
"""



CONFIG_TESTEE = """{
   "processes": [
      {
         "type": "worker",
         "modules": [
            {
               "type": "router",
               "realms": {
                  "realm1": {
                     "permissions": {
                        "anonymous": {
                           "create": true,
                           "join": true,
                           "access": {
                              "*": {
                                 "publish": true,
                                 "subscribe": true,
                                 "call": true,
                                 "register": true
                              }
                           }
                        }
                     }
                  }
               },
               "transports": [
                  {
                     "type": "websocket.testee",
                     "endpoint": {
                        "type": "tcp",
                        "port": 9001
                     },
                     "url": "ws://localhost:9001",
                     "options": {
                        "compression": {
                           "deflate": {
                           }
                        }
                     }
                  }
               ]
            }
         ]
      }
   ]
}
"""



CONFIG_TEMPLATES = {
   "default": {
      "help": "A minimal WAMP router",
      "config": CONFIG_DEFAULT,
   },
   "hello:python": {
      "help": "A Python WAMP application with a WAMP router",
      "config": CONFIG_DEFAULT,
      "basedir": "templates/python",
      "params": {
         "node_id": "node1",
         "realm_id": "realm1",
         "appname": "hello"
      }
   }
   #"demos": CONFIG_DEMOS,
   #"testee": CONFIG_TESTEE,
}


def print_templates_help():
   print("\nAvailable Crossbar.io node templates:\n")
   for t in CONFIG_TEMPLATES:
      print("  {} {}".format(t.ljust(20, ' '), CONFIG_TEMPLATES[t]['help']))
   print("")



import jinja2
import pkg_resources

   #    templates_dir = os.path.abspath(pkg_resources.resource_filename("crossbar", "web/templates"))
   #    if self.debug:
   #       log.msg("Using Web templates from {}".format(templates_dir))
   #    self._templates = jinja2.Environment(loader = jinja2.FileSystemLoader(templates_dir))

   #    self._page = templates.get_template('cb_web_404.html')
   #    self._directory = directory

   # def render_GET(self, request):
   #    s = self._page.render(cbVersion = crossbar.__version__,
   #                          directory = self._directory)


class Templates:

   def __init__(self):
      self._templates = CONFIG_TEMPLATES

   def __contains__(self, template):
      return template in self._templates

   def init(self, cbdir, template, params = None, dryrun = False):
      template = self._templates[template]
      basedir = os.path.abspath(pkg_resources.resource_filename("crossbar", template['basedir']))

      appdir = os.path.abspath(os.path.join(cbdir, '..'))

      jinja_env = jinja2.Environment(loader = jinja2.FileSystemLoader(basedir),
         keep_trailing_newline = True)

      _params = template['params'].copy()
      if params:
         _params.update(params)

      created = []
      try:
         for root, dirs, files in os.walk(basedir):
            for d in dirs:
               reldir = os.path.relpath(os.path.join(root, d), basedir)
               reldir = reldir.replace('appname', _params['appname'])
               create_dir_path = os.path.join(appdir, reldir)

               print("Creating directory {}".format(create_dir_path))
               if not dryrun:
                  os.mkdir(create_dir_path)
               created.append(('dir', create_dir_path))

            for f in files:
               ## FIXME
               if not f.endswith(".pyc"):
                  src_file = os.path.join(root, f)
                  src_file_rel_path = os.path.relpath(src_file, basedir)
                  reldir = os.path.relpath(root, basedir)
                  reldir = reldir.replace('appname', _params['appname'])
                  dst_dir_path = os.path.join(appdir, reldir)
                  f = f.replace('appname', _params['appname'])
                  dst_file = os.path.abspath(os.path.join(dst_dir_path, f))

                  print("Creating file      {}".format(dst_file))
                  if not dryrun:
                     with open(dst_file, 'wb') as dst_file_fd:
                        page = jinja_env.get_template(src_file_rel_path)
                        contents = page.render(**_params)
                        dst_file_fd.write(contents)

                  created.append(('file', dst_file))

         # force exception to test rollback
         #a = 1/0

      except Exception as e:
         print("Error encountered - rolling back")
         for ptype, path in reversed(created):
            if ptype == 'file':
               try:
                  print("Removing file {}".format(path))
                  if not dryrun:
                     os.remove(path)
               except:
                  print("Warning: could not remove file {}".format(path))
            elif ptype == 'dir':
               try:
                  print("Removing directory {}".format(path))
                  if not dryrun:
                     os.rmdir(path)
               except:
                  print("Warning: could not remove directory {}".format(path))
            else:
               raise Exception("logic error")
         raise e

      return

      with open(os.path.join(cbdir, 'config.json'), 'wb') as outfile:
         outfile.write(config)
      print("Node configuration created from template '{}'".format(template))

########NEW FILE########
__FILENAME__ = types
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import


from datetime import datetime
from collections import deque

from twisted.python import log
from twisted.internet.defer import Deferred

from autobahn.util import utcnow



class WorkerProcess:
   """
   Internal run-time representation of a worker process.
   """

   TYPE = 'worker'
   LOGNAME = 'Worker'

   def __init__(self, controller, id, who, keeplog = None):
      """
      Ctor.

      :param controller: The node controller this worker was created by.
      :type controller: instance of NodeControllerSession
      :param id: The ID of the worker.
      :type id: str
      :param who: Who triggered creation of this worker.
      :type who: str
      :param keeplog: If not `None`, buffer log message received to be later
                      retrieved via getlog(). If `0`, keep infinite log internally.
                      If `> 0`, keep at most such many log entries in buffer.
      :type keeplog: int or None
      """
      self._controller = controller

      self.id = id
      self.who = who
      self.pid = None
      self.status = "starting"

      self.created = datetime.utcnow()
      self.connected = None
      self.started = None

      ## a buffered log for log messages coming from the worker
      ## native workers will send log messages on stderr, while
      ## guest worker may use stdout/stderr
      self._keeplog = keeplog
      if self._keeplog is not None:
         self._log = deque()
      else:
         self._log = None

      self._log_fds = [2]
      self._log_lineno = 0
      self._log_topic = 'crossbar.node.{}.worker.{}.on_log'.format(self._controller._node_id, self.id)

      ## A deferred that resolves when the worker is ready.
      self.ready = Deferred()

      ## A deferred that resolves when the worker has exited.
      self.exit = Deferred()


   def log(self, childFD, data):
      """
      FIXME: line buffering
      """
      assert(childFD in self._log_fds)

      for msg in data.split('\n'):
         msg = msg.strip()
         if msg != "":

            ## log entry used for buffered worker log and/or worker log events
            ##
            if self._log is not None or self._log_topic:
               log_entry = (self._log_lineno, utcnow(), msg)

            ## maintain buffered worker log
            ##
            if self._log is not None:
               self._log_lineno += 1
               self._log.append(log_entry)
               if self._keeplog > 0 and len(self._log) > self._keeplog:
                  self._log.popleft()

            ## publish worker log event
            ##
            if self._log_topic:
               self._controller.publish(self._log_topic, log_entry)

            ## log to controller
            ##
            log.msg(msg, system = "{:<10} {:>6}".format(self.LOGNAME, self.pid), override_system = True)


   def getlog(self, limit = None):
      """
      Get buffered worker log.

      :param limit: Optionally, limit the amount of log entries returned
         to the last N entries.
      :type limit: None or int

      :returns: list -- Buffered log.
      """
      if self._log:
         if limit and len(self._log) > limit:
            return list(self._log)[len(self._log) - limit:]
         else:
            return list(self._log)
      else:
         return []




class NativeWorkerProcess(WorkerProcess):
   """
   Internal run-time representation of a native worker (router or
   container currently) process.
   """

   TYPE = 'native'
   LOGNAME = 'Native'

   def __init__(self, controller, id, who, keeplog = None):
      """
      Ctor.

      :param controller: The node controller this worker was created by.
      :type controller: instance of NodeControllerSession
      :param id: The ID of the worker.
      :type id: str
      :param who: Who triggered creation of this worker.
      :type who: str
      """
      WorkerProcess.__init__(self, controller, id, who, keeplog)

      self.factory = None
      self.proto = None



class RouterWorkerProcess(NativeWorkerProcess):
   """
   Internal run-time representation of a router worker process.
   """

   TYPE = 'router'
   LOGNAME = 'Router'



class ContainerWorkerProcess(NativeWorkerProcess):
   """
   Internal run-time representation of a container worker process.
   """

   TYPE = 'container'
   LOGNAME = 'Container'



class GuestWorkerProcess(WorkerProcess):
   """
   Internal run-time representation of a guest worker process.
   """

   TYPE = 'guest'
   LOGNAME = 'Guest'

   def __init__(self, controller, id, who, keeplog = None):
      """
      Ctor.

      :param controller: The node controller this worker was created by.
      :type controller: instance of NodeControllerSession
      :param id: The ID of the worker.
      :type id: str
      :param who: Who triggered creation of this worker.
      :type who: str
      """
      WorkerProcess.__init__(self, controller, id, who, keeplog)

      self._log_fds = [1, 2]
      self.proto = None

########NEW FILE########
__FILENAME__ = protocol
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['CrossbarWampWebSocketServerFactory',
           'CrossbarWampRawSocketServerFactory']

import datetime

from twisted.python import log
from autobahn.twisted.websocket import WampWebSocketServerProtocol, \
                                       WampWebSocketServerFactory, \
                                       WampWebSocketClientProtocol, \
                                       WampWebSocketClientFactory

from autobahn.twisted.rawsocket import WampRawSocketServerProtocol, \
                                       WampRawSocketServerFactory, \
                                       WampRawSocketClientProtocol, \
                                       WampRawSocketClientFactory

from twisted.internet.defer import Deferred

import json
from six.moves import urllib
from six.moves import http_cookies

import os
import sqlite3

try:
   from twisted.enterprise import adbapi
   _HAS_ADBAPI = True
except ImportError:
   ## Twisted hasn't ported this to Python 3 yet
   _HAS_ADBAPI = False



from autobahn import util
from autobahn.websocket import http
from autobahn.websocket.compress import *

from autobahn.wamp import types
from autobahn.wamp import message
from autobahn.wamp.router import RouterFactory
from autobahn.twisted.wamp import RouterSession, RouterSessionFactory

import crossbar



def set_websocket_options(factory, options):
   """
   Set WebSocket options on a WebSocket or WAMP-WebSocket factory.

   :param factory: The WebSocket or WAMP-WebSocket factory to set options on.
   :type factory:  Instance of :class:`autobahn.twisted.websocket.WampWebSocketServerFactory`
                   or :class:`autobahn.twisted.websocket.WebSocketServerFactory`.
   :param options: Options from Crossbar.io transport configuration.
   :type options: dict
   """
   c = options

   versions = []
   if c.get("enable_hixie76", True):
      versions.append(0)
   if c.get("enable_hybi10", True):
      versions.append(8)
   if c.get("enable_rfc6455", True):
      versions.append(13)

   ## FIXME: enforce!!
   ##
   #self.connectionCap = c.get("max_connections")

   ## convert to seconds
   ##
   openHandshakeTimeout = float(c.get("open_handshake_timeout", 0))
   if openHandshakeTimeout:
      openHandshakeTimeout = openHandshakeTimeout / 1000.

   closeHandshakeTimeout = float(c.get("close_handshake_timeout", 0))
   if closeHandshakeTimeout:
      closeHandshakeTimeout = closeHandshakeTimeout / 1000.

   factory.setProtocolOptions(versions = versions,
                              allowHixie76 = c.get("enable_hixie76", True),
                              webStatus = c.get("enable_webstatus", True),
                              utf8validateIncoming = c.get("validate_utf8", True),
                              maskServerFrames = c.get("mask_server_frames", False),
                              requireMaskedClientFrames = c.get("require_masked_client_frames", True),
                              applyMask = c.get("apply_mask", True),
                              maxFramePayloadSize = c.get("max_frame_size", 0),
                              maxMessagePayloadSize = c.get("max_message_size", 0),
                              autoFragmentSize = c.get("auto_fragment_size", 0),
                              failByDrop = c.get("fail_by_drop", False),
                              echoCloseCodeReason = c.get("echo_close_codereason", False),
                              openHandshakeTimeout = openHandshakeTimeout,
                              closeHandshakeTimeout = closeHandshakeTimeout,
                              tcpNoDelay = c.get("tcp_nodelay", True))

   ## WebSocket compression
   ##
   factory.setProtocolOptions(perMessageCompressionAccept = lambda _: None)
   if 'compression' in c:

      ## permessage-deflate
      ##
      if 'deflate' in c['compression']:

         log.msg("enabling WebSocket compression (permessage-deflate)")

         params = c['compression']['deflate']

         requestNoContextTakeover   = params.get('request_no_context_takeover', False)
         requestMaxWindowBits       = params.get('request_max_window_bits', 0)
         noContextTakeover          = params.get('no_context_takeover', None)
         windowBits                 = params.get('max_window_bits', None)
         memLevel                   = params.get('memory_level', None)

         def accept(offers):
            for offer in offers:
               if isinstance(offer, PerMessageDeflateOffer):
                  if (requestMaxWindowBits == 0 or offer.acceptMaxWindowBits) and \
                     (not requestNoContextTakeover or offer.acceptNoContextTakeover):
                     return PerMessageDeflateOfferAccept(offer,
                                                         requestMaxWindowBits = requestMaxWindowBits,
                                                         requestNoContextTakeover = requestNoContextTakeover,
                                                         noContextTakeover = noContextTakeover,
                                                         windowBits = windowBits,
                                                         memLevel = memLevel)

         factory.setProtocolOptions(perMessageCompressionAccept = accept)



import traceback


class CrossbarWampWebSocketServerProtocol(WampWebSocketServerProtocol):

   ## authid -> cookie -> set(connection)

   def onConnect(self, request):

      if self.factory.debug_traffic:
         from twisted.internet import reactor

         def print_traffic():
            print("Traffic {}: {} / {} in / out bytes - {} / {} in / out msgs".format(self.peer,
               self.trafficStats.incomingOctetsWireLevel,
               self.trafficStats.outgoingOctetsWireLevel,
               self.trafficStats.incomingWebSocketMessages,
               self.trafficStats.outgoingWebSocketMessages))
            reactor.callLater(1, print_traffic)

         print_traffic()

      protocol, headers = WampWebSocketServerProtocol.onConnect(self, request)

      try:

         self._origin = request.origin

         ## transport authentication
         ##
         self._authid = None
         self._authrole = None
         self._authmethod = None

         ## cookie tracking
         ##
         self._cbtid = None

         if self.factory._cookiestore:

            self._cbtid = self.factory._cookiestore.parse(request.headers)

            ## if no cookie is set, create a new one ..
            if self._cbtid is None:

               self._cbtid, headers['Set-Cookie'] = self.factory._cookiestore.create()

               if self.debug:
                  log.msg("Setting new cookie: %s" % headers['Set-Cookie'])

            else:
               if self.debug:
                  log.msg("Cookie already set")

            ## add this WebSocket connection to the set of connections
            ## associated with the same cookie
            self.factory._cookiestore.addProto(self._cbtid, self)

            if self.debug:
               log.msg("Cookie tracking enabled on WebSocket connection {}".format(self))

            ## if cookie-based authentication is enabled, set auth info from cookie store
            ##
            if 'auth' in self.factory._config and 'cookie' in self.factory._config['auth']:

               self._authid, self._authrole, self._authmethod = self.factory._cookiestore.getAuth(self._cbtid)

               if self.debug:
                  log.msg("Authenticated client via cookie", self._authid, self._authrole, self._authmethod)
            else:
               if self.debug:
                  log.msg("Cookie-based authentication disabled")

         else:

            if self.debug:
               log.msg("Cookie tracking disabled on WebSocket connection {}".format(self))

         ## accept the WebSocket connection, speaking subprotocol `protocol`
         ## and setting HTTP headers `headers`
         return (protocol, headers)

      except Exception as e:
         traceback.print_exc()


   def sendServerStatus(self, redirectUrl = None, redirectAfter = 0):
      """
      Used to send out server status/version upon receiving a HTTP/GET without
      upgrade to WebSocket header (and option serverStatus is True).
      """
      try:
         page = self.factory._templates.get_template('cb_ws_status.html')
         self.sendHtml(page.render(redirectUrl = redirectUrl,
                                   redirectAfter = redirectAfter,
                                   cbVersion = crossbar.__version__,
                                   wsUri = self.factory.url,
                                   peer = self.peer,
                                   workerPid = os.getpid()))
      except Exception as e:         
         log.msg("Error rendering WebSocket status page template: %s" % e)


   def onDisconnect(self):
      ## remove this WebSocket connection from the set of connections
      ## associated with the same cookie
      if self._cbtid:
         self.factory._cookiestore.dropProto(self._cbtid, self)





class CookieStore:
   """
   A cookie store.
   """

   def __init__(self, config, debug = False):
      """
      Ctor.

      :param config: The cookie configuration.
      :type config: dict
      """
      self.debug = debug
      if self.debug:
         log.msg("CookieStore.__init__()", config)

      self._config = config      
      self._cookie_id_field = config.get('name', 'cbtid')
      self._cookie_id_field_length = int(config.get('length', 24))
      self._cookie_max_age = int(config.get('max_age', 86400 * 30 * 12))

      self._cookies = {}


   def parse(self, headers):
      """
      Parse HTTP header for cookie. If cookie is found, return cookie ID,
      else return None.
      """
      if self.debug:
         log.msg("CookieStore.parse()", headers)

      ## see if there already is a cookie set ..
      if 'cookie' in headers:
         try:
            cookie = http_cookies.SimpleCookie()
            cookie.load(str(headers['cookie']))
         except http_cookies.CookieError:
            pass
         else:
            if self._cookie_id_field in cookie:
               id = cookie[self._cookie_id_field].value
               if id in self._cookies:
                  return id
      return None


   def create(self):
      """
      Create a new cookie, returning the cookie ID and cookie header value.
      """
      if self.debug:
         log.msg("CookieStore.create()")

      ## http://tools.ietf.org/html/rfc6265#page-20
      ## 0: delete cookie
      ## -1: preserve cookie until browser is closed

      id = util.newid(self._cookie_id_field_length)

      cbtData = {'created': util.utcnow(),
                 'authid': None,
                 'authrole': None,
                 'authmethod': None,
                 'max_age': self._cookie_max_age,
                 'connections': set()}

      self._cookies[id] = cbtData

      ## do NOT add the "secure" cookie attribute! "secure" refers to the
      ## scheme of the Web page that triggered the WS, not WS itself!!
      ##
      return id, '%s=%s;max-age=%d' % (self._cookie_id_field, id, cbtData['max_age'])


   def exists(self, id):
      """
      Check if cookie with given ID exists.
      """
      if self.debug:
         log.msg("CookieStore.exists()", id)

      return id in self._cookies


   def getAuth(self, id):
      """
      Return `(authid, authrole, authmethod)` triple given cookie ID.
      """
      if self.debug:
         log.msg("CookieStore.getAuth()", id)

      if id in self._cookies:
         c = self._cookies[id]
         return c['authid'], c['authrole'], c['authmethod']
      else:
         return None, None, None


   def setAuth(self, id, authid, authrole, authmethod):
      """
      Set `(authid, authrole, authmethod)` triple for given cookie ID.
      """
      if id in self._cookies:
         c = self._cookies[id]
         c['authid'] = authid
         c['authrole'] = authrole
         c['authmethod'] = authmethod


   def addProto(self, id, proto):
      """
      Add given WebSocket connection to the set of connections associated
      with the cookie having the given ID. Return the new count of
      connections associated with the cookie.
      """
      if self.debug:
         log.msg("CookieStore.addProto()", id, proto)

      if id in self._cookies:
         self._cookies[id]['connections'].add(proto)
         return len(self._cookies[id]['connections'])
      else:
         return 0


   def dropProto(self, id, proto):
      """
      Remove given WebSocket connection from the set of connections associated
      with the cookie having the given ID. Return the new count of
      connections associated with the cookie.
      """
      if self.debug:
         log.msg("CookieStore.dropProto()", id, proto)

      ## remove this WebSocket connection from the set of connections
      ## associated with the same cookie
      if id in self._cookies:
         self._cookies[id]['connections'].discard(proto)
         return len(self._cookies[id]['connections'])
      else:
         return 0


   def getProtos(self, id):
      """
      Get all WebSocket connections currently associated with the cookie.
      """
      if id in self._cookies:
         return self._cookies[id]['connections']
      else:
         return []



if _HAS_ADBAPI:

   class PersistentCookieStore(CookieStore):
      """
      A persistent cookie store.
      """

      def __init__(self, dbfile, config, debug = False):
         CookieStore.__init__(self, config, debug)
         self._dbfile = dbfile

         ## initialize database and create database connection pool
         self._init_db()
         self._dbpool = adbapi.ConnectionPool('sqlite3', self._dbfile, check_same_thread = False)


      def _init_db(self):
         if not os.path.isfile(self._dbfile):

            db = sqlite3.connect(self._dbfile)
            cur = db.cursor()

            cur.execute("""
                        CREATE TABLE cookies (
                           id                TEXT     NOT NULL,
                           created           TEXT     NOT NULL,
                           max_age           INTEGER  NOT NULL,
                           authid            TEXT,
                           authrole          TEXT,
                           authmethod        TEXT,
                           PRIMARY KEY (id))
                        """)

            log.msg("Cookie DB created.")

         else:
            log.msg("Cookie DB already exists.")

            db = sqlite3.connect(self._dbfile)
            cur = db.cursor()

            cur.execute("SELECT id, created, max_age, authid, authrole, authmethod FROM cookies")
            n = 0
            for row in cur.fetchall():
               id = row[0]
               cbtData = {'created': row[1],
                          'max_age': row[2],
                          'authid': row[3],
                          'authrole': row[4],
                          'authmethod': row[5],
                          'connections': set()}
               self._cookies[id] = cbtData
               n += 1
            log.msg("Loaded {} cookies into cache.".format(n))


      def create(self):
         id, header = CookieStore.create(self)

         def run(txn):
            c = self._cookies[id]
            txn.execute("INSERT INTO cookies (id, created, max_age, authid, authrole, authmethod) VALUES (?, ?, ?, ?, ?, ?)",
               [id, c['created'], c['max_age'], c['authid'], c['authrole'], c['authmethod']])
            if self.debug:
               log.msg("Cookie {} stored".format(id))

         self._dbpool.runInteraction(run)

         return id, header


      def setAuth(self, id, authid, authrole, authmethod):
         CookieStore.setAuth(self, id, authid, authrole, authmethod)

         def run(txn):
            txn.execute("UPDATE cookies SET authid = ?, authrole = ?, authmethod = ? WHERE id = ?",
               [authid, authrole, authmethod, id])
            if self.debug:
               log.msg("Cookie {} updated".format(id))

         self._dbpool.runInteraction(run)




class CrossbarWampWebSocketServerFactory(WampWebSocketServerFactory):

   protocol = CrossbarWampWebSocketServerProtocol

   def __init__(self, factory, cbdir, config, templates):
      """
      Ctor.

      :param factory: WAMP session factory.
      :type factory: An instance of ..
      :param cbdir: The Crossbar.io node directory.
      :type cbdir: str
      :param config: Crossbar transport configuration.
      :type config: dict 
      """
      self.debug = config.get('debug', False)
      self.debug_traffic = config.get('debug_traffic', False)

      options = config.get('options', {})

      server = "Crossbar/{}".format(crossbar.__version__)
      externalPort = options.get('external_port', None)

      ## explicit list of WAMP serializers
      ##
      if 'serializers' in options:
         serializers = []
         sers = set(options['serializers'])

         if 'json' in sers:
            ## try JSON WAMP serializer
            try:
               from autobahn.wamp.serializer import JsonSerializer
               serializers.append(JsonSerializer())
            except ImportError:
               print("Warning: could not load WAMP-JSON serializer")
            else:
               sers.discard('json')

         if 'msgpack' in sers:
            ## try MsgPack WAMP serializer
            try:
               from autobahn.wamp.serializer import MsgPackSerializer
               serializers.append(MsgPackSerializer())
            except ImportError:
               print("Warning: could not load WAMP-MsgPack serializer")
            else:
               sers.discard('msgpack')

         if not serializers:
            raise Exception("no valid WAMP serializers specified")

         if len(sers) > 0:
            raise Exception("invalid WAMP serializers specified: {}".format(sers))

      else:
         serializers = None

      WampWebSocketServerFactory.__init__(self,
                                          factory,
                                          serializers = serializers,
                                          url = config.get('url', None),
                                          server = server,
                                          externalPort = externalPort,
                                          debug = self.debug,
                                          debug_wamp = self.debug)

      ## Crossbar.io node directory
      self._cbdir = cbdir

      ## transport configuration
      self._config = config

      ## Jinja2 templates for 404 etc
      self._templates = templates

      ## cookie tracking
      if 'cookie' in config:
         if 'database' in config['cookie'] and _HAS_ADBAPI:
            dbfile = os.path.abspath(os.path.join(self._cbdir, config['cookie']['database']))
            self._cookiestore = PersistentCookieStore(dbfile, config['cookie'])
            log.msg("Persistent cookie store active: {}".format(dbfile))
         else:
            self._cookiestore = CookieStore(config['cookie'])
            log.msg("Transient cookie store active.")
      else:
         self._cookiestore = None

      ## set WebSocket options
      set_websocket_options(self, options)



class CrossbarWampRawSocketServerProtocol(WampRawSocketServerProtocol):

   def connectionMade(self):
      WampRawSocketServerProtocol.connectionMade(self)
      ## transport authentication
      ##
      self._authid = None
      self._authrole = None
      self._authmethod = None



class CrossbarWampRawSocketServerFactory(WampRawSocketServerFactory):

   protocol = CrossbarWampRawSocketServerProtocol

   def __init__(self, factory, config):

      ## transport configuration
      self._config = config

      ## WAMP serializer
      ##
      serid = config.get('serializer', 'msgpack')

      if serid == 'json':
         ## try JSON WAMP serializer
         try:
            from autobahn.wamp.serializer import JsonSerializer
            serializer = JsonSerializer()
         except ImportError:
            raise Exception("could not load WAMP-JSON serializer")

      elif serid == 'msgpack':
         ## try MsgPack WAMP serializer
         try:
            from autobahn.wamp.serializer import MsgPackSerializer
            serializer = MsgPackSerializer()
            serializer._serializer.ENABLE_V5 = False ## FIXME
         except ImportError:
            raise Exception("could not load WAMP-MsgPack serializer")

      else:
         raise Exception("invalid WAMP serializer '{}'".format(serid))

      WampRawSocketServerFactory.__init__(self, factory, serializer)




class CrossbarWampRawSocketClientProtocol(WampRawSocketClientProtocol):
   """
   """



class CrossbarWampRawSocketClientFactory(WampRawSocketClientFactory):
   """
   """
   protocol = CrossbarWampRawSocketClientProtocol

   def __init__(self, factory, config):

      ## transport configuration
      self._config = config

      ## WAMP serializer
      ##
      serid = config.get('serializer', 'msgpack')

      if serid == 'json':
         ## try JSON WAMP serializer
         try:
            from autobahn.wamp.serializer import JsonSerializer
            serializer = JsonSerializer()
         except ImportError:
            raise Exception("could not load WAMP-JSON serializer")

      elif serid == 'msgpack':
         ## try MsgPack WAMP serializer
         try:
            from autobahn.wamp.serializer import MsgPackSerializer
            serializer = MsgPackSerializer()
            serializer._serializer.ENABLE_V5 = False ## FIXME
         except ImportError:
            raise Exception("could not load WAMP-MsgPack serializer")

      else:
         raise Exception("invalid WAMP serializer '{}'".format(serid))

      WampRawSocketClientFactory.__init__(self, factory, serializer)




class CrossbarWampWebSocketClientProtocol(WampWebSocketClientProtocol):
   """
   """



class CrossbarWampWebSocketClientFactory(WampWebSocketClientFactory):
   """
   """
   protocol = CrossbarWampWebSocketClientProtocol

   def __init2__(self, factory, config):

      ## transport configuration
      self._config = config

      WampWebSocketClientFactory.__init__(self, config)

      self.setProtocolOptions(failByDrop = False)



   def buildProtocol(self, addr):
      self._proto = WampWebSocketClientFactory.buildProtocol(self, addr)
      return self._proto


########NEW FILE########
__FILENAME__ = session
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['CrossbarRouterSessionFactory',
           'CrossbarRouterFactory']

import datetime

from twisted.python import log
from twisted.internet.defer import Deferred

import json

from six.moves import urllib

from autobahn import util
from autobahn.websocket import http
from autobahn.websocket.compress import *

from autobahn.wamp import types
from autobahn.wamp import message
from autobahn.wamp.router import RouterFactory
from autobahn.twisted.wamp import RouterSession, RouterSessionFactory

import crossbar



class PendingAuth:
   pass



class PendingAuthPersona(PendingAuth):
   def __init__(self, provider, audience, role = None):
      self.provider = provider
      self.audience = audience
      self.role = role



class CrossbarRouterSession(RouterSession):
   """
   Router-side of (non-embedded) Crossbar.io WAMP sessions.
   """

   def onOpen(self, transport):
      RouterSession.onOpen(self, transport)

      if hasattr(self._transport.factory, '_config'):
         self._transport_config = self._transport.factory._config
      else:
         self._transport_config = {}

      self._pending_auth = None
      self._session_details = None


   def onHello(self, realm, details):

      if self._transport._authid is not None:
         ## already authenticated .. e.g. via cookie
         ##
         return types.Accept(authid = self._transport._authid,
                             authrole = self._transport._authrole,
                             authmethod = self._transport._authmethod)
      else:
         ## if authentication is enabled on the transport ..
         ##
         if "auth" in self._transport_config:

            ## iterate over authentication methods announced by client ..
            ##
            for authmethod in details.authmethods or ["anonymous"]:

               ## .. and if the configuration has an entry for the authmethod
               ## announced, process ..
               if authmethod in self._transport_config["auth"]:

                  ## Mozilla Persona
                  ##
                  if authmethod == "mozilla_persona":
                     cfg = self._transport_config['auth']['mozilla_persona']

                     audience = cfg.get('audience', self._transport._origin)
                     provider = cfg.get('provider', "https://verifier.login.persona.org/verify")

                     ## authrole mapping
                     ##
                     authrole = None
                     try:
                        if 'role' in cfg:
                           if cfg['role']['type'] == 'static':
                              authrole = cfg['role']['value']
                     except Exception as e:
                        log.msg("error processing 'role' part of 'auth' config: {}".format(e))

                     self._pending_auth = PendingAuthPersona(provider, audience, authrole)
                     return types.Challenge("mozilla-persona")

                  ## Anonymous
                  ##
                  elif authmethod == "anonymous":
                     cfg = self._transport_config['auth']['anonymous']

                     ## authrole mapping
                     ##
                     authrole = "anonymous"
                     try:
                        if 'role' in cfg:
                           if cfg['role']['type'] == 'static':
                              authrole = cfg['role']['value']
                     except Exception as e:
                        log.msg("error processing 'role' part of 'auth' config: {}".format(e))

                     ## authid generation
                     ##
                     if self._transport._cbtid:
                        ## set authid to cookie value
                        authid = self._transport._cbtid
                     else:
                        authid = util.newid(24)

                     self._transport._authid = authid
                     self._transport._authrole = authrole
                     self._transport._authmethod = "anonymous"

                     return types.Accept(authid = authid, authrole = authrole, authmethod = self._transport._authmethod)

                  elif authmethod == "cookie":
                     pass
                     # if self._transport._cbtid:
                     #    cookie = self._transport.factory._cookies[self._transport._cbtid]
                     #    authid = cookie['authid']
                     #    authrole = cookie['authrole']
                     #    authmethod = "cookie.{}".format(cookie['authmethod'])
                     #    return types.Accept(authid = authid, authrole = authrole, authmethod = authmethod)
                     # else:
                     #    return types.Deny()
                  else:
                     log.msg("unknown authmethod '{}'".format(authmethod))


            ## if authentication is configured, by default, deny.
            ##
            return types.Deny()
         else:
            ## FIXME: if not "auth" key present, allow anyone
            return types.Accept(authid = "anonymous", authrole = "anonymous", authmethod = "anonymous")


   def onAuthenticate(self, signature, extra):

      if isinstance(self._pending_auth, PendingAuthPersona):

         dres = Deferred()

         ## The client did it's Mozilla Persona authentication thing
         ## and now wants to verify the authentication and login.
         assertion = signature
         audience = str(self._pending_auth.audience) # eg "http://192.168.1.130:8080/"
         provider = str(self._pending_auth.provider) # eg "https://verifier.login.persona.org/verify"

         ## To verify the authentication, we need to send a HTTP/POST
         ## to Mozilla Persona. When successful, Persona will send us
         ## back something like:

         # {
         #    "audience": "http://192.168.1.130:8080/",
         #    "expires": 1393681951257,
         #    "issuer": "gmail.login.persona.org",
         #    "email": "tobias.oberstein@gmail.com",
         #    "status": "okay"
         # }

         headers = {'Content-Type': 'application/x-www-form-urlencoded'}
         body = urllib.urlencode({'audience': audience, 'assertion': assertion})

         from twisted.web.client import getPage
         d = getPage(url = provider,
                     method = 'POST',
                     postdata = body,
                     headers = headers)

         log.msg("Authentication request sent.")

         def done(res):
            res = json.loads(res)
            try:
               if res['status'] == 'okay':

                  ## awesome: Mozilla Persona successfully authenticated the user
                  self._transport._authid = res['email']
                  self._transport._authrole = self._pending_auth.role
                  self._transport._authmethod = 'mozilla_persona'

                  log.msg("Authenticated user {} with role {}".format(self._transport._authid, self._transport._authrole))
                  dres.callback(types.Accept(authid = self._transport._authid, authrole = self._transport._authrole, authmethod = self._transport._authmethod))

                  ## remember the user's auth info (this marks the cookie as authenticated)
                  if self._transport._cbtid and self._transport.factory._cookiestore:
                     cs = self._transport.factory._cookiestore
                     cs.setAuth(self._transport._cbtid, self._transport._authid, self._transport._authrole, self._transport._authmethod)

                     ## kick all sessions using same cookie (but not _this_ connection)
                     if True:
                        for proto in cs.getProtos(self._transport._cbtid):
                           if proto and proto != self._transport:
                              try:
                                 proto.close()
                              except Exception as e:
                                 pass
               else:
                  log.msg("Authentication failed!")
                  log.msg(res)
                  dres.callback(types.Deny(reason = "wamp.error.authorization_failed", message = res.get("reason", None)))
            except Exception as e:
               log.msg("internal error during authentication verification: {}".format(e))
               dres.callback(types.Deny(reason = "wamp.error.internal_error", message = str(e)))

         def error(err):
            log.msg("Authentication request failed: {}".format(err.value))
            dres.callback(types.Deny(reason = "wamp.error.authorization_request_failed", message = str(err.value)))

         d.addCallbacks(done, error)

         return dres

      else:

         log.msg("don't know how to authenticate")

         return types.Deny()


   def onJoin(self, details):

      self._session_details = {
         'authid': details.authid,
         'authrole': details.authrole,
         'authmethod': details.authmethod,
         'realm': details.realm,
         'session': details.session
      }

      ## FIXME: dispatch metaevent
      #self.publish('wamp.metaevent.session.on_join', evt)

      msg = message.Publish(0, u'wamp.metaevent.session.on_join', [self._session_details])
      self._router.process(self, msg)


   def onLeave(self, details):

      ## FIXME: dispatch metaevent
      #self.publish('wamp.metaevent.session.on_join', evt)

      msg = message.Publish(0, u'wamp.metaevent.session.on_leave', [self._session_details])
      self._router.process(self, msg)
      self._session_details = None

      if details.reason == u"wamp.close.logout":
         if self._transport._cbtid and self._transport.factory._cookiestore:
            cs = self._transport.factory._cookiestore
            cs.setAuth(self._transport._cbtid, None, None, None)
            for proto in cs.getProtos(self._transport._cbtid):
               proto.sendClose()



class CrossbarRouterSessionFactory(RouterSessionFactory):
   """
   Factory creating the router side of (non-embedded) Crossbar.io WAMP sessions.
   This is the session factory that will given to router transports.
   """
   session = CrossbarRouterSession



class CrossbarRouterFactory(RouterFactory):
   def __init__(self, options = None, debug = False):
      options = types.RouterOptions(uri_check = types.RouterOptions.URI_CHECK_LOOSE)
      RouterFactory.__init__(self, options, debug)



# from autobahn.wamp.interfaces import IRouter, IRouterFactory


# class CrossbarRouterFactory:
#    """
#    Basic WAMP Router factory.

#    This class implements :class:`autobahn.wamp.interfaces.IRouterFactory`.
#    """

#    def __init__(self, options = None, debug = False):
#       """
#       Ctor.

#       :param options: Default router options.
#       :type options: Instance of :class:`autobahn.wamp.types.RouterOptions`.      
#       """
#       self._routers = {}
#       self.debug = debug
#       self._options = options or types.RouterOptions()


#    def get(self, realm):
#       """
#       Implements :func:`autobahn.wamp.interfaces.IRouterFactory.get`
#       """
#       if not realm in self._routers:
#          self._routers[realm] = Router(self, realm, self._options)
#          if self.debug:
#             print("Router created for realm '{}'".format(realm))
#       return self._routers[realm]


#    def onLastDetach(self, router):
#       assert(router.realm in self._routers)
#       del self._routers[router.realm]
#       if self.debug:
#          print("Router destroyed for realm '{}'".format(router.realm))



# IRouterFactory.register(CrossbarRouterFactory)

########NEW FILE########
__FILENAME__ = appname
from autobahn.twisted.wamp import ApplicationSession

class AppSession(ApplicationSession):

   def onJoin(self, details):

      def hello():
         return "Hello from Python!"

      self.register(hello, 'com.{{ appname }}.hello')

########NEW FILE########
__FILENAME__ = endpoint
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from __future__ import absolute_import

__all__ = ['create_listening_endpoint_from_config',
           'create_listening_port_from_config',
           'create_connecting_endpoint_from_config',
           'create_connecting_port_from_config']


import os, sys

from twisted.internet import defer
from twisted.internet.endpoints import TCP4ServerEndpoint, \
                                       TCP6ServerEndpoint, \
                                       TCP4ClientEndpoint, \
                                       TCP6ClientEndpoint, \
                                       UNIXServerEndpoint, \
                                       UNIXClientEndpoint

try:
   from OpenSSL import crypto, SSL
   from twisted.internet.endpoints import SSL4ServerEndpoint, \
                                          SSL4ClientEndpoint
except ImportError:
   _HAS_TLS = False
else:
   _HAS_TLS = True
   from crossbar.twisted.tlsctx import TlsServerContextFactory, \
                                       TlsClientContextFactory


from crossbar.twisted.sharedport import SharedPort




def create_listening_endpoint_from_config(config, cbdir, reactor):
   """
   Create a Twisted stream server endpoint from a Crossbar.io transport configuration.

   See: https://twistedmatrix.com/documents/current/api/twisted.internet.interfaces.IStreamServerEndpoint.html

   :param config: The transport configuration.
   :type config: dict
   :param cbdir: Crossbar.io node directory (we need this for TLS key/certificates).
   :type cbdir: str
   :param reactor: The reactor to use for endpoint creation.
   :type reactor: obj

   :returns obj -- An instance implementing IStreamServerEndpoint
   """
   endpoint = None


   ## a TCP endpoint
   ##
   if config['type'] == 'tcp':

      ## the TCP protocol version (v4 or v6)
      ##
      version = int(config.get('version', 4))

      ## the listening port
      ##
      port = int(config['port'])

      ## the listening interface
      ##
      interface = str(config.get('interface', '').strip())

      ## the TCP accept queue depth
      ##
      backlog = int(config.get('backlog', 50))

      if 'tls' in config:
         
         if _HAS_TLS:
            key_filepath = os.path.abspath(os.path.join(cbdir, config['tls']['key']))
            cert_filepath = os.path.abspath(os.path.join(cbdir, config['tls']['certificate']))

            with open(key_filepath) as key_file:
               with open(cert_filepath) as cert_file:

                  if 'dhparam' in config['tls']:
                     dhparam_filepath = os.path.abspath(os.path.join(cbdir, config['tls']['dhparam']))
                  else:
                     dhparam_filepath = None

                  ## create a TLS context factory
                  ##
                  key = key_file.read()
                  cert = cert_file.read()
                  ciphers = config['tls'].get('ciphers', None)
                  ctx = TlsServerContextFactory(key, cert, ciphers = ciphers, dhParamFilename = dhparam_filepath)

            ## create a TLS server endpoint
            ##
            if version == 4:
               endpoint = SSL4ServerEndpoint(reactor,
                                                    port,
                                                    ctx,
                                                    backlog = backlog,
                                                    interface = interface)
            elif version == 6:
               raise Exception("TLS on IPv6 not implemented")
            else:
               raise Exception("invalid TCP protocol version {}".format(version))

         else:
            raise Exception("TLS transport requested, but TLS packages not available")
            
      else:
         ## create a non-TLS server endpoint
         ##
         if version == 4:
            endpoint = TCP4ServerEndpoint(reactor,
                                          port,
                                          backlog = backlog,
                                          interface = interface)
         elif version == 6:
            endpoint = TCP6ServerEndpoint(reactor,
                                          port,
                                          backlog = backlog,
                                          interface = interface)
         else:
            raise Exception("invalid TCP protocol version {}".format(version))


   ## a Unix Domain Socket endpoint
   ##
   elif config['type'] == 'unix':

      ## the accept queue depth
      ##
      backlog = int(config.get('backlog', 50))

      ## the path
      ##
      path = os.path.abspath(os.path.join(cbdir, config['path']))

      ## create the endpoint
      ##
      endpoint = UNIXServerEndpoint(reactor, path, backlog = backlog)

   else:
      raise Exception("invalid endpoint type '{}'".format(config['type']))

   return endpoint




def create_listening_port_from_config(config, factory, cbdir, reactor):
   """
   Create a Twisted listening port from a Crossbar.io transport configuration.

   See: https://twistedmatrix.com/documents/current/api/twisted.internet.interfaces.IListeningPort.html

   :param config: The transport configuration.
   :type config: dict
   :param factory: The transport factory to use (a provider of IProtocolFactory).
   :type factory: obj
   :param cbdir: Crossbar.io node directory (we need this for TLS key/certificates).
   :type cbdir: str
   :param reactor: The reactor to use for endpoint creation.
   :type reactor: obj

   :returns obj -- A Deferred that results in an IListeningPort or an CannotListenError
   """
   if config['type'] == 'tcp' and config.get('shared', False):

      ## the TCP protocol version (v4 or v6)
      ##
      version = int(config.get('version', 4))

      ## the listening port
      ##
      port = int(config['port'])

      ## the listening interface
      ##
      interface = str(config.get('interface', '').strip())

      ## the TCP accept queue depth
      ##
      backlog = int(config.get('backlog', 50))

      listening_port = SharedPort(port, factory, backlog, interface, reactor, shared = True)
      try:
         listening_port.startListening()
         return defer.succeed(listening_port)
      except Exception as e:
         return defer.fail(e)

   else:

      endpoint = create_listening_endpoint_from_config(config, cbdir, reactor)
      return endpoint.listen(factory)



def create_connecting_endpoint_from_config(config, cbdir, reactor):
   """
   Create a Twisted stream client endpoint from a Crossbar.io transport configuration.

   See: https://twistedmatrix.com/documents/current/api/twisted.internet.interfaces.IStreamClientEndpoint.html

   :param config: The transport configuration.
   :type config: dict
   :param cbdir: Crossbar.io node directory (we need this for Unix domain socket paths and TLS key/certificates).
   :type cbdir: str
   :param reactor: The reactor to use for endpoint creation.
   :type reactor: obj

   :returns obj -- An instance implementing IStreamClientEndpoint
   """
   endpoint = None

   ## a TCP endpoint
   ##
   if config['type'] == 'tcp':

      ## the TCP protocol version (v4 or v6)
      ##
      version = int(config.get('version', 4))

      ## the host to connect to
      ##
      host = str(config['host'])

      ## the port to connect to
      ##
      port = int(config['port'])

      ## connection timeout in seconds
      ##
      timeout = int(config.get('timeout', 10))

      if 'tls' in config:

         if _HAS_TLS:
            ctx = TlsClientContextFactory()

            ## create a TLS client endpoint
            ##
            if version == 4:
               endpoint = SSL4ClientEndpoint(reactor,
                                             host,
                                             port,
                                             ctx,
                                             timeout = timeout)
            elif version == 6:
               raise Exception("TLS on IPv6 not implemented")
            else:
               raise Exception("invalid TCP protocol version {}".format(version))

         else:
            raise Exception("TLS transport requested, but TLS packages not available")

      else:
         ## create a non-TLS client endpoint
         ##
         if version == 4:
            endpoint = TCP4ClientEndpoint(reactor,
                                          host,
                                          port,
                                          timeout = timeout)
         elif version == 6:
            endpoint = TCP6ClientEndpoint(reactor,
                                          host,
                                          port,
                                          timeout = timeout)
         else:
            raise Exception("invalid TCP protocol version {}".format(version))

   ## a Unix Domain Socket endpoint
   ##
   elif config['type'] == 'unix':

      ## the path
      ##
      path = os.path.abspath(cbdir, config['path'])

      ## connection timeout in seconds
      ##
      timeout = int(config.get('timeout', 10))

      ## create the endpoint
      ##
      endpoint = UNIXClientEndpoint(reactor, path, timeout = timeout)

   else:
      raise Exception("invalid endpoint type '{}'".format(config['type']))

   return endpoint



def create_connecting_port_from_config(config, factory, cbdir, reactor):
   """
   Create a Twisted connecting port from a Crossbar.io transport configuration.

   See: https://twistedmatrix.com/documents/current/api/twisted.internet.interfaces.IListeningPort.html

   :param config: The transport configuration.
   :type config: dict
   :param factory: The transport factory to use (a provider of IProtocolFactory).
   :type factory: obj
   :param cbdir: Crossbar.io node directory (we need this for Unix domain socket paths and TLS key/certificates).
   :type cbdir: str
   :param reactor: The reactor to use for endpoint creation.
   :type reactor: obj

   :returns obj -- A Deferred that results in an IProtocol upon successful connection otherwise a ConnectError
   """
   endpoint = create_connecting_endpoint_from_config(config, cbdir, reactor)
   return endpoint.connect(factory)

########NEW FILE########
__FILENAME__ = process
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import os
from collections import deque

from twisted.python import util
from twisted.python import log
from twisted.python.log import FileLogObserver, textFromEventDict

from twisted.internet.endpoints import _WrapIProtocol, ProcessEndpoint
from twisted.internet.address import _ProcessAddress
from twisted.internet import defer



class _WorkerWrapIProtocol(_WrapIProtocol):
   """
   Wraps an IProtocol into an IProcessProtocol which forwards data
   received on Worker._log_fds to WorkerProcess.log().
   """

   def childDataReceived(self, childFD, data):
      if childFD in self._worker._log_fds:
         self._worker.log(childFD, data)
      else:
         _WrapIProtocol.childDataReceived(self, childFD, data)



class WorkerProcessEndpoint(ProcessEndpoint):
   """
   A custom process endpoint for workers.

   :see: http://twistedmatrix.com/documents/current/api/twisted.internet.endpoints.ProcessEndpoint.html
   """

   def __init__(self, *args, **kwargs):
      """
      Ctor.

      :param worker: The worker this endpoint is being used for.
      :type worker: instance of WorkerProcess
      """
      self._worker = kwargs.pop('worker')
      ProcessEndpoint.__init__(self, *args, **kwargs)


   def connect(self, protocolFactory):
      """
      See base class.
      """
      proto = protocolFactory.buildProtocol(_ProcessAddress())
      try:
         wrapped = _WorkerWrapIProtocol(proto, self._executable, self._errFlag)
         wrapped._worker = self._worker
         self._spawnProcess(wrapped,
            self._executable, self._args, self._env, self._path, self._uid,
            self._gid, self._usePTY, self._childFDs)
      except:
         return defer.fail()
      else:
         return defer.succeed(proto)



class BareFormatFileLogObserver(FileLogObserver):
   """
   Log observer without any additional formatting (such as timestamps).
   """

   def emit(self, eventDict):
      text = textFromEventDict(eventDict)
      if text:
         util.untilConcludes(self.write, text + "\n")
         util.untilConcludes(self.flush)



class DefaultSystemFileLogObserver(FileLogObserver):
   """
   Log observer with default settable system.
   """

   def __init__(self, f, system = None, override = True):
      FileLogObserver.__init__(self, f)
      if system:
         self._system = system
      else:
         self._system = "Process {}".format(os.getpid())
      self._override = override


   def emit(self, eventDict):
      if 'system' in eventDict and 'override_system' in eventDict and eventDict['override_system']:
         pass
      else:
         if self._override or (not 'system' in eventDict) or eventDict['system'] == "-":
            eventDict['system'] = self._system
      FileLogObserver.emit(self, eventDict)

########NEW FILE########
__FILENAME__ = resource
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

import os
import json

from twisted.python import log
from twisted.web.resource import Resource, NoResource
from twisted.web import server


try:
   ## triggers module level reactor import
   ## https://twistedmatrix.com/trac/ticket/6849#comment:4  
   from twisted.web.static import File
   _HAS_STATIC = True
except ImportError:
   ## Twisted hasn't ported this to Python 3 yet
   _HAS_STATIC = False


try:
   ## trigers module level reactor import
   ## https://twistedmatrix.com/trac/ticket/6849#comment:5
   from twisted.web.twcgi import CGIScript, CGIProcessProtocol
   _HAS_CGI = True
except ImportError:
   ## Twisted hasn't ported this to Python 3 yet
   _HAS_CGI = False


import crossbar



class JsonResource(Resource):
   """
   Static Twisted Web resource that renders to a JSON document.
   """

   def __init__(self, value):
      Resource.__init__(self)
      self._data = json.dumps(value, sort_keys = True, indent = 3)

   def render_GET(self, request):
      request.setHeader('content-type', 'application/json; charset=UTF-8')
      return self._data



class Resource404(Resource):
   """
   Custom error page (404).
   """
   def __init__(self, templates, directory):
      Resource.__init__(self)
      self._page = templates.get_template('cb_web_404.html')
      self._directory = directory

   def render_GET(self, request):
      s = self._page.render(cbVersion = crossbar.__version__,
                            directory = self._directory)
      return s.encode('utf8')



class RedirectResource(Resource):

   isLeaf = True

   def __init__(self, redirect_url):
      Resource.__init__(self)
      self._redirect_url = redirect_url

   def render_GET(self, request):
      request.redirect(self._redirect_url)
      request.finish()
      return server.NOT_DONE_YET



if _HAS_STATIC:

   class FileNoListing(File):
      """
      A file hierarchy resource with directory listing disabled.
      """
      def directoryListing(self):
         return self.childNotFound



if _HAS_CGI:

   from twisted.python.filepath import FilePath

   class CgiScript(CGIScript):

      def __init__(self, filename, filter):
         CGIScript.__init__(self, filename)
         self.filter = filter

      def runProcess(self, env, request, qargs = []):
         p = CGIProcessProtocol(request)
         from twisted.internet import reactor
         reactor.spawnProcess(p, self.filter, [self.filter, self.filename], env, os.path.dirname(self.filename))


   class CgiDirectory(Resource, FilePath):

      cgiscript = CgiScript

      def __init__(self, pathname, filter, childNotFound = None):
         Resource.__init__(self)
         FilePath.__init__(self, pathname)
         self.filter = filter
         if childNotFound:
            self.childNotFound = childNotFound
         else:
            self.childNotFound = NoResource("CGI directories do not support directory listing.")

      def getChild(self, path, request):
         fnp = self.child(path)
         if not fnp.exists():
            return File.childNotFound
         elif fnp.isdir():
            return CgiDirectory(fnp.path, self.filter, self.childNotFound)
         else:
            return self.cgiscript(fnp.path, self.filter)
         return NoResource()

      def render(self, request):
         return self.childNotFound.render(request)

########NEW FILE########
__FILENAME__ = sharedport
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


# https://lwn.net/Articles/542629/
# http://twistedmatrix.com/documents/current/api/twisted.internet.interfaces.IReactorSocket.html
# http://stackoverflow.com/questions/14388706/socket-options-so-reuseaddr-and-so-reuseport-how-do-they-differ-do-they-mean-t
# http://www.freebsd.org/cgi/man.cgi?query=setsockopt&sektion=2
# "SO_REUSEPORT on FreeBSD doesn't load balance incoming connections."
# http://lists.freebsd.org/pipermail/freebsd-net/2013-July/036131.html
# https://github.com/kavu/go_reuseport
# http://freeprogrammersblog.vhex.net/post/linux-39-introdued-new-way-of-writing-socket-servers/2
# http://gitweb.dragonflybsd.org/dragonfly.git/commitdiff/740d1d9f7b7bf9c9c021abb8197718d7a2d441c9
# http://stackoverflow.com/questions/12542700/setsockopt-before-connect-for-reactor-connecttcp
# http://twistedmatrix.com/documents/current/api/twisted.internet.interfaces.IReactorSocket.html
# http://stackoverflow.com/questions/10077745/twistedweb-on-multicore-multiprocessor
# http://msdn.microsoft.com/de-de/library/windows/desktop/cc150667(v=vs.85).aspx
# http://freeprogrammersblog.vhex.net/post/linux-39-introduced-new-way-of-writing-socket-servers/2


import sys
import socket

from twisted.internet import fdesc
from twisted.python.runtime import platformType

## Flag indiciating support for creating shared sockets with in-kernel
## load-balancing (!). Note that while FreeBSD had SO_REUSEPORT for ages,
## it does NOT (currently) implement load-balancing. Linux >= 3.9 and
## DragonFly BSD does.
_HAS_SHARED_LOADBALANCED_SOCKET = False

import platform
if sys.platform.startswith('linux'):
   try:
      # get Linux kernel version, like: (3, 19)
      _LINUX_KERNEL_VERSION = tuple(platform.uname()[2].split('.')[:2])

      ## SO_REUSEPORT only supported for Linux kernels >= 3.9
      if _LINUX_KERNEL_VERSION[0] >= 3 and _LINUX_KERNEL_VERSION[1] >= 9:
         _HAS_SHARED_LOADBALANCED_SOCKET = True

         ## monkey patch missing constant if needed
         if not hasattr(socket, 'SO_REUSEPORT'):
            socket.SO_REUSEPORT = 15
   except:
      pass



def create_stream_socket(addressFamily, shared = False):
   """
   Create a new socket for use with Twisted's IReactor.adoptStreamPort.

   :param addressFamily: The socket address family.
   :type addressFamily: One of socket.AF_INET, socket.AF_INET6, socket.AF_UNIX
   :param shared: If `True`, request to create a shared, load-balanced socket.
                  When this feature is not available, throw an exception.
   :type shared: bool
   :returns obj -- A socket.
   """
   s = socket.socket(addressFamily, socket.SOCK_STREAM)
   s.setblocking(0)
   fdesc._setCloseOnExec(s.fileno())   

   if platformType == "posix" and sys.platform != "cygwin":
      s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

   if shared:
      if addressFamily not in [socket.AF_INET, socket.AF_INET6]:
         raise Exception("shared sockets are only supported for TCP")

      if _HAS_SHARED_LOADBALANCED_SOCKET:
         s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)
      else:
         raise Exception("shared sockets unsupported on this system")

   return s



from twisted.internet import tcp


class SharedPort(tcp.Port):
   """
   A custom port which sets socket options for sharing TCP ports between multiple processes.

   port = SharedPort(9000, factory, shared = True)
   port.startListening()
   """

   def __init__(self, port, factory, backlog = 50, interface = '', reactor = None, shared = False):

      if shared and not _HAS_SHARED_LOADBALANCED_SOCKET:
         raise Exception("shared sockets unsupported on this system")

      tcp.Port.__init__(self, port, factory, backlog, interface, reactor)

      self._shared = shared


   def createInternetSocket(self):
      s = tcp.Port.createInternetSocket(self)
      if self._shared:
         s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)
      return s

########NEW FILE########
__FILENAME__ = site
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import


def createHSTSRequestFactory(requestFactory, hstsMaxAge = 31536000):
   """
   Builds a request factory that sets HSTS (HTTP Strict Transport
   Security) headers, by wrapping another request factory.
   """

   def makeRequest(*a, **kw):
      request = requestFactory(*a, **kw)
      request.responseHeaders.setRawHeaders("Strict-Transport-Security",
         ["max-age={}".format(hstsMaxAge)])
      return request

   return makeRequest

########NEW FILE########
__FILENAME__ = tlsctx
###############################################################################
##
##  Copyright (C) 2011-2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import tempfile

from OpenSSL import crypto, SSL
from twisted.internet.ssl import DefaultOpenSSLContextFactory

from twisted.python import log

## Monkey patch missing constants
##
## See:
##   - https://bugs.launchpad.net/pyopenssl/+bug/1244201
##   - https://www.openssl.org/docs/ssl/SSL_CTX_set_options.html
##
SSL.OP_NO_COMPRESSION                         = 0x00020000
SSL.OP_CIPHER_SERVER_PREFERENCE               = 0x00400000
SSL.OP_SINGLE_ECDH_USE                        = 0x00080000
SSL.OP_SINGLE_DH_USE                          = 0x00100000
SSL.OP_DONT_INSERT_EMPTY_FRAGMENTS            = 0x00000800
SSL.OP_NO_TLSv1                               = 0x04000000
SSL.OP_NO_SESSION_RESUMPTION_ON_RENEGOTIATION = 0x00010000
SSL.OP_NO_TICKET                              = 0x00004000

SSL_DEFAULT_OPTIONS = SSL.OP_NO_SSLv2 | \
                      SSL.OP_NO_SSLv3 | \
                      SSL.OP_NO_COMPRESSION | \
                      SSL.OP_CIPHER_SERVER_PREFERENCE | \
                      SSL.OP_SINGLE_ECDH_USE | \
                      SSL.OP_SINGLE_DH_USE | \
                      SSL.OP_DONT_INSERT_EMPTY_FRAGMENTS | \
                      SSL.OP_NO_SESSION_RESUMPTION_ON_RENEGOTIATION | \
                      SSL.OP_NO_TICKET

## List of available ciphers
##
## Check via: https://www.ssllabs.com/ssltest/analyze.html?d=myserver.com
##
## http://www.openssl.org/docs/apps/ciphers.html#CIPHER_LIST_FORMAT
##

# http://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/
#SSL_DEFAULT_CIPHERS = 'ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AES:RSA+3DES:!ADH:!AECDH:!MD5:!DSS'

## We prefer to make every single cipher (6 in total) _explicit_ (to reduce chances either we or the pattern-matching
## language inside OpenSSL messes up) and drop support for Windows XP (we do WebSocket anyway).
## We don't use AES256 and SHA384, to reduce number of ciphers and since the additional security gain seems
## to worth the additional performance drain.
##
SSL_DEFAULT_CIPHERS = 'ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA'
#SSL_DEFAULT_CIPHERS = 'AES128-GCM-SHA256'

## Resorted to prioritize ECDH (hence favor performance over cipher strength) - no gain in practice, that doesn't
## change the effectively accepted cipher with common browsers/clients
#SSL_DEFAULT_CIPHERS = 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA'


## Named curves built into OpenSSL .. can be listed using:
##
##  openssl ecparam -list_curves
##
## Only some of those are exposed in pyOpenSSL
##
## http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf

## curves over binary fields
##
SSL.SN_X9_62_c2pnb163v1      = "c2pnb163v1"
SSL.NID_X9_62_c2pnb163v1     = 684

SSL.SN_X9_62_c2pnb163v2      = "c2pnb163v2"
SSL.NID_X9_62_c2pnb163v2     = 685

SSL.SN_X9_62_c2pnb163v3      = "c2pnb163v3"
SSL.NID_X9_62_c2pnb163v3     = 686

SSL.SN_X9_62_c2pnb176v1      = "c2pnb176v1"
SSL.NID_X9_62_c2pnb176v1     = 687

SSL.SN_X9_62_c2tnb191v1      = "c2tnb191v1"
SSL.NID_X9_62_c2tnb191v1     = 688

SSL.SN_X9_62_c2tnb191v2      = "c2tnb191v2"
SSL.NID_X9_62_c2tnb191v2     = 689

SSL.SN_X9_62_c2tnb191v3      = "c2tnb191v3"
SSL.NID_X9_62_c2tnb191v3     = 690

SSL.SN_X9_62_c2onb191v4      = "c2onb191v4"
SSL.NID_X9_62_c2onb191v4     = 691

SSL.SN_X9_62_c2onb191v5      = "c2onb191v5"
SSL.NID_X9_62_c2onb191v5     = 692

SSL.SN_X9_62_c2pnb208w1      = "c2pnb208w1"
SSL.NID_X9_62_c2pnb208w1     = 693

SSL.SN_X9_62_c2tnb239v1      = "c2tnb239v1"
SSL.NID_X9_62_c2tnb239v1     = 694

SSL.SN_X9_62_c2tnb239v2      = "c2tnb239v2"
SSL.NID_X9_62_c2tnb239v2     = 695

SSL.SN_X9_62_c2tnb239v3      = "c2tnb239v3"
SSL.NID_X9_62_c2tnb239v3     = 696

SSL.SN_X9_62_c2onb239v4      = "c2onb239v4"
SSL.NID_X9_62_c2onb239v4     = 697

SSL.SN_X9_62_c2onb239v5      = "c2onb239v5"
SSL.NID_X9_62_c2onb239v5     = 698

SSL.SN_X9_62_c2pnb272w1      = "c2pnb272w1"
SSL.NID_X9_62_c2pnb272w1     = 699

SSL.SN_X9_62_c2pnb304w1      = "c2pnb304w1"
SSL.NID_X9_62_c2pnb304w1     = 700

SSL.SN_X9_62_c2tnb359v1      = "c2tnb359v1"
SSL.NID_X9_62_c2tnb359v1     = 701

SSL.SN_X9_62_c2pnb368w1      = "c2pnb368w1"
SSL.NID_X9_62_c2pnb368w1     = 702

SSL.SN_X9_62_c2tnb431r1      = "c2tnb431r1"
SSL.NID_X9_62_c2tnb431r1     = 703

## curves over prime fields
##
SSL.SN_X9_62_prime192v1      = "prime192v1"
SSL.NID_X9_62_prime192v1     = 409
SSL.SN_X9_62_prime192v2      = "prime192v2"
SSL.NID_X9_62_prime192v2     = 410
SSL.SN_X9_62_prime192v3      = "prime192v3"
SSL.NID_X9_62_prime192v3     = 411
SSL.SN_X9_62_prime239v1      = "prime239v1"
SSL.NID_X9_62_prime239v1     = 412
SSL.SN_X9_62_prime239v2      = "prime239v2"
SSL.NID_X9_62_prime239v2     = 413
SSL.SN_X9_62_prime239v3      = "prime239v3"
SSL.NID_X9_62_prime239v3     = 414
SSL.SN_X9_62_prime256v1      = "prime256v1"
SSL.NID_X9_62_prime256v1     = 415

## map of curve name to curve NID
##
ELLIPTIC_CURVES = {
   SSL.SN_X9_62_c2pnb163v1: SSL.NID_X9_62_c2pnb163v1,
   SSL.SN_X9_62_c2pnb163v2: SSL.NID_X9_62_c2pnb163v2,
   SSL.SN_X9_62_c2pnb163v3: SSL.NID_X9_62_c2pnb163v3,
   SSL.SN_X9_62_c2pnb176v1: SSL.NID_X9_62_c2pnb176v1,
   SSL.SN_X9_62_c2tnb191v1: SSL.NID_X9_62_c2tnb191v1,
   SSL.SN_X9_62_c2tnb191v2: SSL.NID_X9_62_c2tnb191v2,
   SSL.SN_X9_62_c2tnb191v3: SSL.NID_X9_62_c2tnb191v3,
   SSL.SN_X9_62_c2onb191v4: SSL.NID_X9_62_c2onb191v4,
   SSL.SN_X9_62_c2onb191v5: SSL.NID_X9_62_c2onb191v5,
   SSL.SN_X9_62_c2pnb208w1: SSL.NID_X9_62_c2pnb208w1,
   SSL.SN_X9_62_c2tnb239v1: SSL.NID_X9_62_c2tnb239v1,
   SSL.SN_X9_62_c2tnb239v2: SSL.NID_X9_62_c2tnb239v2,
   SSL.SN_X9_62_c2tnb239v3: SSL.NID_X9_62_c2tnb239v3,
   SSL.SN_X9_62_c2onb239v4: SSL.NID_X9_62_c2onb239v4,
   SSL.SN_X9_62_c2onb239v5: SSL.NID_X9_62_c2onb239v5,
   SSL.SN_X9_62_c2pnb272w1: SSL.NID_X9_62_c2pnb272w1,
   SSL.SN_X9_62_c2pnb304w1: SSL.NID_X9_62_c2pnb304w1,
   SSL.SN_X9_62_c2tnb359v1: SSL.NID_X9_62_c2tnb359v1,
   SSL.SN_X9_62_c2pnb368w1: SSL.NID_X9_62_c2pnb368w1,
   SSL.SN_X9_62_c2tnb431r1: SSL.NID_X9_62_c2tnb431r1,

   SSL.SN_X9_62_prime192v1: SSL.NID_X9_62_prime192v1,
   SSL.SN_X9_62_prime192v2: SSL.NID_X9_62_prime192v2,
   SSL.SN_X9_62_prime192v3: SSL.NID_X9_62_prime192v3,
   SSL.SN_X9_62_prime239v1: SSL.NID_X9_62_prime239v1,
   SSL.SN_X9_62_prime239v2: SSL.NID_X9_62_prime239v2,
   SSL.SN_X9_62_prime239v3: SSL.NID_X9_62_prime239v3,
   SSL.SN_X9_62_prime256v1: SSL.NID_X9_62_prime256v1
}

## prime256v1: X9.62/SECG curve over a 256 bit prime field
##
## This is elliptic curve "NIST P-256" from here
## http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf
##
## This seems to be the most widely used curve
##
##   http://crypto.stackexchange.com/questions/11310/with-openssl-and-ecdhe-how-to-show-the-actual-curve-being-used
##
## and researchers think it is "ok" (other than wrt timing attacks etc)
##
##   https://twitter.com/hyperelliptic/status/394258454342148096
##
ECDH_DEFAULT_CURVE_NAME = "prime256v1"
ECDH_DEFAULT_CURVE = ELLIPTIC_CURVES[ECDH_DEFAULT_CURVE_NAME]



class TlsServerContextFactory(DefaultOpenSSLContextFactory):
   """
   TLS context factory for use with Twisted.

   Like the default

      http://twistedmatrix.com/trac/browser/tags/releases/twisted-11.1.0/twisted/internet/ssl.py#L42

   but loads key/cert from string, not file and supports chained certificates.

   See also:

      http://pyopenssl.sourceforge.net/pyOpenSSL.html/openssl-context.html
      http://www.openssl.org/docs/ssl/SSL_CTX_use_certificate.html

   Chained certificates:
      The certificates must be in PEM format and must be sorted starting with
      the subject's certificate (actual client or server certificate), followed
      by intermediate CA certificates if applicable, and ending at the
      highest level (root) CA.

   Hardening:
      http://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/
      https://www.ssllabs.com/ssltest/analyze.html?d=www.example.com
   """

   def __init__(self,
                privateKeyString,
                certificateString,
                chainedCertificate = True,
                dhParamFilename = None,
                ciphers = None):
      self._privateKeyString = str(privateKeyString)
      self._certificateString = str(certificateString)
      self._chainedCertificate = chainedCertificate
      self._dhParamFilename = str(dhParamFilename) if dhParamFilename else None
      self._ciphers = str(ciphers) if ciphers else None

      ## do a SSLv2-compatible handshake even for TLS
      ##
      self.sslmethod = SSL.SSLv23_METHOD

      self._contextFactory = SSL.Context
      self.cacheContext()


   def cacheContext(self):
      if self._context is None:
         ctx = self._contextFactory(self.sslmethod)

         ## SSL hardening
         ##
         ctx.set_options(SSL_DEFAULT_OPTIONS)

         if self._ciphers:
            ctx.set_cipher_list(self._ciphers)
            log.msg("Using explicit cipher list.")
         else:
            ctx.set_cipher_list(SSL_DEFAULT_CIPHERS)
            log.msg("Using default cipher list.")


         ## Activate DH(E)
         ##
         ## http://linux.die.net/man/3/ssl_ctx_set_tmp_dh
         ## http://linux.die.net/man/1/dhparam
         ##
         if self._dhParamFilename:
            try:
               ctx.load_tmp_dh(self._dhParamFilename)
            except Exception as e:
               log.msg("Error: OpenSSL DH modes not active - failed to load DH parameter file [{}]".format(e))
            else:
               log.msg("Ok, OpenSSL Diffie-Hellman ciphers parameter file loaded.")
         else:
            log.msg("Warning: OpenSSL DH modes not active - missing DH param file")


         ## Activate ECDH(E)
         ##
         ## This needs pyOpenSSL 0.14
         ##
         try:
            ## without setting a curve, ECDH won't be available even if listed
            ## in SSL_DEFAULT_CIPHERS!
            ##
            #print OpenSSL.SSL.ELLIPTIC_CURVE_DESCRIPTIONS
            ctx.set_tmp_ecdh_curve(ECDH_DEFAULT_CURVE_NAME)
         except Exception as e:
            log.msg("Warning: OpenSSL failed to set ECDH default curve [{}]".format(e))
         else:
            log.msg("Ok, OpenSSL is using ECDH elliptic curve {}".format(ECDH_DEFAULT_CURVE_NAME))


         ## load certificate (chain) into context
         ##
         if not self._chainedCertificate:
            cert = crypto.load_certificate(crypto.FILETYPE_PEM, self._certificateString)
            ctx.use_certificate(cert)
         else:
            # http://pyopenssl.sourceforge.net/pyOpenSSL.html/openssl-context.html
            # there is no "use_certificate_chain" function, so we need to create
            # a temporary file writing the certificate chain file
            f = tempfile.NamedTemporaryFile(delete = False)
            f.write(self._certificateString)
            f.close()
            ctx.use_certificate_chain_file(f.name)


         ## load private key into context
         ##
         key = crypto.load_privatekey(crypto.FILETYPE_PEM, self._privateKeyString)
         ctx.use_privatekey(key)
         ctx.check_privatekey()


         ## set cached context
         ##
         self._context = ctx



from twisted.internet.ssl import ClientContextFactory

class TlsClientContextFactory(ClientContextFactory):
   pass

########NEW FILE########
__FILENAME__ = container
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['ContainerWorkerSession']


import os
import sys
import importlib
import pkg_resources
import traceback

from six import StringIO
from datetime import datetime

from twisted.internet import reactor
from twisted import internet
from twisted.python import log
from twisted.internet.defer import Deferred, \
                                   DeferredList, \
                                   inlineCallbacks, \
                                   returnValue

from autobahn.util import utcnow, utcstr
from autobahn.wamp.exception import ApplicationError
from autobahn.wamp.types import ComponentConfig, \
                                PublishOptions, \
                                RegisterOptions

from crossbar import common
from crossbar.worker.native import NativeWorkerSession
from crossbar.router.protocol import CrossbarWampWebSocketClientFactory, \
                                     CrossbarWampRawSocketClientFactory

from crossbar.twisted.endpoint import create_connecting_endpoint_from_config



class ContainerComponent:
   """
   An application component running inside a container.

   This class is for _internal_ use within ContainerWorkerSession.
   """
   def __init__(self, id, config, proto, session):
      """
      Ctor.

      :param id: The ID of the component within the container.
      :type id: int
      :param config: The component configuration the component was created from.
      :type config: dict
      :param proto: The transport protocol instance the component runs for talking
                    to the application router.
      :type proto: instance of CrossbarWampWebSocketClientProtocol or CrossbarWampRawSocketClientProtocol
      :param session: The application session of this component.
      :type session: Instance derived of ApplicationSession.
      """
      self.started = datetime.utcnow()
      self.id = id
      self.config = config
      self.proto = proto
      self.session = session


   def marshal(self):
      """
      Marshal object information for use with WAMP calls/events.
      """
      now = datetime.utcnow()
      return {
         'id': self.id,
         'started': utcstr(self.started),
         'uptime': (now - self.started).total_seconds(),
         'config': self.config
      }




class ContainerWorkerSession(NativeWorkerSession):
   """
   A container is a native worker process that hosts application components
   written in Python. A container connects to an application router (creating
   a WAMP transport) and attached to a given realm on the application router.
   """
   WORKER_TYPE = 'container'


   @inlineCallbacks
   def onJoin(self, details):
      """
      Called when worker process has joined the node's management realm.
      """
      ## map: component id -> ContainerComponent
      self.components = {}
      self.component_id = 0


      dl = []
      procs = [
         'get_components',
         'start_component',
         'stop_component',
         'restart_component'
      ]

      for proc in procs:
         uri = 'crossbar.node.{}.worker.{}.container.{}'.format(self.config.extra.node, self.config.extra.worker, proc)
         dl.append(self.register(getattr(self, proc), uri, options = RegisterOptions(details_arg = 'details', discloseCaller = True)))

      regs = yield DeferredList(dl)

      yield NativeWorkerSession.onJoin(self, details)



   def start_component(self, config, reload_modules = False, details = None):
      """
      Starts a Class or WAMPlet in this component container.

      :param config: Component configuration.
      :type config: dict
      :param reload_modules: If `True`, enforce reloading of modules (user code)
                             that were modified (see: TrackingModuleReloader).
      :type reload_modules: bool
      :param details: Caller details.
      :type details: instance of :class:`autobahn.wamp.types.CallDetails`

      :returns dict -- A dict with combined info from component starting.
      """
      try:
         common.config.check_container_component(config)
      except Exception as e:
         emsg = "ERROR: could not start container component - invalid configuration ({})".format(e)
         log.msg(emsg)
         raise ApplicationError('crossbar.error.invalid_configuration', emsg)


      ## 1) create WAMP application component factory
      ##
      if config['type'] == 'wamplet':

         package = config['package']
         entrypoint = config['entrypoint']

         try:
            ## create_component() is supposed to make instances of ApplicationSession later
            ##
            create_component = pkg_resources.load_entry_point(package, 'autobahn.twisted.wamplet', entrypoint)

         except Exception as e:
            tb = traceback.format_exc()
            emsg = 'ERROR: failed to import WAMPlet {}.{} ("{}")'.format(package, entrypoint, e)
            log.msg(emsg)
            raise ApplicationError("crossbar.error.cannot_import", emsg, tb)

         else:
            if self.debug:
               log.msg("Creating component from WAMPlet {}.{}".format(package, entrypoint))


      elif config['type'] == 'class':

         qualified_classname = config['classname']

         try:
            c = qualified_classname.split('.')
            module_name, class_name = '.'.join(c[:-1]), c[-1]
            module = importlib.import_module(module_name)

            ## create_component() is supposed to make instances of ApplicationSession later
            ##
            create_component = getattr(module, class_name)

         except Exception as e:
            tb = traceback.format_exc()
            emsg = 'ERROR: failed to import class {} ("{}")'.format(qualified_classname, e)
            log.msg(emsg)
            raise ApplicationError("crossbar.error.cannot_import", emsg, tb)

         else:
            if self.debug:
               log.msg("Creating component from class {}".format(qualified_classname))

      else:
         ## should not arrive here, since we did `check_container_component()`
         raise Exception("logic error")


      ## force reload of modules (user code)
      ##
      if reload_modules:
         self._module_tracker.reload()


      ## WAMP application session factory
      ##
      def create_session():
         cfg = ComponentConfig(realm = config['router']['realm'],
            extra = config.get('extra', None))
         c = create_component(cfg)
         return c


      ## 2) create WAMP transport factory
      ##
      transport_config = config['router']['transport']
      transport_debug = transport_config.get('debug', False)
      transport_debug_wamp = transport_config.get('debug_wamp', False)


      ## WAMP-over-WebSocket transport
      ##
      if transport_config['type'] == 'websocket':

         ## create a WAMP-over-WebSocket transport client factory
         ##
         transport_factory = CrossbarWampWebSocketClientFactory(create_session,
            transport_config['url'],
            debug = transport_debug,
            debug_wamp = transport_debug_wamp)

      ## WAMP-over-RawSocket transport
      ##
      elif transport_config['type'] == 'rawsocket':

         transport_factory = CrossbarWampRawSocketClientFactory(create_session,
            transport_config)

      else:
         ## should not arrive here, since we did `check_container_component()`
         raise Exception("logic error")


      ## 3) create and connect client endpoint
      ##
      endpoint = create_connecting_endpoint_from_config(transport_config['endpoint'],
         self.config.extra.cbdir,
         reactor)


      ## now connect the client
      ##
      d = endpoint.connect(transport_factory)

      def success(proto):
         self.component_id += 1
         self.components[self.component_id] = ContainerComponent(self.component_id,
            config, proto, None)

         ## publish event "on_component_start" to all but the caller
         ##
         topic = 'crossbar.node.{}.worker.{}.container.on_component_start'.format(self.config.extra.node, self.config.extra.worker)
         event = {'id': self.component_id}
         self.publish(topic, event, options = PublishOptions(exclude = [details.caller]))

         return event

      def error(err):
         ## https://twistedmatrix.com/documents/current/api/twisted.internet.error.ConnectError.html
         if isinstance(err.value, internet.error.ConnectError):
            emsg = "ERROR: could not connect container component to router - transport establishment failed ({})".format(err.value)
            log.msg(emsg)
            raise ApplicationError('crossbar.error.cannot_connect', emsg)
         else:
            ## should not arrive here (since all errors arriving here should be subclasses of ConnectError)
            raise err

      d.addCallbacks(success, error)

      return d



   @inlineCallbacks
   def restart_component(self, id, reload_modules = False, details = None):
      """
      Restart a component currently running within this container using the
      same configuration that was used when first starting the component.

      :param id: The ID of the component to restart.
      :type id: int
      :param reload_modules: If `True`, enforce reloading of modules (user code)
                             that were modified (see: TrackingModuleReloader).
      :type reload_modules: bool
      :param details: Caller details.
      :type details: instance of :class:`autobahn.wamp.types.CallDetails`

      :returns dict -- A dict with combined info from component stopping/starting.
      """
      if id not in self.components:
         raise ApplicationError('crossbar.error.no_such_object', 'no component with ID {} running in this container'.format(id))

      config = self.components[id].config
      stopped = yield self.stop_component(id, details = details)
      started = yield self.start_component(config, reload_modules = reload_modules, details = details)
      returnValue({'stopped': stopped, 'started': started})



   def stop_component(self, id, details = None):
      """
      Stop a component currently running within this container.

      :param id: The ID of the component to stop.
      :type id: int
      :param details: Caller details.
      :type details: instance of :class:`autobahn.wamp.types.CallDetails`

      :returns dict -- A dict with component start information.
      """
      if id not in self.components:
         raise ApplicationError('crossbar.error.no_such_object', 'no component with ID {} running in this container'.format(id))

      now = datetime.utcnow()

      ## FIXME: should we session.leave() first and only close the transport then?
      ## This gives the app component a better hook to do any cleanup.
      self.components[id].proto.close()

      c = self.components[id]
      event = {
         'id': id,
         'started': utcstr(c.started),
         'stopped': utcstr(now),
         'uptime': (now - c.started).total_seconds()
      }

      ## publish event "on_component_stop" to all but the caller
      ##
      topic = 'crossbar.node.{}.worker.{}.container.on_component_stop'.format(self.config.extra.node, self.config.extra.worker)
      self.publish(topic, event, options = PublishOptions(exclude = [details.caller]))

      del self.components[id]

      return event



   def get_components(self, details = None):
      """
      Get components currently running within this container.

      :param details: Caller details.
      :type details: instance of :class:`autobahn.wamp.types.CallDetails`

      :returns list -- List of components.
      """
      res = []
      for c in self.components.values():
         res.append(c.marshal())
      return res

########NEW FILE########
__FILENAME__ = native
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['NativeWorkerSession']

import os
import sys

from datetime import datetime

from twisted.python import log
from twisted.internet.defer import Deferred, \
                                   DeferredList, \
                                   inlineCallbacks, \
                                   returnValue


from autobahn.wamp.exception import ApplicationError
from autobahn.wamp.types import PublishOptions, \
                                RegisterOptions

from crossbar.common.processinfo import _HAS_PSUTIL
if _HAS_PSUTIL:
   import psutil

from crossbar.common import checkconfig
from crossbar.common.reloader import TrackingModuleReloader
from crossbar.common.process import NativeProcessSession




class NativeWorkerSession(NativeProcessSession):
   """
   A native Crossbar.io worker process. The worker will be connected
   to the node's management router running inside the node controller
   via WAMP-over-stdio.
   """

   WORKER_TYPE = 'native'


   def onConnect(self):
      """
      Called when the worker has connected to the node's management router.
      """
      self._uri_prefix = 'crossbar.node.{}.worker.{}'.format(self.config.extra.node, self.config.extra.worker)

      NativeProcessSession.onConnect(self, False)

      self._module_tracker = TrackingModuleReloader(debug = True)

      self.join(self.config.realm)



   @inlineCallbacks
   def onJoin(self, details, publish_ready = True):
      """
      Called when worker process has joined the node's management realm.
      """
      yield NativeProcessSession.onJoin(self, details)

      procs = [
         'get_cpu_affinity',
         'set_cpu_affinity',
         'get_pythonpath',
         'add_pythonpath',
      ]

      dl = []
      for proc in procs:
         uri = '{}.{}'.format(self._uri_prefix, proc)
         if self.debug:
            log.msg("Registering procedure '{}'".format(uri))
         dl.append(self.register(getattr(self, proc), uri, options = RegisterOptions(details_arg = 'details', discloseCaller = True)))

      regs = yield DeferredList(dl)

      if self.debug:
         log.msg("{} registered {} procedures".format(self.__class__.__name__, len(regs)))

      if publish_ready:
         yield self.publish_ready()



   @inlineCallbacks
   def publish_ready(self):
      ## signal that this worker is ready for setup. the actual setup procedure
      ## will either be sequenced from the local node configuration file or remotely
      ## from a management service
      ##
      pub = yield self.publish('crossbar.node.{}.on_worker_ready'.format(self.config.extra.node),
         {'type': self.WORKER_TYPE, 'id': self.config.extra.worker, 'pid': os.getpid()},
         options = PublishOptions(acknowledge = True))

      if self.debug:
         log.msg("NativeWorker ready event published")



   def get_cpu_affinity(self, details = None):
      """
      Get CPU affinity of this process.

      :returns list -- List of CPU IDs the process affinity is set to.
      """
      if self.debug:
         log.msg("{}.get_cpu_affinity".format(self.__class__.name))

      if not _HAS_PSUTIL:
         emsg = "ERROR: unable to get CPU affinity - required package 'psutil' is not installed"
         log.msg(emsg)
         raise ApplicationError("crossbar.error.feature_unavailable", emsg)

      try:
         p = psutil.Process(os.getpid())
         current_affinity = p.get_cpu_affinity()
      except Exception as e:
         emsg = "ERROR: could not get CPU affinity ({})".format(e)
         log.msg(emsg)
         raise ApplicationError("crossbar.error.runtime_error", emsg)
      else:
         res = {'affinity': current_affinity}
         return res



   def set_cpu_affinity(self, cpus, details = None):
      """
      Set CPU affinity of this process.

      :param cpus: List of CPU IDs to set process affinity to.
      :type cpus: list
      """
      if self.debug:
         log.msg("{}.set_cpu_affinity".format(self.__class__.name))

      if not _HAS_PSUTIL:
         emsg = "ERROR: unable to set CPU affinity - required package 'psutil' is not installed"
         log.msg(emsg)
         raise ApplicationError("crossbar.error.feature_unavailable", emsg)

      try:
         p = psutil.Process(os.getpid())
         p.set_cpu_affinity(cpus)
         new_affinity = p.get_cpu_affinity()
      except Exception as e:
         emsg = "ERROR: could not set CPU affinity ({})".format(e)
         log.msg(emsg)
         raise ApplicationError("crossbar.error.runtime_error", emsg)
      else:

         ## publish info to all but the caller ..
         ##
         cpu_affinity_set_topic = 'crossbar.node.{}.worker.{}.on_cpu_affinity_set'.format(self.config.extra.node, self.config.extra.worker)
         cpu_affinity_set_info = {
            'affinity': new_affinity,
            'who': details.authid
         }
         self.publish(cpu_affinity_set_topic, cpu_affinity_set_info, options = PublishOptions(exclude = [details.caller]))

         ## .. and return info directly to caller
         ##
         return cpu_affinity_set_info



   def get_pythonpath(self, details = None):
      """
      Returns the current Python module search paths.

      :returns list -- List of module search paths.
      """
      if self.debug:
         log.msg("{}.get_pythonpath".format(self.__class__.name))

      return sys.path



   def add_pythonpath(self, paths, prepend = True, details = None):
      """
      Add paths to Python module search paths.

      :param paths: List of paths. Relative paths will be resolved relative
                    to the node directory.
      :type paths: list
      :param prepend: If `True`, prepend the given paths to the current paths.
                      Otherwise append.
      :type prepend: bool
      """
      if self.debug:
         log.msg("{}.add_pythonpath".format(self.__class__.name))

      paths_added = []
      for p in paths:
         ## transform all paths (relative to cbdir) into absolute paths
         ##
         path_to_add = os.path.abspath(os.path.join(self.config.extra.cbdir, p))
         if os.path.isdir(path_to_add):
            paths_added.append({'requested': p, 'resolved': path_to_add})
         else:
            emsg = "ERROR: cannot add Python search path '{}' - resolved path '{}' is not a directory".format(p, path_to_add)
            log.msg(emsg)
            raise ApplicationError('crossbar.error.invalid_argument', emsg, requested = p, resolved = path_to_add)

      ## now extend python module search path
      ##
      paths_added_resolved = [p['resolved'] for p in paths_added]
      if prepend:
         sys.path = paths_added_resolved + sys.path
      else:
         sys.path.extend(paths_added_resolved)

      ## publish event "on_pythonpath_add" to all but the caller
      ##
      topic = 'crossbar.node.{}.worker.{}.on_pythonpath_add'.format(self.config.extra.node, self.config.extra.worker)
      res = {
         'paths': sys.path,
         'paths_added': paths_added,
         'prepend': prepend,
         'who': details.authid
      }
      self.publish(topic, res, options = PublishOptions(exclude = [details.caller]))

      return res

########NEW FILE########
__FILENAME__ = process
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['run']


def run():
   """
   Entry point into (native) worker processes. This wires up stuff such that
   a worker instance is talking WAMP-over-stdio to the node controller.
   """
   import os, sys, platform

   ## create the top-level parser
   ##
   import argparse
   parser = argparse.ArgumentParser()

   parser.add_argument('-d',
                       '--debug',
                       action = 'store_true',
                       help = 'Debug on (optional).')

   parser.add_argument('--reactor',
                       default = None,
                       choices = ['select', 'poll', 'epoll', 'kqueue', 'iocp'],
                       help = 'Explicit Twisted reactor selection (optional).')

   parser.add_argument('-c',
                       '--cbdir',
                       type = str,
                       help = "Crossbar.io node directory (required).")

   parser.add_argument('-n',
                       '--node',
                       type = str,
                       help = 'Crossbar.io node ID (required).')

   parser.add_argument('-w',
                       '--worker',
                       type = str,
                       help = 'Crossbar.io worker ID (required).')

   parser.add_argument('-r',
                       '--realm',
                       type = str,
                       help = 'Crossbar.io node (management) realm (required).')

   parser.add_argument('-t',
                       '--type',
                       choices = ['router', 'container'],
                       help = 'Worker type (required).')

   parser.add_argument('--title',
                       type = str,
                       default = None,
                       help = 'Worker process title to set (optional).')

   options = parser.parse_args()


   ## make sure logging to something else than stdio is setup _first_
   ##
   from twisted.python import log
   from crossbar.twisted.process import BareFormatFileLogObserver
   flo = BareFormatFileLogObserver(sys.stderr)
   log.startLoggingWithObserver(flo.emit)


   try:
      import setproctitle
   except ImportError:
      log.msg("Warning: could not set worker process title (setproctitle not installed)")
   else:
      ## set process title if requested to
      ##
      if options.title:
         setproctitle.setproctitle(options.title)
      else:
         WORKER_TYPE_TO_TITLE = {
            'router': 'crossbar-worker [router]',
            'container': 'crossbar-worker [container]'
         }
         setproctitle.setproctitle(WORKER_TYPE_TO_TITLE[options.type].strip())


   ## we use an Autobahn utility to import the "best" available Twisted reactor
   ##
   from autobahn.twisted.choosereactor import install_reactor
   reactor = install_reactor(options.reactor)

   from twisted.python.reflect import qual
   log.msg("Running under {} using {} reactor".format(platform.python_implementation(), qual(reactor.__class__).split('.')[-1]))


   options.cbdir = os.path.abspath(options.cbdir)
   os.chdir(options.cbdir)
   #log.msg("Starting from node directory {}".format(options.cbdir))


   from crossbar.worker.router import RouterWorkerSession
   from crossbar.worker.container import ContainerWorkerSession

   WORKER_TYPE_TO_CLASS = {
      'router': RouterWorkerSession,
      'container': ContainerWorkerSession
   }


   from autobahn.twisted.websocket import WampWebSocketServerProtocol

   class WorkerServerProtocol(WampWebSocketServerProtocol):

      def connectionLost(self, reason):
         try:
            ## this log message is unlikely to reach the controller (unless
            ## only stdin/stdout pipes were lost, but not stderr)
            log.msg("Connection to node controller lost.")
            WampWebSocketServerProtocol.connectionLost(self, reason)
         except:
            pass
         finally:
            ## loosing the connection to the node controller is fatal:
            ## stop the reactor and exit with error
            if reactor.running:
               reactor.addSystemEventTrigger('after', 'shutdown', os._exit, 1)
               reactor.stop()
            else:
               sys.exit(1)

   try:
      ## create a WAMP application session factory
      ##
      from autobahn.twisted.wamp import ApplicationSessionFactory
      from autobahn.wamp.types import ComponentConfig

      session_config = ComponentConfig(realm = options.realm, extra = options)
      session_factory = ApplicationSessionFactory(session_config)
      session_factory.session = WORKER_TYPE_TO_CLASS[options.type]


      ## create a WAMP-over-WebSocket transport server factory
      ##
      from autobahn.twisted.websocket import WampWebSocketServerFactory
      transport_factory = WampWebSocketServerFactory(session_factory, "ws://localhost", debug = False, debug_wamp = False)
      transport_factory.protocol = WorkerServerProtocol
      transport_factory.setProtocolOptions(failByDrop = False)

      ## create a protocol instance and wire up to stdio
      ##
      from twisted.internet import stdio
      proto = transport_factory.buildProtocol(None)
      stdio.StandardIO(proto)

      ## now start reactor loop
      ##
      log.msg("Entering event loop ..")
      reactor.run()

   except Exception as e:
      log.msg("Unhandled exception: {}".format(e))
      if reactor.running:
         reactor.addSystemEventTrigger('after', 'shutdown', os._exit, 1)
         reactor.stop()
      else:
         sys.exit(1)



if __name__ == '__main__':
   run()

########NEW FILE########
__FILENAME__ = router
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from __future__ import absolute_import

__all__ = ['RouterWorker']


import os
import jinja2
import pkg_resources

from twisted.internet import reactor

from twisted.python import log
from twisted.internet.defer import DeferredList
from twisted.internet.defer import inlineCallbacks

from twisted.internet.endpoints import serverFromString

from autobahn.wamp.exception import ApplicationError

from crossbar.router.session import CrossbarRouterSessionFactory, \
                                    CrossbarRouterFactory

from crossbar.router.protocol import CrossbarWampWebSocketServerFactory, \
                                     CrossbarWampRawSocketServerFactory

from crossbar.worker.testee import TesteeServerFactory


try:
   from twisted.web.wsgi import WSGIResource
   _HAS_WSGI = True
except ImportError:
   ## Twisted hasn't ported this to Python 3 yet
   _HAS_WSGI = False


from autobahn.twisted.resource import WebSocketResource, \
                                      WSGIRootResource, \
                                      HTTPChannelHixie76Aware


import importlib
import pkg_resources

from twisted.web.server import Site

## monkey patch the Twisted Web server identification
import twisted
import crossbar
twisted.web.server.version = "Crossbar/{}".format(crossbar.__version__)

try:
   from twisted.web.static import File
   from crossbar.twisted.resource import FileNoListing
   _HAS_STATIC = True
except ImportError:
   ## Twisted hasn't ported this to Python 3 yet
   _HAS_STATIC = False


from twisted.web.resource import Resource

from autobahn.twisted.resource import WebSocketResource

from crossbar.twisted.site import createHSTSRequestFactory
from crossbar.twisted.resource import JsonResource, Resource404, RedirectResource

from crossbar.twisted.resource import _HAS_STATIC, _HAS_CGI

if _HAS_CGI:
   from crossbar.twisted.resource import CgiDirectory



from autobahn.wamp.types import ComponentConfig
from autobahn.twisted.wamp import ApplicationSession

from crossbar.worker.native import NativeWorkerSession

from crossbar.common import checkconfig




EXTRA_MIME_TYPES = {
   '.svg': 'image/svg+xml',
   '.jgz': 'text/javascript'
}



class RouterRealm:
   """
   A realm managed by a router.
   """
   def __init__(self, id, realm, config):
      """
      Ctor.

      :param id: The realm index within the router.
      :type id: int
      :param realm: The realm name.
      :type realm: str
      :param config: The realm configuration.
      :type config: str
      """
      self.id = id
      self.realm = realm
      self.config = config



class RouterTransport:
   """
   A transport attached to a router.
   """
   def __init__(self, id, config, port):
      """
      Ctor.

      :param id: The transport index within the router.
      :type id: int
      :param config: The transport's configuration.
      :type config: dict
      :param port: The transport's listening port (https://twistedmatrix.com/documents/current/api/twisted.internet.interfaces.IListeningPort.html)
      :type port: obj
      """
      self.id = id
      self.config = config
      self.port = port



class RouterComponent:
   """
   An embedded application component running inside a router instance.
   """
   def __init__(self, id, config, session):
      """
      Ctor.

      :param id: The component index within the router instance.
      :type id: int
      :param config: The component's configuration.
      :type config: dict
      :param session: The component application session.
      :type session: obj (instance of ApplicationSession)
      """
      self.id = id
      self.config = config
      self.session = session
      self.created = datetime.utcnow()



class RouterWorkerSession(NativeWorkerSession):
   """
   A native Crossbar.io worker that runs a WAMP router which can manage
   multiple realms, run multiple transports and links, as well as host
   multiple (embedded) application components.
   """
   WORKER_TYPE = 'router'


   @inlineCallbacks
   def onJoin(self, details):
      """
      """
      yield NativeWorkerSession.onJoin(self, details, publish_ready = False)

      ## Jinja2 templates for Web (like WS status page et al)
      ##
      templates_dir = os.path.abspath(pkg_resources.resource_filename("crossbar", "web/templates"))
      if self.debug:
         log.msg("Using Web templates from {}".format(templates_dir))
      self._templates = jinja2.Environment(loader = jinja2.FileSystemLoader(templates_dir))

      ## factory for producing (per-realm) routers
      self.factory = CrossbarRouterFactory()

      ## factory for producing router sessions
      self.session_factory = CrossbarRouterSessionFactory(self.factory)

      ## map: realm index -> RouterRealm
      self.realms = {}

      ## map: transport index -> RouterTransport
      self.transports = {}

      ## map: link index -> RouterLink
      self.links = {}

      ## map: component index -> RouterComponent
      self.components = {}

      self.debug_app = True


      ## the procedures registered
      procs = [
         'get_router_realms',
         'start_router_realm',
         'stop_router_realm',
         'get_router_components',
         'start_router_component',
         'stop_router_component',
         'get_router_transports',
         'start_router_transport',
         'stop_router_transport',
         'get_router_links',
         'start_router_link',
         'stop_router_link'
      ]

      dl = []
      for proc in procs:
         uri = '{}.{}'.format(self._uri_prefix, proc)
         if self.debug:
            log.msg("Registering procedure '{}'".format(uri))
         dl.append(self.register(getattr(self, proc), uri))

      regs = yield DeferredList(dl)

      if self.debug:
         log.msg("RouterWorker registered {} procedures".format(len(regs)))

      ## NativeWorkerSession.publish_ready()
      yield self.publish_ready()



   def get_router_realms(self):
      """
      List realms currently managed by this router.
      """
      if self.debug:
         log.msg("{}.get_router_realms".format(self.__class__.name))

      raise NotImplementedError()



   def start_router_realm(self, id, config):
      """
      Starts a realm managed by this router.

      :param id: The ID of the realm to start.
      :type id: str
      :param config: The realm configuration.
      :type config: dict
      """
      if self.debug:
         log.msg("{}.start_router_realm".format(self.__class__.name), id, config)

      raise NotImplementedError()



   def stop_router_realm(self, id, close_sessions = False):
      """
      Stop a router realm.

      When a realm has stopped, no new session will be allowed to attach to the realm.
      Optionally, close all sessions currently attached to the realm.

      :param id: ID of the realm to stop.
      :type id: str
      :param close_sessions: If `True`, close all session currently attached.
      :type close_sessions: bool
      """
      if self.debug:
         log.msg("{}.stop_router_realm".format(self.__class__.name), id, close_sessions)

      raise NotImplementedError()



   def get_router_components(self):
      """
      List application components currently running (embedded) in this router.
      """
      if self.debug:
         log.msg("{}.get_router_components".format(self.__class__.name))

      res = []
      for component in sorted(self._components.values(), key = lambda c: c.created):
         res.append({
            'id': component.id,
            'created': utcstr(component.created),
            'config': component.config,
         })
      return res



   def start_router_component(self, id, config):
      """
      Dynamically start an application component to run next to the router in "embedded mode".

      :param id: The ID of the component to start.
      :type id: str
      :param config: The component configuration.
      :type config: obj
      """
      if self.debug:
         log.msg("{}.start_router_component".format(self.__class__.name), id, config)

      cfg = ComponentConfig(realm = config['realm'], extra = config.get('extra', None))

      if config['type'] == 'class':

         try:
            klassname = config['name']

            if self.debug:
               log.msg("Starting class '{}'".format(klassname))

            import importlib
            c = klassname.split('.')
            mod, klass = '.'.join(c[:-1]), c[-1]
            app = importlib.import_module(mod)
            make = getattr(app, klass)

         except Exception as e:
            emsg = "Failed to import class '{}' - {}".format(klassname, e)
            log.msg(emsg)
            raise ApplicationError("crossbar.error.class_import_failed", emsg)

      elif config['type'] == 'wamplet':

         try:
            dist = config['dist']
            name = config['entry']

            if self.debug:
               log.msg("Starting WAMPlet '{}/{}'".format(dist, name))

            ## make is supposed to make instances of ApplicationSession
            make = pkg_resources.load_entry_point(dist, 'autobahn.twisted.wamplet', name)

         except Exception as e:
            emsg = "Failed to import wamplet '{}/{}' - {}".format(dist, name, e)
            log.msg(emsg)
            raise ApplicationError("crossbar.error.class_import_failed", emsg)

      else:
         raise ApplicationError("crossbar.error.invalid_configuration", "invalid component type '{}'".format(config['type']))


      ## .. and create and add an WAMP application session to
      ## run the component next to the router
      ##
      try:
         comp = make(cfg)
      except Exception as e:
         raise ApplicationError("crossbar.error.class_import_failed", str(e))

      if not isinstance(comp, ApplicationSession):
         raise ApplicationError("crossbar.error.class_import_failed", "session not derived of ApplicationSession")


      self.session_factory.add(comp)

      #self.components[id] = RouterComponent(id, realm, config, comp)



   def stop_router_component(self, id):
      """
      Stop an application component running on this router.

      :param id: The ID of the component to stop.
      :type id: str
      """
      if self.debug:
         log.msg("{}.stop_router_component".format(self.__class__.name), id)

      if id in self._components:
         if self.debug:
            log.msg("Worker {}: stopping component {}".format(self.config.extra.worker, id))

         try:
            #self._components[id].disconnect()
            self._session_factory.remove(self._components[id])
            del self._components[id]
         except Exception as e:
            raise ApplicationError("crossbar.error.component.cannot_stop", "Failed to stop component {}: {}".format(id, e))
      else:
         raise ApplicationError("crossbar.error.no_such_component", "No component {}".format(id))



   def get_router_transports(self):
      """
      List currently running transports.
      """
      if self.debug:
         log.msg("{}.get_router_transports".format(self.__class__.name))

      res = {}
      for key, transport in self._transports.items():
         res[key] = transport.config
      return res
      #return sorted(self._transports.keys())



   def start_router_transport(self, id, config):
      """
      Start a transport on this router.

      :param id: The ID of the transport to start.
      :type id: str
      :param config: The transport configuration.
      :type config: dict
      """
      if self.debug:
         log.msg("{}.start_router_transport".format(self.__class__.name), id, config)

      ## prohibit starting a transport twice
      ##
      if id in self.transports:
         emsg = "ERROR: could not start transport - a transport with ID '{}'' is already running (or starting)".format(id)
         log.msg(emsg)
         raise ApplicationError('crossbar.error.already_running', emsg)

      ## check configuration
      ##
      try:
         #checkconfig.check_transport(config)
         pass
      except Exception as e:
         emsg = "ERROR: invalid router transport configuration ({})".format(e)
         log.msg(emsg)
         raise ApplicationError("crossbar.error.invalid_configuration", emsg)
      else:
         if self.debug:
            log.msg("Starting {}-transport on router.".format(config['type']))


      ## standalone WAMP-RawSocket transport
      ##
      if config['type'] == 'rawsocket':

         transport_factory = CrossbarWampRawSocketServerFactory(self.session_factory, config)


      ## standalone WAMP-WebSocket transport
      ##
      elif config['type'] == 'websocket':

         transport_factory = CrossbarWampWebSocketServerFactory(self.session_factory, self.config.extra.cbdir, config, self._templates)


      ## standalone WebSocket testee transport
      ##
      elif config['type'] == 'websocket.testee':

         transport_factory = TesteeServerFactory(config, self._templates)


      ## Twisted Web transport
      ##
      elif config['type'] == 'web':

         options = config.get('options', {})


         ## create Twisted Web root resource
         ##
         root_config = config['paths']['/']
         root_type = root_config['type']


         ## Static file hierarchy root resource
         ##
         if root_type == 'static':


            if 'directory' in root_config:

               root_dir = os.path.abspath(os.path.join(self.config.extra.cbdir, root_config['directory']))

            elif 'module' in root_config:
               if not 'resource' in root_config:
                  raise ApplicationError("crossbar.error.invalid_configuration", "missing module")

               try:
                  mod = importlib.import_module(root_config['module'])
               except ImportError:
                  raise ApplicationError("crossbar.error.invalid_configuration", "module import failed")
               else:
                  try:
                     root_dir = os.path.abspath(pkg_resources.resource_filename(root_config['module'], root_config['resource']))
                  except Exception as e:
                     raise ApplicationError("crossbar.error.invalid_configuration", str(e))
                  else:
                     mod_version = getattr(mod, '__version__', '?.?.?')
                     log.msg("Loaded static Web resource '{}' from module '{} {}' (filesystem path {})".format(root_config['resource'], root_config['module'], mod_version, root_dir))

            else:
               raise ApplicationError("crossbar.error.invalid_configuration", "missing web spec")

            root_dir = root_dir.encode('ascii', 'ignore') # http://stackoverflow.com/a/20433918/884770
            if self.debug:
               log.msg("Starting Web service at root directory {}".format(root_dir))


            ## create resource for file system hierarchy
            ##
            if options.get('enable_directory_listing', False):
               root = File(root_dir)
            else:
               root = FileNoListing(root_dir)

            ## set extra MIME types
            ##
            root.contentTypes.update(EXTRA_MIME_TYPES)

            ## render 404 page on any concrete path not found
            ##
            root.childNotFound = Resource404(self._templates, root_dir)


         ## WSGI root resource
         ##
         elif root_type == 'wsgi':

            if not _HAS_WSGI:
               raise ApplicationError("crossbar.error.invalid_configuration", "WSGI unsupported")

            wsgi_options = root_config.get('options', {})

            if not 'module' in root_config:
               raise ApplicationError("crossbar.error.invalid_configuration", "missing module")

            if not 'object' in root_config:
               raise ApplicationError("crossbar.error.invalid_configuration", "missing object")

            try:
               mod = importlib.import_module(root_config['module'])
            except ImportError:
               raise ApplicationError("crossbar.error.invalid_configuration", "module import failed")
            else:
               if not root_config['object'] in mod.__dict__:
                  raise ApplicationError("crossbar.error.invalid_configuration", "object not in module")
               else:
                  app = getattr(mod, root_config['object'])

            ## create a Twisted Web WSGI resource from the user's WSGI application object
            try:
               wsgi_resource = WSGIResource(reactor, reactor.getThreadPool(), app)
            except Exception as e:
               raise ApplicationError("crossbar.error.invalid_configuration", "could not instantiate WSGI resource: {}".format(e))
            else:
               ## create a root resource serving everything via WSGI
               root = WSGIRootResource(wsgi_resource, {})


         ## Redirecting root resource
         ##
         elif root_type == 'redirect':

            redirect_url = root_config['url'].encode('ascii', 'ignore')
            root = RedirectResource(redirect_url)


         ## Invalid root resource
         ##
         else:
            raise ApplicationError("crossbar.error.invalid_configuration", "invalid Web root path type '{}'".format(root_type))


         ## create Twisted Web resources on all non-root paths configured
         ##
         for path in sorted(config.get('paths', [])):

            if path != "/":

               path_config = config['paths'][path]

               ## websocket_echo
               ## websocket_testee
               ## s3mirror
               ## websocket_stdio
               ##

               ## WAMP-WebSocket resource
               ##
               if path_config['type'] == 'websocket':
                  ws_factory = CrossbarWampWebSocketServerFactory(self.session_factory, self.config.extra.cbdir, path_config, self._templates)

                  ## FIXME: Site.start/stopFactory should start/stop factories wrapped as Resources
                  ws_factory.startFactory()

                  ws_resource = WebSocketResource(ws_factory)
                  root.putChild(path, ws_resource)


               ## Static file hierarchy resource
               ##
               elif path_config['type'] == 'static':

                  static_options = path_config.get('options', {})

                  if 'directory' in path_config:

                     static_dir = os.path.abspath(os.path.join(self.config.extra.cbdir, path_config['directory']))

                  elif 'module' in path_config:

                     if not 'resource' in path_config:
                        raise ApplicationError("crossbar.error.invalid_configuration", "missing module")

                     try:
                        mod = importlib.import_module(path_config['module'])
                     except ImportError:
                        raise ApplicationError("crossbar.error.invalid_configuration", "module import failed")
                     else:
                        try:
                           static_dir = os.path.abspath(pkg_resources.resource_filename(path_config['module'], path_config['resource']))
                        except Exception as e:
                           raise ApplicationError("crossbar.error.invalid_configuration", str(e))

                  else:

                     raise ApplicationError("crossbar.error.invalid_configuration", "missing web spec")

                  static_dir = static_dir.encode('ascii', 'ignore') # http://stackoverflow.com/a/20433918/884770

                  ## create resource for file system hierarchy
                  ##
                  if static_options.get('enable_directory_listing', False):
                     static_resource = File(static_dir)
                  else:
                     static_resource = FileNoListing(static_dir)

                  ## set extra MIME types
                  ##
                  static_resource.contentTypes.update(EXTRA_MIME_TYPES)

                  ## render 404 page on any concrete path not found
                  ##
                  static_resource.childNotFound = Resource404(self._templates, static_dir)

                  root.putChild(path, static_resource)


               ## WSGI resource
               ##
               elif path_config['type'] == 'wsgi':

                  if not _HAS_WSGI:
                     raise ApplicationError("crossbar.error.invalid_configuration", "WSGI unsupported")

                  wsgi_options = path_config.get('options', {})

                  if not 'module' in path_config:
                     raise ApplicationError("crossbar.error.invalid_configuration", "missing module")

                  if not 'object' in path_config:
                     raise ApplicationError("crossbar.error.invalid_configuration", "missing object")

                  try:
                     mod = importlib.import_module(path_config['module'])
                  except ImportError:
                     raise ApplicationError("crossbar.error.invalid_configuration", "module import failed")
                  else:
                     if not path_config['object'] in mod.__dict__:
                        raise ApplicationError("crossbar.error.invalid_configuration", "object not in module")
                     else:
                        app = getattr(mod, path_config['object'])

                  ## create a Twisted Web WSGI resource from the user's WSGI application object
                  try:
                     wsgi_resource = WSGIResource(reactor, reactor.getThreadPool(), app)
                  except Exception as e:
                     raise ApplicationError("crossbar.error.invalid_configuration", "could not instantiate WSGI resource: {}".format(e))
                  else:
                     root.putChild(path, wsgi_resource)


               ## Redirecting resource
               ##
               elif path_config['type'] == 'redirect':
                  redirect_url = path_config['url'].encode('ascii', 'ignore')
                  redirect_resource = RedirectResource(redirect_url)
                  root.putChild(path, redirect_resource)


               ## JSON value resource
               ##
               elif path_config['type'] == 'json':
                  value = path_config['value']

                  json_resource = JsonResource(value)
                  root.putChild(path, json_resource)


               ## CGI script resource
               ##
               elif path_config['type'] == 'cgi':

                  cgi_processor = path_config['processor']
                  cgi_directory = os.path.abspath(os.path.join(self.config.extra.cbdir, path_config['directory']))
                  cgi_directory = cgi_directory.encode('ascii', 'ignore') # http://stackoverflow.com/a/20433918/884770

                  cgi_resource = CgiDirectory(cgi_directory, cgi_processor, Resource404(self._templates, cgi_directory))

                  root.putChild(path, cgi_resource)


               ## WAMP-Longpoll transport resource
               ##
               elif path_config['type'] == 'longpoll':

                  log.msg("Web path type 'longpoll' not implemented")

               else:
                  raise ApplicationError("crossbar.error.invalid_configuration", "invalid Web path type '{}'".format(path_config['type']))


         ## create the actual transport factory
         ##
         transport_factory = Site(root)


         ## Web access logging
         ##
         if not options.get('access_log', False):
            transport_factory.log = lambda _: None

         ## Traceback rendering
         ##
         transport_factory.displayTracebacks = options.get('display_tracebacks', False)

         ## HSTS
         ##
         if options.get('hsts', False):
            if 'tls' in config['endpoint']:
               hsts_max_age = int(options.get('hsts_max_age', 31536000))
               transport_factory.requestFactory = createHSTSRequestFactory(transport_factory.requestFactory, hsts_max_age)
            else:
               log.msg("Warning: HSTS requested, but running on non-TLS - skipping HSTS")

         ## enable Hixie-76 on Twisted Web
         ##
         if options.get('hixie76_aware', False):
            transport_factory.protocol = HTTPChannelHixie76Aware # needed if Hixie76 is to be supported

      else:
         ## should not arrive here, since we did check_transport() in the beginning
         raise Exception("logic error")


      ## create transport endpoint / listening port from transport factory
      ##
      from twisted.internet import reactor
      from crossbar.twisted.endpoint import create_listening_port_from_config

      d = create_listening_port_from_config(config['endpoint'], transport_factory, self.config.extra.cbdir, reactor)

      def ok(port):
         self.transports[id] = RouterTransport(id, config, port)
         if self.debug:
            log.msg("Router transport {} started and listening".format(self.transport_no))
         return

      def fail(err):
         emsg = "ERROR: cannot listen on transport endpoint ({})".format(err.value)
         log.msg(emsg)
         raise ApplicationError("crossbar.error.cannot_listen", emsg)

      d.addCallbacks(ok, fail)
      return d



   def stop_router_transport(self, id):
      """
      Stop a transport on this router on this router.

      :param id: The ID of the transport to stop.
      :type id: dict
      """
      if self.debug:
         log.msg("{}.stop_router_transport".format(self.__class__.name), id)

      if not id in self.transports or self.transports['id'] != 'started':
         emsg = "ERROR: cannot stop transport - no transport with ID '{}' (or already stopping)".format(id)
         log.msg(emsg)
         raise ApplicationError('crossbar.error.not_running', emsg)

      if self.debug:
         log.msg("Stopping transport with ID '{}'".format(id))

      d = self._transports[id].port.stopListening()

      def ok(_):
         del self._transports[id]

      def fail(err):
         raise ApplicationError("crossbar.error.cannot_stop", "Failed to stop transport: {}".format(str(err.value)))

      d.addCallbacks(ok, fail)
      return d



   def get_router_links(self):
      """
      List currently running router links.
      """
      if self.debug:
         log.msg("{}.get_router_links".format(self.__class__.name))

      raise NotImplementedError()



   def start_router_link(self, id, config):
      """
      Start a link on this router.

      :param id: The ID of the link to start.
      :type id: str
      :param config: The link configuration.
      :type config: dict
      """
      if self.debug:
         log.msg("{}.start_router_link".format(self.__class__.name), id, config)

      raise NotImplementedError()



   def stop_router_link(self, id):
      """
      Stop a link on this router.

      :param id: The ID of the link to stop.
      :type id: str
      """
      if self.debug:
         log.msg("{}.stop_router_link".format(self.__class__.name), id)

      raise NotImplementedError()

########NEW FILE########
__FILENAME__ = testee
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import crossbar

from autobahn.twisted.websocket import WebSocketServerFactory, \
                                       WebSocketServerProtocol

from autobahn.websocket.compress import *

from crossbar.router.protocol import set_websocket_options


class TesteeServerProtocol(WebSocketServerProtocol):

   def onMessage(self, payload, isBinary):
      self.sendMessage(payload, isBinary)

   def sendServerStatus(self, redirectUrl = None, redirectAfter = 0):
      """
      Used to send out server status/version upon receiving a HTTP/GET without
      upgrade to WebSocket header (and option serverStatus is True).
      """
      try:
         page = self.factory._templates.get_template('cb_ws_testee_status.html')
         self.sendHtml(page.render(redirectUrl = redirectUrl,
                                   redirectAfter = redirectAfter,
                                   cbVersion = crossbar.__version__,
                                   wsUri = self.factory.url))
      except Exception as e:         
         log.msg("Error rendering WebSocket status page template: %s" % e)



class StreamingTesteeServerProtocol(WebSocketServerProtocol):

   def onMessageBegin(self, isBinary):
      #print "onMessageBegin"
      WebSocketServerProtocol.onMessageBegin(self, isBinary)
      self.beginMessage(isBinary = isBinary)

   def onMessageFrameBegin(self, length):
      #print "onMessageFrameBegin"
      WebSocketServerProtocol.onMessageFrameBegin(self, length)
      self.beginMessageFrame(length)

   def onMessageFrameData(self, data):
      #print "onMessageFrameData", len(data)
      self.sendMessageFrameData(data)

   def onMessageFrameEnd(self):
      #print "onMessageFrameEnd"
      pass

   def onMessageEnd(self):
      #print "onMessageEnd"
      self.endMessage()




class TesteeServerFactory(WebSocketServerFactory):

   protocol = TesteeServerProtocol
   #protocol = StreamingTesteeServerProtocol

   def __init__(self, config, templates):
      """
      Ctor.

      :param factory: WAMP session factory.
      :type factory: An instance of ..
      :param config: Crossbar transport configuration.
      :type config: dict 
      """
      options = config.get('options', {})

      server = "Crossbar/{}".format(crossbar.__version__)
      externalPort = options.get('external_port', None)


      WebSocketServerFactory.__init__(self,
                                      url = config.get('url', None),
                                      server = server,
                                      externalPort = externalPort,
                                      debug = config.get('debug', False))

      ## transport configuration
      self._config = config

      ## Jinja2 templates for 404 etc
      self._templates = templates

      ## set WebSocket options
      set_websocket_options(self, options)

########NEW FILE########
__FILENAME__ = timeservice
###############################################################################
##
##  Copyright (C) 2014 Tavendo GmbH
##
##  Licensed under the Apache License, Version 2.0 (the "License");
##  you may not use this file except in compliance with the License.
##  You may obtain a copy of the License at
##
##      http://www.apache.org/licenses/LICENSE-2.0
##
##  Unless required by applicable law or agreed to in writing, software
##  distributed under the License is distributed on an "AS IS" BASIS,
##  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
##  See the License for the specific language governing permissions and
##  limitations under the License.
##
###############################################################################

import datetime

from autobahn.wamp.types import RegisterOptions
from autobahn.twisted.wamp import ApplicationSession



class TimeService(ApplicationSession):
   """
   A simple time service application component.
   """

   def __init__(self, realm = "realm1"):
      ApplicationSession.__init__(self)
      self._realm = realm


   def onConnect(self):
      self.join(self._realm)


   def onJoin(self, details):

      def utcnow(details = None):
         ## details is an instance of autobahn.wamp.types.CallDetails
         ## and provides information on the caller
         now = datetime.datetime.utcnow()
         now = now.strftime("%Y-%m-%dT%H:%M:%SZ")
         return "{} (called by session {} / authid '{}' / authrole '{}')".format(\
            now, details.caller, details.authid, details.authrole)

      ## To get caller information when being called, we need to
      ## register with options ..
      self.register(utcnow, 'com.timeservice.now',
         options = RegisterOptions(details_arg = 'details', discloseCaller = True))

########NEW FILE########
__FILENAME__ = myapp
import random
from flask import Flask, render_template, request

##
## Our WSGI application .. in this case Flask based
##
app = Flask(__name__)


@app.route('/')
def page_home():
   return render_template('index.html', message = "Hello from Crossbar.io")


@app.route('/call')
def page_call():
   return render_template('call.html')


@app.route('/square', methods = ['POST', 'GET'])
def page_square():
   if request.method == 'POST':
      value = int(request.form['value'])
   else:
      value = random.randint(0, 100)
   return render_template('square.html', value = value)



if __name__ == "__main__":
   app.run (port = 8090, debug = True)

########NEW FILE########
__FILENAME__ = adbapi
# -*- test-case-name: twisted.test.test_adbapi -*-
# Copyright (c) Twisted Matrix Laboratories.
# See LICENSE for details.

"""
An asynchronous mapping to U{DB-API 2.0<http://www.python.org/topics/database/DatabaseAPI-2.0.html>}.
"""

import sys, pprint

from twisted.internet import threads
from twisted.python import reflect, log
from twisted.python.deprecate import deprecated
from twisted.python.versions import Version



class ConnectionLost(Exception):
    """
    This exception means that a db connection has been lost.  Client code may
    try again.
    """



class Connection(object):
    """
    A wrapper for a DB-API connection instance.

    The wrapper passes almost everything to the wrapped connection and so has
    the same API. However, the Connection knows about its pool and also
    handle reconnecting should when the real connection dies.
    """

    def __init__(self, pool):
        self._pool = pool
        self._connection = None
        self.reconnect()

    def close(self):
        # The way adbapi works right now means that closing a connection is
        # a really bad thing  as it leaves a dead connection associated with
        # a thread in the thread pool.
        # Really, I think closing a pooled connection should return it to the
        # pool but that's handled by the runWithConnection method already so,
        # rather than upsetting anyone by raising an exception, let's ignore
        # the request
        pass

    def rollback(self):
        if not self._pool.reconnect:
            self._connection.rollback()
            return

        try:
            self._connection.rollback()
            curs = self._connection.cursor()
            curs.execute(self._pool.good_sql)
            curs.close()
            self._connection.commit()
            return
        except:
            log.err(None, "Rollback failed")

        self._pool.disconnect(self._connection)

        if self._pool.noisy:
            log.msg("Connection lost.")

        raise ConnectionLost()

    def reconnect(self):
        if self._connection is not None:
            self._pool.disconnect(self._connection)
        self._connection = self._pool.connect()

    def savePrepared(self, key, cur, extra = None):
        self.delPrepared(key)
        self._pool.prepared[self._connection][key] = (cur, extra)
        if self._pool.noisy:
            cvars, sql = extra
            log.msg('adbapi prepared cursor stored: %s [%d vars]' % (key, len(cvars)))
            log.msg(pprint.pformat(cvars))
            log.msg(pprint.pformat(sql.splitlines()))

    def isPrepared(self, key):
        return key in self._pool.prepared[self._connection]

    def getPrepared(self, key):
        return self._pool.prepared[self._connection].get(key, (None, None))

    def delPrepared(self, key):
        cur, extra = self.getPrepared(key)
        if cur:
            try:
                if self._pool.noisy:
                    log.msg('adbapi prepared cursor closing: %s [%s]' % (key, extra))
                cur.close()
            except:
                log.err(None, "Prepared cursor close failed")
            del self._pool.prepared[self._connection][key]

    def __getattr__(self, name):
        return getattr(self._connection, name)


class Transaction:
    """A lightweight wrapper for a DB-API 'cursor' object.

    Relays attribute access to the DB cursor. That is, you can call
    execute(), fetchall(), etc., and they will be called on the
    underlying DB-API cursor object. Attributes will also be
    retrieved from there.
    """
    _cursor = None

    def __init__(self, pool, connection):
        self._pool = pool
        self._connection = connection
        self.reopen()

    def close(self):
        _cursor = self._cursor
        self._cursor = None
        _cursor.close()

    def reopen(self):
        if self._cursor is not None:
            self.close()

        try:
            self._cursor = self._connection.cursor()
            return
        except:
            if not self._pool.reconnect:
                raise
            else:
                log.err(None, "Cursor creation failed")

        if self._pool.noisy:
            log.msg('Connection lost, reconnecting')

        self.reconnect()
        self._cursor = self._connection.cursor()

    def reconnect(self):
        self._connection.reconnect()
        self._cursor = None

    def __getattr__(self, name):
        return getattr(self._cursor, name)


class ConnectionPool:
    """
    Represent a pool of connections to a DB-API 2.0 compliant database.

    @ivar connectionFactory: factory for connections, default to L{Connection}.
    @type connectionFactory: any callable.

    @ivar transactionFactory: factory for transactions, default to
        L{Transaction}.
    @type transactionFactory: any callable

    @ivar shutdownID: C{None} or a handle on the shutdown event trigger
        which will be used to stop the connection pool workers when the
        reactor stops.

    @ivar _reactor: The reactor which will be used to schedule startup and
        shutdown events.
    @type _reactor: L{IReactorCore} provider
    """

    CP_ARGS = "min max name noisy openfun closefun reconnect good_sql".split()

    noisy = False # if true, generate informational log messages
    min = 3 # minimum number of connections in pool
    max = 5 # maximum number of connections in pool
    name = None # Name to assign to thread pool for debugging
    openfun = None # A function to call on new connections
    closefun = None # A function to call upon connection close
    reconnect = False # reconnect when connections fail
    good_sql = 'select 1' # a query which should always succeed

    running = False # true when the pool is operating
    connectionFactory = Connection
    transactionFactory = Transaction

    # Initialize this to None so it's available in close() even if start()
    # never runs.
    shutdownID = None

    def __init__(self, dbapiName, *connargs, **connkw):
        """Create a new ConnectionPool.

        Any positional or keyword arguments other than those documented here
        are passed to the DB-API object when connecting. Use these arguments to
        pass database names, usernames, passwords, etc.

        @param dbapiName: an import string to use to obtain a DB-API compatible
                          module (e.g. 'pyPgSQL.PgSQL')

        @param cp_min: the minimum number of connections in pool (default 3)

        @param cp_max: the maximum number of connections in pool (default 5)

        @param cp_noisy: generate informational log messages during operation
                         (default False)

        @param cp_openfun: a callback invoked after every connect() on the
                           underlying DB-API object. The callback is passed a
                           new DB-API connection object.  This callback can
                           setup per-connection state such as charset,
                           timezone, etc.

        @param cp_closefun: a callback invoked immediately before close() on the
                           underlying DB-API object. The callback is passed the
                           DB-API connection object that will get closed.

        @param cp_reconnect: detect connections which have failed and reconnect
                             (default False). Failed connections may result in
                             ConnectionLost exceptions, which indicate the
                             query may need to be re-sent.

        @param cp_good_sql: an sql query which should always succeed and change
                            no state (default 'select 1')

        @param cp_reactor: use this reactor instead of the global reactor
            (added in Twisted 10.2).
        @type cp_reactor: L{IReactorCore} provider
        """

        self.dbapiName = dbapiName
        self.dbapi = reflect.namedModule(dbapiName)

        if getattr(self.dbapi, 'apilevel', None) != '2.0':
            log.msg('DB API module not DB API 2.0 compliant.')

        if getattr(self.dbapi, 'threadsafety', 0) < 1:
            log.msg('DB API module not sufficiently thread-safe.')

        reactor = connkw.pop('cp_reactor', None)
        if reactor is None:
            from twisted.internet import reactor
        self._reactor = reactor

        self.connargs = connargs
        self.connkw = connkw

        for arg in self.CP_ARGS:
            cp_arg = 'cp_%s' % arg
            if cp_arg in connkw:
                setattr(self, arg, connkw[cp_arg])
                del connkw[cp_arg]

        self.min = min(self.min, self.max)
        self.max = max(self.min, self.max)

        self.connections = {}  # all connections, hashed on thread id
        self.prepared = {}  # prepared cursor, hashed on connections

        # these are optional so import them here
        from twisted.python import threadpool
        import thread

        self.threadID = thread.get_ident
        self.threadpool = threadpool.ThreadPool(self.min, self.max)
        self.startID = self._reactor.callWhenRunning(self._start)


    def _start(self):
        self.startID = None
        return self.start()


    def start(self):
        """
        Start the connection pool.

        If you are using the reactor normally, this function does *not*
        need to be called.
        """
        if not self.running:
            self.threadpool.start()
            self.shutdownID = self._reactor.addSystemEventTrigger(
                'during', 'shutdown', self.finalClose)
            self.running = True


    def runWithConnection(self, func, *args, **kw):
        """
        Execute a function with a database connection and return the result.

        @param func: A callable object of one argument which will be executed
            in a thread with a connection from the pool.  It will be passed as
            its first argument a L{Connection} instance (whose interface is
            mostly identical to that of a connection object for your DB-API
            module of choice), and its results will be returned as a Deferred.
            If the method raises an exception the transaction will be rolled
            back.  Otherwise, the transaction will be committed.  B{Note} that
            this function is B{not} run in the main thread: it must be
            threadsafe.

        @param *args: positional arguments to be passed to func

        @param **kw: keyword arguments to be passed to func

        @return: a Deferred which will fire the return value of
            C{func(Transaction(...), *args, **kw)}, or a Failure.
        """
        from twisted.internet import reactor
        return threads.deferToThreadPool(reactor, self.threadpool,
                                         self._runWithConnection,
                                         func, *args, **kw)


    def _runWithConnection(self, func, *args, **kw):
        conn = self.connectionFactory(self)
        try:
            result = func(conn, *args, **kw)
            conn.commit()
            return result
        except:
            excType, excValue, excTraceback = sys.exc_info()
            try:
                conn.rollback()
            except:
                log.err(None, "Rollback failed")
            raise excType, excValue, excTraceback


    def runInteraction(self, interaction, *args, **kw):
        """
        Interact with the database and return the result.

        The 'interaction' is a callable object which will be executed
        in a thread using a pooled connection. It will be passed an
        L{Transaction} object as an argument (whose interface is
        identical to that of the database cursor for your DB-API
        module of choice), and its results will be returned as a
        Deferred. If running the method raises an exception, the
        transaction will be rolled back. If the method returns a
        value, the transaction will be committed.

        NOTE that the function you pass is *not* run in the main
        thread: you may have to worry about thread-safety in the
        function you pass to this if it tries to use non-local
        objects.

        @param interaction: a callable object whose first argument
            is an L{adbapi.Transaction}.

        @param *args: additional positional arguments to be passed
            to interaction

        @param **kw: keyword arguments to be passed to interaction

        @return: a Deferred which will fire the return value of
            'interaction(Transaction(...), *args, **kw)', or a Failure.
        """
        from twisted.internet import reactor
        return threads.deferToThreadPool(reactor, self.threadpool,
                                         self._runInteraction,
                                         interaction, *args, **kw)


    def runQuery(self, *args, **kw):
        """Execute an SQL query and return the result.

        A DB-API cursor will will be invoked with cursor.execute(*args, **kw).
        The exact nature of the arguments will depend on the specific flavor
        of DB-API being used, but the first argument in *args be an SQL
        statement. The result of a subsequent cursor.fetchall() will be
        fired to the Deferred which is returned. If either the 'execute' or
        'fetchall' methods raise an exception, the transaction will be rolled
        back and a Failure returned.

        The  *args and **kw arguments will be passed to the DB-API cursor's
        'execute' method.

        @return: a Deferred which will fire the return value of a DB-API
        cursor's 'fetchall' method, or a Failure.
        """
        return self.runInteraction(self._runQuery, *args, **kw)


    def runOperation(self, *args, **kw):
        """Execute an SQL query and return None.

        A DB-API cursor will will be invoked with cursor.execute(*args, **kw).
        The exact nature of the arguments will depend on the specific flavor
        of DB-API being used, but the first argument in *args will be an SQL
        statement. This method will not attempt to fetch any results from the
        query and is thus suitable for INSERT, DELETE, and other SQL statements
        which do not return values. If the 'execute' method raises an
        exception, the transaction will be rolled back and a Failure returned.

        The args and kw arguments will be passed to the DB-API cursor's
        'execute' method.

        return: a Deferred which will fire None or a Failure.
        """
        return self.runInteraction(self._runOperation, *args, **kw)


    def close(self):
        """
        Close all pool connections and shutdown the pool.
        """
        if self.shutdownID:
            self._reactor.removeSystemEventTrigger(self.shutdownID)
            self.shutdownID = None
        if self.startID:
            self._reactor.removeSystemEventTrigger(self.startID)
            self.startID = None
        self.finalClose()

    def finalClose(self):
        """This should only be called by the shutdown trigger."""

        self.shutdownID = None
        self.threadpool.stop()
        self.running = False
        for conn in self.connections.values():
            self._close(conn)
        self.connections.clear()

    def connect(self):
        """Return a database connection when one becomes available.

        This method blocks and should be run in a thread from the internal
        threadpool. Don't call this method directly from non-threaded code.
        Using this method outside the external threadpool may exceed the
        maximum number of connections in the pool.

        @return: a database connection from the pool.
        """

        tid = self.threadID()
        conn = self.connections.get(tid)
        if conn is None:
            if self.noisy:
                log.msg('adbapi connecting: %s %s%s' % (self.dbapiName,
                                                        self.connargs or '',
                                                        self.connkw or ''))
            conn = self.dbapi.connect(*self.connargs, **self.connkw)
            self.connections[tid] = conn
            self.prepared[conn] = {}
            # call openfun at the very end to allow preparing cursors in openfun
            if self.openfun != None:
                self.openfun(conn)
        return conn

    def disconnect(self, conn):
        """Disconnect a database connection associated with this pool.

        Note: This function should only be used by the same thread which
        called connect(). As with connect(), this function is not used
        in normal non-threaded twisted code.
        """
        tid = self.threadID()
        if conn is not self.connections.get(tid):
            raise Exception("wrong connection for thread")
        if conn is not None:
            # call closefun immediately before closing the underlying connection
            if self.closefun != None:
                self.closefun(conn)
            for key in self.prepared[conn]:
                cur, extra = self.prepared[conn][key]
                try:
                    if self.noisy:
                        log.msg('adbapi prepared cursor closing: %s [%s]' % (key, extra))
                    cur.close()
                except:
                    log.err(None, "Prepared cursor close failed")
            self._close(conn)
            del self.prepared[conn]
            del self.connections[tid]


    def delPrepared(self, key):
        """Closes prepared cursors on all connections in the pool for given key.
        """
        for conn in self.connections:
            if key in self.prepared[conn]:
                cur, extra = self.prepared[conn][key]
                if self.noisy:
                    log.msg('adbapi prepared cursor closing: %s [%s]' % (key, extra))
                try:
                    cur.close()
                except:
                    log.err(None, "Prepared cursor close failed")
                del self.prepared[conn][key]


    def _close(self, conn):
        if self.noisy:
            log.msg('adbapi closing: %s' % (self.dbapiName,))
        try:
            conn.close()
        except:
            log.err(None, "Connection close failed")


    def _runInteraction(self, interaction, *args, **kw):
        conn = self.connectionFactory(self)
        trans = self.transactionFactory(self, conn)
        try:
            result = interaction(trans, *args, **kw)
            trans.close()
            conn.commit()
            return result
        except:
            excType, excValue, excTraceback = sys.exc_info()
            try:
                conn.rollback()
            except:
                log.err(None, "Rollback failed")
            raise excType, excValue, excTraceback


    def _runQuery(self, trans, *args, **kw):
        trans.execute(*args, **kw)
        return trans.fetchall()

    def _runOperation(self, trans, *args, **kw):
        trans.execute(*args, **kw)

    def __getstate__(self):
        return {'dbapiName': self.dbapiName,
                'min': self.min,
                'max': self.max,
                'noisy': self.noisy,
                'reconnect': self.reconnect,
                'good_sql': self.good_sql,
                'connargs': self.connargs,
                'connkw': self.connkw}

    def __setstate__(self, state):
        self.__dict__ = state
        self.__init__(self.dbapiName, *self.connargs, **self.connkw)


__all__ = ['Transaction', 'ConnectionPool']

########NEW FILE########
__FILENAME__ = appcreds
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class AppCreds:
   """
   Application credentials model.
   """

   APPCRED_KEY_PATTERN = "^[a-z0-9_\-]*$"
   APPCRED_KEY_MIN_LENGTH = 3
   APPCRED_KEY_MAX_LENGTH = 15

   APPCRED_SECRET_PATTERN = "^[a-zA-Z0-9_\-!$%&/=]*$"
   APPCRED_SECRET_MIN_LENGTH = 6
   APPCRED_SECRET_MAX_LENGTH = 20

   APPCRED_LABEL_MIN_LENGTH = 3
   APPCRED_LABEL_MAX_LENGTH = 20


   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _createAppCred(self, txn, spec):
      """
      Create new application credential, runs in database transaction.
      """
      attrs = {"label": (True,
                         [str, unicode],
                         AppCreds.APPCRED_LABEL_MIN_LENGTH,
                         AppCreds.APPCRED_LABEL_MAX_LENGTH,
                         None),
               "key": (True,
                       [str, unicode],
                       AppCreds.APPCRED_KEY_MIN_LENGTH,
                       AppCreds.APPCRED_KEY_MAX_LENGTH,
                       AppCreds.APPCRED_KEY_PATTERN),
               "secret": (True,
                          [str, unicode],
                          AppCreds.APPCRED_SECRET_MIN_LENGTH,
                          AppCreds.APPCRED_SECRET_MAX_LENGTH,
                          AppCreds.APPCRED_SECRET_PATTERN)}

      errcnt, errs = self.proto.checkDictArg("appcred spec", spec, attrs)

      txn.execute("SELECT created FROM appcredential WHERE key = ?", [spec["key"]])
      if txn.fetchone() is not None:
         errs["key"].append((self.proto.shrink(URI_ERROR + "duplicate-value"), "Application key '%s' already exists" % spec["key"]))
         errcnt += 1

      if errcnt:
         raise Exception(URI_ERROR + "illegal-argument", "one or more illegal arguments (%d errors)" % errcnt, errs)

      id = newid()
      appcred_uri = URI_APPCRED + id
      label = spec["label"].strip()
      now = utcnow()
      txn.execute("INSERT INTO appcredential (id, label, key, created, secret) VALUES (?, ?, ?, ?, ?)",
                  [id,
                   label,
                   spec["key"],
                   now,
                   spec["secret"]])

      services = self.proto.factory.services
      if services.has_key("restpusher"):
         services["restpusher"].recache(txn)
      if services.has_key("clientfilter"):
         services["clientfilter"].recache(txn)

      appcred = {"uri": appcred_uri,
                 "created": now,
                 "label": label,
                 "key": spec["key"],
                 "secret": spec["secret"]}

      self.proto.dispatch(URI_EVENT + "on-appcred-created", appcred, [self.proto])

      appcred["uri"] = self.proto.shrink(appcred_uri)
      return appcred


   @exportRpc("create-appcred")
   def createAppCred(self, spec):
      """
      Create new application credential.

      Parameters:

         spec:             Application credential specification, a dictionary.
         spec[]
            label:         Label, a string, not necessarily unique.
            key:           Key, a string, must be unique.
            secret:        Secret, a string.

      Result:

         {"uri":        <Appcred URI>,
          "created":    <Appcred creation timestamp>,
          "label":      <Appcred label>,
          "key":        <Appcred key>,
          "secret":     <Appcred secret>}

      Events:

         on-appcred-created

      Errors:

         spec:                   illegal-argument

         spec[]:

            *:                   illegal-attribute-type,
                                 missing-attribute

            label,
            key,
            secret:              attribute-value-too-short,
                                 attribute-value-too-long

            key,
            secret:              attribute-value-invalid-characters

            key:                 duplicate-value

            ?:                   unknown-attribute
      """
      return self.proto.dbpool.runInteraction(self._createAppCred, spec)


   def _deleteAppCred(self, txn, appCredUri, cascade):

      ## check arguments
      ##
      if type(appCredUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument appCredUri, but got %s" % str(type(appCredUri)))

      if type(cascade) not in [bool]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type bool for agument cascade, but got %s" % str(type(cascade)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(appCredUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM appcredential WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check for depending pgremotes
         ##
         txn.execute("SELECT id FROM pgremote WHERE require_appcred_id = ?", [id])
         dependingPgRemotes = []
         for r in txn.fetchall():
            dependingPgRemotes.append(r[0])

         ## check for depending oraremotes
         ##
         txn.execute("SELECT id FROM oraremote WHERE require_appcred_id = ?", [id])
         dependingOraRemotes = []
         for r in txn.fetchall():
            dependingOraRemotes.append(r[0])

         ## check for depending hanaremotes
         ##
         txn.execute("SELECT id FROM hanaremote WHERE require_appcred_id = ?", [id])
         dependingHanaRemotes = []
         for r in txn.fetchall():
            dependingHanaRemotes.append(r[0])

         ## check for depending postrules
         ##
         txn.execute("SELECT id FROM postrule WHERE require_appcred_id = ?", [id])
         dependingPostrules = []
         for r in txn.fetchall():
            dependingPostrules.append(r[0])

         ## check for depending clientperms
         ##
         txn.execute("SELECT id FROM clientperm WHERE require_appcred_id = ?", [id])
         dependingClientperms = []
         for r in txn.fetchall():
            dependingClientperms.append(r[0])

         ## delete depending objects and object
         ##
         if len(dependingPostrules) > 0 or len(dependingClientperms) > 0 or len(dependingPgRemotes) > 0:
            if not cascade:
               raise Exception(URI_ERROR + "depending-objects",
                               "Cannot delete application credential: %d depending postules, %d depending clientperms, %d depending PG remotes" % (len(dependingPostrules), len(dependingClientperms), len(dependingPgRemotes)),
                               ([self.proto.shrink(URI_POSTRULE + id) for id in dependingPostrules],
                                [self.proto.shrink(URI_CLIENTPERM + id) for id in dependingClientperms],
                                [self.proto.shrink(URI_PGREMOTE + id) for id in dependingPgRemotes]))
            else:
               if len(dependingPostrules) > 0:
                  txn.execute("DELETE FROM postrule WHERE require_appcred_id = ?", [id])
               if len(dependingClientperms) > 0:
                  txn.execute("DELETE FROM clientperm WHERE require_appcred_id = ?", [id])

               if len(dependingPgRemotes) > 0:
                  txn.execute("DELETE FROM pgremote WHERE require_appcred_id = ?", [id])
               if len(dependingOraRemotes) > 0:
                  txn.execute("DELETE FROM oraremote WHERE require_appcred_id = ?", [id])
               if len(dependingHanaRemotes) > 0:
                  txn.execute("DELETE FROM hanaremote WHERE require_appcred_id = ?", [id])

         txn.execute("DELETE FROM appcredential WHERE id = ?", [id])

         ## recache in services if necessary
         ##
         services = self.proto.factory.services
         if services.has_key("restpusher"):
            services["restpusher"].recache(txn)
         if services.has_key("clientfilter"):
            services["clientfilter"].recache(txn)

         if len(dependingPgRemotes) > 0 and services.has_key("pgremoter"):
            services["pgremoter"].recache(txn)
         if len(dependingOraRemotes) > 0 and services.has_key("oraremoter"):
            services["oraremoter"].recache(txn)
         if len(dependingHanaRemotes) > 0 and services.has_key("hanaremoter"):
            services["hanaremoter"].recache(txn)

         ## dispatch on-deleted events
         ##
         for id in dependingPostrules:
            self.proto.dispatch(URI_EVENT + "on-postrule-deleted", URI_POSTRULE + id, [])

         for id in dependingClientperms:
            self.proto.dispatch(URI_EVENT + "on-clientperm-deleted", URI_CLIENTPERM + id, [])

         for id in dependingPgRemotes:
            self.proto.dispatch(URI_EVENT + "on-pgremote-deleted", URI_PGREMOTE + id, [])

         for id in dependingOraRemotes:
            self.proto.dispatch(URI_EVENT + "on-oraremote-deleted", URI_ORAREMOTE + id, [])

         for id in dependingHanaRemotes:
            self.proto.dispatch(URI_EVENT + "on-hanaremote-deleted", URI_HANAREMOTE + id, [])

         self.proto.dispatch(URI_EVENT + "on-appcred-deleted", uri, [self.proto])

         ## return deleted object URI
         ##
         return self.proto.shrink(uri)

      else:
         raise Exception(URI_ERROR + "no-such-object", "No application credentials with URI %s" % uri)


   @exportRpc("delete-appcred")
   def deleteAppCred(self, appCredUri, cascade = False):
      """
      Delete application credential, and optionally delete all depending objects.

      Parameters:

         appCredUri:          URI or CURIE of application credential to modify.
         cascade:             True/False to cascade the delete to depending post-/client rules.

      Result:

         <Application credential URI>

      Events:

         on-appcred-deleted
         on-postrule-deleted

      Errors:

         appCredUri,
         cascade:                illegal-argument

         appCredUri:             no-such-object,
                                 depending-objects
      """
      return self.proto.dbpool.runInteraction(self._deleteAppCred, appCredUri, cascade)


   def _modifyAppCred(self, txn, appCredUri, specDelta):

      ## check arguments
      ##
      if type(appCredUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument appCredUri, but got %s" % str(type(appCredUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(appCredUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT label, key, secret FROM appcredential WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check arguments
         ##
         attrs = {"label": (False,
                            [str, unicode],
                            AppCreds.APPCRED_LABEL_MIN_LENGTH,
                            AppCreds.APPCRED_LABEL_MAX_LENGTH,
                            None),
                  "key": (False,
                          [str, unicode],
                          AppCreds.APPCRED_KEY_MIN_LENGTH,
                          AppCreds.APPCRED_KEY_MAX_LENGTH,
                          AppCreds.APPCRED_KEY_PATTERN),
                  "secret": (False,
                             [str, unicode],
                             AppCreds.APPCRED_SECRET_MIN_LENGTH,
                             AppCreds.APPCRED_SECRET_MAX_LENGTH,
                             AppCreds.APPCRED_SECRET_PATTERN)}

         errcnt, errs = self.proto.checkDictArg("appcred delta spec", specDelta, attrs)

         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("label"):
            newval = specDelta["label"].strip()
            if newval != res[0]:
               delta["label"] = newval
               sql += ", label = ?"
               sql_vars.append(newval)

         if specDelta.has_key("key"):
            newval = specDelta["key"]
            if newval != res[1]:
               txn.execute("SELECT created FROM appcredential WHERE key = ?", [newval])
               if txn.fetchone() is not None:
                  errs["key"].append((self.proto.shrink(URI_ERROR + "duplicate-value"), "application key '%s' already exists" % newval))
               delta["key"] = newval
               sql += ", key = ?"
               sql_vars.append(newval)

         if specDelta.has_key("secret"):
            newval = specDelta["secret"]
            if newval != res[2]:
               delta["secret"] = newval
               sql += ", secret = ?"
               sql_vars.append(newval)

         if errcnt:
            raise Exception(URI_ERROR + "illegal-argument", "one or more illegal arguments (%d errors)" % errcnt, errs)

         ## proceed when there is an actual change in data
         ##
         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE appcredential SET %s WHERE id = ?" % sql, sql_vars)

            ## recache in services if necessary
            ##
            services = self.proto.factory.services
            if services.has_key("restpusher"):
               services["restpusher"].recache(txn)
            if services.has_key("clientfilter"):
               services["clientfilter"].recache(txn)

            ## database remoters only care about "key" field
            if delta.has_key("key"):
               if services.has_key("pgremoter"):
                  services["pgremoter"].recache(txn)
               if services.has_key("oraremoter"):
                  services["oraremoter"].recache(txn)
               if services.has_key("hanaremoter"):
                  services["hanaremoter"].recache(txn)

            ## dispatch on-modified events
            ##
            self.proto.dispatch(URI_EVENT + "on-appcred-modified", delta, [self.proto])

            ## return object delta
            ##
            delta["uri"] = self.proto.shrink(uri)
            return delta
         else:
            ## object unchanged
            ##
            return {}

      else:
         raise Exception(URI_ERROR + "no-such-object", "No application credentials with URI %s" % uri)


   @exportRpc("modify-appcred")
   def modifyAppCred(self, appCredUri, specDelta):
      """
      Modify existing application credential.

      Parameters:

         appCredUri:          URI or CURIE of application credential to modify.
         specDelta:           Application credential change specification, a dictionary.
         specDelta[]:
            label:            Label, a string, not necessarily unique.
            key:              Key, a string, must be unique.
            secret:           Secret, a string.

      Result:

         {"uri":           <Appcred URI>,
          "modified":      <Appcred modification timestamp>,
          "label":         <Appcred label>,
          "key":           <Appcred key>,
          "secret":        <Appcred secret>}

      Events:

         on-appcred-modified

      Errors:

         appCredUri,
         specDelta:              illegal-argument

         appCredUri:             no-such-object

         specDelta[]:

            *:                   illegal-attribute-type,
                                 missing-attribute

            label,
            key,
            secret:              attribute-value-too-short,
                                 attribute-value-too-long

            key,
            secret:              attribute-value-invalid-characters

            key:                 duplicate-value

            ?:                   unknown-attribute
      """
      return self.proto.dbpool.runInteraction(self._modifyAppCred, appCredUri, specDelta)


   @exportRpc("get-appcreds")
   def getAppCreds(self):
      """
      Return list of application credentials (ordered by label/key ascending).
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, label, key, secret FROM appcredential ORDER BY label, key ASC")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_APPCRED + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "label": r[3],
                                  "key": r[4],
                                  "secret": r[5]} for r in res])
      return d

########NEW FILE########
__FILENAME__ = clientperms
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class ClientPerms:
   """
   Client permissions model.
   """

   DOCNAME = "Client Permissions"

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def checkClientPermSpec(self, spec, specDelta, errs):

      ## default client permission flags
      ##
      flags = ["allow-publish", "allow-subscribe"]

      ## check that at least one of the flags is True (after an update with spec)
      ##
      flags_current = {}
      any = False
      for f in flags:
         if errs[f]:
            return 0
         if specDelta.has_key(f):
            flags_current[f] = specDelta[f]
         else:
            flags_current[f] = spec[f]
         any = any or flags_current[f]
      errcnt = 0
      if not any:
         for f in flags:
            if specDelta.has_key(f):
               errs[f].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"), "At least on of allow-* must be true"))
               errcnt += 2

      return errcnt


   def _createClientPerm(self, txn, spec):

      attrs = {"topic-uri": (True, [str, unicode], 0, URI_MAXLEN),
               "match-by-prefix": (True, [bool]),
               "filter-expression": (False, [str, unicode, types.NoneType], 0, 2000),
               "allow-publish": (True, [bool]),
               "allow-subscribe": (True, [bool]),
               "require-appcred-uri": (False, [str, unicode, types.NoneType])}

      errcnt, errs = self.proto.checkDictArg("clientperm spec", spec, attrs)

      if not errs["topic-uri"]:
         topic_uri, errs2 = self.proto.validateUri(spec["topic-uri"])
         errs["topic-uri"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and spec.has_key("require-appcred-uri"):
         if spec["require-appcred-uri"] == "null" or spec["require-appcred-uri"] == "":
            spec["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if spec.has_key("require-appcred-uri") and spec["require-appcred-uri"] is not None and spec["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(spec["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      filter_expr = None
      if spec.has_key("filter-expression") and spec["filter-expression"] is not None and spec["filter-expression"].strip() != "":
         filter_expr = spec["filter-expression"].strip()

      errcnt += self.checkClientPermSpec({}, spec, errs)

      self.proto.raiseDictArgException(errs)

      id = newid()
      clientperm_uri = URI_CLIENTPERM + id
      now = utcnow()

      txn.execute("INSERT INTO clientperm (id, created, topic_uri, match_by_prefix, require_appcred_id, filter_expr, allow_publish, allow_subscribe) VALUES (?, ?, ?, ?, ?, ?, ?, ?)",
                                       [id,
                                        now,
                                        topic_uri,
                                        int(spec["match-by-prefix"]),
                                        appcred_id,
                                        filter_expr,
                                        int(spec["allow-publish"]),
                                        int(spec["allow-subscribe"])
                                        ])

      services = self.proto.factory.services
      if services.has_key("clientfilter"):
         self.proto.factory.services["clientfilter"].recache(txn)

      clientperm = {"uri": clientperm_uri,
                    "topic-uri": topic_uri,
                    "match-by-prefix": spec["match-by-prefix"],
                    "require-appcred-uri": appcred_uri,
                    "filter-expression": filter_expr,
                    "allow-publish": spec["allow-publish"],
                    "allow-subscribe": spec["allow-subscribe"]}

      self.proto.dispatch(URI_EVENT + "on-clientperm-created", clientperm, [self.proto])

      clientperm["uri"] = self.proto.shrink(clientperm_uri)
      if clientperm["require-appcred-uri"] is not None:
         clientperm["require-appcred-uri"] = self.proto.shrink(appcred_uri)
      return clientperm


   @exportRpc("create-clientperm")
   def createClientPerm(self, spec):
      return self.proto.dbpool.runInteraction(self._createClientPerm, spec)


   def _modifyClientPerm(self, txn, clientPermUri, specDelta):

      if type(clientPermUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument clientPermUri, but got %s" % str(type(clientPermUri)))

      attrs = {"topic-uri": (False, [str, unicode], 0, URI_MAXLEN),
               "match-by-prefix": (False, [bool]),
               "filter-expression": (False, [str, unicode], 0, 2000),
               "allow-publish": (False, [bool]),
               "allow-subscribe": (False, [bool]),
               "require-appcred-uri": (False, [str, unicode, types.NoneType])}

      errcnt, errs = self.proto.checkDictArg("clientperm delta spec", specDelta, attrs)

      if not errs["topic-uri"] and specDelta.has_key("topic-uri"):
         normalizedUri, errs2 = self.proto.validateUri(specDelta["topic-uri"])
         errs["topic-uri"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and specDelta.has_key("require-appcred-uri"):
         if specDelta["require-appcred-uri"] == "null" or specDelta["require-appcred-uri"] == "":
            specDelta["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if specDelta.has_key("require-appcred-uri") and specDelta["require-appcred-uri"] is not None and specDelta["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(specDelta["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      uri = self.proto.resolveOrPass(clientPermUri)
      id = self.proto.uriToId(uri)
      txn.execute("SELECT topic_uri, match_by_prefix, filter_expr, require_appcred_id, allow_publish, allow_subscribe FROM clientperm WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         spec = {}
         spec["topic-uri"] = res[0]
         spec["match-by-prefix"] = res[1] != 0
         spec["filter-expression"] = res[2]
         spec["require-appcred-uri"] = self.proto.shrink(URI_APPCRED + res[3]) if res[3] else None
         spec["allow-publish"] = res[4] != 0
         spec["allow-subscribe"] = res[5] != 0

         errcnt += self.checkClientPermSpec(spec, specDelta, errs)

         self.proto.raiseDictArgException(errs)

         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("topic-uri"): # and specDelta["topic-uri"] is not None:
            #newval = self.proto.resolveOrPass(specDelta["topic-uri"].strip())
            newval = normalizedUri
            if newval != "" and newval != res[0]:
               delta["topic-uri"] = newval
               sql += ", topic_uri = ?"
               sql_vars.append(newval)

         if specDelta.has_key("match-by-prefix"): # and specDelta["match-by-prefix"] is not None:
            newval = specDelta["match-by-prefix"]
            if newval != (res[1] != 0):
               delta["match-by-prefix"] = newval
               sql += ", match_by_prefix = ?"
               sql_vars.append(newval)

         if specDelta.has_key("filter-expression"): # and specDelta["filter-expression"] is not None:
            newval = specDelta["filter-expression"]
            if newval != res[2]:
               delta["filter-expression"] = newval
               sql += ", filter_expr = ?"
               sql_vars.append(newval)

#         if specDelta.has_key("require-appcred-uri") and specDelta["require-appcred-uri"] is not None and specDelta["require-appcred-uri"].strip() != "":
         if specDelta.has_key("require-appcred-uri"):
            if appcred_id != res[3]:
               delta["require-appcred-uri"] = appcred_uri
               sql += ", require_appcred_id = ?"
               sql_vars.append(appcred_id)

         if specDelta.has_key("allow-publish"): # and specDelta["allow-publish"] is not None:
            newval = specDelta["allow-publish"]
            if newval != (res[4] != 0):
               delta["allow-publish"] = newval
               sql += ", allow_publish = ?"
               sql_vars.append(newval)

         if specDelta.has_key("allow-subscribe"): # and specDelta["allow-subscribe"] is not None:
            newval = specDelta["allow-subscribe"]
            if newval != (res[5] != 0):
               delta["allow-subscribe"] = newval
               sql += ", allow_subscribe = ?"
               sql_vars.append(newval)

         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE clientperm SET %s WHERE id = ?" % sql, sql_vars)

            services = self.proto.factory.services
            if services.has_key("clientfilter"):
               services["clientfilter"].recache(txn)

            self.proto.dispatch(URI_EVENT + "on-clientperm-modified", delta, [self.proto])

            delta["uri"] = self.proto.shrink(uri)
            if delta.has_key("require-appcred-uri") and delta["require-appcred-uri"] is not None:
               delta["require-appcred-uri"] = self.proto.shrink(appcred_uri)
            return delta
         else:
            return {}
      else:
         raise Exception(URI_ERROR + "no-such-object", "No client permission with URI %s" % uri)


   @exportRpc("modify-clientperm")
   def modifyClientPerm(self, clientPermUri, specDelta):
      return self.proto.dbpool.runInteraction(self._modifyClientPerm, clientPermUri, specDelta)


   def _deleteClientPerm(self, txn, clientPermUri):

      if type(clientPermUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument clientPermUri, but got %s" % str(type(clientPermUri)))

      uri = self.proto.resolveOrPass(clientPermUri)
      id = self.proto.uriToId(uri)
      txn.execute("SELECT created FROM clientperm WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         txn.execute("DELETE FROM clientperm WHERE id = ?", [id])

         services = self.proto.factory.services
         if services.has_key("clientfilter"):
            services["clientfilter"].recache(txn)

         self.proto.dispatch(URI_EVENT + "on-clientperm-deleted", uri, [self.proto])

         return self.proto.shrink(uri)
      else:
         raise Exception(URI_ERROR + "no-such-object", "No client permission with URI %s" % uri)


   @exportRpc("delete-clientperm")
   def deleteClientPerm(self, clientPermUri):
      return self.proto.dbpool.runInteraction(self._deleteClientPerm, clientPermUri)


   @exportRpc("get-clientperms")
   def getClientPerms(self):
      """
      Return client permissions list.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, topic_uri, match_by_prefix, require_appcred_id, filter_expr, allow_publish, allow_subscribe FROM clientperm ORDER BY LENGTH(topic_uri) ASC, topic_uri")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_CLIENTPERM + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "topic-uri": r[3],
                                  "match-by-prefix": r[4] != 0,
                                  "require-appcred-uri": self.proto.shrink(URI_APPCRED + r[5]) if r[5] else None,
                                  "filter-expression": r[6],
                                  "allow-publish": r[7] != 0,
                                  "allow-subscribe": r[8] != 0} for r in res])
      return d

########NEW FILE########
__FILENAME__ = extdirectremotes
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class ExtDirectRemotes:
   """
   Ext.Direct Remotes model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def checkExtDirectRemotePermSpec(self, spec, specDelta, errs):
      return 0


   def _createExtDirectRemote(self, txn, spec):

      attrs = {"rpc-base-uri": (True, [str, unicode], 0, URI_MAXLEN),
               "router-url": (True, [str, unicode], 0, URI_MAXLEN),
               "api-url": (True, [str, unicode], 0, URI_MAXLEN),
               "api-object": (True, [str, unicode], 0, 100),
               "forward-cookies": (True, [bool]),
               "redirect-limit": (True, [int], 0, 10),
               "connection-timeout": (True, [int], 0, 120),
               "request-timeout": (True, [int], 0, 120),
               "max-persistent-connections": (True, [int], 0, 1000),
               "persistent-connection-timeout": (True, [int], 0, 60 * 60),
               "require-appcred-uri": (False, [str, unicode, types.NoneType])}

      errcnt, errs = self.proto.checkDictArg("extdirectremote spec", spec, attrs)

      if not errs["rpc-base-uri"]:
         rpcBaseUri, errs2 = self.proto.validateUri(spec["rpc-base-uri"])
         errs["rpc-base-uri"].extend(errs2)
         errcnt += len(errs2)

      if not errs["router-url"]:
         routerUrl, errs2 = self.proto.validateUri(spec["router-url"])
         errs["router-url"].extend(errs2)
         errcnt += len(errs2)

      if not errs["api-url"]:
         apiUrl, errs2 = self.proto.validateUri(spec["api-url"])
         errs["api-url"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and spec.has_key("require-appcred-uri"):
         if spec["require-appcred-uri"] == "null" or spec["require-appcred-uri"] == "":
            spec["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if spec.has_key("require-appcred-uri") and spec["require-appcred-uri"] is not None and spec["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(spec["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      errcnt += self.checkExtDirectRemotePermSpec({}, spec, errs)

      self.proto.raiseDictArgException(errs)

      id = newid()
      extdirectremote_uri = URI_EXTDIRECTREMOTE + id
      now = utcnow()

      txn.execute("INSERT INTO extdirectremote (id, created, require_appcred_id, rpc_base_uri, router_url, api_url, api_object, forward_cookies, redirect_limit, connection_timeout, request_timeout, max_persistent_conns, persistent_conn_timeout) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                                       [id,
                                        now,
                                        appcred_id,
                                        rpcBaseUri,
                                        routerUrl,
                                        apiUrl,
                                        spec["api-object"],
                                        spec["forward-cookies"],
                                        int(spec["redirect-limit"]),
                                        int(spec["connection-timeout"]),
                                        int(spec["request-timeout"]),
                                        int(spec["max-persistent-connections"]),
                                        int(spec["persistent-connection-timeout"])
                                        ])

      services = self.proto.factory.services
      if services.has_key("extdirectremoter"):
         services["extdirectremoter"].recache(txn)

      extdirectremote = {"uri": extdirectremote_uri,
                         "require-appcred-uri": appcred_uri,
                         "rpc-base-uri": rpcBaseUri,
                         "router-url": routerUrl,
                         "api-url": apiUrl,
                         "api-object": spec["api-object"],
                         "forward-cookies": spec["forward-cookies"],
                         "redirect-limit": int(spec["redirect-limit"]),
                         "connection-timeout": int(spec["connection-timeout"]),
                         "request-timeout": int(spec["request-timeout"]),
                         "max-persistent-connections": int(spec["max-persistent-connections"]),
                         "persistent-connection-timeout": int(spec["persistent-connection-timeout"])}

      self.proto.dispatch(URI_EVENT + "on-extdirectremote-created", extdirectremote, [self.proto])

      extdirectremote["uri"] = self.proto.shrink(extdirectremote_uri)
      if extdirectremote["require-appcred-uri"] is not None:
         extdirectremote["require-appcred-uri"] = self.proto.shrink(appcred_uri)
      return extdirectremote


   @exportRpc("create-extdirectremote")
   def createExtDirectRemote(self, spec):
      return self.proto.dbpool.runInteraction(self._createExtDirectRemote, spec)


   def _modifyExtDirectRemote(self, txn, extDirectUri, specDelta):

      if type(extDirectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument extDirectUri, but got %s" % str(type(extDirectUri)))

      attrs = {"rpc-base-uri": (False, [str, unicode], 0, URI_MAXLEN),
               "router-url": (False, [str, unicode], 0, URI_MAXLEN),
               "api-url": (False, [str, unicode], 0, URI_MAXLEN),
               "api-object": (False, [str, unicode], 0, 100),
               "forward-cookies": (False, [bool]),
               "redirect-limit": (False, [int], 0, 10),
               "connection-timeout": (False, [int], 0, 120),
               "request-timeout": (False, [int], 0, 120),
               "max-persistent-connections": (False, [int], 0, 1000),
               "persistent-connection-timeout": (False, [int], 0, 60 * 60),
               "require-appcred-uri": (False, [str, unicode, types.NoneType])}

      errcnt, errs = self.proto.checkDictArg("extdirectremote delta spec", specDelta, attrs)

      if not errs["rpc-base-uri"] and specDelta.has_key("rpc-base-uri"):
         rpcBaseUri, errs2 = self.proto.validateUri(specDelta["rpc-base-uri"])
         errs["rpc-base-uri"].extend(errs2)
         errcnt += len(errs2)

      if not errs["router-url"] and specDelta.has_key("router-url"):
         routerUrl, errs2 = self.proto.validateUri(specDelta["router-url"])
         errs["router-url"].extend(errs2)
         errcnt += len(errs2)

      if not errs["api-url"] and specDelta.has_key("api-url"):
         apiUrl, errs2 = self.proto.validateUri(specDelta["api-url"])
         errs["api-url"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and specDelta.has_key("require-appcred-uri"):
         if specDelta["require-appcred-uri"] == "null" or specDelta["require-appcred-uri"] == "":
            specDelta["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if specDelta.has_key("require-appcred-uri") and specDelta["require-appcred-uri"] is not None and specDelta["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(specDelta["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      uri = self.proto.resolveOrPass(extDirectUri)
      id = self.proto.uriToId(uri)
      txn.execute("SELECT require_appcred_id, rpc_base_uri, router_url, api_url, api_object, forward_cookies, redirect_limit, connection_timeout, request_timeout, max_persistent_conns, persistent_conn_timeout FROM extdirectremote WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         spec = {}
         spec["require-appcred-uri"] = self.proto.shrink(URI_APPCRED + res[0]) if res[0] else None
         spec["rpc-base-uri"] = res[1]
         spec["router-url"] = res[2]
         spec["api-url"] = res[3]
         spec["api-object"] = res[4]
         spec["forward-cookies"] = res[5] != 0
         spec["redirect-limit"] = res[6]
         spec["connection-timeout"] = res[7]
         spec["request-timeout"] = res[8]
         spec["max-persistent-connections"] = res[9]
         spec["persistent-connection-timeout"] = res[10]

         errcnt += self.checkExtDirectRemotePermSpec(spec, specDelta, errs)

         self.proto.raiseDictArgException(errs)

         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("require-appcred-uri"):
            if appcred_id != res[0]:
               delta["require-appcred-uri"] = appcred_uri
               sql += ", require_appcred_id = ?"
               sql_vars.append(appcred_id)

         if specDelta.has_key("rpc-base-uri"):
            newval = rpcBaseUri
            if newval != "" and newval != res[1]:
               delta["rpc-base-uri"] = newval
               sql += ", rpc_base_uri = ?"
               sql_vars.append(newval)

         if specDelta.has_key("router-url"):
            newval = routerUrl
            if newval != "" and newval != res[2]:
               delta["router-url"] = newval
               sql += ", router_url = ?"
               sql_vars.append(newval)

         if specDelta.has_key("api-url"):
            newval = apiUrl
            if newval != "" and newval != res[3]:
               delta["api-url"] = newval
               sql += ", api_url = ?"
               sql_vars.append(newval)

         if specDelta.has_key("api-object"):
            newval = specDelta["api-object"]
            if newval != "" and newval != res[4]:
               delta["api-object"] = newval
               sql += ", api_object = ?"
               sql_vars.append(newval)

         if specDelta.has_key("forward-cookies"):
            newval = specDelta["forward-cookies"]
            if newval != (res[5] != 0):
               delta["forward-cookies"] = newval
               sql += ", forward_cookies = ?"
               sql_vars.append(newval)

         if specDelta.has_key("redirect-limit"):
            newval = specDelta["redirect-limit"]
            if newval != res[6]:
               delta["redirect-limit"] = newval
               sql += ", redirect_limit = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-timeout"):
            newval = specDelta["connection-timeout"]
            if newval != res[7]:
               delta["connection-timeout"] = newval
               sql += ", connection_timeout = ?"
               sql_vars.append(newval)

         if specDelta.has_key("request-timeout"):
            newval = specDelta["request-timeout"]
            if newval != res[8]:
               delta["request-timeout"] = newval
               sql += ", request_timeout = ?"
               sql_vars.append(newval)

         if specDelta.has_key("max-persistent-connections"):
            newval = specDelta["max-persistent-connections"]
            if newval != res[9]:
               delta["max-persistent-connections"] = newval
               sql += ", max_persistent_conns = ?"
               sql_vars.append(newval)

         if specDelta.has_key("persistent-connection-timeout"):
            newval = specDelta["persistent-connection-timeout"]
            if newval != res[10]:
               delta["persistent-connection-timeout"] = newval
               sql += ", persistent_conn_timeout = ?"
               sql_vars.append(newval)

         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE extdirectremote SET %s WHERE id = ?" % sql, sql_vars)

            services = self.proto.factory.services
            if services.has_key("extdirectremoter"):
               services["extdirectremoter"].recache(txn)

            self.proto.dispatch(URI_EVENT + "on-extdirectremote-modified", delta, [self.proto])

            delta["uri"] = self.proto.shrink(uri)
            if delta.has_key("require-appcred-uri") and delta["require-appcred-uri"] is not None:
               delta["require-appcred-uri"] = self.proto.shrink(appcred_uri)
            return delta
         else:
            return {}
      else:
         raise Exception(URI_ERROR + "no-such-object", "No Ext.Direct remote with URI %s" % uri)


   @exportRpc("modify-extdirectremote")
   def modifyExtDirectRemote(self, extDirectUri, specDelta):
      return self.proto.dbpool.runInteraction(self._modifyExtDirectRemote, extDirectUri, specDelta)


   def _deleteExtDirectRemote(self, txn, extDirectUri):

      if type(extDirectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument extDirectUri, but got %s" % str(type(extDirectUri)))

      uri = self.proto.resolveOrPass(extDirectUri)
      id = self.proto.uriToId(uri)
      txn.execute("SELECT created FROM extdirectremote WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         txn.execute("DELETE FROM extdirectremote WHERE id = ?", [id])

         services = self.proto.factory.services
         if services.has_key("extdirectremoter"):
            services["extdirectremoter"].recache(txn)

         self.proto.dispatch(URI_EVENT + "on-extdirectremote-deleted", uri, [self.proto])

         return self.proto.shrink(uri)
      else:
         raise Exception(URI_ERROR + "no-such-object", "No Ext.Direct remote with URI %s" % uri)


   @exportRpc("delete-extdirectremote")
   def deleteExtDirectRemote(self, extDirectUri):
      """
      Delete an Ext.Direct remote.
      """
      return self.proto.dbpool.runInteraction(self._deleteExtDirectRemote, extDirectUri)


   @exportRpc("get-extdirectremotes")
   def getExtDirectRemotes(self):
      """
      Return Ext.Direct remotes list.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, require_appcred_id, rpc_base_uri, router_url, api_url, api_object, forward_cookies, redirect_limit, connection_timeout, request_timeout, max_persistent_conns, persistent_conn_timeout FROM extdirectremote ORDER BY require_appcred_id, rpc_base_uri, created")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_EXTDIRECTREMOTE + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "require-appcred-uri": self.proto.shrink(URI_APPCRED + r[3]) if r[3] else None,
                                  "rpc-base-uri": r[4],
                                  "router-url": r[5],
                                  "api-url": r[6],
                                  "api-object": r[7],
                                  "forward-cookies": r[8] != 0,
                                  "redirect-limit": r[9],
                                  "connection-timeout": r[10],
                                  "request-timeout": r[11],
                                  "max-persistent-connections": r[12],
                                  "persistent-connection-timeout": r[13]} for r in res])
      return d


   def _getExtDirectApiSorted(self, res):
      r = []
      for k in sorted(res.keys()):
         rr = res[k]
         r.append((k, rr[1], rr[2], rr[3]))
      return r


   @exportRpc("query-extdirectapi")
   def queryExtDirectApi(self, extDirectUri):

      if type(extDirectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument extDirectUri, but got %s" % str(type(extDirectUri)))

      uri = self.proto.resolveOrPass(extDirectUri)
      id = self.proto.uriToId(uri)
      d = self.proto.factory.services["extdirectremoter"].queryApi(id)
      if d:
         d.addCallback(self._getExtDirectApiSorted)
         return d
      else:
         raise Exception(URI_ERROR + "no-such-object", "No Ext.Direct remote with URI %s" % uri)


   @exportRpc("query-extdirectapi-by-appkey")
   def queryExtDirectApiByAppKey(self, appkey):
      return self.proto.factory.services["extdirectremoter"].getRemotes(appkey)

########NEW FILE########
__FILENAME__ = ftpusers
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import os, shutil, sys

from twisted.python import log

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class FtpUsers:
   """
   FTP users model.
   """

   FTPUSER_USER_PATTERN = "^[a-z0-9_\-]*$"
   FTPUSER_USER_MIN_LENGTH = 3
   FTPUSER_USER_MAX_LENGTH = 15

   FTPUSER_PASSWORD_PATTERN = "^[a-zA-Z0-9_\-!$%&/=]*$"
   FTPUSER_PASSWORD_MIN_LENGTH = 6
   FTPUSER_PASSWORD_MAX_LENGTH = 20

   FTPUSER_LABEL_MIN_LENGTH = 3
   FTPUSER_LABEL_MAX_LENGTH = 20


   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _createFtpDir(self, user):
      ftp_base_dir = str(self.proto.factory.services["config"].get("ftp-dir"))
      if not os.path.isdir(ftp_base_dir):
         os.mkdir(ftp_base_dir)
         log.msg("FTP base directory %s created" % ftp_base_dir)

      ftp_dir = os.path.join(ftp_base_dir, user)
      if not os.path.isdir(ftp_dir):
         os.mkdir(ftp_dir)

         log_dir = self.proto.factory.services["config"].get("log-dir")
         n = 0
         for root, dirs, files in os.walk(log_dir):
            for f in files:
               sourcepath = os.path.join(root, f)
               targetpath = os.path.join(ftp_dir, f)

               # http://bugs.python.org/issue8879
               if sys.platform.startswith("win"):
                  # FIXME: this is not correct, will only work for files
                  # that are not modified thereafter!!
                  shutil.copyfile(sourcepath, targetpath)
               else:
                  os.link(sourcepath, targetpath)

               n += 1

         log.msg("FTP directory %s created, hard linked %d log files" % (ftp_dir, n))


   def _removeFtpDir(self, user):
      ftp_dir = os.path.join(self.proto.factory.services["config"].get("ftp-dir"), user)
      if os.path.isdir(ftp_dir):
         shutil.rmtree(ftp_dir, True)
         log.msg("FTP directory %s removed" % ftp_dir)


   def _moveFtpDir(self, olduser, newuser):
      ftp_dir_old = os.path.join(self.proto.factory.services["config"].get("ftp-dir"), olduser)
      ftp_dir_new = os.path.join(self.proto.factory.services["config"].get("ftp-dir"), newuser)
      shutil.move(ftp_dir_old, ftp_dir_new)
      log.msg("FTP directory %s moved to %s" % (ftp_dir_old, ftp_dir_new))


   def _createFtpUser(self, txn, spec):
      """
      Create new FTP user, runs in database transaction.
      """
      attrs = {"label": (True,
                         [str, unicode],
                         FtpUsers.FTPUSER_LABEL_MIN_LENGTH,
                         FtpUsers.FTPUSER_LABEL_MAX_LENGTH,
                         None),
               "user": (True,
                        [str, unicode],
                        FtpUsers.FTPUSER_USER_MIN_LENGTH,
                        FtpUsers.FTPUSER_USER_MAX_LENGTH,
                        FtpUsers.FTPUSER_USER_PATTERN),
               "password": (True,
                            [str, unicode],
                            FtpUsers.FTPUSER_PASSWORD_MIN_LENGTH,
                            FtpUsers.FTPUSER_PASSWORD_MAX_LENGTH,
                            FtpUsers.FTPUSER_PASSWORD_PATTERN)}

      errcnt, errs = self.proto.checkDictArg("ftpuser spec", spec, attrs)

      txn.execute("SELECT created FROM ftpuser WHERE user = ?", [spec["user"]])
      if txn.fetchone() is not None:
         errs["user"].append((self.proto.shrink(URI_ERROR + "duplicate-value"), "FTP user '%s' already exists" % spec["user"]))
         errcnt += 1

      if errcnt:
         raise Exception(URI_ERROR + "illegal-argument", "one or more illegal arguments (%d errors)" % errcnt, errs)

      try:
         user = str(spec["user"])
         #self._createFtpDir(user)
      except Exception, e:
         msg = "could not create FTP dir for new FTP user '%s' (%s)" % (user, str(e))
         log.msg(msg)
         raise Exception(msg)

      id = newid()
      ftpuser_uri = URI_FTPUSER + id
      label = spec["label"].strip()
      now = utcnow()
      txn.execute("INSERT INTO ftpuser (id, label, user, created, password) VALUES (?, ?, ?, ?, ?)",
                  [id,
                   label,
                   spec["user"],
                   now,
                   spec["password"]])

      ftpuser = {"uri": ftpuser_uri,
                 "created": now,
                 "label": label,
                 "user": spec["user"],
                 "password": spec["password"]}

      self.proto.dispatch(URI_EVENT + "on-ftpuser-created", ftpuser, [self.proto])

      ftpuser["uri"] = self.proto.shrink(ftpuser_uri)
      return ftpuser


   @exportRpc("create-ftpuser")
   def createFtpUser(self, spec):
      """
      Create new FTP user.

      Parameters:

         spec:             FTP user specification, a dictionary.
         spec[]
            label:         Label, a string, not necessarily unique.
            user:          User, a string, must be unique.
            password:      Password, a string.

      Result:

         {"uri":        <FtpUser URI>,
          "created":    <FtpUser creation timestamp>,
          "label":      <FtpUser label>,
          "user":       <FtpUser user>,
          "password":   <FtpUser password>}

      Events:

         on-ftpuser-created

      Errors:

         spec:                   illegal-argument

         spec[]:

            *:                   illegal-attribute-type,
                                 missing-attribute

            label,
            user,
            password:            attribute-value-too-short,
                                 attribute-value-too-long

            user,
            password:            attribute-value-invalid-characters

            user:                duplicate-value

            ?:                   unknown-attribute
      """
      return self.proto.dbpool.runInteraction(self._createFtpUser, spec)


   def _deleteFtpUser(self, txn, ftpUserUri):

      if type(ftpUserUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument ftpUserUri, but got %s" % str(type(ftpUserUri)))

      uri = self.proto.resolveOrPass(ftpUserUri)
      id = self.proto.uriToId(uri)

      txn.execute("SELECT user FROM ftpuser WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         try:
            user = str(res[0])
            #self._removeFtpDir(user)
         except Exception, e:
            msg = "could not remove FTP dir for deleted FTP user '%s' (%s)" % (user, str(e))
            log.msg(msg)
            raise Exception(msg)

         txn.execute("DELETE FROM ftpuser WHERE id = ?", [id])

         self.proto.dispatch(URI_EVENT + "on-ftpuser-deleted", uri, [self.proto])

         return self.proto.shrink(uri)

      else:
         raise Exception(URI_ERROR + "no-such-object", "No FTP user with URI %s" % uri)


   @exportRpc("delete-ftpuser")
   def deleteAppCred(self, ftpUserUri):
      """
      Delete an FTP user.

      Parameters:

         ftpUserUri:          URI or CURIE of FTP user to delete.

      Result:

         <FTP User URI>

      Events:

         on-ftpuser-deleted

      Errors:

         ftpUserUri:             illegal-argument,
                                 no-such-object
      """
      return self.proto.dbpool.runInteraction(self._deleteFtpUser, ftpUserUri)


   def _modifyFtpUser(self, txn, ftpUserUri, specDelta):

      if type(ftpUserUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument ftpUserUri, but got %s" % str(type(ftpUserUri)))

      uri = self.proto.resolveOrPass(ftpUserUri)
      id = self.proto.uriToId(uri)

      txn.execute("SELECT label, user, password FROM ftpuser WHERE id = ?", [id])
      res = txn.fetchone()

      if res is not None:

         attrs = {"label": (False,
                            [str, unicode],
                            FtpUsers.FTPUSER_LABEL_MIN_LENGTH,
                            FtpUsers.FTPUSER_LABEL_MAX_LENGTH,
                            None),
                  "user": (False,
                           [str, unicode],
                           FtpUsers.FTPUSER_USER_MIN_LENGTH,
                           FtpUsers.FTPUSER_USER_MAX_LENGTH,
                           FtpUsers.FTPUSER_USER_PATTERN),
                  "password": (False,
                               [str, unicode],
                               FtpUsers.FTPUSER_PASSWORD_MIN_LENGTH,
                               FtpUsers.FTPUSER_PASSWORD_MAX_LENGTH,
                               FtpUsers.FTPUSER_PASSWORD_PATTERN)}

         errcnt, errs = self.proto.checkDictArg("ftpuser delta spec", specDelta, attrs)

         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("label"):
            newval = specDelta["label"].strip()
            if newval != res[0]:
               delta["label"] = newval
               sql += ", label = ?"
               sql_vars.append(newval)

         if specDelta.has_key("user"):
            newval = specDelta["user"].strip()
            if newval != res[1]:
               txn.execute("SELECT created FROM ftpuser WHERE user = ?", [newval])
               if txn.fetchone() is not None:
                  errs["user"].append((self.proto.shrink(URI_ERROR + "duplicate-value"), "FTP user '%s' already exists" % newval))
               delta["user"] = newval
               sql += ", user = ?"
               sql_vars.append(newval)

         if specDelta.has_key("password"):
            newval = specDelta["password"]
            if newval != res[2]:
               delta["password"] = newval
               sql += ", password = ?"
               sql_vars.append(newval)

         if errcnt:
            raise Exception(URI_ERROR + "illegal-argument", "one or more illegal arguments (%d errors)" % errcnt, errs)

         if len(delta) > 0:

            ## move FTP directory when 'user' has changed
            ##
            olduser = str(res[1])
            newuser = str(delta.get("user", olduser))
            if newuser != olduser:
               try:
                  pass
                  #self._moveFtpDir(olduser, newuser)
               except:
                  msg = "could not move FTP dir for FTP user '%s' to '%s' (%s)" % (olduser, newuser, str(e))
                  log.msg(msg)
                  raise Exception(msg)

            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE ftpuser SET %s WHERE id = ?" % sql, sql_vars)

            self.proto.dispatch(URI_EVENT + "on-ftpuser-modified", delta, [self.proto])

            delta["uri"] = self.proto.shrink(uri)
            return delta
         else:
            return {}

      else:
         raise Exception(URI_ERROR + "no-such-object", "No FTP user with URI %s" % uri)


   @exportRpc("modify-ftpuser")
   def modifyFtpUser(self, ftpUserUri, specDelta):
      """
      Modify existing FTP user.

      Parameters:

         ftpUserUri:          URI or CURIE of FTP user to modify.
         specDelta:           FTP user change specification, a dictionary.
         specDelta[]:
            label:            Label, a string, not necessarily unique.
            user:             User, a string, must be unique.
            password:         Password, a string.

      Result:

         {"uri":           <FTP User URI>,
          "modified":      <FTP User modification timestamp>,
          "label":         <FTP User label>,
          "user":          <FTP User user>,
          "password":      <FTP User password>}

      Events:

         on-ftpuser-modified

      Errors:

         ftpUserUri,
         specDelta:              illegal-argument

         ftpUserUri:             no-such-object

         specDelta[]:

            *:                   illegal-attribute-type,
                                 missing-attribute

            label,
            user,
            password:            attribute-value-too-short,
                                 attribute-value-too-long

            user,
            password:            attribute-value-invalid-characters

            user:                duplicate-value

            ?:                   unknown-attribute
      """
      return self.proto.dbpool.runInteraction(self._modifyFtpUser, ftpUserUri, specDelta)


   @exportRpc("get-ftpusers")
   def getFtpUsers(self):
      """
      Return list of FTP users (ordered by label/user ascending).
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, label, user, password FROM ftpuser ORDER BY label, user ASC")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_FTPUSER + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "label": r[3],
                                  "user": r[4],
                                  "password": r[5]} for r in res])
      return d

########NEW FILE########
__FILENAME__ = hanaconnects
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import uuid, binascii

from twisted.python import log
from twisted.internet.threads import deferToThread
from twisted.internet.defer import Deferred, returnValue, inlineCallbacks

from netaddr.ip import IPAddress

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class HanaConnects:
   """
   SAP HANA Connects model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def checkSpec(self, spec, errs):

      errcnt = 0

      if not errs["host"] and spec.has_key("host"):
         host = str(spec["host"])
         try:
            addr = IPAddress(host)
            spec["host"] = str(addr)
         except Exception, e:
            errs["host"].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"),
                                 "Illegal value '%s' for host (%s)." % (host, str(e))))
            errcnt += 1

      return errcnt


   def _createHanaConnect(self, txn, spec):

      ## check arguments
      ##
      attrs = {"label": (False, [str, unicode], 3, 20),
               "driver": (False, [str, unicode], 0, 20),
               "host": (False, [str, unicode], 0, 20),
               "port": (False, [int], 1, 65535),
               "database": (False, [str, unicode], 0, 20),
               "user": (False, [str, unicode], 0, 20),
               "password": (False, [str, unicode], 0, 20)}

      errcnt, errs = self.proto.checkDictArg("hanaconnect spec", spec, attrs)

      errcnt += self.checkSpec(spec, errs)

      self.proto.raiseDictArgException(errs)

      ## normalize args
      ##
      for p in ["driver", "database", "user"]:
         if spec.has_key(p):
            spec[p] = spec[p].upper()
      spec["label"] = spec["label"].strip()

      ## insert new object into service database
      ##
      id = newid()
      uri = URI_HANACONNECT + id
      now = utcnow()

      txn.execute("INSERT INTO hanaconnect (id, created, label, driver, host, port, database, user, password) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
                  [id,
                   now,
                   spec["label"],
                   spec["driver"],
                   spec["host"],
                   spec["port"],
                   spec["database"],
                   spec["user"],
                   spec["password"]])

      ## recache in services if necessary
      ##
      services = self.proto.factory.services
      if services.has_key("hanapusher"):
         services["hanapusher"].recache(txn)
      if services.has_key("hanaremoter"):
         services["hanaremoter"].recache(txn)

      obj = {"uri": uri,
             "created": now,
             "label": spec["label"],
             "driver": spec["driver"],
             "host": spec["host"],
             "port": spec["port"],
             "database": spec["database"],
             "user": spec["user"],
             "password": spec["password"]}

      ## dispatch on-created event
      ##
      self.proto.dispatch(URI_EVENT + "on-hanaconnect-created", obj, [self.proto])

      ## return complete object
      ##
      obj["uri"] = self.proto.shrink(uri)
      return obj


   @exportRpc("create-hanaconnect")
   def createHanaConnect(self, spec):
      """
      Create a new SAP HANA database connect.
      """
      return self.proto.dbpool.runInteraction(self._createHanaConnect, spec)


   def _deleteHanaConnect(self, txn, hanaConnectUri, cascade):

      ## check arguments
      ##
      if type(hanaConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument hanaConnectUri, but got %s" % str(type(hanaConnectUri)))

      if type(cascade) not in [bool]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type bool for agument cascade, but got %s" % str(type(cascade)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(hanaConnectUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM hanaconnect WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check for depending hanaremotes
         ##
         txn.execute("SELECT id FROM hanaremote WHERE hanaconnect_id = ?", [id])
         dependingRemotes = []
         for r in txn.fetchall():
            dependingRemotes.append(r[0])

         ## check for depending hanapushrules
         ##
         txn.execute("SELECT id FROM hanapushrule WHERE hanaconnect_id = ?", [id])
         dependingPushRules = []
         for r in txn.fetchall():
            dependingPushRules.append(r[0])

         ## delete depending objects and object
         ##
         if len(dependingRemotes) > 0 or len(dependingPushRules) > 0:
            if not cascade:
               raise Exception(URI_ERROR + "depending-objects",
                               "Cannot delete database connect: %d depending remotes, %d depending pushrules" % (len(dependingRemotes), len(dependingPushRules)),
                               ([self.proto.shrink(URI_HANAREMOTE + id) for id in dependingRemotes],
                                [self.proto.shrink(URI_HANAPUSHRULE + id) for id in dependingPushRules]))
            else:
               if len(dependingRemotes) > 0:
                  txn.execute("DELETE FROM hanaremote WHERE hanaconnect_id = ?", [id])
               if len(dependingPushRules) > 0:
                  txn.execute("DELETE FROM hanapushrule WHERE hanaconnect_id = ?", [id])

         txn.execute("DELETE FROM hanaconnect WHERE id = ?", [id])

         ## recache in services if necessary
         ##
         services = self.proto.factory.services
         if len(dependingRemotes) > 0 and services.has_key("hanaremoter"):
            services["hanaremoter"].recache(txn)

         if len(dependingPushRules) > 0 and services.has_key("hanapusher"):
            services["hanapusher"].recache(txn)

         ## dispatch on-deleted events
         ##
         for id in dependingRemotes:
            self.proto.dispatch(URI_EVENT + "on-hanaremote-deleted", URI_HANAREMOTE + id, [])

         for id in dependingPushRules:
            self.proto.dispatch(URI_EVENT + "on-hanapushrule-deleted", URI_HANAPUSHRULE + id, [])

         self.proto.dispatch(URI_EVENT + "on-hanaconnect-deleted", uri, [self.proto])

         ## return deleted object URI
         ##
         return self.proto.shrink(uri)

      else:
         raise Exception(URI_ERROR + "no-such-object", "No HANA connect with URI %s" % uri)


   @exportRpc("delete-hanaconnect")
   def deleteHanaConnect(self, hanaConnectUri, cascade = False):
      """
      Delete a SAP HANA database connect.
      """
      return self.proto.dbpool.runInteraction(self._deleteHanaConnect, hanaConnectUri, cascade)


   def _modifyHanaConnect(self, txn, hanaConnectUri, specDelta):

      ## check arguments
      ##
      if type(hanaConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument hanaConnectUri, but got %s" % str(type(hanaConnectUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(hanaConnectUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT label, driver, host, port, database, user, password FROM hanaconnect WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check arguments
         ##
         attrs = {"label": (False, [str, unicode], 3, 20),
                  "driver": (False, [str, unicode], 0, 20),
                  "host": (False, [str, unicode], 0, 20),
                  "port": (False, [int], 1, 65535),
                  "database": (False, [str, unicode], 0, 20),
                  "user": (False, [str, unicode], 0, 20),
                  "password": (False, [str, unicode], 0, 20)}

         errcnt, errs = self.proto.checkDictArg("hanaconnect delta spec", specDelta, attrs)

         errcnt += self.checkSpec(specDelta, errs)

         self.proto.raiseDictArgException(errs)

         ## normalize args
         ##
         for p in ["driver", "database", "user"]:
            if specDelta.has_key(p):
               specDelta[p] = specDelta[p].upper()
         if specDelta.has_key("label"):
            specDelta["label"] = specDelta["label"].strip()

         ## compute delta and SQL
         ##
         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         for p in [('label', 0),
                   ('driver', 1),
                   ('host', 2),
                   ('port', 3),
                   ('database', 4),
                   ('user', 5),
                   ('password', 6)]:
            if specDelta.has_key(p[0]):
               newval = specDelta[p[0]]
               if newval != res[p[1]]:
                  delta[p[0]] = newval
                  sql += ", %s = ?" % p[0]
                  sql_vars.append(newval)

         ## proceed when there is an actual change in data
         ##
         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE hanaconnect SET %s WHERE id = ?" % sql, sql_vars)

            ## recache in services if necessary
            ##
            services = self.proto.factory.services
            if services.has_key("hanapusher"):
               services["hanapusher"].recache(txn)
            if services.has_key("hanaremoter"):
               services["hanaremoter"].recache(txn)

            ## dispatch on-modified events
            ##
            self.proto.dispatch(URI_EVENT + "on-hanaconnect-modified", delta, [self.proto])

            ## return object delta
            ##
            delta["uri"] = self.proto.shrink(uri)
            return delta
         else:
            ## object unchanged
            ##
            return {}

      else:
         raise Exception(URI_ERROR + "no-such-object", "No HANA connect with URI %s" % uri)


   @exportRpc("modify-hanaconnect")
   def modifyHanaConnect(self, hanaConnectUri, specDelta):
      """
      Modify a SAP HANA database connect.
      """
      return self.proto.dbpool.runInteraction(self._modifyHanaConnect, hanaConnectUri, specDelta)


   @exportRpc("get-hanaconnects")
   def getHanaConnects(self):
      """
      Return list of SAP HANA database connects.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, label, driver, host, port, database, user, password FROM hanaconnect ORDER BY label, user, database, id ASC")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_HANACONNECT + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "label": r[3],
                                  "driver": r[4],
                                  "host": r[5],
                                  "port": r[6],
                                  "database": r[7],
                                  "user": r[8],
                                  "password": r[9]} for r in res])
      return d


   def _getHanaConnectPusherState(self, txn, hanaConnectUri):

      ## check arguments
      ##
      if type(hanaConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument hanaConnectUri, but got %s" % str(type(hanaConnectUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(hanaConnectUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM hanaconnect WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         if self.proto.factory.services.has_key("hanapusher"):
            return self.proto.factory.services["hanapusher"].getPusherState(id)
         else:
            raise Exception("hanapusher not running")

      else:
         raise Exception(URI_ERROR + "no-such-object", "No SAP HANA connect with URI %s" % uri)


   @exportRpc("get-hanaconnect-pusherstate")
   def getHanaConnectPusherState(self, hanaConnectUri):
      """
      Retrieve the current state of database pusher associated with this connect (if any).
      """
      return self.proto.dbpool.runInteraction(self._getHanaConnectPusherState, hanaConnectUri)


   @exportRpc("test-hanaconnect")
   def testHanaConnect(self, hanaConnectUri):
      """
      Test a SAP HANA database connect.

      This is done on a completely new database connection run from a new, short-lived background thread.
      """

      ## check arguments
      ##
      if type(hanaConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument hanaConnectUri, but got %s" % str(type(hanaConnectUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(hanaConnectUri)
      id = self.proto.uriToId(uri)

      ## get database connection definition and test ..
      ##
      d = self.proto.dbpool.runQuery("SELECT driver, host, port, database, user, password FROM hanaconnect WHERE id = ?", [id])

      def dotest(res):
         if res is not None and len(res) > 0:

            res = res[0]

            driver = str(res[0])
            host = str(res[1])
            port = str(res[2])
            database = str(res[3])
            user = str(res[4])
            password = str(res[5])
            connectstr = 'DRIVER={%s};SERVERNODE=%s:%s;SERVERDB=%s;UID=%s;PWD=%s' % (driver, host, port, database, user, password)
            log.msg("Testing HANA connect (%s)" % connectstr)

            def test():
               import pyodbc
               conn = pyodbc.connect(connectstr)
               #conn.timeout = 3 # raises ODBC error from HANA driver: "optional feature not implemented"
               cur = conn.cursor()
               #cur.execute("SELECT now() FROM dummy")
               cur.execute("SELECT now() AS now, start_time, version, sysuuid FROM sys.m_database")
               rr = cur.fetchone()
               current_time = str(rr[0]).strip()
               start_time = str(rr[1]).strip()
               version = str(rr[2]).strip()
               sysuuid = str(uuid.UUID(binascii.b2a_hex(rr[3])))
               r = {'current-time': current_time,
                    'start-time': start_time,
                    'version': version,
                    'uuid': sysuuid}
               print r
               return r

            return deferToThread(test)

         else:
            raise Exception(URI_ERROR + "no-such-object", "No HANA connect with URI %s" % uri)

      d.addCallback(dotest)
      return d

########NEW FILE########
__FILENAME__ = hanapushrules
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class HanaPushRules:
   """
   SAP HANA Push Rules model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def checkSpec(self, spec, errs):

      errcnt = 0
      return errcnt


   def _createHanaPushRule(self, txn, spec):

      ## check arguments
      ##
      attrs = {"topic-uri": (True, [str, unicode], 0, URI_MAXLEN),
               "match-by-prefix": (True, [bool]),
               "user": (False, [str, unicode, types.NoneType], 0, 30),
               "hanaconnect-uri": (True, [str, unicode], 0, URI_MAXLEN)}

      errcnt, errs = self.proto.checkDictArg("HANA pushrule spec", spec, attrs)

      if not errs["topic-uri"]:
         topic_uri, errs2 = self.proto.validateUri(spec["topic-uri"])
         errs["topic-uri"].extend(errs2)
         errcnt += len(errs2)

      errcnt += self.checkSpec(spec, errs)

      hanaconnect_id = None
      hanaconnect_uri = None
      if spec.has_key("hanaconnect-uri") and spec["hanaconnect-uri"] is not None and spec["hanaconnect-uri"].strip() != "":
         hanaconnect_uri = self.proto.resolveOrPass(spec["hanaconnect-uri"].strip())
         hanaconnect_id = self.proto.uriToId(hanaconnect_uri)
         txn.execute("SELECT created FROM hanaconnect WHERE id = ?", [hanaconnect_id])
         if txn.fetchone() is None:
            errs["hanaconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No HANA connect with URI %s" % appcred_uri))

      self.proto.raiseDictArgException(errs)


      ## insert new object into service database
      ##
      id = newid()
      uri = URI_HANAPUSHRULE + id
      now = utcnow()
      user = spec['user'].strip() if spec.has_key('user') else None

      txn.execute("INSERT INTO hanapushrule (id, created, modified, hanaconnect_id, user, topic_uri, match_by_prefix) VALUES (?, ?, ?, ?, ?, ?, ?)",
                  [id,
                   now,
                   None,
                   hanaconnect_id,
                   user,
                   topic_uri,
                   int(spec["match-by-prefix"])])

      ## recache in services if necessary
      ##
      services = self.proto.factory.services
      if services.has_key("hanapusher"):
         services["hanapusher"].recache(txn)

      obj = {"uri": uri,
             "created": now,
             "modified": None,
             "hanaconnect-uri": hanaconnect_uri,
             "user": user,
             "topic-uri": topic_uri,
             "match-by-prefix": spec["match-by-prefix"]}

      ## dispatch on-created event
      ##
      self.proto.dispatch(URI_EVENT + "on-hanapushrule-created", obj, [self.proto])

      ## return complete object
      ##
      obj["uri"] = self.proto.shrink(uri)
      if obj["hanaconnect-uri"] is not None:
         obj["hanaconnect-uri"] = self.proto.shrink(hanaconnect_uri)
      return obj


   @exportRpc("create-hanapushrule")
   def createHanaPushRule(self, spec):
      """
      Create a new SAP HANA push rule.
      """
      return self.proto.dbpool.runInteraction(self._createHanaPushRule, spec)


   def _deleteHanaPushRule(self, txn, hanaPushRuleUri):

      ## check arguments
      ##
      if type(hanaPushRuleUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument hanaPushRuleUri, but got %s" % str(type(hanaPushRuleUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(hanaPushRuleUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM hanapushrule WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         txn.execute("DELETE FROM hanapushrule WHERE id = ?", [id])

         ## recache in services if necessary
         ##
         services = self.proto.factory.services
         if services.has_key("hanapusher"):
            services["hanapusher"].recache(txn)

         ## dispatch on-deleted events
         ##
         self.proto.dispatch(URI_EVENT + "on-hanapushrule-deleted", uri, [self.proto])

         ## return deleted object URI
         ##
         return self.proto.shrink(uri)
      else:
         raise Exception(URI_ERROR + "no-such-object", "No HANA push rule with URI %s" % uri)


   @exportRpc("delete-hanapushrule")
   def deleteHanaPushRule(self, hanaPushRuleUri):
      """
      Delete a SAP HANA push rule.
      """
      return self.proto.dbpool.runInteraction(self._deleteHanaPushRule, hanaPushRuleUri)


   def _modifyHanaPushRule(self, txn, hanaPushRuleUri, specDelta):

      ## check arguments
      ##
      if type(hanaPushRuleUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument hanaPushRuleUri, but got %s" % str(type(hanaPushRuleUri)))

      attrs = {"topic-uri": (False, [str, unicode], 0, URI_MAXLEN),
               "match-by-prefix": (False, [bool]),
               "user": (False, [str, unicode, types.NoneType], 0, 30),
               "hanaconnect-uri": (False, [str, unicode], 0, URI_MAXLEN)}

      errcnt, errs = self.proto.checkDictArg("HANA pushrule delta spec", specDelta, attrs)

      if not errs["topic-uri"] and specDelta.has_key("topic-uri"):
         topic_uri, errs2 = self.proto.validateUri(specDelta["topic-uri"])
         errs["topic-uri"].extend(errs2)
         errcnt += len(errs2)

      errcnt += self.checkSpec(specDelta, errs)

      hanaconnect_id = None
      hanaconnect_uri = None
      if specDelta.has_key("hanaconnect-uri") and specDelta["hanaconnect-uri"] is not None and specDelta["hanaconnect-uri"].strip() != "":
         hanaconnect_uri = self.proto.resolveOrPass(specDelta["hanaconnect-uri"].strip())
         hanaconnect_id = self.proto.uriToId(hanaconnect_uri)
         txn.execute("SELECT created FROM hanaconnect WHERE id = ?", [hanaconnect_id])
         if txn.fetchone() is None:
            errs["hanaconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No HANA connect with URI %s" % hanaconnect_uri))

      self.proto.raiseDictArgException(errs)

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(hanaPushRuleUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT topic_uri, match_by_prefix, user, hanaconnect_id FROM hanapushrule WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## compute delta and SQL
         ##
         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("topic-uri"):
            newval = topic_uri
            if newval != "" and newval != res[0]:
               delta["topic-uri"] = newval
               sql += ", topic_uri = ?"
               sql_vars.append(newval)

         if specDelta.has_key("match-by-prefix"):
            newval = specDelta["match-by-prefix"]
            if newval != (res[1] != 0):
               delta["match-by-prefix"] = newval
               sql += ", match_by_prefix = ?"
               sql_vars.append(newval)

         if specDelta.has_key("user"):
            newval = specDelta["user"]
            if newval != res[2]:
               delta["user"] = newval
               sql += ", user = ?"
               sql_vars.append(newval)

         if specDelta.has_key("hanaconnect-uri"):
            if hanaconnect_id != res[3]:
               delta["hanaconnect-uri"] = hanaconnect_uri
               sql += ", hanaconnect_id = ?"
               sql_vars.append(hanaconnect_id)

         ## proceed when there is an actual change in data
         ##
         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE hanapushrule SET %s WHERE id = ?" % sql, sql_vars)

            ## recache in services if necessary
            ##
            services = self.proto.factory.services
            if services.has_key("hanapusher"):
               services["hanapusher"].recache(txn)

            ## dispatch on-modified events
            ##
            self.proto.dispatch(URI_EVENT + "on-hanapushrule-modified", delta, [self.proto])

            ## return object delta
            ##
            delta["uri"] = self.proto.shrink(uri)
            if delta.has_key("hanaconnect-uri") and delta["hanaconnect-uri"] is not None:
               delta["hanaconnect-uri"] = self.proto.shrink(hanaconnect_uri)
            return delta
         else:
            ## object unchanged
            ##
            return {}
      else:
         raise Exception(URI_ERROR + "no-such-object", "No HANA push rule with URI %s" % uri)


   @exportRpc("modify-hanapushrule")
   def modifyHanaPushRule(self, hanaPushRuleUri, specDelta):
      """
      Modify a SAP HANA push rule.
      """
      return self.proto.dbpool.runInteraction(self._modifyHanaPushRule, hanaPushRuleUri, specDelta)


   @exportRpc("get-hanapushrules")
   def getHanaPushRules(self):
      """
      Return list of SAP HANA push rules.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, hanaconnect_id, user, topic_uri, match_by_prefix FROM hanapushrule ORDER BY hanaconnect_id, user, topic_uri")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_HANAPUSHRULE + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "hanaconnect-uri": self.proto.shrink(URI_HANACONNECT + r[3]) if r[3] else None,
                                  "user": r[4],
                                  "topic-uri": r[5],
                                  "match-by-prefix": r[6] != 0} for r in res])
      return d

########NEW FILE########
__FILENAME__ = hanaremotes
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class HanaRemotes:
   """
   SAP HANA Remotes model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _checkSpec(self, spec, specDelta, errs):

      errcnt = 0

      if not errs["schema-list"]:
         if specDelta.has_key('schema-list'):
            try:
               specDelta['schema-list'] = ','.join(sorted([x.strip().lower() for x in specDelta['schema-list'].split(',')]))
            except Exception, e:
               errs["schema-list"].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"), "Illegal value '%s' for schema list [%s]." % (spec["schema-list"], str(e))))
               errcnt += 1

      if not errs["connection-pool-min-size"] and not errs["connection-pool-max-size"]:
         if specDelta.has_key('connection-pool-min-size') or specDelta.has_key('connection-pool-max-size'):
            cpMinSize = specDelta.get('connection-pool-min-size', spec.get('connection-pool-min-size', None))
            cpMaxSize = specDelta.get('connection-pool-max-size', spec.get('connection-pool-max-size', None))
            if cpMinSize > cpMaxSize:
               if specDelta.has_key('connection-pool-min-size'):
                  errs["connection-pool-min-size"].append((self.proto.shrink(URI_ERROR + "invalid-range-value"),
                                                           "Illegal value '%s' for connection pool min size - must be smaller than or equal to max size." % specDelta['connection-pool-min-size']))
                  errcnt += 1
               if specDelta.has_key('connection-pool-max-size'):
                  errs["connection-pool-max-size"].append((self.proto.shrink(URI_ERROR + "invalid-range-value"),
                                                           "Illegal value '%s' for connection pool max size - must be larger than or equal to min size." % specDelta['connection-pool-max-size']))
                  errcnt += 1

      return errcnt


   def _createHanaRemote(self, txn, spec):

      ## check arguments
      ##
      attrs = {"require-appcred-uri": (False, [str, unicode, types.NoneType]),
               "hanaconnect-uri": (True, [str, unicode]),
               "schema-list": (True, [str, unicode], 0, 1000),
               "rpc-base-uri": (True, [str, unicode], 0, URI_MAXLEN),
               "connection-pool-min-size": (True, [int], 1, 30),
               "connection-pool-max-size": (True, [int], 1, 100),
               "connection-timeout": (True, [int], 0, 120),
               "request-timeout": (True, [int], 0, 120)}

      errcnt, errs = self.proto.checkDictArg("hanaremote spec", spec, attrs)

      if not errs["rpc-base-uri"]:
         rpcBaseUri, errs2 = self.proto.validateUri(spec["rpc-base-uri"])
         errs["rpc-base-uri"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and spec.has_key("require-appcred-uri"):
         if spec["require-appcred-uri"] == "null" or spec["require-appcred-uri"] == "":
            spec["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if spec.has_key("require-appcred-uri") and spec["require-appcred-uri"] is not None and spec["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(spec["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      connect_id = None
      connect_uri = None
      if spec.has_key("hanaconnect-uri") and spec["hanaconnect-uri"] is not None and spec["hanaconnect-uri"].strip() != "":
         connect_uri = self.proto.resolveOrPass(spec["hanaconnect-uri"].strip())
         connect_id = self.proto.uriToId(connect_uri)
         txn.execute("SELECT created FROM hanaconnect WHERE id = ?", [connect_id])
         if txn.fetchone() is None:
            errs["hanaconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No HANA connect URI %s" % connect_uri))

      errcnt += self._checkSpec({}, spec, errs)

      self.proto.raiseDictArgException(errs)

      ## insert new object into service database
      ##
      id = newid()
      hanaremote_uri = URI_HANAREMOTE + id
      now = utcnow()

      txn.execute("INSERT INTO hanaremote (id, created, require_appcred_id, hanaconnect_id, schema_list, rpc_base_uri, connection_pool_min_size, connection_pool_max_size, connection_timeout, request_timeout) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                                       [id,
                                        now,
                                        appcred_id,
                                        connect_id,
                                        spec["schema-list"],
                                        rpcBaseUri,
                                        int(spec["connection-pool-min-size"]),
                                        int(spec["connection-pool-max-size"]),
                                        int(spec["connection-timeout"]),
                                        int(spec["request-timeout"])
                                        ])

      ## recache in services if necessary
      ##
      services = self.proto.factory.services
      if services.has_key("hanaremoter"):
         services["hanaremoter"].recache(txn)

      hanaremote = {"uri": hanaremote_uri,
                    "require-appcred-uri": appcred_uri,
                    "hanaconnect-uri": connect_uri,
                    "schema-list": spec["schema-list"],
                    "rpc-base-uri": rpcBaseUri,
                    "connection-pool-min-size": int(spec["connection-pool-min-size"]),
                    "connection-pool-max-size": int(spec["connection-pool-max-size"]),
                    "connection-timeout": int(spec["connection-timeout"]),
                    "request-timeout": int(spec["request-timeout"])}

      ## dispatch on-created event
      ##
      self.proto.dispatch(URI_EVENT + "on-hanaremote-created", hanaremote, [self.proto])

      ## return complete object
      ##
      hanaremote["uri"] = self.proto.shrink(hanaremote_uri)

      if hanaremote["require-appcred-uri"] is not None:
         hanaremote["require-appcred-uri"] = self.proto.shrink(appcred_uri)

      if hanaremote["hanaconnect-uri"] is not None:
         hanaremote["hanaconnect-uri"] = self.proto.shrink(connect_uri)

      return hanaremote


   @exportRpc("create-hanaremote")
   def createHanaRemote(self, spec):
      """
      Create a new SAP HANA remote.
      """
      return self.proto.dbpool.runInteraction(self._createHanaRemote, spec)


   def _modifyHanaRemote(self, txn, hanaRemoteUri, specDelta):

      ## check arguments
      ##
      if type(hanaRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument hanaRemoteUri, but got %s" % str(type(hanaRemoteUri)))

      attrs = {"require-appcred-uri": (False, [str, unicode, types.NoneType]),
               "hanaconnect-uri": (False, [str, unicode]),
               "schema-list": (False, [str, unicode], 0, 1000),
               "rpc-base-uri": (False, [str, unicode], 0, URI_MAXLEN),
               "connection-pool-min-size": (False, [int], 1, 30),
               "connection-pool-max-size": (False, [int], 1, 100),
               "connection-timeout": (False, [int], 0, 120),
               "request-timeout": (False, [int], 0, 120)}

      errcnt, errs = self.proto.checkDictArg("hanaremote delta spec", specDelta, attrs)

      if not errs["rpc-base-uri"] and specDelta.has_key("rpc-base-uri"):
         rpcBaseUri, errs2 = self.proto.validateUri(specDelta["rpc-base-uri"])
         errs["rpc-base-uri"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and specDelta.has_key("require-appcred-uri"):
         if specDelta["require-appcred-uri"] == "null" or specDelta["require-appcred-uri"] == "":
            specDelta["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if specDelta.has_key("require-appcred-uri") and specDelta["require-appcred-uri"] is not None and specDelta["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(specDelta["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      connect_id = None
      connect_uri = None
      if specDelta.has_key("hanaconnect-uri") and specDelta["hanaconnect-uri"] is not None and specDelta["hanaconnect-uri"].strip() != "":
         connect_uri = self.proto.resolveOrPass(specDelta["hanaconnect-uri"].strip())
         connect_id = self.proto.uriToId(connect_uri)
         txn.execute("SELECT created FROM hanaconnect WHERE id = ?", [connect_id])
         if txn.fetchone() is None:
            errs["hanaconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No HANA connect URI %s" % connect_uri))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(hanaRemoteUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT require_appcred_id, hanaconnect_id, schema_list, rpc_base_uri, connection_pool_min_size, connection_pool_max_size, connection_timeout, request_timeout FROM hanaremote WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check arguments
         ##
         spec = {}
         spec["require-appcred-uri"] = self.proto.shrink(URI_APPCRED + res[0]) if res[0] else None
         spec["hanaconnect-uri"] = self.proto.shrink(URI_HANACONNECT + res[1]) if res[1] else None
         spec["schema-list"] = res[2]
         spec["rpc-base-uri"] = res[3]
         spec["connection-pool-min-size"] = res[4]
         spec["connection-pool-max-size"] = res[5]
         spec["connection-timeout"] = res[6]
         spec["request-timeout"] = res[7]

         errcnt += self._checkSpec(spec, specDelta, errs)

         self.proto.raiseDictArgException(errs)

         ## compute delta and SQL
         ##
         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("require-appcred-uri"):
            if appcred_id != res[0]:
               delta["require-appcred-uri"] = appcred_uri
               sql += ", require_appcred_id = ?"
               sql_vars.append(appcred_id)

         if specDelta.has_key("hanaconnect-uri"):
            if connect_id != res[1]:
               delta["hanaconnect-uri"] = connect_uri
               sql += ", hanaconnect_id = ?"
               sql_vars.append(connect_id)

         if specDelta.has_key("schema-list"):
            newval = specDelta["schema-list"]
            if newval != "" and newval != res[2]:
               delta["schema-list"] = newval
               sql += ", schema_list = ?"
               sql_vars.append(newval)

         if specDelta.has_key("rpc-base-uri"):
            newval = rpcBaseUri
            if newval != "" and newval != res[3]:
               delta["rpc-base-uri"] = newval
               sql += ", rpc_base_uri = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-pool-min-size"):
            newval = specDelta["connection-pool-min-size"]
            if newval != res[4]:
               delta["connection-pool-min-size"] = newval
               sql += ", connection_pool_min_size = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-pool-max-size"):
            newval = specDelta["connection-pool-max-size"]
            if newval != res[5]:
               delta["connection-pool-max-size"] = newval
               sql += ", connection_pool_max_size = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-timeout"):
            newval = specDelta["connection-timeout"]
            if newval != res[6]:
               delta["connection-timeout"] = newval
               sql += ", connection_timeout = ?"
               sql_vars.append(newval)

         if specDelta.has_key("request-timeout"):
            newval = specDelta["request-timeout"]
            if newval != res[7]:
               delta["request-timeout"] = newval
               sql += ", request_timeout = ?"
               sql_vars.append(newval)

         ## proceed when there is an actual change in data
         ##
         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE hanaremote SET %s WHERE id = ?" % sql, sql_vars)

            ## recache in services if necessary
            ##
            services = self.proto.factory.services
            if services.has_key("hanaremoter"):
               services["hanaremoter"].recache(txn)

            ## dispatch on-modified events
            ##
            self.proto.dispatch(URI_EVENT + "on-hanaremote-modified", delta, [self.proto])

            ## return object delta
            ##
            delta["uri"] = self.proto.shrink(uri)

            if delta.has_key("require-appcred-uri") and delta["require-appcred-uri"] is not None:
               delta["require-appcred-uri"] = self.proto.shrink(appcred_uri)

            if delta.has_key("hanaconnect-uri") and delta["hanaconnect-uri"] is not None:
               delta["hanaconnect-uri"] = self.proto.shrink(connect_uri)

            return delta
         else:
            ## object unchanged
            ##
            return {}
      else:
         raise Exception(URI_ERROR + "no-such-object", "No HANA remote with URI %s" % uri)


   @exportRpc("modify-hanaremote")
   def modifyHanaRemote(self, hanaRemoteUri, specDelta):
      """
      Modify a SAP HANA remote.
      """
      return self.proto.dbpool.runInteraction(self._modifyHanaRemote, hanaRemoteUri, specDelta)


   def _deleteHanaRemote(self, txn, hanaRemoteUri):

      ## check arguments
      ##
      if type(hanaRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument hanaRemoteUri, but got %s" % str(type(hanaRemoteUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(hanaRemoteUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM hanaremote WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         txn.execute("DELETE FROM hanaremote WHERE id = ?", [id])

         ## recache in services if necessary
         ##
         services = self.proto.factory.services
         if services.has_key("hanaremoter"):
            services["hanaremoter"].recache(txn)

         ## dispatch on-deleted events
         ##
         self.proto.dispatch(URI_EVENT + "on-hanaremote-deleted", uri, [self.proto])

         return self.proto.shrink(uri)
      else:
         raise Exception(URI_ERROR + "no-such-object", "No HANA remote with URI %s" % uri)


   @exportRpc("delete-hanaremote")
   def deleteHanaRemote(self, hanaRemoteUri):
      """
      Delete a HANA remote.
      """
      return self.proto.dbpool.runInteraction(self._deleteHanaRemote, hanaRemoteUri)


   @exportRpc("get-hanaremotes")
   def getHanaRemotes(self):
      """
      Return HANA remotes list.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, require_appcred_id, hanaconnect_id, schema_list, rpc_base_uri, connection_pool_min_size, connection_pool_max_size, connection_timeout, request_timeout FROM hanaremote ORDER BY require_appcred_id, rpc_base_uri, created")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_HANAREMOTE + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "require-appcred-uri": self.proto.shrink(URI_APPCRED + r[3]) if r[3] else None,
                                  "hanaconnect-uri": self.proto.shrink(URI_APPCRED + r[4]) if r[4] else None,
                                  "schema-list": r[5],
                                  "rpc-base-uri": r[6],
                                  "connection-pool-min-size": r[7],
                                  "connection-pool-max-size": r[8],
                                  "connection-timeout": r[9],
                                  "request-timeout": r[10]} for r in res])
      return d


   @exportRpc("query-hanapool")
   def queryHanaPool(self, hanaRemoteUri):
      """
      Query current SAP HANA database connection pool for remote.
      """
      if type(hanaRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument hanaRemoteUri, but got %s" % str(type(hanaRemoteUri)))

      uri = self.proto.resolveOrPass(hanaRemoteUri)
      id = self.proto.uriToId(uri)

      if self.proto.factory.services.has_key("hanaremoter"):
         res = self.proto.factory.services["hanaremoter"].queryPool(id)
         if res is not None:
            r = []
            for c in sorted(res):
               r.append({'created': c[1], 'backend-pid': c[0]})
            return r
         else:
            raise Exception(URI_ERROR + "no-such-object", "No SAP HANA remote with URI %s" % uri)
      else:
         return []


   def _getHanaApiSorted(self, res):
      r = []
      for k in sorted(res.keys()):
         rr = res[k]
         r.append((k, rr[0], rr[1], rr[2]))
      return r


   @exportRpc("query-hanaapi")
   def queryHanaApi(self, hanaRemoteUri):
      """
      Query SAP HANA remoted API for this remote.
      """
      if type(hanaRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument hanaRemoteUri, but got %s" % str(type(hanaRemoteUri)))

      uri = self.proto.resolveOrPass(hanaRemoteUri)
      id = self.proto.uriToId(uri)

      if self.proto.factory.services.has_key("hanaremoter"):
         d = self.proto.factory.services["hanaremoter"].queryApi(id)
         if d is not None:
            d.addCallback(self._getHanaApiSorted)
            return d
         else:
            raise Exception(URI_ERROR + "no-such-object", "No SAP HANA remote with URI %s" % uri)
      else:
         return []


   @exportRpc("query-hanaapi-by-appkey")
   def queryHanaApiByAppKey(self, appkey):
      """
      Query SAP HANA remoted API by authentication key.
      """
      return self.proto.factory.services["hanaremoter"].getRemotes(appkey)

########NEW FILE########
__FILENAME__ = oraconnects
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import uuid, binascii, socket, types

from twisted.python import log
from twisted.python.failure import Failure

from twisted.internet.threads import deferToThread
from twisted.internet.defer import Deferred, returnValue, inlineCallbacks, CancelledError, succeed

from netaddr.ip import IPAddress

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.txutil import isValidHostname

from crossbar.adminwebmodule.uris import *

from crossbar.bridge import oraschema
from crossbar.bridge import oraschemarepo
from crossbar.bridge import oraschemademo



class OraConnects:
   """
   Oracle connects.
   """

   # We use the same restrictions as for Oracle database name for SID, though
   # the rules for SID are actually platform dependent:
   #
   #  "Restrictions related to the valid characters in an ORACLE_SID are
   #   platform-specific. On some platforms, the SID is case-sensitive."
   #
   # http://docs.oracle.com/cd/E11882_01/server.112/e25513/initparams064.htm#REFRN10041
   # http://docs.oracle.com/cd/E11882_01/server.112/e10595/create003.htm#i1008816
   #
   ORACLE_SID_PATTERN = "^[a-zA-Z0-9_#\$]*$"
   ORACLE_SID_MIN_LENGTH = 1
   ORACLE_SID_MAX_LENGTH = 8

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _checkSpec(self, spec, specDelta, errs):

      errcnt = 0

      if not errs["host"] and specDelta.has_key("host"):
         host = str(specDelta["host"]).strip()
         try:
            addr = IPAddress(host)
            specDelta["host"] = str(addr) # return normalized IP
         except Exception, e:
            if not isValidHostname(host):
               errs["host"].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"),
                                    "Illegal value '%s' for host - not a hostname, and not a valid IP address (%s)." % (host, str(e))))
               errcnt += 1
            else:
               try:
                  a = socket.gethostbyname(host)
                  specDelta["host"] = host
               except Exception, e:
                  errs["host"].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"),
                                       "Illegal value '%s' for host - hostname could not be resolved (%s)." % (host, str(e))))
                  errcnt += 1

      if not errs['sid'] and specDelta.has_key('sid'):
         specDelta['sid'] = specDelta['sid'].strip().upper()

      if not errs['user'] and specDelta.has_key('user'):
         specDelta['user'] = specDelta['user'].strip().upper()

      if not errs['demo-user'] and specDelta.has_key('demo-user') and specDelta['demo-user'] is not None:
         specDelta['demo-user'] = specDelta['demo-user'].strip().upper()
         if specDelta['demo-user'] == "":
            specDelta['demo-user'] = None

      if not errs['demo-password'] and specDelta.has_key('demo-password') and specDelta['demo-password'] is not None:
         specDelta['demo-password'] = specDelta['demo-password'].strip()
         if specDelta['demo-password'] == "":
            specDelta['demo-password'] = None

      if not errs['label'] and specDelta.has_key('label'):
         specDelta['label'] = specDelta['label'].strip()

      return errcnt


   def _checkDupConnect2(self, txn, id, spec, specDelta, errs):
      ## check for duplicate (host, port, sid, user)
      ##
      errcnt = 0

      attrs = ['host', 'port', 'sid', 'user', 'demo-user']
      attrvals = {}
      for a in attrs:
         if not errs[a] and specDelta.has_key(a):
            attrvals[a] = specDelta[a]
         else:
            attrvals[a] = spec[a]

      if id is None:
         txn.execute("SELECT id FROM oraconnect WHERE host = ? AND port = ? AND sid = ? AND (user = ? OR demo_user = ?)",
                     [attrvals['host'], attrvals['port'], attrvals['sid'], attrvals['user'], attrvals['demo-user']])
      else:
         txn.execute("SELECT id FROM oraconnect WHERE host = ? AND port = ? AND sid = ? AND (user = ? OR demo_user = ?) AND id != ?",
                     [attrvals['host'], attrvals['port'], attrvals['sid'], attrvals['user'], attrvals['demo-user'], id])

      res = txn.fetchall()
      if res and len(res) > 0:
         for e in attrs:
            if specDelta.has_key(e):
               errs[e].append((self.proto.shrink(URI_ERROR + "duplicate-attribute-value"),
                               "%d database connect already exist for same Host, Port, SID, Repo-User/Demo-User" % len(res)))
               errcnt += 1

      return errcnt


   def _checkDupConnect(self, txn, id, spec, specDelta, errs):
      ## check for duplicate (host, port, sid)
      ##
      errcnt = 0

      attrs = ['host', 'port', 'sid']
      attrvals = {}
      for a in attrs:
         if not errs[a] and specDelta.has_key(a):
            attrvals[a] = specDelta[a]
         else:
            attrvals[a] = spec[a]

      if id is None:
         txn.execute("SELECT id FROM oraconnect WHERE host = ? AND port = ? AND sid = ?",
                     [attrvals['host'], attrvals['port'], attrvals['sid']])
      else:
         txn.execute("SELECT id FROM oraconnect WHERE host = ? AND port = ? AND sid = ? AND id != ?",
                     [attrvals['host'], attrvals['port'], attrvals['sid'], id])

      res = txn.fetchall()
      if res and len(res) > 0:
         for e in attrs:
            if specDelta.has_key(e):
               errs[e].append((self.proto.shrink(URI_ERROR + "duplicate-attribute-value"),
                               "%d database connect already exist for same Host/Port/SID" % len(res)))
               errcnt += 1

      return errcnt


   def _createOraConnect(self, txn, spec):

      ## check arguments
      ##
      attrs = {"label": (True, [str, unicode], 3, 20),
               "host": (True, [str, unicode], 0, 255),
               "port": (True, [int], 1, 65535),
               "sid": (True, [str, unicode], OraConnects.ORACLE_SID_MIN_LENGTH, OraConnects.ORACLE_SID_MAX_LENGTH, OraConnects.ORACLE_SID_PATTERN),
               "user": (True, [str, unicode], 1, 30),
               "password": (True, [str, unicode], 1, 30),
               "demo-user": (False, [str, unicode, types.NoneType], 0, 30),
               "demo-password": (False, [str, unicode, types.NoneType], 0, 30),
               "connection-timeout": (True, [int], 2, 120)}

      errcnt, errs = self.proto.checkDictArg("oraconnect spec", spec, attrs)

      errcnt += self._checkSpec({}, spec, errs)

      self.proto.raiseDictArgException(errs)

      errcnt += self._checkDupConnect(txn, None, {}, spec, errs)

      self.proto.raiseDictArgException(errs)

      if not spec.has_key("demo-user"):
         spec["demo-user"] = None

      if not spec.has_key("demo-password"):
         spec["demo-password"] = None

      ## insert new object into service database
      ##
      id = newid()
      uri = URI_ORACONNECT + id
      now = utcnow()

      txn.execute("INSERT INTO oraconnect (id, created, label, host, port, sid, user, password, demo_user, demo_password, connection_timeout) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                  [id,
                   now,
                   spec["label"],
                   spec["host"],
                   spec["port"],
                   spec["sid"],
                   spec["user"],
                   spec["password"],
                   spec["demo-user"],
                   spec["demo-password"],
                   spec["connection-timeout"]])

      ## recache in services if necessary
      ##
      services = self.proto.factory.services
      if services.has_key("orapusher"):
         services["orapusher"].recache(txn)
      if services.has_key("oraremoter"):
         services["oraremoter"].recache(txn)

      obj = {"uri": uri,
             "created": now,
             "label": spec["label"],
             "host": spec["host"],
             "port": spec["port"],
             "sid": spec["sid"],
             "user": spec["user"],
             "password": spec["password"],
             "demo-user": spec["demo-user"],
             "demo-password": spec["demo-password"],
             "connection-timeout": spec["connection-timeout"]}

      ## dispatch on-created event
      ##
      self.proto.dispatch(URI_EVENT + "on-oraconnect-created", obj, [self.proto])

      ## return complete object
      ##
      obj["uri"] = self.proto.shrink(uri)
      return obj


   @exportRpc("create-oraconnect")
   def createOraConnect(self, spec):
      """
      Create a new Oracle database connect.
      """
      return self.proto.dbpool.runInteraction(self._createOraConnect, spec)


   def _deleteOraConnect(self, txn, oraConnectUri, cascade):

      ## check arguments
      ##
      if type(oraConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument oraConnectUri, but got %s" % str(type(oraConnectUri)))

      if type(cascade) not in [bool]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type bool for agument cascade, but got %s" % str(type(cascade)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(oraConnectUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM oraconnect WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check for depending oraremotes
         ##
         txn.execute("SELECT id FROM oraremote WHERE oraconnect_id = ?", [id])
         dependingRemotes = []
         for r in txn.fetchall():
            dependingRemotes.append(r[0])

         ## check for depending orapushrules
         ##
         txn.execute("SELECT id FROM orapushrule WHERE oraconnect_id = ?", [id])
         dependingPushRules = []
         for r in txn.fetchall():
            dependingPushRules.append(r[0])

         ## delete depending objects and object
         ##
         if len(dependingRemotes) > 0 or len(dependingPushRules) > 0:
            if not cascade:
               raise Exception(URI_ERROR + "depending-objects",
                               "Cannot delete database connect: %d depending remotes, %d depending pushrules" % (len(dependingRemotes), len(dependingPushRules)),
                               ([self.proto.shrink(URI_ORAREMOTE + id) for id in dependingRemotes],
                                [self.proto.shrink(URI_ORAPUSHRULE + id) for id in dependingPushRules]))
            else:
               if len(dependingRemotes) > 0:
                  txn.execute("DELETE FROM oraremote WHERE oraconnect_id = ?", [id])
               if len(dependingPushRules) > 0:
                  txn.execute("DELETE FROM orapushrule WHERE oraconnect_id = ?", [id])

         txn.execute("DELETE FROM oraconnect WHERE id = ?", [id])

         ## recache in services if necessary
         ##
         services = self.proto.factory.services
         if len(dependingRemotes) > 0 and services.has_key("oraremoter"):
            services["oraremoter"].recache(txn)

         if len(dependingPushRules) and services.has_key("orapusher"):
            services["orapusher"].recache(txn)

         ## dispatch on-deleted events
         ##
         for id in dependingRemotes:
            self.proto.dispatch(URI_EVENT + "on-oraremote-deleted", URI_ORAREMOTE + id, [])

         for id in dependingPushRules:
            self.proto.dispatch(URI_EVENT + "on-orapushrule-deleted", URI_ORAPUSHRULE + id, [])

         self.proto.dispatch(URI_EVENT + "on-oraconnect-deleted", uri, [self.proto])

         ## return deleted object URI
         ##
         return self.proto.shrink(uri)

      else:
         raise Exception(URI_ERROR + "no-such-object", "No Oracle connect with URI %s" % uri)


   @exportRpc("delete-oraconnect")
   def deleteOraConnect(self, oraConnectUri, cascade = False):
      """
      Delete an Oracle database connect.
      """
      return self.proto.dbpool.runInteraction(self._deleteOraConnect, oraConnectUri, cascade)


   def _modifyOraConnect(self, txn, oraConnectUri, specDelta):

      ## check arguments
      ##
      if type(oraConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument oraConnectUri, but got %s" % str(type(oraConnectUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(oraConnectUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT label, host, port, sid, user, password, demo_user, demo_password, connection_timeout FROM oraconnect WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## existing definition
         ##
         spec = {}
         spec['label'] = res[0]
         spec['host'] = res[1]
         spec['port'] = int(res[2])
         spec['sid'] = res[3]
         spec['user'] = res[4]
         spec['password'] = res[5]
         spec['demo-user'] = res[6]
         spec['demo-password'] = res[7]
         spec['connection-timeout'] = int(res[8])

         ## check arguments
         ##
         attrs = {"label": (False, [str, unicode], 3, 20),
                  "host": (False, [str, unicode], 0, 255),
                  "port": (False, [int], 1, 65535),
                  "sid": (False, [str, unicode], OraConnects.ORACLE_SID_MIN_LENGTH, OraConnects.ORACLE_SID_MAX_LENGTH, OraConnects.ORACLE_SID_PATTERN),
                  "user": (False, [str, unicode], 1, 30),
                  "password": (False, [str, unicode], 1, 30),
                  "demo-user": (False, [str, unicode, types.NoneType], 0, 30),
                  "demo-password": (False, [str, unicode, types.NoneType], 0, 30),
                  "connection-timeout": (False, [int], 2, 120)}

         errcnt, errs = self.proto.checkDictArg("oraconnect delta spec", specDelta, attrs)

         errcnt += self._checkSpec(spec, specDelta, errs)

         errcnt += self._checkDupConnect(txn, id, spec, specDelta, errs)

         self.proto.raiseDictArgException(errs)

         ## compute delta and SQL
         ##
         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         # [(API attribute, DB column name, DB column index)]
         for p in [('label', 'label', 0),
                   ('host', 'host', 1),
                   ('port', 'port', 2),
                   ('sid', 'sid', 3),
                   ('user', 'user', 4),
                   ('password', 'password', 5),
                   ('demo-user', 'demo_user', 6),
                   ('demo-password', 'demo_password', 7),
                   ('connection-timeout', 'connection_timeout', 8)]:
            if specDelta.has_key(p[0]):
               newval = specDelta[p[0]]
               if newval != res[p[2]]:
                  delta[p[0]] = newval
                  sql += ", %s = ?" % p[1]
                  sql_vars.append(newval)

         ## proceed when there is an actual change in data
         ##
         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE oraconnect SET %s WHERE id = ?" % sql, sql_vars)

            ## recache in services if necessary
            ##
            services = self.proto.factory.services
            if services.has_key("orapusher"):
               services["orapusher"].recache(txn)
            if services.has_key("oraremoter"):
               services["oraremoter"].recache(txn)

            ## dispatch on-modified events
            ##
            self.proto.dispatch(URI_EVENT + "on-oraconnect-modified", delta, [self.proto])

            ## return object delta
            ##
            delta["uri"] = self.proto.shrink(uri)
            return delta
         else:
            ## object unchanged
            ##
            return {}

      else:
         raise Exception(URI_ERROR + "no-such-object", "No Oracle connect with URI %s" % uri)


   @exportRpc("modify-oraconnect")
   def modifyOraConnect(self, oraConnectUri, specDelta):
      """
      Modify an Oracle database connect.
      """
      return self.proto.dbpool.runInteraction(self._modifyOraConnect, oraConnectUri, specDelta)


   @exportRpc("get-oraconnects")
   def getOraConnects(self):
      """
      Return list of Oracle database connects.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, label, host, port, sid, user, password, demo_user, demo_password, connection_timeout FROM oraconnect ORDER BY label, user, sid, id ASC")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_ORACONNECT + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "label": r[3],
                                  "host": r[4],
                                  "port": r[5],
                                  "sid": r[6],
                                  "user": r[7],
                                  "password": r[8],
                                  "demo-user": r[9],
                                  "demo-password": r[10],
                                  "connection-timeout": r[11]} for r in res])
      return d


   def _getOraConnectPusherState(self, txn, oraConnectUri):

      ## check arguments
      ##
      if type(oraConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument oraConnectUri, but got %s" % str(type(oraConnectUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(oraConnectUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM oraconnect WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         if self.proto.factory.services.has_key("orapusher"):
            return self.proto.factory.services["orapusher"].getPusherState(id)
         else:
            raise Exception("orapusher not running")

      else:
         raise Exception(URI_ERROR + "no-such-object", "No Oracle connect with URI %s" % uri)


   @exportRpc("get-oraconnect-pusherstate")
   def getOraConnectPusherState(self, oraConnectUri):
      """
      Retrieve the current state of database pusher associated with this connect (if any).
      """
      return self.proto.dbpool.runInteraction(self._getOraConnectPusherState, oraConnectUri)


   @exportRpc("generate-ora-createschema-script")
   def generateOraCreateSchemaScript(self, user, userPassword, demoUser = None, demoPassword = None):
      """
      Generate script for creating repository schema/user.
      """
      return oraschema.getCreateUsersScript(user, userPassword, demoUser = demoUser, demoPassword = demoPassword)


   @exportRpc("generate-oraconnect-createschema-script")
   def generateOraConnectCreateSchemaScript(self, oraConnectUri = None):
      """
      Generate script for creating repository schema/user.
      """

      if oraConnectUri is not None:
         ## check arguments
         ##
         if type(oraConnectUri) not in [str, unicode]:
            raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument oraConnectUri, but got %s" % str(type(oraConnectUri)))

         ## resolve URI to database object ID
         ##
         uri = self.proto.resolveOrPass(oraConnectUri)
         id = self.proto.uriToId(uri)

         ## get database connection definition and test ..
         ##
         d = self.proto.dbpool.runQuery("SELECT user, password, demo_user, demo_password FROM oraconnect WHERE id = ?", [id])
      else:
         d = succeed([['CROSSBAR', 'crossbar', 'CROSSBARDEMO', 'crossbardemo']])

      def start(res):
         if res is not None and len(res) > 0:
            res = res[0]
            user = str(res[0])
            password = str(res[1])
            demoUser = str(res[2]) if res[2] is not None else None
            demoPassword = str(res[3]) if res[3] is not None else None
            return self.generateOraCreateSchemaScript(user, password, demoUser, demoPassword)
         else:
            raise Exception(URI_ERROR + "no-such-object", "No Oracle connect with URI %s" % uri)

      d.addCallback(start)
      return d


   @exportRpc("generate-ora-dropschema-script")
   def generateOraDropSchemaScript(self, user, demoUser = None):
      """
      Generate script for dropping repository schema/user.
      """
      return oraschema.getDropUsersScript(user, demoUser)


   @exportRpc("execute-ora-createschema-script")
   def executeOraCreateSchemaScript(self, connect, user, userPassword, demoUser = None, demoPassword = None):
      script = oraschema.getCreateUsersScript(user, userPassword, demoUser = demoUser, demoPassword = demoPassword)
      return self._dbExecuteImmediate(connect, script)


   @exportRpc("execute-ora-dropschema-script")
   def executeOraDropSchemaScript(self, connect, user, demoUser = None):
      script = oraschema.getDropUsersScript(user, demoUser)
      return self._dbExecuteImmediate(connect, script)




   @exportRpc("generate-oraconnect-dropschema-script")
   def generateOraConnectDropSchemaScript(self, oraConnectUri = None):
      """
      Generate script for dropping repository schema/user.
      """

      if oraConnectUri is not None:
         ## check arguments
         ##
         if type(oraConnectUri) not in [str, unicode]:
            raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument oraConnectUri, but got %s" % str(type(oraConnectUri)))

         ## resolve URI to database object ID
         ##
         uri = self.proto.resolveOrPass(oraConnectUri)
         id = self.proto.uriToId(uri)

         ## get database connection definition and test ..
         ##
         d = self.proto.dbpool.runQuery("SELECT user, demo_user FROM oraconnect WHERE id = ?", [id])
      else:
         d = succeed([['CROSSBAR', 'CROSSBARDEMO']])

      def start(res):
         if res is not None and len(res) > 0:
            res = res[0]
            user = str(res[0])
            demoUser = str(res[1]) if res[1] is not None else None
            return self.generateOraDropSchemaScript(user, demoUser)
         else:
            raise Exception(URI_ERROR + "no-such-object", "No Oracle connect with URI %s" % uri)

      d.addCallback(start)
      return d


   def _dbexecute(self, oraConnectUri, runme, category = "repository"):
      """
      Execute something on a fresh, short-lived database connection on a background thread.

      :param oraConnectUri: URI of Oracle connect.
      :type oraConnectUri: str
      :param runme: Callable that will get a database connection as argument and should return it's results.
      :type runme: callable
      """

      ## check arguments
      ##
      if type(oraConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument oraConnectUri, but got %s" % str(type(oraConnectUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(oraConnectUri)
      id = self.proto.uriToId(uri)

      ## get database connection definition and test ..
      ##
      d = self.proto.dbpool.runQuery("SELECT host, port, sid, user, password, demo_user, demo_password, connection_timeout FROM oraconnect WHERE id = ?", [id])

      def start(res):
         if res is not None and len(res) > 0:

            res = res[0]

            host = str(res[0])
            port = int(res[1])
            sid = str(res[2])
            user = str(res[3])
            password = str(res[4])
            demoUser = str(res[5]) if res[5] is not None else None
            demoPassword = str(res[6]) if res[6] is not None else None
            connection_timeout = int(res[7])

            if category == "demo":
               if demoUser is None or demoUser == "":
                  raise Exception(URI_ERROR + "illegal-argument", "Oracle connect with URI %s has no demo user configured" % uri)
               else:
                  user = demoUser
                  password = demoPassword
            elif category == "repository":
               pass
            else:
               raise Exception("logic error")

            def doit():
               import os
               #os.environ["NLS_LANG"] = "GERMAN_GERMANY.UTF8"
               os.environ["NLS_LANG"] = "AMERICAN_AMERICA.UTF8"
               import cx_Oracle

               try:
                  dsn = cx_Oracle.makedsn(host, port, sid)
                  conn = cx_Oracle.connect(user, password, dsn, threaded = True)

               except cx_Oracle.DatabaseError, e:
                  error, = e.args
                  code = error.code
                  offset = error.offset
                  message = error.message
                  context = error.context

                  log.msg("OraConnects._dbexecute [%s]" % str(e).strip())

                  if code == 1017:
                     ## ORA-01017: invalid username/password; logon denied
                     raise Failure(Exception(URI_ERROR + "invalid-user-or-password", "Invalid database username or password - login denied."))
                  else:
                     ## => produce generic SQL error
                     ##
                     raise Failure(Exception(URI_ERROR_SQL + ("%d" % code), message.strip()))

               except Exception, e:
                  ## => produce generic error
                  ##
                  log.msg("OraConnects._dbexecute [%s]" % str(e).strip())
                  raise Failure(Exception(URI_ERROR, str(e).strip()))

               app = self.proto.factory.services["master"]
               return runme(app, conn)

            d = deferToThread(doit)

            def onerror(failure):
               if failure.check(CancelledError):
                  raise Exception(URI_ERROR + "failure", "connection timeout")
               elif isinstance(failure, Failure):
                  raise failure
               else:
                  m = failure.getErrorMessage()
                  raise Exception(URI_ERROR + "failure", m)

            def onsuccess(r):
               r['uri'] = uri
               return r

            d.addCallback(onsuccess)
            d.addErrback(onerror)

            ## there seems to be no way of altering the connection timeout
            ## hardcoded into OCI (which when fires produces ORA-12170: TNS: Connect Timeout)
            #if connection_timeout > 0:
            #   reactor.callLater(connection_timeout, d.cancel)

            return d

         else:
            raise Exception(URI_ERROR + "no-such-object", "No Oracle connect with URI %s" % uri)

      d.addCallback(start)
      return d


   def _dbExecuteImmediate(self, connect, script):

      def doit():
         import os
         os.environ["NLS_LANG"] = "AMERICAN_AMERICA.UTF8"

         import cx_Oracle

         MODES = {'SYSDBA': cx_Oracle.SYSDBA,
                  'SYSOPER': cx_Oracle.SYSOPER}

         try:
            dsn = cx_Oracle.makedsn(connect['host'], connect['port'], connect['sid'])
            mode = connect.get('mode', 'normal').upper()
            if MODES.has_key(mode):
               conn = cx_Oracle.connect(connect['user'], connect['password'], dsn, mode = MODES[mode], threaded = True)
            else:
               conn = cx_Oracle.connect(connect['user'], connect['password'], dsn, threaded = True)

            cur = conn.cursor()
            blocks = script.split('/')
            n = 1
            for b in blocks:
               s = b.strip()
               if len(s) > 0:
                  log.msg("Executing block %d:\n%s" % (n, s))
                  cur.execute(s)
                  n += 1

         except cx_Oracle.DatabaseError, e:
            error, = e.args
            code = error.code
            offset = error.offset
            message = error.message
            context = error.context

            log.msg("Error - OraConnects._dbExecuteImmediate [%s]" % str(e).strip())

            if code == 1017:
               ## ORA-01017: invalid username/password; logon denied
               raise Failure(Exception(URI_ERROR + "invalid-user-or-password", "Invalid database username or password - login denied."))
            else:
               ## => produce generic SQL error
               ##
               raise Failure(Exception(URI_ERROR_SQL + ("%d" % code), message.strip()))

         except Exception, e:
            ## => produce generic error
            ##
            log.msg("OraConnects._dbexecute [%s]" % str(e).strip())
            raise Failure(Exception(URI_ERROR, str(e).strip()))

      d = deferToThread(doit)

      def onerror(failure):
         if failure.check(CancelledError):
            raise Exception(URI_ERROR + "failure", "connection timeout")
         elif isinstance(failure, Failure):
            raise failure
         else:
            m = failure.getErrorMessage()
            raise Exception(URI_ERROR + "failure", m)

      def onsuccess(r):
         return r

      d.addCallback(onsuccess)
      d.addErrback(onerror)

      ## there seems to be no way of altering the connection timeout
      ## hardcoded into OCI (which when fires produces ORA-12170: TNS: Connect Timeout)
      #if connection_timeout > 0:
      #   reactor.callLater(connection_timeout, d.cancel)

      return d


   @exportRpc("install-oraconnect-schema")
   def installOraConnectSchema(self, oraConnectUri, category = "repository"):
      """
      Setup schema in Oracle.
      """
      m = {'demo': oraschemademo.setupSchema,
           'repository': oraschemarepo.setupSchema}

      if m.has_key(category):
         d = self._dbexecute(oraConnectUri, m[category], category)
      else:
         raise Exception(URI_ERROR + "illegal-argument", "Invalid schema category '%s'" % category)

      def done(res):
         self.proto.dispatch(URI_EVENT + "on-oraconnect-schema-changed", res, [self.proto])
         res['uri'] = self.proto.shrink(res['uri'])
         return res

      d.addCallback(done)
      return d


   @exportRpc("reinstall-oraconnect-schema")
   def reinstallOraConnectSchema(self, oraConnectUri, category = "repository"):
      """
      Reinstall schema in Oracle.
      """
      m = {'demo': oraschemademo.reinstallSchema,
           'repository': oraschemarepo.reinstallSchema}

      if m.has_key(category):
         d = self._dbexecute(oraConnectUri, m[category], category)
      else:
         raise Exception(URI_ERROR + "illegal-argument", "Invalid schema category '%s'" % category)

      def done(res):
         self.proto.dispatch(URI_EVENT + "on-oraconnect-schema-changed", res, [self.proto])
         res['uri'] = self.proto.shrink(res['uri'])
         return res

      d.addCallback(done)
      return d


   @exportRpc("uninstall-oraconnect-schema")
   def uninstallOraConnectSchema(self, oraConnectUri, category = "repository"):
      """
      Uninstall schema from Oracle.
      """
      m = {'demo': oraschemademo.dropSchema,
           'repository': oraschemarepo.dropSchema}

      if m.has_key(category):
         d = self._dbexecute(oraConnectUri, m[category], category)
      else:
         raise Exception(URI_ERROR + "illegal-argument", "Invalid schema category '%s'" % category)

      def done(res):
         self.proto.dispatch(URI_EVENT + "on-oraconnect-schema-changed", res, [self.proto])
         res['uri'] = self.proto.shrink(res['uri'])
         return res

      d.addCallback(done)
      return d


   @exportRpc("upgrade-oraconnect-schema")
   def upgradeOraConnectSchema(self, oraConnectUri, category = "repository"):
      """
      Upgrade schema in Oracle.
      """
      m = {'demo': oraschemademo.upgradeSchema,
           'repository': oraschemarepo.upgradeSchema}

      if m.has_key(category):
         d = self._dbexecute(oraConnectUri, m[category], category)
      else:
         raise Exception(URI_ERROR + "illegal-argument", "Invalid schema category '%s'" % category)

      def done(res):
         self.proto.dispatch(URI_EVENT + "on-oraconnect-schema-changed", res, [self.proto])
         res['uri'] = self.proto.shrink(res['uri'])
         return res

      d.addCallback(done)
      return d


   @exportRpc("get-oraconnect-schema-version")
   def getOraConnectSchemaVersion(self, oraConnectUri, category = "repository"):
      """
      Get schema information from Oracle.
      """
      m = {'demo': oraschemademo.getSchemaVersion,
           'repository': oraschemarepo.getSchemaVersion}

      if m.has_key(category):
         return self._dbexecute(oraConnectUri, m[category], category)
      else:
         raise Exception(URI_ERROR + "illegal-argument", "Invalid schema category '%s'" % category)


   @exportRpc("test-oraconnect-schema")
   def testOraConnectSchema(self, oraConnectUri, category = "repository"):
      """
      Test an Oracle schema by retrieving some basic database information.
      """
      return self._dbexecute(oraConnectUri, oraschema.getDatabaseInfo, category)

########NEW FILE########
__FILENAME__ = orapushrules
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class OraPushRules:
   """
   Oracle push rules.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _checkSpec(self, spec, specDelta, errs):

      errcnt = 0

      if not errs["user"]:
         if specDelta.has_key('user') and specDelta['user'] is not None:
            if specDelta['user'].strip() == "":
               specDelta['user'] = None
            else:
               try:
                  specDelta['user'] = ','.join(sorted([x.strip().upper() for x in specDelta['user'].split(',')]))
               except Exception, e:
                  errs["user"].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"), "Illegal value '%s' for schema list [%s]." % (spec["schema-list"], str(e))))
                  errcnt += 1

      return errcnt


   def _createOraPushRule(self, txn, spec):

      ## check arguments
      ##
      attrs = {"topic-uri": (True, [str, unicode], 0, URI_MAXLEN),
               "match-by-prefix": (True, [bool]),
               "user": (False, [str, unicode, types.NoneType], 30),
               "oraconnect-uri": (True, [str, unicode], 0, URI_MAXLEN)}

      errcnt, errs = self.proto.checkDictArg("orapushrule spec", spec, attrs)

      if not errs["topic-uri"]:
         topic_uri, errs2 = self.proto.validateUri(spec["topic-uri"])
         errs["topic-uri"].extend(errs2)
         errcnt += len(errs2)

      oraconnect_id = None
      oraconnect_uri = None
      if spec.has_key("oraconnect-uri") and spec["oraconnect-uri"] is not None and spec["oraconnect-uri"].strip() != "":
         oraconnect_uri = self.proto.resolveOrPass(spec["oraconnect-uri"].strip())
         oraconnect_id = self.proto.uriToId(oraconnect_uri)
         txn.execute("SELECT created FROM oraconnect WHERE id = ?", [oraconnect_id])
         if txn.fetchone() is None:
            errs["oraconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No ORA connect with URI %s" % appcred_uri))

      errcnt += self._checkSpec({}, spec, errs)

      self.proto.raiseDictArgException(errs)


      ## insert new object into service database
      ##
      id = newid()
      uri = URI_ORAPUSHRULE + id
      now = utcnow()
      user = spec['user'] if spec.has_key('user') else None

      txn.execute("INSERT INTO orapushrule (id, created, modified, oraconnect_id, user, topic_uri, match_by_prefix) VALUES (?, ?, ?, ?, ?, ?, ?)",
                  [id,
                   now,
                   None,
                   oraconnect_id,
                   user,
                   topic_uri,
                   int(spec["match-by-prefix"])])

      ## recache in services if necessary
      ##
      services = self.proto.factory.services
      if services.has_key("orapusher"):
         services["orapusher"].recache(txn)

      obj = {"uri": uri,
             "created": now,
             "modified": None,
             "oraconnect-uri": oraconnect_uri,
             "user": user,
             "topic-uri": topic_uri,
             "match-by-prefix": spec["match-by-prefix"]}

      ## dispatch on-created event
      ##
      self.proto.dispatch(URI_EVENT + "on-orapushrule-created", obj, [self.proto])

      ## return complete object
      ##
      obj["uri"] = self.proto.shrink(uri)
      if obj["oraconnect-uri"] is not None:
         obj["oraconnect-uri"] = self.proto.shrink(oraconnect_uri)

      return obj


   @exportRpc("create-orapushrule")
   def createOraPushRule(self, spec):
      """
      Create a new Oracle push rule.
      """
      return self.proto.dbpool.runInteraction(self._createOraPushRule, spec)


   def _deleteOraPushRule(self, txn, oraPushRuleUri):

      ## check arguments
      ##
      if type(oraPushRuleUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument oraPushRuleUri, but got %s" % str(type(oraPushRuleUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(oraPushRuleUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM orapushrule WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         txn.execute("DELETE FROM orapushrule WHERE id = ?", [id])

         ## recache in services if necessary
         ##
         services = self.proto.factory.services
         if services.has_key("orapusher"):
            services["orapusher"].recache(txn)

         ## dispatch on-deleted events
         ##
         self.proto.dispatch(URI_EVENT + "on-orapushrule-deleted", uri, [self.proto])

         ## return deleted object URI
         ##
         return self.proto.shrink(uri)
      else:
         raise Exception(URI_ERROR + "no-such-object", "No ORA push rule with URI %s" % uri)


   @exportRpc("delete-orapushrule")
   def deleteOraPushRule(self, oraPushRuleUri):
      """
      Delete a Oracle push rule.
      """
      return self.proto.dbpool.runInteraction(self._deleteOraPushRule, oraPushRuleUri)


   def _modifyOraPushRule(self, txn, oraPushRuleUri, specDelta):

      ## check arguments
      ##
      if type(oraPushRuleUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument oraPushRuleUri, but got %s" % str(type(oraPushRuleUri)))

      attrs = {"topic-uri": (False, [str, unicode], 0, URI_MAXLEN),
               "match-by-prefix": (False, [bool]),
               "user": (False, [str, unicode, types.NoneType], 0, 30),
               "oraconnect-uri": (False, [str, unicode], 0, URI_MAXLEN)}

      errcnt, errs = self.proto.checkDictArg("ORA pushrule delta spec", specDelta, attrs)

      if not errs["topic-uri"] and specDelta.has_key("topic-uri"):
         topic_uri, errs2 = self.proto.validateUri(specDelta["topic-uri"])
         errs["topic-uri"].extend(errs2)
         errcnt += len(errs2)

      oraconnect_id = None
      oraconnect_uri = None
      if specDelta.has_key("oraconnect-uri") and specDelta["oraconnect-uri"] is not None and specDelta["oraconnect-uri"].strip() != "":
         oraconnect_uri = self.proto.resolveOrPass(specDelta["oraconnect-uri"].strip())
         oraconnect_id = self.proto.uriToId(oraconnect_uri)
         txn.execute("SELECT created FROM oraconnect WHERE id = ?", [oraconnect_id])
         if txn.fetchone() is None:
            errs["oraconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No ORA connect with URI %s" % oraconnect_uri))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(oraPushRuleUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT topic_uri, match_by_prefix, user, oraconnect_id FROM orapushrule WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check arguments
         ##
         spec = {}
         spec["topic-uri"] = res[0]
         spec["match-by-prefix"] = res[1] != 0
         spec["user"] = res[2]
         spec["oraconnect-uri"] = self.proto.shrink(URI_ORACONNECT + res[3]) if res[3] else None

         errcnt += self._checkSpec(spec, specDelta, errs)

         self.proto.raiseDictArgException(errs)

         ## compute delta and SQL
         ##
         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("topic-uri"):
            newval = topic_uri
            if newval != "" and newval != res[0]:
               delta["topic-uri"] = newval
               sql += ", topic_uri = ?"
               sql_vars.append(newval)

         if specDelta.has_key("match-by-prefix"):
            newval = specDelta["match-by-prefix"]
            if newval != (res[1] != 0):
               delta["match-by-prefix"] = newval
               sql += ", match_by_prefix = ?"
               sql_vars.append(newval)

         if specDelta.has_key("user"):
            newval = specDelta["user"]
            if newval != res[2]:
               delta["user"] = newval
               sql += ", user = ?"
               sql_vars.append(newval)

         if specDelta.has_key("oraconnect-uri"):
            if oraconnect_id != res[3]:
               delta["oraconnect-uri"] = oraconnect_uri
               sql += ", oraconnect_id = ?"
               sql_vars.append(oraconnect_id)

         ## proceed when there is an actual change in data
         ##
         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE orapushrule SET %s WHERE id = ?" % sql, sql_vars)

            ## recache in services if necessary
            ##
            services = self.proto.factory.services
            if services.has_key("orapusher"):
               services["orapusher"].recache(txn)

            ## dispatch on-modified events
            ##
            self.proto.dispatch(URI_EVENT + "on-orapushrule-modified", delta, [self.proto])

            ## return object delta
            ##
            delta["uri"] = self.proto.shrink(uri)
            if delta.has_key("oraconnect-uri") and delta["oraconnect-uri"] is not None:
               delta["oraconnect-uri"] = self.proto.shrink(oraconnect_uri)
            return delta
         else:
            ## object unchanged
            ##
            return {}
      else:
         raise Exception(URI_ERROR + "no-such-object", "No ORA push rule with URI %s" % uri)


   @exportRpc("modify-orapushrule")
   def modifyOraPushRule(self, oraPushRuleUri, specDelta):
      """
      Modify a Oracle push rule.
      """
      return self.proto.dbpool.runInteraction(self._modifyOraPushRule, oraPushRuleUri, specDelta)


   @exportRpc("get-orapushrules")
   def getOraPushRules(self):
      """
      Return list of Oracle push rules.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, oraconnect_id, user, topic_uri, match_by_prefix FROM orapushrule ORDER BY oraconnect_id, user, topic_uri")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_ORAPUSHRULE + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "oraconnect-uri": self.proto.shrink(URI_ORACONNECT + r[3]) if r[3] else None,
                                  "user": r[4],
                                  "topic-uri": r[5],
                                  "match-by-prefix": r[6] != 0} for r in res])
      return d

########NEW FILE########
__FILENAME__ = oraremotes
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class OraRemotes:
   """
   Oracle remotes.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _checkSpec(self, spec, specDelta, errs):

      errcnt = 0

      if not errs["schema-list"]:
         if specDelta.has_key('schema-list'):
            try:
               specDelta['schema-list'] = ','.join(sorted([x.strip().lower() for x in specDelta['schema-list'].split(',')]))
            except Exception, e:
               errs["schema-list"].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"), "Illegal value '%s' for schema list [%s]." % (spec["schema-list"], str(e))))
               errcnt += 1

      if not errs["connection-pool-min-size"] and not errs["connection-pool-max-size"]:
         if specDelta.has_key('connection-pool-min-size') or specDelta.has_key('connection-pool-max-size'):
            cpMinSize = specDelta.get('connection-pool-min-size', spec.get('connection-pool-min-size', None))
            cpMaxSize = specDelta.get('connection-pool-max-size', spec.get('connection-pool-max-size', None))
            if cpMinSize > cpMaxSize:
               if specDelta.has_key('connection-pool-min-size'):
                  errs["connection-pool-min-size"].append((self.proto.shrink(URI_ERROR + "invalid-range-value"),
                                                           "Illegal value '%s' for connection pool min size - must be smaller than or equal to max size." % specDelta['connection-pool-min-size']))
                  errcnt += 1
               if specDelta.has_key('connection-pool-max-size'):
                  errs["connection-pool-max-size"].append((self.proto.shrink(URI_ERROR + "invalid-range-value"),
                                                           "Illegal value '%s' for connection pool max size - must be larger than or equal to min size." % specDelta['connection-pool-max-size']))
                  errcnt += 1

      return errcnt


   def _createOraRemote(self, txn, spec):

      ## check arguments
      ##
      attrs = {"require-appcred-uri": (False, [str, unicode, types.NoneType]),
               "oraconnect-uri": (True, [str, unicode]),
               "schema-list": (True, [str, unicode], 0, 1000),
               "rpc-base-uri": (True, [str, unicode], 0, URI_MAXLEN),
               "connection-pool-min-size": (True, [int], 1, 30),
               "connection-pool-max-size": (True, [int], 1, 100),
               "connection-timeout": (True, [int], 0, 120),
               "request-timeout": (True, [int], 0, 120)}

      errcnt, errs = self.proto.checkDictArg("oraremote spec", spec, attrs)

      if not errs["rpc-base-uri"]:
         rpcBaseUri, errs2 = self.proto.validateUri(spec["rpc-base-uri"])
         errs["rpc-base-uri"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and spec.has_key("require-appcred-uri"):
         if spec["require-appcred-uri"] == "null" or spec["require-appcred-uri"] == "":
            spec["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if spec.has_key("require-appcred-uri") and spec["require-appcred-uri"] is not None and spec["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(spec["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      connect_id = None
      connect_uri = None
      if spec.has_key("oraconnect-uri") and spec["oraconnect-uri"] is not None and spec["oraconnect-uri"].strip() != "":
         connect_uri = self.proto.resolveOrPass(spec["oraconnect-uri"].strip())
         connect_id = self.proto.uriToId(connect_uri)
         txn.execute("SELECT created FROM oraconnect WHERE id = ?", [connect_id])
         if txn.fetchone() is None:
            errs["oraconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No ORA connect URI %s" % connect_uri))

      errcnt += self._checkSpec({}, spec, errs)

      self.proto.raiseDictArgException(errs)

      ## insert new object into service database
      ##
      id = newid()
      oraremote_uri = URI_ORAREMOTE + id
      now = utcnow()

      txn.execute("INSERT INTO oraremote (id, created, require_appcred_id, oraconnect_id, schema_list, rpc_base_uri, connection_pool_min_size, connection_pool_max_size, connection_timeout, request_timeout) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                                       [id,
                                        now,
                                        appcred_id,
                                        connect_id,
                                        spec["schema-list"],
                                        rpcBaseUri,
                                        int(spec["connection-pool-min-size"]),
                                        int(spec["connection-pool-max-size"]),
                                        int(spec["connection-timeout"]),
                                        int(spec["request-timeout"])
                                        ])

      ## recache in services if necessary
      ##
      services = self.proto.factory.services
      if services.has_key("oraremoter"):
         services["oraremoter"].recache(txn)

      oraremote = {"uri": oraremote_uri,
                   "require-appcred-uri": appcred_uri,
                   "oraconnect-uri": connect_uri,
                   "schema-list": spec["schema-list"],
                   "rpc-base-uri": rpcBaseUri,
                   "connection-pool-min-size": int(spec["connection-pool-min-size"]),
                   "connection-pool-max-size": int(spec["connection-pool-max-size"]),
                   "connection-timeout": int(spec["connection-timeout"]),
                   "request-timeout": int(spec["request-timeout"])}

      ## dispatch on-created event
      ##
      self.proto.dispatch(URI_EVENT + "on-oraremote-created", oraremote, [self.proto])

      ## return complete object
      ##
      oraremote["uri"] = self.proto.shrink(oraremote_uri)

      if oraremote["require-appcred-uri"] is not None:
         oraremote["require-appcred-uri"] = self.proto.shrink(appcred_uri)

      if oraremote["oraconnect-uri"] is not None:
         oraremote["oraconnect-uri"] = self.proto.shrink(connect_uri)

      return oraremote


   @exportRpc("create-oraremote")
   def createOraRemote(self, spec):
      """
      Create a new Oracle remote.
      """
      return self.proto.dbpool.runInteraction(self._createOraRemote, spec)


   def _modifyOraRemote(self, txn, oraRemoteUri, specDelta):

      ## check arguments
      ##
      if type(oraRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument oraRemoteUri, but got %s" % str(type(oraRemoteUri)))

      attrs = {"require-appcred-uri": (False, [str, unicode, types.NoneType]),
               "oraconnect-uri": (False, [str, unicode]),
               "schema-list": (False, [str, unicode], 0, 1000),
               "rpc-base-uri": (False, [str, unicode], 0, URI_MAXLEN),
               "connection-pool-min-size": (False, [int], 1, 30),
               "connection-pool-max-size": (False, [int], 1, 100),
               "connection-timeout": (False, [int], 0, 120),
               "request-timeout": (False, [int], 0, 120)}

      errcnt, errs = self.proto.checkDictArg("oraremote delta spec", specDelta, attrs)

      if not errs["rpc-base-uri"] and specDelta.has_key("rpc-base-uri"):
         rpcBaseUri, errs2 = self.proto.validateUri(specDelta["rpc-base-uri"])
         errs["rpc-base-uri"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and specDelta.has_key("require-appcred-uri"):
         if specDelta["require-appcred-uri"] == "null" or specDelta["require-appcred-uri"] == "":
            specDelta["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if specDelta.has_key("require-appcred-uri") and specDelta["require-appcred-uri"] is not None and specDelta["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(specDelta["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      connect_id = None
      connect_uri = None
      if specDelta.has_key("oraconnect-uri") and specDelta["oraconnect-uri"] is not None and specDelta["oraconnect-uri"].strip() != "":
         connect_uri = self.proto.resolveOrPass(specDelta["oraconnect-uri"].strip())
         connect_id = self.proto.uriToId(connect_uri)
         txn.execute("SELECT created FROM oraconnect WHERE id = ?", [connect_id])
         if txn.fetchone() is None:
            errs["oraconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No ORA connect URI %s" % connect_uri))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(oraRemoteUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT require_appcred_id, oraconnect_id, schema_list, rpc_base_uri, connection_pool_min_size, connection_pool_max_size, connection_timeout, request_timeout FROM oraremote WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check arguments
         ##
         spec = {}
         spec["require-appcred-uri"] = self.proto.shrink(URI_APPCRED + res[0]) if res[0] else None
         spec["oraconnect-uri"] = self.proto.shrink(URI_ORACONNECT + res[1]) if res[1] else None
         spec["schema-list"] = res[2]
         spec["rpc-base-uri"] = res[3]
         spec["connection-pool-min-size"] = res[4]
         spec["connection-pool-max-size"] = res[5]
         spec["connection-timeout"] = res[6]
         spec["request-timeout"] = res[7]

         errcnt += self._checkSpec(spec, specDelta, errs)

         self.proto.raiseDictArgException(errs)

         ## compute delta and SQL
         ##
         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("require-appcred-uri"):
            if appcred_id != res[0]:
               delta["require-appcred-uri"] = appcred_uri
               sql += ", require_appcred_id = ?"
               sql_vars.append(appcred_id)

         if specDelta.has_key("oraconnect-uri"):
            if connect_id != res[1]:
               delta["oraconnect-uri"] = connect_uri
               sql += ", oraconnect_id = ?"
               sql_vars.append(connect_id)

         if specDelta.has_key("schema-list"):
            newval = specDelta["schema-list"]
            if newval != "" and newval != res[2]:
               delta["schema-list"] = newval
               sql += ", schema_list = ?"
               sql_vars.append(newval)

         if specDelta.has_key("rpc-base-uri"):
            newval = rpcBaseUri
            if newval != "" and newval != res[3]:
               delta["rpc-base-uri"] = newval
               sql += ", rpc_base_uri = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-pool-min-size"):
            newval = specDelta["connection-pool-min-size"]
            if newval != res[4]:
               delta["connection-pool-min-size"] = newval
               sql += ", connection_pool_min_size = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-pool-max-size"):
            newval = specDelta["connection-pool-max-size"]
            if newval != res[5]:
               delta["connection-pool-max-size"] = newval
               sql += ", connection_pool_max_size = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-timeout"):
            newval = specDelta["connection-timeout"]
            if newval != res[6]:
               delta["connection-timeout"] = newval
               sql += ", connection_timeout = ?"
               sql_vars.append(newval)

         if specDelta.has_key("request-timeout"):
            newval = specDelta["request-timeout"]
            if newval != res[7]:
               delta["request-timeout"] = newval
               sql += ", request_timeout = ?"
               sql_vars.append(newval)

         ## proceed when there is an actual change in data
         ##
         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE oraremote SET %s WHERE id = ?" % sql, sql_vars)

            ## recache in services if necessary
            ##
            services = self.proto.factory.services
            if services.has_key("oraremoter"):
               services["oraremoter"].recache(txn)

            ## dispatch on-modified events
            ##
            self.proto.dispatch(URI_EVENT + "on-oraremote-modified", delta, [self.proto])

            ## return object delta
            ##
            delta["uri"] = self.proto.shrink(uri)

            if delta.has_key("require-appcred-uri") and delta["require-appcred-uri"] is not None:
               delta["require-appcred-uri"] = self.proto.shrink(appcred_uri)

            if delta.has_key("oraconnect-uri") and delta["oraconnect-uri"] is not None:
               delta["oraconnect-uri"] = self.proto.shrink(connect_uri)

            return delta
         else:
            ## object unchanged
            ##
            return {}
      else:
         raise Exception(URI_ERROR + "no-such-object", "No ORA remote with URI %s" % uri)


   @exportRpc("modify-oraremote")
   def modifyOraRemote(self, oraRemoteUri, specDelta):
      """
      Modify an Oracle remote.
      """
      return self.proto.dbpool.runInteraction(self._modifyOraRemote, oraRemoteUri, specDelta)


   def _deleteOraRemote(self, txn, oraRemoteUri):

      ## check arguments
      ##
      if type(oraRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument oraRemoteUri, but got %s" % str(type(oraRemoteUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(oraRemoteUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM oraremote WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         txn.execute("DELETE FROM oraremote WHERE id = ?", [id])

         ## recache in services if necessary
         ##
         services = self.proto.factory.services
         if services.has_key("oraremoter"):
            services["oraremoter"].recache(txn)

         ## dispatch on-deleted events
         ##
         self.proto.dispatch(URI_EVENT + "on-oraremote-deleted", uri, [self.proto])

         ## return deleted object URI
         ##
         return self.proto.shrink(uri)
      else:
         raise Exception(URI_ERROR + "no-such-object", "No ORA remote with URI %s" % uri)


   @exportRpc("delete-oraremote")
   def deleteOraRemote(self, oraRemoteUri):
      """
      Delete an Oracle remote.
      """
      return self.proto.dbpool.runInteraction(self._deleteOraRemote, oraRemoteUri)


   @exportRpc("get-oraremotes")
   def getOraRemotes(self):
      """
      Return Oracle remotes list.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, require_appcred_id, oraconnect_id, schema_list, rpc_base_uri, connection_pool_min_size, connection_pool_max_size, connection_timeout, request_timeout FROM oraremote ORDER BY require_appcred_id, rpc_base_uri, created")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_ORAREMOTE + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "require-appcred-uri": self.proto.shrink(URI_APPCRED + r[3]) if r[3] else None,
                                  "oraconnect-uri": self.proto.shrink(URI_APPCRED + r[4]) if r[4] else None,
                                  "schema-list": r[5],
                                  "rpc-base-uri": r[6],
                                  "connection-pool-min-size": r[7],
                                  "connection-pool-max-size": r[8],
                                  "connection-timeout": r[9],
                                  "request-timeout": r[10]} for r in res])
      return d


   @exportRpc("query-orapool")
   def queryOraPool(self, oraRemoteUri):
      """
      Query current Oracle database connection pool for remote.
      """
      if type(oraRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument oraRemoteUri, but got %s" % str(type(oraRemoteUri)))

      uri = self.proto.resolveOrPass(oraRemoteUri)
      id = self.proto.uriToId(uri)

      if self.proto.factory.services.has_key("oraremoter"):
         res = self.proto.factory.services["oraremoter"].queryPool(id)
         if res is not None:
            r = []
            for c in sorted(res):
               r.append({'audsid': c[0], 'sid': c[1], 'created': c[2]})
            return r
         else:
            raise Exception(URI_ERROR + "no-such-object", "No Oracle remote with URI %s" % uri)
      else:
         return []


   def _getOraApiSorted(self, res):
      r = []
      for k in sorted(res.keys()):
         meta = res[k]
         r.append((k, meta.procedure, meta.cargs))
      return r


   @exportRpc("query-oraapi")
   def queryOraApi(self, oraRemoteUri):
      """
      Query Oracle remoted API for Oracle remote.
      """
      if type(oraRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument oraRemoteUri, but got %s" % str(type(oraRemoteUri)))

      uri = self.proto.resolveOrPass(oraRemoteUri)
      id = self.proto.uriToId(uri)

      if self.proto.factory.services.has_key("oraremoter"):
         d = self.proto.factory.services["oraremoter"].queryApi(id)
         if d is not None:
            d.addCallback(self._getOraApiSorted)
            return d
         else:
            raise Exception(URI_ERROR + "no-such-object", "No Oracle remote with URI %s" % uri)
      else:
         return []


   @exportRpc("query-oraapi-by-appkey")
   def queryOraApiByAppKey(self, appkey):
      """
      Query Oracle remoted API for authentication key.
      """
      return self.proto.factory.services["oraremoter"].getRemotes(appkey)

########NEW FILE########
__FILENAME__ = pgconnects
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import uuid, binascii

from twisted.python import log
from twisted.internet.threads import deferToThread
from twisted.internet.defer import Deferred, returnValue, inlineCallbacks

from netaddr.ip import IPAddress

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class PgConnects:
   """
   PostgreSQL Connects model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _checkSpec(self, spec, errs):

      errcnt = 0

      if not errs["host"] and spec.has_key("host"):
         host = str(spec["host"])
         try:
            addr = IPAddress(host)
            spec["host"] = str(addr)
         except Exception, e:
            errs["host"].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"),
                                 "Illegal value '%s' for host (%s)." % (host, str(e))))
            errcnt += 1

      return errcnt


   def _createPgConnect(self, txn, spec):

      ## check arguments
      ##
      attrs = {"label": (False, [str, unicode], 3, 20),
               "host": (False, [str, unicode], 0, 20),
               "port": (False, [int], 1, 65535),
               "database": (False, [str, unicode], 0, 20),
               "user": (False, [str, unicode], 0, 20),
               "password": (False, [str, unicode], 0, 20),
               "connection-timeout": (False, [int], 2, 120)}

      errcnt, errs = self.proto.checkDictArg("pgconnect spec", spec, attrs)

      errcnt += self._checkSpec(spec, errs)

      self.proto.raiseDictArgException(errs)

      ## normalize args
      ##
      for p in ["label", "database", "user"]:
         if spec.has_key(p):
            spec[p] = spec[p].strip()

      ## insert new object into service database
      ##
      id = newid()
      uri = URI_PGCONNECT + id
      now = utcnow()

      txn.execute("INSERT INTO pgconnect (id, created, label, host, port, database, user, password, connection_timeout) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
                  [id,
                   now,
                   spec["label"],
                   spec["host"],
                   spec["port"],
                   spec["database"],
                   spec["user"],
                   spec["password"],
                   spec["connection-timeout"]])

      ## recache in services if necessary
      ##
      services = self.proto.factory.services
      if services.has_key("pgpusher"):
         services["pgpusher"].recache(txn)
      if services.has_key("pgremoter"):
         services["pgremoter"].recache(txn)

      obj = {"uri": uri,
             "created": now,
             "label": spec["label"],
             "host": spec["host"],
             "port": spec["port"],
             "database": spec["database"],
             "user": spec["user"],
             "password": spec["password"],
             "connection-timeout": spec["connection-timeout"]}

      ## dispatch on-created event
      ##
      self.proto.dispatch(URI_EVENT + "on-pgconnect-created", obj, [self.proto])

      ## return complete object
      ##
      obj["uri"] = self.proto.shrink(uri)
      return obj


   @exportRpc("create-pgconnect")
   def createPgConnect(self, spec):
      """
      Create a new PostgreSQL database connect.
      """
      return self.proto.dbpool.runInteraction(self._createPgConnect, spec)


   def _deletePgConnect(self, txn, pgConnectUri, cascade):

      ## check arguments
      ##
      if type(pgConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument pgConnectUri, but got %s" % str(type(pgConnectUri)))

      if type(cascade) not in [bool]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type bool for agument cascade, but got %s" % str(type(cascade)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(pgConnectUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM pgconnect WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check for depending pgremotes
         ##
         txn.execute("SELECT id FROM pgremote WHERE pgconnect_id = ?", [id])
         dependingRemotes = []
         for r in txn.fetchall():
            dependingRemotes.append(r[0])

         ## check for depending pgpushrules
         ##
         txn.execute("SELECT id FROM pgpushrule WHERE pgconnect_id = ?", [id])
         dependingPushRules = []
         for r in txn.fetchall():
            dependingPushRules.append(r[0])

         ## delete depending objects and object
         ##
         if len(dependingRemotes) > 0 or len(dependingPushRules) > 0:
            if not cascade:
               raise Exception(URI_ERROR + "depending-objects",
                               "Cannot delete database connect: %d depending remotes, %d depending pushrules" % (len(dependingRemotes), len(dependingPushRules)),
                               ([self.proto.shrink(URI_PGREMOTE + id) for id in dependingRemotes],
                                [self.proto.shrink(URI_PGPUSHRULE + id) for id in dependingPushRules]))
            else:
               if len(dependingRemotes) > 0:
                  txn.execute("DELETE FROM pgremote WHERE pgconnect_id = ?", [id])
               if len(dependingPushRules) > 0:
                  txn.execute("DELETE FROM pgpushrule WHERE pgconnect_id = ?", [id])

         txn.execute("DELETE FROM pgconnect WHERE id = ?", [id])

         ## recache in services if necessary
         ##
         services = self.proto.factory.services
         if len(dependingRemotes) > 0 and services.has_key("pgremoter"):
            services["pgremoter"].recache(txn)

         if len(dependingPushRules) > 0 and services.has_key("pgpusher"):
            services["pgpusher"].recache(txn)

         ## dispatch on-deleted events
         ##
         for id in dependingRemotes:
            self.proto.dispatch(URI_EVENT + "on-pgremote-deleted", URI_PGREMOTE + id, [])

         for id in dependingPushRules:
            self.proto.dispatch(URI_EVENT + "on-pgpushrule-deleted", URI_PGPUSHRULE + id, [])

         self.proto.dispatch(URI_EVENT + "on-pgconnect-deleted", uri, [self.proto])

         ## return deleted object URI
         ##
         return self.proto.shrink(uri)

      else:
         raise Exception(URI_ERROR + "no-such-object", "No PostgreSQL connect with URI %s" % uri)


   @exportRpc("delete-pgconnect")
   def deletePgConnect(self, pgConnectUri, cascade = False):
      """
      Delete a PostgreSQL database connect.
      """
      return self.proto.dbpool.runInteraction(self._deletePgConnect, pgConnectUri, cascade)


   def _modifyPgConnect(self, txn, pgConnectUri, specDelta):

      ## check arguments
      ##
      if type(pgConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument pgConnectUri, but got %s" % str(type(pgConnectUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(pgConnectUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT label, host, port, database, user, password, connection_timeout FROM pgconnect WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check arguments
         ##
         attrs = {"label": (False, [str, unicode], 3, 20),
                  "host": (False, [str, unicode], 0, 20),
                  "port": (False, [int], 1, 65535),
                  "database": (False, [str, unicode], 0, 20),
                  "user": (False, [str, unicode], 0, 20),
                  "password": (False, [str, unicode], 0, 20),
                  "connection-timeout": (False, [int], 2, 120)}

         errcnt, errs = self.proto.checkDictArg("pgconnect delta spec", specDelta, attrs)

         errcnt += self._checkSpec(specDelta, errs)

         self.proto.raiseDictArgException(errs)

         ## normalize args
         ##
         for p in ["label", "database", "user"]:
            if specDelta.has_key(p):
               specDelta[p] = specDelta[p].strip()

         ## compute delta and SQL
         ##
         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         # [(API attribute, DB column name, DB column index)]
         for p in [('label', 'label', 0),
                   ('host', 'host', 1),
                   ('port', 'port', 2),
                   ('database', 'database', 3),
                   ('user', 'user', 4),
                   ('password', 'password', 5),
                   ('connection-timeout', 'connection_timeout', 6)]:
            if specDelta.has_key(p[0]):
               newval = specDelta[p[0]]
               if newval != res[p[2]]:
                  delta[p[0]] = newval
                  sql += ", %s = ?" % p[1]
                  sql_vars.append(newval)

         ## proceed when there is an actual change in data
         ##
         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE pgconnect SET %s WHERE id = ?" % sql, sql_vars)

            ## recache in services if necessary
            ##
            services = self.proto.factory.services
            if services.has_key("pgpusher"):
               services["pgpusher"].recache(txn)
            if services.has_key("pgremoter"):
               services["pgremoter"].recache(txn)

            ## dispatch on-modified events
            ##
            self.proto.dispatch(URI_EVENT + "on-pgconnect-modified", delta, [self.proto])

            ## return object delta
            ##
            delta["uri"] = self.proto.shrink(uri)
            return delta
         else:
            ## object unchanged
            ##
            return {}

      else:
         raise Exception(URI_ERROR + "no-such-object", "No PostgreSQL connect with URI %s" % uri)


   @exportRpc("modify-pgconnect")
   def modifyPgConnect(self, pgConnectUri, specDelta):
      """
      Modify a PostgreSQL database connect.
      """
      return self.proto.dbpool.runInteraction(self._modifyPgConnect, pgConnectUri, specDelta)


   @exportRpc("get-pgconnects")
   def getPgConnects(self):
      """
      Return list of PostgreSQL database connects.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, label, host, port, database, user, password, connection_timeout FROM pgconnect ORDER BY label, user, database, id ASC")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_PGCONNECT + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "label": r[3],
                                  "host": r[4],
                                  "port": r[5],
                                  "database": r[6],
                                  "user": r[7],
                                  "password": r[8],
                                  "connection-timeout": r[9]} for r in res])
      return d


   def _getPgConnectPusherState(self, txn, pgConnectUri):

      ## check arguments
      ##
      if type(pgConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument pgConnectUri, but got %s" % str(type(pgConnectUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(pgConnectUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM pgconnect WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         if self.proto.factory.services.has_key("pgpusher"):
            return self.proto.factory.services["pgpusher"].getPusherState(id)
         else:
            raise Exception("pgpusher not running")

      else:
         raise Exception(URI_ERROR + "no-such-object", "No PostgreSQL connect with URI %s" % uri)


   @exportRpc("get-pgconnect-pusherstate")
   def getPgConnectPusherState(self, pgConnectUri):
      """
      Retrieve the current state of database pusher associated with this connect (if any).
      """
      return self.proto.dbpool.runInteraction(self._getPgConnectPusherState, pgConnectUri)


   @exportRpc("test-pgconnect")
   def testPgConnect(self, pgConnectUri):
      """
      Test a PostgreSQL database connect.

      This is done on a completely new database connection run from a new, short-lived background thread.
      """

      ## check arguments
      ##
      if type(pgConnectUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument pgConnectUri, but got %s" % str(type(pgConnectUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(pgConnectUri)
      id = self.proto.uriToId(uri)

      ## get database connection definition and test ..
      ##
      d = self.proto.dbpool.runQuery("SELECT host, port, database, user, password, connection_timeout FROM pgconnect WHERE id = ?", [id])

      def dotest(res):
         if res is not None and len(res) > 0:

            res = res[0]

            host = str(res[0])
            port = int(res[1])
            database = str(res[2])
            user = str(res[3])
            password = str(res[4])
            connection_timeout = int(res[5])

            def test():
               import psycopg2
               conn = psycopg2.connect(host = host,
                                       port = port,
                                       database = database,
                                       user = user,
                                       password = password,
                                       connect_timeout = connection_timeout)
               conn.autocommit = True
               cur = conn.cursor()
               cur.execute("SELECT now() AS now, pg_postmaster_start_time() AS start_time, version() AS version_str, (SELECT setting FROM pg_settings WHERE name = 'server_version') AS version")

               rr = cur.fetchone()
               cur.close()
               conn.close()

               current_time = str(rr[0]).strip()
               start_time = str(rr[1]).strip()
               version_str = str(rr[2]).strip()
               version = str(rr[3]).strip()
               sysuuid = None # str(uuid.UUID(binascii.b2a_hex(rr[3])))

               r = {'current-time': current_time,
                    'start-time': start_time,
                    'version': version,
                    'version-string': version_str,
                    'uuid': sysuuid}
               return r

            return deferToThread(test)

         else:
            raise Exception(URI_ERROR + "no-such-object", "No PostgreSQL connect with URI %s" % uri)

      d.addCallback(dotest)
      return d

########NEW FILE########
__FILENAME__ = pgpushrules
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class PgPushRules:
   """
   PostgreSQL Push Rules model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _checkSpec(self, spec, errs):

      errcnt = 0
      return errcnt


   def _createPgPushRule(self, txn, spec):

      ## check arguments
      ##
      attrs = {"topic-uri": (True, [str, unicode], 0, URI_MAXLEN),
               "match-by-prefix": (True, [bool]),
               "user": (False, [str, unicode, types.NoneType], 0, 30),
               "pgconnect-uri": (True, [str, unicode], 0, URI_MAXLEN)}

      errcnt, errs = self.proto.checkDictArg("PG pushrule spec", spec, attrs)

      if not errs["topic-uri"]:
         topic_uri, errs2 = self.proto.validateUri(spec["topic-uri"])
         errs["topic-uri"].extend(errs2)
         errcnt += len(errs2)

      errcnt += self._checkSpec(spec, errs)

      pgconnect_id = None
      pgconnect_uri = None
      if spec.has_key("pgconnect-uri") and spec["pgconnect-uri"] is not None and spec["pgconnect-uri"].strip() != "":
         pgconnect_uri = self.proto.resolveOrPass(spec["pgconnect-uri"].strip())
         pgconnect_id = self.proto.uriToId(pgconnect_uri)
         txn.execute("SELECT created FROM pgconnect WHERE id = ?", [pgconnect_id])
         if txn.fetchone() is None:
            errs["pgconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No PG connect with URI %s" % appcred_uri))

      self.proto.raiseDictArgException(errs)


      ## insert new object into service database
      ##
      id = newid()
      uri = URI_PGPUSHRULE + id
      now = utcnow()
      user = spec['user'].strip() if spec.has_key('user') else None

      txn.execute("INSERT INTO pgpushrule (id, created, modified, pgconnect_id, user, topic_uri, match_by_prefix) VALUES (?, ?, ?, ?, ?, ?, ?)",
                  [id,
                   now,
                   None,
                   pgconnect_id,
                   user,
                   topic_uri,
                   int(spec["match-by-prefix"])])

      ## recache in services if necessary
      ##
      services = self.proto.factory.services
      if services.has_key("pgpusher"):
         services["pgpusher"].recache(txn)

      obj = {"uri": uri,
             "created": now,
             "modified": None,
             "pgconnect-uri": pgconnect_uri,
             "user": user,
             "topic-uri": topic_uri,
             "match-by-prefix": spec["match-by-prefix"]}

      ## dispatch on-created event
      ##
      self.proto.dispatch(URI_EVENT + "on-pgpushrule-created", obj, [self.proto])

      ## return complete object
      ##
      obj["uri"] = self.proto.shrink(uri)
      if obj["pgconnect-uri"] is not None:
         obj["pgconnect-uri"] = self.proto.shrink(pgconnect_uri)
      return obj


   @exportRpc("create-pgpushrule")
   def createPgPushRule(self, spec):
      """
      Create a new PostgreSQL push rule.
      """
      return self.proto.dbpool.runInteraction(self._createPgPushRule, spec)


   def _deletePgPushRule(self, txn, pgPushRuleUri):

      ## check arguments
      ##
      if type(pgPushRuleUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument pgPushRuleUri, but got %s" % str(type(pgPushRuleUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(pgPushRuleUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM pgpushrule WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         txn.execute("DELETE FROM pgpushrule WHERE id = ?", [id])

         ## recache in services if necessary
         ##
         services = self.proto.factory.services
         if services.has_key("pgpusher"):
            services["pgpusher"].recache(txn)

         ## dispatch on-deleted events
         ##
         self.proto.dispatch(URI_EVENT + "on-pgpushrule-deleted", uri, [self.proto])

         ## return deleted object URI
         ##
         return self.proto.shrink(uri)
      else:
         raise Exception(URI_ERROR + "no-such-object", "No PG push rule with URI %s" % uri)


   @exportRpc("delete-pgpushrule")
   def deletePgPushRule(self, pgPushRuleUri):
      """
      Delete a PostgreSQL push rule.
      """
      return self.proto.dbpool.runInteraction(self._deletePgPushRule, pgPushRuleUri)


   def _modifyPgPushRule(self, txn, pgPushRuleUri, specDelta):

      ## check arguments
      ##
      if type(pgPushRuleUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument pgPushRuleUri, but got %s" % str(type(pgPushRuleUri)))

      attrs = {"topic-uri": (False, [str, unicode], 0, URI_MAXLEN),
               "match-by-prefix": (False, [bool]),
               "user": (False, [str, unicode, types.NoneType], 0, 30),
               "pgconnect-uri": (False, [str, unicode], 0, URI_MAXLEN)}

      errcnt, errs = self.proto.checkDictArg("PG pushrule delta spec", specDelta, attrs)

      if not errs["topic-uri"] and specDelta.has_key("topic-uri"):
         topic_uri, errs2 = self.proto.validateUri(specDelta["topic-uri"])
         errs["topic-uri"].extend(errs2)
         errcnt += len(errs2)

      errcnt += self._checkSpec(specDelta, errs)

      pgconnect_id = None
      pgconnect_uri = None
      if specDelta.has_key("pgconnect-uri") and specDelta["pgconnect-uri"] is not None and specDelta["pgconnect-uri"].strip() != "":
         pgconnect_uri = self.proto.resolveOrPass(specDelta["pgconnect-uri"].strip())
         pgconnect_id = self.proto.uriToId(pgconnect_uri)
         txn.execute("SELECT created FROM pgconnect WHERE id = ?", [pgconnect_id])
         if txn.fetchone() is None:
            errs["pgconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No PG connect with URI %s" % pgconnect_uri))

      self.proto.raiseDictArgException(errs)

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(pgPushRuleUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT topic_uri, match_by_prefix, user, pgconnect_id FROM pgpushrule WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## compute delta and SQL
         ##
         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("topic-uri"):
            newval = topic_uri
            if newval != "" and newval != res[0]:
               delta["topic-uri"] = newval
               sql += ", topic_uri = ?"
               sql_vars.append(newval)

         if specDelta.has_key("match-by-prefix"):
            newval = specDelta["match-by-prefix"]
            if newval != (res[1] != 0):
               delta["match-by-prefix"] = newval
               sql += ", match_by_prefix = ?"
               sql_vars.append(newval)

         if specDelta.has_key("user"):
            newval = specDelta["user"]
            if newval != res[2]:
               delta["user"] = newval
               sql += ", user = ?"
               sql_vars.append(newval)

         if specDelta.has_key("pgconnect-uri"):
            if pgconnect_id != res[3]:
               delta["pgconnect-uri"] = pgconnect_uri
               sql += ", pgconnect_id = ?"
               sql_vars.append(pgconnect_id)

         ## proceed when there is an actual change in data
         ##
         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE pgpushrule SET %s WHERE id = ?" % sql, sql_vars)

            ## recache in services if necessary
            ##
            services = self.proto.factory.services
            if services.has_key("pgpusher"):
               services["pgpusher"].recache(txn)

            ## dispatch on-modified events
            ##
            self.proto.dispatch(URI_EVENT + "on-pgpushrule-modified", delta, [self.proto])

            ## return object delta
            ##
            delta["uri"] = self.proto.shrink(uri)
            if delta.has_key("pgconnect-uri") and delta["pgconnect-uri"] is not None:
               delta["pgconnect-uri"] = self.proto.shrink(pgconnect_uri)
            return delta
         else:
            ## object unchanged
            ##
            return {}
      else:
         raise Exception(URI_ERROR + "no-such-object", "No PG push rule with URI %s" % uri)


   @exportRpc("modify-pgpushrule")
   def modifyPgPushRule(self, pgPushRuleUri, specDelta):
      """
      Modify a PostgreSQL push rule.
      """
      return self.proto.dbpool.runInteraction(self._modifyPgPushRule, pgPushRuleUri, specDelta)


   @exportRpc("get-pgpushrules")
   def getPgPushRules(self):
      """
      Return list of PostgreSQL push rules.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, pgconnect_id, user, topic_uri, match_by_prefix FROM pgpushrule ORDER BY pgconnect_id, user, topic_uri")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_PGPUSHRULE + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "pgconnect-uri": self.proto.shrink(URI_PGCONNECT + r[3]) if r[3] else None,
                                  "user": r[4],
                                  "topic-uri": r[5],
                                  "match-by-prefix": r[6] != 0} for r in res])
      return d

########NEW FILE########
__FILENAME__ = pgremotes
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class PgRemotes:
   """
   PostgreSQL Remotes model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _checkSpec(self, spec, specDelta, errs):

      errcnt = 0

      if not errs["schema-list"]:
         if specDelta.has_key('schema-list'):
            try:
               specDelta['schema-list'] = ','.join(sorted([x.strip().lower() for x in specDelta['schema-list'].split(',')]))
            except Exception, e:
               errs["schema-list"].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"), "Illegal value '%s' for schema list [%s]." % (spec["schema-list"], str(e))))
               errcnt += 1

      if not errs["connection-pool-min-size"] and not errs["connection-pool-max-size"]:
         if specDelta.has_key('connection-pool-min-size') or specDelta.has_key('connection-pool-max-size'):
            cpMinSize = specDelta.get('connection-pool-min-size', spec.get('connection-pool-min-size', None))
            cpMaxSize = specDelta.get('connection-pool-max-size', spec.get('connection-pool-max-size', None))
            if cpMinSize > cpMaxSize:
               if specDelta.has_key('connection-pool-min-size'):
                  errs["connection-pool-min-size"].append((self.proto.shrink(URI_ERROR + "invalid-range-value"),
                                                           "Illegal value '%s' for connection pool min size - must be smaller than or equal to max size." % specDelta['connection-pool-min-size']))
                  errcnt += 1
               if specDelta.has_key('connection-pool-max-size'):
                  errs["connection-pool-max-size"].append((self.proto.shrink(URI_ERROR + "invalid-range-value"),
                                                           "Illegal value '%s' for connection pool max size - must be larger than or equal to min size." % specDelta['connection-pool-max-size']))
                  errcnt += 1

      return errcnt


   def _createPgRemote(self, txn, spec):

      ## check arguments
      ##
      attrs = {"require-appcred-uri": (False, [str, unicode, types.NoneType]),
               "pgconnect-uri": (True, [str, unicode]),
               "schema-list": (True, [str, unicode], 0, 1000),
               "rpc-base-uri": (True, [str, unicode], 0, URI_MAXLEN),
               "connection-pool-min-size": (True, [int], 1, 30),
               "connection-pool-max-size": (True, [int], 1, 100),
               "connection-timeout": (True, [int], 0, 120),
               "request-timeout": (True, [int], 0, 120)}

      errcnt, errs = self.proto.checkDictArg("pgremote spec", spec, attrs)

      if not errs["rpc-base-uri"]:
         rpcBaseUri, errs2 = self.proto.validateUri(spec["rpc-base-uri"])
         errs["rpc-base-uri"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and spec.has_key("require-appcred-uri"):
         if spec["require-appcred-uri"] == "null" or spec["require-appcred-uri"] == "":
            spec["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if spec.has_key("require-appcred-uri") and spec["require-appcred-uri"] is not None and spec["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(spec["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      connect_id = None
      connect_uri = None
      if spec.has_key("pgconnect-uri") and spec["pgconnect-uri"] is not None and spec["pgconnect-uri"].strip() != "":
         connect_uri = self.proto.resolveOrPass(spec["pgconnect-uri"].strip())
         connect_id = self.proto.uriToId(connect_uri)
         txn.execute("SELECT created FROM pgconnect WHERE id = ?", [connect_id])
         if txn.fetchone() is None:
            errs["pgconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No PostgreSQL connect URI %s" % connect_uri))

      errcnt += self._checkSpec({}, spec, errs)

      self.proto.raiseDictArgException(errs)

      ## insert new object into service database
      ##
      id = newid()
      pgremote_uri = URI_PGREMOTE + id
      now = utcnow()

      txn.execute("INSERT INTO pgremote (id, created, require_appcred_id, pgconnect_id, schema_list, rpc_base_uri, connection_pool_min_size, connection_pool_max_size, connection_timeout, request_timeout) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                                       [id,
                                        now,
                                        appcred_id,
                                        connect_id,
                                        spec["schema-list"],
                                        rpcBaseUri,
                                        int(spec["connection-pool-min-size"]),
                                        int(spec["connection-pool-max-size"]),
                                        int(spec["connection-timeout"]),
                                        int(spec["request-timeout"])
                                        ])

      ## recache in services if necessary
      ##
      services = self.proto.factory.services
      if services.has_key("pgremoter"):
         services["pgremoter"].recache(txn)

      pgremote = {"uri": pgremote_uri,
                  "require-appcred-uri": appcred_uri,
                  "pgconnect-uri": connect_uri,
                  "schema-list": spec["schema-list"],
                  "rpc-base-uri": rpcBaseUri,
                  "connection-pool-min-size": int(spec["connection-pool-min-size"]),
                  "connection-pool-max-size": int(spec["connection-pool-max-size"]),
                  "connection-timeout": int(spec["connection-timeout"]),
                  "request-timeout": int(spec["request-timeout"])}

      ## dispatch on-created event
      ##
      self.proto.dispatch(URI_EVENT + "on-pgremote-created", pgremote, [self.proto])

      ## return complete object
      ##
      pgremote["uri"] = self.proto.shrink(pgremote_uri)

      if pgremote["require-appcred-uri"] is not None:
         pgremote["require-appcred-uri"] = self.proto.shrink(appcred_uri)

      if pgremote["pgconnect-uri"] is not None:
         pgremote["pgconnect-uri"] = self.proto.shrink(connect_uri)

      return pgremote


   @exportRpc("create-pgremote")
   def createPgRemote(self, spec):
      """
      Create a new PostgreSQL remote.
      """
      return self.proto.dbpool.runInteraction(self._createPgRemote, spec)


   def _modifyPgRemote(self, txn, pgRemoteUri, specDelta):

      ## check arguments
      ##
      if type(pgRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument pgRemoteUri, but got %s" % str(type(pgRemoteUri)))

      attrs = {"require-appcred-uri": (False, [str, unicode, types.NoneType]),
               "pgconnect-uri": (False, [str, unicode]),
               "schema-list": (False, [str, unicode], 0, 1000),
               "rpc-base-uri": (False, [str, unicode], 0, URI_MAXLEN),
               "connection-pool-min-size": (False, [int], 1, 30),
               "connection-pool-max-size": (False, [int], 1, 100),
               "connection-timeout": (False, [int], 0, 120),
               "request-timeout": (False, [int], 0, 120)}

      errcnt, errs = self.proto.checkDictArg("pgremote delta spec", specDelta, attrs)

      if not errs["rpc-base-uri"] and specDelta.has_key("rpc-base-uri"):
         rpcBaseUri, errs2 = self.proto.validateUri(specDelta["rpc-base-uri"])
         errs["rpc-base-uri"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and specDelta.has_key("require-appcred-uri"):
         if specDelta["require-appcred-uri"] == "null" or specDelta["require-appcred-uri"] == "":
            specDelta["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if specDelta.has_key("require-appcred-uri") and specDelta["require-appcred-uri"] is not None and specDelta["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(specDelta["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      connect_id = None
      connect_uri = None
      if specDelta.has_key("pgconnect-uri") and specDelta["pgconnect-uri"] is not None and specDelta["pgconnect-uri"].strip() != "":
         connect_uri = self.proto.resolveOrPass(specDelta["pgconnect-uri"].strip())
         connect_id = self.proto.uriToId(connect_uri)
         txn.execute("SELECT created FROM pgconnect WHERE id = ?", [connect_id])
         if txn.fetchone() is None:
            errs["pgconnect-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No PostgreSQL connect URI %s" % connect_uri))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(pgRemoteUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT require_appcred_id, pgconnect_id, schema_list, rpc_base_uri, connection_pool_min_size, connection_pool_max_size, connection_timeout, request_timeout FROM pgremote WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         ## check arguments
         ##
         spec = {}
         spec["require-appcred-uri"] = self.proto.shrink(URI_APPCRED + res[0]) if res[0] else None
         spec["pgconnect-uri"] = self.proto.shrink(URI_PGCONNECT + res[1]) if res[1] else None
         spec["schema-list"] = res[2]
         spec["rpc-base-uri"] = res[3]
         spec["connection-pool-min-size"] = res[4]
         spec["connection-pool-max-size"] = res[5]
         spec["connection-timeout"] = res[6]
         spec["request-timeout"] = res[7]

         errcnt += self._checkSpec(spec, specDelta, errs)

         self.proto.raiseDictArgException(errs)

         ## compute delta and SQL
         ##
         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("require-appcred-uri"):
            if appcred_id != res[0]:
               delta["require-appcred-uri"] = appcred_uri
               sql += ", require_appcred_id = ?"
               sql_vars.append(appcred_id)

         if specDelta.has_key("pgconnect-uri"):
            if connect_id != res[1]:
               delta["pgconnect-uri"] = connect_uri
               sql += ", pgconnect_id = ?"
               sql_vars.append(connect_id)

         if specDelta.has_key("schema-list"):
            newval = specDelta["schema-list"]
            if newval != "" and newval != res[2]:
               delta["schema-list"] = newval
               sql += ", schema_list = ?"
               sql_vars.append(newval)

         if specDelta.has_key("rpc-base-uri"):
            newval = rpcBaseUri
            if newval != "" and newval != res[3]:
               delta["rpc-base-uri"] = newval
               sql += ", rpc_base_uri = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-pool-min-size"):
            newval = specDelta["connection-pool-min-size"]
            if newval != res[4]:
               delta["connection-pool-min-size"] = newval
               sql += ", connection_pool_min_size = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-pool-max-size"):
            newval = specDelta["connection-pool-max-size"]
            if newval != res[5]:
               delta["connection-pool-max-size"] = newval
               sql += ", connection_pool_max_size = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-timeout"):
            newval = specDelta["connection-timeout"]
            if newval != res[6]:
               delta["connection-timeout"] = newval
               sql += ", connection_timeout = ?"
               sql_vars.append(newval)

         if specDelta.has_key("request-timeout"):
            newval = specDelta["request-timeout"]
            if newval != res[7]:
               delta["request-timeout"] = newval
               sql += ", request_timeout = ?"
               sql_vars.append(newval)

         ## proceed when there is an actual change in data
         ##
         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE pgremote SET %s WHERE id = ?" % sql, sql_vars)

            ## recache in services if necessary
            ##
            services = self.proto.factory.services
            if services.has_key("pgremoter"):
               services["pgremoter"].recache(txn)

            ## dispatch on-modified events
            ##
            self.proto.dispatch(URI_EVENT + "on-pgremote-modified", delta, [self.proto])

            ## return object delta
            ##
            delta["uri"] = self.proto.shrink(uri)

            if delta.has_key("require-appcred-uri") and delta["require-appcred-uri"] is not None:
               delta["require-appcred-uri"] = self.proto.shrink(appcred_uri)

            if delta.has_key("pgconnect-uri") and delta["pgconnect-uri"] is not None:
               delta["pgconnect-uri"] = self.proto.shrink(connect_uri)

            return delta
         else:
            ## object unchanged
            ##
            return {}
      else:
         raise Exception(URI_ERROR + "no-such-object", "No PostgreSQL remote with URI %s" % uri)


   @exportRpc("modify-pgremote")
   def modifyPgRemote(self, pgRemoteUri, specDelta):
      """
      Modify a PostgreSQL remote.
      """
      return self.proto.dbpool.runInteraction(self._modifyPgRemote, pgRemoteUri, specDelta)


   def _deletePgRemote(self, txn, pgRemoteUri):

      ## check arguments
      ##
      if type(pgRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument pgRemoteUri, but got %s" % str(type(pgRemoteUri)))

      ## resolve URI to database object ID
      ##
      uri = self.proto.resolveOrPass(pgRemoteUri)
      id = self.proto.uriToId(uri)

      ## only proceed when object actually exists
      ##
      txn.execute("SELECT created FROM pgremote WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         txn.execute("DELETE FROM pgremote WHERE id = ?", [id])

         ## recache in services if necessary
         ##
         services = self.proto.factory.services
         if services.has_key("pgremoter"):
            services["pgremoter"].recache(txn)

         ## dispatch on-deleted events
         ##
         self.proto.dispatch(URI_EVENT + "on-pgremote-deleted", uri, [self.proto])

         ## return deleted object URI
         ##
         return self.proto.shrink(uri)
      else:
         raise Exception(URI_ERROR + "no-such-object", "No PostgreSQL remote with URI %s" % uri)


   @exportRpc("delete-pgremote")
   def deletePgRemote(self, pgRemoteUri):
      """
      Delete a PostgreSQL remote.
      """
      return self.proto.dbpool.runInteraction(self._deletePgRemote, pgRemoteUri)


   @exportRpc("get-pgremotes")
   def getPgRemotes(self):
      """
      Return PostgreSQL remotes list.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, require_appcred_id, pgconnect_id, schema_list, rpc_base_uri, connection_pool_min_size, connection_pool_max_size, connection_timeout, request_timeout FROM pgremote ORDER BY require_appcred_id, rpc_base_uri, created")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_PGREMOTE + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "require-appcred-uri": self.proto.shrink(URI_APPCRED + r[3]) if r[3] else None,
                                  "pgconnect-uri": self.proto.shrink(URI_APPCRED + r[4]) if r[4] else None,
                                  "schema-list": r[5],
                                  "rpc-base-uri": r[6],
                                  "connection-pool-min-size": r[7],
                                  "connection-pool-max-size": r[8],
                                  "connection-timeout": r[9],
                                  "request-timeout": r[10]} for r in res])
      return d


   @exportRpc("query-pgpool")
   def queryPgPool(self, pgRemoteUri):
      """
      Query current PostgreSQL database connection pool for remote.
      """
      if type(pgRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument pgRemoteUri, but got %s" % str(type(pgRemoteUri)))

      uri = self.proto.resolveOrPass(pgRemoteUri)
      id = self.proto.uriToId(uri)

      if self.proto.factory.services.has_key("pgremoter"):
         res = self.proto.factory.services["pgremoter"].queryPool(id)
         if res is not None:
            r = []
            for c in sorted(res):
               r.append({'created': c[1], 'backend-pid': c[0]})
            return r
         else:
            raise Exception(URI_ERROR + "no-such-object", "No PostgreSQL remote with URI %s" % uri)
      else:
         return []


   def _getPgApiSorted(self, res):
      r = []
      for k in sorted(res.keys()):
         meta = res[k]
         r.append((k, meta.procedure, meta.cargs))
      return r


   @exportRpc("query-pgapi")
   def queryPgApi(self, pgRemoteUri):
      """
      Query PostgreSQL remoted API for this remote.
      """
      if type(pgRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument pgRemoteUri, but got %s" % str(type(pgRemoteUri)))

      uri = self.proto.resolveOrPass(pgRemoteUri)
      id = self.proto.uriToId(uri)

      if self.proto.factory.services.has_key("pgremoter"):
         d = self.proto.factory.services["pgremoter"].queryApi(id)
         if d is not None:
            d.addCallback(self._getPgApiSorted)
            return d
         else:
            raise Exception(URI_ERROR + "no-such-object", "No PostgreSQL remote with URI %s" % uri)
      else:
         return []


   @exportRpc("query-pgapi-by-appkey")
   def queryPgApiByAppKey(self, appkey):
      """
      Query PostgreSQL remoted API by authentication key.
      """
      return self.proto.factory.services["pgremoter"].getRemotes(appkey)

########NEW FILE########
__FILENAME__ = postrules
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types
from netaddr.ip import IPAddress, IPNetwork

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class PostRules:
   """
   Post rules model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def checkPostRuleSpec(self, spec, specDelta, errs):

      errcnt = 0

      ## check rule action
      ##
      if not errs["action"]:
         if specDelta.has_key("action"):
            valid_actions = ['ALLOW', 'DENY']
            if specDelta["action"] not in valid_actions:
               errs["action"].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"), "Illegal value '%s' for action [must be one of %s]." % (specDelta["action"], ", ".join(valid_actions))))
               errcnt += 1

      ## check IP network filter
      ##
      network = spec.get("filter-ip-network", None)
      if not errs["filter-ip-network"]:
         if specDelta.has_key("filter-ip-network"):
            if specDelta["filter-ip-network"] is not None and specDelta["filter-ip-network"].strip() != "":
               nw = specDelta["filter-ip-network"].strip()
               try:
                  network = IPNetwork(nw)
                  if network.version != 4:
                     network = None
                     errs["filter-ip-network"].append((self.proto.shrink(URI_ERROR + "non-ipv4-network"),
                                                       "Illegal value '%s' for filter IP network - only IPv4 supported." % nw))
                     errcnt += 1
                  specDelta["filter-ip-network"] = str(network)
               except Exception, e:
                  errs["filter-ip-network"].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"),
                                                    "Illegal value '%s' for filter IP network (%s)." % (nw, str(e))))
                  errcnt += 1
            else:
               specDelta["filter-ip-network"] = None

      if not errs["filter-ip"]:
         if specDelta.has_key("filter-ip") and specDelta["filter-ip"] and network is None:
            errs["filter-ip-network"].append((self.proto.shrink(URI_ERROR + "missing-attribute"), "Filter IP = true, but no IP network specified."))
            errcnt += 1

      return errcnt


   def _createPostRule(self, txn, spec, insertAtPostRuleUri, insertAfter):

      if type(insertAtPostRuleUri) not in [str, unicode, types.NoneType]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode/null for agument insertAtPostRuleUri, but got %s" % str(type(insertAtPostRuleUri)))

      if type(insertAfter) != bool:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type bool for agument insertAfter, but got %s" % str(type(insertAfter)))

      attrs = {"topic-uri": (True, [str, unicode], 0, URI_MAXLEN),
               "match-by-prefix": (True, [bool]),
               "filter-ip": (True, [bool]),
               "filter-ip-network": (False, [str, unicode, types.NoneType]),
               "require-signature": (True, [bool]),
               "require-appcred-uri": (False, [str, unicode, types.NoneType]),
               "action": (True, [str, unicode])}

      errcnt, errs = self.proto.checkDictArg("postrule spec", spec, attrs)

      if not errs["topic-uri"]:
         normalizedUri, errs2 = self.proto.validateUri(spec["topic-uri"])
         errs["topic-uri"].extend(errs2)
         errcnt += len(errs2)

      errcnt += self.checkPostRuleSpec({}, spec, errs)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and spec.has_key("require-appcred-uri"):
         if spec["require-appcred-uri"] == "null" or spec["require-appcred-uri"] == "":
            spec["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if spec.has_key("require-appcred-uri") and spec["require-appcred-uri"] is not None and spec["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(spec["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      self.proto.raiseDictArgException(errs)


      ## determine new position
      ##
      if insertAtPostRuleUri is not None and insertAtPostRuleUri.strip() != "":

         at_uri = self.proto.resolveOrPass(insertAtPostRuleUri.strip())
         at_id = self.proto.uriToId(at_uri)
         txn.execute("SELECT position FROM postrule WHERE id = ?", [at_id])
         res = txn.fetchone()
         if res is None:
            raise Exception(URI_ERROR + "no-such-object", "No post rule with URI %s" % at_uri)

         at_pos = float(res[0])
         if insertAfter:
            txn.execute("SELECT position FROM postrule WHERE position > ? ORDER BY position ASC", [at_pos])
            res = txn.fetchone()
            if res is not None:
               new_pos = at_pos + abs(float(res[0]) - at_pos) / 2.
            else:
               new_pos = at_pos + 1.
         else:
            txn.execute("SELECT position FROM postrule WHERE position < ? ORDER BY position DESC", [at_pos])
            res = txn.fetchone()
            if res is not None:
               new_pos = at_pos - abs(float(res[0]) - at_pos) / 2.
            else:
               new_pos = at_pos - 1.
      else:
         txn.execute("SELECT MAX(position) FROM postrule")
         res = txn.fetchone()
         if res is not None and res[0] is not None:
            new_pos = float(res[0]) + 1.
         else:
            new_pos = 1.


      id = newid()
      postrule_uri = URI_POSTRULE + id
      now = utcnow()
      #topic_uri = self.proto.resolveOrPass(spec["topic-uri"].strip())
      topic_uri = normalizedUri
      network = spec.get("filter-ip-network", None)

      txn.execute("INSERT INTO postrule (id, created, modified, position, topic_uri, match_by_prefix, filter_ip, filter_ip_network, require_signature, require_appcred_id, action) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                                          [id,
                                           now,
                                           None,
                                           new_pos,
                                           topic_uri,
                                           int(spec["match-by-prefix"]),
                                           int(spec["filter-ip"]),
                                           network,
                                           int(spec["require-signature"]),
                                           appcred_id,
                                           spec["action"]
                                           ])

      services = self.proto.factory.services
      if services.has_key("restpusher"):
         services["restpusher"].recache(txn)

      postrule = {"uri": postrule_uri,
                  "created": now,
                  "modified": None,
                  "position": new_pos,
                  "topic-uri": topic_uri,
                  "match-by-prefix": spec["match-by-prefix"],
                  "filter-ip": spec["filter-ip"],
                  "filter-ip-network": network,
                  "require-signature": spec["require-signature"],
                  "require-appcred-uri": appcred_uri,
                  "action": spec["action"]}

      if insertAtPostRuleUri:
         postrule["inserted-at-uri"] = self.proto.shrink(URI_POSTRULE + at_id)
         postrule["inserted-after"] = insertAfter

      self.proto.dispatch(URI_EVENT + "on-postrule-created", postrule, [self.proto])

      postrule["uri"] = self.proto.shrink(postrule_uri)
      if postrule["require-appcred-uri"] is not None:
         postrule["require-appcred-uri"] = self.proto.shrink(appcred_uri)
      return postrule


   @exportRpc("create-postrule")
   def createPostRule(self, spec, insertAtPostRuleUri = None, insertAfter = True):
      """
      Create new postrule.

      Parameters:

         spec:                         Postrule specification.
         spec[]:
            topic-uri:                 Topic URI.
            match-by-prefix:           Match topic URI by prefix?
            filter-ip:                 Match only for specific IPs?
            filter-ip-network:         Specify IPs as IP network when filtering by IP.
            require-signature:         Require signed POSTs?
            require-appcred:           Require signing with specific application credential.
            require-appcred-uri:       Require signing with this application credential.
            action:                    Action: 'ALLOW' or 'DENY'.

         insertAtPostRuleUri:          None or URI or CURIE of existing postrule the
                                       new one is to be created after/before.
         insertAfter:                  None or True/False

      Events:

         on-postrule-created

      Errors:

         spec,
         insertAtPostRuleUri,
         insertAfter:               illegal-argument-type

         insertAtPostRuleUri:       no-such-object

         spec[]:

            *:                      illegal-attribute-type,
                                    missing-attribute

            topic-uri:              attribute-value-too-long,
                                    invalid-uri,
                                    missing-uri-scheme,
                                    invalid-uri-scheme,
                                    missing-uri-network-location,
                                    uri-contains-query-component

            require-appcred-uri:    no-such-object

            action:                 invalid-attribute-value

            require-signature:      invalid-attribute-value

            filter-ip-network:      invalid-attribute-value,
                                    non-ipv4-network

            ?:                      unknown-attribute
      """
      return self.proto.dbpool.runInteraction(self._createPostRule, spec, insertAtPostRuleUri, insertAfter)


   def _deletePostRule(self, txn, postRuleUri):

      if type(postRuleUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument postRuleUri, but got %s" % str(type(postRuleUri)))

      uri = self.proto.resolveOrPass(postRuleUri)
      id = self.proto.uriToId(uri)
      txn.execute("SELECT created FROM postrule WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         txn.execute("DELETE FROM postrule WHERE id = ?", [id])

         services = self.proto.factory.services
         if services.has_key("restpusher"):
            services["restpusher"].recache(txn)

         self.proto.dispatch(URI_EVENT + "on-postrule-deleted", uri, [self.proto])

         return self.proto.shrink(uri)
      else:
         raise Exception(URI_ERROR + "no-such-object", "No post rule with URI %s" % uri)


   @exportRpc("delete-postrule")
   def deletePostRule(self, postRuleUri):
      """
      Delete existing postrule.

      Parameters:

         postRuleUri:         URI or CURIE of postrule to delete

      Result:

         <postrule URI>

      Events:

         on-postrule-deleted

      Errors:

         postRuleUri:               illegal-argument-type,
                                    no-such-object
      """
      return self.proto.dbpool.runInteraction(self._deletePostRule, postRuleUri)


   def _movePostRule(self, txn, postRuleUri, moveAtPostRuleUri, moveAfter):

      if type(postRuleUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument postRuleUri, but got %s" % str(type(postRuleUri)))

      if type(moveAtPostRuleUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument moveAtPostRuleUri, but got %s" % str(type(moveAtPostRuleUri)))

      if type(moveAfter) != bool:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type bool for agument moveAfter, but got %s" % str(type(moveAfter)))

      uri = self.proto.resolveOrPass(postRuleUri)
      id = self.proto.uriToId(uri)
      txn.execute("SELECT position FROM postrule WHERE id = ?", [id])
      res = txn.fetchone()
      if res is None:
         raise Exception(URI_ERROR + "no-such-object", "No post rule with URI %s to move." % uri)
      pos = res[0]

      to_uri = self.proto.resolveOrPass(moveAtPostRuleUri)
      to_id = self.proto.uriToId(to_uri)
      txn.execute("SELECT position FROM postrule WHERE id = ?", [to_id])
      res = txn.fetchone()
      if res is None:
         raise Exception(URI_ERROR + "no-such-object", "No post rule with URI %s to move after/before." % uri)
      to_pos = float(res[0])

      if moveAfter:
         txn.execute("SELECT position FROM postrule WHERE position > ? ORDER BY position ASC", [to_pos])
         res = txn.fetchone()
         if res is not None:
            new_pos = to_pos + abs(float(res[0]) - to_pos) / 2.
         else:
            new_pos = to_pos + 1.
      else:
         txn.execute("SELECT position FROM postrule WHERE position < ? ORDER BY position DESC", [to_pos])
         res = txn.fetchone()
         if res is not None:
            new_pos = to_pos - abs(float(res[0]) - to_pos) / 2.
         else:
            new_pos = to_pos - 1.

      now = utcnow()
      txn.execute("UPDATE postrule SET position = ?, modified = ? WHERE id = ?", [new_pos, now, id])

      services = self.proto.factory.services
      if services.has_key("restpusher"):
         services["restpusher"].recache(txn)

      moved = {"uri": uri,
               "modified": now,
               "position": new_pos,
               "moved-at-uri": URI_POSTRULE + to_id,
               "moved-after": moveAfter}

      self.proto.dispatch(URI_EVENT + "on-postrule-moved", moved, [self.proto])

      moved["uri"] = self.proto.shrink(uri)
      moved["moved-at-uri"] = self.proto.shrink(URI_POSTRULE + to_id)

      return moved


   @exportRpc("move-postrule")
   def movePostRule(self, postRuleUri, moveAtPostRuleUri, moveAfter = True):
      """
      Move existing postrule within filter list.

      Parameters:

         postRuleUri:         URI or CURIE of postrule to move
         moveAtPostRuleUri:   URI or CURIE of move anchor postrule anchor
         moveAfter:           True/False => move after/before move anchor

      Result:

         {"uri":           <URI of moved postrule>,
          "modified":      <timestamp of modification>,
          "position":      <new postrule position>,
          "moved-at-uri":  <URI of move anchor postrule>,
          "moved-after":   <true/false => moved after/before}

      Events:

         on-postrule-moved

      Errors:

         postRuleUri,
         moveAtPostRuleUri,
         moveAfter:                 illegal-argument-type

         postRuleUri,
         moveAtPostRuleUri:         no-such-object
      """
      return self.proto.dbpool.runInteraction(self._movePostRule, postRuleUri, moveAtPostRuleUri, moveAfter)


   def _modifyPostRule(self, txn, postRuleUri, specDelta):

      if type(postRuleUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument postRuleUri, but got %s" % str(type(postRuleUri)))

      attrs = {"topic-uri": (False, [str, unicode], 0, URI_MAXLEN),
               "match-by-prefix": (False, [bool]),
               "filter-ip": (False, [bool]),
               "filter-ip-network": (False, [str, unicode, types.NoneType]),
               "require-signature": (False, [bool]),
               "require-appcred-uri": (False, [str, unicode, types.NoneType]),
               "action": (False, [str, unicode])}

      errcnt, errs = self.proto.checkDictArg("postrule delta spec", specDelta, attrs)

      if not errs["topic-uri"] and specDelta.has_key("topic-uri"):
         normalizedUri, errs2 = self.proto.validateUri(specDelta["topic-uri"])
         errs["topic-uri"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and specDelta.has_key("require-appcred-uri"):
         if specDelta["require-appcred-uri"] == "null" or specDelta["require-appcred-uri"] == "":
            specDelta["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if specDelta.has_key("require-appcred-uri") and specDelta["require-appcred-uri"] is not None and specDelta["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(specDelta["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))


      uri = self.proto.resolveOrPass(postRuleUri)
      id = self.proto.uriToId(uri)
      txn.execute("SELECT topic_uri, match_by_prefix, filter_ip, filter_ip_network, require_signature, require_appcred_id, action FROM postrule WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         spec = {}
         spec["topic-uri"] = res[0]
         spec["match-by-prefix"] = res[1] != 0
         spec["filter-ip"] = res[2] != 0
         spec["filter-ip-network"] = str(res[3]) if res[3] is not None else None
         spec["require-signature"] = res[4] != 0
         spec["require-appcred-uri"] = self.proto.shrink(URI_APPCRED + res[5]) if res[5] else None
         spec["action"] = str(res[6])

         errcnt += self.checkPostRuleSpec(spec, specDelta, errs)

         self.proto.raiseDictArgException(errs)

         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("topic-uri"): # and specDelta["topic-uri"] is not None:
            #newval = self.proto.resolveOrPass(specDelta["topic-uri"].strip())
            newval = normalizedUri
            if newval != "" and newval != res[0]:
               delta["topic-uri"] = newval
               sql += ", topic_uri = ?"
               sql_vars.append(newval)

         if specDelta.has_key("match-by-prefix"): # and specDelta["match-by-prefix"] is not None:
            newval = specDelta["match-by-prefix"]
            if newval != (res[1] != 0):
               delta["match-by-prefix"] = newval
               sql += ", match_by_prefix = ?"
               sql_vars.append(newval)

         if specDelta.has_key("filter-ip"): # and specDelta["filter-ip"] is not None:
            newval = specDelta["filter-ip"]
            if newval != (res[2] != 0):
               delta["filter-ip"] = newval
               sql += ", filter_ip = ?"
               sql_vars.append(newval)

         if specDelta.has_key("filter-ip-network"): # and specDelta["filter-ip-network"] is not None:
            newval = specDelta["filter-ip-network"]
            if newval != res[3]:
               delta["filter-ip-network"] = newval
               sql += ", filter_ip_network = ?"
               sql_vars.append(newval)

         if specDelta.has_key("require-signature"): # and specDelta["require-signature"] is not None:
            newval = specDelta["require-signature"]
            if newval != (res[4] != 0):
               delta["require-signature"] = newval
               sql += ", require_signature = ?"
               sql_vars.append(newval)

#         if specDelta.has_key("require-appcred-uri") and specDelta["require-appcred-uri"] is not None and specDelta["require-appcred-uri"].strip() != "":
         if specDelta.has_key("require-appcred-uri"):
            if appcred_id != res[5]:
               delta["require-appcred-uri"] = appcred_uri
               sql += ", require_appcred_id = ?"
               sql_vars.append(appcred_id)

         if specDelta.has_key("action"): # and specDelta["action"] is not None:
            newval = specDelta["action"]
            if newval != res[6]:
               delta["action"] = newval
               sql += ", action = ?"
               sql_vars.append(newval)

         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE postrule SET %s WHERE id = ?" % sql, sql_vars)

            services = self.proto.factory.services
            if services.has_key("restpusher"):
               services["restpusher"].recache(txn)

            self.proto.dispatch(URI_EVENT + "on-postrule-modified", delta, [self.proto])

            delta["uri"] = self.proto.shrink(uri)
            if delta.has_key("require-appcred-uri") and delta["require-appcred-uri"] is not None:
               delta["require-appcred-uri"] = self.proto.shrink(appcred_uri)
            return delta
         else:
            return {}
      else:
         raise Exception(URI_ERROR + "no-such-object", "No post rule with URI %s" % uri)


   @exportRpc("modify-postrule")
   def modifyPostRule(self, postRuleUri, specDelta):
      """
      Modify existing postrule's attributes (other than position).

      Parameters:

         postRuleUri:               URI or CURIE of existing postrule.
         specDelta:                 Change spec for postrule.
         specDelta[]:
            topic-uri:                 Topic URI.
            match-by-prefix:           Match topic URI by prefix?
            filter-ip:                 Match only for specific IPs?
            filter-ip-network:         Specify IPs as IP network when filtering by IP.
            require-signature:         Require signed POSTs?
            require-appcred-uri:       Require signing with this application credential.
            action:                    Action: 'ALLOW' or 'DENY'.

      Events:

         on-postrule-modified

      Errors:

         postRuleUri,
         specDelta:                 illegal-argument-type

         postRuleUri:               no-such-object

         specDelta[]:

            *:                      illegal-attribute-type,
                                    missing-attribute

            topic-uri:              attribute-value-too-long,
                                    invalid-uri,
                                    missing-uri-scheme,
                                    invalid-uri-scheme,
                                    missing-uri-network-location,
                                    uri-contains-query-component

            require-appcred-uri:    no-such-object

            action:                 invalid-attribute-value

            require-signature:      invalid-attribute-value

            filter-ip-network:      invalid-attribute-value,
                                    non-ipv4-network

            ?:                      unknown-attribute
      """
      return self.proto.dbpool.runInteraction(self._modifyPostRule, postRuleUri, specDelta)


   @exportRpc("get-postrules")
   def getPostRules(self):
      """
      Return postrule filter list (ordered by postrule position ascending).
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, position, topic_uri, match_by_prefix, filter_ip, filter_ip_network, require_signature, require_appcred_id, action FROM postrule ORDER BY position ASC")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_POSTRULE + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "position": r[3],
                                  "topic-uri": r[4],
                                  "match-by-prefix": r[5] != 0,
                                  "filter-ip": r[6] != 0,
                                  "filter-ip-network": r[7],
                                  "require-signature": r[8] != 0,
                                  "require-appcred-uri": self.proto.shrink(URI_APPCRED + r[9]) if r[9] else None,
                                  "action": r[10]} for r in res])
      return d

########NEW FILE########
__FILENAME__ = restremotes
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *


class RestRemotes:
   """
   REST Remotes model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def checkRestRemotePermSpec(self, spec, specDelta, errs):
      ## FIXME: check "payload-format"
      return 0


   def _createRestRemote(self, txn, spec):

      attrs = {"rpc-base-uri": (True, [str, unicode], 0, URI_MAXLEN),
               "rest-base-url": (True, [str, unicode], 0, URI_MAXLEN),
               "payload-format": (True, [str, unicode], ["json"]),
               "forward-cookies": (True, [bool]),
               "redirect-limit": (True, [int], 0, 10),
               "connection-timeout": (True, [int], 0, 120),
               "request-timeout": (True, [int], 0, 120),
               "max-persistent-connections": (True, [int], 0, 1000),
               "persistent-connection-timeout": (True, [int], 0, 60 * 60),
               "require-appcred-uri": (True, [str, unicode, types.NoneType])}

      errcnt, errs = self.proto.checkDictArg("restremote spec", spec, attrs)

      if not errs["rpc-base-uri"]:
         rpcBaseUri, errs2 = self.proto.validateUri(spec["rpc-base-uri"])
         errs["rpc-base-uri"].extend(errs2)
         errcnt += len(errs2)

      if not errs["rest-base-url"]:
         restBaseUrl, errs2 = self.proto.validateUri(spec["rest-base-url"])
         errs["rest-base-url"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and spec.has_key("require-appcred-uri"):
         if spec["require-appcred-uri"] == "null" or spec["require-appcred-uri"] == "":
            spec["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if spec.has_key("require-appcred-uri") and spec["require-appcred-uri"] is not None and spec["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(spec["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      errcnt += self.checkRestRemotePermSpec({}, spec, errs)

      self.proto.raiseDictArgException(errs)

      id = newid()
      restremote_uri = URI_RESTREMOTE + id
      now = utcnow()

      txn.execute("INSERT INTO restremote (id, created, require_appcred_id, rpc_base_uri, rest_base_url, payload_format, forward_cookies, redirect_limit, connection_timeout, request_timeout, max_persistent_conns, persistent_conn_timeout) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                                       [id,
                                        now,
                                        appcred_id,
                                        rpcBaseUri,
                                        restBaseUrl,
                                        str(spec["payload-format"]),
                                        spec["forward-cookies"],
                                        int(spec["redirect-limit"]),
                                        int(spec["connection-timeout"]),
                                        int(spec["request-timeout"]),
                                        int(spec["max-persistent-connections"]),
                                        int(spec["persistent-connection-timeout"])
                                        ])

      services = self.proto.factory.services
      if services.has_key("restremoter"):
        services["restremoter"].recache(txn)

      restremote = {"uri": restremote_uri,
                    "require-appcred-uri": appcred_uri,
                    "rpc-base-uri": rpcBaseUri,
                    "rest-base-url": restBaseUrl,
                    "payload-format": spec["payload-format"],
                    "forward-cookies": spec["forward-cookies"],
                    "redirect-limit": int(spec["redirect-limit"]),
                    "connection-timeout": int(spec["connection-timeout"]),
                    "request-timeout": int(spec["request-timeout"]),
                    "max-persistent-connections": int(spec["max-persistent-connections"]),
                    "persistent-connection-timeout": int(spec["persistent-connection-timeout"])}

      self.proto.dispatch(URI_EVENT + "on-restremote-created", restremote, [self.proto])

      restremote["uri"] = self.proto.shrink(restremote_uri)
      if restremote["require-appcred-uri"] is not None:
         restremote["require-appcred-uri"] = self.proto.shrink(appcred_uri)
      return restremote


   @exportRpc("create-restremote")
   def createRestRemote(self, spec):
      return self.proto.dbpool.runInteraction(self._createRestRemote, spec)


   def _modifyRestRemote(self, txn, restRemoteUri, specDelta):

      if type(restRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument restRemoteUri, but got %s" % str(type(restRemoteUri)))

      attrs = {"rpc-base-uri": (False, [str, unicode], 0, URI_MAXLEN),
               "rest-base-url": (False, [str, unicode], 0, URI_MAXLEN),
               "payload-format": (False, [str, unicode], ["json"]),
               "forward-cookies": (False, [bool]),
               "redirect-limit": (False, [int], 0, 10),
               "connection-timeout": (False, [int], 0, 120),
               "request-timeout": (False, [int], 0, 120),
               "max-persistent-connections": (False, [int], 0, 1000),
               "persistent-connection-timeout": (False, [int], 0, 60 * 60),
               "require-appcred-uri": (False, [str, unicode, types.NoneType])}

      errcnt, errs = self.proto.checkDictArg("restremote delta spec", specDelta, attrs)

      if not errs["rpc-base-uri"] and specDelta.has_key("rpc-base-uri"):
         rpcBaseUri, errs2 = self.proto.validateUri(specDelta["rpc-base-uri"])
         errs["rpc-base-uri"].extend(errs2)
         errcnt += len(errs2)

      if not errs["rest-base-url"] and specDelta.has_key("rest-base-url"):
         restBaseUrl, errs2 = self.proto.validateUri(specDelta["rest-base-url"])
         errs["rest-base-url"].extend(errs2)
         errcnt += len(errs2)

      ## convenience handling in JS
      if not errs["require-appcred-uri"] and specDelta.has_key("require-appcred-uri"):
         if specDelta["require-appcred-uri"] == "null" or specDelta["require-appcred-uri"] == "":
            specDelta["require-appcred-uri"] = None

      appcred_id = None
      appcred_uri = None
      if specDelta.has_key("require-appcred-uri") and specDelta["require-appcred-uri"] is not None and specDelta["require-appcred-uri"].strip() != "":
         appcred_uri = self.proto.resolveOrPass(specDelta["require-appcred-uri"].strip())
         appcred_id = self.proto.uriToId(appcred_uri)
         txn.execute("SELECT created FROM appcredential WHERE id = ?", [appcred_id])
         if txn.fetchone() is None:
            errs["require-appcred-uri"].append((self.proto.shrink(URI_ERROR + "no-such-object"), "No application credentials with URI %s" % appcred_uri))

      uri = self.proto.resolveOrPass(restRemoteUri)
      id = self.proto.uriToId(uri)
      txn.execute("SELECT require_appcred_id, rpc_base_uri, rest_base_url, payload_format, forward_cookies, redirect_limit, connection_timeout, request_timeout, max_persistent_conns, persistent_conn_timeout FROM restremote WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         spec = {}
         spec["require-appcred-uri"] = self.proto.shrink(URI_APPCRED + res[0]) if res[0] else None
         spec["rpc-base-uri"] = res[1]
         spec["rest-base-url"] = res[2]
         spec["payload-format"] = res[3]
         spec["forward-cookies"] = res[4] != 0
         spec["redirect-limit"] = res[5]
         spec["connection-timeout"] = res[6]
         spec["request-timeout"] = res[7]
         spec["max-persistent-connections"] = res[8]
         spec["persistent-connection-timeout"] = res[9]

         errcnt += self.checkRestRemotePermSpec(spec, specDelta, errs)

         self.proto.raiseDictArgException(errs)

         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("require-appcred-uri"):
            if appcred_id != res[0]:
               delta["require-appcred-uri"] = appcred_uri
               sql += ", require_appcred_id = ?"
               sql_vars.append(appcred_id)

         if specDelta.has_key("rpc-base-uri"):
            newval = rpcBaseUri
            if newval != "" and newval != res[1]:
               delta["rpc-base-uri"] = newval
               sql += ", rpc_base_uri = ?"
               sql_vars.append(newval)

         if specDelta.has_key("rest-base-url"):
            newval = restBaseUrl
            if newval != "" and newval != res[2]:
               delta["rest-base-url"] = newval
               sql += ", rest_base_url = ?"
               sql_vars.append(newval)

         if specDelta.has_key("payload-format"):
            newval = specDelta["payload-format"]
            if newval != "" and newval != res[3]:
               delta["payload-format"] = newval
               sql += ", payload_format = ?"
               sql_vars.append(newval)

         if specDelta.has_key("forward-cookies"):
            newval = specDelta["forward-cookies"]
            if newval != (res[4] != 0):
               delta["forward-cookies"] = newval
               sql += ", forward_cookies = ?"
               sql_vars.append(newval)

         if specDelta.has_key("redirect-limit"):
            newval = specDelta["redirect-limit"]
            if newval != res[5]:
               delta["redirect-limit"] = newval
               sql += ", redirect_limit = ?"
               sql_vars.append(newval)

         if specDelta.has_key("connection-timeout"):
            newval = specDelta["connection-timeout"]
            if newval != res[6]:
               delta["connection-timeout"] = newval
               sql += ", connection_timeout = ?"
               sql_vars.append(newval)

         if specDelta.has_key("request-timeout"):
            newval = specDelta["request-timeout"]
            if newval != res[7]:
               delta["request-timeout"] = newval
               sql += ", request_timeout = ?"
               sql_vars.append(newval)

         if specDelta.has_key("max-persistent-connections"):
            newval = specDelta["max-persistent-connections"]
            if newval != res[8]:
               delta["max-persistent-connections"] = newval
               sql += ", max_persistent_conns = ?"
               sql_vars.append(newval)

         if specDelta.has_key("persistent-connection-timeout"):
            newval = specDelta["persistent-connection-timeout"]
            if newval != res[9]:
               delta["persistent-connection-timeout"] = newval
               sql += ", persistent_conn_timeout = ?"
               sql_vars.append(newval)

         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE restremote SET %s WHERE id = ?" % sql, sql_vars)

            services = self.proto.factory.services
            if services.has_key("restremoter"):
              services["restremoter"].recache(txn)

            self.proto.dispatch(URI_EVENT + "on-restremote-modified", delta, [self.proto])

            delta["uri"] = self.proto.shrink(uri)
            if delta.has_key("require-appcred-uri") and delta["require-appcred-uri"] is not None:
               delta["require-appcred-uri"] = self.proto.shrink(appcred_uri)
            return delta
         else:
            return {}
      else:
         raise Exception(URI_ERROR + "no-such-object", "No REST remote with URI %s" % uri)


   @exportRpc("modify-restremote")
   def modifyRestRemote(self, restRemoteUri, specDelta):
      return self.proto.dbpool.runInteraction(self._modifyRestRemote, restRemoteUri, specDelta)


   def _deleteRestRemote(self, txn, restRemoteUri):

      if type(restRemoteUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument restRemoteUri, but got %s" % str(type(restRemoteUri)))

      uri = self.proto.resolveOrPass(restRemoteUri)
      id = self.proto.uriToId(uri)
      txn.execute("SELECT created FROM restremote WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         txn.execute("DELETE FROM restremote WHERE id = ?", [id])

         services = self.proto.factory.services
         if services.has_key("restremoter"):
           services["restremoter"].recache(txn)

         self.proto.dispatch(URI_EVENT + "on-restremote-deleted", uri, [self.proto])

         return self.proto.shrink(uri)
      else:
         raise Exception(URI_ERROR + "no-such-object", "No REST remote with URI %s" % uri)


   @exportRpc("delete-restremote")
   def deleteRestRemote(self, restRemoteUri):
      """
      Delete a REST remote.
      """
      return self.proto.dbpool.runInteraction(self._deleteRestRemote, restRemoteUri)


   @exportRpc("get-restremotes")
   def getRestRemotes(self):
      """
      Return REST remotes list.
      """
      d = self.proto.dbpool.runQuery("SELECT id, created, modified, require_appcred_id, rpc_base_uri, rest_base_url, payload_format, forward_cookies, redirect_limit, connection_timeout, request_timeout, max_persistent_conns, persistent_conn_timeout FROM restremote ORDER BY require_appcred_id, rpc_base_uri, created")
      d.addCallback(lambda res: [{"uri": self.proto.shrink(URI_RESTREMOTE + r[0]),
                                  "created": r[1],
                                  "modified": r[2],
                                  "require-appcred-uri": self.proto.shrink(URI_APPCRED + r[3]) if r[3] else None,
                                  "rpc-base-uri": r[4],
                                  "rest-base-url": r[5],
                                  "payload-format": r[6],
                                  "forward-cookies": r[7] != 0,
                                  "redirect-limit": r[8],
                                  "connection-timeout": r[9],
                                  "request-timeout": r[10],
                                  "max-persistent-connections": r[11],
                                  "persistent-connection-timeout": r[12]} for r in res])
      return d


   @exportRpc("query-restapi")
   def queryRestApi(self, restRemoteUri):
      uri = self.proto.resolveOrPass(restRemoteUri)
      id = self.proto.uriToId(uri)
      res = self.proto.factory.services["restremoter"].queryApi(id)
      if res:
         r = []
         for k in sorted(res.keys()):
            r.append((k, res[k][1]))
         return r
      else:
         raise Exception(URI_ERROR + "no-such-object", "No REST remote with URI %s" % uri)


   @exportRpc("query-restapi-by-appkey")
   def queryRestApiByAppKey(self, appkey):
      return self.proto.factory.services["restremoter"].getRemotes(appkey)

########NEW FILE########
__FILENAME__ = serviceconfig
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import types

from netaddr import IPAddress

from autobahn.wamp import exportRpc, json_loads, json_dumps

from crossbar.adminwebmodule.uris import *
from crossbar.database import Database


class ServiceConfig:
   """
   Service config model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _getSingleConfig(self, txn, key):
      txn.execute("SELECT value FROM config WHERE key = ?", [key,])
      res = txn.fetchone()
      if res:
         val = json_loads(res[0])
         if key in Database.NETPORTS_TLS_KEYS and val is not None:
            val = self.proto.shrink(URI_SERVICEKEY + val)
         return val
      else:
         raise Exception(URI_ERROR + "invalid-config-parameter", "No configuration parameter '%s'" % key)


   def _getAllConfig(self, txn):
      txn.execute("SELECT key, value FROM config ORDER BY key")
      res = {}
      for r in txn.fetchall():
         key = r[0]
         val = json_loads(r[1])
         if key in Database.NETPORTS_TLS_KEYS and val is not None:
            val = self.proto.shrink(URI_SERVICEKEY + val)
         res[key] = val
      return res


   def _getMultipleConfig(self, txn, keys):
      all = self._getAllConfig(txn)
      res = {}
      for r in all:
         if r in keys:
            res[r] = all[r]
      return res


   @exportRpc("get-config")
   def getConfig(self, key = None):
      """
      Get configuration, either all or single parameter.
      """
      if type(key) == types.NoneType:
         return self.proto.dbpool.runInteraction(self._getAllConfig)
      elif type(key) in [str, unicode]:
         return self.proto.dbpool.runInteraction(self._getSingleConfig, str(key))
      elif type(key) == list:
         return self.proto.dbpool.runInteraction(self._getMultipleConfig, key)
      else:
         raise Exception(URI_ERROR + "illegal-argument-type",
                         "Expected argument of type str, unicode, None or list for %s, got %s" % (key, str(type(key))))


   def _getConfigChangeset(self, txn, attrs, delta):
      all = delta.copy()
      changed = {}
      ss = ""
      for p in attrs:
         ss += "'%s'," % p
      ss = ss[:-1]
      txn.execute("SELECT key, value FROM config WHERE key IN (" + ss + ")")
      for r in txn.fetchall():
         val = json_loads(r[1])
         if not all.has_key(r[0]):
            all[r[0]] = val
         else:
            if all[r[0]] != val:
               changed[r[0]] = all[r[0]]
      return (all, changed)


   def _setServicePorts(self, txn, ports, dryRun):

      ## check entry argument types
      ##
      if type(ports) != dict:
         raise Exception(URI_ERROR + "invalid-argument", "Invalid argument of type '%s' [expected dict]" % str(type(ports)))

      ## errors will be accumulated here (per port-key)
      ##
      errs = {}

      ## convenience handling in JS
      for u in Database.NETPORTS_TLS_PREFIXES:
         o = u + "-tlskey"
         if ports.has_key(o):
            if ports[o] == "null" or ports[o] == "":
               ports[o] = None

      ## check each port in change for itself
      ##
      uports = {}
      c_tls_flags = {}
      c_tls_keys = {}
      for k in ports.keys():
         if k in Database.NETPORTS:
            try:
               port = int(ports[k])
            except:
               errs[k] = (self.proto.shrink(URI_ERROR + "not-an-integer"), "Invalid value '%s' for port '%s' (not an integer)" % (ports[k], k))
            else:
               if port < 1 or port > 65535:
                  errs[k] = (self.proto.shrink(URI_ERROR + "out-of-range"), "Invalid value %d for port '%s' (out of valid range [1, 65535])" % (port, k))
               else:
                  if k in Database.NETPORTS_READONLY:
                     errs[k] = (self.proto.shrink(URI_ERROR + "read-only"), "Port '%s' is read-only." % k)
                  else:
                     uports[k] = port
         elif k in Database.NETPORTS_TLS_FLAGS:
            if type(ports[k]) != bool:
               errs[k] = (self.proto.shrink(URI_ERROR + "invalid-attribute-type"), "Expected bool for attribute %s, got %s" % (k, str(type(ports[k]))))
            else:
               c_tls_flags[k] = ports[k]
         elif k in Database.NETPORTS_TLS_KEYS:
            if type(ports[k]) not in [str, unicode, types.NoneType]:
               errs[k] = (self.proto.shrink(URI_ERROR + "invalid-attribute-type"), "Expected str/unicode for attribute %s, got %s" % (k, str(type(ports[k]))))
            else:
               c_tls_keys[k] = None
               if ports[k] is not None:
                  ruri = str(ports[k]).strip()
                  if ruri != "":
                     uri = self.proto.resolveOrPass(ruri)
                     id = self.proto.uriToId(uri)
                     c_tls_keys[k] = id
         else:
            errs[str(k)] = (self.proto.shrink(URI_ERROR + "unknown-attribute"), "Illegal attribute '%s'" % k)

      ## determine all TLS flags/keys (changed+existing) and change set
      (all_tls_flags, changed_tls_flags) = self._getConfigChangeset(txn, Database.NETPORTS_TLS_FLAGS, c_tls_flags)
      (all_tls_keys, changed_tls_keys) = self._getConfigChangeset(txn, Database.NETPORTS_TLS_KEYS, c_tls_keys)

      for u in Database.NETPORTS_TLS_PREFIXES:

         o = u + "-tlskey"
         if changed_tls_keys.has_key(o):
            id = changed_tls_keys[o]
            if id is not None:
               txn.execute("SELECT cert FROM servicekey WHERE ID = ?", [id])
               res = txn.fetchone()
               if res:
                  if res[0] is None:
                     errs[o] = (self.proto.shrink(URI_ERROR + "servicekey-without-certificate"), "Service key with URI %s has no certificate" % URI_SERVICEKEY + id)
               else:
                  errs[o] = (self.proto.shrink(URI_ERROR + "no-such-object"), "No service key with URI %s" % URI_SERVICEKEY + id)
            else:
               if all_tls_flags[u + "-tls"]:
                  errs[o] = (self.proto.shrink(URI_ERROR + "tls-enabled-without-servicekey"), "TLS set to enabled, but no service key given.")

         o = u + "-tls"
         if changed_tls_flags.has_key(o):
            if changed_tls_flags[o] and all_tls_keys[u + "-tlskey"] is None:
               errs[o] = (self.proto.shrink(URI_ERROR + "missing-servicekey"), "TLS enabled, but service key missing.")

      ## For Admin Web/WebSocket pair, disallow running Web via TLS, but WebSocket non-TLS
      ## i.e. Firefox throws a "security-exception" when we try that ..
      ## For Hub Web/WebSocket we allow this, since both are "independent" services (that is Hub Web
      ## does not serve the HTML/JS that connects to Hub WebSocket)
      ##
      if all_tls_flags["admin-web-tls"] and not all_tls_flags["admin-websocket-tls"]:
         errs["admin-websocket-tls"] = (self.proto.shrink(URI_ERROR + "non-tls-websocket-from-tls-web"), "TLS on WebSocket port set to enabled, but corresponding Web serving port running non-TLS.")
         errs["admin-web-tls"] = (self.proto.shrink(URI_ERROR + "non-tls-websocket-from-tls-web"), "TLS on WebSocket port set to enabled, but corresponding Web serving port running non-TLS.")

      ## determine all ports (changed+existing) and change set
      ##
      (aports, cports) = self._getConfigChangeset(txn, Database.NETPORTS, uports)

      ## duplicate check
      ##
      if len(set(aports.values())) != len(aports):
         dups = {}
         for d in aports:
            if not dups.has_key(aports[d]):
               dups[aports[d]] = []
            dups[aports[d]].append(d)
         for d in dups:
            if len(dups[d]) > 1:
               for k in dups[d]:
                  errs[k] = (self.proto.shrink(URI_ERROR + "duplicate-value"), "Duplicate port %d for %s" % (d, str(dups[d])))

      ## valid passive FTP port range
      ##
      if aports["ftp-passive-port-start"] > aports["ftp-passive-port-end"]:
         e = (self.proto.shrink(URI_ERROR + "invalid-range"), "Start port must be <= end port")
         errs["ftp-passive-port-start"] = e
         errs["ftp-passive-port-end"] = e

      ## check collisions of service ports with passive FTP port range
      ##
      passive_port_range = xrange(aports["ftp-passive-port-start"], aports["ftp-passive-port-end"] + 1)
      for p in Database.NETPORTS:
         if aports[p] in passive_port_range and p not in ["ftp-passive-port-start", "ftp-passive-port-end"]:
            e = (self.proto.shrink(URI_ERROR + "duplicate-value"),
                 "Duplicate port %d for %s collides with passive FTP port range %d-%d" % (aports[p],
                                                                                          p,
                                                                                          aports["ftp-passive-port-start"],
                                                                                          aports["ftp-passive-port-end"])
                 )
            errs[p] = e

      ## bail out on any errors accumulated
      ##
      if len(errs) > 0:
         raise Exception(URI_ERROR + "invalid-argument", "One or more invalid attributes (see errorDetails).", errs)

      ## now do the actual database update (if there is any change left)
      ##
      delta = {}
      delta.update(cports)
      delta.update(changed_tls_flags)
      delta.update(changed_tls_keys)

      if len(delta) > 0:
         if not dryRun:
            for p in delta:
               txn.execute("UPDATE config SET value = ? WHERE key = ?", [json_dumps(delta[p]), p])

            ## recache config
            services = self.proto.factory.services
            if services.has_key("config"):
              services["config"].recache(txn)

         ## automatically restart services when required
         restartRequired = len(cports) > 0 or len(changed_tls_flags) > 0
         for t in Database.NETPORTS_TLS_PREFIXES:
            if delta.has_key(t + "-tlskey") and all_tls_flags[t + "-tls"]:
               restartRequired = True
               break

         for t in Database.NETPORTS_TLS_KEYS:
            if delta.has_key(t) and delta[t]:
               delta[t] = URI_SERVICEKEY + delta[t]

         if not dryRun:
            self.proto.dispatch(URI_EVENT + "on-service-ports-set", delta, [self.proto])

         for t in Database.NETPORTS_TLS_KEYS:
            if delta.has_key(t) and delta[t]:
               delta[t] = self.proto.shrink(delta[t])

         if restartRequired and not dryRun:
            from twisted.internet import reactor
            reactor.callLater(1, self.proto.serviceControl.restartHub)

      else:
         restartRequired = False

      ## return change set
      ##
      return [delta, restartRequired]


   @exportRpc("set-service-ports")
   def setServicePorts(self, ports, dryRun = False):
      """
      Set service ports. When this leads to an actual change of at least
      one port, the application is automatically restarted!

      Errors:

         ports:         invalid-argument

         ports[]:

            ssh-port,
            hub-web-port,
            hub-websocket-port,
            admin-web-port,
            admin-websocket-port,
            echo-websocket-port,
            ftp-port,
            ftp-passive-port-start,
            ftp-passive-port-end:         not-an-integer,
                                          out-of-range,
                                          invalid-range,
                                          read-only,
                                          duplicate-value

            hub-web-tls,
            hub-websocket-tls,
            admin-web-tls,
            admin-websocket-tls,
            echo-websocket-tls:           illegal-attribute-type

            hub-web-tlskey,
            hub-websocket-tlskey,
            admin-web-tlskey,
            admin-websocket-tlskey,
            echo-websocket-tlskey:        illegal-attribute-type,
                                          no-such-object

            ?:                            unknown-attribute
      """
      return self.proto.dbpool.runInteraction(self._setServicePorts, ports, dryRun)


   def _modifyConfig(self, txn, configDelta):
      ## determine actual set of modified stuff
      ##
      modified = {}
      for c in configDelta:
         txn.execute("SELECT value FROM config WHERE key = ?", [c,])
         res = txn.fetchone()
         if res:
            cval = json_loads(res[0])
            if cval != configDelta[c]:
               modified[c] = configDelta[c]
               txn.execute("UPDATE config SET value = ? WHERE key = ?", [json_dumps(configDelta[c]), c])

      ## only something to do when there was an actual change
      ##
      if len(modified) > 0:
         ## recache config
         ##
         services = self.proto.factory.services
         if services.has_key("config"):
           services["config"].recache(txn)

         ## check if WebSocket option changed .. if so, notify WS factory
         ##
         wsOptionChanged = False
         for k in modified:
            if k[:2] == 'ws':
               wsOptionChanged = True
               break
         if wsOptionChanged:
            if self.proto.factory.services.has_key("appws"):
               self.proto.factory.services["appws"].setOptionsFromConfig()
            if self.proto.factory.services.has_key("echows"):
               self.proto.factory.services["echows"].setOptionsFromConfig()

         ## check for restart required
         ##
         for k in modified:
            if k in Database.SERVICES:
               self.proto.factory.issueRestartRequired()

         ## notify subscribers
         ##
         self.proto.dispatch(URI_EVENT + "on-config-modified", modified, [self.proto])

         ## return modified set to caller
         ##
         return modified
      else:
         ## nothing changed
         ##
         return {}


   @exportRpc("modify-config")
   def modifyConfig(self, configDelta):
      """
      Modify service configuration

      Parameters:

         configDelta:         Configuration change specification.

      Events:

         on-config-modified

      Errors:

         configDelta:                  illegal-argument

         configDelta[]:

            postrule-default-action,
            log-write-interval,
            post-body-limit,
            sig-timestamp-delta-limit,
            update-check-interval,
            auth-cookie-lifetime,
            client-auth-timeout,
            client-auth-allow-anonymous: illegal-attribute-type,
                                         out-of-range

            ?:                         unknown-attribute
      """
      attrs = {"postrule-default-action": (False, [str, unicode], ["ALLOW", "DENY"]),
               "post-body-limit": (False, [int], 0, 1000000),
               "sig-timestamp-delta-limit": (False, [int], 1, 3600),

               "client-auth-timeout": (False, [int], 0, 120),
               "client-auth-allow-anonymous": (False, [bool]),

               "log-retention-time": (False, [int], 0, 24*90),
               "log-write-interval": (False, [int], 1, 600),

               "update-url": (False, [str, unicode], 0, 1000),
               "update-check-interval": (False, [int], 0, 60 * 60 * 24),

               "auth-cookie-lifetime": (False, [int], 0, 60 * 60 * 24 * 30),
               "ftp-passive-public-ip": (False, [str, unicode, types.NoneType], 0, 20),

               "ws-allow-version-0": (False, [bool]),
               "ws-allow-version-8": (False, [bool]),
               "ws-allow-version-13": (False, [bool]),
               "ws-max-connections": (False, [int], 0, 200000),
               "ws-max-frame-size": (False, [int], 0, 16*2**20),
               "ws-max-message-size": (False, [int], 0, 16*2**20),
               "ws-auto-fragment-size": (False, [int], 0, 16*2**20),
               "ws-fail-by-drop": (False, [bool]),
               "ws-echo-close-codereason": (False, [bool]),
               "ws-open-handshake-timeout": (False, [int], 0, 120),
               "ws-close-handshake-timeout": (False, [int], 0, 120),
               "ws-tcp-nodelay": (False, [bool]),
               "ws-mask-server-frames": (False, [bool]),
               "ws-require-masked-client-frames": (False, [bool]),
               "ws-apply-mask": (False, [bool]),
               "ws-validate-utf8": (False, [bool]),
               "ws-enable-webstatus": (False, [bool]),
               "ws-accept-queue-size": (False, [int], 10, 10000),
               "ws-enable-webserver": (False, [bool]),
               "ws-websocket-path": (False, [str, unicode], 2, 100, "^[a-zA-Z0-9_-]*$"),

               "ws-enable-permessage-deflate": (False, [bool]),
               "ws-permessage-deflate-window-size": (False, [int], [0, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768]),
               "ws-permessage-deflate-require-window-size": (False, [bool]),

               "appweb-cgi-enable": (False, [bool]),
               "appweb-cgi-path": (False, [str, unicode], 3, 100, r"^[a-zA-Z0-9_\-]*$"),
               "appweb-cgi-processor": (False, [str, unicode], 3, 100, r"^[a-zA-Z0-9_/\-\.\\]*$"),
               }

      for s in Database.SERVICES:
         attrs[s] = (False, [bool])

      errcnt, errs = self.proto.checkDictArg("config modification delta", configDelta, attrs)

      attr = "ftp-passive-public-ip"
      if configDelta.has_key(attr):
         ## normalize
         if configDelta[attr].strip() == "":
            configDelta[attr] = None

         ## check
         if configDelta[attr]:
            try:
               ## normalize
               ip = IPAddress(str(configDelta[attr]))
               configDelta[attr] = str(ip)
               if ip.version != 4:
                  errcnt += 1
                  errs[attr].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"), "Not an IP version 4 address"))
            except:
               errcnt += 1
               errs[attr].append((self.proto.shrink(URI_ERROR + "invalid-attribute-value"), "Not an IP address"))

      if configDelta.has_key("update-url") and not errs["update-url"]:
         update_url, errs2 = self.proto.validateUri(configDelta["update-url"])
         errs["update-url"].extend(errs2)
         errcnt += len(errs2)
         configDelta["update-url"] = update_url

      ## bail out if any errors were accumulated
      ##
      if errcnt:
         raise Exception(URI_ERROR + "illegal-argument", "one or more illegal arguments (%d errors)" % errcnt, errs)
      else:
         return self.proto.dbpool.runInteraction(self._modifyConfig, configDelta)


   def _storeObject(self, txn, uri, obj):
      ## check arguments
      ##
      if type(uri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument uri, but got %s" % str(type(uri)))

      ## resolve URI
      ##
      uri = self.proto.resolveOrPass(uri)
      modified = True

      txn.execute("SELECT obj FROM objstore WHERE uri = ?", [uri])
      res = txn.fetchone()
      if res is not None:
         oldobj = json_loads(res[0])
         if obj is not None:
            objser = json_dumps(obj)
            if objser != res[0]:
               txn.execute("UPDATE objstore SET obj = ? WHERE uri = ?", [objser, uri])
            else:
               modified = False
         else:
            txn.execute("DELETE FROM objstore WHERE uri = ?", [uri])
      else:
         oldobj = None
         if obj is not None:
            objser = json_dumps(obj)
            txn.execute("INSERT INTO objstore (uri, obj) VALUES (?, ?)", [uri, objser])
         else:
            modified = False

      if modified:
         event = {'uri': uri, 'old': oldobj, 'new': obj}
         self.proto.dispatch(URI_EVENT + "on-store-modified", event, [self.proto])
         event["uri"] = self.proto.shrink(uri)
         return event
      else:
         return None


   @exportRpc("store-obj")
   def storeObj(self, uri, obj):
      return self.proto.dbpool.runInteraction(self._storeObject, uri, obj)


   def _loadObject(self, txn, uri):
      ## check arguments
      ##
      if type(uri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument uri, but got %s" % str(type(uri)))

      ## resolve URI
      ##
      uri = self.proto.resolveOrPass(uri)

      txn.execute("SELECT obj FROM objstore WHERE uri = ?", [uri])
      res = txn.fetchone()
      if res is not None:
         obj = json_loads(res[0])
         return obj
      else:
         return None


   @exportRpc("load-obj")
   def loadObj(self, uri):
      return self.proto.dbpool.runInteraction(self._loadObject, uri)

########NEW FILE########
__FILENAME__ = servicecontrol
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import json, re

from twisted.internet import defer
from twisted.python.failure import Failure
from twisted.python import log

import autobahn
from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

import crossbar
from crossbar.adminwebmodule.uris import *
from crossbar.dbexport import DbExportProtocol


class ServiceControl:
   """
   Service control model.
   """

   DBEXPORT_PASSWORD_PATTERN = "^[a-z0-9_\-]{3,10}$"

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   @exportRpc("scratch-webdir")
   def scratchWebDir(self, init = True):
      return self.proto.factory.services["database"].scratchWebDir(init = init)


   @exportRpc("get-log")
   def getLog(self, limit = None):
      return self.proto.factory.services["logger"].getLog(limit)


   @exportRpc("scratch-database")
   def scratchDatabase(self, restart = True):
      self.proto.factory.services["database"].scratchDatabase()
      if restart:
         self.restartHub()


   @exportRpc("check-for-updates")
   def checkForUpdates(self, forceCheckNow = False):
      """
      Online check for appliance updates. This requires an outgoing
      Internet connection from crossbar.io.

      Events:

         on-update-available
      """
      if forceCheckNow:
         ## force new check result
         return self.proto.factory.checkForUpdatesNow()
      else:
         ## return cached check result
         return self.proto.factory.updateAvailable


   @exportRpc("export-database")
   def exportDatabase(self, password = None):
      """
      Export the hub database.
      """
      if password is not None:
         if type(password) not in [str, unicode]:
            raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument password, but got %s" % str(type(password)))
         try:
            password = str(password)
         except:
            raise Exception(URI_ERROR + "illegal-argument", "Password contains non-ASCII characters (%s)" % password)
         else:
            if password.strip() == "":
               password = None
            else:
               pat = re.compile(ServiceControl.DBEXPORT_PASSWORD_PATTERN)
               if not pat.match(password):
                  raise Exception(URI_ERROR + "illegal-argument", "Password %s does not match pattern %s" % (password, AdminWebSocketProtocol.DBEXPORT_PASSWORD_PATTERN))
      d = defer.Deferred()
      cfg = self.proto.factory.services["config"]
      dbfile = self.proto.factory.services["database"].dbfile
      log.msg("Exporting service database from %s ..", dbfile)
      p = DbExportProtocol(d,
                           self.proto.factory.services,
                           str(dbfile),
                           str(cfg.get("database-version")),
                           str(cfg.get("export-dir")),
                           str(cfg.get("export-url")),
                           password = password)
      p.run()
      return d


   @exportRpc("create-diagnostics-file")
   def createDiagnosticsFiles(self):
      """
      Create a diagnostics file which contains non-sensitive database information export
      and log files as ZIP file.
      """
      d = defer.Deferred()
      cfg = self.proto.factory.services["config"]
      dbfile = self.proto.factory.services["database"].dbfile
      p = DbExportProtocol(d,
                           self.proto.factory.services,
                           str(dbfile),
                           str(cfg.get("database-version")),
                           str(cfg.get("export-dir")),
                           str(cfg.get("export-url")),
                           mode = DbExportProtocol.MODE_DIAGNOSTICS,
                           logsdir = str(cfg.get("log-dir")))
      p.run()
      return d


   @exportRpc("restart")
   def restartHub(self):
      """
      Restart all services.
      """
      log.msg("appliance service restart requested via admin console")
      return self.proto.factory.services["platform"].applianceControl("restart")


   @exportRpc("update")
   def updateAppliance(self):
      """
      Update appliance software.
      """
      log.msg("appliance software update requested via admin console")
      res = self.proto.factory.services["platform"].applianceControl("update")
      self.proto.factory.issueRestartRequired()
      return res

########NEW FILE########
__FILENAME__ = servicekeys
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import os, re, datetime

from twisted.python import log

from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

from crossbar.adminwebmodule.uris import *

from crossbar.x509util import generate_rsa_key, \
                           check_rsa_key, \
                           create_selfsigned_certificate, \
                           create_certificate_signing_request, \
                           unpack_certificate

from crossbar.database import Database


class ServiceKeys:
   """
   Service keys model.
   """

   SERVICEKEY_LABEL_MIN_LENGTH = 3
   SERVICEKEY_LABEL_MAX_LENGTH = 40

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto


   def _importServiceKeys(self, txn, removeImported):

      ## filled with imported keys
      ##
      svckeys = []

      ## look in keys/certs import directory
      ##
      import_dir = str(self.proto.factory.services["config"].get("import-dir"))
      if os.path.isdir(import_dir):
         log.msg("service key/cert import: walking import directory %s" % import_dir)

         for root, dirs, files in os.walk(import_dir):
            for f in files:

               filename = os.path.join(root, f)
               ext = os.path.splitext(filename)[1][1:]
               basename = os.path.splitext(os.path.basename(filename))[0]

               if ext == 'key':

                  keyFile = filename
                  log.msg("service key/cert import: considering key file %s" % keyFile)

                  ## verify file actually is a RSA key
                  ##
                  try:
                     key_pem = open(keyFile).read()
                     (key_pub_pem, key_length, key_fingerprint) = check_rsa_key(key_pem)
                  except Exception, e:
                     log.msg("skipping key from file %s - invalid RSA key (%s)" % (keyFile, e))
                  else:

                     ## skip keys we already have
                     ##
                     txn.execute("SELECT id FROM servicekey WHERE key_fingerprint = ?", [key_fingerprint])
                     res = txn.fetchone()
                     if res is not None:
                        log.msg("skipping key from file %s already imported (fingerprint %s)" % (keyFile, key_fingerprint))

                     else:

                        ## check if we have a corresponding cert file
                        ##
                        certFile = os.path.join(os.path.dirname(filename), basename + '.crt')

                        if not os.path.isfile(certFile):
                           log.msg("skipping key from file %s because cert file %s does not exist" % (keyFile, certFile))
                        else:
                           try:
                              certPem = open(certFile).read()
                              (cert, cert_text) = unpack_certificate(certPem)
                           except Exception, e:
                              log.msg("skipping cert from file %s - invalid RSA cert (%s)" % (certFile, e))
                           else:

                              log.msg("importing key from file %s (fingerprint %s) and cert from file %s" % (keyFile, key_fingerprint, certFile))

                              id = newid()
                              svckey_uri = URI_SERVICEKEY + id
                              now = utcnow()

                              ## Auto-generate label
                              ##
                              key_label = basename + datetime.datetime.utcnow().strftime("_%Y%m%d_%H%M%S")
                              #key_label = basename

                              txn.execute("INSERT INTO servicekey (id, created, label, key_priv, key_pub, key_length, key_fingerprint, cert, cert_fingerprint) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
                                          [id,
                                           now,
                                           key_label,
                                           key_pem,
                                           key_pub_pem,
                                           key_length,
                                           key_fingerprint,
                                           certPem,
                                           cert['fingerprint'],
                                           ])

                              svckey = {"uri": svckey_uri,
                                        "created": now,
                                        "label": key_label,
                                        "length": key_length,
                                        "fingerprint": key_fingerprint,
                                        "public": key_pub_pem,
                                        "certificate": cert,
                                        "certificate-text": cert_text}

                              self.proto.dispatch(URI_EVENT + "on-servicekey-created", svckey, [])

                              svckey["uri"] = self.proto.shrink(svckey_uri)

                              svckeys.append(svckey)

                              if removeImported:
                                 os.remove(keyFile)
                                 os.remove(certFile)
                                 log.msg("removed imported key file %s and cert file %s" % (keyFile, certFile))

               else:
                  #log.msg("skipping file %s" % filename)
                  pass
      else:
         raise Exception("keys/certs import directory does not exist")

      return svckeys


   @exportRpc("import-servicekeys")
   def importServiceKeys(self, removeImported = True):
      """
      Import pairs of service keys/certs from import directory.
      """
      return self.proto.dbpool.runInteraction(self._importServiceKeys, removeImported)


   def _getServiceKeys(self, txn):
      txn.execute("SELECT id, created, modified, label, key_pub, key_length, key_fingerprint, cert FROM servicekey ORDER BY label ASC, key_fingerprint ASC")
      sks = []
      res = txn.fetchall()
      for r in res:
         try:
            (cert, cert_text) = unpack_certificate(str(r[7]))
         except:
            (cert, cert_text) = (None, "")
         sk = {"uri": self.proto.shrink(URI_SERVICEKEY + r[0]),
               "created": r[1],
               "modified": r[2],
               "label": r[3],
               "public": r[4],
               "length": r[5],
               "fingerprint": r[6],
               "certificate": cert,
               "certificate-text": cert_text}
         sks.append(sk)
      return sks


   @exportRpc("get-servicekeys")
   def getServiceKeys(self):
      """
      Return list of service keys.

      Parameters:

         -

      Errors:

         -

      Events:

         -

      Result:

         object[]:

         created:       Creation timestamp of service key.
         modified:      Last modification timestamp for service key.
         label:         Service key label
         public:        Service key RSA public key (PEM format)
         length:        Service key length in bits (1024, 2048 or 4096)
         fingerprint:   Service key public key fingerprint.
         certificate:   Subobject containing the current x509 certificate set for the
                        service key or null when no certificate is set.
      """
      return self.proto.dbpool.runInteraction(self._getServiceKeys)


   def _createSelfSignedCertForServiceKey(self, txn, serviceKeyUri, subjectInfo, validForDays):

      try:
         validForDays = int(validForDays)
         if validForDays < 1 or validForDays > 10000:
            raise Exception(URI_ERROR + "out-of-range", "validForDays must be between 1 and 10000", 1, 10000)
      except:
         raise Exception(URI_ERROR + "illegal-argument-type", "validForDays must be integer (was '%s')" % validForDays)

      if type(serviceKeyUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument serviceKeyUri, but got %s" % str(type(serviceKeyUri)))

      uri = self.proto.resolveOrPass(serviceKeyUri)
      id = self.proto.uriToId(uri)

      txn.execute("SELECT key_priv, selfsigned_cert_serial FROM servicekey WHERE id = ?", [id])
      res = txn.fetchone()

      if res is not None:

         if res[1] is None:
            serial = 1
         else:
            serial = res[1] + 1

         try:
            (cert_pem, cert_text, cert_fingerprint) = create_selfsigned_certificate(str(res[0]),
                                                                                    subjectInfo,
                                                                                    validForDays,
                                                                                    serial)
         except:
            raise Exception(URI_ERROR + "x509-error", "Could not create Self-Signed Certificate (%s)" % str(e), str(e))

         txn.execute("UPDATE servicekey SET selfsigned_cert_serial = ? WHERE id = ?", [serial,
                                             id])

         return {"pem": cert_pem, "text": cert_text}

      else:
         raise Exception(URI_ERROR + "no-such-object", "No service key with URI %s" % uri)


   @exportRpc("create-ssc-for-servicekey")
   def createSelfSignedCertForServiceKey(self, serviceKeyUri, subjectInfo, validForDays = 360):
      """
      Create a new self-signed certificate for an existing PKI service key.

      Parameters:

         serviceKeyUri:          URI or CURIE of existing service key.
         subjectInfo:            Certificate subject detail object[]:

            common-name:         x509 CN field - Subject common name, in case of server certificates
                                 this should be the server's fully qualified hostname, i.e.
                                 "wshub.tavendo.de" - MANDATORY.

            country-name:              x509 C field - Subject ISO country code, i.e. "DE" - OPTIONAL.
            state-or-province-name:    x509 ST field - i.e. "Bayern" - OPTIONAL
            locality-name:             x509 L field - i.e. "Erlangen" - OPTIONAL
            organization-name:         x509 O field - i.e. "Tavendo GmbH" - OPTIONAL
            organization-unit-name:    x509 OU field - i.e. "Network Services" - OPTIONAL
            email-address:             x509 Email field - i.e. "x509@tavendo.de" - OPTIONAL

         validForDays:           Certificate validity in days (from now), i.e. 360.

      Events:

         -

      Errors:

         illegal-argument-type,
         out-of-range,
         no-such-object,
         x509-error

      Result:

         Self-signed x509 certificate object[]:

            pem:     Certificate PEM-encoded.
            text:    Certificate as human-readable text.
      """
      return self.proto.dbpool.runInteraction(self._createSelfSignedCertForServiceKey, serviceKeyUri, subjectInfo, validForDays)


   def _createCsrForServiceKey(self, txn, serviceKeyUri, subjectInfo):

      if type(serviceKeyUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument-type", "Expected type str/unicode for agument serviceKeyUri, but got %s" % str(type(serviceKeyUri)))

      uri = self.proto.resolveOrPass(serviceKeyUri)
      id = self.proto.uriToId(uri)

      txn.execute("SELECT key_priv, key_pub FROM servicekey WHERE id = ?", [id])
      res = txn.fetchone()

      if res is not None:

         try:
            (csr_pem, csr_text) = create_certificate_signing_request(str(res[0]), subjectInfo)
         except Exception, e:
            raise Exception(URI_ERROR + "x509-error", "Could not create CSR (%s)" % str(e), str(e))

         return {"pem": csr_pem, "text": csr_text}

      else:
         raise Exception(URI_ERROR + "no-such-object", "No service key with URI %s" % uri)


   @exportRpc("create-csr-for-servicekey")
   def createCsrForServiceKey(self, serviceKeyUri, subjectInfo):
      """
      Create a CSR for a service key.

      Parameters:

         serviceKeyUri:          URI or CURIE of existing service key.
         subjectInfo:            Certificate subject detail object[]:

            common-name:         x509 CN field - Subject common name, in case of server certificates
                                 this should be the server's fully qualified hostname, i.e.
                                 "wshub.tavendo.de" - MANDATORY.

            country-name:              x509 C field - Subject ISO country code, i.e. "DE" - OPTIONAL.
            state-or-province-name:    x509 ST field - i.e. "Bayern" - OPTIONAL
            locality-name:             x509 L field - i.e. "Erlangen" - OPTIONAL
            organization-name:         x509 O field - i.e. "Tavendo GmbH" - OPTIONAL
            organization-unit-name:    x509 OU field - i.e. "Network Services" - OPTIONAL
            email-address:             x509 Email field - i.e. "x509@tavendo.de" - OPTIONAL

      Events:

         -

      Errors:

         illegal-argument-type,
         no-such-object,
         x509-error

      Result:

         x509 certificate signing request (CSR) object[]:

            pem:     CSR PEM-encoded.
            text:    CSR as human-readable text.
      """
      return self.proto.dbpool.runInteraction(self._createCsrForServiceKey, serviceKeyUri, subjectInfo)


   def _checkCertificate(self, txn, certPem):

      if type(certPem) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument certPem, but got %s" % str(type(certPem)))

      try:
         (cert, cert_text) = unpack_certificate(str(certPem))
      except Exception, e:
         raise Exception(URI_ERROR + "invalid-certificate", "Could not analyze X509 certificate (%s)" % str(e), str(e))
      else:
         ret = {}
         ret["certificate"] = cert

         fp = cert["public-key"]["fingerprint"]
         txn.execute("SELECT id, cert_fingerprint FROM servicekey WHERE key_fingerprint = ?", [fp])

         ## we can only have 1 servicekey here, since there is a unique key on key_fingerprint
         ##
         res = txn.fetchone()
         if res is not None:
            ret["servicekey-uri"] = self.proto.shrink(URI_SERVICEKEY + res[0])
            is_changed = res[1] != cert["fingerprint"]
            ret["is-certificate-changed"] = is_changed
            if is_changed:
               (etls, ctls) = self._getAffectedServices(res[0])
               ret["changed-services"] = ctls
               ret["affected-services"] = etls
            else:
               ret["changed-services"] = []
               ret["affected-services"] = []
            ret["restart-required"] = True if len(etls) > 0 else False
         else:
            ret["servicekey-uri"] = None
            ret["is-certificate-changed"] = False
            ret["changed-services"] = []
            ret["affected-services"] = []
            ret["restart-required"] = False

         return ret


   @exportRpc("check-certificate")
   def checkCertificate(self, certPem):
      """
      Parses a x509 certificate in PEM format and returns detail information.
      This should be called before setting a certificate on a service key.

      Parameters:

         certPem:          x509 certificate in PEM format (as string).

      Events:

         -

      Errors:

         illegal-argument:       Argument was not a string.
         invalid-certificate:    Given string could not be parsed as x509 PEM-encoded certificate.

      Result:

         object[]:

         certificate:      Subobject with certificate detail information.
         servicekey-uri:   Either the URI of the servicekey the certificate matches for
                           or null. In the latter case the certificate cannot be imported.
         is-certificate-changed:    Boolean indicating whether the certificate has changed
                                    w.r.t. any certificate already set for the matching
                                    service key (if any).
         restart-required: Indicates whether a restart of services would be done when
                           the certificate would be set on the matching service key (if any).
         changed-services: List of services that would have their certificate changed, but
                           for which TLS is currently disabled.
         affected-services:   List of services that would have their certificate changed and
                              for which TLS is currently enabled (and thus triggered a restart).
      """
      return self.proto.dbpool.runInteraction(self._checkCertificate, certPem)


   def _setServiceKeyCertificate(self, txn, serviceKeyUri, certPem):

      if type(serviceKeyUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument serviceKeyUri, but got %s" % str(type(serviceKeyUri)))

      uri = self.proto.resolveOrPass(serviceKeyUri)
      id = self.proto.uriToId(uri)

      txn.execute("SELECT key_fingerprint, cert_fingerprint FROM servicekey WHERE id = ?", [id])
      res = txn.fetchone()

      if res is not None:

         try:
            (cert, cert_text) = unpack_certificate(str(certPem))
         except Exception, e:
            raise Exception(URI_ERROR + "invalid-certificate", "Could analyze X509 certificate (%s)" % str(e), str(e))
         else:
            ## check that certificate matches service key
            ##
            fp = cert["public-key"]["fingerprint"]
            if res[0] != fp:
               raise Exception(URI_ERROR + "certificate-does-not-match", "Certificate subject public key does not match service key.")

            ## certificate unchanged
            ##
            if res[1] == cert["fingerprint"]:
               return {}

            ## determine changed/effected services
            ##
            (etls, ctls) = self._getAffectedServices(id)
            restartRequired = True if len(etls) > 0 else False

            now = utcnow()
            txn.execute("UPDATE servicekey SET modified = ?, cert = ?, cert_text = ?, cert_fingerprint = ?, is_cert_selfsigned = ? WHERE id = ?",
                        [now,
                         certPem,
                         cert["text"],
                         cert["fingerprint"],
                         cert["is-selfsigned"],
                         id])

            if restartRequired:
               reactor.callLater(1, self.proto.restartHub)

            delta = {}
            delta["modified"] = now
            delta["uri"] = uri
            delta["certificate"] = cert

            self.proto.dispatch(URI_EVENT + "on-servicekey-modified", delta, [self.proto])

            delta["uri"] = self.proto.shrink(uri)
            return delta

      else:
         raise Exception(URI_ERROR + "no-such-object", "No service key with URI %s" % uri)


   @exportRpc("set-servicekey-certificate")
   def setServiceKeyCertificate(self, serviceKeyUri, certPem):
      """
      Set a X509 certificate for a service key.
      """
      return self.proto.dbpool.runInteraction(self._setServiceKeyCertificate, serviceKeyUri, certPem)


   def _createServiceKey(self, txn, label, keylength):

      attrs = {"label": (True,
                         [str, unicode],
                         ServiceKeys.SERVICEKEY_LABEL_MIN_LENGTH,
                         ServiceKeys.SERVICEKEY_LABEL_MAX_LENGTH,
                         None),
               "keylength": (True,
                             [int],
                             [1024, 2048, 4096])}

      values = {"label": label, "keylength": keylength}

      errcnt, errs = self.proto.checkDictArg("appcred spec", values, attrs)

      if errcnt:
         raise Exception(URI_ERROR + "illegal-argument", "one or more illegal arguments (%d errors)" % errcnt, errs)

      ## generate new RSA key
      ##
      log.msg("generating new service key (length %d) .." % values["keylength"])

      (key_pem, key_pub_pem, key_fingerprint) = generate_rsa_key(values["keylength"])

      log.msg("new service key generated (length %d)" % values["keylength"])

      ## store new key
      ##
      id = newid()
      svckey_uri = URI_SERVICEKEY + id
      now = utcnow()

      txn.execute("INSERT INTO servicekey (id, created, label, key_priv, key_pub, key_length, key_fingerprint) VALUES (?, ?, ?, ?, ?, ?, ?)",
                  [id,
                   now,
                   values["label"],
                   key_pem,
                   key_pub_pem,
                   values["keylength"],
                   key_fingerprint])

      svckey = {"uri": svckey_uri,
                "created": now,
                "label": values["label"],
                "length": values["keylength"],
                "fingerprint": key_fingerprint,
                "public": key_pub_pem}

      self.proto.dispatch(URI_EVENT + "on-servicekey-created", svckey, [self.proto])

      svckey["uri"] = self.proto.shrink(svckey_uri)
      return svckey


   @exportRpc("create-servicekey")
   def createServiceKey(self, label, keylength = 2048):
      """
      Create a new RSA service key.

      Parameters:

         label:      Label, a string, not necessarily unique.
         length:     Key length, one of 1024, 2048 or 4096.

      Result:

         {"uri":           <service key URI>,
          "created":       <service key creation timestamp>,
          "label":         <service key label>,
          "length":        <service key length>,
          "fingerprint":   <service key fingerprint>}

      Events:

         on-servicekey-created

      Errors:
      """
      return self.proto.dbpool.runInteraction(self._createServiceKey, label, keylength)


   def _modifyServiceKey(self, txn, serviceKeyUri, specDelta):

      if type(serviceKeyUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument serviceKeyUri, but got %s" % str(type(serviceKeyUri)))

      uri = self.proto.resolveOrPass(serviceKeyUri)
      id = self.proto.uriToId(uri)

      txn.execute("SELECT label FROM servicekey WHERE id = ?", [id])
      res = txn.fetchone()

      if res is not None:

         attrs = {"label": (False,
                            [str, unicode],
                            ServiceKeys.SERVICEKEY_LABEL_MIN_LENGTH,
                            ServiceKeys.SERVICEKEY_LABEL_MAX_LENGTH,
                            None)}

         errcnt, errs = self.proto.checkDictArg("servicekey delta spec", specDelta, attrs)

         now = utcnow()
         delta = {}
         sql = "modified = ?"
         sql_vars = [now]

         if specDelta.has_key("label"):
            newval = specDelta["label"].strip()
            if newval != res[0]:
               delta["label"] = newval
               sql += ", label = ?"
               sql_vars.append(newval)

         if errcnt:
            raise Exception(URI_ERROR + "illegal-argument", "one or more illegal arguments (%d errors)" % errcnt, errs)

         if len(delta) > 0:
            delta["modified"] = now
            delta["uri"] = uri

            sql_vars.append(id)
            txn.execute("UPDATE servicekey SET %s WHERE id = ?" % sql, sql_vars)

            self.proto.dispatch(URI_EVENT + "on-servicekey-modified", delta, [self.proto])

            delta["uri"] = self.proto.shrink(uri)
            return delta
         else:
            return {}

      else:
         raise Exception(URI_ERROR + "no-such-object", "No service key with URI %s" % uri)


   @exportRpc("modify-servicekey")
   def modifyServiceKey(self, serviceKeyUri, specDelta):
      """
      Modify service key.
      """
      return self.proto.dbpool.runInteraction(self._modifyServiceKey, serviceKeyUri, specDelta)


   def _getAffectedServices(self, serviceKeyId):
      """
      Given servicekey ID, determine which services would be
      changed and effected by a change to the RSA key and/or cert of
      the servicekey. Returns (effected, changed). If effected is a
      non-empty list, the hub will need a restart.
      """
      etls = []
      ctls = []
      for t in Database.NETPORTS_TLS_PREFIXES:
         s_tls = self.proto.factory.services["config"].get(t + "-tls")
         s_tlskey = self.proto.factory.services["config"].get(t + "-tlskey")
         if s_tlskey == serviceKeyId:
            if s_tls:
               etls.append(t)
            else:
               ctls.append(t)
      return (etls, ctls)


   def _deleteServiceKey(self, txn, serviceKeyUri):

      if type(serviceKeyUri) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument serviceKeyUri, but got %s" % str(type(serviceKeyUri)))

      uri = self.proto.resolveOrPass(serviceKeyUri)
      id = self.proto.uriToId(uri)

      txn.execute("SELECT created FROM servicekey WHERE id = ?", [id])
      res = txn.fetchone()
      if res is not None:

         (etls, ctls) = self._getAffectedServices(id)

         if len(etls) > 0:
            raise Exception(URI_ERROR + "depending-service", "One or more services have TLS activated using this service key.", etls)

         if len(ctls) > 0:
            delta = {}
            for t in ctls:
               delta[t + "-tlskey"] = None
            self.proto.serviceConfig._modifyConfig(txn, delta)

         txn.execute("DELETE FROM servicekey WHERE id = ?", [id])

         self.proto.dispatch(URI_EVENT + "on-servicekey-deleted", uri, [self.proto])

         return self.proto.shrink(uri)

      else:
         raise Exception(URI_ERROR + "no-such-object", "No service key with URI %s" % uri)


   @exportRpc("delete-servicekey")
   def deleteServiceKey(self, serviceKeyUri):
      return self.proto.dbpool.runInteraction(self._deleteServiceKey, serviceKeyUri)

########NEW FILE########
__FILENAME__ = servicestatus
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import datetime

import autobahn
from autobahn.wamp import exportRpc
from autobahn.util import utcstr, utcnow, parseutc, newid

import crossbar
from crossbar.adminwebmodule.uris import *


class ServiceStatus:
   """
   Service status model.
   """

   def __init__(self, proto):
      """
      :param proto: WAMP protocol class this model is exposed from.
      :type proto: Instance of AdminWebSocketProtocol.
      """
      self.proto = proto
      self.services = proto.factory.services
      self.publishSystemStatus()


   def publishSystemStatus(self):
      e = self.getSystemStatus()
      self.proto.dispatch(URI_EVENT + "on-system-status", e, [])
      self.proto.factory.reactor.callLater(1, self.publishSystemStatus)


   @exportRpc("get-restart-required")
   def getRestartRequired(self):
      """
      Check if a restart of the service is required to
      make changes effective.
      """
      return self.proto.factory.getRestartRequired()


   @exportRpc("get-system-info")
   def getSystemInfo(self):
      """
      Get system information.
      """
      p = self.services["platform"]
      i = {"memory": p.getMemory(),
           "model": p.getHardwareModel(),
           "cores": p.getCoreCount(),
           "clock": p.getCoreClock()}
      return i


   @exportRpc("get-system-status")
   def getSystemStatus(self):
      """
      Get system status.
      """
      now = datetime.datetime.utcnow()
      booted = self.services["platform"].getBoottime()
      started = self.services["master"].started
      r = {"booted": utcstr(booted),
           "booted-ago": int(round((now - booted).total_seconds())),
           "started": utcstr(started),
           "started-ago": int(round((now - started).total_seconds()))
           }
      return r


   @exportRpc("get-network-config")
   def getNetworkConfig(self):
      """
      Get appliance network configuration.
      """
      return self.services["platform"].getNetworkConfig()


   @exportRpc("get-software-versions")
   def getSoftwareVersions(self):
      """
      Get software versions running.
      """
      p = self.services["platform"]
      v = {"crossbar": crossbar.version,
           "autobahn": autobahn.version,
           "twisted": p.getTwistedVersion(),
           "python": p.getPythonVersion(),
           "python-versionstring": p.getPythonVersionString(),
           "os": p.getOsVersion()}

      if self.services["master"].isExe:
         v["appliance"] = "Self-contained Executable"
      else:
         v["appliance"] = p.getApplianceVersion()

      return v


   @exportRpc("get-database-info")
   def getDatabaseInfo(self):
      """
      Get database information.
      """
      return self.services["database"].getDatabaseInfo()


   @exportRpc("get-wsstats")
   def getWsStats(self):
      """
      Get WebSocket statistics.

      Events:

         on-wsstat
      """
      if self.services.has_key("appws"):
         return self.services["appws"].getStats()
      else:
         return {"ws-connections": 0,
                 "ws-dispatched-failed": 0,
                 "ws-dispatched-success": 0,
                 "ws-publications": 0}


   @exportRpc("set-wiretap-mode")
   def setWiretapMode(self, sessionid, enable):
      """
      Enable/disable wiretapping on WAMP session.
      """
      if self.services.has_key("appws"):
         return self.services["appws"].setWiretapMode(sessionid, enable)
      else:
         raise Exception("service not enabled")


   @exportRpc("get-wsechostats")
   def getWsEchoStats(self):
      """
      Get WebSocket echo endpoint statistics.

      Events:

         on-wsechostat
      """
      if self.services.has_key("echows"):
         return self.services["echows"].getStats()
      else:
         return {}



   @exportRpc("get-restremoterstats")
   def getRestRemoterStats(self):
      """
      Get REST remoter statistics.

      Events:

         on-restremoterstat
      """
      if self.services.has_key("restremoter"):
         return self.services["restremoter"].getRemoterStats()
      else:
         return [{'uri': None,
                  'call-allowed': 0,
                  'call-denied': 0,
                  'forward-success': 0,
                  'forward-failed': 0}]


   @exportRpc("get-extdirectremoterstats")
   def getExtDirectRemoterStats(self):
      """
      Get Ext.Direct remoter statistics.

      Events:

         on-extdirectremoterstat
      """
      if self.services.has_key("extdirectremoter"):
         return self.services["extdirectremoter"].getRemoterStats()
      else:
         return [{'uri': None,
                  'call-allowed': 0,
                  'call-denied': 0,
                  'forward-success': 0,
                  'forward-failed': 0}]


   @exportRpc("get-oraremoterstats")
   def getOraRemoterStats(self):
      """
      Get Oracle remoter statistics.

      Events:

         on-oraremoterstat
      """
      if self.services.has_key("oraremoter"):
         return self.services["oraremoter"].getRemoterStats()
      else:
         return [{'uri': None,
                  'call-allowed': 0,
                  'call-denied': 0,
                  'forward-success': 0,
                  'forward-failed': 0}]


   @exportRpc("get-pgremoterstats")
   def getPgRemoterStats(self):
      """
      Get PostgreSQL remoter statistics.

      Events:

         on-pgremoterstat
      """
      if self.services.has_key("pgremoter"):
         return self.services["pgremoter"].getRemoterStats()
      else:
         return [{'uri': None,
                  'call-allowed': 0,
                  'call-denied': 0,
                  'forward-success': 0,
                  'forward-failed': 0}]


   @exportRpc("get-hanaremoterstats")
   def getHanaRemoterStats(self):
      """
      Get SAP HANA remoter statistics.

      Events:

         on-hanaremoterstat
      """
      if self.services.has_key("hanaremoter"):
         return self.services["hanaremoter"].getRemoterStats()
      else:
         return [{'uri': None,
                  'call-allowed': 0,
                  'call-denied': 0,
                  'forward-success': 0,
                  'forward-failed': 0}]


   @exportRpc("get-restpusherstats")
   def getRestPusherStats(self):
      """
      Get REST pusher statistics.

      Events:

         on-restpusherstat
      """
      if self.services.has_key("hubweb"):
         return self.services["hubweb"].getStats()
      else:
         return [{'uri': None,
                  'publish-allowed': 0,
                  'publish-denied': 0,
                  'dispatch-success': 0,
                  'dispatch-failed': 0}]


   @exportRpc("get-orapusherstats")
   def getOraPusherStats(self):
      """
      Get Oracle pusher statistics.

      Events:

         on-orapusherstat
      """
      if self.services.has_key("orapusher"):
         return self.services["orapusher"].getPusherStats()
      else:
         return [{'uri': None,
                  'publish-allowed': 0,
                  'publish-denied': 0,
                  'dispatch-success': 0,
                  'dispatch-failed': 0}]


   @exportRpc("get-pgpusherstats")
   def getPgPusherStats(self):
      """
      Get PostgreSQL pusher statistics.

      Events:

         on-pgpusherstat
      """
      if self.services.has_key("pgpusher"):
         return self.services["pgpusher"].getPusherStats()
      else:
         return [{'uri': None,
                  'publish-allowed': 0,
                  'publish-denied': 0,
                  'dispatch-success': 0,
                  'dispatch-failed': 0}]


   @exportRpc("get-hanapusherstats")
   def getHanaPusherStats(self):
      """
      Get SAP HANA pusher statistics.

      Events:

         on-hanapusherstat
      """
      if self.services.has_key("hanapusher"):
         return self.services["hanapusher"].getPusherStats()
      else:
         return [{'uri': None,
                  'publish-allowed': 0,
                  'publish-denied': 0,
                  'dispatch-success': 0,
                  'dispatch-failed': 0}]


   @exportRpc("get-vmstats")
   def getVmStats(self):
      """
      Get current system load.

      Events:

         on-vmstat
      """
      return self.services["vmstat"].getCurrent()


   @exportRpc("get-netstats")
   def getNetStats(self):
      """
      Get current network load.

      Events:

         on-netstat
      """
      return self.services["netstat"].getCurrent()


   @exportRpc("get-service-status")
   def getServiceStatus(self):
      """
      """
      licenseOptions = self.services["master"].licenseOptions
      installedOptions = self.services["master"].installedOptions
      res = {}
      for s, l, i in [
                ("appws", None, None),

                ("flashpolicy", None, None),
                ("echows", None, None),
                ("ftp", None, None),

                ("netstat", None, None),
                ("vmstat", None, None),

                ("restpusher", "rest", None),
                ("restremoter", "rest", None),
                ("pgpusher", "postgresql", "postgresql"),
                ("pgremoter", "postgresql", "postgresql"),
                ("orapusher", "oracle", "oracle"),
                ("oraremoter", "oracle", "oracle"),
                ("hanapusher", "hana", "hana"),
                ("hanaremoter", "hana", "hana"),

                ("extdirectremoter", "extdirect", None),
                ]:
         if self.services.has_key(s):
            res[s] = self.services[s].isRunning
         else:
            if licenseOptions.has_key(l) and not licenseOptions[l]:
               ## service unavailable because not licensed
               res[s] = None
            elif installedOptions.has_key(i) and not installedOptions[i]:
               ## service unavailable because not installed
               res[s] = None
            else:
               ## service unavailable because disabled
               res[s] = False

      if self.services.has_key("adminweb") and self.services.has_key("adminws"):
         res["adminui"] = self.services["adminweb"].isRunning and self.services["adminws"].isRunning
      else:
         res["adminui"] = False

      if self.services.has_key("appws"):
         res["appweb"] = self.services["appws"].isRunning and self.services["appws"].enableAppWeb
      else:
         res["appweb"] = False

      if self.services["master"].isExe:
         # a self-contained EXE cannot be updated or automatically restarted
         #
         res["update"] = False
         res["autorestart"] = False
      else:
         res["update"] = True
         res["autorestart"] = True

      return res

########NEW FILE########
__FILENAME__ = uris
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


URI_BASE = "http://crossbar.io/"

URI_ERROR = URI_BASE + "error#"
URI_API = URI_BASE + "api#"
URI_EVENT = URI_BASE + "event#"
URI_WIRETAP_EVENT = URI_BASE + "event/wiretap#"

## remoting technical error
URI_ERROR_REMOTING = URI_BASE + "error#remoting"

## SQL error
URI_ERROR_SQL = URI_BASE + "error#sql"

URI_APPCRED = URI_BASE + "object/appcred/"

URI_HANACONNECT = URI_BASE + "object/hanaconnect/"
URI_HANAPUSHRULE = URI_BASE + "object/hanapushrule/"
URI_HANAREMOTE = URI_BASE + "object/hanaremote/"

URI_PGCONNECT = URI_BASE + "object/pgconnect/"
URI_PGPUSHRULE = URI_BASE + "object/pgpushrule/"
URI_PGREMOTE = URI_BASE + "object/pgremote/"

URI_ORACONNECT = URI_BASE + "object/oraconnect/"
URI_ORAPUSHRULE = URI_BASE + "object/orapushrule/"
URI_ORAREMOTE = URI_BASE + "object/oraremote/"

URI_POSTRULE = URI_BASE + "object/postrule/"
URI_SERVICEKEY = URI_BASE + "object/servicekey/"
URI_CLIENTPERM = URI_BASE + "object/clientperm/"
URI_EXTDIRECTREMOTE = URI_BASE + "object/extdirectremote/"
URI_RESTREMOTE = URI_BASE + "object/restremote/"
URI_FTPUSER = URI_BASE + "object/ftpuser/"

URI_MAXLEN = 2000

URI_WAMP_BASE = "http://api.wamp.ws/"
URI_WAMP_ERROR = URI_WAMP_BASE + "error#"
URI_WAMP_RPC = URI_WAMP_BASE + "procedure#"
URI_WAMP_EVENT = URI_WAMP_BASE + "event#"

########NEW FILE########
__FILENAME__ = dbpusher
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log
from twisted.application import service

from twisted.python import log
from twisted.internet import threads
from twisted.application import service
from twisted.enterprise import adbapi
from twisted.internet.defer import Deferred, \
                                   returnValue, \
                                   inlineCallbacks, \
                                   CancelledError

from pusher import Pusher


class PushStats:

   def __init__(self, id):
      self.stats = {'uri': id,
                    'publish-allowed': 0,
                    'publish-denied': 0,
                    'dispatch-success': 0,
                    'dispatch-failed': 0}
      self.statsChanged = False

   def updateDispatches(self, receiver_count, requested_count):
      if receiver_count > 0:
         self.stats['dispatch-success'] += receiver_count

      error_count = requested_count - receiver_count
      if error_count > 0:
         self.stats['dispatch-failed'] += error_count

      if receiver_count > 0 or error_count > 0:
         self.statsChanged = True

   def updatePublications(self, allowed_count, denied_count):
      if allowed_count > 0:
         self.stats['publish-allowed'] += 1

      if denied_count > 0:
         self.stats['publish-denied'] += 1

      if allowed_count > 0 or denied_count > 0:
         self.statsChanged = True

   def get(self, changedonly = True, reset = True):
      if not changedonly or self.statsChanged:
         if reset:
            self.statsChanged = False
         return self.stats
      else:
         return None


from collections import deque


class DbPushClient:
   """
   Database Push Client. Base class for specific pushers.
   """

   def __init__(self, pusher, connect, purge = True, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.pusher = pusher
      self.connect = connect
      self.stopped = False
      self.isRunning = False
      self.isConnected = False
      self.autoReconnect = True
      self.conn = None
      self.failure = None

      ## purge processed events by DELETE, instead of marking with UPDATE
      self.purge = purge

      ## process events that have accumulated since we were offline
      self.processOldEvents = False

      ## when running in poll-mode, seconds to sleep for throttling the poll loop
      self.pollThrottle = float(0.2)

      ## track dispatched
      self._trackDispatched = True

      if self._trackDispatched:
         self.dispatched = deque()
      else:
         self.dispatched = None


   def trackDispatched(self, eventId, dispatchStatus, dispatchSuccess, dispatchFailed):
      """
      Track dispatched events.
      """
      if self._trackDispatched:
         self.dispatched.append((eventId, dispatchStatus, dispatchSuccess, dispatchFailed))


   def stop(self):
      """
      Stop the background pusher. This is safe to call directly from the
      reactor thread.
      """
      log.msg("%s stopping .." % self.LOGID)

      self.stopped = True
      self.failure = CancelledError()

      ## try cancel any query running ..
      if self.conn:
         try:
            self.conn.cancel()
         except:
            pass


   def run(self):

      if self.isRunning:
         raise Exception("%s already running" % self.LOGID)

      log.msg("%s starting .." % self.LOGID)

      self.stopped = False
      self.failure = None

      self.isRunning = True
      self.retries = 0

      try:
         self.loop()

         if self.failure:
            raise self.failure

         if self.conn:
            try:
               self.conn.close()
            except:
               pass
         self.conn = None
         self.isConnected = False
         self.isRunning = False

         if self._trackDispatched:
            self.dispatched = deque()
         else:
            self.dispatched = None

         log.msg("%s stopped" % self.LOGID)

      except Exception, e:

         if self.conn:
            try:
               self.conn.close()
            except:
               pass

         self.conn = None
         self.isConnected = False
         self.isRunning = False

         self.pusher.publishPusherStateChange(self.connect.id, False, True, str(e))

         if self._trackDispatched:
            self.dispatched = deque()
         else:
            self.dispatched = None

         log.msg("%s failed [%s]" % (self.LOGID, e))

         raise e



class DbPusher(Pusher):
   """
   Database pusher service. Base class for specific pusher services.
   """

   def __init__(self, dbpool, services, reactor = None):
      Pusher.__init__(self, dbpool, services, reactor)


   def publishPusherStateChange(self, connectId, isConnected, shouldBeConnected, lastErrMessage = None):
      evt = {"uri": self.CONNECT_ID_BASEURI + connectId,
             "is-connected": isConnected,
             "should-be-connected": shouldBeConnected,
             "last-error": lastErrMessage}
      if self.connects.has_key(connectId):
         self.connects[connectId].pushclientLastStateEvent = evt
      self.services["adminws"].dispatchAdminEvent(self.PUSHER_STATE_CHANGE_EVENT_URI, evt)


   def getPusherState(self, connectId):
      state = {'is-connected': False, 'should-be-connected': False, 'last-error': None}
      try:
         e = self.connects[connectId].pushclientLastStateEvent
         state['is-connected'] = e['is-connected']
         state['should-be-connected'] = e['should-be-connected']
         state['last-error'] = e['last-error']
      except:
         pass
      return state


   def _createPushStat(self, id):
      return PushStats(self.CONNECT_ID_BASEURI + id if id is not None else None)


   def getPusherStats(self):
      res = []
      for s in self.stats.values():
         res.append(s.get(changedonly = False, reset = False))
      return res


   def publishPusherStats(self):
      if not self.stopped:
         res = []
         for s in self.stats.values():
            v = s.get()
            if v:
               res.append(v)
         if len(res) > 0:
            self.services["adminws"].dispatchAdminEvent(self.STATS_EVENT_URI, res)
         self.reactor.callLater(0.2, self.publishPusherStats)


   def push(self, eventId, connectId, pushedBy, topicUri, payload, exclude = [], eligible = None):
      ## Called from background database pusher thread
      #print "OraPusher", connectId, allowed, pushedBy, topic, payload, type(payload), exclude, eligible
      allowed = False
      dbc = self.connects.get(connectId, None)
      if dbc:
         for pushrule in dbc.pushrules:
            if pushrule.user is None or pushedBy in pushrule.user:
               if pushrule.topicUri == topicUri or (pushrule.matchByPrefix and pushrule.topicUri == topicUri[:len(pushrule.topicUri)]):
                  allowed = True
                  break
      if allowed:
         d = self.services["appws"].dispatchHubEvent(topicUri, payload, exclude, eligible)

         if not self.stats.has_key(connectId):
            self.stats[connectId] = self._createPushStat(connectId)

         def onpushed(res):
            (receiver_count, requested_count) = res
            self.stats[None].updateDispatches(receiver_count, requested_count)
            self.stats[connectId].updateDispatches(receiver_count, requested_count)

            ## track event dispatch stats in database
            ##
            if dbc.pushclient:
               dbc.pushclient.trackDispatched(eventId, 0, receiver_count, requested_count - receiver_count)

         d.addCallback(onpushed)

         self.stats[None].updatePublications(1, 0)
         self.stats[connectId].updatePublications(1, 0)
      else:
         self.stats[None].updatePublications(0, 1)
         self.stats[connectId].updatePublications(0, 1)

         ## track event dispatch stats in database
         ##
         if dbc.pushclient:
            dbc.pushclient.trackDispatched(eventId, 1, 0, 0)


   def startService(self):
      Pusher.startService(self)

      self.stopped = False
      self.connects = {}
      self.dbpool.runInteraction(self.recache)

      ## current statistics
      self.stats = {}
      self.stats[None] = self._createPushStat(None)
      self.publishPusherStats()


   def stopService(self):
      self.stopped = True
      for k in self.connects:
         c = self.connects[k]
         if c.pushclient is not None:
            c.pushclient.stop()
            c.pushclient = None

      Pusher.stopService(self)


   def _cache(self, connectRows, ruleRows):

      ## map of rules by connect ID
      ##
      rules = {}
      for ruleRow in ruleRows:
         rule = self.makeRule(ruleRow)
         if not rules.has_key(rule.connectId):
            rules[rule.connectId] = []
         rules[rule.connectId].append(rule)

      ## map of connects by connect ID
      ##
      connects = {}
      for connectRow in connectRows:
         connect = self.makeConnect(connectRow)
         if rules.has_key(connect.id):
            connect.pushrules = rules[connect.id]
         else:
            connect.pushrules = []
         connect.pushruleCount = len(connect.pushrules)
         connect.pushclient = None
         connect.pushclientIsConnected = False
         connects[connect.id] = connect

      ## check for dropped connects
      ##
      for id in self.connects.keys():
         if not connects.has_key(id):
            ## stop push client
            if self.connects[id].pushclient is not None:
               log.msg("%s pushclient : stopping - connect dropped .. [connect ID %s]" % (self.LOGID, id))
               self.publishPusherStateChange(id, self.connects[id].pushclientIsConnected, False)
               self.connects[id].pushclient.autoReconnect = False
               self.connects[id].pushclient.stop()
               self.connects[id].pushclient = None

            ## remove dropped connect
            del self.connects[id]

      ## check for new/changed connects
      ##
      nConnects = 0
      nRules = 0
      for id in connects:

         dbc = connects[id]

         nConnects += 1
         nRules += len(dbc.pushrules)

         ## reuse existing pushclient (if any) by copying the reference
         ##
         if self.connects.has_key(id):
            dbc.pushclient = self.connects[id].pushclient

         ## start/stop pushclient as needed
         ##
         if len(dbc.pushrules) == 0:

            ## no pushrules, so no pushclient needed ..
            ##
            if dbc.pushclient is not None:
               log.msg("%s pushclient : stopping - pushrule count dropped to zero .. [connect ID %s]" % (self.LOGID, id))

               self.publishPusherStateChange(id, dbc.pushclient.isConnected, False)

               ## we need to prohibit a pushclient that has not yet connected from
               ## trying to reconnect when it again fails to connect
               dbc.pushclient.autoReconnect = False

               ## we try to immediately stop a connected pushclient. we also provide
               ## a CancelledError() that the pushclient will raise when exiting
               dbc.pushclient.stop()

               ## we immediately delete our reference so that it gets GCed soon
               dbc.pushclient = None
            else:
               log.msg("%s pushclient : skipped, since no push rules configured [connect ID %s]" % (self.LOGID, id))
         else:

            ## at least 1 pushrules, hence we need a pushclient ..
            ##
            if dbc.pushclient is None:

               ## create new push client
               ##
               dbc.pushclient = self.makeClient(dbc)
               dbc.cancelCall = None
               dbc.retries = 0
               self.publishPusherStateChange(id, dbc.pushclient.isConnected, True)

               ## create a startup function to start/retrystart the pushclient ..
               ##
               def connectPushClient():

                  log.msg("%s pushclient : starting .. [connect ID %s]" % (self.LOGID, id))
                  d = threads.deferToThread(dbc.pushclient.run)

                  ## not all DBI implementations allow to specify a connect timeout, so
                  ## we try the best we can do by manually setting up a timeout which will
                  ## stop-cancel ..
                  if dbc.connectionTimeout > 0 and dbc.cancelCall is None:
                     def cancelIfNotConnected():
                        if dbc and dbc.pushclient and not dbc.pushclient.isConnected:
                           log.msg("%s pushclient : database connection timeout fired [connect ID %s]" % (self.LOGID, id))
                           ## stop-cancel the pushclient. note that we can't just d.cancel(),
                           ## since when the pushclient later actually exits, the deferred
                           ## was already consumed
                           dbc.pushclient.stop()
                        else:
                           log.msg("%s pushclient : database connection timeout skipped, since already connected [connect ID %s]" % (self.LOGID, id))

                     dbc.cancelCall = self.reactor.callLater(dbc.connectionTimeout, cancelIfNotConnected)

                  def onstop(_):
                     if dbc and dbc.cancelCall:
                        dbc.cancelCall.cancel()
                        dbc.cancelCall = None
                     ## pushclient has exited cleanly
                     log.msg("%s pushclient : stopped [connect ID %s]" % (self.LOGID, id))
                     self.publishPusherStateChange(id, dbc.pushclient.isConnected, False)

                  def onerror(failure):
                     try:
                        if dbc and dbc.cancelCall:
                           dbc.cancelCall.cancel()
                           dbc.cancelCall = None
                     except Exception, e:
                        log.msg("Could not cancel Oracle connection - %s" % e)

                     if failure.check(CancelledError):
                        m = "connection timeout - retries %d" % dbc.retries
                        log.msg("%s pushclient : database connection timeout [connect ID %s]" % (self.LOGID, id))
                     else:
                        m = "%s - retries %d" % (failure.getErrorMessage(), dbc.retries)
                        log.msg("%s pushclient : database error %s [connect ID %s]" % (self.LOGID, m, id))

                     ## only try to restart if not yet running and set to autoconnect ..
                     if dbc.pushclient and not dbc.pushclient.isRunning and dbc.pushclient.autoReconnect:
                        dbc.retries += 1
                        self.publishPusherStateChange(id, dbc.pushclient.isConnected, True, m)
                        self.reactor.callLater(2, connectPushClient)

                  d.addCallbacks(onstop, onerror)

               ## start/retrystart the pushclient. this will
               connectPushClient()
            else:
               ## reuse existing pushclient
               ##
               log.msg("%s pushclient : reusing already running [connect ID %s]" % (self.LOGID, id))

         ## store
         ##
         self.connects[id] = dbc

      log.msg("%s._cacheConnects (%d, %d)" % (self.LOGID, nConnects, nRules))

########NEW FILE########
__FILENAME__ = dbremoter
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log
from twisted.internet import defer
from twisted.internet.defer import succeed
from twisted.internet.defer import Deferred, DeferredList

from remoter import Remoter


class DbRemote:

   # http://jcalderone.livejournal.com/32837.html !!
   def __ne__(self, other):
      result = self.__eq__(other)
      if result is NotImplemented:
         return result
      return not result


   def getPool(self):
      """
      Get the database connection pool associated with this remote. This
      will create a pool if there isn't one, and merely return the
      created one when one already exists.
      """
      if self.pool is None:
         self.pool = self.makePool()
      return self.pool


   def destroyPool(self):
      """
      Destroy the database connection pool associated with this remote - if any.
      This will release all database connections.
      """
      if self.pool is not None:
         self.pool.close()
         self.pool = None
         self.poolConnections = []


class DbProcedureMeta:
   def __init__(self,
                remoteId,
                procedure,
                cargs):
      self.remoteId = remoteId
      self.procedure = procedure
      self.cargs = cargs



class DbRemoter(Remoter):

   def __init__(self, dbpool, services):
      Remoter.__init__(self, dbpool, services)


   def startService(self):
      Remoter.startService(self)

      self.connects = {}
      self.remotesByAuthKey = {}
      self.remotesById = {}

      self.dbpool.runInteraction(self.recache)


   def stopService(self):
      Remoter.stopService(self)


   def _cache(self, res):
      for remote in self.remotesById.values():
         remote.destroyPool()

      self.remotesByAuthKey = {}
      self.remotesById = {}

      n = 0
      for r in res:

         remote = self.makeRemote(r)

         if not self.remotesByAuthKey.has_key(remote.appkey):
            self.remotesByAuthKey[remote.appkey] = []

         self.remotesByAuthKey[remote.appkey].append(remote)
         self.remotesById[remote.id] = remote

         n += 1

      log.msg("%s._cache (%d)" % (self.LOGID, n))


   def queryPool(self, remoteId):
      """
      Query the current database connection pool associated with the
      given remote.

      Returns a list of [(PostgreSQL Backend PID, Connection Creation Time: UTC as String)]
      or None if the remoteId does not exist.
      """
      remote = self.remotesById.get(remoteId, None)
      if remote:
         #return [(c[0], c[1]) for c in remote.poolConnections]
         return [c[:-1] for c in remote.poolConnections]
      else:
         return None


   def queryApi(self, remoteId):
      """
      Query the API provided by the given remote.
      """
      remote = self.remotesById.get(remoteId, None)
      if remote:
         pool = remote.getPool()
         if pool:
            return pool.runInteraction(self._getRemotes, remote)
         else:
            ## should not arrive here (that is, we should have a db connection pool setup for every remote)
            return None
      else:
         return None


   def getRemotes(self, authKey, authExtra):
      """
      Get remoted procedures.

      This will return a Twisted Deferred that yields

        ('pg', {'http://example.com/myschema#myfun': ('myschema', 'myfun', 2, pool, 'SELECT myschema.myfun(%s,%s)')})

      for a 2-ary stored procedure myschema.myfun. The dictionary is indexed by RPC endpoint URI with
      values being 5-tuples containing schema, function, arity, database connection pool and SQL statement.

      This will be called in WampCraServerProtocol.getAuthPermissions().
      """

      ## we need to collect all remoted stored procedures from all remotes
      d = []
      for remote in self.remotesByAuthKey.get(authKey, []):
         ## get the database connection pool for the authKey
         pool = remote.getPool()
         if pool:
            d.append(pool.runInteraction(self._getRemotes, remote))
         else:
            ## should not arrive here (that is, we should have
            ## a db connection pool setup for every remote)
            pass
      rd = defer.gatherResults(d, consumeErrors = True)
      def process(res):
         procs = {}
         for r in res:
            procs.update(r)
         return (self.REMOTERID, procs)
      rd.addCallback(process)
      return rd


   def remoteCall(self, call):
      """
      This method will get registered as an RPC handler via registerHandlerMethodForRpc
      within a WampCraServerProtocol instance after successful authentication.
      """
      proto = call.proto
      uri = call.uri
      args = call.args

      ## extract extra information from RPC call handler argument
      meta = call.extra

      if len(args) != meta.cargs:
         m = "stored procedure %s expects %d arguments, but received %d" % (meta.procedure, meta.cargs, len(args))
         raise Exception(m)

      remote = self.remotesById.get(meta.remoteId, None)
      if remote:
         pool = remote.getPool()
         if pool and pool.running:
            d = pool.runWithConnection(self._callSp, call)
            d.addCallback(self.onAfterRemoteCallSuccess, meta.remoteId)
            d.addErrback(self.onAfterRemoteCallError, meta.remoteId)
            return d
         else:
            raise Exception("pool disappeared or shut down")
      else:
         raise Exception("remote disappeared")

########NEW FILE########
__FILENAME__ = dbschema
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from autobahn.wamp import json_loads


def getSchemaVersion(conn, latestVersions):

      info = {'schema-category': None,
              'schema-version': None,
              'schema-created': None,
              'schema-latest-version': None}

      cur = conn.cursor()
      try:
         cur.execute("SELECT key, value FROM config WHERE key IN ('schema-category', 'schema-version', 'schema-created')")
         for row in cur.fetchall():
            info[row[0]] = json_loads(row[1]) if row[1] is not None else None
      except:
         pass

      if info.has_key('schema-category'):
         if latestVersions.has_key(info['schema-category']):
            info['schema-latest-version'] = latestVersions[info['schema-category']]

      if info['schema-version'] is not None:
         info['schema-needs-upgrade'] = info['schema-version'] < info['schema-latest-version']
      else:
         info['schema-needs-upgrade'] = False

      return info

########NEW FILE########
__FILENAME__ = extdirectremoter
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import urlparse

from twisted.python import log
#from twisted.web.client import getPage
from crossbar.txutil import getPage, StringReceiver, StringProducer, getDomain

from twisted.internet import defer
from twisted.internet.defer import Deferred
from twisted.web.http_headers import Headers

from autobahn.wamp import WampProtocol
from autobahn.wamp import json_loads, json_dumps

from crossbar.adminwebmodule.uris import URI_ERROR_REMOTING
from crossbar.adminwebmodule.uris import URI_EVENT, URI_EXTDIRECTREMOTE

from remoter import Remoter



class ExtDirectRemote:
   """
   Model for a single Ext.Direct Remote.
   """

   def __init__(self,
                id,
                appkey,
                rpcBaseUri,
                routerUrl,
                apiUrl,
                apiObject,
                forwardCookies,
                redirectLimit,
                connectionTimeout,
                requestTimeout,
                usePersistentConnections,
                maxPersistentConnections,
                persistentConnectionTimeout):
      self.id = id
      self.appkey = appkey
      self.rpcBaseUri = rpcBaseUri
      self.routerUrl = routerUrl
      self.routerDomain = getDomain(unicode(routerUrl))
      self.apiUrl = apiUrl
      self.apiObject = apiObject
      self.forwardCookies = forwardCookies
      self.redirectLimit = redirectLimit
      self.connectionTimeout = connectionTimeout
      self.requestTimeout = requestTimeout
      self.usePersistentConnections = usePersistentConnections
      self.maxPersistentConnections = maxPersistentConnections
      self.persistentConnectionTimeout = persistentConnectionTimeout


class ExtDirectRemoter(Remoter):
   """
   Provides a model cache for Ext.Direct remotes and actual API query
   and RPC forwarding for Ext.Direct.

   TODO: Cookies!
   """

   USER_AGENT = "crossbar.io"
   """
   User agent provided in HTTP header for requests issued.
   """

   SERVICENAME = "Ext.Direct Remoter"

   REMOTE_ID_BASEURI = URI_EXTDIRECTREMOTE

   REMOTER_STATE_CHANGE_EVENT_URI = URI_EVENT + "on-extdirectremoter-statechange"
   STATS_EVENT_URI = URI_EVENT + "on-extdirectremoterstat"


   def startService(self):
      Remoter.startService(self)

      ## HTTP connection pools indexed by Ext.Direct Remote ID.
      ## Note that we usually do NOT want to recreate those on mere recaches
      ## since that would unnecessarily drop all currently kept alive connections.
      self.httppools = {}

      ## immedialy cache
      self.dbpool.runInteraction(self.recache)


   def recache(self, txn):
      """
      Recache Ext.Direct Remotes.
      """
      log.msg("ExtDirectRemoter.recache")

      txn.execute("SELECT a.key, r.id, r.rpc_base_uri, r.router_url, r.api_url, r.api_object, r.forward_cookies, r.redirect_limit, r.connection_timeout, r.request_timeout, r.max_persistent_conns, r.persistent_conn_timeout FROM extdirectremote r LEFT OUTER JOIN appcredential a ON r.require_appcred_id = a.id ORDER BY a.key ASC, r.created ASC")
      self._cacheExtDirectRemotes(txn.fetchall())


   def _cacheExtDirectRemotes(self, res):
      self.remotesByAppKey = {}
      self.remotesById = {}
      n = 0
      for r in res:
         appkey = str(r[0]) if r[0] is not None else None
         id = str(r[1])
         if not self.remotesByAppKey.has_key(appkey):
            self.remotesByAppKey[appkey] = []
         usePersistentConnections = int(r[8]) > 0
         remote = ExtDirectRemote(id = id,
                                  appkey = appkey,
                                  rpcBaseUri = str(r[2]),
                                  routerUrl = str(r[3]),
                                  apiUrl = str(r[4]),
                                  apiObject = str(r[5]),
                                  forwardCookies = r[6] != 0,
                                  redirectLimit = int(r[7]),
                                  connectionTimeout = int(r[8]),
                                  requestTimeout = int(r[9]),
                                  usePersistentConnections = usePersistentConnections,
                                  maxPersistentConnections = int(r[10]),
                                  persistentConnectionTimeout = int(r[11]))
         self.remotesByAppKey[appkey].append(remote)
         self.remotesById[id] = remote

         ## avoid module level reactor import
         from twisted.web.client import HTTPConnectionPool

         if usePersistentConnections:
            ## setup HTTP Connection Pool for remote
            if not self.httppools.has_key(id) or self.httppools[id] is None:
               self.httppools[id] = HTTPConnectionPool(self.reactor, persistent = True)
            self.httppools[id].maxPersistentPerHost = remote.maxPersistentConnections
            self.httppools[id].cachedConnectionTimeout = remote.persistentConnectionTimeout
            self.httppools[id].retryAutomatically = False
         else:
            ## make sure to GC existing pool (if any)
            self.httppools[id] = None

         n += 1
      log.msg("ExtDirectRemoter._cacheExtDirectRemotes (%d)" % n)


   def getRemotes(self, authKey, authExtra):
      """
      Get remoted API calls. This is usually called within getAuthPermissions
      on a WAMP session.
      """
      d = []
      for remote in self.remotesByAppKey.get(authKey, []):
         d.append(self.queryApi(remote.id))
      rd = defer.gatherResults(d, consumeErrors = True)
      def process(res):
         l = {}
         for k in res:
            for p in k:
               l[p] = k[p]
         return ('extdirect', l)
      rd.addCallback(process)
      return rd


   def queryApi(self, remoteId):
      """
      Query Ext.Direct API by remote ID.
      """
      remote = self.remotesById.get(remoteId, None)
      if remote is None:
         return None

      if not remote.usePersistentConnections:
         ## Do HTTP/POST as individual request
         ##
         d = getPage(url = remote.apiUrl,
                     method = 'GET',
                     headers = {'User-Agent': ExtDirectRemoter.USER_AGENT},
                     timeout = remote.requestTimeout,
                     connectionTimeout = remote.connectionTimeout,
                     followRedirect = remote.redirectLimit > 0)

      else:
         ## Do HTTP/POST via HTTP connection pool
         ##

         ## avoid module level reactor import
         from twisted.web.client import Agent, RedirectAgent

         agent = Agent(self.reactor,
                       pool = self.httppools[remote.id],
                       connectTimeout = remote.connectionTimeout)

         if remote.redirectLimit > 0:
            agent = RedirectAgent(agent, redirectLimit = remote.redirectLimit)

         ## FIXME: honor requestTimeout
         d = agent.request('GET',
                           remote.apiUrl,
                           Headers({'User-Agent': [ExtDirectRemoter.USER_AGENT]}))

         def onResponse(response):
            if response.code == 200:
               finished = Deferred()
               response.deliverBody(StringReceiver(finished))
               return finished
            else:
               return defer.fail("%s [%s]" % (response.code, response.phrase))

         d.addCallback(onResponse)

      apiRequest = {'provider': 'extdirect',
                    'api-url': remote.apiUrl,
                    'use-persistent-connections': remote.usePersistentConnections,
                    'request-timeout': remote.requestTimeout,
                    'connection-timeout': remote.connectionTimeout}

      d.addCallbacks(self._onQueryApiResult,
                     self._onQueryApiError,
                     callbackArgs = [remote, apiRequest],
                     errbackArgs = [apiRequest])

      return d


   def _onQueryApiResult(self, res, remote, apiRequest):
      """
      Consume Ext.Direct API request result.
      """
      ## cut out JSON with API definition
      ## FIXME: make this more robust!
      i1 = res.find(remote.apiObject)
      if i1 < 0:
         raise Exception(URI_ERROR_REMOTING,
                         "API object could not be found in response payload",
                        {'message': "The API object %s could not be found in the response payload" % remote.apiObject,
                         'response': res,
                         'request': apiRequest})
      i2 = res.find("=", i1) + 1
      r = res[i2:len(res) - 1].strip()

      ## parse JSON API definition
      try:
         o = json_loads(r)
      except Exception, e:
         raise Exception(URI_ERROR_REMOTING,
                         "remoting API response payload could not be decoded",
                        {'message': str(e),
                         'response': res,
                         'json': r,
                         'request': apiRequest})

      ## result set is dictionary indexed by RPC URI containing tuples: (Remote ID, Action, Name, ArgsCount)
      procs = {}
      for c in o['actions']:
         for p in o['actions'][c]:
            if p.has_key('len'):
               ## FIXME? We map to a fixed format URI = <RPC Base URI>/<Action>#<Name>
               procUri = urlparse.urljoin(remote.rpcBaseUri, str(c)) + "#%s" % str(p['name'])
               procs[procUri] = [remote.id, str(c), str(p['name']), int(p['len'])]
            else:
               ## FIXME: handle procedures with named arguments
               pass
      return procs


   def _onQueryApiError(self, e, apiRequest):
      """
      Consume Ext.Direct API request error.
      """
      raise Exception(URI_ERROR_REMOTING,
                      "remoting API could not be queried",
                      {'message': e.getErrorMessage(),
                       'request': apiRequest})


   def remoteCall(self, call):
      """
      RPC handler remoting to Ext.Direct servers. This method is usually
      registered via registerHandlerMethodForRpc on a WAMP protocol.
      """
      proto = call.proto
      uri = call.uri
      args = call.args

      ## extract extra information from RPC call handler argument
      (id, action, method, _) = call.extra

      ## get the Ext.Direct remote onto which we will forward the call
      remote = self.remotesById[id]

      ## construct the POST body
      d = {'action': action,
           'method': method,
           'data': args,
           'type': 'rpc',
           'tid': 1}
      body = json_dumps(d)

      if remote.forwardCookies and \
         proto.cookies and \
         proto.cookies.has_key(remote.routerDomain) and \
         proto.cookies[remote.routerDomain] != "":

         cookie = str(proto.cookies[remote.routerDomain])
      else:
         cookie = None

      if not remote.usePersistentConnections:
         ## Do HTTP/POST as individual request
         ##

         headers = {'Content-Type': 'application/json',
                    'User-Agent': ExtDirectRemoter.USER_AGENT}

         if cookie:
            headers['Cookie'] = cookie

         d = getPage(url = remote.routerUrl,
                     method = 'POST',
                     postdata = body,
                     headers = headers,
                     timeout = remote.requestTimeout,
                     connectionTimeout = remote.connectionTimeout,
                     followRedirect = remote.redirectLimit > 0)

      else:
         ## Do HTTP/POST via HTTP connection pool
         ##

         headers = {'Content-Type': ['application/json'],
                    'User-Agent': [ExtDirectRemoter.USER_AGENT]}

         if cookie:
            headers['Cookie'] = [cookie]

         agent = Agent(self.reactor,
                       pool = self.httppools[remote.id],
                       connectTimeout = remote.connectionTimeout)

         if remote.redirectLimit > 0:
            agent = RedirectAgent(agent, redirectLimit = remote.redirectLimit)

         ## FIXME: honor requestTimeout
         d = agent.request('POST',
                           remote.routerUrl,
                           Headers(headers),
                           StringProducer(body))

         def onResponse(response):
            if response.code == 200:
               finished = Deferred()
               response.deliverBody(StringReceiver(finished))
               return finished
            else:
               return defer.fail("%s [%s]" % (response.code, response.phrase))

         d.addCallback(onResponse)

      ## request information provided as error detail in case of call fails
      remotingRequest = {'provider': 'extdirect',
                         'router-url': remote.routerUrl,
                         'use-persistent-connections': remote.usePersistentConnections,
                         'request-timeout': remote.requestTimeout,
                         'connection-timeout': remote.connectionTimeout,
                         'action': action,
                         'method': method}

      d.addCallbacks(self._onRemoteCallResult,
                     self._onRemoteCallError,
                     callbackArgs = [remotingRequest],
                     errbackArgs = [remotingRequest])

      ## FIXME!
      d.addCallback(self.onAfterRemoteCallSuccess, id)
      d.addErrback(self.onAfterRemoteCallError, id)

      return d


   def _onRemoteCallResult(self, r, remotingRequest):
      """
      Consume Ext.Direct remoting result. Note that this still can trigger a WAMP exception.
      """
      try:
         res = json_loads(r)
      except Exception, e:
         raise Exception(URI_ERROR_REMOTING,
                         "response payload could not be decoded",
                        {'message': str(e),
                         'response': r,
                         'request': remotingRequest})
      if type(res) != dict:
         raise Exception(URI_ERROR_REMOTING,
                         "invalid response (Ext.Direct response not a dict (was %s)" % type(res),
                         {'response': res,
                          'request': remotingRequest})
      if res.has_key('type'):
         if res['type'] == 'rpc':
            if res.has_key('result'):
               return res['result']
            else:
               raise Exception(URI_ERROR_REMOTING,
                               "invalid response (Ext.Direct response missing field 'result')",
                               {'response': res,
                                'request': remotingRequest})
         elif res['type'] == 'exception':
            details = {}
            details['request'] = remotingRequest
            details['where'] = res.get('where', None)
            raise Exception(WampProtocol.ERROR_URI_GENERIC,
                            res.get('message', None),
                            details)
         else:
            raise Exception(URI_ERROR_REMOTING,
                            "invalid response (Ext.Direct response field 'type' unknown value '%s')" % res['type'],
                            {'response': res,
                             'request': remotingRequest})
      else:
         raise Exception(URI_ERROR_REMOTING,
                         "invalid response (Ext.Direct response missing field 'type')",
                         {'response': res,
                          'request': remotingRequest})


   def _onRemoteCallError(self, e, remotingRequest):
      """
      Consume Ext.Direct remoting error.
      """
      raise Exception(URI_ERROR_REMOTING,
                      "RPC could not be remoted",
                      {'message': e.getErrorMessage(),
                       'request': remotingRequest})

########NEW FILE########
__FILENAME__ = hanaclient
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log
from autobahn.wamp import json_dumps


class HanaConnect:
   """
   SAP HANA Connect.
   """

   def __init__(self,
                id,
                driver,
                host,
                port,
                database,
                user,
                password):

      ## 2 connects are equal (unchanged) iff the following are equal (unchanged)
      self.id = str(id)
      self.driver = str(driver)
      self.host = str(host)
      self.port = int(port)
      self.database = str(database)
      self.user = str(user)
      self.password = str(password)

      self.connectstr = 'DRIVER={%s};SERVERNODE=%s:%s;SERVERDB=%s;UID=%s;PWD=%s' % (self.driver, self.host, self.port, self.database, self.user, self.password)

   def __eq__(self, other):
      if isinstance(other, HanaConnect):
         return self.id == other.id and \
                self.driver == other.driver and \
                self.host == other.host and \
                self.port == other.port and \
                self.database == other.database and \
                self.user == other.user and \
                self.password == other.password
      return NotImplemented

   # http://jcalderone.livejournal.com/32837.html !!
   def __ne__(self, other):
      result = self.__eq__(other)
      if result is NotImplemented:
         return result
      return not result

   def __repr__(self):
      r = {'id': self.id,
           'driver': self.driver,
           'host': self.host,
           'port': self.port,
           'database': self.database,
           'user': self.user,
           'password': self.password}
      return json_dumps(r)


class HanaSchemaSetup:

   SQL_CREATE_TABLE_EVENT = """
CREATE TABLE event
(
   id             BIGINT         PRIMARY KEY,
   published_at   TIMESTAMP      NOT NULL,
   published_by   VARCHAR(100)   NOT NULL,
   topic          VARCHAR(5000)  NOT NULL,
   payload_type   TINYINT        NOT NULL,
   payload        VARCHAR(5000)
)
"""

   SQL_CREATE_PROCEDURE_PUBLISH = """
CREATE PROCEDURE publish(IN topic VARCHAR, IN payload VARCHAR, IN payload_type TINYINT)
LANGUAGE SQLSCRIPT AS
   id               BIGINT       := NULL;
   published_at     TIMESTAMP;
   published_by     VARCHAR(100);
BEGIN
   IF payload_type = 1 OR payload_type = 2 THEN
      SELECT event_id.NEXTVAL, NOW(), current_user INTO id, published_at, published_by FROM dummy;
      INSERT INTO event (id, published_at, published_by, topic, payload_type, payload) VALUES (id, published_at, published_by, topic, payload_type, payload);
   END IF;
   SELECT id FROM dummy;
END
"""

   SQL_TABLES = [('event', SQL_CREATE_TABLE_EVENT)]
   SQL_SEQUENCES = [('event_id', "CREATE SEQUENCE event_id")]
   SQL_PROCEDURES = [('publish', SQL_CREATE_PROCEDURE_PUBLISH)]

   def __init__(self, connectstr, schema, recreate = False):
      self.connectstr = connectstr
      self.schema = schema
      self.recreate = recreate

   def run(self):
      log.msg("HanaSchemaSetup started")

      try:
         import time, json
         import pyodbc

         conn = pyodbc.connect(self.connectstr)
         cur = conn.cursor()

         if self.recreate:
            log.msg("Recreating schema objects")

            for o in self.SQL_PROCEDURES:
               try:
                  cur.execute("DROP PROCEDURE ?", [o[0]])
                  log.msg("TABLE %s dropped" % o[0])
               except:
                  pass

            for o in self.SQL_SEQUENCES:
               try:
                  cur.execute("DROP SEQUENCE ?", [o[0]])
                  log.msg("SEQUENCE %s dropped" % o[0])
               except:
                  pass

            for o in self.SQL_TABLES:
               try:
                  cur.execute("DROP TABLE ?", [o[0]])
                  log.msg("TABLE %s dropped" % o[0])
               except:
                  pass

         for o in self.SQL_TABLES:
            cur.execute("SELECT 1 FROM SYS.TABLES WHERE schema_name = ? AND table_name = ?", [self.schema, o[0].upper()])
            if cur.fetchone() is None:
               cur.execute(o[1])
               log.msg("TABLE %s created" % o[0])
            else:
               log.msg("TABLE %s already exists" % o[0])

         for o in self.SQL_SEQUENCES:
            cur.execute("SELECT 1 FROM SYS.SEQUENCES WHERE schema_name = ? AND sequence_name = ?", [self.schema, o[0].upper()])
            if cur.fetchone() is None:
               cur.execute(o[1])
               log.msg("SEQUENCE %s created" % o[0])
            else:
               log.msg("SEQUENCE %s already exists" % o[0])

         for o in self.SQL_PROCEDURES:
            cur.execute("SELECT 1 FROM SYS.PROCEDURES WHERE schema_name = ? AND procedure_name = ?", [self.schema, o[0].upper()])
            if cur.fetchone() is None:
               cur.execute(o[1])
               log.msg("PROCEDURE %s created" % o[0])
            else:
               log.msg("PROCEDURE %s already exists" % o[0])


      except Exception, e:
         log.msg(e)
         raise e

########NEW FILE########
__FILENAME__ = hanapusher
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log

from autobahn.wamp import json_loads

from crossbar.adminwebmodule.uris import URI_EVENT, URI_HANACONNECT
from hanaclient import HanaConnect
from dbpusher import DbPusher, DbPushClient


class HanaPushRule:
   """
   SAP HANA Push Rule.

   User:
      SAP HANA: current_user
      http://help.sap.com/hana/html/_esql_functions_misc.html
   """
   def __init__(self,
                id,
                connectId,
                user,
                topicUri,
                matchByPrefix):
      self.id = str(id)
      self.connectId = str(connectId)
      self.user = str(user) if user is not None else None
      self.topicUri = str(topicUri)
      self.matchByPrefix = matchByPrefix != 0



class HanaPushClient(DbPushClient):
   """
   SAP HANA Push Client.
   """

   LOGID = "HanaPushClient"


   def loop(self):
      import time
      import pyodbc

      conn = pyodbc.connect(self.connectstr)
      cur1 = conn.cursor()
      cur2 = conn.cursor()

      cur1.execute("SELECT COALESCE(MAX(id), 0), COALESCE(MIN(id), 0), COUNT(*) FROM crossbar.event")
      (id, minid, evtcnt) = cur1.fetchone()

      while not self.stopped:
         cur1.execute("SELECT id, pushed_by, topic, payload_type, payload FROM crossbar.event WHERE id > ? ORDER BY id ASC", [id])
         oldid = id
         for r in cur1.fetchall():

            id = r[0]
            pushedBy = r[1]
            topic = r[2]
            payload = None

            if r[4] is not None:

               ## JSON payload
               if r[3] == 2:
                  try:
                     payload = json_loads(r[4])
                  except Exception, e:
                     log.msg("%s - INVALID JSON PAYLOAD - %s" % (r[4], str(e)))

               ## plain string payload
               elif r[3] == 1:
                  payload = r[4]

               else:
                  log.msg("INVALID PAYLOAD TYPE %s" % r[4])

            reactor.callFromThread(self.pusher, self.hanaconnectId, pushedBy, topic, payload)

         if self.purge and id > oldid:
            cur2.execute("DELETE FROM crossbar.event WHERE id <= ?", id)
            conn.commit()

         if self.throttle > 0:
            time.sleep(self.throttle)




class HanaPusher(DbPusher):
   """
   SAP HANA Pusher Service.

   For each SAP HANA Connect with >0 push rules, spawn 1 background pusher thread.
   """

   SERVICENAME = "SAP HANA Pusher"

   LOGID = "HanaPusher"

   CONNECT_ID_BASEURI = URI_HANACONNECT

   PUSHER_STATE_CHANGE_EVENT_URI = URI_EVENT + "on-hanapusher-statechange"
   STATS_EVENT_URI = URI_EVENT + "on-hanapusherstat"

   def makeConnect(self, r):
      ## called from DbPusher base class to create database connect instances
      return HanaConnect(r[0], r[1], r[2], r[3], r[4], r[5], r[6])

   def makeRule(self, r):
      ## called from DbPusher base class to create push rule instances
      return HanaPushRule(r[0], r[1], r[2], r[3], r[4])

   def makeClient(self, connect):
      ## called from DbPusher base class to create background push client instances
      return HanaPushClient(self, connect, False)

   def recache(self, txn):
      log.msg("HanaPusher.recache")

      txn.execute("SELECT id, driver, host, port, database, user, password FROM hanaconnect")
      connects = txn.fetchall()

      txn.execute("SELECT id, hanaconnect_id, user, topic_uri, match_by_prefix FROM hanapushrule")
      rules = txn.fetchall()

      self._cache(connects, rules)

      #log.msg("SAP HANA Connects cached: %s" % self.connects)

########NEW FILE########
__FILENAME__ = hanaremoter
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log
from twisted.application import service
from twisted.enterprise import adbapi
from twisted.internet.defer import succeed


#CONNECTSTR = 'DRIVER={HANA};SERVERNODE=10.231.17.219:30015;SERVERDB=HDB;UID=TEST;PWD=Abcd2366'
CONNECTSTR = 'DRIVER={HDBODBC32};SERVERNODE=54.247.126.11:30015;SERVERDB=HDB;UID=TEST;PWD=Abcd2366'


class HanaRemoter(service.Service):
   """

   Restrictions:
   HanaRemoter is currently only able for forward RPCs to SQLScript stored procedures that:

      - have only IN parameters (no OUT, no INOUT)
      - have only primitive types for parameters
      - return a single result set (have single SELECT statement at the end of the SP body)
   """

   SERVICENAME = "SAP HANA Remoter"

   def __init__(self, dbpool, services):
      self.dbpool = dbpool
      self.services = services
      self.enabled = False

      if False and services["database"].getLicenseOptions()["hana"]:
         try:
            import pyodbc
            self.enabled = True
            self.pool1 = adbapi.ConnectionPool("pyodbc",
                                               CONNECTSTR,
                                               cp_min = 3,
                                               cp_max = 10,
                                               cp_noisy = True,
                                               cp_openfun = self.onDbConnect,
                                               cp_reconnect = True,
                                               cp_good_sql = "SELECT 1 FROM dummy")
         except Exception, e:
            log.msg("no pyodbc module")


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)
      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      self.isRunning = False


   def getRemoterStats(self):
      return [{'uri': None,
               'call-allowed': 0,
               'call-denied': 0,
               'forward-success': 0,
               'forward-failed': 0}]


   def onDbConnect(self, conn):
      log.msg("SAP HANA database connection opened")


   def _getRemotes(self, txn):
      PREFIX = "http://example.com/"
      txn.execute("SELECT schema_name, procedure_name, input_parameter_count FROM sys.PROCEDURES WHERE schema_name = 'TEST' AND output_parameter_count = 0 AND inout_parameter_count = 0 AND result_set_count = 0")
      procs = {}
      res = txn.fetchall()
      if res is not None:
         for r in res:
            uri = PREFIX + str(r[0]).lower() + "#" + str(r[1]).lower()
            statement = "{call %s.%s(%s)}" % (str(r[0]), str(r[1]), ("?," * r[2])[:-1])
            procs[uri] = (r[0], r[1], r[2], statement)
      return ('hana', procs)


   def getRemotes(self, authKey, authExtra):
      if self.enabled:
         return self.pool1.runInteraction(self._getRemotes)
      else:
         return succeed(('hana', {}))


   def _callSp(self, txn, statement, args):
      #txn.execute("{call test.echo(?)}", [args[0]])
      txn.execute(statement, args)
      rr = txn.fetchall()
      res = None
      if rr is not None:
         if len(rr) > 1:
            res = []
            for r in rr:
               if len(r) > 1:
                  res.append(list(r))
               else:
                  res.append(r[0])
         else:
            if len(rr[0]) > 1:
               res = list(rr[0])
            else:
               res = rr[0][0]
      return res


   def remoteCall(self, uri, args, extra):

      ## get protocol we are remoting for
      proto = extra[0]

      ## extract extra information from RPC call handler argument
      (schema, proc, cargs, statement) = extra[1]

      if len(args) != cargs:
         raise Exception("stored procedure %s expects %d arguments, but received %d" % (schema.upper() + "." + proc.upper(), cargs, len(args)))

      return self.pool1.runInteraction(self._callSp, statement, args)

########NEW FILE########
__FILENAME__ = oraclient
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from autobahn.wamp import json_dumps


class OraConnect:
   """
   Oracle Connect.
   """

   def __init__(self,
                id,
                host,
                port,
                sid,
                user,
                password,
                demoUser,
                demoPassword,
                connectionTimeout):

      ## 2 connects are equal (unchanged) iff the following are equal (unchanged)
      self.id = str(id)
      self.host = str(host)
      self.port = int(port)
      self.sid = str(sid)
      self.user = str(user)
      self.password = str(password)
      self.demoUser = str(demoUser) if demoUser is not None else None
      self.demoPassword = str(demoPassword) if demoPassword is not None else None

      self.connectionTimeout = connectionTimeout

   def __eq__(self, other):
      if isinstance(other, OraConnect):
         return self.id == other.id and \
                self.host == other.host and \
                self.port == other.port and \
                self.sid == other.sid and \
                self.user == other.user and \
                self.password == other.password and \
                self.demoUser == other.demoUser and \
                self.demoPassword == other.demoPassword
      return NotImplemented

   # http://jcalderone.livejournal.com/32837.html !!
   def __ne__(self, other):
      result = self.__eq__(other)
      if result is NotImplemented:
         return result
      return not result

   def __repr__(self):
      r = {'id': self.id,
           #'connectionTimeout': self.connectionTimeout,
           'host': self.host,
           'port': self.port,
           'sid': self.sid,
           'user': self.user,
           'password': self.password,
           'demo-user': self.demoUser,
           'demo-password': self.demoPassword,
           }
      return json_dumps(r)

########NEW FILE########
__FILENAME__ = orapusher
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log

from autobahn.wamp import json_loads

from crossbar.adminwebmodule.uris import URI_EVENT, URI_ORACONNECT
from oraclient import OraConnect
from dbpusher import DbPusher, DbPushClient
from pusher import validateUri


class OraPushRule:
   """
   Oracle Push Rule.

   User:
      Oracle: Session User => sys_context('USERENV', 'SESSION_USER')
   """
   def __init__(self,
                id,
                connectId,
                user,
                topicUri,
                matchByPrefix):
      self.id = str(id)
      self.connectId = str(connectId)
      self.user = set([x.strip().upper() for x in str(user).split(',')]) if user is not None else None
      self.topicUri = str(topicUri)
      self.matchByPrefix = matchByPrefix != 0



class OraPushClient(DbPushClient):
   """
   Oracle Push Client.
   """

   LOGID = "OraPushClient"

   def loop(self):

      ## use DBMS_PIPE based notification
      self.usePipe = True

      ## DBMS_PIPE.receive_message timeout in secs
      self.pipeTimeout = int(1)

      ## Iff true, recheck event table on every pipe timeout
      self.recheckOnPipeTimeout = False

      import time, json

      import os
      os.environ["NLS_LANG"] = "AMERICAN_AMERICA.UTF8"

      import cx_Oracle

      try:
         dsn = cx_Oracle.makedsn(self.connect.host,
                                 self.connect.port,
                                 self.connect.sid)
         self.conn = cx_Oracle.connect(self.connect.user,
                                       self.connect.password,
                                       dsn,
                                       threaded = False)
         self.conn.autocommit = True
         log.msg("pusher Oracle connection established")
      except Exception, e:
         #log.msg(str(e))
         raise e


      ## verify that we are the only pusher connected to this DB
      ## by allocating an X-lock.
      ## FIXME:
      ##   - the lock is not schema-wise, but instance wise
      ##   - we should cover the whole crossbar.io/Oracle integration (not only the pusher)
      cur = self.conn.cursor()
      cur.prepare("""
         DECLARE
            l_lockhandle VARCHAR2(128);
         BEGIN
           DBMS_LOCK.ALLOCATE_UNIQUE('crossbar', l_lockhandle);
           :retval := DBMS_LOCK.REQUEST(l_lockhandle, DBMS_LOCK.X_MODE, 0, FALSE);
         END;
      """)
      curVars = cur.setinputsizes(retval = cx_Oracle.NUMBER)
      cur.execute(None)
      retval = int(curVars["retval"].getvalue())
      if retval != 0:
         rmap = {0: "Success",
                 1: "Timeout",
                 2: "Deadlock",
                 3: "Parameter error",
                 4: "Don't own lock specified by id or lockhandle",
                 5: "Illegal lock handle"}
         raise Exception("There seems to be another pusher connected [lock result %d - %s]" % (retval, rmap.get(retval, "??")))
      else:
         log.msg("Ok, we are the only pusher connected to the Oracle instance")


      self.isConnected = True
      self.pusher.publishPusherStateChange(self.connect.id, True, True)

      cur = self.conn.cursor()

      cur.execute("SELECT sys_context('USERENV', 'SESSION_USER') FROM dual")
      session_user = cur.fetchone()[0].upper()

      cur.execute("""
                  BEGIN
                     DBMS_SESSION.SET_IDENTIFIER(:1);
                  END;
                  """, ['CROSSBAR_%s_PUSHER_%s' % (session_user, self.connect.id)])

      ## when using DBMS_PIPE, the name of the event pipe
      PIPENAME = 'CROSSBAR_%s_ONPUBLISH' % session_user
      print "using pipe", PIPENAME

      ## if using pipe mode, prepare for that
      ##
      if self.usePipe:
         cur.execute("""
                     BEGIN
                        SYS.DBMS_PIPE.purge(:pipename);
                     END;
                     """, pipename = PIPENAME)

         curWaitPipe = self.conn.cursor()
         curWaitPipe.prepare("""
                             BEGIN
                                :retval := SYS.DBMS_PIPE.receive_message(:pipename, :timeout);
                                IF :retval = 0 THEN
                                   SYS.DBMS_PIPE.unpack_message(:event_id);
                                   SYS.DBMS_PIPE.purge(:pipename);
                                END IF;
                             END;
                             """)
         curWaitPipeVars = curWaitPipe.setinputsizes(retval = cx_Oracle.NUMBER,
                                                     pipename = cx_Oracle.STRING,
                                                     timeout = cx_Oracle.NUMBER,
                                                     event_id = cx_Oracle.NUMBER)
         pipePipename = curWaitPipeVars["pipename"]
         pipePipename.setvalue(0, PIPENAME)

         pipeTimeout = curWaitPipeVars["timeout"]
         pipeTimeout.setvalue(0, self.pipeTimeout)

         pipeRetVal = curWaitPipeVars["retval"]
         pipeEventId = curWaitPipeVars["event_id"]


      ## setup stuff for getting unprocessed events
      ##
      curGetEvents = self.conn.cursor()
      curGetEvents.prepare("""
                           SELECT id,
                                  published_by,
                                  topic,
                                  qos,
                                  payload_type,
                                  payload_str,
                                  payload_lob,
                                  exclude_sids,
                                  eligible_sids
                            FROM
                               event WHERE id > :id AND processed_at IS NULL
                            ORDER BY id ASC
                            """)
      curGetEventsVars = curGetEvents.setinputsizes(id = cx_Oracle.NUMBER)
      getFromEventId = curGetEventsVars["id"]


      ## setup stuff for purging/marking processed events
      ##
      if self.purge:
         curDeleteEvents = self.conn.cursor()
         curDeleteEvents.prepare("""DELETE FROM event WHERE id = :id""")
         curDeleteEventsVars = curDeleteEvents.setinputsizes(id = cx_Oracle.NUMBER)
         deleteEventId = curDeleteEventsVars["id"]
      else:
         curMarkEvents = self.conn.cursor()
         curMarkEvents.prepare("""
                               UPDATE event SET processed_at = systimestamp at time zone 'utc',
                                                processed_status = :processed_status,
                                                processed_errmsg = :processed_errmsg,
                                                processed_len = :processed_len
                                 WHERE id = :id""")
         curMarkEventsVars = curMarkEvents.setinputsizes(id = cx_Oracle.NUMBER,
                                                         processed_status = cx_Oracle.NUMBER,
                                                         processed_errmsg = cx_Oracle.STRING,
                                                         processed_len = cx_Oracle.NUMBER)
         markEventId = curMarkEventsVars["id"]
         markEventProcessedStatus = curMarkEventsVars["processed_status"]
         markEventProcessedErrMsg = curMarkEventsVars["processed_errmsg"]
         markEventProcessedLen = curMarkEventsVars["processed_len"]


      ## setup stuff for tracking stats of processed events
      ##
      if self._trackDispatched:
         curTrackEvents = self.conn.cursor()
         curTrackEvents.prepare("""
                               UPDATE event SET dispatch_status = :dispatch_status,
                                                dispatch_success = :dispatch_success,
                                                dispatch_failed = :dispatch_failed
                                 WHERE id = :id""")
         curTrackEventsVars = curTrackEvents.setinputsizes(id = cx_Oracle.NUMBER,
                                                           dispatch_status = cx_Oracle.NUMBER,
                                                           dispatch_success = cx_Oracle.NUMBER,
                                                           dispatch_failed = cx_Oracle.NUMBER)
         trackEventId = curTrackEventsVars["id"]
         trackDispatchStatus = curTrackEventsVars["dispatch_status"]
         trackDispatchSuccess = curTrackEventsVars["dispatch_success"]
         trackDispatchFailed = curTrackEventsVars["dispatch_failed"]


      ## check current contents of event table
      ##
      cur.execute("SELECT NVL(MIN(id), 0), NVL(MAX(id), 0), COUNT(*) FROM event WHERE processed_at IS NULL")
      (minId, maxId, evtCnt) = cur.fetchone()

      ## event ID after we will start processing events ..
      ##
      id = None

      ## purge or mark events left over since we were offline
      ##
      if evtCnt > 0:
         if not self.processOldEvents:
            log.msg("skipping %d events accumulated since we were offline [purge = %s]" % (evtCnt, self.purge))
            if self.purge:
               cur.execute("""
                           DELETE FROM event
                              WHERE id >= :1 AND
                                    id <= :2 AND
                                    processed_at IS NULL""",
                                    [minId,
                                     maxId])
               #self.conn.commit()
            else:
               processed_status = 5
               processed_errmsg = None
               cur.execute("""
                           UPDATE event
                              SET processed_at = systimestamp at time zone 'utc',
                                  processed_status = :1,
                                  processed_errmsg = :2
                              WHERE
                                  id >= :3 AND
                                  id <= :4 AND
                                  processed_at IS NULL""",
                                  [processed_status,
                                   processed_errmsg[:4000] if processed_errmsg is not None else None,
                                   minId,
                                   maxId])
               #self.conn.commit()

            ## start processing only with new events (skipping events that accumulated while we were offline)
            id = maxId
         else:
            log.msg("%d events accumulated since we were offline - will process those now" % evtCnt)

            ## start processing at events that accumulated while we were offline
            id = minId - 1
      else:
         log.msg("no events accumulated since we were offline")

         ## start processing with new events
         id = maxId

      ## inner loop, will run until we get stop()'ed
      ##
      while not self.stopped:

         checkAgain = True
         while checkAgain:

            if self.trackDispatched:
               while self.dispatched and len(self.dispatched) > 0:
                  trackedEventId, dispatch_status, dispatch_success, dispatch_failed = self.dispatched.popleft()
                  trackEventId.setvalue(0, trackedEventId)
                  trackDispatchStatus.setvalue(0, dispatch_status)
                  trackDispatchSuccess.setvalue(0, dispatch_success)
                  trackDispatchFailed.setvalue(0, dispatch_failed)
                  curTrackEvents.execute(None)
                  #self.conn.commit()


            ## we do this rather low-level with a cursor loop, since
            ## we process CLOB columns
            ##
            gotRows = 0

            #cur.execute("""SELECT id,
            #                      published_by,
            #                      topic,
            #                      qos,
            #                      payload_type,
            #                      payload_str,
            #                      payload_lob,
            #                      exclude_sids,
            #                      eligible_sids
            #                FROM
            #                   event WHERE id > :1 AND processed_at IS NULL
            #                ORDER BY id ASC""", [id])

            getFromEventId.setvalue(0, id)
            curGetEvents.execute(None)

            doFetch = True
            while doFetch:
               #r = cur.fetchone()
               r = curGetEvents.fetchone()
               if r is not None:
                  gotRows += 1

                  ## processed_status:
                  ##
                  ##     0 - ok
                  ##     1 - invalid event topic URI
                  ##     2 - illegal event payload type
                  ##     3 - invalid event payload
                  ##     4 - illegal event qos type
                  ##     5 - unprocessed old event (got published as we were offline)
                  ##
                  processed_status = 0 # default to valid processing
                  processed_errmsg = None # filled when processed_status != 0

                  id = r[0]
                  pushedBy = r[1]
                  topic = r[2]
                  qos = r[3]
                  payload_type = r[4]

                  if r[6] is not None:
                     ## cx_Oracle.LOB object
                     payload_raw_len = r[6].size()
                     payload_raw = r[6].read()
                  else:
                     ## cx_Oracle.STRING
                     if r[5] is not None:
                        payload_raw_len = len(r[5])
                        payload_raw = r[5]
                     else:
                        payload_raw_len = 0
                        payload_raw = None

                  payload = None
                  exclude = r[7] if r[7] is not None else []
                  eligible = r[8] if r[8] is not None else None

                  ## validate/parse event
                  ##
                  if processed_status == 0:
                     uriValid, result = validateUri(topic)
                     if not uriValid:
                        processed_status = 1
                        processed_errmsg = result

                  if processed_status == 0:
                     if payload_type == 1:
                        ## plain string
                        ##
                        payload = payload_raw
                     elif payload_type == 2:
                        ## JSON
                        ##
                        try:
                           if payload_raw is not None:
                              payload = json_loads(payload_raw)
                           else:
                              payload = None
                        except Exception, e:
                           ## this should not happen, since we have serialized the
                           ## payload from a JSON typed object within Oracle!
                           ##
                           processed_status = 3 # invalid payload
                           processed_errmsg = "invalid JSON payload ('%s')" % str(e)
                     else:
                        ## this should not happen, since we have a CHECK constraint
                        ## on the underlying event table!
                        ##
                        processed_status = 2
                        processed_errmsg = "illegal event payload type %d" % payload_type

                  if processed_status == 0:
                     if qos == 1:
                        pass
                     else:
                        processed_status = 4
                        processed_errmsg = "illegal event qos type %d" % qos

                  ## let the events be dispatched on the reactor thread
                  ##
                  if processed_status == 0:
                     self.reactor.callFromThread(self.pusher.push,
                                                id,
                                                self.connect.id,
                                                pushedBy,
                                                topic,
                                                payload,
                                                exclude,
                                                eligible)

                  ## purge or mark processed event
                  ##
                  if self.purge:
                     #cur.execute("DELETE FROM event WHERE id = :1", [id])
                     deleteEventId.setvalue(0, id)
                     curDeleteEvents.execute(None)
                     #self.conn.commit()
                  else:
                     #cur.execute("UPDATE event SET processed_at = systimestamp at time zone 'utc', processed_status = :1, processed_errmsg = :2 WHERE id = :3", [processed_status, processed_errmsg[:4000] if processed_errmsg is not None else None, id])
                     markEventId.setvalue(0, id)
                     markEventProcessedStatus.setvalue(0, processed_status)
                     markEventProcessedErrMsg.setvalue(0, processed_errmsg)
                     markEventProcessedLen.setvalue(0, payload_raw_len)
                     curMarkEvents.execute(None)
                     #self.conn.commit()
               else:
                  doFetch = False

            ## immediately check again if we got rows.
            ## otherwise go to sleep / wait on pipe notification
            ##
            if gotRows > 0:
               #log.msg("got %d events, checking again .." % gotRows)
               checkAgain = True
            else:
               #log.msg("no new events")
               checkAgain = False

         ## wait for new events ..
         ##
         if not self.usePipe:
            ## when in polling mode, just sleep a little and recheck for events ..
            ##
            if self.pollThrottle > 0:
               time.sleep(self.pollThrottle)
         else:
            ## when using DBMS_PIPE, block in pipe receive for new events ..
            ##
            waitForPipe = True
            debugPipe = False

            while waitForPipe:

               ## the following will block in pipe receive ..
               ##
               curWaitPipe.execute(None)
               retval = int(pipeRetVal.getvalue())

               if retval == 1:

                  ## pipe timeout
                  ##
                  if debugPipe:
                     log.msg("DBMS_PIPE timeout")

               elif retval == 0:

                  ## the pipe got a new event ID ..
                  ##
                  notifiedId = int(pipeEventId.getvalue())
                  waitForPipe = False

                  if debugPipe:
                     log.msg("DBMS_PIPE data available [event %s]" % notifiedId)

               else:
                  ## could not receive from pipe .. something bad happened.
                  ## exit and rely on automatic pusher restart
                  ##
                  raise Exception("error while doing DBMS_PIPE.receive_message - return value %d" % retval)

               if self.recheckOnPipeTimeout:
                  waitForPipe = False



class OraPusher(DbPusher):
   """
   Oracle Pusher Service.

   For each OraConnect with >0 push rules, spawn 1 background pusher thread.
   """

   SERVICENAME = "Oracle Pusher"

   LOGID = "OraPusher"

   CONNECT_ID_BASEURI = URI_ORACONNECT

   PUSHER_STATE_CHANGE_EVENT_URI = URI_EVENT + "on-orapusher-statechange"
   STATS_EVENT_URI = URI_EVENT + "on-orapusherstat"

   def makeConnect(self, r):
      ## called from DbPusher base class to create database connect instances
      return OraConnect(r[0], r[1], r[2], r[3], r[4], r[5], r[6], r[7], r[8])

   def makeRule(self, r):
      ## called from DbPusher base class to create push rule instances
      return OraPushRule(r[0], r[1], r[2], r[3], r[4])

   def makeClient(self, connect):
      ## called from DbPusher base class to create background push client instances
      return OraPushClient(self, connect, False)

   def recache(self, txn):
      log.msg("OraPusher.recache")

      txn.execute("SELECT id, host, port, sid, user, password, demo_user, demo_password, connection_timeout FROM oraconnect ORDER BY id")
      connects = txn.fetchall()

      txn.execute("SELECT id, oraconnect_id, user, topic_uri, match_by_prefix FROM orapushrule ORDER BY oraconnect_id, id")
      rules = txn.fetchall()

      self._cache(connects, rules)

########NEW FILE########
__FILENAME__ = oraremoter
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import datetime, isodate

from autobahn.wamp import json_loads, json_dumps

from autobahn.util import utcnow

from twisted.python import log
from twisted.python.failure import Failure

from crossbar.adminwebmodule.uris import URI_EVENT, URI_ORAREMOTE
from crossbar.adbapi import ConnectionPool

from dbremoter import DbRemoter, DbRemote, DbProcedureMeta

from crossbar.adminwebmodule.uris import URI_BASE, \
                                      URI_ERROR, \
                                      URI_ERROR_REMOTING, \
                                      URI_ERROR_SQL


class OraRemote(DbRemote):
   """
   Model for flattened Oracle database remotes.

   Objects of this class contain flattened information from the following
   service database entities:

     - oraremote
     - oraconnect
     - appcredential
   """

   def __init__(self,
                id,
                appkey,
                host,
                port,
                sid,
                user,
                password,
                schemaList,
                rpcBaseUri,
                connectionPoolMinSize,
                connectionPoolMaxSize,
                connectionTimeout,
                requestTimeout):

      self.id = str(id)
      self.appkey = str(appkey) if appkey is not None else None

      self.host = str(host)
      self.port = int(port)
      self.sid = str(sid)
      self.user = str(user)
      self.password = str(password)

      self.schemaList = str(schemaList)
      self.rpcBaseUri = str(rpcBaseUri)

      self.connectionPoolMinSize = int(connectionPoolMinSize)
      self.connectionPoolMaxSize = int(connectionPoolMaxSize)
      self.connectionTimeout = int(connectionTimeout)
      self.requestTimeout = int(requestTimeout)

      self.pool = None
      self.poolConnections = []


   def __eq__(self, other):
      if isinstance(other, OraRemote):
         return self.id == other.id and \
                self.appkey == other.appkey and \
                self.host == other.host and \
                self.port == other.port and \
                self.sid == other.sid and \
                self.user == other.connectId and \
                self.password == other.password and \
                self.schemaList == other.schemaList and \
                self.rpcBaseUri == other.rpcBaseUri and \
                self.connectionPoolMinSize == other.connectionPoolMinSize and \
                self.connectionPoolMaxSize == other.connectionPoolMaxSize and \
                self.connectionTimeout == other.connectionTimeout and \
                self.requestTimeout == other.requestTimeout
      return NotImplemented


   def __repr__(self):
      r = {'id': self.id,
           'appkey': self.appkey,

           'host': self.host,
           'port': self.port,
           'sid': self.sid,
           'user': self.user,
           'password': self.password,

           'schemaList': self.schemaList,
           'rpcBaseUri': self.rpcBaseUri,
           'connectionPoolMinSize': self.connectionPoolMinSize,
           'connectionPoolMaxSize': self.connectionPoolMaxSize,
           'connectionTimeout': self.connectionTimeout,
           'requestTimeout': self.requestTimeout,
           }
      return json_dumps(r)


   def makePool(self):
      import os
      os.environ["NLS_LANG"] = "AMERICAN_AMERICA.UTF8"
      import cx_Oracle

      dsn = cx_Oracle.makedsn(self.host, self.port, self.sid)
      pool = ConnectionPool("cx_Oracle",
                            user = self.user,
                            password = self.password,
                            dsn = dsn,
                            threaded = True,
                            cp_min = self.connectionPoolMinSize,
                            cp_max = self.connectionPoolMaxSize,
                            cp_noisy = True,
                            cp_openfun = self._onPoolConnectionCreated,
                            cp_reconnect = True,
                            cp_good_sql = "SELECT 1 FROM dual")
      return pool


   def _onPoolConnectionCreated(self, conn):
      ## setup per connection settings

      conn.autocommit = True

      cur = conn.cursor()

      ## set session identifier to help DBAs
      cur.execute("""
                  BEGIN
                     DBMS_SESSION.SET_IDENTIFIER(:1);
                  END;
                  """, ['CROSSBAR_%s_REMOTER_%s' % (self.user.upper(), self.id)])

      ## set UTC for session
      cur.execute("ALTER SESSION SET TIME_ZONE='+00:00'")

      ## set ISO 8601 format for date/timestamp default to string conversion
      cur.execute("""
                  ALTER SESSION SET NLS_DATE_FORMAT = 'YYYY-MM-DD"T"HH24:MI:SS"Z"'
                  """)
      cur.execute("""
                  ALTER SESSION SET NLS_TIMESTAMP_FORMAT = 'YYYY-MM-DD"T"HH24:MI:SS.FF"Z"'
                  """)
      cur.execute("""
                  ALTER SESSION SET NLS_TIMESTAMP_TZ_FORMAT = 'YYYY-MM-DD"T"HH24:MI:SS.FFTZH:TZM'
                  """)

      ## This work even when we don't have privileges on V$SESSION
      ## and returns the AUDSID
      ##
      cur.execute("SELECT sys_context('USERENV', 'SESSIONID') FROM dual")
      audsid = cur.fetchone()[0]

      ## Works only from 10g onwards
      ##
      try:
         cur.execute("SELECT sys_context('USERENV', 'SID') FROM dual")
         sid = cur.fetchone()[0]
      except:
         sid = None

      self.poolConnections.append((audsid, sid, utcnow(), conn))

      log.msg("Oracle pool connection for OraRemote %s created [AUDSID = %s, SID = %s]" % (self.id, audsid, sid))


class OraRemoter(DbRemoter):
   """
   Implements remoting of Oracle stored procedures.
   """

   SERVICENAME = "Oracle Remoter"

   LOGID = "OraRemoter"
   REMOTERID = "ora"

   REMOTE_ID_BASEURI = URI_ORAREMOTE

   REMOTER_STATE_CHANGE_EVENT_URI = URI_EVENT + "on-oraremoter-statechange"
   STATS_EVENT_URI = URI_EVENT + "on-oraremoterstat"


   def recache(self, txn):
      """
      Recache Oracle database remotes.

      Recaching is triggered from the following classes:

         - OraRemotes
         - OraConnects
         - AppCreds
      """
      log.msg("OraRemoter.recache")

      txn.execute("""
         SELECT
            r.id,
            a.key,
            b.host,
            b.port,
            b.sid,
            b.user,
            b.password,
            r.schema_list,
            r.rpc_base_uri,
            r.connection_pool_min_size,
            r.connection_pool_max_size,
            r.connection_timeout,
            r.request_timeout
         FROM
            oraremote r
            INNER JOIN
               oraconnect b ON r.oraconnect_id = b.id
            LEFT OUTER JOIN
               appcredential a ON r.require_appcred_id = a.id
         ORDER BY
            a.key ASC,
            b.id ASC,
            r.created ASC
      """)
      remotes = txn.fetchall()
      self._cache(remotes)


   def makeRemote(self, r):
      remote = OraRemote(id = r[0],
                         appkey = r[1],
                         host = r[2],
                         port = r[3],
                         sid = r[4],
                         user = r[5],
                         password = r[6],
                         schemaList = r[7],
                         rpcBaseUri = r[8],
                         connectionPoolMinSize = r[9],
                         connectionPoolMaxSize = r[10],
                         connectionTimeout = r[11],
                         requestTimeout = r[12])
      return remote


   def _getRemotes(self, txn, remote):

      ## the procedures remoted (indexed by URI) we return
      ##
      procs = {}

      txn.execute("""
                  SELECT id,
                         schema,
                         package,
                         procedure,
                         object_id,
                         subprogram_id,
                         return_type,
                         args_cnt,
                         arg_types,
                         arg_inouts,
                         uri,
                         authkeys
                    FROM endpoint
                  """)

      res = txn.fetchall()
      if res is not None:
         for r in res:
            id = r[0]
            schema = r[1]
            package = r[2]
            procedure = r[3]
            return_type = r[6]
            args_cnt = r[7]
            arg_types = r[8]
            arg_inouts = r[9]
            uri = r[10]
            authkeys = r[11]

            meta = DbProcedureMeta(remote.id,
                                   "%s.%s.%s" % (schema, package, procedure),
                                   args_cnt)
            meta.id = id
            meta.uri = uri
            meta.return_type = return_type
            meta.arg_types = arg_types
            meta.arg_inouts = arg_inouts
            meta.arg_sess_inout = None
            for i in xrange(len(meta.arg_types)):
               if meta.arg_types[i] == 'CROSSBAR_SESSION':
                  meta.arg_sess_inout = meta.arg_inouts[i]
                  break
            procs[uri] = meta

      return procs


   def _callSp(self, conn, call):
      """
      Call a remoted stored procedure.

      This is called using ConnectionPool.runWithConnection on the
      Twisted main thread from within DbRemoter.remoteCall.

      :param conn: A database connection from the pool.
      :type conn: obj
      :param session: Information on calling WAMP session.
      :type session: Instance of SessionInfo
      :param meta: SP metadata.
      :type meta: tuple
      :param args: SP calling arguments.
      :type args: list
      :return obj -- Result from calling the SP.
      """

      session = call.proto.sessionInfo
      meta = call.extra
      args = call.args

      import cx_Oracle

      ## http://docs.oracle.com/cd/B28359_01/server.111/b28318/datatype.htm
      ## http://docs.oracle.com/cd/B28359_01/appdev.111/b28370/datatypes.htm

      ## Supported:
      ##
      ##   cx_Oracle.NUMBER
      ##   cx_Oracle.NATIVE_FLOAT
      ##   cx_Oracle.STRING
      ##   cx_Oracle.UNICODE
      ##   cx_Oracle.FIXED_CHAR
      ##   cx_Oracle.FIXED_UNICODE
      ##   cx_Oracle.DATETIME
      ##   cx_Oracle.TIMESTAMP
      ##   cx_Oracle.INTERVAL
      ##   cx_Oracle.CURSOR
      ##
      ## Unsupported:
      ##
      ##   cx_Oracle.OBJECT
      ##   cx_Oracle.ROWID
      ##   cx_Oracle.BINARY
      ##   cx_Oracle.BFILE
      ##   cx_Oracle.LOB
      ##   cx_Oracle.BLOB
      ##   cx_Oracle.CLOB
      ##   cx_Oracle.NCLOB
      ##   cx_Oracle.LONG_BINARY
      ##   cx_Oracle.LONG_STRING
      ##   cx_Oracle.LONG_UNICODE

      ## Issues:
      ##
      ##  INTERVAL YEAR TO MONTH Support
      ##    Python datetime.timedelta only supports periods up to 1 day.
      ##    isodate has it's own Duration class to represent longer periods,
      ##    but such objects can't be consumed by cx_Oracle.
      ##


      ## map of endpoint.return_type / endpoint.arg_types to
      ##
      ##    (cx_Oracle bind var type, PL/SQL type, PL/SQL caster)
      ##
      ## for input parameters
      ##
      TYPEMAP = {'NUMBER': (cx_Oracle.NUMBER, None, None),
                 'VARCHAR2': (cx_Oracle.STRING, None, None),
                 'NVARCHAR2': (cx_Oracle.UNICODE, None, None),
                 'CHAR': (cx_Oracle.FIXED_CHAR, None, None),
                 'NCHAR': (cx_Oracle.FIXED_UNICODE, None, None),
                 'BINARY_FLOAT': (cx_Oracle.NATIVE_FLOAT, None, None),
                 'BINARY_DOUBLE': (cx_Oracle.NATIVE_FLOAT, None, None),
                 'DATE': (cx_Oracle.DATETIME, None, None),
                 'TIMESTAMP': (cx_Oracle.TIMESTAMP, None, None),
                 'TIMESTAMP WITH TIME ZONE': (cx_Oracle.TIMESTAMP, None, None),
                 'TIMESTAMP WITH LOCAL TIME ZONE': (cx_Oracle.TIMESTAMP, None, None),
                 'INTERVAL DAY TO SECOND': (cx_Oracle.INTERVAL, None, None),
                 #'INTERVAL YEAR TO MONTH': (cx_Oracle.INTERVAL, None, None),
                 'REF CURSOR': (cx_Oracle.CURSOR, None, None),
                 'JSON': (cx_Oracle.CLOB, 'json', 'json'),
                 'JSON_VALUE': (cx_Oracle.CLOB, 'json_value', 'json_parser.parse_any'),
                 'JSON_LIST': (cx_Oracle.CLOB, 'json_list', 'json_list'),
                 'CROSSBAR_SESSION': (None, 'crossbar_session', 'crossbar_session')}

      ## these object types are treated specially
      ##
      JSONTYPES = ['JSON',
                   'JSON_VALUE',
                   'JSON_LIST']

      DATETIMETYPES = ['DATE', 'TIMESTAMP']

      INTERVALTYPES = ['INTERVAL DAY TO SECOND',
                       #'INTERVAL YEAR TO MONTH',
                       ]

      ## create or get prepared cursor for calling SP
      ##
      cur, extra = conn.getPrepared(meta.uri)

      if not cur:
         ## construct SQL statement for calling SP
         ##

         ## input parameters
         ##
         arg_types = []
         if len(meta.arg_types) > 0:
            ## SP takes at least 1 input parameters
            ##
            iargs = []
            i = 0
            j = 0
            while i < len(meta.arg_types):
               if meta.arg_types[i] == 'CROSSBAR_SESSION':
                  if meta.arg_inouts[i] in ['IN', 'IN/OUT']:
                     iargs.append('l_sess')
                  else:
                     raise Exception("invalid direction %s for session object parameter" % meta.arg_sess_inout)
               else:
                  cast = TYPEMAP[meta.arg_types[i]][2]
                  if cast:
                     ## parameter value is casted
                     iargs.append('%s(:in%d)' % (cast, j))
                  else:
                     ## plain parameter
                     iargs.append(':in%d' % j)
                  arg_types.append(meta.arg_types[i])
                  j += 1
               i += 1
            s_args = "(" + ','.join(iargs) + ")"
         else:
            ## SP takes no input parameters
            ##
            s_args = ""

         ## return value
         ##
         if meta.return_type is not None:
            if meta.return_type not in JSONTYPES:
               s_out = ":out := "
            else:
               s_out = ""
         else:
            s_out = ""

         ## anonymous PL/SQL block
         ##
         ## For MODIFY_PACKAGE_STATE, see:
         ##   - http://stackoverflow.com/questions/12688317/clear-oracle-session-state
         ##   - http://docs.oracle.com/cd/E11882_01/appdev.112/e25788/d_sessio.htm#CEGIICCC
         ##
         if meta.return_type in JSONTYPES:
            ## for JSON types the SQL is different since we need to cast from
            ## JSON object type to CLOB
            if meta.arg_sess_inout == "IN/OUT":
               sql = """
                     DECLARE
                        l_sess   crossbar_session := crossbar_session(:so1, :so2, JSON(:so3));
                        l_out    %s;
                     BEGIN
                        DBMS_SESSION.MODIFY_PACKAGE_STATE(DBMS_SESSION.REINITIALIZE);
                        l_out := %s%s;
                        l_out.to_clob(:out);
                        l_sess.data.to_clob(:sout);
                     END;
                     """ % (TYPEMAP[meta.return_type][1], meta.procedure, s_args)
            elif meta.arg_sess_inout == "IN":
               sql = """
                     DECLARE
                        l_sess   crossbar_session := crossbar_session(:so1, :so2, JSON(:so3));
                        l_out    %s;
                     BEGIN
                        DBMS_SESSION.MODIFY_PACKAGE_STATE(DBMS_SESSION.REINITIALIZE);
                        l_out := %s%s;
                        l_out.to_clob(:out);
                     END;
                     """ % (TYPEMAP[meta.return_type][1], meta.procedure, s_args)
            else:
               sql = """
                     DECLARE
                        l_out   %s;
                     BEGIN
                        DBMS_SESSION.MODIFY_PACKAGE_STATE(DBMS_SESSION.REINITIALIZE);
                        l_out := %s%s;
                        l_out.to_clob(:out);
                     END;
                     """ % (TYPEMAP[meta.return_type][1], meta.procedure, s_args)
         else:
            if meta.arg_sess_inout == "IN/OUT":
               sql = """
                     DECLARE
                        l_sess   crossbar_session := crossbar_session(:so1, :so2, JSON(:so3));
                     BEGIN
                        DBMS_SESSION.MODIFY_PACKAGE_STATE(DBMS_SESSION.REINITIALIZE);
                        %s%s%s;
                        l_sess.data.to_clob(:sout);
                     END;
                     """ % (s_out, meta.procedure, s_args)
            elif meta.arg_sess_inout == "IN":
               sql = """
                     DECLARE
                        l_sess   crossbar_session := crossbar_session(:so1, :so2, JSON(:so3));
                     BEGIN
                        DBMS_SESSION.MODIFY_PACKAGE_STATE(DBMS_SESSION.REINITIALIZE);
                        %s%s%s;
                     END;
                     """ % (s_out, meta.procedure, s_args)
            else:
               sql = """
                     BEGIN
                        DBMS_SESSION.MODIFY_PACKAGE_STATE(DBMS_SESSION.REINITIALIZE);
                        %s%s%s;
                     END;
                     """ % (s_out, meta.procedure, s_args)

         ## create fresh cursor and prepare SQL
         ##
         cur = conn.cursor()
         cur.prepare(sql)

         ## map var types to cx_Oracle types
         ##
         if meta.return_type in JSONTYPES:
            ## when calling a SP that returns a JSON type, the return bind var
            ## is the last, since we need to cast from JSON to CLOB/STRING
            ##
            ttypes = arg_types + [meta.return_type]
         elif meta.return_type is not None:
            ## otherwise if the SP returns something, the return bind var
            ## is the first
            ##
            ttypes = [meta.return_type] + arg_types
         else:
            ## otherwise when the SP does not return anything, bind vars
            ## are just input parameters
            ##
            ttypes = arg_types

         if meta.arg_sess_inout:
            ttypes = ['VARCHAR2', 'VARCHAR2', 'JSON'] + ttypes
            if meta.arg_sess_inout == "IN/OUT":
               ttypes.append('JSON')

         atypes = [TYPEMAP[x][0] for x in ttypes]

         ## setup cx_Oracle bind vars
         curvars = cur.setinputsizes(*atypes)

         ## save the prepared cursor and bindvars. we also save the SQL
         ## for debugging purposes
         ##
         conn.savePrepared(meta.uri, cur, (curvars, sql))

      else:
         ## cursor was saved previously - get the bind vars ..
         ##
         curvars, sql = extra


      ## set parameters and call SP
      ##

      ## indexes 'args'
      i = 0

      ## indexes 'curvars'
      if meta.return_type in JSONTYPES:
         ## json return value (needs to be unwrapped via local PL/SQL var)
         j = 0
      elif meta.return_type is not None:
         ## scalar/refcursor return
         j = 1
      else:
         ## no return value
         j = 0


      ## inject session information
      ##
      if meta.arg_sess_inout:
         curvars[0].setvalue(0, session.sessionId)
         curvars[1].setvalue(0, session.authenticatedAs)
         curvars[2].setvalue(0, json_dumps(session.data))
         j += 3

      ## indexes 'meta.arg_types'
      k = 0

      while k < len(meta.arg_types):
         if meta.arg_types[k] == 'CROSSBAR_SESSION':
            k += 1

         else:
            if meta.arg_types[k] in JSONTYPES:
               val = json_dumps(args[i])

            elif meta.arg_types[k] in DATETIMETYPES:
               ## Target argument is a DATE/TIMESTAMP. Need to convert
               ## to Python datetime.datetime from string. We use ISO 8601 format.
               ##
               if args[i] is not None:
                  try:
                     val = isodate.parse_datetime(args[i])
                  except Exception, e:
                     raise Exception("invalid value for datetime/timestamp - expected a string in ISO 8601 datetime format [%s]" % e)
               else:
                  val = None

            elif meta.arg_types[k] in INTERVALTYPES:
               ## Target argument is a INTERVAL. Need to convert
               ## to Python datetime.timedelta from string. We use ISO 8601 format.
               ##
               if args[i] is not None:
                  try:
                     val = isodate.parse_duration(args[i])
                     if not isinstance(val, datetime.timedelta):
                        ## val will be an instance of isodate.Duration, due to
                        ## limits of Python datetime.timedelta
                        raise Exception("invalid value for literal - ISO 8601 years/months currently unsupported")
                  except Exception, e:
                     raise Exception("invalid value for interval - expected a string in ISO 8601 period format [%s]" % e)
               else:
                  val = None

            else:
               val = args[i]

            curvars[j].setvalue(0, val)
            j += 1
            k += 1
            i += 1


      ## initialize CLOBs for unwrapping
      if meta.arg_sess_inout == "IN/OUT":
         curvars[-1].setvalue(0, '')
         if meta.return_type in JSONTYPES:
            curvars[-2].setvalue(0, '')
      else:
         if meta.return_type in JSONTYPES:
            curvars[-1].setvalue(0, '')


      ## run SP
      try:
         if call.timings:
            call.timings.track("onBeforeRemoteCall")

         cur.execute(None)

         if call.timings:
            call.timings.track("onAfterRemoteCallReceiveSuccess")

      except cx_Oracle.DatabaseError, e:

         if call.timings:
            call.timings.track("onAfterRemoteCallError")

         error, = e.args
         code = error.code
         offset = error.offset
         message = error.message
         context = error.context

         ## handle crossbar.io application errors
         ##
         if code == 20999:

            ## extract crossbar.io application error payload
            ##
            try:
               lines = message.splitlines()
               fl = lines[0]
               i = fl.find(':') + 2
               s = fl[i:].strip()
               o = json_loads(s)
               rest = '\n'.join(lines[1:])
            except:
               o = {}
               rest = message

            if o.has_key('uri'):
               uri = o['uri']
            else:
               uri = URI_ERROR_SQL + ("%d" % code)

            if o.has_key('desc'):
               #m = "%s\n%s" % (o['desc'], rest)
               m = o['desc']
            else:
               m = rest

            if o.has_key('detail'):
               detail = o['detail']
            elif o.has_key('callstack'):
               detail = o['callstack'].splitlines()
            else:
               detail = None

            if o.has_key('kill'):
               kill = o['kill']
            else:
               kill = False

            raise Failure(Exception(uri, m, detail, kill))

         else:
            ## => produce generic SQL error
            ##
            raise Failure(Exception(URI_ERROR_SQL + ("%d" % code), message))

      except Exception, e:

         if call.timings:
            call.timings.track("onAfterRemoteCallError")

         ## => produce generic error
         ##
         raise Failure(Exception(URI_ERROR, str(e)))


      ## get result
      if meta.arg_sess_inout == "IN/OUT":
         sessRes = json_loads(curvars[-1].getvalue().read())
         session.data = sessRes

      if meta.return_type in JSONTYPES:
         ## result needs to be extracted from JSON value
         ##
         if meta.arg_sess_inout == "IN/OUT":
            res = json_loads(curvars[-2].getvalue().read())
         else:
            res = json_loads(curvars[-1].getvalue().read())

      else:
         if meta.arg_sess_inout:
            ri = 3
         else:
            ri = 0

         if meta.return_type == 'REF CURSOR':
            ## result is a REFCURSOR: get and read from it
            ##
            refcur = curvars[ri].getvalue()
            if refcur is not None:
               res = refcur.fetchall()
            else:
               res = None

         elif meta.return_type in DATETIMETYPES:
            ## Result is a Python datetime.datetime object
            ##
            ## Need to convert to string for later serialization to JSON. We use ISO 8601 format.
            ##
            ## Note: we do not use isodate module currently (as we do for parsing),
            ## since "time formating does not allow to create fractional representations"
            ##
            res = curvars[ri].getvalue()
            if res is not None:
               res = res.isoformat()

         elif meta.return_type in INTERVALTYPES:
            ## Result is a Python datetime.timedelta object
            ##
            ## Need to convert to string for later serialization to JSON. We use ISO 8601 format.
            ##
            res = curvars[ri].getvalue()
            if res is not None:
               res = isodate.duration_isoformat(res)

         elif meta.return_type is not None:
            ## result is a scalar value
            ##
            res = curvars[ri].getvalue()

         else:
            ## no return value (a procedure)
            ##
            res = None

      if call.timings:
         call.timings.track("onAfterRemoteCallSuccess")

      return res

########NEW FILE########
__FILENAME__ = oraschema
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


__all__ = ["getDatabaseInfo",
           "getCreateUsersScript",
           "getDropUsersScript",
           "LATESTVERSIONS"]

from twisted.python import log

import dbschema
import oraschemarepo
import oraschemademo

LATESTVERSIONS = {'repository': oraschemarepo.SCHEMAVERSION,
                  'demo': oraschemademo.SCHEMAVERSION}


def getDatabaseInfo(app, conn):
   """
   Get database information.
   """
   cur = conn.cursor()

   ## this information should be accessible by any user that can CONNECT
   ##
   cur.execute("""SELECT systimestamp AT TIME ZONE 'UTC',
                         (SELECT version FROM product_component_version WHERE product LIKE 'Oracle%' AND rownum < 2) AS product_version,
                         (SELECT * FROM v$version WHERE banner LIKE 'Oracle%' AND rownum < 2) AS product_version_str,
                         sys_context('USERENV', 'CURRENT_SCHEMA')
                  FROM dual""")

   rr = cur.fetchone()
   current_time = rr[0]
   version_str = str(rr[1]).strip()
   version = str(rr[2]).strip()
   current_schema = rr[3]

   ## the following seems to require "SELECT ANY DICTIONARY" grant
   ##
   try:
      cur.execute("SELECT startup_time FROM sys.v_$instance")
      rr = cur.fetchone()
      start_time = rr[0]
   except:
      start_time = None

   ## the following seems to require "SELECT ANY DICTIONARY" grant
   ##
   try:
      cur.execute("SELECT dbid FROM v$database")
      rr = cur.fetchone()
      sysuuid = str(rr[0]).strip()
   except:
      sysuuid = None

   dbinfo = {'current-schema': current_schema,
             # FIXME!!
             #'current-time': current_time,
             #'start-time': start_time,
             'current-time': None,
             'start-time': None,
             'version': version,
             'version-string': version_str,
             'uuid': sysuuid}

   schemainfo = dbschema.getSchemaVersion(conn, LATESTVERSIONS)

   return {'database': dbinfo, 'schema': schemainfo}


def getDropUsersScript(user, demoUser = None):
   script = """
BEGIN
   -- kick all sessions for crossbar.io Repository user
   --
   FOR r IN (SELECT s.sid, s.serial#
               FROM v$session s
              WHERE s.username = UPPER('%(user)s'))
   LOOP
      EXECUTE IMMEDIATE
         'ALTER SYSTEM KILL SESSION ''' || r.sid || ',' || r.serial# || '''';
   END LOOP;
END;
/

BEGIN
   -- drop public synonyms created by crossbar.io Repository user
   --
   FOR r IN (SELECT DISTINCT sname
               FROM synonyms
              WHERE creator = UPPER('%(user)s') AND syntype = 'PUBLIC')
   LOOP
      EXECUTE IMMEDIATE 'DROP PUBLIC SYNONYM ' || r.sname;
   END LOOP;
END;
/

DECLARE
   l_id   NUMBER;
BEGIN
   -- remove all pipes for crossbar.io Repository user
   --
   FOR r IN (SELECT name
               FROM v$db_pipes
              WHERE name LIKE UPPER('CROSSBAR#_%(user)s%%') ESCAPE '#')
   LOOP
      BEGIN
         l_id   := sys.DBMS_PIPE.remove_pipe (pipename => r.name);
      EXCEPTION
         WHEN OTHERS THEN
            NULL;
      END;
   END LOOP;
END;
/

BEGIN
   -- drop crossbar.io Repository user and all it's objects
   --
   EXECUTE IMMEDIATE 'DROP USER %(user)s CASCADE';
EXCEPTION WHEN OTHERS THEN
   NULL;
END;
/
""" % {'user': user.lower()}

   if demoUser is not None:
      script += """
BEGIN
   -- kick all sessions for crossbar.io Demo user
   --
   FOR r IN (SELECT s.sid, s.serial#
               FROM v$session s
              WHERE s.username = UPPER('%(user)s'))
   LOOP
      EXECUTE IMMEDIATE
         'ALTER SYSTEM KILL SESSION ''' || r.sid || ',' || r.serial# || '''';
   END LOOP;
END;
/

BEGIN
   -- drop crossbar.io Demo user and all it's objects
   --
   EXECUTE IMMEDIATE 'DROP USER %(user)s CASCADE';
EXCEPTION WHEN OTHERS THEN
   NULL;
END;
/
""" % {'user': demoUser.lower()}

   return script


def getCreateUsersScript(user,
                         password,
                         tablespace = 'users',
                         publicsyn = True,
                         demoUser = None,
                         demoPassword = None):
   """
   Generate DDL for setting up crossbar.io Connect repository user.

   :param user: Oracle user name.
   :type user: str
   :param password: Password for Oracle user.
   :type password: str
   :param tablespace: Default tablespace for Oracle user.
   :type tablespace: str
   :param publicsyn: Grant public synonym create/drop to user.
   :type publicsyn: bool
   :returns str -- User create DDL script.
   """
   script = """
--
-- Create crossbar.io Repository Schema
--
CREATE USER %(user)s IDENTIFIED BY %(password)s
/
ALTER USER %(user)s DEFAULT TABLESPACE %(tablespace)s QUOTA UNLIMITED ON %(tablespace)s
/

GRANT CREATE SESSION TO %(user)s
/
GRANT CREATE TABLE TO %(user)s
/
GRANT CREATE VIEW TO %(user)s
/
GRANT CREATE SEQUENCE TO %(user)s
/
GRANT CREATE TYPE TO %(user)s
/
GRANT CREATE PROCEDURE TO %(user)s
/
GRANT CREATE TRIGGER TO %(user)s
/

GRANT EXECUTE ON SYS.DBMS_PIPE TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_LOCK TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_SESSION TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_LOB TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_TYPES TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_STATS TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_SQL TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_UTILITY TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_XMLGEN TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_RANDOM TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_CRYPTO TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_OUTPUT TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_DB_VERSION TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_APPLICATION_INFO TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_AQADM TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_AQ TO %(user)s
/
""" % {'user': user.lower(),
       'password': password,
       'tablespace': tablespace.lower()}

   if publicsyn:
      script += """
GRANT CREATE PUBLIC SYNONYM TO %(user)s
/
GRANT DROP PUBLIC SYNONYM TO %(user)s
/
""" % {'user': user.lower()}


   if demoUser is not None and demoPassword is not None:
      script += """
--
-- Create crossbar.io Demo Schema
--
CREATE USER %(user)s IDENTIFIED BY %(password)s
/
ALTER USER %(user)s DEFAULT TABLESPACE %(tablespace)s QUOTA UNLIMITED ON %(tablespace)s
/

GRANT CREATE SESSION TO %(user)s
/
GRANT CREATE TABLE TO %(user)s
/
GRANT CREATE VIEW TO %(user)s
/
GRANT CREATE SEQUENCE TO %(user)s
/
GRANT CREATE PROCEDURE TO %(user)s
/
GRANT CREATE TRIGGER TO %(user)s
/

GRANT EXECUTE ON SYS.DBMS_STATS TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_RANDOM TO %(user)s
/
GRANT EXECUTE ON SYS.DBMS_OUTPUT TO %(user)s
/
""" % {'user': demoUser.lower(),
       'password': demoPassword,
       'tablespace': tablespace.lower()}

   return script

########NEW FILE########
__FILENAME__ = oraschemademo
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


__all__ = ["getSchemaVersion",
           "setupSchema",
           "reinstallSchema",
           "dropSchema",
           "upgradeSchema"]

import os

from twisted.python import log

from autobahn.wamp import json_loads, json_dumps

from autobahn.util import utcnow

import dbschema
import oraschema


SCHEMAVERSION = 13


def getSchemaVersion(app, conn):
   return dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)


def extractDDL(scriptdir, scriptfiles):
   tsql = []

   ## we need to split install files contents into individual SQL
   ## statements and clean away any SQLplus related stuff
   for fn in scriptfiles:
      try:
         f = open(os.path.join(scriptdir, fn), "rb")
         fc = f.read()
         block = 1
         sql = []
         for l in fc.splitlines():
            if l.lower().startswith("sho") or l.lower().startswith("set") or l.lower().startswith("exit"):
               pass
            elif l.startswith("/") and l.strip() == "/":
               s = '\n'.join(sql).strip()
               sql = []
               if len(s) > 0:
                  tsql.append((fn, block, s))
                  block += 1
            else:
               sql.append(l)
      except Exception, e:
         em = "Error while processing %s [%s]" % (fn, e)
         log.msg(em)
         raise Exception(em)

   return tsql


def executeDDL(cur, tsql):
   for fn, block, t in tsql:
      try:
         log.msg("executing %s block %d .." % (fn, block))
         cur.execute(t)
      except Exception, e:
         m = "error installing %s block %d (%s)" % (fn, block, e)
         log.msg(t)
         raise Exception(m)


def _setupSchema(app, conn, uninstallOnly = False):

   cf = os.path.join(app.webdata, "demo", "demo.json")
   try:
      cfo = json_loads(open(cf).read())
   except Exception, e:
      log.msg("Could not read Oracle demo schema spec [%s]" % e)
      raise e

   scriptdir = os.path.join(app.webdata, "demo")

   uninstalls = []
   installs = []
   for d in cfo["demos"].values():
      installs.extend(d["sqlInstall"])
      uninstalls.extend(d["sqlUninstall"])

   SCHEMAVERSION = cfo["version"]

   print scriptdir, installs, uninstalls, SCHEMAVERSION

   cur = conn.cursor()
   executeDDL(cur, extractDDL(scriptdir, uninstalls))

   TABLES = ['config']

   for o in TABLES:
      cur.execute("""
                  BEGIN
                     EXECUTE IMMEDIATE 'DROP TABLE %s';
                  EXCEPTION
                     WHEN OTHERS THEN
                        IF SQLCODE != -942 THEN
                           RAISE;
                        END IF;
                  END;
                  """ % o)
      log.msg("database table '%s' dropped" % o)

   if not uninstallOnly:

      executeDDL(cur, extractDDL(scriptdir, installs))

      ## CONFIG table
      ##
      cur.execute("""
                  CREATE TABLE config
                  (
                     key                 VARCHAR2(30)                     PRIMARY KEY,
                     value               VARCHAR2(4000)                   NOT NULL
                  )
                  """)
      log.msg("database table '%s' created" % "config")

      ## store database schema version
      ##
      config = [('schema-category', 'demo'),
                ('schema-version', SCHEMAVERSION),
                ('schema-created', utcnow())]
      for key, value in config:
         cur.execute("INSERT INTO config (key, value) VALUES (:1, :2)", [key, json_dumps(value)])
      conn.commit()

      log.msg("crossbar.io Demo schema created (version %d)!" % SCHEMAVERSION)

   else:

      log.msg("crossbar.io Demo schema dropped!")

   return dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)


def setupSchema(app, conn):
   r = dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)

   if r['schema-version'] is not None:
      raise Exception("crossbar.io Demo already installed")

   return _setupSchema(app, conn)


def reinstallSchema(app, conn):
   r = dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)

   if r['schema-version'] is None:
      raise Exception("crossbar.io Demo not installed")

   return _setupSchema(app, conn)


def dropSchema(app, conn):
   r = dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)

   if r['schema-version'] is None:
      raise Exception("crossbar.io Demo not installed")

   return _setupSchema(app, conn, uninstallOnly = True)


def upgradeSchema(app, conn):
   r = dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)

   if r['schema-version'] is None:
      raise Exception("crossbar.io Demo not installed")

   if not r['schema-needs-upgrade']:
      raise Exception("crossbar.io Demo needs no upgrade")

   return _setupSchema(app, conn)

########NEW FILE########
__FILENAME__ = oraschemarepo
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


__all__ = ["getSchemaVersion",
           "setupSchema",
           "reinstallSchema",
           "dropSchema",
           "upgradeSchema"]

import os
import pkg_resources

from twisted.python import log

from autobahn.util import utcnow
from autobahn.wamp import json_dumps

import dbschema
import oraschema


SCHEMAVERSION = 3


def getSchemaVersion(app, conn):
   return dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)


def _getPLJSONDDL(oracleMajorVersion, uninstallOnly = False):
   """
   Install PL/JSON from static files.

   Returns a list of 3-tuples (filename, blocknumber, sql), where there sql
   contains single SQL statements to be executed in list order.
   """
   ## root path to PL/JSON files from installed package
   root = pkg_resources.resource_filename("crossbar", "ddl/oracle/pljson")

   ## main install script. we parse this to get the list of individual files
   installfile = os.path.join(root, 'install.sql')

   installfiles = []

   if False:
      ## determine install files from parsing "install.sql"
      ##
      if uninstallOnly:
         files = ['uninstall.sql']
      else:
         files = ['uninstall.sql']
         for l in open(installfile).read().splitlines():
            if l.startswith('@@') and (not uninstallOnly or l.startswith('@@uninstall.sql')):
               i = l.find('--')
               if i > 0:
                  s = l[2:i]
               else:
                  s = l[2:]
               files.append(s.strip())
   else:
      ## manually create list of install files
      ##
      if uninstallOnly:
         files = ['uninstall.sql']
      else:
         files = ['uninstall.sql']
         files.extend(['json_value.sql',
                       'json_list.sql',
                       'json.sql',
                       'json_parser.sql',
                       'json_printer.sql',
                       'json_value_body.sql',
                       'json_ext.sql',
                       'json_body.sql',
                       'json_list_body.sql',
                       'json_ac.sql'])

         if oracleMajorVersion >= 11:
            files.append('addons/json_dyn_11g.sql')
         else:
            files.append('addons/json_dyn.sql')

         files.extend([#'addons/jsonml.sql',
                       #'addons/json_xml.sql',
                       #'addons/json_util_pkg.sql',
                       'addons/json_helper.sql'])

   for f in files:
      installfiles.append(os.path.join(root, f))

   tsql = []

   ## we need to split install files contents into individual SQL
   ## statements and clean away any SQLplus related stuff
   for fn in installfiles:
      try:
         f = open(fn, "rb")
         fc = f.read()
         block = 1
         sql = []
         for l in fc.splitlines():
            if l.startswith("sho") or l.startswith("set"):
               pass
            elif l.startswith("/") and l.strip() == "/":
               s = '\n'.join(sql).strip()
               sql = []
               if len(s) > 0:
                  tsql.append((fn, block, s))
                  block += 1
            else:
               sql.append(l)
      except Exception, e:
         em = "Error while processing %s [%s]" % (fn, e)
         log.msg(em)
         raise Exception(em)

   return tsql



def _setupSchema(conn,
                 grantedusers = ['public'],
                 publicsyn = True,
                 uninstallOnly = False):
   """
   Setup crossbar.io Connect repository.

   :param conn: A connected cx_Oracle connection.
   :type conn: cx_Oracle.Connection
   :param grantedusers: List of user granted access to crossbar.io.
   :type grantedusers: List of str.
   :param publicsyn: Create public synonyms for crossbar.io objects.
   :type publicsyn: bool
   :returns dict -- Repository information.
   """

   log.msg("(Re-)creating crossbar.io database connect repository ...")

   import cx_Oracle
   cur = conn.cursor()

   ## Session User
   ##
   cur.execute("SELECT sys_context('USERENV', 'SESSION_USER') FROM dual")
   session_user = cur.fetchone()[0]

   ## Oracle Version
   ##
   cur.execute("SELECT version FROM product_component_version WHERE product LIKE 'Oracle%' AND rownum < 2")
   dbversion = cur.fetchone()[0]
   oracleMajorVersion = int(dbversion.split('.')[0])

   ## Set PL/SQL optimization level
   ##
   ## Note: Check via user_stored_settings / all_stored_settings:
   ##
   ## SELECT *
   ##   FROM all_stored_settings
   ##  WHERE     owner = 'crossbar'
   ##        AND param_name = 'plsql_optimize_level'
   ##        AND object_type LIKE '%BODY'
   ##
   if oracleMajorVersion >= 11:
      log.msg("Setting PL/SQL optimization level 3 + native")
      cur.execute("ALTER SESSION SET PLSQL_OPTIMIZE_LEVEL = 3")
      cur.execute("ALTER SESSION SET plsql_code_type = 'NATIVE'")
   else:
      log.msg("Setting PL/SQL optimization level 2")
      cur.execute("ALTER SESSION SET PLSQL_OPTIMIZE_LEVEL = 2")

   ## The maximum column size allowed is 4000 characters when the
   ## national character set is UTF8 and 2000 when it is AL16UTF16.
   ##
   cur.execute("SELECT value FROM nls_database_parameters WHERE parameter = 'NLS_NCHAR_CHARACTERSET'")
   if cur.fetchone()[0] == 'AL16UTF16':
      nchar_maxlen = 2000
   else:
      nchar_maxlen = 4000

   log.msg("NCHAR MAXLEN = %d" % nchar_maxlen)

   ## (Re)install PL/JSON
   ##
   tsql = _getPLJSONDDL(oracleMajorVersion, uninstallOnly)
   for fn, block, t in tsql:
      try:
         log.msg("executing %s block %d .." % (fn, block))
         cur.execute(t)
      except Exception, e:
         m = "error installing %s block %d (%s)" % (fn, block, e)
         raise Exception(m)

   ## DBMS_PIPE based pipes
   ##
   ## Notes:
   ##   - pipe name are global for the instance
   ##   - v$db_pipes lists pipes, but needs extended privileges
   ##

   PIPE_ONPUBLISH = 'CROSSBAR_%s_ONPUBLISH' % session_user.upper()
   PIPE_ONEXPORT = 'CROSSBAR_%s_ONEXPORT' % session_user.upper()

   PLJSONOBJS = [# PL/JSON object types
                 'json',
                 'json_list',
                 'json_value',
                 'json_value_array',
                 # PL/JSON packages
                 'json_ext',
                 'json_parser',
                 'json_printer',
                 # addon packages
                 'json_ac',
                 'json_dyn',
                 'json_helper',
                 #'json_ml',
                 #'json_util_pkg',
                 #'json_xml',
                 ]

   PIPES = [PIPE_ONPUBLISH, PIPE_ONEXPORT]
   PACKAGES = ['crossbar']

   VIEWS = ['crossbar_event',
            'crossbar_endpoint']

   TABLES = ['config',
             'event',
             'endpoint']

   TYPES = ['crossbar_session',
            'crossbar_sessionids',
            'crossbar_authkeys',
            't_arg_types',
            't_arg_inouts']

   SEQUENCES = ['event_id',
                'endpoint_id']

   PUBSYNS = ['crossbar',
              'crossbar_event',
              'crossbar_endpoint',
              'crossbar_session',
              'crossbar_sessionids',
              'crossbar_authkeys']

   PUBSYNS.extend(PLJSONOBJS)

   USERGRANTS = [('EXECUTE', ['crossbar'] + TYPES + PLJSONOBJS),
                 ('SELECT', ['crossbar_event', 'crossbar_endpoint'])]

   if publicsyn or uninstallOnly:
      for o in PUBSYNS:
         try:
            cur.execute("""
                        BEGIN
                           EXECUTE IMMEDIATE 'DROP PUBLIC SYNONYM %s';
                        EXCEPTION
                           WHEN OTHERS THEN
                              IF SQLCODE != -1432 THEN
                                 RAISE;
                              END IF;
                        END;
                        """ % o)
            log.msg("public synonym '%s' dropped" % o)
         except:
            log.msg("warning: could not drop public synonym '%s'" % o)

   for p in PIPES:
      cur.execute("SELECT SYS.DBMS_PIPE.remove_pipe(pipename => :pipe) FROM dual", pipe = p)
      res = cur.fetchone()[0]
      if res != 0:
         raise Exception("could not remove pipe '%s' [%d]" % (p, res))
      else:
         log.msg("pipe %s removed" % p)

   for o in PACKAGES:
      cur.execute("""
                  BEGIN
                     EXECUTE IMMEDIATE 'DROP PACKAGE %s';
                  EXCEPTION
                     WHEN OTHERS THEN
                        IF SQLCODE != -4043 THEN
                           RAISE;
                        END IF;
                  END;
                  """ % o)
      log.msg("database package '%s' dropped" % o)

   for o in VIEWS:
      cur.execute("""
                  BEGIN
                     EXECUTE IMMEDIATE 'DROP VIEW %s';
                  EXCEPTION
                     WHEN OTHERS THEN
                        IF SQLCODE != -942 THEN
                           RAISE;
                        END IF;
                  END;
                  """ % o)
      log.msg("database view '%s' dropped" % o)

   for o in TABLES:
      cur.execute("""
                  BEGIN
                     EXECUTE IMMEDIATE 'DROP TABLE %s';
                  EXCEPTION
                     WHEN OTHERS THEN
                        IF SQLCODE != -942 THEN
                           RAISE;
                        END IF;
                  END;
                  """ % o)
      log.msg("database table '%s' dropped" % o)

   for o in SEQUENCES:
      cur.execute("""
                  BEGIN
                     EXECUTE IMMEDIATE 'DROP SEQUENCE %s';
                  EXCEPTION
                     WHEN OTHERS THEN
                        IF SQLCODE != -2289 THEN
                           RAISE;
                        END IF;
                  END;
                  """ % o)
      log.msg("database sequence '%s' dropped" % o)

   for o in TYPES:
      cur.execute("""
                  BEGIN
                     EXECUTE IMMEDIATE 'DROP TYPE %s FORCE';
                  EXCEPTION
                     WHEN OTHERS THEN
                        IF SQLCODE != -4043 THEN
                           RAISE;
                        END IF;
                  END;
                  """ % o)
      log.msg("database type '%s' dropped" % o)


   ## setup repository schema
   ##
   if not uninstallOnly:
      ## create TYPEs
      ##
      cur.execute("""
                  CREATE TYPE crossbar_sessionids IS TABLE OF VARCHAR2(16) NOT NULL
                  """)
      log.msg("database type '%s' created" % "crossbar_sessionids")

      cur.execute("""
                  CREATE TYPE crossbar_authkeys IS TABLE OF VARCHAR2(30)
                  """)
      log.msg("database type '%s' created" % "crossbar_authkeys")

      cur.execute("""
                  CREATE TYPE t_arg_types IS TABLE OF VARCHAR2(96)
                  """)
      log.msg("database type '%s' created" % "t_arg_types")

      cur.execute("""
                  CREATE TYPE t_arg_inouts IS TABLE OF VARCHAR2(9)
                  """)
      log.msg("database type '%s' created" % "t_arg_inouts")

      cur.execute("""
                  CREATE OR REPLACE TYPE crossbar_session AS OBJECT
                  (
                     sessionid   VARCHAR2(16),
                     authkey     VARCHAR2(30),
                     data        JSON
                  )
                  """)
      log.msg("database type '%s' created" % "crossbar_session")



      ## create SEQUENCEs
      ##
      for s in SEQUENCES:
         cur.execute("""
                     CREATE SEQUENCE %s
                     """ % s)
         log.msg("database sequence '%s' created" % s)


      ## CONFIG table
      ##
      cur.execute("""
                  CREATE TABLE config
                  (
                     key                 VARCHAR2(30)                     PRIMARY KEY,
                     value               VARCHAR2(4000)                   NOT NULL
                  )
                  """)
      log.msg("database table '%s' created" % "config")


      ## ENDPOINT table
      ##
      cur.execute("""
                  CREATE TABLE endpoint
                  (
                     id                  NUMBER(38)                       PRIMARY KEY,
                     created_at          TIMESTAMP                        NOT NULL,
                     created_by          VARCHAR2(30)                     NOT NULL,
                     modified_at         TIMESTAMP,
                     schema              VARCHAR2(30)                     NOT NULL,
                     package             VARCHAR2(30)                     NOT NULL,
                     procedure           VARCHAR2(30)                     NOT NULL,
                     object_id           NUMBER                           NOT NULL,
                     subprogram_id       NUMBER                           NOT NULL,
                     return_type         VARCHAR2(30),
                     args_cnt            NUMBER                           NOT NULL,
                     arg_types           t_arg_types,
                     arg_inouts          t_arg_inouts,
                     uri                 NVARCHAR2(%(nchar_maxlen)d)      NOT NULL,
                     authkeys            crossbar_authkeys
                  )
                  NESTED TABLE authkeys   STORE AS endpoint_authkeys
                  NESTED TABLE arg_types  STORE AS endpoint_arg_types
                  NESTED TABLE arg_inouts STORE AS endpoint_arg_inouts
                  """ % {'nchar_maxlen': nchar_maxlen})
      log.msg("database table '%s' created" % "endpoint")

      cur.execute("""
                  CREATE UNIQUE INDEX idx_endpoint1 ON endpoint (uri)
                  """)


      ## EVENT table
      ##
      cur.execute("""
                  CREATE TABLE event
                  (
                     id                  NUMBER(38)                       PRIMARY KEY,
                     published_at        TIMESTAMP                        NOT NULL,
                     published_by        VARCHAR2(30)                     NOT NULL,
                     processed_at        TIMESTAMP,
                     processed_status    INT,
                     processed_len       NUMBER(38),
                     processed_errmsg    VARCHAR2(4000),
                     dispatch_status     INT,
                     dispatch_success    NUMBER(38),
                     dispatch_failed     NUMBER(38),
                     topic               NVARCHAR2(%(nchar_maxlen)d)      NOT NULL,
                     qos                 INT                              NOT NULL,
                     payload_type        INT                              NOT NULL,
                     payload_str         NVARCHAR2(%(nchar_maxlen)d),
                     payload_lob         NCLOB,
                     exclude_sids        crossbar_sessionids,
                     eligible_sids       crossbar_sessionids
                  )
                  NESTED TABLE exclude_sids  STORE AS event_exclude_sids
                  NESTED TABLE eligible_sids STORE AS event_eligible_sids
                  """ % {'nchar_maxlen': nchar_maxlen})

      cur.execute("""
                  ALTER TABLE event ADD CONSTRAINT cstr_event_payload_type CHECK (payload_type IN (1, 2)) ENABLE
                  """)

      cur.execute("""
                  ALTER TABLE event ADD CONSTRAINT cstr_event_qos CHECK (qos IN (1)) ENABLE
                  """)

      cur.execute("""
                  ALTER TABLE event ADD CONSTRAINT cstr_event_processed_status CHECK (processed_status IN (0, 1, 2, 3, 4, 5)) ENABLE
                  """)

      cur.execute("""
                  ALTER TABLE event ADD CONSTRAINT cstr_event_dispatch_status CHECK (dispatch_status IN (0, 1)) ENABLE
                  """)

      cur.execute("""
                  CREATE INDEX idx_event1 ON event (published_by, published_at)
                  """)

      log.msg("database table '%s' created" % "event")


      ## views
      ##
      cur.execute("""
                  CREATE VIEW crossbar_event
                  AS
                  SELECT * FROM event
                  WHERE published_by = sys_context('USERENV', 'SESSION_USER')
                  """)
      log.msg("database view '%s' created" % "crossbar_event")

      cur.execute("""
                  CREATE VIEW crossbar_endpoint
                  AS
                  SELECT * FROM endpoint
                  WHERE created_by = sys_context('USERENV', 'SESSION_USER')
                  """)
      log.msg("database view '%s' created" % "crossbar_endpoint")


      ## pipes
      ##
      for p in PIPES:
         res = cur.callfunc("SYS.DBMS_PIPE.create_pipe", cx_Oracle.NUMBER, [], {'pipename': p, 'private': True, 'maxpipesize': 64 * 8192})
         if res != 0:
            raise Exception("could not create pipe '%s' [%d]" % (p, res))
         else:
            log.msg("pipe %s created" % p)


      ## packages
      ##
      cur.execute("""
CREATE OR REPLACE PACKAGE crossbar
AS
   /**
    * crossbar.io Oracle PL/SQL API.
    *
    * Copyright (C) 2011-2013 Tavendo GmbH.
    * Licensed under Apache 2.0 license (http://www.apache.org/licenses/LICENSE-2.0.html)
    *
    * Publish & Subscribe:
    *
    *   The package provides functions to publish events to crossbar.io from within
    *   Oracle which are dispatched to any clients subscribed and authorized
    *   to receive events on the respective topic.
    *
    * Remote Procedure Calls:
    *
    *   The package provides functions to export Oracle stored procedures which
    *   then can be called by clients authorized to do so. crossbar.io will forward
    *   client calls to stored procedure invocations.
    */

   /**
    * Event payload type is plain string.
    */
   PAYLOAD_TYPE_STRING   CONSTANT INTEGER := 1;

   /**
    * Event payload type is JSON.
    */
   PAYLOAD_TYPE_JSON     CONSTANT INTEGER := 2;

   /**
    * Event delivery quality-of-service is "best-effort".
    *
    * Any subscriber currently subscribed on the topic the event was
    * published to SHOULD receive the event once. However, there is
    * no strict guarantee for this to happen: the event may be delivered
    * once, more than once, or get lost completely.
    */
   QOS_BEST_EFFORT       CONSTANT INTEGER := 1;


   /**
    * crossbar.io repository user.
    */
   REPOUSER              CONSTANT VARCHAR2(30) := sys_context('USERENV', 'CURRENT_SCHEMA');


   /**
    * Publish event without payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    * @return                  Event ID.
    */
   FUNCTION publish(p_topic     IN NVARCHAR2,
                    p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                    p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                    p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT) RETURN NUMBER;

   /**
    * Publish event without payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    */
   PROCEDURE publish(p_topic     IN NVARCHAR2,
                     p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                     p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                     p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT);

   /**
    * Publish event with plain string payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_payload         Event payload.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    * @return                  Event ID.
    */
   FUNCTION publish(p_topic     IN NVARCHAR2,
                    p_payload   IN NVARCHAR2,
                    p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                    p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                    p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT) RETURN NUMBER;

   /**
    * Publish event with plain string payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_payload         Event payload.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    */
   PROCEDURE publish(p_topic     IN NVARCHAR2,
                     p_payload   IN NVARCHAR2,
                     p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                     p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                     p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT);

   /**
    * Publish event with large string payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_payload         Event payload.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    * @return                  Event ID.
    */
   FUNCTION publish(p_topic     IN NVARCHAR2,
                    p_payload   IN NCLOB,
                    p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                    p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                    p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT) RETURN NUMBER;

   /**
    * Publish event with large string payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_payload         Event payload.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    */
   PROCEDURE publish(p_topic     IN NVARCHAR2,
                     p_payload   IN NCLOB,
                     p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                     p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                     p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT);

   /**
    * Publish event with JSON (value) payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_payload         Event payload.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    * @return                  Event ID.
    */
   FUNCTION publish(p_topic     IN NVARCHAR2,
                    p_payload   IN JSON_VALUE,
                    p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                    p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                    p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT) RETURN NUMBER;

   /**
    * Publish event with JSON (value) payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_payload         Event payload.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    */
   PROCEDURE publish(p_topic     IN NVARCHAR2,
                     p_payload   IN JSON_VALUE,
                     p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                     p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                     p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT);

   /**
    * Publish event with JSON (object) payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_payload         Event payload.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    * @return                  Event ID.
    */
   FUNCTION publish(p_topic     IN NVARCHAR2,
                    p_payload   IN JSON,
                    p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                    p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                    p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT) RETURN NUMBER;

   /**
    * Publish event with JSON (object) payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_payload         Event payload.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    */
   PROCEDURE publish(p_topic     IN NVARCHAR2,
                     p_payload   IN JSON,
                     p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                     p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                     p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT);

   /**
    * Publish event with JSON (list) payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_payload         Event payload.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    * @return                  Event ID.
    */
   FUNCTION publish(p_topic     IN NVARCHAR2,
                    p_payload   IN JSON_LIST,
                    p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                    p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                    p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT) RETURN NUMBER;

   /**
    * Publish event with JSON (list) payload to topic.
    *
    * @param p_topic           URI of topic to publish to.
    * @param p_payload         Event payload.
    * @param p_exclude         If present, exclude this list of WAMP session IDs from receivers.
    * @param p_eligible        If present, only this list of WAMP session IDs is eligible for receiving.
    * @param p_qos             Quality-of-Service for event delivery.
    */
   PROCEDURE publish(p_topic     IN NVARCHAR2,
                     p_payload   IN JSON_LIST,
                     p_exclude   IN crossbar_sessionids   DEFAULT NULL,
                     p_eligible  IN crossbar_sessionids   DEFAULT NULL,
                     p_qos       IN INTEGER            DEFAULT QOS_BEST_EFFORT);

   /**
    * Export a stored procedure or function for RPC.
    *
    * You may export a given stored procedure under different endpoint URIs,
    * but there can only be at most one export per given URI.
    *
    * @param p_schema           Schema (owner) of stored procedure to be exported.
    * @param p_package          Package containing stored procedure to be exported.
    * @param p_proc             Procedure within package to be exported.
    * @param p_uri              URI under which the endpoint will be reachable via WAMP RPC.
    * @param p_authkeys         List of authentication keys that may access this endpoint.
    * @return                   Endpoint ID.
    */
   FUNCTION export(p_schema    IN VARCHAR2,
                   p_package   IN VARCHAR2,
                   p_proc      IN VARCHAR2,
                   p_endpoint  IN NVARCHAR2,
                   p_authkeys  IN crossbar_authkeys      DEFAULT NULL) RETURN NUMBER;


   /**
    * Export a stored procedure or function for RPC.
    *
    * Convenience shortcut procedure.
    */
   PROCEDURE export(p_package   IN VARCHAR2,
                    p_proc      IN VARCHAR2,
                    p_endpoint  IN NVARCHAR2,
                    p_authkeys  IN crossbar_authkeys      DEFAULT NULL);

   /**
    * Delete existing RPC export of a stored procedure. To delete an export,
    * you need to be the owner (= original creator) of the exported endpoint.
    *
    * @param p_endpoint_id     ID of endpoint as returned from creating the export.
    */
   PROCEDURE remove_export(p_endpoint_id   IN NUMBER);

   /**
    * Delete all existing RPC exports for the given schema/package/procedure.
    * You must be owner (= original creator) of _all_ exported endpoints for
    * this to succeed.
    *
    * @param p_schema          Schema name of exported procedures to delete or NULL for current schema.
    * @param p_package         Package name of exported procedures to delete or NULL for any package.
    * @param p_proc            Procedure name of exported procedures to delete or NULL for any procedure.
    * @return                  Number of exported endpoints deleted.
    */
   FUNCTION remove_exports(p_schema    IN VARCHAR2,
                           p_package   IN VARCHAR2,
                           p_proc      IN VARCHAR2) RETURN NUMBER;

   /**
    * Delete all existing RPC exports for the given schema/package/procedure.
    * You must be owner (= original creator) of _all_ exported endpoints for
    * this to succeed.
    *
    * @param p_schema          Schema name of exported procedures to delete or NULL for current schema.
    * @param p_package         Package name of exported procedures to delete or NULL for any package.
    * @param p_proc            Procedure name of exported procedures to delete or NULL for any procedure.
    */
   PROCEDURE remove_exports(p_schema    IN VARCHAR2,
                            p_package   IN VARCHAR2,
                            p_proc      IN VARCHAR2 DEFAULT NULL);

   /**
    * Delete all existing RPC exports for the given package/procedure within the current schema.
    * You must be owner (= original creator) of _all_ exported endpoints for
    * this to succeed.
    *
    * @param p_package         Package name of exported procedures to delete or NULL for any package.
    * @param p_proc            Procedure name of exported procedures to delete or NULL for any procedure.
    */
   PROCEDURE remove_exports(p_package   IN VARCHAR2,
                            p_proc      IN VARCHAR2 DEFAULT NULL);

   /**
    * Delete all existing RPC exports for stored procedures exported
    * under given URI pattern. The pattern is applied via a WHERE .. LIKE ..
    * expression. You must be owner (= original creator) of _all_ exported
    * endpoints for this to succeed.
    *
    * @param p_uri             URI of exported endpoints to delete.
    * @return                  Number of exported endpoints deleted.
    */
   FUNCTION remove_exports_by_uri(p_uri_pattern   IN NVARCHAR2) RETURN NUMBER;

   /**
    * Delete all existing RPC exports for stored procedures exported
    * under given URI pattern. The pattern is applied via a WHERE .. LIKE ..
    * expression. You must be owner (= original creator) of _all_ exported
    * endpoints for this to succeed.
    *
    * @param p_uri             URI of exported endpoints to delete.
    */
   PROCEDURE remove_exports_by_uri(p_uri_pattern   IN NVARCHAR2);

   /**
    * Raise application level exception. The WAMP client session will receive
    * an RPC error return.
    *
    * @param p_uri             Application error URI that identifies the error.
    * @param p_desc            Error description (for development/logging).
    * @param p_kill_session    Iff true, close the client's WAMP session (after sending the error).
    */
   PROCEDURE raise (p_uri             IN VARCHAR2,
                    p_desc            IN VARCHAR2,
                    p_kill_session    IN BOOLEAN DEFAULT FALSE);

   /**
    * Raise application level exception. The WAMP client session will receive
    * an RPC error return.
    *
    * @param p_uri             Application error URI that identifies the error.
    * @param p_desc            Error description (for development/logging).
    * @param p_detail          Optional application error details.
    * @param p_kill_session    Iff true, close the client's WAMP session (after sending the error).
    */
   PROCEDURE raise (p_uri             IN VARCHAR2,
                    p_desc            IN VARCHAR2,
                    p_detail          IN JSON_VALUE,
                    p_kill_session    IN BOOLEAN DEFAULT FALSE);

   /**
    * Raise application level exception. The WAMP client session will receive
    * an RPC error return.
    *
    * @param p_uri             Application error URI that identifies the error.
    * @param p_desc            Error description (for development/logging).
    * @param p_detail          Optional application error details.
    * @param p_kill_session    Iff true, close the client's WAMP session (after sending the error).
    */
   PROCEDURE raise (p_uri             IN VARCHAR2,
                    p_desc            IN VARCHAR2,
                    p_detail          IN JSON,
                    p_kill_session    IN BOOLEAN DEFAULT FALSE);

   /**
    * Raise application level exception. The WAMP client session will receive
    * an RPC error return.
    *
    * @param p_uri             Application error URI that identifies the error.
    * @param p_desc            Error description (for development/logging).
    * @param p_detail          Optional application error details.
    * @param p_kill_session    Iff true, close the client's WAMP session (after sending the error).
    */
   PROCEDURE raise (p_uri             IN VARCHAR2,
                    p_desc            IN VARCHAR2,
                    p_detail          IN JSON_LIST,
                    p_kill_session    IN BOOLEAN DEFAULT FALSE);

END crossbar;""")

      cur.execute("""
CREATE OR REPLACE PACKAGE BODY crossbar
AS
   FUNCTION dopublish(p_topic         NVARCHAR2,
                      p_payload_type  INTEGER,
                      p_payload_str   NVARCHAR2,
                      p_payload_lob   NCLOB,
                      p_exclude       crossbar_sessionids,
                      p_eligible      crossbar_sessionids,
                      p_qos           INTEGER) RETURN NUMBER
   AS
      l_now    TIMESTAMP;
      l_user   VARCHAR2(30);
      l_id     NUMBER(38);
      l_status NUMBER;
   BEGIN
      --
      -- check args
      --
      IF p_qos NOT IN (QOS_BEST_EFFORT) THEN
         RAISE_APPLICATION_ERROR(-20001, 'illegal QoS mode ' || p_qos);
      END IF;

      --
      -- event metadata
      --
      SELECT systimestamp at time zone 'utc',
             sys_context('USERENV', 'SESSION_USER'),
             event_id.nextval
         INTO
             l_now,
             l_user,
             l_id
         FROM dual;

      -- persist event
      --
      INSERT INTO event (id, published_at, published_by, topic, qos, payload_type, payload_str, payload_lob, exclude_sids, eligible_sids)
         VALUES
            (l_id, l_now, l_user, p_topic, p_qos, p_payload_type, p_payload_str, p_payload_lob, p_exclude, p_eligible);

      -- notify pipe
      --
      DBMS_PIPE.pack_message(l_id);
      l_status := DBMS_PIPE.send_message('%(PIPE_ONPUBLISH)s');

      -- commit and return event ID on success
      --
      IF l_status != 0 THEN
         ROLLBACK;
         RAISE_APPLICATION_ERROR(-20001, 'could not pipe event');
      ELSE
         COMMIT;
         RETURN l_id;
      END IF;
   END dopublish;


   FUNCTION publish(p_topic      NVARCHAR2,
                    p_exclude    crossbar_sessionids,
                    p_eligible   crossbar_sessionids,
                    p_qos        INTEGER) RETURN NUMBER
   AS
      PRAGMA AUTONOMOUS_TRANSACTION;
   BEGIN
      RETURN dopublish(p_topic, PAYLOAD_TYPE_STRING, NULL, NULL, p_exclude, p_eligible, p_qos);
   END publish;


   PROCEDURE publish(p_topic      NVARCHAR2,
                     p_exclude    crossbar_sessionids,
                     p_eligible   crossbar_sessionids,
                     p_qos        INTEGER)
   AS
      l_id     NUMBER;
   BEGIN
      l_id := publish(p_topic, p_exclude, p_eligible, p_qos);
   END publish;


   FUNCTION publish(p_topic      NVARCHAR2,
                    p_payload    NVARCHAR2,
                    p_exclude    crossbar_sessionids,
                    p_eligible   crossbar_sessionids,
                    p_qos        INTEGER) RETURN NUMBER
   AS
      PRAGMA AUTONOMOUS_TRANSACTION;
   BEGIN
      RETURN dopublish(p_topic, PAYLOAD_TYPE_STRING, p_payload, NULL, p_exclude, p_eligible, p_qos);
   END publish;


   PROCEDURE publish(p_topic      NVARCHAR2,
                     p_payload    NVARCHAR2,
                     p_exclude    crossbar_sessionids,
                     p_eligible   crossbar_sessionids,
                     p_qos        INTEGER)
   AS
      l_id     NUMBER;
   BEGIN
      l_id := publish(p_topic, p_payload, p_exclude, p_eligible, p_qos);
   END publish;


   FUNCTION publish(p_topic      NVARCHAR2,
                    p_payload    NCLOB,
                    p_exclude    crossbar_sessionids,
                    p_eligible   crossbar_sessionids,
                    p_qos        INTEGER) RETURN NUMBER
   AS
      PRAGMA AUTONOMOUS_TRANSACTION;
   BEGIN
      RETURN dopublish(p_topic, PAYLOAD_TYPE_STRING, NULL, p_payload, p_exclude, p_eligible, p_qos);
   END publish;


   PROCEDURE publish(p_topic      NVARCHAR2,
                     p_payload    NCLOB,
                     p_exclude    crossbar_sessionids,
                     p_eligible   crossbar_sessionids,
                     p_qos        INTEGER)
   AS
      l_id     NUMBER;
   BEGIN
      l_id := publish(p_topic, p_payload, p_exclude, p_eligible, p_qos);
   END publish;


   FUNCTION publish(p_topic      NVARCHAR2,
                    p_payload    JSON_VALUE,
                    p_exclude    crossbar_sessionids,
                    p_eligible   crossbar_sessionids,
                    p_qos        INTEGER) RETURN NUMBER
   AS
      PRAGMA AUTONOMOUS_TRANSACTION;

      l_id     NUMBER;
      l_lob    CLOB;
      l_str    VARCHAR2(4000);
   BEGIN
      BEGIN
         -- try serializing into VARCHAR2 with target column length limit
         --
         l_str := p_payload.to_char();
         l_id := dopublish(p_topic, PAYLOAD_TYPE_JSON, l_str, NULL, p_exclude, p_eligible, p_qos);
      EXCEPTION WHEN OTHERS THEN
         --
         -- if serialization is too long for VARCHAR2, try again using LOB
         --
         DBMS_LOB.createtemporary(lob_loc => l_lob,
                                  cache => true,
                                  dur => DBMS_LOB.call);
         p_payload.to_clob(l_lob);
         l_id := dopublish(p_topic, PAYLOAD_TYPE_JSON, NULL, l_lob, p_exclude, p_eligible, p_qos);
         DBMS_LOB.freetemporary(l_lob);
      END;
      RETURN l_id;
   END publish;


   PROCEDURE publish(p_topic      NVARCHAR2,
                     p_payload    JSON_VALUE,
                     p_exclude    crossbar_sessionids,
                     p_eligible   crossbar_sessionids,
                     p_qos        INTEGER)
   AS
      l_id     NUMBER;
   BEGIN
      l_id := publish(p_topic, p_payload, p_exclude, p_eligible, p_qos);
   END publish;


   FUNCTION publish(p_topic      NVARCHAR2,
                    p_payload    JSON,
                    p_exclude    crossbar_sessionids,
                    p_eligible   crossbar_sessionids,
                    p_qos        INTEGER) RETURN NUMBER
   AS
      PRAGMA AUTONOMOUS_TRANSACTION;

      l_id     NUMBER;
      l_lob    CLOB;
      l_str    VARCHAR2(4000);
   BEGIN
      BEGIN
         -- try serializing into VARCHAR2 with target column length limit
         --
         l_str := p_payload.to_char();
         l_id := dopublish(p_topic, PAYLOAD_TYPE_JSON, l_str, NULL, p_exclude, p_eligible, p_qos);
      EXCEPTION WHEN OTHERS THEN
         --
         -- if serialization is too long for VARCHAR2, try again using LOB
         --
         DBMS_LOB.createtemporary(lob_loc => l_lob,
                                  cache => true,
                                  dur => DBMS_LOB.call);
         p_payload.to_clob(l_lob);
         l_id := dopublish(p_topic, PAYLOAD_TYPE_JSON, NULL, l_lob, p_exclude, p_eligible, p_qos);
         DBMS_LOB.freetemporary(l_lob);
      END;
      RETURN l_id;
   END publish;


   PROCEDURE publish(p_topic      NVARCHAR2,
                     p_payload    JSON,
                     p_exclude    crossbar_sessionids,
                     p_eligible   crossbar_sessionids,
                     p_qos        INTEGER)
   AS
      l_id     NUMBER;
   BEGIN
      l_id := publish(p_topic, p_payload, p_exclude, p_eligible, p_qos);
   END publish;


   FUNCTION publish(p_topic      NVARCHAR2,
                    p_payload    JSON_LIST,
                    p_exclude    crossbar_sessionids,
                    p_eligible   crossbar_sessionids,
                    p_qos        INTEGER) RETURN NUMBER
   AS
      PRAGMA AUTONOMOUS_TRANSACTION;

      l_id     NUMBER;
      l_lob    CLOB;
      l_str    VARCHAR2(4000);
   BEGIN
      BEGIN
         -- try serializing into VARCHAR2 with target column length limit
         --
         l_str := p_payload.to_char();
         l_id := dopublish(p_topic, PAYLOAD_TYPE_JSON, l_str, NULL, p_exclude, p_eligible, p_qos);
      EXCEPTION WHEN OTHERS THEN
         --
         -- if serialization is too long for VARCHAR2, try again using LOB
         --
         DBMS_LOB.createtemporary(lob_loc => l_lob,
                                  cache => true,
                                  dur => DBMS_LOB.call);
         p_payload.to_clob(l_lob);
         l_id := dopublish(p_topic, PAYLOAD_TYPE_JSON, NULL, l_lob, p_exclude, p_eligible, p_qos);
         DBMS_LOB.freetemporary(l_lob);
      END;
      RETURN l_id;
   END publish;


   PROCEDURE publish(p_topic      NVARCHAR2,
                     p_payload    JSON_LIST,
                     p_exclude    crossbar_sessionids,
                     p_eligible   crossbar_sessionids,
                     p_qos        INTEGER)
   AS
      l_id     NUMBER;
   BEGIN
      l_id := publish(p_topic, p_payload, p_exclude, p_eligible, p_qos);
   END publish;


   PROCEDURE remove_export(p_endpoint_id   IN NUMBER)
   AS
      PRAGMA AUTONOMOUS_TRANSACTION;

      l_now              TIMESTAMP;
      l_created_by       VARCHAR2(30);
      l_user             VARCHAR2(30);
      l_id               NUMBER(38);
      l_status           NUMBER;
   BEGIN
      --
      -- get current time / user
      --
      SELECT systimestamp at time zone 'utc',
             sys_context('USERENV', 'SESSION_USER')
         INTO
             l_now,
             l_user
         FROM dual;

      BEGIN
         SELECT created_by INTO l_created_by FROM endpoint WHERE id = p_endpoint_id;
      EXCEPTION WHEN NO_DATA_FOUND THEN
         RAISE_APPLICATION_ERROR(-20001, 'no endpoint with ID ' || p_endpoint_id);
      END;

      IF l_created_by != l_user THEN
         RAISE_APPLICATION_ERROR(-20001, 'not allowed to delete export with ID ' || p_endpoint_id || ' (not owner)');
      END IF;

      DELETE FROM endpoint WHERE id = p_endpoint_id;
      COMMIT;

      -- notify pipe
      --
      DBMS_PIPE.pack_message(p_endpoint_id);
      l_status := DBMS_PIPE.send_message('%(PIPE_ONEXPORT)s');

   END remove_export;


   FUNCTION remove_exports(p_schema    IN VARCHAR2,
                           p_package   IN VARCHAR2,
                           p_proc      IN VARCHAR2) RETURN NUMBER
   AS
      PRAGMA AUTONOMOUS_TRANSACTION;

      l_cnt              NUMBER;
      l_now              TIMESTAMP;
      l_created_by       VARCHAR2(30);
      l_user             VARCHAR2(30);
      l_id               NUMBER(38);
      l_status           NUMBER;

      l_schema           VARCHAR2(30);
      l_package          VARCHAR2(30);
      l_proc             VARCHAR2(30);
   BEGIN
      --
      -- determine schema of remoted package procedure
      --
      IF p_schema IS NOT NULL THEN
         l_schema := UPPER(SUBSTR(p_schema, 1, 30));
      ELSE
         l_schema := sys_context('USERENV', 'SESSION_USER');
      END IF;

      IF p_package IS NOT NULL THEN
         l_package := UPPER(SUBSTR(p_package, 1, 30));
      ELSE
         l_package := NULL;
      END IF;

      IF p_proc IS NOT NULL THEN
         l_proc := UPPER(SUBSTR(p_proc, 1, 30));
      ELSE
         l_proc := NULL;
      END IF;

      --
      -- get current time / user
      --
      SELECT systimestamp at time zone 'utc',
             sys_context('USERENV', 'SESSION_USER')
         INTO
             l_now,
             l_user
         FROM dual;

      SELECT COUNT(*) INTO l_cnt FROM endpoint e
         WHERE
            schema = l_schema AND
            package = NVL(l_package, e.package) AND
            procedure = NVL(l_proc, e.procedure) AND
            created_by != l_user;

      IF l_cnt > 0 THEN
         RAISE_APPLICATION_ERROR(-20001, 'cannot delete exports - ' || l_cnt || ' exported endpoint(s) not owned by current user');
      END IF;

      l_cnt := 0;
      FOR r IN (SELECT id FROM endpoint e
                   WHERE
                      schema = l_schema AND
                      package = NVL(l_package, e.package) AND
                      procedure = NVL(l_proc, e.procedure) AND
                      created_by = l_user)
      LOOP
         DELETE FROM endpoint WHERE id = r.id;
         COMMIT;
         DBMS_PIPE.pack_message(r.id);
         l_status := DBMS_PIPE.send_message('%(PIPE_ONEXPORT)s');
         l_cnt := l_cnt + 1;
      END LOOP;

      RETURN l_cnt;

   END remove_exports;


   PROCEDURE remove_exports(p_schema    IN VARCHAR2,
                            p_package   IN VARCHAR2,
                            p_proc      IN VARCHAR2)
   IS
      l_cnt       NUMBER;
   BEGIN
      l_cnt := remove_exports(p_schema, p_package, p_proc);
   END remove_exports;


   PROCEDURE remove_exports(p_package   IN VARCHAR2,
                            p_proc      IN VARCHAR2)
   IS
      l_cnt       NUMBER;
   BEGIN
      l_cnt := remove_exports(NULL, p_package, p_proc);
   END remove_exports;


   FUNCTION remove_exports_by_uri(p_uri_pattern   IN NVARCHAR2) RETURN NUMBER
   AS
      PRAGMA AUTONOMOUS_TRANSACTION;

      l_cnt              NUMBER;
      l_now              TIMESTAMP;
      l_created_by       VARCHAR2(30);
      l_user             VARCHAR2(30);
      l_id               NUMBER(38);
      l_status           NUMBER;
   BEGIN
      --
      -- get current time / user
      --
      SELECT systimestamp at time zone 'utc',
             sys_context('USERENV', 'SESSION_USER')
         INTO
             l_now,
             l_user
         FROM dual;

      SELECT COUNT(*) INTO l_cnt FROM endpoint WHERE uri LIKE p_uri_pattern AND created_by != l_user;
      IF l_cnt > 0 THEN
         RAISE_APPLICATION_ERROR(-20001, 'cannot delete exports - ' || l_cnt || ' exported endpoint(s) not owned by current user');
      END IF;

      l_cnt := 0;
      FOR r IN (SELECT id FROM endpoint WHERE uri LIKE p_uri_pattern AND created_by = l_user)
      LOOP
         DELETE FROM endpoint WHERE id = r.id;
         COMMIT;
         DBMS_PIPE.pack_message(r.id);
         l_status := DBMS_PIPE.send_message('%(PIPE_ONEXPORT)s');
         l_cnt := l_cnt + 1;
      END LOOP;

      RETURN l_cnt;

   END remove_exports_by_uri;


   PROCEDURE remove_exports_by_uri(p_uri_pattern   IN NVARCHAR2)
   IS
      l_cnt       NUMBER;
   BEGIN
      l_cnt := remove_exports_by_uri(p_uri_pattern);
   END remove_exports_by_uri;


   FUNCTION export (p_schema      VARCHAR2,
                    p_package     VARCHAR2,
                    p_proc        VARCHAR2,
                    p_endpoint    NVARCHAR2,
                    p_authkeys    crossbar_authkeys) RETURN NUMBER
   AS
      PRAGMA AUTONOMOUS_TRANSACTION;

      l_isnew            BOOLEAN := TRUE;
      l_now              TIMESTAMP;
      l_created_by       VARCHAR2(30);
      l_authkeys         crossbar_authkeys;
      l_user             VARCHAR2(30);
      l_id               NUMBER(38);
      l_object_id        NUMBER;
      l_subprogram_id    NUMBER;
      l_overload_cnt     NUMBER;
      l_sessobj_cnt      NUMBER;
      l_status           NUMBER;
      l_schema           VARCHAR2(30);
      l_package          VARCHAR2(30) := UPPER(p_package);
      l_proc             VARCHAR2(30) := UPPER(p_proc);

      -- existing metadata (for updating)
      l_cur_return_type  VARCHAR2(30);
      l_cur_args_cnt     NUMBER;
      l_cur_arg_types    t_arg_types;
      l_cur_arg_inouts   t_arg_inouts;

      -- new metadata
      l_return_type      VARCHAR2(30) := NULL;
      l_args_cnt         NUMBER := 0;
      l_arg_types        t_arg_types := t_arg_types();
      l_arg_inouts       t_arg_inouts := t_arg_inouts();
      l_data_type        VARCHAR2(30);
   BEGIN
      --
      -- determine schema of remoted package procedure
      --
      IF p_schema IS NULL THEN
         l_schema := sys_context('USERENV', 'SESSION_USER');
      ELSE
         l_schema := UPPER(p_schema);
      END IF;

      --
      -- get current time / user
      --
      SELECT systimestamp at time zone 'utc',
             sys_context('USERENV', 'SESSION_USER')
         INTO
             l_now,
             l_user
         FROM dual;

      --
      -- check if package exists and if we have execute grants on it
      --
      BEGIN
         SELECT object_id INTO l_object_id FROM all_procedures
            WHERE owner = l_schema AND object_name = l_package AND object_type = 'PACKAGE' AND subprogram_id = 0;
      EXCEPTION WHEN NO_DATA_FOUND THEN
         RAISE_APPLICATION_ERROR(-20001, 'no package ' || l_schema || '.' || l_package || ' or no execute grant on package');
      END;

      --
      -- check if package procedure/function exists
      --
      BEGIN
         SELECT MAX(subprogram_id), COUNT(*) INTO l_subprogram_id, l_overload_cnt FROM all_procedures
            WHERE owner = l_schema AND object_name = l_package AND procedure_name = l_proc AND object_type = 'PACKAGE' AND subprogram_id > 0
            GROUP BY owner, object_name, procedure_name;
      EXCEPTION WHEN NO_DATA_FOUND THEN
         RAISE_APPLICATION_ERROR(-20001, 'no procedure or function ' || l_schema || '.' || l_package || '.' || l_proc);
      END;

      --
      -- check for overloaded SP
      --
      IF l_overload_cnt > 1 THEN
         RAISE_APPLICATION_ERROR(-20001, 'procedure or function ' || l_schema || '.' || l_package || '.' || l_proc || ' is overloaded [' || l_overload_cnt || ' overloads]');
      END IF;

      --
      -- check for SP with multiple session object parameters
      --
      SELECT COUNT(*) INTO l_sessobj_cnt
        FROM all_arguments
       WHERE     object_id = l_object_id
             AND subprogram_id = l_subprogram_id
             AND data_type = 'OBJECT'
             AND type_owner = 'PUBLIC'
             AND type_name = 'CROSSBAR_SESSION';
      IF l_sessobj_cnt > 1 THEN
         RAISE_APPLICATION_ERROR(-20001, 'procedure or function ' || l_schema || '.' || l_package || '.' || l_proc || ' uses more than 1 session object parameter [' || l_sessobj_cnt || ' session object parameters]');
      END IF;

      --
      -- check SP arguments
      --
      FOR r IN (SELECT position,
                       argument_name,
                       data_type,
                       type_owner,
                       type_name,
                       defaulted,
                       in_out FROM all_arguments
                 WHERE object_id = l_object_id AND
                       subprogram_id = l_subprogram_id
              ORDER BY position ASC)
      LOOP
         --
         -- check for stuff we (currently) don't supports
         --
         IF r.position = 0 AND r.in_out != 'OUT' THEN
            -- should not happen anyway (it seems that functions are the only items having arg (= return value) in position 0)
            RAISE_APPLICATION_ERROR(-20001, 'procedure or function ' || l_schema || '.' || l_package || '.' || l_proc || ' uses IN/INOUT parameter in position 0');
         END IF;
         IF r.position > 0 AND r.in_out != 'IN' THEN
            IF r.data_type = 'OBJECT' AND r.type_owner = 'PUBLIC' AND r.type_name = 'CROSSBAR_SESSION' THEN
               -- session info is the only parameter type allowed to be IN or IN/OUT (but not OUT)
               IF r.in_out NOT IN ('IN', 'IN/OUT') THEN
                  RAISE_APPLICATION_ERROR(-20001, 'procedure or function ' || l_schema || '.' || l_package || '.' || l_proc || ' uses session object parameter of OUT (only IN or IN/OUT allowed)');
               END IF;
            ELSE
               RAISE_APPLICATION_ERROR(-20001, 'procedure or function ' || l_schema || '.' || l_package || '.' || l_proc || ' uses OUT/INOUT parameters');
            END IF;
         END IF;
         IF r.defaulted != 'N' THEN
            RAISE_APPLICATION_ERROR(-20001, 'procedure or function ' || l_schema || '.' || l_package || '.' || l_proc || ' uses parameters defaults');
         END IF;
         IF r.position = 0 AND
            r.data_type != 'NUMBER' AND
            r.data_type != 'VARCHAR2' AND
            r.data_type != 'NVARCHAR2' AND
            r.data_type != 'CHAR' AND
            r.data_type != 'NCHAR' AND
            r.data_type != 'BINARY_FLOAT' AND
            r.data_type != 'BINARY_DOUBLE' AND
            r.data_type != 'DATE' AND
            r.data_type != 'TIMESTAMP' AND
            r.data_type != 'TIMESTAMP WITH TIME ZONE' AND
            r.data_type != 'TIMESTAMP WITH LOCAL TIME ZONE' AND
            r.data_type != 'INTERVAL DAY TO SECOND' AND
            --r.data_type != 'INTERVAL YEAR TO MONTH' AND
            NOT (r.data_type = 'OBJECT' AND r.type_owner = 'PUBLIC' AND r.type_name IN ('JSON', 'JSON_VALUE', 'JSON_LIST')) AND
            r.data_type != 'REF CURSOR'
            THEN
            RAISE_APPLICATION_ERROR(-20001, 'procedure or function ' || l_schema || '.' || l_package || '.' || l_proc || ' uses unsupported return type');
         END IF;
         IF r.position > 0 AND
            r.data_type != 'NUMBER' AND
            r.data_type != 'VARCHAR2' AND
            r.data_type != 'NVARCHAR2' AND
            r.data_type != 'CHAR' AND
            r.data_type != 'NCHAR' AND
            r.data_type != 'BINARY_FLOAT' AND
            r.data_type != 'BINARY_DOUBLE' AND
            r.data_type != 'DATE' AND
            r.data_type != 'TIMESTAMP' AND
            r.data_type != 'TIMESTAMP WITH TIME ZONE' AND
            r.data_type != 'TIMESTAMP WITH LOCAL TIME ZONE' AND
            r.data_type != 'INTERVAL DAY TO SECOND' AND
            --r.data_type != 'INTERVAL YEAR TO MONTH' AND
            NOT (r.data_type = 'OBJECT' AND r.type_owner = 'PUBLIC' AND r.type_name IN ('CROSSBAR_SESSION', 'JSON', 'JSON_VALUE', 'JSON_LIST'))
            THEN
            RAISE_APPLICATION_ERROR(-20001, 'procedure or function ' || l_schema || '.' || l_package || '.' || l_proc || ' uses unsupported parameter type');
         END IF;

         --
         -- remember return type (if a function) and number of (IN) args
         --
         IF r.data_type = 'OBJECT' AND r.type_owner = 'PUBLIC' AND r.type_name IN ('CROSSBAR_SESSION', 'JSON', 'JSON_VALUE', 'JSON_LIST') THEN
            l_data_type := r.type_name;
         ELSE
            l_data_type := r.data_type;
         END IF;

         --
         -- remember arg types
         --
         IF r.position = 0 THEN
            l_return_type := l_data_type;
         ELSE
            -- don't count injected args
            --
            IF NOT (r.data_type = 'OBJECT' AND r.type_owner = 'PUBLIC' AND r.type_name IN ('CROSSBAR_SESSION')) THEN
               l_args_cnt := l_args_cnt + 1;
            END IF;

            IF l_data_type IS NOT NULL THEN
               l_arg_types.extend(1);
               l_arg_types(l_arg_types.last) := l_data_type;
               l_arg_inouts.extend(1);
               l_arg_inouts(l_arg_inouts.last) := r.in_out;
            END IF;
         END IF;
      END LOOP;

      BEGIN
         SELECT id, created_by, authkeys, return_type, args_cnt, arg_types, arg_inouts INTO l_id, l_created_by, l_authkeys, l_cur_return_type, l_cur_args_cnt, l_cur_arg_types, l_cur_arg_inouts FROM endpoint
            WHERE schema = l_schema AND package = l_package AND procedure = l_proc AND uri = p_endpoint;

         IF l_created_by != l_user THEN
            RAISE_APPLICATION_ERROR(-20001, 'endpoint already exists, but was created by different user: not allowed to modify endpoint');
         END IF;

         l_isnew := FALSE;

         IF l_authkeys != p_authkeys OR
            (l_authkeys IS NULL     AND p_authkeys IS NOT NULL) OR
            (l_authkeys IS NOT NULL AND p_authkeys IS NULL) OR
            l_cur_return_type != l_return_type OR
            (l_cur_return_type IS NULL     AND l_return_type IS NOT NULL) OR
            (l_cur_return_type IS NOT NULL AND l_return_type IS NULL) OR
            l_cur_args_cnt != l_args_cnt OR
            l_arg_types != l_cur_arg_types OR
            (l_arg_types IS NULL     AND l_cur_arg_types IS NOT NULL) OR
            (l_arg_types IS NOT NULL AND l_cur_arg_types IS NULL) OR
            l_arg_inouts != l_cur_arg_inouts OR
            (l_arg_inouts IS NULL     AND l_cur_arg_inouts IS NOT NULL) OR
            (l_arg_inouts IS NOT NULL AND l_cur_arg_inouts IS NULL)
            THEN

            UPDATE endpoint
               SET
                  modified_at = l_now,
                  authkeys    = p_authkeys,
                  return_type = l_return_type,
                  args_cnt    = l_args_cnt,
                  arg_types   = l_arg_types,
                  arg_inouts  = l_arg_inouts
               WHERE
                  id = l_id;
            COMMIT;

            -- notify via pipe
            --
            --DBMS_PIPE.pack_message(l_id);
            --l_status := DBMS_PIPE.send_message('%(PIPE_ONEXPORT)s');
         END IF;

      EXCEPTION WHEN NO_DATA_FOUND THEN

         SELECT endpoint_id.nextval INTO l_id FROM dual;

         INSERT INTO endpoint
            (id, created_at, created_by, schema, package, procedure, object_id, subprogram_id, return_type, args_cnt, arg_types, arg_inouts, uri, authkeys) VALUES
               (l_id, l_now, l_user, l_schema, l_package, l_proc, l_object_id, l_subprogram_id, l_return_type, l_args_cnt, l_arg_types, l_arg_inouts, p_endpoint, p_authkeys);
         COMMIT;

         -- notify via pipe
         --
         --DBMS_PIPE.pack_message(l_id);
         --l_status := DBMS_PIPE.send_message('%(PIPE_ONEXPORT)s');
      END;

      RETURN l_id;

   END export;


   PROCEDURE export(p_package   IN VARCHAR2,
                    p_proc      IN VARCHAR2,
                    p_endpoint  IN NVARCHAR2,
                    p_authkeys  IN crossbar_authkeys      DEFAULT NULL)
   IS
      l_id   NUMBER;
   BEGIN
      l_id := export(NULL, p_package, p_proc, p_endpoint, p_authkeys);
   END export;


   PROCEDURE raise (p_uri VARCHAR2, p_desc VARCHAR2, p_kill_session BOOLEAN)
   IS
      l_obj    JSON := JSON();
   BEGIN
      l_obj.put('uri', p_uri);
      l_obj.put('desc', p_desc);
      l_obj.put('kill', p_kill_session);
      l_obj.put('callstack', DBMS_UTILITY.FORMAT_CALL_STACK);
      --l_obj.put('backtrace', DBMS_UTILITY.FORMAT_ERROR_BACKTRACE);
      --l_obj.put('errorstack', DBMS_UTILITY.FORMAT_ERROR_STACK);
      RAISE_APPLICATION_ERROR(-20999, l_obj.to_char(false));
   END raise;


   PROCEDURE raise (p_uri VARCHAR2, p_desc VARCHAR2, p_detail JSON_VALUE, p_kill_session BOOLEAN)
   IS
      l_obj    JSON := JSON();
   BEGIN
      l_obj.put('uri', p_uri);
      l_obj.put('desc', p_desc);
      IF p_detail IS NOT NULL THEN
         l_obj.put('detail', p_detail);
      END IF;
      l_obj.put('kill', p_kill_session);
      l_obj.put('callstack', DBMS_UTILITY.FORMAT_CALL_STACK);
      --l_obj.put('backtrace', DBMS_UTILITY.FORMAT_ERROR_BACKTRACE);
      --l_obj.put('errorstack', DBMS_UTILITY.FORMAT_ERROR_STACK);
      RAISE_APPLICATION_ERROR(-20999, l_obj.to_char(false));
   END raise;


   PROCEDURE raise (p_uri VARCHAR2, p_desc VARCHAR2, p_detail JSON, p_kill_session BOOLEAN)
   IS
      l_obj    JSON := JSON();
   BEGIN
      l_obj.put('uri', p_uri);
      l_obj.put('desc', p_desc);
      IF p_detail IS NOT NULL THEN
         l_obj.put('detail', p_detail);
      END IF;
      l_obj.put('kill', p_kill_session);
      l_obj.put('callstack', DBMS_UTILITY.FORMAT_CALL_STACK);
      --l_obj.put('backtrace', DBMS_UTILITY.FORMAT_ERROR_BACKTRACE);
      --l_obj.put('errorstack', DBMS_UTILITY.FORMAT_ERROR_STACK);
      RAISE_APPLICATION_ERROR(-20999, l_obj.to_char(false));
   END raise;


   PROCEDURE raise (p_uri VARCHAR2, p_desc VARCHAR2, p_detail JSON_LIST, p_kill_session BOOLEAN)
   IS
      l_obj    JSON := JSON();
   BEGIN
      l_obj.put('uri', p_uri);
      l_obj.put('desc', p_desc);
      IF p_detail IS NOT NULL THEN
         l_obj.put('detail', p_detail);
      END IF;
      l_obj.put('kill', p_kill_session);
      l_obj.put('callstack', DBMS_UTILITY.FORMAT_CALL_STACK);
      --l_obj.put('backtrace', DBMS_UTILITY.FORMAT_ERROR_BACKTRACE);
      --l_obj.put('errorstack', DBMS_UTILITY.FORMAT_ERROR_STACK);
      RAISE_APPLICATION_ERROR(-20999, l_obj.to_char(false));
   END raise;

END crossbar;""" % {'PIPE_ONPUBLISH': PIPE_ONPUBLISH,
                 'PIPE_ONEXPORT': PIPE_ONEXPORT})

      log.msg("database package '%s' created" % "crossbar")


      ## public synonyms
      ##
      if publicsyn:
         for s in PUBSYNS:
            try:
               cur.execute("CREATE PUBLIC SYNONYM %s FOR %s" % (s, s))
               log.msg("public synonym '%s' created for '%s'" % (s, s))
            except:
               log.msg("warning: could not create public synonym '%s' for '%s'" % (s, s))


      ## public grants
      ##
      for grant, objects in USERGRANTS:
         for object in objects:
            for user in grantedusers:
               try:
                  cur.execute("GRANT %s ON %s TO %s" % (grant, object, user))
                  log.msg("granted %s on '%s' to '%s'" % (grant, object, user))
               except:
                  log.msg("warning: could not grant %s on '%s' to '%s'" % (grant, object, user))


      ## store database schema version
      ##
      created = utcnow()
      config = [('schema-category', 'repository'),
                ('schema-version', SCHEMAVERSION),
                ('schema-created', utcnow())]
      for key, value in config:
         cur.execute("INSERT INTO config (key, value) VALUES (:1, :2)", [key, json_dumps(value)])
      conn.commit()

      log.msg("crossbar.io Repository schema created (version %d)!" % SCHEMAVERSION)

   else:

      log.msg("crossbar.io Repository schema dropped!")

   return dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)


def setupSchema(app,
                conn,
                grantedusers = ['public'],
                publicsyn = True):
   """
   Setup crossbar.io Connect repository.

   :param conn: A connected cx_Oracle connection.
   :type conn: cx_Oracle.Connection
   :param grantedusers: List of user granted access to crossbar.io.
   :type grantedusers: List of str.
   :param publicsyn: Create public synonyms for crossbar.io objects.
   :type publicsyn: bool
   :returns dict -- Repository information.
   """
   r = dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)

   if r['schema-version'] is not None:
      raise Exception("crossbar.io Repository already installed")

   return _setupSchema(conn, grantedusers, publicsyn)


def reinstallSchema(app,
                    conn,
                    grantedusers = ['public'],
                    publicsyn = True):
   """
   Reinstall crossbar.io Connect repository.

   :param conn: A connected cx_Oracle connection.
   :type conn: cx_Oracle.Connection
   :param grantedusers: List of user granted access to crossbar.io.
   :type grantedusers: List of str.
   :param publicsyn: Create public synonyms for crossbar.io objects.
   :type publicsyn: bool
   :returns dict -- Repository information.
   """
   r = dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)

   if r['schema-version'] is None:
      raise Exception("crossbar.io Repository not installed")

   return _setupSchema(conn, grantedusers, publicsyn)


def dropSchema(app, conn):
   """
   Drop crossbar.io repository.
   """
   r = dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)

   if r['schema-version'] is None:
      raise Exception("crossbar.io Repository not installed")

   return _setupSchema(conn, uninstallOnly = True)


def upgradeSchema(app, conn):
   """
   Upgrades crossbar.io repository.
   """
   r = dbschema.getSchemaVersion(conn, oraschema.LATESTVERSIONS)

   if r['schema-version'] is None:
      raise Exception("crossbar.io Repository not installed")

   if not r['schema-needs-upgrade']:
      raise Exception("crossbar.io Repository needs no upgrade")

   ## FIXME
   raise Exception("crossbar.io Repository upgrade not implemented")



if __name__ == '__main__':

   ## Test setup of PL/JSON
   ##
   tsql = _getPLJSONDDL()
   for fn, block, t in tsql:
      print fn, block, t

   import cx_Oracle

   dsn = cx_Oracle.makedsn("127.0.0.1", 1521, "orcl")
   conn = cx_Oracle.connect("crossbar", "secret", dsn, threaded = True)
   cur = conn.cursor()

   for fn, block, t in tsql:
      try:
         cur.execute(t)
      except Exception, e:
         print fn, block
         print t
         print e
         raise

########NEW FILE########
__FILENAME__ = pgclient
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log

from autobahn.wamp import json_dumps


class PgConnect:
   """
   PostgreSQL Connect.
   """

   def __init__(self,
                id,
                host,
                port,
                database,
                user,
                password,
                connectionTimeout):

      ## 2 connects are equal (unchanged) iff the following are equal (unchanged)
      self.id = str(id)
      self.host = str(host)
      self.port = int(port)
      self.database = str(database)
      self.user = str(user)
      self.password = str(password)

      self.connectionTimeout = connectionTimeout

   def __eq__(self, other):
      if isinstance(other, PgConnect):
         return self.id == other.id and \
                self.host == other.host and \
                self.port == other.port and \
                self.database == other.database and \
                self.user == other.user and \
                self.password == other.password
      return NotImplemented

   # http://jcalderone.livejournal.com/32837.html !!
   def __ne__(self, other):
      result = self.__eq__(other)
      if result is NotImplemented:
         return result
      return not result

   def __repr__(self):
      r = {'id': self.id,
           #'connectionTimeout': self.connectionTimeout,
           'host': self.host,
           'port': self.port,
           'database': self.database,
           'user': self.user,
           'password': self.password}
      return json_dumps(r)


class PgSchemaSetup:

   SQL_CREATE_TABLE_EVENT = """
CREATE TABLE event
(
   id             BIGINT         PRIMARY KEY,
   published_at   TIMESTAMP      NOT NULL,
   published_by   VARCHAR(100)   NOT NULL,
   dispatched_at  TIMESTAMP,
   topic          VARCHAR        NOT NULL,
   payload_str    VARCHAR,
   payload_json   JSON
)
"""

   SQL_CREATE_PROCEDURE_PUBLISH = """
CREATE OR REPLACE FUNCTION publish(topic IN VARCHAR, payload IN VARCHAR)
RETURNS void
AS
$$
DECLARE
l_now                   TIMESTAMP;
BEGIN
   l_now := NOW () AT TIME ZONE 'UTC';
   INSERT INTO event (published_at, published_by, topic, payload_str) VALUES (l_now, session_user, topic, payload);
   NOTIFY event_published;
END
$$ LANGUAGE plpgsql SECURITY DEFINER;

CREATE OR REPLACE FUNCTION publish(topic IN VARCHAR, payload IN JSON)
RETURNS void
AS
$$
DECLARE
l_now                   TIMESTAMP;
BEGIN
   l_now := NOW () AT TIME ZONE 'UTC';
   INSERT INTO event (published_at, published_by, topic, payload_json) VALUES (l_now, session_user, topic, payload);
   NOTIFY event_published;
END
$$ LANGUAGE plpgsql SECURITY DEFINER;
"""

   SQL_TABLES = [('event', SQL_CREATE_TABLE_EVENT)]
   SQL_SEQUENCES = [('event_id', "CREATE SEQUENCE event_id")]
   SQL_PROCEDURES = [('publish', SQL_CREATE_PROCEDURE_PUBLISH)]

   def __init__(self, connect, schema, recreate = False):
      self.connect = connect
      self.schema = schema
      self.recreate = recreate

   def run(self):
      log.msg("PgSchemaSetup started")

      try:
         import time, json
         import psycopg2

         conn = psycopg2.connect(user = self.connect.user,
                                 password = self.connect.password,
                                 database = self.connect.database,
                                 host = self.connect.host,
                                 port = self.connect.port)
         conn.autocommit = True
         cur = conn.cursor()

         if self.recreate:
            log.msg("Recreating schema objects")

            for o in self.SQL_PROCEDURES:
               try:
                  cur.execute("DROP PROCEDURE ?", [o[0]])
                  log.msg("PROCEDURE %s dropped" % o[0])
               except:
                  pass

            for o in self.SQL_SEQUENCES:
               try:
                  cur.execute("DROP SEQUENCE ?", [o[0]])
                  log.msg("SEQUENCE %s dropped" % o[0])
               except:
                  pass

            for o in self.SQL_TABLES:
               try:
                  cur.execute("DROP TABLE ?", [o[0]])
                  log.msg("TABLE %s dropped" % o[0])
               except:
                  pass

         for o in self.SQL_TABLES:
            cur.execute("SELECT 1 FROM SYS.TABLES WHERE schema_name = ? AND table_name = ?", [self.schema, o[0].upper()])
            if cur.fetchone() is None:
               cur.execute(o[1])
               log.msg("TABLE %s created" % o[0])
            else:
               log.msg("TABLE %s already exists" % o[0])

         for o in self.SQL_SEQUENCES:
            cur.execute("SELECT 1 FROM SYS.SEQUENCES WHERE schema_name = ? AND sequence_name = ?", [self.schema, o[0].upper()])
            if cur.fetchone() is None:
               cur.execute(o[1])
               log.msg("SEQUENCE %s created" % o[0])
            else:
               log.msg("SEQUENCE %s already exists" % o[0])

         for o in self.SQL_PROCEDURES:
            cur.execute("SELECT 1 FROM SYS.PROCEDURES WHERE schema_name = ? AND procedure_name = ?", [self.schema, o[0].upper()])
            if cur.fetchone() is None:
               cur.execute(o[1])
               log.msg("PROCEDURE %s created" % o[0])
            else:
               log.msg("PROCEDURE %s already exists" % o[0])


      except Exception, e:
         log.msg(e)
         raise e

########NEW FILE########
__FILENAME__ = pgpusher
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log

from crossbar.adminwebmodule.uris import URI_EVENT, URI_PGCONNECT
from pgclient import PgConnect
from dbpusher import PushStats, DbPusher, DbPushClient


class PgPushRule:
   """
   PostgreSQL Push Rule.

   User:
      PostgreSQL: current_user
      http://www.postgresql.org/docs/9.1/static/functions-info.html
   """
   def __init__(self,
                id,
                connectId,
                user,
                topicUri,
                matchByPrefix):
      self.id = str(id)
      self.connectId = str(connectId)
      self.user = str(user) if user is not None else None
      self.topicUri = str(topicUri)
      self.matchByPrefix = matchByPrefix != 0



class PgPushClient(DbPushClient):
   """
   PostgreSQL Push Client.
   """

   LOGID = "PgPushClient"

   def loop(self):
      import time, json
      import select
      import psycopg2
      import psycopg2.extensions

      ## establish database connection
      ##
      try:
         self.conn = psycopg2.connect(user = self.connect.user,
                                      password = self.connect.password,
                                      database = self.connect.database,
                                      host = self.connect.host,
                                      port = self.connect.port)
      except Exception, e:
         log.msg(str(e))
         raise Exception(str(e))

      self.conn.autocommit = True

      ## note state change and trigger event
      ##
      self.isConnected = True
      self.pusher.publishPusherStateChange(self.connect.id, True, True)

      cur1 = self.conn.cursor()
      cur2 = self.conn.cursor()
      cur3 = self.conn.cursor()
      cur4 = self.conn.cursor()

      useNotify = True

      cur1.execute("SELECT COALESCE(MAX(id), 0), COALESCE(MIN(id), 0), COUNT(*) FROM event WHERE dispatched_at IS NULL")
      (id, minid, evtcnt) = cur1.fetchone()

      while not self.stopped:
         cur1.execute("SELECT id, published_by, topic, payload_type, payload_str, payload_json, exclude_sids, eligible_sids FROM event WHERE id > %s AND dispatched_at IS NULL ORDER BY id ASC", [id])
         oldid = id
         for r in cur1.fetchall():

            id = r[0]
            pushedBy = r[1]
            topic = r[2]
            payload_type = r[3]
            exclude = r[6] if r[6] is not None else []
            eligible = r[7]

            ## Psycopg2 does automatic typecasting from PG JSON to Python object
            ##
            if payload_type == 1:
               ## string
               payload = r[4]
            elif payload_type == 2:
               ## JSON
               payload = r[5] # Psycopg2 already did automatic typecasting from PG JSON to Python object

               ## manual typecasting from PG JSON to Python object
               #try:
               #   payload = json.loads(r[5])
               #except Exception, e:
               #   ## should not arrive here, since event table column is of type JSON already!
               #   log.msg("%s - INVALID JSON PAYLOAD - %s" % (r[4], str(e)))
            else:
               raise Exception("unknown payload type %d" % payload_type)

            reactor.callFromThread(self.pusher.push, id, self.connect.id, pushedBy, topic, payload, exclude, eligible)

         if self.purge and id > oldid:
            cur2.execute("DELETE FROM event WHERE id <= %s", [id])
            self.conn.commit()
         else:
            cur3.execute("UPDATE event SET dispatched_at = NOW () AT TIME ZONE 'UTC' WHERE id <= %s AND dispatched_at IS NULL", [id])
            self.conn.commit()

         if not useNotify:
            if self.throttle > 0:
               time.sleep(self.throttle)
         else:
            cur4.execute("LISTEN onpublish")
            if select.select([self.conn], [], [], 5) == ([], [], []):
               pass
               #print "timeout"
            else:
               self.conn.poll()
               while self.conn.notifies:
                  notify = self.conn.notifies.pop()
                  #print "Got NOTIFY:", notify.pid, notify.channel, notify.payload



class PgPusher(DbPusher):
   """
   PostgreSQL Pusher Service.

   For each PostgreSQL Connect with >0 push rules, spawn 1 background pusher thread.
   """

   SERVICENAME = "PostgreSQL Pusher"

   LOGID = "PgPusher"

   CONNECT_ID_BASEURI = URI_PGCONNECT

   PUSHER_STATE_CHANGE_EVENT_URI = URI_EVENT + "on-pgpusher-statechange"
   STATS_EVENT_URI = URI_EVENT + "on-pgpusherstat"

   def makeConnect(self, r):
      ## called from DbPusher base class to create database connect instances
      return PgConnect(r[0], r[1], r[2], r[3], r[4], r[5], r[6])

   def makeRule(self, r):
      ## called from DbPusher base class to create push rule instances
      return PgPushRule(r[0], r[1], r[2], r[3], r[4])

   def makeClient(self, connect):
      ## called from DbPusher base class to create background push client instances
      return PgPushClient(self, connect, False)

   def recache(self, txn):
      log.msg("PgPusher.recache")

      txn.execute("SELECT id, host, port, database, user, password, connection_timeout FROM pgconnect ORDER BY id")
      connects = txn.fetchall()

      txn.execute("SELECT id, pgconnect_id, user, topic_uri, match_by_prefix FROM pgpushrule ORDER BY pgconnect_id, id")
      rules = txn.fetchall()

      self._cache(connects, rules)

      #log.msg("PostgreSQL Connects cached: %s" % self.connects)

########NEW FILE########
__FILENAME__ = pgremoter
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from urlparse import urljoin

from autobahn.util import utcnow
from autobahn.wamp import json_dumps

from twisted.python import log
from twisted.enterprise import adbapi

from crossbar.adminwebmodule.uris import URI_EVENT, URI_PGREMOTE
from dbremoter import DbRemoter, DbRemote, DbProcedureMeta

#import json
#from decimal import Decimal
#
#class DecimalEncoder(json.JSONEncoder):
#   def default(self, obj):
#      if isinstance(obj, Decimal):
#         # print "%s" % Decimal.from_float(0.1)
#         #return "%.2f" % obj
#         return "%s" % obj
#      return json.JSONEncoder.default(self, obj)
#

## FIXME: load the following stuff dynamically, maybe at startup
#try:
#   import psycopg2
#   import psycopg2.extras
#except:
#   log.msg("psycopg2 not installed")
#else:
#   ## automatically adapt Python dictionaries to PostgreSQL JSON
#   ##
#   try:
#      ## Latest psycopg2 has builtin support
#      ##
#      psycopg2.extensions.register_adapter(dict, psycopg2.extras.Json)
#   except:
#      ## PG 9.2 OIDs
#      ##
#      json_oid, jsonarray_oid = 114, 199
#
#      def cast_json(value, cur):
#         if value is None:
#            return None
#         try:
#            o = json.loads(value)
#            #o = simplejson.loads(value, use_decimal = True)
#            return o
#         except:
#            raise InterfaceError("bad JSON representation")
#
#      JSON = psycopg2.extensions.new_type((json_oid,), "JSON", cast_json)
#      psycopg2.extensions.register_type(JSON)
#      psycopg2.extensions.register_type(psycopg2.extensions.new_array_type((jsonarray_oid,), "JSON[]", JSON))



class PgRemote(DbRemote):
   """
   Model for flattened PostgreSQL database remotes.

   Objects of this class contain flattened information from the following
   service database entities:

     - pgremote
     - pgconnect
     - appcredential
   """

   def __init__(self,
                id,
                appkey,
                host,
                port,
                database,
                user,
                password,
                schemaList,
                rpcBaseUri,
                connectionPoolMinSize,
                connectionPoolMaxSize,
                connectionTimeout,
                requestTimeout):

      self.id = str(id)
      self.appkey = str(appkey) if appkey is not None else None

      self.host = str(host)
      self.port = int(port)
      self.database = str(database)
      self.user = str(user)
      self.password = str(password)

      self.schemaList = str(schemaList)
      self.rpcBaseUri = str(rpcBaseUri)

      self.connectionPoolMinSize = int(connectionPoolMinSize)
      self.connectionPoolMaxSize = int(connectionPoolMaxSize)
      self.connectionTimeout = int(connectionTimeout)
      self.requestTimeout = int(requestTimeout)

      self.pool = None
      self.poolConnections = []


   def __eq__(self, other):
      if isinstance(other, PgRemote):
         return self.id == other.id and \
                self.appkey == other.appkey and \
                self.host == other.host and \
                self.port == other.port and \
                self.database == other.database and \
                self.user == other.connectId and \
                self.password == other.password and \
                self.schemaList == other.schemaList and \
                self.rpcBaseUri == other.rpcBaseUri and \
                self.connectionPoolMinSize == other.connectionPoolMinSize and \
                self.connectionPoolMaxSize == other.connectionPoolMaxSize and \
                self.connectionTimeout == other.connectionTimeout and \
                self.requestTimeout == other.requestTimeout
      return NotImplemented


   def __repr__(self):
      r = {'id': self.id,
           'appkey': self.appkey,

           'host': self.host,
           'port': self.port,
           'database': self.database,
           'user': self.user,
           'password': self.password,

           'schemaList': self.schemaList,
           'rpcBaseUri': self.rpcBaseUri,
           'connectionPoolMinSize': self.connectionPoolMinSize,
           'connectionPoolMaxSize': self.connectionPoolMaxSize,
           'connectionTimeout': self.connectionTimeout,
           'requestTimeout': self.requestTimeout,
           }
      return json_dumps(r)


   def makePool(self):
      pool = adbapi.ConnectionPool("psycopg2",
                                    host = self.host,
                                    port = self.port,
                                    database = self.database,
                                    user = self.user,
                                    password = self.password,
                                    cp_min = self.connectionPoolMinSize,
                                    cp_max = self.connectionPoolMaxSize,
                                    cp_noisy = True,
                                    cp_openfun = self._onPoolConnectionCreated,
                                    cp_reconnect = True,
                                    cp_good_sql = "SELECT 1")
      return pool


   def _onPoolConnectionCreated(self, conn):
      ## per connection settings
      conn.autocommit = True

      ## get connection info and store that
      backendPid = conn.get_backend_pid()
      serverVersion = conn.server_version
      self.poolConnections.append((backendPid, utcnow(), serverVersion, conn))

      #log.msg("PostgreSQL pool connection for PgRemote %s created [backend PID = %s, PG version = %s]" % (self.id, backendPid, serverVersion))



class PgRemoter(DbRemoter):
   """
   Implements remoting of PostgreSQL stored procedures.
   """

   SERVICENAME = "PostgreSQL Remoter"

   LOGID = "PgRemoter"
   REMOTERID = "pg"

   REMOTE_ID_BASEURI = URI_PGREMOTE

   REMOTER_STATE_CHANGE_EVENT_URI = URI_EVENT + "on-pgremoter-statechange"
   STATS_EVENT_URI = URI_EVENT + "on-pgremoterstat"


   def recache(self, txn):
      """
      Recache PostgreSQL database remotes.

      Recaching is triggered from the following classes:

         - PgRemotes
         - PgConnects
         - AppCreds
      """
      log.msg("PgRemoter.recache")

      txn.execute("""
         SELECT
            r.id,
            a.key,
            b.host,
            b.port,
            b.database,
            b.user,
            b.password,
            r.schema_list,
            r.rpc_base_uri,
            r.connection_pool_min_size,
            r.connection_pool_max_size,
            r.connection_timeout,
            r.request_timeout
         FROM
            pgremote r
            INNER JOIN
               pgconnect b ON r.pgconnect_id = b.id
            LEFT OUTER JOIN
               appcredential a ON r.require_appcred_id = a.id
         ORDER BY
            a.key ASC,
            b.id ASC,
            r.created ASC
      """)
      remotes = txn.fetchall()
      self._cache(remotes)


   def makeRemote(self, r):
      remote = PgRemote(id = r[0],
                        appkey = r[1],
                        host = r[2],
                        port = r[3],
                        database = r[4],
                        user = r[5],
                        password = r[6],
                        schemaList = r[7],
                        rpcBaseUri = r[8],
                        connectionPoolMinSize = r[9],
                        connectionPoolMaxSize = r[10],
                        connectionTimeout = r[11],
                        requestTimeout = r[12])
      return remote


   def _getRemotes(self, txn, remote):

      ## FIXME: filter
      ##   - overloaded funs
      ##   - funs with default params
      ##   - funs with parameter types we cannot digest

      ## the procedures remoted (indexed by URI) we return
      ##
      procs = {}

      ## iterate over all Schemas defined in the remote
      ##
      for s in remote.schemaList.split(','):

         ## FIXME: are PG identifiers case-insensitive?
         ##
         schema = s.strip().lower()

         ## get info on all stored procedures in given schema for which
         ## we (the connection pool user connecting) have execute rights
         ##
         txn.execute("""
            SELECT
               n.nspname,
               p.proname,
               p.pronargs,
               p.pronargdefaults
            FROM
               pg_proc p
               INNER JOIN
                  pg_namespace n ON p.pronamespace = n.oid
            WHERE
               n.nspname = %s
               AND has_schema_privilege(current_user, n.oid, 'usage') = true
               AND has_function_privilege(current_user, p.oid, 'execute') = true
            ORDER BY
               n.nspname,
               p.proname
         """,
         [schema])

         res = txn.fetchall()
         if res is not None:
            for r in res:
               ## the RPC endpoint URI is constructed as:
               ## RPC Base URI + Schema Name + '#' + Function Name
               ##
               uri = urljoin(remote.rpcBaseUri, str(r[0]).lower() + "#" + str(r[1]).lower())

               ## the SQL statement used when calling the SP later
               ##
               statement = "SELECT %s.%s(%s)" % (str(r[0]), str(r[1]), ("%s," * r[2])[:-1])

               ## procs[uri] = (Schema Name,
               ##               Function Name,
               ##               Function Arity,
               ##               Remote ID,
               ##               SQL Statement)
               ##
               meta = DbProcedureMeta(remote.id, r[0] + '.' + r[1], r[2])
               meta.statement = statement
               procs[uri] = meta

      return procs


   def _callSp(self, txn, meta, args):

      print self.LOGID, meta.statement, args

      ## actually perform the stored procedure call and process it's result
      ##
      txn.execute(meta.statement, args)
      rr = txn.fetchall()
      res = None
      if rr is not None:
         if len(rr) > 1:
            res = []
            for r in rr:
               if len(r) > 1:
                  res.append(list(r))
               else:
                  res.append(r[0])
         else:
            if len(rr[0]) > 1:
               res = list(rr[0])
            else:
               res = rr[0][0]
      return res

########NEW FILE########
__FILENAME__ = pusher
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import urlparse

from twisted.python import log
from twisted.application import service


def validateUri(uri, allowEmptyNetworkLocation = False):

   ## valid URI: absolute URI from http(s) scheme, no query component
   ##
   try:
      p = urlparse.urlparse(uri)

      if p.scheme == "":
         return False, "URI '%s' does not contain a scheme." % uri
      else:
         if p.scheme not in ['http', 'https']:
            return False, "URI '%s' scheme '%s' is invalid (only 'http' or 'https' allowed." % (uri, p.scheme)

      if p.netloc == "" and not allowEmptyNetworkLocation:
         return False, "URI '%s' does not contain a network location." % uri

      if p.query != "":
         return False, "URI '%s' contains a query component '%s'." % (uri, p.query)

      normalizedUri = urlparse.urlunparse(p)

      return True, normalizedUri

   except Exception, e:

      return False, "Invalid URI '%s' - could not parse URI (%s)" % (uri, str(e))



class Pusher(service.Service):

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)
      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      self.isRunning = False

########NEW FILE########
__FILENAME__ = remoter
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from twisted.python import log
from twisted.application import service



class RemoteStats:

   def __init__(self, id):
      self.stats = {'uri': id,
                    'call-allowed': 0,
                    'call-denied': 0,
                    'forward-success': 0,
                    'forward-failed': 0}
      self.statsChanged = False

   def updateForwards(self, success_count, failed_count):
      if success_count > 0:
         self.stats['forward-success'] += success_count

      if failed_count > 0:
         self.stats['forward-failed'] += failed_count

      if success_count > 0 or failed_count > 0:
         self.statsChanged = True

   def updateCalls(self, allowed_count, denied_count):
      if allowed_count > 0:
         self.stats['call-allowed'] += 1

      if denied_count > 0:
         self.stats['call-denied'] += 1

      if allowed_count > 0 or denied_count > 0:
         self.statsChanged = True

   def get(self, changedonly = True, reset = True):
      if not changedonly or self.statsChanged:
         if reset:
            self.statsChanged = False
         return self.stats
      else:
         return None


class Remoter(service.Service):

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)
      self.stopped = False

      ## current statistics
      self.stats = {}
      self.stats[None] = self._createRemoteStat(None)
      self.publishRemoterStats()

      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      self.stopped = True
      self.isRunning = False


   def _createRemoteStat(self, id):
      return RemoteStats(self.REMOTE_ID_BASEURI + id if id is not None else None)


   def getRemoterStats(self):
      res = []
      for s in self.stats.values():
         res.append(s.get(changedonly = False, reset = False))
      return res


   def publishRemoterStats(self):
      if not self.stopped:
         res = []
         for s in self.stats.values():
            v = s.get()
            if v:
               res.append(v)
         if len(res) > 0:
            self.services["adminws"].dispatchAdminEvent(self.STATS_EVENT_URI, res)
         self.reactor.callLater(0.2, self.publishRemoterStats)


   def onAfterRemoteCallSuccess(self, result, remoteId):
      if not self.stats.has_key(remoteId):
         self.stats[remoteId] = self._createRemoteStat(remoteId)
      self.stats[None].updateForwards(1, 0)
      return result


   def onAfterRemoteCallError(self, error, remoteId):
      if not self.stats.has_key(remoteId):
         self.stats[remoteId] = self._createRemoteStat(remoteId)
      self.stats[None].updateForwards(0, 1)
      raise error

########NEW FILE########
__FILENAME__ = restpusher
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import hmac, hashlib, base64

from twisted.python import log
from twisted.application import service
from twisted.enterprise import adbapi

from netaddr.ip import IPAddress, IPNetwork


class PostFilterRule:

   def __init__(self,
                id,
                topicUri,
                matchByPrefix,
                filterIp,
                filterIpNetwork,
                requireSignature,
                appCredKey,
                action):

      self.id = str(id)
      self.topicUri = str(topicUri)
      self.matchByPrefix = matchByPrefix
      self.filterIp = filterIp
      self.filterIpNetwork = filterIpNetwork
      self.requireSignature = requireSignature
      self.appCredKey = appCredKey
      self.action = action

      self.definition = "{'topicUri': %s, 'matchByPrefix': %s, 'filterIp': %s, 'filterIpNetwork': %s, 'requireSignature': %s, 'appCredKey': %s, 'action': %s}" % \
                        (self.topicUri, self.matchByPrefix, self.filterIp, self.filterIpNetwork, self.requireSignature, self.appCredKey, self.action)


class RestPusher(service.Service):

   SERVICENAME = "REST Pusher"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False


   def startService(self):
      log.msg("Starting %s service .." % self.SERVICENAME)
      self.dbpool.runInteraction(self.recache)
      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service .." % self.SERVICENAME)
      self.isRunning = False


   def signature(self, topicUri, appkey, timestamp, body):
      """
      Computes the signature a signed HTTP/POST is expected to have.
      If appkey is unknown, returns None. Else, return Base64 ("url-safe")
      encoded signature.

      HMAC[SHA1]_{appsecret}(topicuri | appkey | timestamp | body) => appsig
      """
      if self.appcreds.has_key(appkey):
         secret = str(self.appcreds[appkey]) # this needs to be str, not unicode!
         hm = hmac.new(secret, None, hashlib.sha256)
         hm.update(topicUri)
         hm.update(appkey)
         hm.update(timestamp)
         hm.update(body)
         return base64.urlsafe_b64encode(hm.digest())
      else:
         return None


   def authorize(self, topicUri, clientIp, appkey):
      """
      Authorizes a HTTP/POST request. Returns a pair (authorized, ruleId), where
      authorized = True|False, and ruleId = ID of rule that was triggered, or None
      if default (deny) rule applied.
      """

      ## check ordered list of rules for request matching rule
      ##
      for r in self.rules:

         ## check if POST request matches rule
         ##

         ## match topic URI completely or by prefix if matchByPrefix set
         if r.topicUri == topicUri or (r.matchByPrefix and r.topicUri == topicUri[:len(r.topicUri)]):

            ## match any client or client IP in network if filterIpNetwork set
            if not r.filterIp or (r.filterIp and IPAddress(clientIp) in r.filterIpNetwork):

               ## match any signed/unsigned or signed/arbitrary appCredKey or signed/specific appCredKey
               if not r.requireSignature or (r.requireSignature and not r.appCredKey and appkey) or (r.requireSignature and r.appCredKey and r.appCredKey == appkey):
                  ## ok, POST request matches rule .. now apply action
                  ##
                  if r.action == "ALLOW":
                     return (True, r.id, r.definition)
                  else:
                     return (False, r.id, r.definition)

      ## no rule matched, apply default rule action
      ##
      defaultAction = self.services["config"].get("postrule-default-action", "DENY")
      if defaultAction == "ALLOW":
         return (True, None, "global default")
      else:
         return (False, None, "global default")


   def _cacheRules(self, res):
      self.rules = [PostFilterRule(id = r[0],
                                   topicUri = r[1],
                                   matchByPrefix = r[2] != 0,
                                   filterIp = r[3] != 0,
                                   filterIpNetwork = IPNetwork(r[4]) if r[4] else None,
                                   requireSignature = r[5] != 0,
                                   appCredKey = r[6],
                                   action = r[7]) for r in res]

      log.msg("RestPusher._cacheRules (%d)" % len(self.rules))


   def _cacheAppCreds(self, res):
      self.appcreds = {}
      for r in res:
         self.appcreds[r[0]] = r[1]
      log.msg("RestPusher._cacheAppCreds (%d)" % len(self.appcreds))


   def recache(self, txn):
      log.msg("RestPusher.recache")

      txn.execute("SELECT r.id, r.topic_uri, r.match_by_prefix, r.filter_ip, r.filter_ip_network, r.require_signature, a.key, r.action FROM postrule r LEFT OUTER JOIN appcredential a ON r.require_appcred_id = a.id ORDER BY r.position ASC")
      self._cacheRules(txn.fetchall())

      txn.execute("SELECT key, secret FROM appcredential ORDER BY key")
      self._cacheAppCreds(txn.fetchall())

########NEW FILE########
__FILENAME__ = restremoter
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import urlparse

from twisted.python import log
#from twisted.web.client import getPage
from crossbar.txutil import getPage, StringReceiver, StringProducer, getDomain

from twisted.internet import defer
from twisted.internet.defer import Deferred, succeed
from twisted.web.http_headers import Headers

from autobahn.wamp import json_loads, json_dumps

from crossbar.adminwebmodule.uris import URI_ERROR_REMOTING
from crossbar.adminwebmodule.uris import URI_EVENT, URI_RESTREMOTE

from remoter import Remoter



class RestRemote:
   """
   Model for a single REST Remote.
   """

   def __init__(self,
                id,
                appkey,
                rpcBaseUri,
                restBaseUrl,
                payloadFormat,
                forwardCookies,
                redirectLimit,
                connectionTimeout,
                requestTimeout,
                usePersistentConnections,
                maxPersistentConnections,
                persistentConnectionTimeout):
      self.id = id
      self.appkey = appkey
      self.rpcBaseUri = rpcBaseUri
      self.restBaseUrl = restBaseUrl
      self.restDomain = getDomain(unicode(restBaseUrl))
      self.payloadFormat = payloadFormat
      self.forwardCookies = forwardCookies
      self.redirectLimit = redirectLimit
      self.connectionTimeout = connectionTimeout
      self.requestTimeout = requestTimeout
      self.usePersistentConnections = usePersistentConnections
      self.maxPersistentConnections = maxPersistentConnections
      self.persistentConnectionTimeout = persistentConnectionTimeout


class RestRemoter(Remoter):
   """
   Provides a model cache for REST remotes and actual RPC forwarding for REST.

   TODO: Cookies!
   """

   USER_AGENT = "crossbar.io"
   """
   User agent provided in HTTP header for requests issued.
   """

   SERVICENAME = "REST Remoter"

   REMOTE_ID_BASEURI = URI_RESTREMOTE

   REMOTER_STATE_CHANGE_EVENT_URI = URI_EVENT + "on-restremoter-statechange"
   STATS_EVENT_URI = URI_EVENT + "on-restremoterstat"


   def startService(self):
      Remoter.startService(self)

      ## HTTP connection pools indexed by Ext.Direct Remote ID.
      ## Note that we usually do NOT want to recreate those on mere recaches
      ## since that would unnecessarily drop all currently kept alive connections.
      self.httppools = {}

      ## immediately cache
      self.dbpool.runInteraction(self.recache)


   def recache(self, txn):
      """
      Recache REST Remotes.
      """
      log.msg("RestRemoter.recache")

      txn.execute("SELECT a.key, r.id, r.rpc_base_uri, r.rest_base_url, r.payload_format, r.forward_cookies, r.redirect_limit, r.connection_timeout, r.request_timeout, r.max_persistent_conns, r.persistent_conn_timeout FROM restremote r LEFT OUTER JOIN appcredential a ON r.require_appcred_id = a.id ORDER BY a.key ASC, r.created ASC")
      self._cacheRestRemotes(txn.fetchall())


   def _cacheRestRemotes(self, res):
      self.remotesByAppKey = {}
      self.remotesById = {}
      n = 0
      for r in res:
         appkey = str(r[0]) if r[0] is not None else None
         id = str(r[1])
         if not self.remotesByAppKey.has_key(appkey):
            self.remotesByAppKey[appkey] = []
         usePersistentConnections = int(r[7]) > 0
         remote = RestRemote(id = id,
                             appkey = appkey,
                             rpcBaseUri = str(r[2]),
                             restBaseUrl = str(r[3]),
                             payloadFormat = str(r[4]),
                             forwardCookies = r[5] != 0,
                             redirectLimit = int(r[6]),
                             connectionTimeout = int(r[7]),
                             requestTimeout = int(r[8]),
                             usePersistentConnections = usePersistentConnections,
                             maxPersistentConnections = int(r[9]),
                             persistentConnectionTimeout = int(r[10]))
         self.remotesByAppKey[appkey].append(remote)
         self.remotesById[id] = remote

         ## avoid module level reactor import
         from twisted.web.client import HTTPConnectionPool

         if usePersistentConnections:
            ## setup HTTP Connection Pool for remote
            if not self.httppools.has_key(id) or self.httppools[id] is None:
               self.httppools[id] = HTTPConnectionPool(self.reactor, persistent = True)
            self.httppools[id].maxPersistentPerHost = remote.maxPersistentConnections
            self.httppools[id].cachedConnectionTimeout = remote.persistentConnectionTimeout
            self.httppools[id].retryAutomatically = False
         else:
            ## make sure to GC existing pool (if any)
            self.httppools[id] = None

         n += 1
      log.msg("RestRemoter._cacheRestRemotes (%d)" % n)


   def getRemotes(self, authKey, authExtra):
      """
      Get remoted API calls. This is usually called within getAuthPermissions
      on a WAMP session.
      """
      d = {}
      for remote in self.remotesByAppKey.get(authKey, []):
         d.update(self.queryApi(remote.id))
      return succeed(('rest', d))


   def queryApi(self, remoteId):
      """
      Query REST API by remote ID.
      """
      remote = self.remotesById.get(remoteId, None)
      if remote is None:
         return None
      else:
         res = {remote.rpcBaseUri + "#create": [remote.id, 'PUT'],
                remote.rpcBaseUri + "#read": [remote.id, 'GET'],
                remote.rpcBaseUri + "#update": [remote.id, 'POST'],
                remote.rpcBaseUri + "#delete": [remote.id, 'DELETE']}
         return res


   def remoteCall(self, call):
      """
      RPC handler remoting to REST servers. This method is usually
      registered via registerHandlerMethodForRpc on a WAMP protocol.
      """
      proto = call.proto
      uri = call.uri
      args = call.args

      ## extract extra information from RPC call handler argument
      (id, method) = call.extra

      ## get the REST remote onto which we will forward the call
      remote = self.remotesById[id]

      body = None

      if method in ['GET', 'DELETE']:
         if len(args) != 1:
            raise Exception(URI_ERROR_REMOTING,
                            "Invalid number of arguments (expected 1, was %d)" % len(args))
      elif method in ['PUT', 'POST']:
         if len(args) != 2:
            raise Exception(URI_ERROR_REMOTING,
                            "Invalid number of arguments (expected 2, was %d)" % len(args))
         body = json_dumps(args[1])
      else:
         ## should not arrive here!
         raise Exception("logic error")

      if remote.forwardCookies and \
         proto.cookies and \
         proto.cookies.has_key(remote.restDomain) and \
         proto.cookies[remote.restDomain] != "":

         cookie = str(proto.cookies[remote.restDomain])
      else:
         cookie = None

      if type(args[0]) not in [str, unicode]:
         raise Exception(URI_ERROR_REMOTING,
                         "Invalid type for argument 1 (expected str, was %s)" % type(args[0]))

      url = urlparse.urljoin(str(remote.restBaseUrl), str(args[0]))

      if not remote.usePersistentConnections:
         ## Do HTTP/POST as individual request
         ##

         headers = {'Content-Type': 'application/json',
                    'User-Agent': RestRemoter.USER_AGENT}

         if cookie:
            headers['Cookie'] = cookie

         d = getPage(url = url,
                     method = method,
                     postdata = body,
                     headers = headers,
                     timeout = remote.requestTimeout,
                     connectionTimeout = remote.connectionTimeout,
                     followRedirect = remote.redirectLimit > 0)

      else:
         ## Do HTTP/POST via HTTP connection pool
         ##
         ## http://twistedmatrix.com/documents/12.1.0/web/howto/client.html
         ##

         ## avoid module level reactor import
         from twisted.web.client import Agent, RedirectAgent

         headers = {'Content-Type': ['application/json'],
                    'User-Agent': [RestRemoter.USER_AGENT]}

         if cookie:
            headers['Cookie'] = [cookie]

         agent = Agent(self.reactor,
                       pool = self.httppools[remote.id],
                       connectTimeout = remote.connectionTimeout)

         if remote.redirectLimit > 0:
            agent = RedirectAgent(agent, redirectLimit = remote.redirectLimit)

         ## FIXME: honor requestTimeout
         if body:
            d = agent.request(method,
                              url,
                              Headers(headers),
                              StringProducer(body))
         else:
            d = agent.request(method,
                              url,
                              Headers(headers))

         def onResponse(response):
            if response.code == 200:
               finished = Deferred()
               response.deliverBody(StringReceiver(finished))
               return finished
            else:
               return defer.fail("%s [%s]" % (response.code, response.phrase))

         d.addCallback(onResponse)

      ## request information provided as error detail in case of call fails
      remotingRequest = {'provider': 'rest',
                         'rest-base-url': remote.restBaseUrl,
                         'use-persistent-connections': remote.usePersistentConnections,
                         'request-timeout': remote.requestTimeout,
                         'connection-timeout': remote.connectionTimeout,
                         'method': method}

      d.addCallbacks(self._onRemoteCallResult,
                     self._onRemoteCallError,
                     callbackArgs = [remotingRequest],
                     errbackArgs = [remotingRequest])

      ## FIXME!
      d.addCallback(self.onAfterRemoteCallSuccess, id)
      d.addErrback(self.onAfterRemoteCallError, id)

      return d


   def _onRemoteCallResult(self, r, remotingRequest):
      """
      Consume REST remoting result. Note that this still can trigger a WAMP exception.
      """
      try:
         if len(r) > 0:
            res = json_loads(r)
            return res
         else:
            return None
      except Exception, e:
         raise Exception(URI_ERROR_REMOTING,
                         "response payload could not be decoded",
                        {'message': str(e),
                         'response': r,
                         'request': remotingRequest})


   def _onRemoteCallError(self, e, remotingRequest):
      """
      Consume REST remoting error.
      """
      raise Exception(URI_ERROR_REMOTING,
                      "RPC could not be remoted",
                      {'message': e.getErrorMessage(),
                       'request': remotingRequest})

########NEW FILE########
__FILENAME__ = choosereactor
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

__all__ = ['install_optimal_reactor','install_reactor']


def install_optimal_reactor():
   """
   Try to install the optimal Twisted reactor for platform.
   """
   import sys

   if 'bsd' in sys.platform or sys.platform.startswith('darwin'):
      try:
         v = sys.version_info
         if v[0] == 1 or (v[0] == 2 and v[1] < 6) or (v[0] == 2 and v[1] == 6 and v[2] < 5):
            raise Exception("Python version too old (%s)" % sys.version)
         from twisted.internet import kqreactor
         kqreactor.install()
      except Exception, e:
         print """
   WARNING: Running on BSD or Darwin, but cannot use kqueue Twisted reactor.

    => %s

   To use the kqueue Twisted reactor, you will need:

     1. Python >= 2.6.5 or PyPy > 1.8
     2. Twisted > 12.0

   Note the use of >= and >.

   Will let Twisted choose a default reactor (potential performance degradation).
   """ % str(e)
         pass

   if sys.platform in ['win32']:
      try:
         from twisted.application.reactors import installReactor
         installReactor("iocp")
      except Exception, e:
         print """
   WARNING: Running on Windows, but cannot use IOCP Twisted reactor.

    => %s

   Will let Twisted choose a default reactor (potential performance degradation).
   """ % str(e)

   if sys.platform.startswith('linux'):
      try:
         from twisted.internet import epollreactor
         epollreactor.install()
      except Exception, e:
         print """
   WARNING: Running on Linux, but cannot use Epoll Twisted reactor.

    => %s

   Will let Twisted choose a default reactor (potential performance degradation).
   """ % str(e)



def install_reactor(_reactor = None, verbose = False):
   """
   Install Twisted reactor. This is used from CLI.
   """
   import sys

   if _reactor:
      ## install explicitly given reactor
      ##
      from twisted.application.reactors import installReactor
      print "Trying to install explicitly specified Twisted reactor '%s'" % _reactor
      try:
         installReactor(_reactor)
      except Exception, e:
         print "Could not install Twisted reactor %s%s" % (_reactor, ' ["%s"]' % e if verbose else '')
         sys.exit(1)
   else:
      ## automatically choose optimal reactor
      ##
      if verbose:
         print "Automatically choosing optimal Twisted reactor"
      install_optimal_reactor()

   ## now the reactor is installed, import it
   from twisted.internet import reactor

   if verbose:
      from twisted.python.reflect import qual
      print "Running Twisted reactor %s" % qual(reactor.__class__)

   return reactor

########NEW FILE########
__FILENAME__ = cli
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

__all__ = ['run']


import sys, json, argparse, pkg_resources, logging
from pprint import pprint

from twisted.python import log
from twisted.internet.defer import Deferred, returnValue, inlineCallbacks

from autobahn.websocket import connectWS
from autobahn.wamp import WampClientFactory, WampCraClientProtocol



def tabify(fields, formats, truncate = 120, filler = ['-', '+']):
   """
   Tabified output formatting.
   """

   ## compute total length of all fields
   ##
   totalLen = 0
   flexIndicators = 0
   flexIndicatorIndex = None
   for i in xrange(len(formats)):
      ffmt = formats[i][1:]
      if ffmt != "*":
         totalLen += int(ffmt)
      else:
         flexIndicators += 1
         flexIndicatorIndex = i

   if flexIndicators > 1:
      raise Exception("more than 1 flex field indicator")

   ## reserve space for column separators (" | " or " + ")
   ##
   totalLen += 3 * (len(formats) - 1)

   if totalLen > truncate:
      raise Exception("cannot fit content in truncate length %d" % truncate)

   r = []
   for i in xrange(len(formats)):

      if i == flexIndicatorIndex:
         N = truncate - totalLen
      else:
         N = int(formats[i][1:]) 

      if fields:
         s = str(fields[i])
         if len(s) > N:
            s = s[:N-2] + ".."
         l = N - len(s)
         m = formats[i][0]
      else:
         s = ''
         l = N
         m = '+'

      if m == 'l':
         r.append(s + ' ' * l)
      elif m == 'r':
         r.append(' ' * l + s)
      elif m == 'c':
         c1 = l / 2
         c2 = l - c1
         r.append(' ' * c1 + s + ' ' * c2)
      elif m == '+':
         r.append(filler[0] * l)
      else:
         raise Exception("invalid field format")

   if m == '+':
      return (filler[0] + filler[1] + filler[0]).join(r)
   else:
      return ' | '.join(r)



def run_command_version(options):
   """
   Print local Crossbar.io software component types and versions.
   """
   from choosereactor import install_reactor
   reactor = install_reactor(options.reactor, options.verbose)

   from twisted.python.reflect import qual

   ## Python
   ##
   py_ver = '.'.join([str(x) for x in list(sys.version_info[:3])])
   if options.verbose:
      py_ver += " [%s]" % sys.version.replace('\n', ' ')

   ## Twisted / Reactor
   ##
   tx_ver = "%s-%s" % (pkg_resources.require("Twisted")[0].version, reactor.__class__.__name__)
   if options.verbose:
      tx_ver += " [%s]" % qual(reactor.__class__)

   ## Autobahn
   ##
   import autobahn
   from autobahn.websocket import WebSocketProtocol
   ab_ver = pkg_resources.require("autobahn")[0].version
   if options.verbose:
      ab_ver += " [%s]" % qual(WebSocketProtocol)

   ## UTF8 Validator
   ##
   from autobahn.utf8validator import Utf8Validator
   s = str(Utf8Validator)
   if 'wsaccel' in s:
      utf8_ver = 'wsaccel-%s' % pkg_resources.require('wsaccel')[0].version
   elif s.startswith('autobahn'):
      utf8_ver = 'autobahn'
   else:
      raise Exception("could not detect UTF8 validator type/version")
   if options.verbose:
      utf8_ver += " [%s]" % qual(Utf8Validator)

   ## XOR Masker
   ##
   from autobahn.xormasker import XorMaskerNull
   s = str(XorMaskerNull)
   if 'wsaccel' in s:
      xor_ver = 'wsaccel-%s' % pkg_resources.require('wsaccel')[0].version
   elif s.startswith('autobahn'):
      xor_ver = 'autobahn'
   else:
      raise Exception("could not detect XOR masker type/version")
   if options.verbose:
      xor_ver += " [%s]" % qual(XorMaskerNull)

   ## JSON Processor
   ##
   s = str(autobahn.wamp.json_lib.__name__)
   if 'ujson' in s:
      json_ver = 'ujson-%s' % pkg_resources.require('ujson')[0].version
      import ujson
      if options.verbose:
         json_ver += " [%s]" % qual(ujson.dumps)
   elif s.startswith('json'):
      json_ver = 'python'
   else:
      raise Exception("could not detect JSON processor type/version")
   
   print
   print "Crossbar.io local component versions:"
   print
   print "Python          : %s" % py_ver
   print "Twisted         : %s" % tx_ver
   print "Autobahn        : %s" % ab_ver
   print "UTF8 Validator  : %s" % utf8_ver
   print "XOR Masker      : %s" % xor_ver
   print "JSON Processor  : %s" % json_ver
   print



class CrossbarCLIProtocol(WampCraClientProtocol):

   def connectionMade(self):
      if self.factory.options.verbose:
         sys.stdout.write(" .. (1) connected ..")

      WampCraClientProtocol.connectionMade(self)


   def onSessionOpen(self):
      if self.factory.options.verbose:
         sys.stdout.write(" (2) session opened ..")

      d = self.authenticate(authKey = self.factory.options.user,
                            authSecret = self.factory.options.password)
      d.addCallbacks(self.onAuthSuccess, self.onAuthError)


   def onClose(self, wasClean, code, reason):
      try:
         self.factory.reactor.stop()
      except:
         pass


   def onAuthSuccess(self, permissions):
      if self.factory.options.verbose:
         sys.stdout.write(" (3) authenticated. Ok.\n\n")

      self.prefix("api", "http://crossbar.io/api#");
      self.prefix("error", "http://crossbar.io/error#");
      self.prefix("event", "http://crossbar.io/event#");
      self.prefix("wiretap", "http://crossbar.io/event/wiretap#");

      CMDS = {'restart': self.cmd_restart,
              'log': self.cmd_log,
              'status': self.cmd_status,
              'watch': self.cmd_watch,
              'config': self.cmd_config,
              'modify': self.cmd_modify,
              'scratchdb': self.cmd_scratchdb,
              'scratchweb': self.cmd_scratchweb,
              'connect': self.cmd_connect,
              'wiretap': self.cmd_wiretap}

      if CMDS.has_key(self.factory.options.command):
         CMDS[self.factory.options.command]()
      else:
         self.factory.done = True
         raise Exception("unknown command '%s'" % self.factory.options.command)


   def onAuthError(self, e):
      uri, desc, details = e.value.args
      if not self.factory.options.json:
         print
         print "Error: authentication failed [%s]" % desc
      self.factory.done = True
      self.sendClose()


   BRIDGENAME = {'ora': 'Oracle',
                 'pg': 'PostgreSQL',
                 'hana': 'SAP HANA',
                 'rest': 'REST',
                 'extdirect': 'Ext.Direct'}

   REMOTERSTATMAP = {'oraremoterstat': 'ora',
                     'pgremoterstat': 'pg',
                     'hanaremoterstat': 'hana',
                     'restremoterstat': 'rest',
                     'extdirectremoterstat': 'extdirect'}

   PUSHERSTATMAP = {'orapusherstat': 'ora',
                    'pgpusherstat': 'pg',
                    'hanapusherstat': 'hana',
                    'restpusherstat': 'rest'}


   def _onremoterstat(self, topic, event):
      z = topic.split('-')[-1]
      for e in event:
         if e['uri'] is None:
            m = CrossbarCLIProtocol.BRIDGENAME[CrossbarCLIProtocol.REMOTERSTATMAP[z]] + " Remoter"
            print m.ljust(20), e


   def _onpusherstat(self, topic, event):
      z = topic.split('-')[-1]
      for e in event:
         if e['uri'] is None:
            m = CrossbarCLIProtocol.BRIDGENAME[CrossbarCLIProtocol.PUSHERSTATMAP[z]] + " Pusher"
            print m.ljust(20), e


   def cmd_watch(self):
      for k in CrossbarCLIProtocol.REMOTERSTATMAP:
         self.subscribe("event:on-%s" % k, self._onremoterstat)
      for k in CrossbarCLIProtocol.PUSHERSTATMAP:
         self.subscribe("event:on-%s" % k, self._onpusherstat)


   @inlineCallbacks
   def cmd_status(self):
      """
      'status' command.
      """
      res = {}
      for t in ['remoter', 'pusher']:
         res[t] = {}
         for s in ['ora', 'pg', 'hana', 'rest']:
            res[t][s] = {}
            try:
               rr = yield self.call("api:get-%s%sstats" % (s, t))
               for r in rr:
                  if r['uri'] is None:
                     for k in r:
                        if k != 'uri':
                           res[t][s][k] = r[k]
            except Exception, e:
               pass
      if self.factory.options.json:
         print json.dumps(res)
      else:

         LINELENGTH = 118

         print
         print tabify(['Crossbar.io Status'], ['c97'], LINELENGTH)
         print

         cnames = {'ora': 'Oracle', 'rest': 'REST', 'pg': 'PostgreSQL', 'hana': 'SAP HANA'}

         LINEFORMAT = ['l15', 'c41', 'c41']
         print tabify(None, LINEFORMAT, LINELENGTH)
         print tabify(['',
                       'PubSub',
                       'RPC',
                       ], LINEFORMAT, LINELENGTH)

         LINEFORMAT = ['l15', 'c19', 'c19', 'c19', 'c19']
         print tabify(None, LINEFORMAT, LINELENGTH)

         print tabify(['',
                       'Publish',
                       'Dispatch',
                       'Call',
                       'Forward',
                       ], LINEFORMAT, LINELENGTH)

         LINEFORMAT = ['l15']
         for i in xrange(8):
            LINEFORMAT.append('c8')
         print tabify(None, LINEFORMAT, LINELENGTH)

         print tabify(['',
                       'allowed',
                       'denied',
                       'success',
                       'failed',
                       'allowed',
                       'denied',
                       'success',
                       'failed',
                       ], LINEFORMAT, LINELENGTH)
         print tabify(None, LINEFORMAT, LINELENGTH)

         LINEFORMAT = ['l15']
         for i in xrange(8):
            LINEFORMAT.append('r8')

         for s in ['rest', 'ora', 'pg']:
#         for s in ['rest', 'pg', 'ora', 'hana']:
            dp = res['pusher'][s]
            dr = res['remoter'][s]
            print tabify([cnames[s],
                         dp['publish-allowed'],
                         dp['publish-denied'],
                         dp['dispatch-success'],
                         dp['dispatch-failed'],
                         dr['call-allowed'],
                         dr['call-denied'],
                         dr['forward-success'],
                         dr['forward-failed'],
                         ], LINEFORMAT, LINELENGTH)
         print tabify(None, LINEFORMAT, LINELENGTH)
         print

      self.factory.done = True
      self.sendClose()


   def cmd_connect(self):
      """
      'connect' command.
      """
      print "Crossbar is alive!"
      self.factory.done = True
      self.sendClose()


   @inlineCallbacks
   def cmd_restart(self):
      """
      'restart' command.
      """
      if not self.factory.options.json:
         print "Restarting Crossbar.io .."

      res = yield self.call("api:restart")


   @inlineCallbacks
   def cmd_scratchdb(self):
      """
      'scratchdb' command.
      """
      restart = self.factory.options.restart
      if not self.factory.options.json:
         if restart:
            print "Scratching service database and immediate restarting .."
         else:
            print "Scratching service database .."

      res = yield self.call("api:scratch-database", restart)

      if not self.factory.options.json:
         print "Service database initialized to factory default."
         if not restart:
            print "You must restart Crossbar.io for settings to become effective."
      else:
         print json.dumps(res)

      if not restart:
         self.factory.done = True
         self.sendClose()


   @inlineCallbacks
   def cmd_scratchweb(self):
      """
      'scratchweb' command.
      """
      demoinit = self.factory.options.demoinit

      if not self.factory.options.json:
         print "Scratching Web directory .."

      res = yield self.call("api:scratch-webdir", demoinit)

      if not self.factory.options.json:
         if demoinit:
            print "Scratched Web directory and copied %d files (%d bytes)." % (res[0], res[1])
         else:
            print "Scratched Web directory."
      else:
         print json.dumps(res)

      self.factory.done = True
      self.sendClose()


   @inlineCallbacks
   def cmd_log(self):
      """
      'log' command.
      """
      def _printlog(self, logobj):
         if self.factory.options['json']:
            print json.dumps(logobj)
         else:
            lineno, timestamp, logclass, logmodule, message = logobj
            print str(lineno).zfill(6), timestamp, logclass.ljust(7), (logmodule + ": " if logmodule.strip() != "-" else "") + message

      def _onlog(self, topic, event):
         _printlog(event)

      try:
         limit = int(self.factory.options['limit'])
      except:
         limit = 0
      self.subscribe("event:on-log", _onlog)
      res = yield self.call("api:get-log", limit)
      for l in res:
         _printlog(l)


   @inlineCallbacks
   def cmd_wiretap(self):
      """
      'wiretap' command.

      session.call("http://api.wamp.ws/procedure#echo", "hello").then(ab.log, ab.log);
      """

      def _onwiretap(topic, event):
         print topic, event

      sessionid = self.factory.options.sessionid
      topic = "wiretap:%s" % sessionid
      self.subscribe(topic, _onwiretap)
      r = yield self.call("api:set-wiretap-mode", sessionid, True)
      print "listening on", topic


   @inlineCallbacks
   def cmd_config(self):
      """
      'config' command
      """
      ctype = self.factory.options.type

      if ctype == 'settings':
         res = yield self.call("api:get-config")

      elif ctype == 'appcreds':
         res = yield self.call("api:get-appcreds")

      elif ctype == 'clientperms':
         res = yield self.call("api:get-clientperms")

      elif ctype == 'postrules':
         res = yield self.call("api:get-postrules")

      elif ctype == 'extdirectremotes':
         res = yield self.call("api:get-extdirectremotes")

      elif ctype == 'oraconnects':
         res = yield self.call("api:get-oraconnects")

      elif ctype == 'orapushrules':
         res = yield self.call("api:get-orapushrules")

      elif ctype == 'oraremotes':
         res = yield self.call("api:get-oraremotes")

      else:
         raise Exception("logic error")

      pprint(res)

      self.factory.done = True
      self.sendClose()


   @inlineCallbacks
   def cmd_modify(self):
      """
      'modify' command
      """
      config = json.loads(open(self.factory.options.config).read())
      restart = self.factory.options.restart

      if config.has_key('settings'):
         r = yield self.call("api:modify-config", config['settings'])
         pprint(r)

      if config.has_key('appcreds'):
         appcreds = yield self.call("api:get-appcreds")
         for ac in appcreds:
            print "dropping application credential", ac['uri']
            r = yield self.call("api:delete-appcred", ac['uri'], True)
         for id, ac in config['appcreds'].items():
            r = yield self.call("api:create-appcred", ac)
            config['appcreds'][id] = r
            print "application credential created:"
            pprint(r)

      if config.has_key('clientperms'):
         clientperms = yield self.call("api:get-clientperms")
         for cp in clientperms:
            print "dropping client permission ", cp['uri']
            r = yield self.call("api:delete-clientperm", cp['uri'])
         for id, cp in config['clientperms'].items():
            if cp["require-appcred-uri"] is not None:
               k = cp["require-appcred-uri"]
               cp["require-appcred-uri"] = config['appcreds'][k]['uri']
            r = yield self.call("api:create-clientperm", cp)
            config['clientperms'][id] = r
            print "client permission created:"
            pprint(r)

      if config.has_key('postrules'):
         postrules = yield self.call("api:get-postrules")
         for pr in postrules:
            print "dropping post rule", pr['uri']
            r = yield self.call("api:delete-postrule", pr['uri'])
         for id, pr in config['postrules'].items():
            if pr["require-appcred-uri"] is not None:
               k = pr["require-appcred-uri"]
               pr["require-appcred-uri"] = config['appcreds'][k]['uri']
            r = yield self.call("api:create-postrule", pr)
            config['postrules'][id] = r
            print "post rule created:"
            pprint(r)

      if config.has_key('extdirectremotes'):
         extdirectremotes = yield self.call("api:get-extdirectremotes")
         for er in extdirectremotes:
            print "dropping ext.direct remote", er['uri']
            r = yield self.call("api:delete-extdirectremote", er['uri'])
         for id, er in config['extdirectremotes'].items():
            if er["require-appcred-uri"] is not None:
               k = er["require-appcred-uri"]
               er["require-appcred-uri"] = config['appcreds'][k]['uri']
            r = yield self.call("api:create-extdirectremote", er)
            config['extdirectremotes'][id] = r
            print "ext.direct remote created:"
            pprint(r)

      if config.has_key('oraconnects'):
         oraconnects = yield self.call("api:get-oraconnects")
         for oc in oraconnects:
            print "dropping Oracle connect", oc['uri']
            r = yield self.call("api:delete-oraconnect", oc['uri'], True)
         for id, oc in config['oraconnects'].items():
            r = yield self.call("api:create-oraconnect", oc)
            config['oraconnects'][id] = r
            print "Oracle connect created:"
            pprint(r)

      if config.has_key('orapushrules'):
         orapushrules = yield self.call("api:get-orapushrules")
         for op in orapushrules:
            print "dropping Oracle publication rule", op['uri']
            r = yield self.call("api:delete-orapushrule", op['uri'])
         for id, op in self.factory.config['orapushrules'].items():
            if op["oraconnect-uri"] is not None:
               k = op["oraconnect-uri"]
               op["oraconnect-uri"] = config['oraconnects'][k]['uri']
            r = yield self.call("api:create-orapushrule", op)
            config['orapushrules'][id] = r
            print "Oracle publication rule created:"
            pprint(r)

      if config.has_key('oraremotes'):
         oraremotes = yield self.call("api:get-oraremotes")
         for om in oraremotes:
            print "dropping Oracle remote", om['uri']
            r = yield self.call("api:delete-oraremote", om['uri'])
         for id, om in config['oraremotes'].items():
            if om["oraconnect-uri"] is not None:
               k = om["oraconnect-uri"]
               om["oraconnect-uri"] = config['oraconnects'][k]['uri']
            if om["require-appcred-uri"] is not None:
               k = om["require-appcred-uri"]
               om["require-appcred-uri"] = config['appcreds'][k]['uri']
            r = yield self.call("api:create-oraremote", om)
            config['oraremotes'][id] = r
            print "Oracle remote created:"
            pprint(r)

      self.factory.done = True
      self.sendClose()



class CrossbarCLIFactory(WampClientFactory):

   protocol = CrossbarCLIProtocol

   def __init__(self, options, reactor):
      self.options = options
      self.done = False
      WampClientFactory.__init__(self,
                                 self.options.server,
                                 debugWamp = self.options.debug)


   def startedConnecting(self, connector):
      if self.options.verbose:
         print
         print "Connecting to Crossbar.io instance as '%s' at %s .." % (self.options.user, self.options.server)


   def _maybeReconnect(self, phase, connector, reason):
      plog = self.options.verbose or phase == 'failed' or not self.done

      if plog:
         print 'Connection %s [%s]' % (phase, reason.value)

      if self.done:
         if plog:
            print "Done"
         try:
            self.reactor.stop()
         except:
            pass
      else:
         if self.options.reconnect > 0:
            if plog:
               print "Retrying in %s seconds" % self.options.reconnect
            self.reactor.callLater(self.options.reconnect, connector.connect)
         else:
            if plog:
               print "Giving up"
            try:
               self.reactor.stop()
            except:
               pass


   def clientConnectionLost(self, connector, reason):
      self._maybeReconnect('lost', connector, reason)


   def clientConnectionFailed(self, connector, reason):
      self._maybeReconnect('failed', connector, reason)



def run_admin_command(options):
   """
   Monitor a Crossbar.io server.
   """
   from choosereactor import install_reactor
   reactor = install_reactor(options.reactor, options.verbose)

   factory = CrossbarCLIFactory(options, reactor)
   connectWS(factory)
   reactor.run()



def run_command_start(options):
   """
   Start Crossbar.io server.
   """
   from choosereactor import install_reactor
   reactor = install_reactor(options.reactor, options.verbose)

   import twisted
   from crossbar import logger

   if False:
      twisted.python.log.startLogging(sys.stdout)
   else:
      flo = logger.LevelFileLogObserver(sys.stdout, level = logging.DEBUG)
      twisted.python.log.startLoggingWithObserver(flo.emit)

   from crossbar.servicefactory import makeService

   svc = makeService(vars(options))
   svc.startService()

   installSignalHandlers = True
   reactor.run(installSignalHandlers)



def run():
   """
   Entry point of installed Crossbar.io tool.
   """
   ## create the top-level parser
   ##
   parser = argparse.ArgumentParser(prog = 'crossbar',
                                    description = "Crossbar.io multi-protocol application router")

   ## top-level options
   ##
   parser.add_argument('-d',
                       '--debug',
                       action = 'store_true',
                       help = 'Debug on.')

   parser.add_argument('--reactor',
                       default = None,
                       choices = ['select', 'poll', 'epoll', 'kqueue', 'iocp'],
                       help = 'Explicit Twisted reactor selection')

   ## output format
   ##
   output_format_dummy = parser.add_argument_group(title = 'Output format control')
   output_format = output_format_dummy.add_mutually_exclusive_group(required = False)

   output_format.add_argument('-v',
                              '--verbose',
                              action = 'store_true',
                              help = 'Verbose (human) output on.')

   output_format.add_argument('-j',
                              '--json',
                              action = 'store_true',
                              help = 'Turn JSON output on.')

   ## create subcommand parser
   ##
   subparsers = parser.add_subparsers(dest = 'command',
                                      title = 'commands',
                                      help = 'Crossbar.io command to run')

   ## "version" command
   ##
   parser_version = subparsers.add_parser('version',
                                          help = 'Print software component versions.')

   parser_version.set_defaults(func = run_command_version)


   ## "start" command
   ##
   parser_start = subparsers.add_parser('start',
                                        help = 'Start a new server process.')

   parser_start.set_defaults(func = run_command_start)

   parser_start.add_argument('--cbdata',
                             type = str,
                             default = None,
                             help = "Data directory (overrides ${CROSSBAR_DATA} and default ./cbdata)")

   parser_start.add_argument('--cbdataweb',
                             type = str,
                             default = None,
                             help = "Web directory (overrides ${CROSSBAR_DATA_WEB} and default CBDATA/web)")

   parser_start.add_argument('--loglevel',
                              type = str,
                              default = 'info',
                              choices = ['trace', 'debug', 'info', 'warn', 'error', 'fatal'],
                              help = "Server log level (overrides default 'info')")

   def add_common_admin_command_arguments(_parser):
      _parser.add_argument('--reconnect',
                           default = 0,
                           type = int,
                           help = 'Reconnect interval in seconds or 0.')

      _parser.add_argument('-s',
                           '--server',
                           type = str,
                           default = 'ws://127.0.0.1:9000',
                           help = 'Administration endpoint WebSocket URI.')

      _parser.add_argument('-u',
                           '--user',
                           type = str,
                           default = 'admin',
                           help = 'User name.')

      _parser.add_argument('-p',
                           '--password',
                           type = str,
                           help = 'Password.')

   ## "status" command
   ##
   parser_status = subparsers.add_parser('status',
                                         help = 'Get server status.')

   add_common_admin_command_arguments(parser_status)
   parser_status.set_defaults(func = run_admin_command)


   ## "watch" command
   ##
   parser_watch = subparsers.add_parser('watch',
                                        help = 'Watch a server.')

   add_common_admin_command_arguments(parser_watch)
   parser_watch.set_defaults(func = run_admin_command)


   ## "restart" command
   ##
   parser_restart = subparsers.add_parser('restart',
                                          help = 'Restart a server.')

   add_common_admin_command_arguments(parser_restart)
   parser_restart.set_defaults(func = run_admin_command)


   ## "scratchdb" command
   ##
   parser_scratchdb = subparsers.add_parser('scratchdb',
                                            help = 'Scratch service database.')

   add_common_admin_command_arguments(parser_scratchdb)

   parser_scratchdb.add_argument('--restart',
                                 action = 'store_true',
                                 help = 'Immediately perform a restart.')

   parser_scratchdb.set_defaults(func = run_admin_command)


   ## "scratchweb" command
   ##
   parser_scratchweb = subparsers.add_parser('scratchweb',
                                             help = 'Scratch Web directory.')

   add_common_admin_command_arguments(parser_scratchweb)

   parser_scratchweb.add_argument('--demoinit',
                                  action = 'store_true',
                                  help = 'Initialize Web directory with demo content.')

   parser_scratchweb.set_defaults(func = run_admin_command)


   ## "wiretap" command
   ##
   parser_wiretap = subparsers.add_parser('wiretap',
                                          help = 'Wiretap a WAMP session.')

   add_common_admin_command_arguments(parser_wiretap)

   parser_wiretap.add_argument('--sessionid',
                               type = str,
                               help = 'WAMP session ID.')

   parser_wiretap.set_defaults(func = run_admin_command)


   ## "config" command
   ##
   parser_config = subparsers.add_parser('config',
                                         help = 'Get service configuration.')

   parser_config.add_argument('--type',
                              required = True,
                              choices = ['settings',
                                         'appcreds',
                                         'clientperms',
                                         'postrules',
                                         'oraconnects',
                                         'oraremotes',
                                         'orapushrules'],
                              help = 'Configuration type to retrieve.')

   add_common_admin_command_arguments(parser_config)

   parser_config.set_defaults(func = run_admin_command)


   ## "modify" command
   ##
   parser_modify = subparsers.add_parser('modify',
                                         help = 'Change service configuration.')

   add_common_admin_command_arguments(parser_modify)

   parser_modify.add_argument('--config',
                              type = str,
                              help = 'Service configuration filename.')

   parser_modify.add_argument('--restart',
                              action = 'store_true',
                              help = 'Immediately perform a restart.')

   parser_modify.set_defaults(func = run_admin_command)


   ## parse cmd line args
   ##
   options = parser.parse_args()


   ## run the subcommand selected
   ##
   options.func(options)



if __name__ == '__main__':
   run()

########NEW FILE########
__FILENAME__ = clientfilter
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import hmac, hashlib, base64, binascii, json

from twisted.python import log
from twisted.application import service
from twisted.enterprise import adbapi

from netaddr.ip import IPAddress, IPNetwork

from autobahn.wamp import WampServerProtocol


class ClientFilterPerm:

   def __init__(self,
                id,
                topicUri,
                matchByPrefix,
                filterExpr,
                allowPublish,
                allowSubscribe):
      self.id = id
      self.topicUri = topicUri
      self.matchByPrefix = matchByPrefix
      self.filterExpr = filterExpr
      self.allowPublish = allowPublish
      self.allowSubscribe = allowSubscribe



class ClientFilter(service.Service):

   SERVICENAME = "Client authentication"


   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)
      self.dbpool.runInteraction(self.recache)
      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      self.isRunning = False


   def getAppSecret(self, appkey):
      """
      Get application secret for application key or None if application key does not exist.
      """
      return self.appcreds.get(appkey, None)


   def getPermissions(self, appkey, extra, skipOnErrs = False):
      """
      Return client permissions by application key.
      """
      ret = []
      if self.perms.has_key(appkey):
         for r in self.perms[appkey]:

            #print r.topicUri, r.allowPublish, r.allowSubscribe, r.filterExpr

            try:
               topic_uri = r.topicUri % extra
            except KeyError, e:
               emsg = "unbound variable in %s (%s)" % (r.topicUri, e)
               if skipOnErrs:
                  log.msg(emsg)
               else:
                  raise Exception(emsg)
            else:

               ## apply filter expression
               ##
               permit = False
               if r.filterExpr is not None and r.filterExpr.strip() != "":

                  try:
                     ## FIXME: make this more secure ..
                     ## => ast.literal_eval (but this does not allow for boolean expressions ..)
                     ##
                     a = eval(r.filterExpr, {'__builtins__': []}, extra)
                  except Exception, e:
                     emsg = "filter expression invalid or unbound variables (%s)" % e
                     if skipOnErrs:
                        log.msg(emsg)
                     else:
                        raise Exception(emsg)

                  if type(a) == bool:
                     permit = a
                  else:
                     emsg = "filter expression returned non-boolean type (%s)" % type(a)
                     if skipOnErrs:
                        log.msg(emsg)
                     else:
                        raise Exception(emsg)
               else:
                  permit = True

               ## append topic if not filtered
               ##
               if permit:
                  ret.append({"uri": topic_uri,
                              "prefix": r.matchByPrefix,
                              "pub": r.allowPublish,
                              "sub": r.allowSubscribe})
      return ret


   def _cachePerms(self, res):
      self.perms = {}
      n = 0
      for r in res:
         if not self.perms.has_key(r[0]):
            self.perms[r[0]] = []
         perm = ClientFilterPerm(id = r[1],
                                 topicUri = r[2],
                                 matchByPrefix = r[3] != 0,
                                 filterExpr = r[4],
                                 allowPublish = r[5] != 0,
                                 allowSubscribe = r[6] != 0)
         self.perms[r[0]].append(perm)
         n += 1
      log.msg("ClientFilter._cachePerms (%d)" % n)


   def _cacheAppCreds(self, res):
      self.appcreds = {}
      for r in res:
         self.appcreds[r[0]] = str(r[1])
      log.msg("ClientFilter._cacheAppCreds (%d)" % len(self.appcreds))


   def recache(self, txn):
      log.msg("ClientFilter.recache")

      txn.execute("SELECT a.key, r.id, r.topic_uri, r.match_by_prefix, r.filter_expr, r.allow_publish, r.allow_subscribe FROM clientperm r LEFT OUTER JOIN appcredential a ON r.require_appcred_id = a.id ORDER BY a.key ASC, LENGTH(r.topic_uri) ASC, r.topic_uri ASC")
      self._cachePerms(txn.fetchall())

      txn.execute("SELECT key, secret FROM appcredential ORDER BY key")
      self._cacheAppCreds(txn.fetchall())

########NEW FILE########
__FILENAME__ = config
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import sqlite3

from twisted.python import log
from twisted.application import service

from autobahn.wamp import json_loads


class Config(service.Service):

   SERVICENAME = "Configuration cache"


   def __init__(self, dbpool, services):
      self.dbpool = dbpool
      self.services = services
      self.isRunning = False

      self._config = self.services["database"].getConfig(includeTls = True)
      return

      ## when instantiated, we do the caching synchronously!
      if True:
         db = sqlite3.connect(self.services["database"].dbfile)
         cur = db.cursor()
         cur.execute("SELECT key, value FROM config ORDER BY key")
         res = cur.fetchall()
         self._cacheConfig(res)
      else:
         self.dbpool.runInteraction(self.recache)


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)
      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      self.isRunning = False


   def get(self, key, default = None):
      return self._config.get(key, default)


   def __getitem__(self, key):
      return self._config.get(key, None)


   def _cacheConfig(self, res):
      self._config = {}
      for r in res:
         self._config[r[0]] = json_loads(r[1])
      log.msg("Config._cacheConfig (%d)" % len(self._config))


   def recache(self, txn):
      log.msg("Config.recache")

      txn.execute("SELECT key, value FROM config ORDER BY key")
      self._cacheConfig(txn.fetchall())

########NEW FILE########
__FILENAME__ = cryptoutil
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import os, binascii, hashlib

from Crypto.PublicKey import RSA
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes
from Crypto.Util import Counter
from Crypto.Util.number import long_to_bytes, bytes_to_long

## We use fixed AES-256-CTR mode!
##
CIPHERBITS = 256

## PKCS-5 padding for AES
##
BS = 16
pad = lambda s: s + (BS - len(s) % BS) * chr(BS - len(s) % BS)
unpad = lambda s : s[0:-ord(s[-1])]


# For AES-CTR encrypt/decrypt using PyCrypto, see:
# https://bugs.launchpad.net/pycrypto/+bug/899818


def encrypt_and_sign(msg,
                     senderPrivPem,
                     receiverPubPem):
   """
   Encrypts a message using AES256-CTR. The procedure first creates a new
   random key/nonce for symmetric encryption and encrypt/signs that via RSA.
   The procedure then symmatrically encrypts the actual message using that key/nonce.

   :param msg: Message to be encrypted.
   :type msg: str
   :param senderPrivPem: Sender private RSA key in PEM format.
   :type senderPrivPem: str
   :param receiverPubPem: Receiver public RSA key in PEM format.
   :type receiverPubPem: str
   :returns tuple -- (AES256-CTR encrypted message, RSA Encrypted Key+IV, RSA Signature) all Base64 encoded.
   """
   ## read in sender/receiver RSA keys
   ##
   skey = RSA.importKey(senderPrivPem)
   rkey = RSA.importKey(receiverPubPem)

   ## create new random key/nonce for AES
   ##
   key = get_random_bytes(CIPHERBITS/8)
   nonce = get_random_bytes(8)
   kv = key + nonce

   #print binascii.b2a_hex(kv)
   #print binascii.b2a_hex(key)
   #print binascii.b2a_hex(nonce)

   ## encrypt key/nonce using RSA
   ##
   emsg = rkey.encrypt(kv, 0)[0]

   ## encrypt msg using AES-256 in CTR mode
   ##
   c = AES.new(key, AES.MODE_CTR, counter = Counter.new(64, prefix = nonce))
   pmsg = c.encrypt(pad(msg))

   ## create a digest of the unencrypted message
   ##
   md = hashlib.sha256()
   md.update(msg)
   dmsg = md.digest()

   ## create a RSA signature over encrypted message + key/nonce
   ##
   ed = hashlib.sha256()
   ed.update(pmsg)
   ed.update(emsg)
   sig = long_to_bytes(skey.sign(ed.digest(), 0)[0])

   return (binascii.b2a_base64(pmsg).strip(),
           binascii.b2a_base64(emsg).strip(),
           binascii.b2a_base64(dmsg).strip(),
           binascii.b2a_base64(sig).strip())



def verify_and_decrypt(pmsg,
                       emsg,
                       dmsg,
                       sig,
                       senderPubPem,
                       receiverPrivPem):
   """

   """
   ## read in sender/receiver RSA keys
   ##
   skey = RSA.importKey(senderPubPem)
   rkey = RSA.importKey(receiverPrivPem)

   ## Base64 decode payloads
   ##
   pmsg = binascii.a2b_base64(pmsg)
   emsg = binascii.a2b_base64(emsg)
   dmsg = binascii.a2b_base64(dmsg)
   sig = binascii.a2b_base64(sig)

   ## verify RSA signature
   ##
   md = hashlib.sha256()
   md.update(pmsg)
   md.update(emsg)
   digest = md.digest()
   if not skey.verify(digest, (bytes_to_long(sig),)):
      raise Exception("could not verify signature")

   ## decrypt symmetric key / nonce
   ##
   kv = rkey.decrypt(emsg)
   key = kv[:CIPHERBITS/8]
   nonce = kv[CIPHERBITS/8:CIPHERBITS/8+8]

   #print binascii.b2a_hex(kv)
   #print binascii.b2a_hex(key)
   #print binascii.b2a_hex(nonce)

   ## decrypt msg using AES-256 in CTR mode
   ##
   c = AES.new(key, AES.MODE_CTR, counter = Counter.new(64, prefix = nonce))
   msg = unpad(c.decrypt(pmsg))

   ## create a digest of the unencrypted message
   ##
   md = hashlib.sha256()
   md.update(msg)
   if dmsg != md.digest():
      raise Exception("invalid key")

   return msg


if __name__ == '__main__':

   msg = "Hello, world  !!!" * 1

   key1prv = open("key1.priv").read()
   key1pub = open("key1.pub").read()
   key2prv = open("key2.priv").read()
   key2pub = open("key2.pub").read()
   key3prv = open("key3.priv").read()
   key3pub = open("key3.pub").read()

   (pmsg, emsg, sig) = encrypt_and_sign(msg, key1prv, key2pub)
   msg2 = verify_and_decrypt(pmsg, emsg, sig, key1pub, key2prv)
   print msg == msg2

########NEW FILE########
__FILENAME__ = customjson
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import datetime, isodate
from json import JSONEncoder


class CustomJsonEncoder(JSONEncoder):
   """
   JSON encoder able to serialize Python datetime.datetime/date/time/timedelta objects.

   To use this class, do

      json.dumps(obj, cls = CustomJsonEncoder)

   See: http://docs.python.org/library/json.html#json.JSONEncoder
   """

   def default(self, obj):

      if isinstance(obj, datetime.date) or \
         isinstance(obj, datetime.datetime) or \
         isinstance(obj, datetime.time):
         ## Note this issue with isodate module: "time formating does not allow
         ## to create fractional representations".
         ## Hence we use standard Python isoformat()
         ##
         s = obj.isoformat()
         if hasattr(obj, 'tzinfo') and obj.tzinfo is None and s[-1] != 'Z':
            ## assume UTC and append 'Z' for ISO format compliance!
            return s + 'Z'
         else:
            return s

      elif isinstance(obj, datetime.timedelta):
         #return (datetime.datetime.min + obj).time().isoformat()
         return isodate.duration_isoformat(obj)

      else:
         return super(CustomJsonEncoder, self).default(obj)

########NEW FILE########
__FILENAME__ = database
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import sqlite3, os, time, datetime

from twisted.python import log
from twisted.enterprise import adbapi

import pkg_resources, shutil

from autobahn.util import utcnow, newid
from autobahn.wamp import json_loads, json_dumps

from cryptoutil import verify_and_decrypt
from crossbar.x509util import generate_rsa_key

from crossbar.adminwebmodule.uris import URI_ERROR


def oldtable(tablename):
   now = datetime.datetime.utcnow()
   return now.strftime(tablename + "_%Y%m%d_%H%M%S")




#class Database(service.Service):
class Database:
   """
   Crossbar.io service database.
   """

   SERVICENAME = "Database"

   DBVERSION = 80
   """
   Database version. This needs to be incremented on structural changes.
   """

   WEBMQ_LICENSE_CA_PUBKEY = """-----BEGIN PUBLIC KEY-----
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAnrLrHYISb0Rd9AiUlYXE
BBvkMoz3a+eF8N8JYkcjmW8uvOjM1o1fKWFJW57TOjbJmOdyf0GNxAvldbQecZCF
yqICmCY9xF4KcPpMJ4RqBHGDVTycCkLoIhUg8hB2Zb5BkL2fxN28ZvBXGuuLkdOu
83Oo882/8DZgFei6HHC5+ISdno8dHcCaw4EieZdsNiFin6qG65Wkr6EMhKupihHS
+7HA/wVQWX1bAFJdkL1Jidt3M4iPSjpI4Edg++yNRI+UdT461j7tpkUq4csLh7fc
LqlHJZhL4Xr6/pikVxjB1ZwU5+NMJrngPasannkp1tfOd/rnSHqkf2jfNDgAAQn3
OQIDAQAB
-----END PUBLIC KEY-----
"""


   ## Package list considered for updating crossbar.io
   ##
   ##
   CROSSBAR_UPDATE_URL = "http://www.tavendo.de/download/webmq/release/eggs/"

   ## Hosts considered for updating crossbar.io
   ##
   ## Note, that we only have Tavendo server here, since pointing to servers
   ## no controlled by us might lead to compromised/unwanted software be installed!!!
   ##
   ## http://packages.python.org/distribute/easy_install.html#restricting-downloads-with-allow-hosts
   ## ie.: "*.myintranet.example.com,*.python.org"
   ##
   #CROSSBAR_UPDATE_HOST = "www.tavendo.de,pypi.python.org"
   CROSSBAR_UPDATE_HOST = "www.tavendo.de"

   ## The following command will get executed:
   ##
   ## ./app/bin/easy_install -H www.tavendo.de -U -v -f http://www.tavendo.de/download/webmq/release/eggs/ WebMQ
   ##

   SERVICES = [
               ## admin API and UI
               "service-enable-adminui", # this should be "not editable" in UI

               ## main application WebSocket/Web network service
               "service-enable-appws",
               "service-enable-appweb", # formerly called 'ws-enable-webserver'

               ## auxiliary network services
               "service-enable-flashpolicy",
               "service-enable-echows",
               "service-enable-ftp",

               ## system monitoring services
               "service-enable-netstat",
               "service-enable-vmstat",

               ## integration services
               "service-enable-restpusher",
               "service-enable-restremoter",
               "service-enable-pgpusher",
               "service-enable-pgremoter",
               "service-enable-orapusher",
               "service-enable-oraremoter",
               "service-enable-hanapusher",
               "service-enable-hanaremoter",
               "service-enable-extdirectremoter",
               # there is no 'extdirectpusher' service!
               ]

   NETPORTS = ["ssh-port",
               "hub-web-port",
               "hub-websocket-port",
               "admin-web-port",
               "admin-websocket-port",
               "flash-policy-port",
               "echo-websocket-port",
               "ftp-port",
               "ftp-passive-port-start",
               "ftp-passive-port-end"]
   """
   Database config keys for network ports. Service network listening ports database keys.
   """

   NETPORTS_READONLY = ["ssh-port"]
   """
   Database config keys for read-only network ports.
   """

   NETPORTS_TLS_PREFIXES = ["hub-web",
                            "hub-websocket",
                            "admin-web",
                            "admin-websocket",
                            "echo-websocket"]
   """
   Prefixes of database config keys for network services capable of TLS.
   """

   NETPORTS_TLS_FLAGS = [x + "-tls" for x in NETPORTS_TLS_PREFIXES]
   """
   Database config keys of enable flags for network services capable of TLS.
   """

   NETPORTS_TLS_KEYS = [x + "-tlskey" for x in NETPORTS_TLS_PREFIXES]
   """
   Database config keys of key/certs for network services (URIs pointing to database
   table "servicekeys") capable of TLS.
   """

   @staticmethod
   def parseLicense(instanceKey, payload):

      if type(payload) not in [str, unicode]:
         raise Exception("invalid license payload type (expected string, got %s" % type(payload))

      arr = payload.split(',')
      if len(arr) != 4:
         raise Exception("invalid license payload (expected 4 elements, got %d" % len(arr))

      # encrypted message, symmetric encryption key and signature
      (msg, key, dig, sig) = arr

      try:
         cmsg = verify_and_decrypt(msg,
                                   key,
                                   dig,
                                   sig,
                                   Database.WEBMQ_LICENSE_CA_PUBKEY,
                                   instanceKey)
      except Exception, e:
         raise Exception("could not decrypt license (%s)" % str(e))

      try:
         license = json_loads(cmsg)
      except Exception, e:
         raise Exception("could not parse license (%s)" % str(e))

      ## check all fields are present and convert Unicode to normal str
      required_fields = ['license-id',
                         'host-id',
                         'instance-id',
                         'valid-from',
                         'valid-to',
                         'type',
                         'connection-cap',
                         'tls-enabled']
      for f in required_fields:
         if not license.has_key(f):
            raise Exception("missing license field '%s'" % f)
         else:
            license[f] = str(license[f])

      return license



   def __init__(self, services):
      """
      Ctor.

      :param services: Crossbar.io services.
      :type services: dict
      """

      self.services = services
      self.isRunning = False

      self.licenseOptions = None
      self.installedOptions = None

      ## Crossbar.io data directory
      self.cbdata = services["master"].cbdata
      self.dbfile = os.path.join(self.cbdata, "crossbar.dat")


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)

      ## create application data directory if it does not exist
      ##
      if not os.path.isdir(self.cbdata):
         log.msg("application data directory %s does not exist - creating" % self.cbdata)
         os.mkdir(self.cbdata)
      else:
         log.msg("starting application from application data directory %s" % self.cbdata)

      self.createOrUpgrade()
      self.checkIntegrity()

      cfg = self.getConfig(includeTls = True)

      ## Create Dir structure
      ##
      dirs = ["log-dir", "export-dir", "import-dir", "web-dir"]
      for d in dirs:
         dir = str(cfg[d])
         if not os.path.isdir(dir):
            if d == "web-dir":
               self.scratchWebDir(dir)
               log.msg("copied web template to application data subdirectory %s" % dir)
            else:
               os.mkdir(dir)
               log.msg("created application data subdirectory %s" % dir)

      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      self.isRunning = False


   def scratchWebDir(self, dir = None, init = True):

      if init:
         log.msg("scratching and initializing web directory %s" % dir)
      else:
         log.msg("scratching web directory %s" % dir)

      if dir is None:
         dir = self.services["config"]["web-dir"]
      dst = os.path.abspath(dir)

      if os.path.isdir(dst):
         try:
            shutil.rmtree(dst)
         except Exception, e:
            raise Exception(URI_ERROR + "execution-error", "Could not remove web directory [%s]." % str(e))

      if init:
         try:
            import crossbardemo
            log.msg("Found crossbardemo package v%s" % crossbardemo.__version__)
         except ImportError:
            os.mkdir(dst)
            log.msg("Skipping web directory init (crossbardemo package not installed)")
         else:
            try:
               src = os.path.abspath(pkg_resources.resource_filename("crossbardemo", "web"))
               shutil.copytree(src, dst)
            except Exception, e:
               raise Exception(URI_ERROR + "execution-error", "Could not init web directory [%s]." % str(e))
            log.msg("scratched and initialized web directory %s" % dst)
      else:
         try:
            os.mkdir(dst)
         except Exception, e:
            raise Exception(URI_ERROR + "execution-error", "Could not create web directory [%s]." % str(e))
         log.msg("scratched web directory %s" % dst)

      def dowalk(dir):
         nfiles = 0
         fsize = 0
         for root, dirs, files in os.walk(dir):
            nfiles += len(files)
            fsize += sum(os.path.getsize(os.path.join(root, name)) for name in files)
            for d in dirs:
               _nfiles, _fsize = dowalk(d)
               nfiles += _nfiles
               fsize += _fsize
         return nfiles, fsize

      return dowalk(dst)


   def createPool(self):
      """
      Create Twisted database connection pool.
      """
      return adbapi.ConnectionPool('sqlite3',
                                   self.dbfile,
                                   check_same_thread = False # http://twistedmatrix.com/trac/ticket/3629
                                   )


   def checkIntegrity(self):
      db = sqlite3.connect(self.dbfile)
      cur = db.cursor()

      cur.execute("SELECT value FROM config WHERE key = ?", ['instance-priv-key'])
      res = cur.fetchone()
      instanceKey = str(json_loads(res[0]))

      invalidLicenseIds = []

      cur.execute("SELECT license_id, license, host_id, instance_id, valid_from, valid_to, license_type, connection_cap, tls_enabled FROM license WHERE enabled = 1")
      res = cur.fetchall()
      for r in res:
         payload = r[1]
         r = list(r)
         r[8] = True if r[8] != 0 else False
         try:
            license = Database.parseLicense(instanceKey, payload)
            errs = []
            i = 2
            for a in ['host-id', 'instance-id', 'valid-from', 'valid-to', 'type', 'connection-cap', 'tls-enabled']:
               if str(r[i]) != str(license[a]):
                  errs.append("%s mismatch (%s / %s)" % (a, r[i], license[a]))
               i += 1
            if len(errs) > 0:
               invalidLicenseIds.append((r[0], errs))
         except Exception, e:
            invalidLicenseIds.append((r[0], str(e)))

      if len(invalidLicenseIds) > 0:
         log.msg("CORRUPT license(s) in database. Disabling corrupt licenses:")
         log.msg(invalidLicenseIds)
         for l in invalidLicenseIds:
            cur.execute("UPDATE license SET enabled = 0 WHERE license_id = ?", [l[0]])
            db.commit()



   def createOrUpgrade(self):
      """
      Create or upgrade application database.
      """
      if not os.path.isfile(self.dbfile):
         log.msg("database does not exist")
         self.createDatabase()
         self.initDatabase()
         log.msg("database created and initialized")
      else:
         info = self.getDatabaseInfo()
         if info is None:
            log.msg("database file exists, but database is corrupt - removing file")
            os.remove(self.dbfile)
            self.createOrUpgrade()
         else:
            version = info["database-version"]
            if version < Database.DBVERSION:
               log.msg("database needs upgrade (from %d to %d)" % (version, Database.DBVERSION))
               self.upgradeDatabase(version, Database.DBVERSION)
            else:
               log.msg("database exists in current version %d" % version)


   def upgradeDatabase(self, currentVersion, newVersion):
      if False:
         ## recreate database from scratch
         os.remove(self.dbfile)
         self.createOrUpgrade()
      else:
         ## graceful upgrade
         db = sqlite3.connect(self.dbfile)
         cur = db.cursor()

         while currentVersion < newVersion:
            log.msg("upgrading database from %d to %d" % (currentVersion, currentVersion + 1))

            if currentVersion == 64:
               ## upgrade: 64 => 65
               ##
               CONFIG = {
                   ## Echo WS service
                   ##
                   "echo-websocket-port": 7000,
                   "echo-websocket-tls": False,
                   "echo-websocket-tlskey": None
                   }
               for k in CONFIG:
                  cur.execute("INSERT INTO config (key, value) VALUES (?, ?)", [k, json_dumps(CONFIG[k])])
               db.commit()

            elif currentVersion == 65:
               ## upgrade: 65 => 66
               ##
               cur.execute("""
                           CREATE TABLE extdirectremote (
                              id                   TEXT     PRIMARY KEY,
                              created              TEXT     NOT NULL,
                              modified             TEXT,
                              require_appcred_id   TEXT,
                              base_uri             TEXT     NOT NULL,
                              server_url           TEXT     NOT NULL,
                              api_path             TEXT     NOT NULL,
                              api_object           TEXT     NOT NULL,
                              timeout              INTEGER  NOT NULL)
                           """)
               cur.execute("CREATE VIEW d_extdirectremote AS SELECT * FROM extdirectremote ORDER BY id")

            elif currentVersion == 66:
               ## upgrade: 66 => 67
               ##
               cur.execute("""DROP VIEW d_extdirectremote""")
               cur.execute("""DROP TABLE extdirectremote""")
               cur.execute("""
                           CREATE TABLE extdirectremote (
                              id                         TEXT     PRIMARY KEY,
                              created                    TEXT     NOT NULL,
                              modified                   TEXT,
                              require_appcred_id         TEXT,
                              rpc_base_uri               TEXT     NOT NULL,
                              router_url                 TEXT     NOT NULL,
                              api_url                    TEXT     NOT NULL,
                              api_object                 TEXT     NOT NULL,
                              connection_timeout         INTEGER  NOT NULL,
                              request_timeout            INTEGER  NOT NULL,
                              max_persistent_conns       INTEGER  NOT NULL,
                              persistent_conn_timeout    INTEGER  NOT NULL)
                           """)
               cur.execute("CREATE VIEW d_extdirectremote AS SELECT * FROM extdirectremote ORDER BY id")

            elif currentVersion == 67:
               ## upgrade: 67 => 68
               ##
               cur.execute("""
                           CREATE TABLE restremote (
                              id                         TEXT     PRIMARY KEY,
                              created                    TEXT     NOT NULL,
                              modified                   TEXT,
                              require_appcred_id         TEXT,
                              rpc_base_uri               TEXT     NOT NULL,
                              rest_base_url              TEXT     NOT NULL,
                              payload_format             TEXT     NOT NULL,
                              connection_timeout         INTEGER  NOT NULL,
                              request_timeout            INTEGER  NOT NULL,
                              max_persistent_conns       INTEGER  NOT NULL,
                              persistent_conn_timeout    INTEGER  NOT NULL)
                           """)
               cur.execute("CREATE VIEW d_restremote AS SELECT * FROM restremote ORDER BY id")

            if currentVersion == 68:
               ## upgrade: 68 => 69
               ##
               CONFIG = {
                  "ws-accept-queue-size": 5000,
                  "ws-enable-webserver": True,
                  "ws-websocket-path": "ws",
                  "web-dir": os.path.join(self.cbdata, "web")
               }
               for k in CONFIG:
                  cur.execute("INSERT INTO config (key, value) VALUES (?, ?)", [k, json_dumps(CONFIG[k])])
               db.commit()

               cur.execute("DROP VIEW d_restremote")
               cur.execute("ALTER TABLE restremote RENAME TO tmp_restremote")
               cur.execute("""
                           CREATE TABLE restremote (
                              id                         TEXT     PRIMARY KEY,
                              created                    TEXT     NOT NULL,
                              modified                   TEXT,
                              require_appcred_id         TEXT,
                              rpc_base_uri               TEXT     NOT NULL,
                              rest_base_url              TEXT     NOT NULL,
                              payload_format             TEXT     NOT NULL,
                              forward_cookies            INTEGER  NOT NULL,
                              redirect_limit             INTEGER  NOT NULL,
                              connection_timeout         INTEGER  NOT NULL,
                              request_timeout            INTEGER  NOT NULL,
                              max_persistent_conns       INTEGER  NOT NULL,
                              persistent_conn_timeout    INTEGER  NOT NULL)
                           """)
               cur.execute("""INSERT INTO restremote (
                                    id,
                                    created,
                                    modified,
                                    require_appcred_id,
                                    rpc_base_uri,
                                    rest_base_url,
                                    payload_format,
                                    forward_cookies,
                                    redirect_limit,
                                    connection_timeout,
                                    request_timeout,
                                    max_persistent_conns,
                                    persistent_conn_timeout
                                    ) SELECT
                                    id,
                                    created,
                                    modified,
                                    require_appcred_id,
                                    rpc_base_uri,
                                    rest_base_url,
                                    payload_format,
                                    1,
                                    0,
                                    connection_timeout,
                                    request_timeout,
                                    max_persistent_conns,
                                    persistent_conn_timeout
                                    FROM tmp_restremote""")
               cur.execute("CREATE VIEW d_restremote AS SELECT * FROM restremote ORDER BY id")
               cur.execute("DROP TABLE tmp_restremote")

               cur.execute("DROP VIEW d_extdirectremote")
               cur.execute("ALTER TABLE extdirectremote RENAME TO tmp_extdirectremote")
               cur.execute("""
                           CREATE TABLE extdirectremote (
                              id                         TEXT     PRIMARY KEY,
                              created                    TEXT     NOT NULL,
                              modified                   TEXT,
                              require_appcred_id         TEXT,
                              rpc_base_uri               TEXT     NOT NULL,
                              router_url                 TEXT     NOT NULL,
                              api_url                    TEXT     NOT NULL,
                              api_object                 TEXT     NOT NULL,
                              forward_cookies            INTEGER  NOT NULL,
                              redirect_limit             INTEGER  NOT NULL,
                              connection_timeout         INTEGER  NOT NULL,
                              request_timeout            INTEGER  NOT NULL,
                              max_persistent_conns       INTEGER  NOT NULL,
                              persistent_conn_timeout    INTEGER  NOT NULL)
                           """)
               cur.execute("""INSERT INTO extdirectremote (
                                    id,
                                    created,
                                    modified,
                                    require_appcred_id,
                                    rpc_base_uri,
                                    router_url,
                                    api_url,
                                    api_object,
                                    forward_cookies,
                                    redirect_limit,
                                    connection_timeout,
                                    request_timeout,
                                    max_persistent_conns,
                                    persistent_conn_timeout
                                    ) SELECT
                                    id,
                                    created,
                                    modified,
                                    require_appcred_id,
                                    rpc_base_uri,
                                    router_url,
                                    api_url,
                                    api_object,
                                    1,
                                    0,
                                    connection_timeout,
                                    request_timeout,
                                    max_persistent_conns,
                                    persistent_conn_timeout
                                    FROM tmp_extdirectremote""")
               cur.execute("CREATE VIEW d_extdirectremote AS SELECT * FROM extdirectremote ORDER BY id")
               cur.execute("DROP TABLE tmp_extdirectremote")

            if currentVersion == 69:
               ## upgrade: 69 => 70
               ##
               CONFIG = {"ftp-passive-public-ip": None}
               for k in CONFIG:
                  cur.execute("INSERT INTO config (key, value) VALUES (?, ?)", [k, json_dumps(CONFIG[k])])
               db.commit()

            if currentVersion == 70:
               ## upgrade: 70 => 71
               ##
               cur.execute("""
                           CREATE TABLE hanaconnect (
                              id                TEXT     PRIMARY KEY,
                              created           TEXT     NOT NULL,
                              modified          TEXT,
                              label             TEXT     NOT NULL,
                              driver            TEXT     NOT NULL,
                              host              TEXT     NOT NULL,
                              port              INTEGER  NOT NULL,
                              database          TEXT     NOT NULL,
                              user              TEXT     NOT NULL,
                              password          TEXT     NOT NULL)
                           """)
               cur.execute("""CREATE VIEW d_hanaconnect AS
                                 SELECT id,
                                        created,
                                        modified,
                                        label,
                                        driver,
                                        host,
                                        port,
                                        database,
                                        user,
                                        length(password) AS length_password FROM hanaconnect ORDER BY id""")

            if currentVersion == 71:
               ## upgrade: 71 => 72
               ##
               cur.execute("""
                           CREATE TABLE hanapushrule (
                              id                   TEXT     PRIMARY KEY,
                              created              TEXT     NOT NULL,
                              modified             TEXT,
                              hanaconnect_id       TEXT     NOT NULL,
                              user                 TEXT,
                              topic_uri            TEXT     NOT NULL,
                              match_by_prefix      INTEGER  NOT NULL)
                           """)
               cur.execute("CREATE VIEW d_hanapushrule AS SELECT * FROM hanapushrule ORDER BY id")

            if currentVersion == 72:
               ## upgrade: 72 => 73
               ##
               cur.execute("""
                           CREATE TABLE pgconnect (
                              id                   TEXT     PRIMARY KEY,
                              created              TEXT     NOT NULL,
                              modified             TEXT,
                              label                TEXT     NOT NULL,
                              host                 TEXT     NOT NULL,
                              port                 INTEGER  NOT NULL,
                              database             TEXT     NOT NULL,
                              user                 TEXT     NOT NULL,
                              password             TEXT     NOT NULL,
                              connection_timeout   INTEGER  NOT NULL
                              )
                           """)
               cur.execute("""CREATE VIEW d_pgconnect AS
                                 SELECT id,
                                        created,
                                        modified,
                                        label,
                                        host,
                                        port,
                                        database,
                                        user,
                                        length(password) AS length_password,
                                        connection_timeout
                                        FROM pgconnect ORDER BY id""")
               cur.execute("""
                           CREATE TABLE pgpushrule (
                              id                   TEXT     PRIMARY KEY,
                              created              TEXT     NOT NULL,
                              modified             TEXT,
                              pgconnect_id         TEXT     NOT NULL,
                              user                 TEXT,
                              topic_uri            TEXT     NOT NULL,
                              match_by_prefix      INTEGER  NOT NULL)
                           """)
               cur.execute("CREATE VIEW d_pgpushrule AS SELECT * FROM pgpushrule ORDER BY id")

            if currentVersion == 73:
               ## upgrade: 73 => 74
               ##
               cur.execute("""
                           CREATE TABLE oraconnect (
                              id                   TEXT     PRIMARY KEY,
                              created              TEXT     NOT NULL,
                              modified             TEXT,
                              label                TEXT     NOT NULL,
                              host                 TEXT     NOT NULL,
                              port                 INTEGER  NOT NULL,
                              sid                  TEXT     NOT NULL,
                              user                 TEXT     NOT NULL,
                              password             TEXT     NOT NULL,
                              connection_timeout   INTEGER  NOT NULL
                              )
                           """)
               cur.execute("""CREATE VIEW d_oraconnect AS
                                 SELECT id,
                                        created,
                                        modified,
                                        label,
                                        host,
                                        port,
                                        sid,
                                        user,
                                        length(password) AS length_password,
                                        connection_timeout
                                        FROM oraconnect ORDER BY id""")

               cur.execute("""
                           CREATE TABLE orapushrule (
                              id                   TEXT     PRIMARY KEY,
                              created              TEXT     NOT NULL,
                              modified             TEXT,
                              oraconnect_id        TEXT     NOT NULL,
                              user                 TEXT,
                              topic_uri            TEXT     NOT NULL,
                              match_by_prefix      INTEGER  NOT NULL)
                           """)
               cur.execute("CREATE VIEW d_orapushrule AS SELECT * FROM orapushrule ORDER BY id")

            if currentVersion == 74:
               ## upgrade: 74 => 75
               ##
               cur.execute("""
                           CREATE TABLE hanaremote (
                              id                         TEXT     PRIMARY KEY,
                              created                    TEXT     NOT NULL,
                              modified                   TEXT,
                              require_appcred_id         TEXT,
                              hanaconnect_id             TEXT     NOT NULL,
                              schema_list                TEXT     NOT NULL,
                              rpc_base_uri               TEXT     NOT NULL,
                              connection_pool_min_size   INTEGER  NOT NULL,
                              connection_pool_max_size   INTEGER  NOT NULL,
                              connection_timeout         INTEGER  NOT NULL,
                              request_timeout            INTEGER  NOT NULL)
                           """)
               cur.execute("""CREATE VIEW d_hanaremote AS
                                 SELECT id,
                                        created,
                                        modified,
                                        require_appcred_id,
                                        hanaconnect_id,
                                        schema_list,
                                        rpc_base_uri,
                                        connection_pool_min_size,
                                        connection_pool_max_size,
                                        connection_timeout,
                                        request_timeout FROM hanaremote ORDER BY id""")

               cur.execute("""
                           CREATE TABLE pgremote (
                              id                         TEXT     PRIMARY KEY,
                              created                    TEXT     NOT NULL,
                              modified                   TEXT,
                              require_appcred_id         TEXT,
                              pgconnect_id               TEXT     NOT NULL,
                              schema_list                TEXT     NOT NULL,
                              rpc_base_uri               TEXT     NOT NULL,
                              connection_pool_min_size   INTEGER  NOT NULL,
                              connection_pool_max_size   INTEGER  NOT NULL,
                              connection_timeout         INTEGER  NOT NULL,
                              request_timeout            INTEGER  NOT NULL)
                           """)
               cur.execute("""CREATE VIEW d_pgremote AS
                                 SELECT id,
                                        created,
                                        modified,
                                        require_appcred_id,
                                        pgconnect_id,
                                        schema_list,
                                        rpc_base_uri,
                                        connection_pool_min_size,
                                        connection_pool_max_size,
                                        connection_timeout,
                                        request_timeout FROM pgremote ORDER BY id""")

               cur.execute("""
                           CREATE TABLE oraremote (
                              id                         TEXT     PRIMARY KEY,
                              created                    TEXT     NOT NULL,
                              modified                   TEXT,
                              require_appcred_id         TEXT,
                              oraconnect_id              TEXT     NOT NULL,
                              schema_list                TEXT     NOT NULL,
                              rpc_base_uri               TEXT     NOT NULL,
                              connection_pool_min_size   INTEGER  NOT NULL,
                              connection_pool_max_size   INTEGER  NOT NULL,
                              connection_timeout         INTEGER  NOT NULL,
                              request_timeout            INTEGER  NOT NULL)
                           """)
               cur.execute("""CREATE VIEW d_oraremote AS
                                 SELECT id,
                                        created,
                                        modified,
                                        require_appcred_id,
                                        oraconnect_id,
                                        schema_list,
                                        rpc_base_uri,
                                        connection_pool_min_size,
                                        connection_pool_max_size,
                                        connection_timeout,
                                        request_timeout FROM oraremote ORDER BY id""")

            if currentVersion == 75:
               ## upgrade: 75 => 76
               ##
               for k in Database.SERVICES:
                  cur.execute("INSERT INTO config (key, value) VALUES (?, ?)", [k, json_dumps(True)])
               db.commit()

            if currentVersion == 76:
               ## upgrade: 76 => 77
               ##
               try:
                  cur.execute("DROP VIEW d_oraconnect")
               except:
                  pass

               tmp = oldtable("oraconnect")
               cur.execute("ALTER TABLE oraconnect RENAME TO %s" % tmp)
               log.msg("renamed table 'oraconnect' to temp table '%s'" % tmp)

               cur.execute("""
                           CREATE TABLE oraconnect (
                              id                   TEXT     PRIMARY KEY,
                              created              TEXT     NOT NULL,
                              modified             TEXT,
                              label                TEXT     NOT NULL,
                              host                 TEXT     NOT NULL,
                              port                 INTEGER  NOT NULL,
                              sid                  TEXT     NOT NULL,
                              user                 TEXT     NOT NULL,
                              password             TEXT     NOT NULL,
                              demo_user            TEXT,
                              demo_password        TEXT,
                              connection_timeout   INTEGER  NOT NULL
                              )
                           """)
               cur.execute("""CREATE VIEW d_oraconnect AS
                                 SELECT id,
                                        created,
                                        modified,
                                        label,
                                        host,
                                        port,
                                        sid,
                                        user,
                                        length(password) AS length_password,
                                        demo_user,
                                        length(demo_password) AS length_demo_password,
                                        connection_timeout
                                        FROM oraconnect ORDER BY id""")

               cur.execute("INSERT INTO oraconnect (id, created, modified, label, host, port, sid, user, password, connection_timeout) SELECT id, created, modified, label, host, port, sid, user, password, connection_timeout FROM %s" % tmp)
               db.commit()
               log.msg("inserted data from temp table '%s' into oraconnect" % tmp)

               cur.execute("DROP TABLE %s" % tmp)
               log.msg("dropped temp table '%s'" % tmp)

            if currentVersion == 77:
               ## upgrade: 77 => 78
               ##
               cur.execute("""
                           CREATE TABLE objstore (
                              uri               TEXT     PRIMARY KEY,
                              obj               TEXT     NOT NULL)
                           """)
               cur.execute("""CREATE VIEW d_objstore AS
                              SELECT uri, obj FROM objstore ORDER BY uri
                           """)

            if currentVersion == 78:
               ## upgrade: 78 => 79
               ##
               CONFIG = {
                  "ws-enable-permessage-deflate": True,
                  "ws-permessage-deflate-window-size": 0,
                  "ws-permessage-deflate-require-window-size": False
               }
               for k in CONFIG:
                  cur.execute("INSERT INTO config (key, value) VALUES (?, ?)", [k, json_dumps(CONFIG[k])])
               db.commit()

            if currentVersion == 79:
               ## upgrade: 79 => 80
               ##
               CONFIG = {
                   ## CGI Processor
                   ##
                   "appweb-cgi-enable": False,
                   "appweb-cgi-path": "cgi",
                   "appweb-cgi-processor": ""
                   }
               for k in CONFIG:
                  cur.execute("INSERT INTO config (key, value) VALUES (?, ?)", [k, json_dumps(CONFIG[k])])
               db.commit()

            ## set new database version
            ##
            currentVersion += 1
            cur.execute("UPDATE config SET value = ? WHERE key = ?", [json_dumps(currentVersion), "database-version"])
            db.commit()


   def createDatabase(self):
      """
      Create WebMQ service database from scratch.
      """
      log.msg("creating database at %s .." % self.dbfile)
      db = sqlite3.connect(self.dbfile)

      cur = db.cursor()

      cur.execute("""
                  CREATE TABLE config (
                     key               TEXT     PRIMARY KEY,
                     value             TEXT     NOT NULL)
                  """)
      cur.execute("""CREATE VIEW d_config AS
                     SELECT * FROM
                     (
                        SELECT key,
                               value FROM config WHERE key NOT IN ('admin-password', 'instance-priv-key')
                        UNION ALL
                        SELECT key,
                               length(value) AS VALUE FROM config WHERE key IN ('admin-password', 'instance-priv-key')
                     ) ORDER BY key""")

      cur.execute("""
                  CREATE TABLE objstore (
                     uri               TEXT     PRIMARY KEY,
                     obj               TEXT     NOT NULL)
                  """)
      cur.execute("""CREATE VIEW d_objstore AS
                     SELECT uri, obj FROM objstore ORDER BY uri
                  """)

      cur.execute("""
                  CREATE TABLE appcredential (
                     id                TEXT     PRIMARY KEY,
                     created           TEXT     NOT NULL,
                     modified          TEXT,
                     label             TEXT     NOT NULL,
                     key               TEXT     NOT NULL UNIQUE,
                     secret            TEXT     NOT NULL)
                  """)
      cur.execute("""CREATE VIEW d_appcredential AS
                        SELECT id,
                               created,
                               modified,
                               label,
                               key,
                               length(secret) AS length_secret FROM appcredential ORDER BY id""")

      cur.execute("""
                  CREATE TABLE ftpuser (
                     id                TEXT     PRIMARY KEY,
                     created           TEXT     NOT NULL,
                     modified          TEXT,
                     label             TEXT     NOT NULL,
                     user              TEXT     NOT NULL UNIQUE,
                     password          TEXT     NOT NULL)
                  """)
      cur.execute("""CREATE VIEW d_ftpuser AS
                        SELECT id,
                               created,
                               modified,
                               label,
                               user,
                               length(password) AS length_password FROM ftpuser ORDER BY id""")

      cur.execute("""
                  CREATE TABLE postrule (
                     id                   TEXT     PRIMARY KEY,
                     created              TEXT     NOT NULL,
                     modified             TEXT,
                     position             FLOAT    NOT NULL UNIQUE,
                     topic_uri            TEXT     NOT NULL,
                     match_by_prefix      INTEGER  NOT NULL,
                     filter_ip            INTEGER  NOT NULL,
                     filter_ip_network    TEXT,
                     require_signature    INTEGER  NOT NULL,
                     require_appcred_id   TEXT,
                     action               TEXT     NOT NULL)
                  """)
      cur.execute("CREATE VIEW d_postrule AS SELECT * FROM postrule ORDER BY id")

      cur.execute("""
                  CREATE TABLE clientperm (
                     id                   TEXT     PRIMARY KEY,
                     created              TEXT     NOT NULL,
                     modified             TEXT,
                     topic_uri            TEXT     NOT NULL,
                     match_by_prefix      INTEGER  NOT NULL,
                     require_appcred_id   TEXT,
                     filter_expr          TEXT,
                     allow_publish        INTEGER  NOT NULL,
                     allow_subscribe      INTEGER  NOT NULL)
                  """)
      cur.execute("CREATE VIEW d_clientperm AS SELECT * FROM clientperm ORDER BY id")

      cur.execute("""
                  CREATE TABLE extdirectremote (
                     id                         TEXT     PRIMARY KEY,
                     created                    TEXT     NOT NULL,
                     modified                   TEXT,
                     require_appcred_id         TEXT,
                     rpc_base_uri               TEXT     NOT NULL,
                     router_url                 TEXT     NOT NULL,
                     api_url                    TEXT     NOT NULL,
                     api_object                 TEXT     NOT NULL,
                     forward_cookies            INTEGER  NOT NULL,
                     redirect_limit             INTEGER  NOT NULL,
                     connection_timeout         INTEGER  NOT NULL,
                     request_timeout            INTEGER  NOT NULL,
                     max_persistent_conns       INTEGER  NOT NULL,
                     persistent_conn_timeout    INTEGER  NOT NULL)
                  """)
      cur.execute("CREATE VIEW d_extdirectremote AS SELECT * FROM extdirectremote ORDER BY id")

      cur.execute("""
                  CREATE TABLE restremote (
                     id                         TEXT     PRIMARY KEY,
                     created                    TEXT     NOT NULL,
                     modified                   TEXT,
                     require_appcred_id         TEXT,
                     rpc_base_uri               TEXT     NOT NULL,
                     rest_base_url              TEXT     NOT NULL,
                     payload_format             TEXT     NOT NULL,
                     forward_cookies            INTEGER  NOT NULL,
                     redirect_limit             INTEGER  NOT NULL,
                     connection_timeout         INTEGER  NOT NULL,
                     request_timeout            INTEGER  NOT NULL,
                     max_persistent_conns       INTEGER  NOT NULL,
                     persistent_conn_timeout    INTEGER  NOT NULL)
                  """)
      cur.execute("CREATE VIEW d_restremote AS SELECT * FROM restremote ORDER BY id")

      cur.execute("""
                  CREATE TABLE servicekey (
                     id                      TEXT     PRIMARY KEY,
                     created                 TEXT     NOT NULL,
                     modified                TEXT,
                     label                   TEXT     NOT NULL,
                     key_priv                TEXT     NOT NULL,
                     key_pub                 TEXT     NOT NULL,
                     key_length              INTEGER  NOT NULL,
                     key_fingerprint         TEXT     NOT NULL UNIQUE,
                     cert                    TEXT,
                     cert_text               TEXT,
                     cert_fingerprint        TEXT,
                     is_cert_selfsigned      INTEGER,
                     selfsigned_cert_serial  INTEGER
                  )
                  """)
      cur.execute("""CREATE VIEW d_servicekey AS
                        SELECT id,
                               created,
                               modified,
                               label,
                               length(key_priv) AS length_key_priv,
                               key_pub,
                               key_length,
                               key_fingerprint,
                               cert,
                               cert_text,
                               cert_fingerprint,
                               is_cert_selfsigned,
                               selfsigned_cert_serial
                        FROM servicekey ORDER BY id""")

      cur.execute("""
                  CREATE TABLE cookie (
                     created              TEXT     NOT NULL,
                     username             TEXT     NOT NULL,
                     value                TEXT     NOT NULL UNIQUE)
                  """)
      cur.execute("""CREATE VIEW d_cookie AS
                        SELECT created,
                               username,
                               length(value) AS length_value
                        FROM cookie ORDER BY created, username""")

      # {"valid-from": "2012-04-19T07:31:33Z",
      #  "valid-to": "2012-06-30T00:00:00Z",
      #  "license-id": "83152182-b583-454d-826f-37b2e3f18544",
      #  "host-id": "00000000-0000-0000-0000-ac50849784fa",
      #  "connection-cap": 0,
      #  "tls-enabled": true,
      #  "type": "BETA",
      #  "instance-id": "32:84:71:98:A4:CF:60:1D:00:22:F6:A2:E7:82:C2:72:91:8D:69:A3"}
      cur.execute("""
                  CREATE TABLE license (
                     created              TEXT     NOT NULL,
                     license              TEXT     NOT NULL,
                     enabled              INTEGER  NOT NULL,
                     license_id           TEXT     NOT NULL UNIQUE,
                     host_id              TEXT     NOT NULL,
                     instance_id          TEXT     NOT NULL,
                     valid_from           TEXT     NOT NULL,
                     valid_to             TEXT     NOT NULL,
                     license_type         TEXT     NOT NULL,
                     connection_cap       INTEGER  NOT NULL,
                     tls_enabled          INTEGER  NOT NULL)
                  """)
      cur.execute("""CREATE VIEW d_license AS
                        SELECT created,
                               license,
                               enabled,
                               license_id,
                               host_id,
                               instance_id,
                               valid_from,
                               valid_to,
                               license_type,
                               connection_cap,
                               tls_enabled
                        FROM license ORDER BY instance_id, valid_from""")


      ## SAP HANA Database Integration Support
      ##
      cur.execute("""
                  CREATE TABLE hanaconnect (
                     id                TEXT     PRIMARY KEY,
                     created           TEXT     NOT NULL,
                     modified          TEXT,
                     label             TEXT     NOT NULL,
                     driver            TEXT     NOT NULL,
                     host              TEXT     NOT NULL,
                     port              INTEGER  NOT NULL,
                     database          TEXT     NOT NULL,
                     user              TEXT     NOT NULL,
                     password          TEXT     NOT NULL)
                  """)
      cur.execute("""CREATE VIEW d_hanaconnect AS
                        SELECT id,
                               created,
                               modified,
                               label,
                               driver,
                               host,
                               port,
                               database,
                               user,
                               length(password) AS length_password FROM hanaconnect ORDER BY id""")

      cur.execute("""
                  CREATE TABLE hanapushrule (
                     id                   TEXT     PRIMARY KEY,
                     created              TEXT     NOT NULL,
                     modified             TEXT,
                     hanaconnect_id       TEXT     NOT NULL,
                     user                 TEXT,
                     topic_uri            TEXT     NOT NULL,
                     match_by_prefix      INTEGER  NOT NULL)
                  """)
      cur.execute("CREATE VIEW d_hanapushrule AS SELECT * FROM hanapushrule ORDER BY id")

      cur.execute("""
                  CREATE TABLE hanaremote (
                     id                         TEXT     PRIMARY KEY,
                     created                    TEXT     NOT NULL,
                     modified                   TEXT,
                     require_appcred_id         TEXT,
                     hanaconnect_id             TEXT     NOT NULL,
                     schema_list                TEXT     NOT NULL,
                     rpc_base_uri               TEXT     NOT NULL,
                     connection_pool_min_size   INTEGER  NOT NULL,
                     connection_pool_max_size   INTEGER  NOT NULL,
                     connection_timeout         INTEGER  NOT NULL,
                     request_timeout            INTEGER  NOT NULL)
                  """)
      cur.execute("""CREATE VIEW d_hanaremote AS
                        SELECT id,
                               created,
                               modified,
                               require_appcred_id,
                               hanaconnect_id,
                               schema_list,
                               rpc_base_uri,
                               connection_pool_min_size,
                               connection_pool_max_size,
                               connection_timeout,
                               request_timeout FROM hanaremote ORDER BY id""")


      ## PostgreSQL Database Integration Support
      ##
      cur.execute("""
                  CREATE TABLE pgconnect (
                     id                   TEXT     PRIMARY KEY,
                     created              TEXT     NOT NULL,
                     modified             TEXT,
                     label                TEXT     NOT NULL,
                     host                 TEXT     NOT NULL,
                     port                 INTEGER  NOT NULL,
                     database             TEXT     NOT NULL,
                     user                 TEXT     NOT NULL,
                     password             TEXT     NOT NULL,
                     connection_timeout   INTEGER  NOT NULL
                     )
                  """)
      cur.execute("""CREATE VIEW d_pgconnect AS
                        SELECT id,
                               created,
                               modified,
                               label,
                               host,
                               port,
                               database,
                               user,
                               length(password) AS length_password,
                               connection_timeout
                               FROM pgconnect ORDER BY id""")

      cur.execute("""
                  CREATE TABLE pgpushrule (
                     id                   TEXT     PRIMARY KEY,
                     created              TEXT     NOT NULL,
                     modified             TEXT,
                     pgconnect_id         TEXT     NOT NULL,
                     user                 TEXT,
                     topic_uri            TEXT     NOT NULL,
                     match_by_prefix      INTEGER  NOT NULL)
                  """)
      cur.execute("CREATE VIEW d_pgpushrule AS SELECT * FROM pgpushrule ORDER BY id")

      cur.execute("""
                  CREATE TABLE pgremote (
                     id                         TEXT     PRIMARY KEY,
                     created                    TEXT     NOT NULL,
                     modified                   TEXT,
                     require_appcred_id         TEXT,
                     pgconnect_id               TEXT     NOT NULL,
                     schema_list                TEXT     NOT NULL,
                     rpc_base_uri               TEXT     NOT NULL,
                     connection_pool_min_size   INTEGER  NOT NULL,
                     connection_pool_max_size   INTEGER  NOT NULL,
                     connection_timeout         INTEGER  NOT NULL,
                     request_timeout            INTEGER  NOT NULL)
                  """)
      cur.execute("""CREATE VIEW d_pgremote AS
                        SELECT id,
                               created,
                               modified,
                               require_appcred_id,
                               pgconnect_id,
                               schema_list,
                               rpc_base_uri,
                               connection_pool_min_size,
                               connection_pool_max_size,
                               connection_timeout,
                               request_timeout FROM pgremote ORDER BY id""")

      ## Oracle Database Integration Support
      ##
      cur.execute("""
                  CREATE TABLE oraconnect (
                     id                   TEXT     PRIMARY KEY,
                     created              TEXT     NOT NULL,
                     modified             TEXT,
                     label                TEXT     NOT NULL,
                     host                 TEXT     NOT NULL,
                     port                 INTEGER  NOT NULL,
                     sid                  TEXT     NOT NULL,
                     user                 TEXT     NOT NULL,
                     password             TEXT     NOT NULL,
                     demo_user            TEXT,
                     demo_password        TEXT,
                     connection_timeout   INTEGER  NOT NULL
                     )
                  """)
      cur.execute("""CREATE VIEW d_oraconnect AS
                        SELECT id,
                               created,
                               modified,
                               label,
                               host,
                               port,
                               sid,
                               user,
                               length(password) AS length_password,
                               demo_user,
                               length(demo_password) AS length_demo_password,
                               connection_timeout
                               FROM oraconnect ORDER BY id""")

      cur.execute("""
                  CREATE TABLE orapushrule (
                     id                   TEXT     PRIMARY KEY,
                     created              TEXT     NOT NULL,
                     modified             TEXT,
                     oraconnect_id        TEXT     NOT NULL,
                     user                 TEXT,
                     topic_uri            TEXT     NOT NULL,
                     match_by_prefix      INTEGER  NOT NULL)
                  """)
      cur.execute("CREATE VIEW d_orapushrule AS SELECT * FROM orapushrule ORDER BY id")

      cur.execute("""
                  CREATE TABLE oraremote (
                     id                         TEXT     PRIMARY KEY,
                     created                    TEXT     NOT NULL,
                     modified                   TEXT,
                     require_appcred_id         TEXT,
                     oraconnect_id              TEXT     NOT NULL,
                     schema_list                TEXT     NOT NULL,
                     rpc_base_uri               TEXT     NOT NULL,
                     connection_pool_min_size   INTEGER  NOT NULL,
                     connection_pool_max_size   INTEGER  NOT NULL,
                     connection_timeout         INTEGER  NOT NULL,
                     request_timeout            INTEGER  NOT NULL)
                  """)
      cur.execute("""CREATE VIEW d_oraremote AS
                        SELECT id,
                               created,
                               modified,
                               require_appcred_id,
                               oraconnect_id,
                               schema_list,
                               rpc_base_uri,
                               connection_pool_min_size,
                               connection_pool_max_size,
                               connection_timeout,
                               request_timeout FROM oraremote ORDER BY id""")

      log.msg("database created.")


   def scratchDatabase(self):
      """
      Scratch all data from database, other than instance key / license.
      """
      log.msg("scratching database at %s .." % self.dbfile)
      db = sqlite3.connect(self.dbfile)

      cur = db.cursor()
      cur.execute("DELETE FROM config WHERE key NOT IN ('database-created', 'admin-password', 'instance-pub-key', 'instance-priv-key', 'instance-id')")
      cur.execute("DELETE FROM appcredential")
      cur.execute("DELETE FROM ftpuser")
      cur.execute("DELETE FROM postrule")
      cur.execute("DELETE FROM clientperm")
      cur.execute("DELETE FROM extdirectremote")
      cur.execute("DELETE FROM restremote")
      cur.execute("DELETE FROM servicekey")
      cur.execute("DELETE FROM cookie")
      # cur.execute("DELETE FROM license") ## license table NOT deleted!
      cur.execute("DELETE FROM hanaconnect")
      cur.execute("DELETE FROM hanapushrule")
      cur.execute("DELETE FROM hanaremote")
      cur.execute("DELETE FROM pgconnect")
      cur.execute("DELETE FROM pgpushrule")
      cur.execute("DELETE FROM pgremote")
      cur.execute("DELETE FROM oraconnect")
      cur.execute("DELETE FROM orapushrule")
      cur.execute("DELETE FROM oraremote")
      db.commit()
      self.initDatabase(scratchMode = True)
      log.msg("database scratched to factory state")


   def initDatabase(self, scratchMode = False):
      """
      Data initialization of application database.
      """
      log.msg("initializing database ..")

      db = sqlite3.connect(self.dbfile)
      cur = db.cursor()

      created = utcnow()

      ## instance RSA key
      ##
      if not scratchMode:
         log.msg("generating new instance key pair ..")
         (privkey, pubkey, fingerprint) = generate_rsa_key(2048)
         cur.execute("INSERT INTO config (key, value) VALUES (?, ?)", ['instance-pub-key', json_dumps(pubkey)])
         cur.execute("INSERT INTO config (key, value) VALUES (?, ?)", ['instance-priv-key', json_dumps(privkey)])
         cur.execute("INSERT INTO config (key, value) VALUES (?, ?)", ['instance-id', json_dumps(fingerprint)])
         db.commit()
         log.msg("new instance key pair generated and stored (fingerprint %s)" % fingerprint)

      ## Default configuration (initial database contents)
      ##
      CONFIG = {
          "database-version": Database.DBVERSION,

          ## authentication related options
          ##
          "auth-cookie-lifetime": 60 * 60 * 12,

          ## client permissions related options
          ##
          "client-auth-timeout": 0,
          "client-auth-allow-anonymous": True,

          ## postrules related options
          ##
          "postrule-default-action": "ALLOW",
          "post-body-limit": 4096,
          "sig-timestamp-delta-limit": 300,

          ## SSH Service (fixed, OS provided)
          ##
          "ssh-port": 22,

          ## Admin Web service
          ##
          "admin-web-port": 9090,
          "admin-web-tls": False,
          "admin-web-tlskey": None,

          ## Admin WS service
          ##
          "admin-websocket-port": 9000,
          "admin-websocket-tls": False,
          "admin-websocket-tlskey": None,

          ## App WS service
          ##
          "hub-websocket-port": 8080,
          "hub-websocket-tls": False,
          "hub-websocket-tlskey": None,

          ## REST/Push service
          ##
          "hub-web-port": 8090,
          "hub-web-tls": False,
          "hub-web-tlskey": None,

          ## Echo WS service
          ##
          "echo-websocket-port": 7000,
          "echo-websocket-tls": False,
          "echo-websocket-tlskey": None,

          ## Flash Policy File service
          ##
          "flash-policy-port": 843,

          ## FTP service
          ##
          "ftp-port": 21,
          "ftp-passive-port-start": 10000,
          "ftp-passive-port-end": 10100,
          "ftp-passive-public-ip": None,

          ## FTP related options
          "ftp-dir": os.path.join(self.cbdata, "ftp"),

          ## Logging related options
          ##
          "log-dir": os.path.join(self.cbdata, "log"),
          "log-retention-time": 24*3,
          "log-write-interval": 60,

          ## export/import directories
          ##
          "export-dir": os.path.join(self.cbdata, "export"),
          "export-url": "export",
          "import-dir": os.path.join(self.cbdata, "import"),
          "import-url": "import",

          ## Web serving directory
          ##
          "web-dir": os.path.join(self.cbdata, "web"), # if ws-enable-webserver == True, we serve file via embedded Web server from here

          ## WebSocket options
          ##
          "ws-allow-version-0": True, # Hixie-76
          "ws-allow-version-8": True,  # Hybi-Draft-10
          "ws-allow-version-13": True, # RFC6455
          "ws-max-connections": 0,
          "ws-max-frame-size": 0,
          "ws-max-message-size": 0,
          "ws-auto-fragment-size": 0,
          "ws-fail-by-drop": False,
          "ws-echo-close-codereason": False,
          "ws-open-handshake-timeout": 0,
          "ws-close-handshake-timeout": 0,
          "ws-tcp-nodelay": True,
          "ws-mask-server-frames": False,
          "ws-require-masked-client-frames": True,
          "ws-apply-mask": True,
          "ws-validate-utf8": True,
          "ws-enable-webstatus": True,
          "ws-accept-queue-size": 5000, # forwarded to backlog parameter on listenTCP/listenSSL
          "ws-enable-webserver": True, # if True, run WebSocket under Twisted Web Site and provide static file Web serving
          "ws-websocket-path": "ws", # if "ws-enable-webserver" == True, path under which WebSocket is mapped with Twisted Web Site

          "ws-enable-permessage-deflate": True,
          "ws-permessage-deflate-window-size": 0,
          "ws-permessage-deflate-require-window-size": False,

          ## CGI
          ##
          "appweb-cgi-enable": False,
          "appweb-cgi-path": "cgi",
          "appweb-cgi-processor": "",

          ## Update options
          ##
          "update-url": Database.CROSSBAR_UPDATE_URL,
          "update-check-interval": 600,

          "eula-accepted": None,

          ## admin API and UI
          "service-enable-adminui": True,
 
          ## main application WebSocket/Web network service
          "service-enable-appws": True,
          "service-enable-appweb": True,
 
          ## auxiliary network services
          "service-enable-flashpolicy": False,
          "service-enable-echows": False,
          "service-enable-ftp": False,
 
          ## system monitoring services
          "service-enable-netstat": True,
          "service-enable-vmstat": True,
 
          ## integration services
          "service-enable-restpusher": True,
          "service-enable-restremoter": True,
          "service-enable-pgpusher": True,
          "service-enable-pgremoter": True,
          "service-enable-orapusher": True,
          "service-enable-oraremoter": True,
          "service-enable-hanapusher": False,
          "service-enable-hanaremoter": False,
          "service-enable-extdirectremoter": False,
          }

      if not scratchMode:
         CONFIG.update({"database-created": created,
                        "admin-password": "secret"})

      ## default global configuration
      ##
      for k in CONFIG:
         cur.execute("INSERT INTO config (key, value) VALUES (?, ?)", [k, json_dumps(CONFIG[k])])
      db.commit()

      ## default client permission: allow everything for anynonymous
      cur.execute("INSERT INTO clientperm (id, created, topic_uri, match_by_prefix, allow_publish, allow_subscribe) VALUES (?, ?, ?, ?, ?, ?)",
                  [newid(), utcnow(), "http://", 1, 1, 1])
      db.commit()

      if self.checkForOracleXE():
         log.msg("Inserting initial configuration for 'Tavendo WebMQ with Oracle XE'")
         oraConnectId = newid()
         now = utcnow()
         cur.execute("INSERT INTO oraconnect (id, created, label, host, port, sid, user, password, demo_user, demo_password, connection_timeout) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                     [oraConnectId, now, "WebMQ", "127.0.0.1", 1521, "XE", "WEBMQ", "webmq", "WEBMQDEMO", "webmqdemo", 5])
         cur.execute("INSERT INTO orapushrule (id, created, oraconnect_id, topic_uri, match_by_prefix) VALUES (?, ?, ?, ?, ?)",
                     [newid(), now, oraConnectId, "http://", 1])
         cur.execute("INSERT INTO oraremote (id, created, oraconnect_id, schema_list, rpc_base_uri, connection_pool_min_size, connection_pool_max_size, connection_timeout, request_timeout) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
                     [newid(), now, oraConnectId, "", "http://", 3, 10, 5, 2])
         db.commit()

      log.msg("database initialized.")


   def checkForOracleXE(self):
      log.msg("Trying to detect locally running Oracle XE ..")
      try:
         import cx_Oracle
         dsn = cx_Oracle.makedsn("127.0.0.1", 1521, "XE")
         conn = cx_Oracle.connect("WEBMQ", "webmq", dsn)
         cur = conn.cursor()
         cur.execute("SELECT SYSTIMESTAMP AT TIME ZONE 'utc' FROM dual")
         res = cur.fetchone()
         log.msg("Oracle XE with WebMQ repository seems to be running on localhost [%s]." % res[0])
         return True
      except:
         log.msg("No Oracle XE is running on localhost or no WebMQ repository installed.")
         return False


   def getDatabaseInfo(self):
      """
      Get information about service database.
      """
      if os.path.isfile(self.dbfile):
         statinfo = os.stat(self.dbfile)
         size = statinfo.st_size
         modified = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(statinfo.st_mtime))
         db = sqlite3.connect(self.dbfile)
         cur = db.cursor()
         cur.execute("SELECT name FROM sqlite_master WHERE type = 'table' ORDER BY name")
         tables = []
         for r in cur.fetchall():
            tables.append(str(r[0]))
         info = {"file-path": self.dbfile,
                 "file-size": size,
                 "file-modified": modified,
                 "database-tables": tables}
         if "config" in tables:
            for a in ['database-version', 'database-created', 'instance-id']:
               cur.execute("SELECT value FROM config WHERE key = ?", [a])
               res = cur.fetchone()
               if res:
                  info[a] = json_loads(res[0])
               else:
                  return None
            info['host-id'] = "FIXME" # self.hostid
            return info
         else:
            return None
      else:
         return None


   def getConfig(self, key = None, includeTls = False, conn = None):
      """
      Get config from application database.
      """
      if not conn:
         conn = sqlite3.connect(self.dbfile)
      cur = conn.cursor()
      if key is None:
         cur.execute("SELECT key, value FROM config ORDER BY key")
         res = {}
         for r in cur.fetchall():
            res[r[0]] = json_loads(r[1])
         if includeTls:
            for t in Database.NETPORTS_TLS_PREFIXES:
               if res[t + "-tls"]:
                  cur.execute("SELECT key_priv, cert FROM servicekey WHERE id = ?", [res[t + "-tlskey"]])
                  res2 = cur.fetchone()
                  if res2:
                     res[t + "-tlskey-pem"] = res2[0]
                     res[t + "-tlscert-pem"] = res2[1]
         return res
      else:
         if type(key) in [str, unicode]:
            cur.execute("SELECT value FROM config WHERE key = ?", [key,])
            rs = cur.fetchone()
            if rs:
               return json_loads(rs[0])
            else:
               return None
         elif type(key) == list:
            cur.execute("SELECT key, value FROM config ORDER BY key")
            res = {}
            for r in cur.fetchall():
               if r[0] in key:
                  res[r[0]] = json_loads(r[1])
            return res
         else:
            return None


   def getWebAdminPort(self):
      """
      Get admin UI web port.
      """
      try:
         res = self.getConfig(["admin-web-port", "admin-web-tls"])
         return (res["admin-web-port"], res["admin-web-tls"])
      except:
         return (ADMIN_WEB_PORT_DEFAULT, False)


   def getWebAdminURL(self):
      adminport = self.getWebAdminPort()
      import socket
      hostname = socket.gethostname()
      return "http%s://%s:%s" % ('s' if adminport[1] else '', hostname, adminport[0])


   def getLicenseOptions(self):
      if self.licenseOptions is None:

         edition = 'oracle'
         #edition = 'appserver'

         opts = {'edition': edition,
                 ##
                 'tls': True,
                 'connections': 200000,
                 ##
                 'rest': True,
                 'extdirect': True,
                 'hana': True,
                 'oracle': True,
                 'postgresql': True}
         self.licenseOptions = opts
      return self.licenseOptions


   def getInstalledOptions(self):
      if self.installedOptions is None:

         opts = {}

         try:
            import pyodbc
            opts['hana'] = True
         except:
            opts['hana'] = False

         try:
            import cx_Oracle
            opts['oracle'] = True
         except:
            opts['oracle'] = False

         try:
            import psycopg2
            opts['postgresql'] = True
         except:
            opts['postgresql'] = False

         self.installedOptions = opts

      return self.installedOptions

########NEW FILE########
__FILENAME__ = dbexport
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import sys, datetime, os, re

from twisted.internet import utils, protocol, defer
from twisted.python import log
from twisted.internet.error import ProcessDone, ProcessTerminated

from crossbar.platform import SYSCMD_ZIP, SYSCMD_SQLITE3


class DbExportZipperProtocol(protocol.ProcessProtocol):

   def __init__(self, d, outdir, outurl, infile, password, extrafiles = []):
      self.d = d
      self.outdir = outdir
      self.outurl = outurl
      self.infile = infile
      self.outfile = '%s.zip' % self.infile
      self.password = password
      self.extrafiles = extrafiles
      self.stderr_data = ""

   def run(self):
      cmd = ['zip', '-q', '-9', '-j']
      if self.password is not None:
         cmd.append('-e')
         cmd.append('-P%s' % self.password)
      cmd.append(self.outfile)
      cmd.append(self.infile)
      for e in self.extrafiles:
         if os.path.exists(e):
            cmd.append(e)
      log.msg("%s %s %s", (SYSCMD_ZIP, cmd, self.outdir))
      from twisted.internet import reactor
      reactor.spawnProcess(self,
                           SYSCMD_ZIP,
                           cmd,
                           path = self.outdir)

   def connectionMade(self):
      self.transport.closeStdin()

   def outReceived(self, data):
      self.stderr_data += data

   def errReceived(self, data):
      self.stderr_data += data

   def processEnded(self, reason):
      if isinstance(reason.value, ProcessDone):
         try:
            os.remove(os.path.join(self.outdir, self.infile))
         except Exception, e:
            self.d.errback(e)
         self.d.callback("%s/%s" % (self.outurl, self.outfile))
      else:
         log.msg("ZIPing SQLite database dump failed")
         log.msg(self.stderr_data)
         self.d.errback(reason)


class DbExportProtocol(protocol.ProcessProtocol):
   """
   SQLite database dumper as Twisted process protocol.
   """

   MODE_BACKUP = 1
   MODE_DIAGNOSTICS = 2

   def __init__(self, d, services, dbfile, dbversion, outdir, outurl, password = None, mode = MODE_BACKUP, logsdir = None):
      """
      Create a ZIP file with a dump of a SQLite database.

      :param d: A deferred which gets fired upon completion.
      :type d: A twisted.internet.defer.Deferred
      :param dbfile: Full path to SQLite database file to export.
      :type dbfile: str
      :param dbversion: Appliance database version.
      :type dbversion: int
      :param outdir: Output directory where to create dump file.
      :type outdir: str
      :param password: Password to encrypt ZIP file or None.
      :type password: str
      :param mode: Export mode, one of MODE_BACKUP (normal DB dump) or MODE_DIAGNOSTICS (diagnostics file).
      :type mode: int
      :param logsdir: Directory of Twisted logs (only relevant for MODE_DIAGNOSTICS, but even there optional)
      :type logsdir: str
      """
      self.mode = mode
      self.logsdir = logsdir
      self.d = d
      self.services = services
      self.dbfile = dbfile
      self.dbversion = dbversion
      self.outdir = outdir

      if not os.path.exists(self.outdir):
         os.mkdir(self.outdir)
         log.msg("database export directory %s created" % self.outdir)

      now = datetime.datetime.utcnow().strftime("%Y%m%d_%H%M%S")

      self.extrafiles = []

      if self.mode == DbExportProtocol.MODE_BACKUP:
         self.outfile = "crossbar_%s_%s.dump" % (now, self.dbversion)
      else:
         self.outfile = "diagnostic_crossbar_%s_%s.dump" % (now, self.dbversion)

         ## add diagnostics log
         ##
         fn = '/tmp/crossbar.diagnostic.log'
         f = open(fn, 'wb')
         f.write(self.services['platform'].getDiagnostics(as_json = True))
         f.close()
         self.extrafiles.append(fn)

         ## add crossbar.io logs (Twisted logs)
         ##
         if self.logsdir is not None:
            self._addExtra(self.logsdir, "^crossbar\.log.*$")

         ## add system logs
         ##
         # FIXME: those are world readable on FreeBSD, but only root-readble on Linux
         #self._addExtra("/var/log", "^messages.*$")

      self.stderr_data = ""
      self.zipper = DbExportZipperProtocol(d, outdir, outurl, self.outfile, password, self.extrafiles)


   def _addExtra(self, fdir, fpat):
      pat = re.compile(fpat)
      for f in os.listdir(fdir):
         if pat.match(f):
            fn = os.path.join(fdir, f)
            if os.path.isfile(fn):
               self.extrafiles.append(fn)


   def run(self):
      from twisted.internet import reactor
      reactor.spawnProcess(self,
                           SYSCMD_SQLITE3,
                           ['sqlite3',
                            self.dbfile],
                           path = self.outdir)

   def connectionMade(self):
      self.transport.write(".output '%s'\n" % self.outfile)

      if self.mode == DbExportProtocol.MODE_BACKUP:
         self.transport.write(".dump\n")
      else:
         self.transport.write(".header on\n")
         self.transport.write(".echo on\n")
         self.transport.write(".mode tabs\n")
         self.transport.write(".schema\n")
         views = ['d_config',
                  'd_license',
                  'd_servicekey',
                  'd_cookie',
                  'd_ftpuser',

                  'd_appcredential',
                  'd_clientperm',
                  'd_postrule',

                  'd_extdirectremote',
                  'd_restremote',

                  'd_hanaconnect',
                  'd_hanapushrule',
                  'd_hanaremote',

                  'd_pgconnect',
                  'd_pgpushrule',
                  'd_pgremote',

                  'd_oraconnect',
                  'd_orapushrule',
                  'd_oraremote'
                  ]
         for v in views:
            self.transport.write("SELECT * FROM %s;\n" % v)

      self.transport.write(".quit\n")
      self.transport.closeStdin()

   def outReceived(self, data):
      self.stderr_data += data

   def errReceived(self, data):
      self.stderr_data += data

   def processEnded(self, reason):
      if isinstance(reason.value, ProcessDone):
         self.zipper.run()
      else:
         msg = "Export of SQLite database to dump failed"
         log.msg(msg)
         log.msg(self.stderr_data)
         self.d.errback(msg)

########NEW FILE########
__FILENAME__ = dbimport
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import sys, datetime, os, zipfile, tempfile, re

from twisted.python import log
from twisted.internet import protocol, defer
from twisted.internet.error import ProcessDone, ProcessTerminated
from twisted.web.resource import Resource

from crossbar.platform import SYSCMD_SQLITE3


class DbImportProtocol(protocol.ProcessProtocol):

   def __init__(self, d, dumpfile, outfile):
      self.d = d
      self.dumpfile = dumpfile
      self.outfile = outfile
      self.stderr_data = ""

   def _removeIfExists(self, filename):
      if os.path.exists(filename):
         if os.path.isfile(filename):
            os.remove(filename)

   def run(self):
      self._removeIfExists(self.outfile)
      from twisted.internet import reactor
      reactor.spawnProcess(self,
                           SYSCMD_SQLITE3,
                           ['sqlite3',
                            self.outfile])

   def connectionMade(self):
      self.transport.write(self.dumpfile.read())
      self.transport.closeStdin()

   def outReceived(self, data):
      self.stderr_data += data

   def errReceived(self, data):
      self.stderr_data += data

   def processEnded(self, reason):
      if isinstance(reason.value, ProcessDone):
         dbinfo = GetDatabaseInfo(self.outfile)
         if dbinfo is not None:
            self.d.callback(dbinfo)
         else:
            self._removeIfExists(self.outfile)
            self.d.errback("SQLite database is not a crossbar.io service database")
      else:
         self._removeIfExists(self.outfile)
         msg = "Import of SQLite database dump failed"
         log.msg(msg)
         log.msg(self.stderr_data)
         self.d.errback(msg)


DUMP_UPLOAD_ERROR_TEMPLATE = """
<html>
   <body>
      <h1>Upload failed!</h1>
      <p>%(error)s</p>
   </body>
</html>
"""

DUMP_UPLOAD_SUCCESS_TEMPLATE = """
<html>
   <body>
      <h1>Upload succeeded. Please restart service.</h1>
      <p>Database Created <b>%(database-created)s</b></p>
      <p>Database Version <b>%(database-version)s</b></p>
   </body>
</html>
"""

class UploadDatabaseDump(Resource):

   def __init__(self, import_dir):
      Resource.__init__(self)
      self.import_dir = str(import_dir)
      if not os.path.exists(self.import_dir):
         os.mkdir(self.import_dir)
         log.msg("database import directory %s created" % self.import_dir)

   def writeSuccess(self, request, dbinfo):
      request.write(DUMP_UPLOAD_SUCCESS_TEMPLATE % dbinfo)

   def writeError(self, request, errmsg):
      #
      # Errors:
      #
      #   No dump file given
      #   File is not a zip file
      #   File is encrypted, password required for extraction
      #   Bad password for file
      #   No database dump file contained in ZIP archive
      #   Multiple database dump files in ZIP archive
      #   Import of SQLite database dump failed
      #   SQLite database is not a Autobahn WebSocket Hub database
      #
      request.write(DUMP_UPLOAD_ERROR_TEMPLATE % {"error": errmsg})

   def render_POST(self, request):

      ## avoid module level reactor import
      from twisted.web.server import NOT_DONE_YET

      if request.args.has_key('dbdump'):

         ## save uploaded file contents to temporary file
         ##
         data = request.args['dbdump'][0]
         f = tempfile.NamedTemporaryFile('wb', dir = self.import_dir)
         f.write(data)
         f.flush()

         ## if ZIP file password was given, use that
         ##
         password = None
         if request.args.has_key('password'):
            pw = request.args['password'][0].strip()
            if pw != "":
               password = pw

         z = None

         try:
            z = zipfile.ZipFile(f.name)
            if password is not None:
               z.setpassword(password)

            dfnames = z.namelist()
            pat = re.compile("^crossbar_\d{8,8}_\d{6,6}_\d+\.dump$") # crossbar_20111205_183519_37.dump
            dfn = None
            for df in dfnames:
               if pat.match(df):
                  if dfn is None:
                     dfn = df
                  else:
                     raise Exception("Multiple database dump files in ZIP archive")

            if dfn is not None:

               z.extract(dfn, self.import_dir, password)

               z.close()
               z = None
               f.close()
               f = None

               dumpfile = open(os.path.join(self.import_dir, dfn), 'rb')

               d = defer.Deferred()

               def closeremove():
                  fn = dumpfile.name
                  dumpfile.close()
                  if os.path.exists(fn) and os.path.isfile(fn):
                     os.remove(fn)

               def success(res, request):
                  closeremove()
                  self.writeSuccess(request, res)
                  request.finish()

               def error(err, request):
                  closeremove()
                  self.writeError(request, err.value)
                  request.finish()

               d.addCallbacks(success, error, callbackArgs = [request], errbackArgs = [request])

               p = DbImportProtocol(d, dumpfile, "%s.import" % DBFILE)
               p.run()

               return NOT_DONE_YET
            else:
               raise Exception("No database dump file contained in ZIP archive")

         except Exception, e:
            errmsg = e.args[0]
            self.writeError(request, errmsg)
            return ""
         finally:
            if z is not None:
               z.close()
            if f is not None:
               f.close()

      else:
         self.writeError(request, "No dump file given")
         return ""

########NEW FILE########
__FILENAME__ = netstat
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import random

from twisted.python import log
from twisted.internet import protocol
from twisted.application import service

from autobahn.util import utcnow

from crossbar.adminwebmodule.uris import URI_EVENT


class NetstatService(service.Service):

   SERVICENAME = "Network monitoring"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.interval = 1
      self.isRunning = False

   def startService(self):
      log.msg("Starting %s service .." % self.SERVICENAME)
      self.current = {"timestamp": utcnow(),
                      "packets-in": 0,
                      "bytes-in": 0,
                      "packets-out": 0,
                      "bytes-out": 0}
      self.isRunning = True
      self.emitFake()

   def stopService(self):
      log.msg("Stopping %s service .." % self.SERVICENAME)
      self.isRunning = False

   def dispatchEvent(self, event):
      if self.services.has_key("adminws"):
         self.services["adminws"].dispatchAdminEvent(URI_EVENT + "on-netstat", event)

   def getCurrent(self):
      return self.current

   def emitFake(self):
      self.processRecord(random.randint(0, 1000),
                         random.randint(0, 100000),
                         random.randint(0, 1000),
                         random.randint(0, 100000))
      if self.isRunning:
         self.reactor.callLater(self.interval, self.emitFake)

   def processRecord(self, inPackets, inBytes, outPackets, outBytes):

      evt = {"timestamp": utcnow(),
             "packets-in": inPackets,
             "bytes-in": inBytes,
             "packets-out": outPackets,
             "bytes-out": outBytes}
      self.current = evt
      self.dispatchEvent(evt)

########NEW FILE########
__FILENAME__ = platform
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import os, sys, datetime, uuid

from distutils.sysconfig import get_python_lib # for site-packages directory

from twisted.python import log
from twisted.application import service

from autobahn.wamp import json_dumps


class PlatformService(service.Service):

   SERVICENAME = "Platform"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)
      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      self.isRunning = False


   def getHostId(self):
      return str(uuid.UUID(int = uuid.getnode()))


   def getHardwareModel(self):
      return "Fake-CPU 3.0 GHz"


   def getCoreCount(self):
      return 1


   def getCoreClock(self):
      return 3000


   def getMemory(self):
      return 1024


   def getPlatformInfo(self):
      return {'os': self.getOsVersion(),
              'appliance': self.getApplianceVersion(),
              'model': self.getHardwareModel(),
              'cores': self.getCoreCount(),
              'clock': self.getCoreClock(),
              'memory': self.getMemory()}


   def getSysctl(self, as_dict = False):
      if as_dict:
         return {}
      else:
         return []


   def getBoottime(self):
      return datetime.datetime.utcnow()


   def getNetworkConfig(self, ifc = "em0"):
      return {'mac': '01:12:34:56',
              'ip': '192.168.1.100',
              'netmask': '255.255.255.0',
              'broadcast': '255.255.255.255',
              'default_router': '192.168.1.1',
              'hostname': 'localhost',
              'nameserver': '192.168.1.1'}


   def getSystime(self):
      return datetime.datetime.utcnow()


   def getUptime(self):
      return '0 s'


   def getOsVersion(self):
      return "Fake OS 1.0"


   def getApplianceVersion(self):
      return "unknown"


   def getPythonVersion(self):
      return '.'.join([str(x) for x in list(sys.version_info[:3])])


   def getPythonVersionString(self):
      return sys.version.replace('\n', ' ')


   def getTwistedVersion(self):
      try:
         import pkg_resources
         version = pkg_resources.require("Twisted")[0].version
      except:
         ## i.e. no setuptools installed ..
         version = None
      return version


   def getDmesg(self):
      return []


   def getIfconfig(self):
      return []


   def getPkgInfo(self):
      return []


   def getSitePackages(self):
      res = sorted(os.listdir(get_python_lib()))
      return res


   def getDiagnostics(self, as_json = False):
      r = {}
      r['python-site-packages'] = self.getSitePackages()
      r['package-info'] = self.getPkgInfo()
      r['interface-config'] = self.getIfconfig()
      r['dmesg'] = self.getDmesg()
      r['twisted-version'] = self.getTwistedVersion()
      r['python-version'] = self.getPythonVersion()
      r['os-version'] = self.getOsVersion()
      r['host-id'] = self.getHostId()
      r['network-config'] = self.getNetworkConfig()
      r['sysctl'] = self.getSysctl()
      if as_json:
         return json_dumps(r, indent = 3)
      else:
         return r


   def applianceControl(self, cmd):
      if cmd == "restart":
         self.reactor.stop()
         sys.exit(0)
      elif cmd == "update":
         log.msg("ApplianceControl [FAKE]: update triggered .. will do nothing on FAKE platform")
         return "Update on FAKE platform: doing nothing!"
      else:
         raise Exception("ApplianceControl [FAKE]: skipping unknown command '%s'" % cmd)

########NEW FILE########
__FILENAME__ = vmstat
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import random

from twisted.python import log
from twisted.internet import protocol
from twisted.application import service

from autobahn.util import utcnow

from crossbar.adminwebmodule.uris import URI_EVENT


class VmstatService(service.Service):

   SERVICENAME = "Memory monitoring"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.interval = 1
      self.isRunning = False

   def startService(self):
      log.msg("Starting %s service .." % self.SERVICENAME)
      self.current = {"timestamp": utcnow(),
                      "mem-used": 0,
                      "mem-free": 0,
                      "cpu-user": 0,
                      "cpu-system": 0,
                      "cpu-idle": 0}
      self.isRunning = True
      self.emitFake()

   def stopService(self):
      log.msg("Stopping %s service .." % self.SERVICENAME)
      self.isRunning = False

   def dispatchEvent(self, event):
      if self.services.has_key("adminws"):
         self.services["adminws"].dispatchAdminEvent(URI_EVENT + "on-vmstat", event)

   def getCurrent(self):
      return self.current

   def emitFake(self):
      m1 = random.randint(0, 100)
      m2 = 100 - m1

      c1 = random.randint(0, 100)
      c2 = random.randint(0, 100 - c1)
      c3 = 100 - c2 - c1
      self.processRecord(m1, m2, c1, c2, c3)
      if self.isRunning:
         self.reactor.callLater(self.interval, self.emitFake)

   def processRecord(self, memUsed, memFree, cpuUser, cpuSys, cpuIdle):
      evt = {"timestamp": utcnow(),
             "mem-used": memUsed,
             "mem-free": memFree,
             "cpu-user": cpuUser,
             "cpu-system": cpuSys,
             "cpu-idle": cpuIdle}
      self.current = evt
      self.dispatchEvent(evt)

########NEW FILE########
__FILENAME__ = netstat
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log
from twisted.internet import protocol
from twisted.application import service

from autobahn.util import utcnow

from crossbar.adminwebmodule.uris import URI_EVENT


class NetstatProtocol(protocol.ProcessProtocol):
   """
   Protocol to continuously consume output from FreeBSD netstat command.
   """

   def __init__(self, service = None):
      self.service = service
      self.current = {"timestamp": utcnow(),
                      "packets-in": 0,
                      "bytes-in": 0,
                      "packets-out": 0,
                      "bytes-out": 0}

   def connectionMade(self):
      self.line = ""
      self.transport.closeStdin()

   def processEnded(self, reason):
      pass

   def outReceived(self, data):
      if len(data) > 0:
         e = data.find('\n')
         if e >= 0:
            self.line += data[:e]
            self.processLine()
            self.line = ""
            self.outReceived(data[e + 1:])
         else:
            self.line += data

   def processLine(self):
      s = self.line.split()
      if len(s) == 8:
         try:
            d = [int(x) for x in s]
         except:
            pass
         else:
            (inPackets, inErrs, inDrops, inBytes, outPackets, outErrs, outBytes, outColls) = d
            self.processRecord(inPackets, inBytes, outPackets, outBytes)

   def processRecord(self, inPackets, inBytes, outPackets, outBytes):
      evt = {"timestamp": utcnow(),
             "packets-in": inPackets,
             "bytes-in": inBytes,
             "packets-out": outPackets,
             "bytes-out": outBytes}
      self.current = evt
      if self.service:
         self.service.dispatchEvent(evt)
      else:
         log.msg(evt)


class NetstatService(service.Service):

   SERVICENAME = "Network monitoring"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.interval = 1
      self.isRunning = False

   def startService(self):
      log.msg("Starting %s service .." % self.SERVICENAME)
      self.netstat = NetstatProtocol(self)
      self.reactor.spawnProcess(self.netstat, 'netstat', ['netstat', '-w', str(self.interval)])
      self.isRunning = True

   def stopService(self):
      log.msg("Stopping %s service .." % self.SERVICENAME)
      self.netstat.transport.signalProcess('KILL')
      self.isRunning = False

   def dispatchEvent(self, event):
      if self.services.has_key("adminws"):
         self.services["adminws"].dispatchAdminEvent(URI_EVENT + "on-netstat", event)

   def getCurrent(self):
      return self.netstat.current

########NEW FILE########
__FILENAME__ = platform
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import os, hmac, hashlib, base64, sys, crypt, getpass, pwd, \
       time, math, datetime, shutil, subprocess, uuid

from distutils.sysconfig import get_python_lib # for site-packages directory

from twisted.python import log
from twisted.internet import utils
from twisted.application import service

from autobahn.wamp import json_loads, json_dumps

from crossbar.database import Database


class PlatformService(service.Service):

   SERVICENAME = "Platform"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False

      self._BOOTED = None
      self._TIMEZONES = None


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)
      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      self.isRunning = False


   def getHostId(self):
      try:
         s = open("/etc/hostid").read()
         return s.strip()
      except:
         return str(uuid.UUID(int = uuid.getnode()))


   def getHardwareModel(self):
      try:
         s = os.popen("sysctl hw.model").read()
         model = ' '.join(s.strip().split()[1:])
         return model
      except:
         return None


   def getCoreCount(self):
      try:
         s = os.popen("sysctl hw.ncpu").read().split()[1]
         ncpu = int(s)
         return ncpu
      except:
         return None


   def getCoreClock(self):
      try:
         s = os.popen("sysctl hw.clockrate").read().split()[1]
         mhz = int(s)
         return mhz
      except:
         return None


   def getMemory(self):
      try:
         s = os.popen("sysctl hw.realmem").read().strip().split()[1]
         return int(math.ceil(float(s)/1024./1024.))
      except:
         return None


   def getPlatformInfo(self):
      return {'os': self.getOsVersion(),
              'appliance': self.getApplianceVersion(),
              'model': self.getHardwareModel(),
              'cores': self.getCoreCount(),
              'clock': self.getCoreClock(),
              'memory': self.getMemory()}


   def getSysctl(self, as_dict = False):
      try:
         s = os.popen("sysctl -a").read().splitlines()
         if as_dict:
            r = {}
            for x in s:
               ss = x.strip()
               if ss != "":
                  i = ss.find(':')
                  if i >= 0:
                     key = ss[:i]
                     val = ss[i+1:].strip()
                     r[key] = val
            return r
         else:
            return [x.strip() for x in s]
      except:
         return None



   def getBoottime(self):
      """
      Get system boot time as UTC datetime.
      """
      if self._BOOTED is not None:
         return self._BOOTED
      else:
         try:
            s = os.popen("sysctl kern.boottime").read()
            i1 = s.find("sec")
            i2 = s.find(",", i1)
            s2 = s[i1:i2]
            i3 = s2.find("=")
            s3 = s2[i3+1:].strip()
            bt = int(s3)
            self._BOOTED = datetime.datetime.utcfromtimestamp(bt)
            return self._BOOTED
         except:
            return None


   def getNetworkConfig(self, ifc = "em0"):

      mac = ""
      ip = ""
      netmask = ""
      broadcast = ""
      default_router = ""
      nameserver = ""

      ## interface configuration
      try:
         s = os.popen("/sbin/ifconfig %s" % ifc).read()
         for l in s.replace('\t', '').splitlines():
            if l[0:5] == "ether":
               mac = l.split(' ')[1]
            if l[0:4] == 'inet':
               p = l.split(' ')
               ip = p[1]
               nm = p[3][2:]
               netmask = "%d.%d.%d.%d" % (int(nm[0:2], 16), int(nm[2:4], 16), int(nm[4:6], 16), int(nm[6:8], 16))
               broadcast = p[5]
      except:
         mac = ""
         ip = ""
         netmask = ""
         broadcast = ""

      ## default router (gateway)
      try:
         s = os.popen("/usr/bin/netstat -rn | /usr/bin/grep default").read()
         default_router = s.split()[1]
      except:
         default_router = ""

      ## nameserver
      try:
         s = os.popen("/usr/bin/grep nameserver /etc/resolv.conf").read()
         nameserver = s.splitlines()[0].split()[1]
      except:
         nameserver = ""

      ## hostname
      hostname = os.popen("hostname").read().strip()

      return {'mac': mac, 'ip': ip, 'netmask': netmask, 'broadcast': broadcast, 'default_router': default_router, 'hostname': hostname, 'nameserver': nameserver}


   def getSystime(self):
      s = os.popen("/bin/date").read()
      return s.strip()


   def getUptime(self):
      s = os.popen("uptime").read()
      i1 = s.find("up")
      i2 = s.find(",", i1)
      return s[i1+2:i2].strip()


   def getOsVersion(self):
      s = os.popen("uname -sr").read()
      return s.strip()


   def getApplianceVersion(self):
      try:
         o = json_load(open("/etc/appliance.json"))
         return o["image"]
      except:
         return "unknown"


   def getPythonVersion(self):
      return '.'.join([str(x) for x in list(sys.version_info[:3])])


   def getPythonVersionString(self):
      return sys.version.replace('\n', ' ')


   def getTwistedVersion(self):
      try:
         import pkg_resources
         version = pkg_resources.require("Twisted")[0].version
      except:
         ## i.e. no setuptools installed ..
         version = None
      return version


   def getDmesg(self):
      s = os.popen("dmesg -a").read().splitlines()
      return [x.strip() for x in s]


   def getIfconfig(self):
      s = os.popen("ifconfig -a").read().splitlines()
      return [x.strip() for x in s]


   def getPkgInfo(self):
      s = os.popen("pkg_info").read()
      return [x.split()[0] for x in s.splitlines()]


   def getSitePackages(self):
      res = sorted(os.listdir(get_python_lib()))
      return res


   def getDiagnostics(self, as_json = False):
      r = {}
      r['python-site-packages'] = self.getSitePackages()
      r['package-info'] = self.getPkgInfo()
      r['interface-config'] = self.getIfconfig()
      r['dmesg'] = self.getDmesg()
      r['twisted-version'] = self.getTwistedVersion()
      r['python-version'] = self.getPythonVersion()
      r['os-version'] = self.getOsVersion()
      r['host-id'] = self.getHostId()
      r['network-config'] = self.getNetworkConfig()
      r['sysctl'] = self.getSysctl()
      if as_json:
         return json_dumps(r, indent = 3)
      else:
         return r


   def applianceControl(self, cmd):
      if cmd == "restart":
         ## for restarting, we just stop the reactor, exit and rely on being
         ## automatically restarted. this is most robust/clean way!
         self.reactor.stop()
         sys.exit(0)
      elif cmd == "update":
         cmd = '/home/crossbar/app/bin/easy_install'
         args = ['-H', Database.CROSSBAR_UPDATE_HOST, '-U', '-v', '-f', Database.CROSSBAR_UPDATE_URL, 'crossbar']
         d = utils.getProcessOutput(cmd, args, errortoo = True)
         def logAndReturn(r):
            log.msg(r)
            return r
         d.addBoth(logAndReturn)
         return d
      else:
         raise Exception("ApplianceControl: skipping unknown command '%s'" % cmd)


   ############################################################################
   ## END OF COMMON INTERFACE!

   def getTimezones(self):
      if self._TIMEZONES is not None:
         return self._TIMEZONES
      else:
         tzr = open("/usr/share/zoneinfo/zone.tab").read().splitlines()
         tz = []
         for t in tzr:
            if len(t) > 0 and t[0] != '#':
               tt = t.split()
               tz.append(tt[2])
         tz = sorted(tz)
         self._TIMEZONES = tz
         return tz


   def getTimeInTimezone(self, tz = None):
      if tz is not None and tz not in self.getTimezones():
         return None
      else:
         if tz is None:
            s1 = os.popen("date").read()
            s2 = os.popen("date '+%Z %z'").read().split()
         else:
            s1 = os.popen("TZ=%s date" % tz).read()
            s2 = os.popen("TZ=%s date '+%%Z %%z'" % tz).read().split()
         return (s1.strip(), s2[0].strip(), s2[1].strip())


   def setTimezone(self, tz):
      if tz in self.getTimezones():
         src = os.path.join("/usr/share/zoneinfo", tz)
         dst = "/etc/localtime"
         if os.path.isfile(src):
            try:
               shutil.copy(src, dst)
               return True
            except:
               pass
      return False


   def login(self, username, cleartext):
      try:
         cryptedpasswd = pwd.getpwnam(username)[1]
      except:
         return -2
      if cryptedpasswd:
         if cryptedpasswd == 'x' or cryptedpasswd == '*':
            return -3 # currently no support for shadow passwords
         if crypt.crypt(cleartext, cryptedpasswd) == cryptedpasswd:
            return 0 # ok, correct password
         else:
            return -1 # wrong password
      else:
         return 0 # no password for user

########NEW FILE########
__FILENAME__ = vmstat
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log
from twisted.internet import protocol
from twisted.application import service

from autobahn.util import utcnow

from crossbar.adminwebmodule.uris import URI_EVENT


class VmstatProtocol(protocol.ProcessProtocol):
   """
   Protocol to continuously consume output from FreeBSD vmstat command.
   """

   def __init__(self, service = None):
      self.service = service
      self.current = {"timestamp": utcnow(),
                      "mem-used": 0,
                      "mem-free": 0,
                      "cpu-user": 0,
                      "cpu-system": 0,
                      "cpu-idle": 0}

   def connectionMade(self):
      self.line = ""
      self.transport.closeStdin()

   def processEnded(self, reason):
      pass

   def outReceived(self, data):
      if len(data) > 0:
         e = data.find('\n')
         if e >= 0:
            self.line += data[:e]
            self.processLine()
            self.line = ""
            self.outReceived(data[e + 1:])
         else:
            self.line += data

   def processLine(self):
      s = self.line.split()
      if len(s) == 17:
         try:
            d = [int(x) for x in s]
         except:
            pass
         else:
            (_r, _b, _w, _avm, _fre, _flt, _re, _pi, _po, _fr, _sr, _in, _sy, _cs, _us, _sy, _id) = d
            memUsed = int(round(100. * float(_avm) / float(_avm + _fre)))
            memFree = 100 - memUsed
            self.processRecord(memUsed, memFree, _us, _sy, _id)

   def processRecord(self, memUsed, memFree, cpuUser, cpuSys, cpuIdle):
      evt = {"timestamp": utcnow(),
             "mem-used": memUsed,
             "mem-free": memFree,
             "cpu-user": cpuUser,
             "cpu-system": cpuSys,
             "cpu-idle": cpuIdle}
      self.current = evt
      if self.service:
         self.service.dispatchEvent(evt)
      else:
         log.msg(evt)


class VmstatService(service.Service):

   SERVICENAME = "Memory monitoring"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.interval = 1
      self.isRunning = False

   def startService(self):
      log.msg("Starting %s service .." % self.SERVICENAME)
      self.vmstat = VmstatProtocol(self)
      self.reactor.spawnProcess(self.vmstat, 'vmstat', ['vmstat', '-H', '-n', '-w', str(self.interval)])
      self.isRunning = True

   def stopService(self):
      log.msg("Stopping %s service .." % self.SERVICENAME)
      self.vmstat.transport.signalProcess('KILL')
      self.isRunning = False

   def dispatchEvent(self, event):
      if self.services.has_key("adminws"):
         self.services["adminws"].dispatchAdminEvent(URI_EVENT + "on-vmstat", event)

   def getCurrent(self):
      return self.vmstat.current

########NEW FILE########
__FILENAME__ = netstat
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.python import log
from twisted.internet import protocol
from twisted.application import service

from autobahn.util import utcnow

from crossbar.adminwebmodule.uris import URI_EVENT


class NetstatProtocol(protocol.ProcessProtocol):
   """
   Protocol to continuously consume output from FreeBSD netstat command.
   """

   def __init__(self, service = None):
      self.service = service
      self.amap = {'RX packets': 'packets-in',
                   'TX packets': 'packets-out',
                   'RX bytes': 'bytes-in',
                   'TX bytes': 'bytes-out'}
      self.lvals = {}
      self.current = {"timestamp": utcnow(),
                      "packets-in": 0,
                      "bytes-in": 0,
                      "packets-out": 0,
                      "bytes-out": 0}

   def connectionMade(self):
      self.line = ""
      self.transport.closeStdin()

   def processEnded(self, reason):
      pass

   def outReceived(self, data):
      if len(data) > 0:
         e = data.find('\n')
         if e >= 0:
            self.line += data[:e]
            self.processLine()
            self.line = ""
            self.outReceived(data[e + 1:])
         else:
            self.line += data

   def processLine(self):
      if len(self.line.strip()) == 0:
         self.processRecord()
      else:
         for k in self.amap.keys():
            if k in self.line:
               i0 = self.line.find(':', self.line.find(k)) + 1
               val = int(self.line[i0:].split()[0])
               if self.lvals.has_key(k):
                  self.current[self.amap[k]] = val - self.lvals[k]
               self.lvals[k] = val

   def processRecord(self):
      self.current["timestamp"] = utcnow()
      if self.service:
         self.service.dispatchEvent(self.current)
      else:
         log.msg(self.current)


class NetstatService(service.Service):

   SERVICENAME = "Network monitoring"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.interval = 1
      self.isRunning = False

   def startService(self):
      # netstat -e -Ieth0 -w 1
      # ip -o -s link
      log.msg("Starting %s service .." % self.SERVICENAME)
      self.netstat = NetstatProtocol(self)
      self.reactor.spawnProcess(self.netstat, 'netstat', ['netstat', '-e', '-Ieth0', '-w', str(self.interval)])
      self.isRunning = True

   def stopService(self):
      log.msg("Stopping %s service .." % self.SERVICENAME)
      #self.netstat.transport.signalProcess('KILL')
      self.isRunning = False

   def dispatchEvent(self, event):
      if self.services.has_key("adminws"):
         self.services["adminws"].dispatchAdminEvent(URI_EVENT + "on-netstat", event)

   def getCurrent(self):
      return self.netstat.current

########NEW FILE########
__FILENAME__ = platform
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import os, hmac, hashlib, base64, sys, crypt, getpass, pwd, \
       time, math, datetime, shutil, subprocess, uuid

from distutils.sysconfig import get_python_lib # for site-packages directory

from twisted.python import log
from twisted.internet import utils
from twisted.application import service

from autobahn.wamp import json_loads, json_dumps

from crossbar.database import Database



class PlatformService(service.Service):

   SERVICENAME = "Platform"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False

      self._BOOTED = None
      self._TIMEZONES = None


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)
      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      self.isRunning = False


   def getHostId(self):
      ## FIXME
      return str(uuid.UUID(int = uuid.getnode()))


   def getHardwareModel(self):
      try:
         s = os.popen('grep "model name" /proc/cpuinfo').read().strip()
         s = s[s.find(':')+1:].strip()
         model = ' '.join([x.strip() for x in s.split()])
         return model
      except:
         return None


   def getCoreCount(self):
      try:
         s = os.popen('grep "cpu cores" /proc/cpuinfo').read().strip().split()[-1]
         ncpu = int(s)
         return ncpu
      except:
         return None


   def getCoreClock(self):
      try:
         s = os.popen('grep "cpu MHz" /proc/cpuinfo').read().strip().split()[-1]
         mhz = int(round(float(s)))
         return mhz
      except:
         return None


   def getMemory(self):
      try:
         s = os.popen("grep MemTotal /proc/meminfo").read().strip().split()[1]
         return int(math.ceil(float(s)/1024.))
      except:
         return None


   def getPlatformInfo(self):
      return {'os': self.getOsVersion(),
              'appliance': self.getApplianceVersion(),
              'model': self.getHardwareModel(),
              'cores': self.getCoreCount(),
              'clock': self.getCoreClock(),
              'memory': self.getMemory()}


   def getSysctl(self, as_dict = False):
      # this could be done using the procinfo command which gathers
      # information from /proc, but for some reasons, the cmd is
      # unavailable on Amazon Linux
      # http://linux.die.net/man/8/procinfo
      if as_dict:
         return {}
      else:
         return []


   def getBoottime(self):
      """
      Get system boot time as UTC datetime.
      """
      if self._BOOTED is not None:
         return self._BOOTED
      else:
         try:
            s = os.popen("grep btime /proc/stat").read()
            self._BOOTED = datetime.datetime.utcfromtimestamp(float(s.split()[1].strip()))
            return self._BOOTED
         except:
            return None


   def getNetworkConfig(self, ifc = "eth0"):

      ## interface configuration
      mac = ""
      ip = ""
      netmask = ""
      broadcast = ""
      try:
         s = os.popen("/sbin/ifconfig %s" % ifc).read()
         for l in s.splitlines():
            ll = l.split()
            if len(ll) == 5 and ll[3] == 'HWaddr':
               mac = ll[4].strip()
            if len(ll) == 4 and ll[0] == 'inet':
               ip = ll[1].split(':')[1]
               broadcast = ll[2].split(':')[1]
               netmask = ll[3].split(':')[1]
      except:
         pass

      ## default router (gateway)
      try:
         s = os.popen("/bin/netstat -rn | /bin/grep UG").read()
         default_router = s.split()[1]
      except:
         default_router = ""

      ## nameserver
      try:
         s = os.popen("/bin/grep nameserver /etc/resolv.conf").read()
         nameserver = s.splitlines()[0].split()[1]
      except:
         nameserver = ""

      ## hostname
      hostname = os.popen("/bin/hostname").read().strip()

      return {'mac': mac, 'ip': ip, 'netmask': netmask, 'broadcast': broadcast, 'default_router': default_router, 'hostname': hostname, 'nameserver': nameserver}


   def getSystime(self):
      s = os.popen("/bin/date").read()
      return s.strip()


   def getUptime(self):
      s = os.popen("uptime").read()
      i1 = s.find("up")
      i2 = s.find(",", i1)
      return s[i1+2:i2].strip()


   def getOsVersion(self):
      s = os.popen("uname -sr").read()
      return s.strip()


   def getApplianceVersion(self):
      try:
         o = json_loads(open("/etc/appliance.json").read())
         return o["image"]
      except:
         return "unknown"


   def getPythonVersion(self):
      return '.'.join([str(x) for x in list(sys.version_info[:3])])


   def getPythonVersionString(self):
      return sys.version.replace('\n', ' ')


   def getTwistedVersion(self):
      try:
         import pkg_resources
         version = pkg_resources.require("Twisted")[0].version
      except:
         ## i.e. no setuptools installed ..
         version = None
      return version


   def getDmesg(self):
      s = os.popen("dmesg").read().splitlines()
      return [x.strip() for x in s]


   def getIfconfig(self):
      s = os.popen("ifconfig -a").read().splitlines()
      return [x.strip() for x in s]


   def getPkgInfo(self):
      s = os.popen("yum list installed").read()
      return [x.split() for x in s.splitlines()]


   def getSitePackages(self):
      res = sorted(os.listdir(get_python_lib()))
      return res


   def getDiagnostics(self, as_json = False):
      r = {}
      r['python-site-packages'] = self.getSitePackages()
      r['package-info'] = self.getPkgInfo()
      r['interface-config'] = self.getIfconfig()
      r['dmesg'] = self.getDmesg()
      r['twisted-version'] = self.getTwistedVersion()
      r['python-version'] = self.getPythonVersion()
      r['os-version'] = self.getOsVersion()
      r['host-id'] = self.getHostId()
      r['network-config'] = self.getNetworkConfig()
      r['sysctl'] = self.getSysctl()
      if as_json:
         return json_dumps(r, indent = 3)
      else:
         return r


   def applianceControl(self, cmd):
      if cmd == "restart":
         ## for restarting, we just stop the reactor, exit and rely on being
         ## automatically restarted. this is most robust/clean way!
         self.reactor.stop()
         sys.exit(0)
      elif cmd == "update":
         #cmd = '/home/ec2-user/app/bin/easy_install'
         cmd = os.path.join(os.path.dirname(sys.executable), 'easy_install')
         args = ['-H', Database.CROSSBAR_UPDATE_HOST, '-U', '-v', '-f', Database.CROSSBAR_UPDATE_URL, 'crossbar']
         d = utils.getProcessOutput(cmd, args, errortoo = True)
         def logAndReturn(r):
            log.msg(r)
            return r
         d.addBoth(logAndReturn)
         return d
      else:
         raise Exception("ApplianceControl: skipping unknown command '%s'" % cmd)

########NEW FILE########
__FILENAME__ = vmstat
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import os

from twisted.python import log
from twisted.internet import protocol
from twisted.application import service

from autobahn.util import utcnow

from crossbar.adminwebmodule.uris import URI_EVENT


class VmstatProtocol(protocol.ProcessProtocol):
   """
   Protocol to continuously consume output from FreeBSD vmstat command.
   """

   def __init__(self, service = None):
      self.service = service

      s = os.popen("grep MemTotal /proc/meminfo").read().strip().split()[1]
      self.totalMemKB = int(s)

      self.current = {"timestamp": utcnow(),
                      "mem-used": 0,
                      "mem-free": 0,
                      "cpu-user": 0,
                      "cpu-system": 0,
                      "cpu-idle": 0}

   def connectionMade(self):
      self.line = ""
      self.transport.closeStdin()

   def processEnded(self, reason):
      pass

   def outReceived(self, data):
      if len(data) > 0:
         e = data.find('\n')
         if e >= 0:
            self.line += data[:e]
            self.processLine()
            self.line = ""
            self.outReceived(data[e + 1:])
         else:
            self.line += data

   def processLine(self):
      s = self.line.split()
      if len(s) == 17:
         try:
            d = [int(x) for x in s]
         except:
            pass
         else:
            (_r, _b, _swpd, _free, _buff, _cache, _si, _so, _bi, _bo, _in, _cs, _us, _sy, _id, _wa, _st) = d
            memUsed = int(round(100. * float(self.totalMemKB - _free) / float(self.totalMemKB)))
            memFree = 100 - memUsed
            self.processRecord(memUsed, memFree, _us, _sy, _id)

   def processRecord(self, memUsed, memFree, cpuUser, cpuSys, cpuIdle):
      evt = {"timestamp": utcnow(),
             "mem-used": memUsed,
             "mem-free": memFree,
             "cpu-user": cpuUser,
             "cpu-system": cpuSys,
             "cpu-idle": cpuIdle}
      self.current = evt
      if self.service:
         self.service.dispatchEvent(evt)
      else:
         log.msg(evt)


class VmstatService(service.Service):

   SERVICENAME = "Memory monitoring"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.interval = 1
      self.isRunning = False

   def startService(self):
      log.msg("Starting %s service .." % self.SERVICENAME)
      self.vmstat = VmstatProtocol(self)
      self.reactor.spawnProcess(self.vmstat, 'vmstat', ['vmstat', '-n', str(self.interval)])
      self.isRunning = True

   def stopService(self):
      log.msg("Stopping %s service .." % self.SERVICENAME)
      self.vmstat.transport.signalProcess('KILL')
      self.isRunning = False

   def dispatchEvent(self, event):
      if self.services.has_key("adminws"):
         self.services["adminws"].dispatchAdminEvent(URI_EVENT + "on-vmstat", event)

   def getCurrent(self):
      return self.vmstat.current

########NEW FILE########
__FILENAME__ = logger
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import sys
import datetime
import logging

import twisted

from crossbar.adminwebmodule.uris import URI_EVENT


class Logger:
   """
   Twisted log observer.
   """

   def __init__(self):
      self.dispatch = None
      self.log = []
      self.lineno = 1


   def setDispatch(self, dispatch):
      """
      Set the event dispatcher to publish log WAMP events.
      """
      self.dispatch = dispatch


   def __call__(self, obj):
      """
      Callback fired on logging.
      """
      # time, system, message, isError
      d = datetime.datetime.fromtimestamp(obj['time'])
      ds = d.strftime("%Y-%m-%d %H:%M:%S")
      if obj['isError']:
         loglevel = 'ERROR'
      else:
         loglevel = 'INFO'
      if type(obj['message']) == tuple and len(obj['message']) > 0:
         msg = obj['message'][0]
      else:
         msg = str(obj['message'])
      m = (self.lineno, ds, loglevel, obj['system'], msg)
      #m = (self.lineno, ds, loglevel, obj['system'], '\n'.join(list(obj['message'])))
      self.lineno += 1
      self.log.append(m)
      if self.dispatch:
         try:
            self.dispatch(URI_EVENT + "on-log", m)
         except:
            pass


   def getLog(self, limit = None):
      """
      Get accumulated log lines.
      """
      if limit is not None:
         return self.log[len(self.log) - limit:]
      else:
         return self.log


class LevelFileLogObserver(twisted.python.log.FileLogObserver):
   """

   NOTSET   = 0
   DEBUG    = 10
   INFO     = 20
   WARN     = 30
   WARNING  = 30
   ERROR    = 40
   CRITICAL = 50
   FATAL    = 50
   """

   def __init__(self, f, level = logging.INFO):
      twisted.python.log.FileLogObserver.__init__(self, f)
      self.logLevel = level


   def emit(self, eventDict):
      if eventDict['isError']:
         level = logging.ERROR
      elif 'level' in eventDict:
         level = eventDict['level']
      else:
         level = logging.INFO
      if level >= self.logLevel:
         twisted.python.log.FileLogObserver.emit(self, eventDict)

# trace

def debug(*args, **kwargs):
   kwargs['level'] = logging.DEBUG
   twisted.python.log.msg(*args, **kwargs)

def info(*args, **kwargs):
   kwargs['level'] = logging.INFO
   twisted.python.log.msg(*args, **kwargs)

def warning(*args, **kwargs):
   kwargs['level'] = logging.WARNING
   twisted.python.log.msg(*args, **kwargs)

if True:
   def error(*args, **kwargs):
      kwargs['level'] = logging.ERROR
      twisted.python.log.err(*args, **kwargs)
else:
   error = twisted.python.log.err

def critical(*args, **kwargs):
   kwargs['level'] = logging.CRITICAL
   twisted.python.log.msg(*args, **kwargs)

# http://docs.jboss.org/process-guide/en/html/logging.html
# FATAL - Use the FATAL level priority for events that indicate a critical service failure. If a service issues a FATAL error it is completely unable to service requests of any kind.
# ERROR - Use the ERROR level priority for events that indicate a disruption in a request or the ability to service a request. A service should have some capacity to continue to service requests in the presence of ERRORs.
# WARN - Use the WARN level priority for events that may indicate a non-critical service error. Resumable errors, or minor breaches in request expectations fall into this category. The distinction between WARN and ERROR may be hard to discern and so its up to the developer to judge. The simplest criterion is would this failure result in a user support call. If it would use ERROR. If it would not use WARN.
# INFO - Use the INFO level priority for service life-cycle events and other crucial related information. Looking at the INFO messages for a given service category should tell you exactly what state the service is in.
# DEBUG - Use the DEBUG level priority for log messages that convey extra information regarding life-cycle events. Developer or in depth information required for support is the basis for this priority. The important point is that when the DEBUG level priority is enabled, the JBoss server log should not grow proportionally with the number of server requests. Looking at the DEBUG and INFO messages for a given service category should tell you exactly what state the service is in, as well as what server resources it is using: ports, interfaces, log files, etc.
# TRACE - Use TRACE the level priority for log messages that are directly associated with activity that corresponds requests. Further, such messages should not be submitted to a Logger unless the Logger category priority threshold indicates that the message will be rendered. Use the Logger.isTraceEnabled() method to determine if the category priority threshold is enabled. The point of the TRACE priority is to allow for deep probing of the JBoss server behavior when necessary. When the TRACE level priority is enabled, you can expect the number of messages in the JBoss server log to grow at least a x N, where N is the number of requests received by the server, a some constant. The server log may well grow as power of N depending on the request-handling layer being traced. 

# #log.msg("HELLO")
# #log.msg("HELLO INFO", level = logging.INFO)
# #log.msg("HELLO ERROR", level = logging.ERROR)
# #log.msg("HELLO DEBUG", level = logging.DEBUG)
# logger.debug("HELLO DEBUG 2")
# try:
#    x = 1/0
# except:
#    logger.error()
#    #twisted.python.log.err()
# #   except Exception, e:
# #      logger.error(e)


########NEW FILE########
__FILENAME__ = adminwebresource
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import pkg_resources, inspect, cgi, json, re, datetime

from twisted.python import log
from twisted.application import service
from twisted.web.resource import Resource
from twisted.web.util import redirectTo

from autobahn.util import utcnow, parseutc, utcstr

from crossbar.cryptoutil import verify_and_decrypt
from crossbar.database import Database
from crossbar.tlsctx import TlsContextFactory

from adminwebsocket import AdminWebSocketProtocol

from crossbar.adminwebmodule.appcreds import AppCreds
from crossbar.adminwebmodule.clientperms import ClientPerms
from crossbar.adminwebmodule.extdirectremotes import ExtDirectRemotes
from crossbar.adminwebmodule.ftpusers import FtpUsers
from crossbar.adminwebmodule.hanaconnects import HanaConnects
from crossbar.adminwebmodule.hanapushrules import HanaPushRules
from crossbar.adminwebmodule.hanaremotes import HanaRemotes
from crossbar.adminwebmodule.oraconnects import OraConnects
from crossbar.adminwebmodule.orapushrules import OraPushRules
from crossbar.adminwebmodule.oraremotes import OraRemotes
from crossbar.adminwebmodule.pgconnects import PgConnects
from crossbar.adminwebmodule.pgpushrules import PgPushRules
from crossbar.adminwebmodule.pgremotes import PgRemotes
from crossbar.adminwebmodule.postrules import PostRules
from crossbar.adminwebmodule.restremotes import RestRemotes
from crossbar.adminwebmodule.serviceconfig import ServiceConfig
from crossbar.adminwebmodule.servicecontrol import ServiceControl
from crossbar.adminwebmodule.servicekeys import ServiceKeys
from crossbar.adminwebmodule.servicestatus import ServiceStatus


from crossbar.adminwebmodule.uris import *
from crossbar.dbimport import UploadDatabaseDump
from crossbar.database import Database

from portconfigresource import addPortConfigResource



class ApiHelpResource(Resource):
   """
   Built-in API documentation.
   """

   def render_GET(self, request):
      help0 = ""
      help1 = ""
      cdel = 100

      prefixes = [('api', URI_API),
                  ('error', URI_ERROR),
                  ('error#remoting', URI_ERROR_REMOTING),
                  ('event', URI_EVENT),
                  ('appcred', URI_APPCRED),
                  ('postrule', URI_POSTRULE),
                  ('hanaconnect', URI_HANACONNECT),
                  ('hanapushrule', URI_HANAPUSHRULE),
                  ('hanaremote', URI_HANAREMOTE),
                  ('pgconnect', URI_PGCONNECT),
                  ('pgpushrule', URI_PGPUSHRULE),
                  ('pgremote', URI_PGREMOTE),
                  ('oraconnect', URI_ORACONNECT),
                  ('orapushrule', URI_ORAPUSHRULE),
                  ('oraremote', URI_ORAREMOTE),
                  ('servicekey', URI_SERVICEKEY),
                  ('clientperm', URI_CLIENTPERM),
                  ('extdirectremote', URI_EXTDIRECTREMOTE),
                  ('restremote', URI_RESTREMOTE),
                  ('ftpuser', URI_FTPUSER),
                  ]

      for p in prefixes:
         help0 += "%s %s\n" % (p[0] + ' ' * (20 - len(p[0])), p[1])
      help0 += "\n\n"

      docclasses = [AdminWebSocketProtocol,
                    AppCreds,
                    ClientPerms,
                    ExtDirectRemotes,
                    FtpUsers,
                    HanaConnects,
                    HanaPushRules,
                    HanaRemotes,
                    OraConnects,
                    OraPushRules,
                    OraRemotes,
                    PgConnects,
                    PgPushRules,
                    PgRemotes,
                    PostRules,
                    RestRemotes,
                    ServiceConfig,
                    ServiceControl,
                    ServiceKeys,
                    ServiceStatus]

      docmethods = []

      for cls in docclasses:
         methods = []
         #print cls.__dict__
         for an in sorted(cls.__dict__):
            a = getattr(cls, an)
            if callable(a) and a.__dict__.has_key('_autobahn_rpc_id'):
               methods.append(a.__name__)
         if cls.__dict__.has_key('DOCNAME'):
            docname = cls.DOCNAME
         else:
            docname = cls.__name__
         docmethods.append((cls, docname, methods))

      #log.msg(docmethods)

      for cls, docname, methods in docmethods:
         #help1 += "\n\n%s\n" % docname
         help1 += "\n\n"
         if cls.__doc__:
            s = cls.__doc__.strip()
            i = s.find('.')
            if i > 0:
               s = s[:i]
            help1 += s + "\n"
         else:
            help1 += "Undocumented"
         help1 += "=" * cdel + "\n\n"
         for m in methods:
            fun = getattr(cls, m)
            #help1 += "\n\n%s.%s\n" % (cls.__name__, fun.__name__)
            signature = []
            fargs = inspect.getargspec(fun).args
            fdefaults = inspect.getargspec(fun).defaults
            if fdefaults is None:
               fdefaults = ()
            i = 1
            k = len(fargs) - len(fdefaults)
            for a in fargs[1:]:
               xx = str(a)
               if i >= k:
                  d = fdefaults[i - k]
                  if d is None:
                     d = "null"
                  elif d == True:
                     d = "true"
                  elif d == False:
                     d = "false"
                  xx += " [Default: %s]" % str(d)
               signature.append(xx)
               i += 1

            help1 += "\napi:%s (%s)\n" % (fun._autobahn_rpc_id, ', '.join(signature))
            help1 += "." * cdel + "\n\n"
            if fun.__doc__:
               fdoc = cgi.escape(inspect.getdoc(fun))
            else:
               fdoc = "Documentation missing."
            help1 += "%s\n\n\n" % fdoc

      html = """
<html>
   <body style="background-color: #fff; color: #333; font-family: Consolas, monospace;">
      <div style="position: relative; width: 100%%;">
         <div style="margin: auto; width: 960px;">
            <h1>API Documentation</h1>

            <h2>Prefixes</h2>
            <pre style="font-family: Consolas, monospace;">%s</pre>

            <h2>RPCs</h2>
            <pre style="font-family: Consolas, monospace;">%s</pre>
         </div>
      </div>
   </body>
</html>"""
      return html % (help0, help1)


ACTIVATE_DENY_HTML = """<!DOCTYPE html>
<html>
   <head>
      <style>
         body {
            background: #fff;
            color: #f00;
            font-family: sans-serif;
            font-size: 24px;
         }
      </style>
   </head>
   <body>
      <p>License activation failed: <b>%(reason)s</b></p>
   </body>
</html>
"""


class Activate(Resource):
   """
   License activation web resource.
   """

   def __init__(self, dbpool, services):
      Resource.__init__(self)
      self.dbpool = dbpool
      self.services = services


   def deny(self, request, reason):
      """
      Called when HTTP/POST is denied.
      """
      request.setResponseCode(400)
      return ACTIVATE_DENY_HTML % {'reason': str(reason)}


   def _activateLicense(self, txn, license, licenseRaw):

      now = utcnow()
      txn.execute("SELECT license_id FROM license WHERE enabled = 1 AND valid_from <= ? AND valid_to > ?", [now, now])
      res = txn.fetchone()
      if res:
         raise Exception("there is already a active license (%s)" % res[0])

      txn.execute("INSERT INTO license (created, license, enabled, license_id, host_id, instance_id, valid_from, valid_to, license_type, connection_cap, tls_enabled) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                  [now,
                   licenseRaw,
                   1,
                   license['license-id'],
                   license['host-id'],
                   license['instance-id'],
                   license['valid-from'],
                   license['valid-to'],
                   license['type'],
                   int(license['connection-cap']),
                   1 if license['tls-enabled'] else 0])
      return "OK, license inserted"


   def _onLicenseActivateSuccess(self, res, request):
      ## reload admin UI
      ##
      log.msg("\n\n!!! LICENSE ACTIVATED !!!\n\n")
      request.write(redirectTo("/", request))
      request.finish()

   def _onLicenseActivateError(self, res, request):
      request.write(self.deny(request, res))
      request.finish()

   def render_POST(self, request):
      """
      Perform license activation. The POST must contain a 'payload' field.
      Payload must be a string consisting of 3 substrings concatenated
      by comma:

         msg, key, sig

         msg: the AES encrypted license
         key: the RSA encrypted AES key
         sig: the RSA signature over the encrypted msg and key

      For details, see cryptoutil.verify_and_decrypt.
      """
      try:
         args = request.args
         headers = request.getAllHeaders()

         if headers.get("content-type", "missing") != 'application/x-www-form-urlencoded':
            return self.deny(request, "bad or missing content type ('%s')" % headers.get("content-type", "missing"))

         if args.has_key('payload'):
            payload = request.args['payload'][0]
         else:
            return self.deny(request, "1: missing payload field")

         # remove any whitespace (also line) from payload string
         re.sub(r'\s', '', payload)

         log.msg("License activation received:")
         log.msg("Raw License: " + payload)

         try:
            license = Database.parseLicense(self.services["config"].get('instance-priv-key'), payload)
         except Exception, e:
            return self.deny(request, "2: " + str(e))

         hostid = str(self.services['platform'].getHostId())
         if hostid != license['host-id']:
            return self.deny(request, "3: license is for host-id '%s', but this host has host-id '%s'" % (license['host-id'], hostid))

         instanceid = str(self.services['config'].get("instance-id"))
         if instanceid != license['instance-id']:
            return self.deny(request, "4: license is for instance-id '%s', but this instance has instance-id '%s'" % (license['instance-id'], instanceid))

         validfrom = parseutc(license['valid-from'])
         validto = parseutc(license['valid-to'])
         now = datetime.datetime.utcnow()
         if now < validfrom:
            return self.deny(request, "5: license is not yet valid (license validity %s - %s, now is %s)" % (license['valid-from'], license['valid-to'], utcstr(now)))
         if now >= validto:
            return self.deny(request, "6: license is expired (license validity %s - %s, now is %s)" % (license['valid-from'], license['valid-to'], utcstr(now)))

         d = self.dbpool.runInteraction(self._activateLicense, license, payload)

         d.addCallback(lambda res: self._onLicenseActivateSuccess(res, request))
         d.addErrback(lambda res: self._onLicenseActivateError(res, request))

         ## avoid module level import of reactor
         from twisted.web.server import NOT_DONE_YET

         return NOT_DONE_YET

      except Exception, e:
         ## catch all .. should not happen (usually)
         return self.deny(request, "0: internal error (%s)" % str(e))


class AdminWebService(service.Service):

   SERVICENAME = "Admin Web"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False
      self.factory = None
      self.listener = None

   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)

      ## avoid module level reactor import
      from twisted.web.static import File
      from twisted.web.server import Site

      ## Crossbar.io Dashboard
      ##
      try:
         import crossbardashboard
         root = File(pkg_resources.resource_filename("crossbardashboard", "web"))

      except ImportError, e:
         log.msg("Crossbar.io Dashboard not installed [%s]" % e)
         root = Resource()

      else:
         log.msg("Found Crossbar.io Dashboard package v%s" % crossbardashboard.__version__)

         ## Crossbar.io ControlCenter
         ##
         try:
            import crossbarcontrolcenter
            root.putChild("controlcenter", File(pkg_resources.resource_filename("crossbarcontrolcenter", "web")))
         except ImportError, e:
            log.msg("Crossbar.io ControlCenter not installed [%s]" % e)
         else:
            log.msg("Found Crossbar.io ControlCenter package v%s" % crossbarcontrolcenter.__version__)

         ## Crossbar.io CodeLab
         ##
         try:
            import crossbarcodelab
            root.putChild("codelab", File(pkg_resources.resource_filename("crossbarcodelab", "web")))
         except ImportError, e:
            log.msg("Crossbar.io CodeLab not installed [%s]" % e)
         else:
            log.msg("Found Crossbar.io CodeLab package v%s" % crossbarcodelab.__version__)

         ## Crossbar.io Manual
         ##
         try:
            import crossbarmanual
            root.putChild("manual", File(pkg_resources.resource_filename("crossbarmanual", "web")))
         except ImportError, e:
            log.msg("Crossbar.io Manual not installed [%s]" % e)
         else:
            log.msg("Found Crossbar.io Manual package v%s" % crossbarmanual.__version__)


      ## REST interface to get config values
      ##
      addPortConfigResource(self.services["config"], root, "config")

      ## API Documentation
      ##
      root.putChild("apidoc", ApiHelpResource())

      ## Database Export
      ##
      dbexp = File(str(self.services["config"].get("export-dir")))
      root.putChild(str(self.services["config"].get("export-url")), dbexp)

      ## Database Import
      ##
      dbimp = UploadDatabaseDump(str(self.services["config"].get("import-dir")))
      root.putChild(str(self.services["config"].get("import-url")), dbimp)

      ## Activate
      ##
      root.putChild("doactivate", Activate(self.dbpool, self.services))


      ## create twisted.web Site
      ##
      factory = Site(root)
      factory.log = lambda _: None # disable any logging

      cfg = self.services["config"]

      port = cfg["admin-web-port"]
      if cfg["admin-web-tls"]:
         contextFactory = TlsContextFactory(cfg["admin-web-tlskey-pem"],
                                            cfg["admin-web-tlscert-pem"],
                                            dhParamFilename = self.services['master'].dhParamFilename)
         self.listener = self.reactor.listenSSL(port, factory, contextFactory)
      else:
         self.listener = self.reactor.listenTCP(port, factory)

      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      if self.listener:
         self.listener.stopListening()
         self.listener = None
         self.factory = None
      self.isRunning = False

########NEW FILE########
__FILENAME__ = adminwebsocket
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import hmac, hashlib, binascii, random, datetime, re, urlparse, urllib

from twisted.application import service
from twisted.python import log
from twisted.python.failure import Failure

from autobahn.util import utcnow, parseutc
from autobahn.websocket import WebSocketProtocol, listenWS
from autobahn.wamp import WampServerFactory, WampCraServerProtocol
from autobahn.wamp import exportRpc
from autobahn.wamp import json_loads, json_dumps

import crossbar

from crossbar.cryptoutil import encrypt_and_sign
from crossbar.tlsctx import TlsContextFactory

from crossbar.adminwebmodule.uris import *
from crossbar.adminwebmodule.appcreds import AppCreds

from crossbar.adminwebmodule.hanaconnects import HanaConnects
from crossbar.adminwebmodule.hanapushrules import HanaPushRules
from crossbar.adminwebmodule.hanaremotes import HanaRemotes

from crossbar.adminwebmodule.pgconnects import PgConnects
from crossbar.adminwebmodule.pgpushrules import PgPushRules
from crossbar.adminwebmodule.pgremotes import PgRemotes

from crossbar.adminwebmodule.oraconnects import OraConnects
from crossbar.adminwebmodule.orapushrules import OraPushRules
from crossbar.adminwebmodule.oraremotes import OraRemotes

from crossbar.adminwebmodule.postrules import PostRules
from crossbar.adminwebmodule.ftpusers import FtpUsers
from crossbar.adminwebmodule.servicekeys import ServiceKeys
from crossbar.adminwebmodule.clientperms import ClientPerms
from crossbar.adminwebmodule.extdirectremotes import ExtDirectRemotes
from crossbar.adminwebmodule.restremotes import RestRemotes
from crossbar.adminwebmodule.serviceconfig import ServiceConfig
from crossbar.adminwebmodule.servicestatus import ServiceStatus
from crossbar.adminwebmodule.servicecontrol import ServiceControl
from crossbar.database import Database

import json
from crossbar.customjson import CustomJsonEncoder


class AdminWebSocketProtocol(WampCraServerProtocol):

   USER_PASSWORD_PATTERN = """^[a-zA-Z0-9_\-!$%&/=()"?+*#,;.:\[\]<>|~{}']*$"""
   USER_PASSWORD_MIN_LENGTH = 6
   USER_PASSWORD_MAX_LENGTH = 20

   def onSessionOpen(self):
      """
      Entry point when admin UI is connected.
      """
      self.dbpool = self.factory.dbpool

      self.registerForRpc(self, URI_API, [AdminWebSocketProtocol.isActivated,
                                          AdminWebSocketProtocol.createActivationRequest,
                                          AdminWebSocketProtocol.getPasswordSet,
                                          AdminWebSocketProtocol.setPassword])

      self.serviceConfig = ServiceConfig(self)

      ## override global client auth options
      self.clientAuthTimeout = 120
      self.clientAuthAllowAnonymous = False

      self.authUser = None

      ## call base class method
      WampCraServerProtocol.onSessionOpen(self)


   def _getPasswordSet(self, txn):
      txn.execute("SELECT value FROM config WHERE key = ?", ["admin-password"])
      res = txn.fetchone()
      if res:
         password = json_loads(res[0])
         return password is not None
      else:
         raise Exception(URI_ERROR + "internal-error", "admin-password key not found.")

   @exportRpc("get-password-set")
   def getPasswordSet(self):
      return self.dbpool.runInteraction(self._getPasswordSet)


   def _getEulaAccepted(self, txn):
      txn.execute("SELECT value FROM config WHERE key = ?", ["eula-accepted"])
      res = txn.fetchone()
      if res:
         eula_accepted = json_loads(res[0])
         return eula_accepted
      else:
         raise Exception(URI_ERROR + "internal-error", "eula-accepted key not found.")

   @exportRpc("get-eula-accepted")
   def getEulaAccepted(self):
      return self.dbpool.runInteraction(self._getEulaAccepted)


   def _acceptEula(self, txn):
      txn.execute("SELECT value FROM config WHERE key = ?", ["eula-accepted"])
      res = txn.fetchone()
      if res:
         eula_accepted = json_loads(res[0])
         if eula_accepted:
            raise Exception(URI_ERROR + "illegal-invocation", "EULA already accepted.")
         else:
            now = utcnow()
            txn.execute("UPDATE config SET value = ? WHERE key = ?", [json_dumps(now), "eula-accepted"])
            self.factory.services["config"].recache(txn)
            return now
      else:
         raise Exception(URI_ERROR + "internal-error", "EULA key not found.")

   @exportRpc("accept-eula")
   def acceptEula(self):
      return self.dbpool.runInteraction(self._acceptEula)


   def _isActivated(self, txn):
      if True:
         return {'license-id': '',
                 'type': 'BETA',
                 'connected-cap': 0,
                 'tls-enabled': True,
                 'valid-from': '1970-01-01T00:00:00:00Z',
                 'valid-to': '2020-01-01T00:00:00:00Z'}
      else:
         now = utcnow()
         txn.execute("SELECT license_id, license_type, connection_cap, tls_enabled, valid_from, valid_to FROM license WHERE enabled = 1 AND valid_from <= ? AND valid_to > ?", [now, now])
         res = txn.fetchone()
         if res:
            return {'license-id': res[0],
                    'type': res[1],
                    'connected-cap': res[2],
                    'tls-enabled': True if res[3] != 0 else False,
                    'valid-from': res[4],
                    'valid-to': res[5]}
         else:
            return None

   @exportRpc("is-activated")
   def isActivated(self):
      #return True
      return self.dbpool.runInteraction(self._isActivated)


   def _createActivationRequest(self, txn, origin, licenseType, extra):

      LICENSE_TYPES = ['BETA']

      if licenseType not in LICENSE_TYPES:
         raise Exception(URI_ERROR + "illegal-argument", "Unknown license type '%s'" % str(licenseType), LICENSE_TYPES)

      ## construct license activation request
      ##
      hostid = self.factory.services['platform'].getHostId()
      instanceid = self.serviceConfig._getSingleConfig(txn, "instance-id")
      msg = {'type': licenseType,
             'host-id': hostid,
             'instance-id': instanceid}

      dbcreated = self.serviceConfig._getSingleConfig(txn, "database-created")
      platform = self.factory.services['platform'].getPlatformInfo()
      network = self.factory.services['platform'].getNetworkConfig()

      msg['info'] = {'request-time': utcnow(),
                     'database-created': dbcreated,
                     'platform': platform,
                     'network': network}

      if extra is not None:
         msg['extra'] = extra

      log.msg("created license activation request: %s" % msg)

      rmsg = json_dumps(msg)

      ## load instance key pair
      ##
      pubkey = str(self.serviceConfig._getSingleConfig(txn, "instance-pub-key"))
      privkey = str(self.serviceConfig._getSingleConfig(txn, "instance-priv-key"))

      ## encrypt activation request for Tavendo public key
      ## and sign encrypted message using instance private key
      ##
      (emsg, skey, dig, sig) = encrypt_and_sign(rmsg,
                                                privkey,
                                                Database.WEBMQ_LICENSE_CA_PUBKEY)

      payload = "%s,%s,%s,%s,%s,%s" % (emsg,
                                       skey,
                                       dig,
                                       sig,
                                       urllib.quote_plus(pubkey),
                                       urllib.quote_plus(origin + "/doactivate"))

      #print payload

      return {'request': msg,
              'url': self.factory.services['master'].licenseserver,
              'payload': payload}


   @exportRpc("create-activation-request")
   def createActivationRequest(self, origin, licenseType, extra = None):
      """
      Create activation request for appliance.

      :param origin: Must be filled with "window.location.origin". This will be used to direct the license activation POST back to this instance.
      :type origin: str
      :param licenseType: Type of license: currently, only "BETA" is allowed.
      :type licenseType: str
      :param extra: User provided extra information like name or email.
      :type extra: dict

      Example:

         session.call("api:create-activation-request",
                      window.location.origin,
                      "BETA",
                      {name: "Foobar Corp.", email: "bob.ross@foobar.com"}).then(ab.log, ab.log);
      """
      return self.dbpool.runInteraction(self._createActivationRequest, origin, licenseType, extra)


   @exportRpc("get-license-options")
   def getLicenseOptions(self):
      return self.factory.services['database'].getLicenseOptions()


   @exportRpc("get-installed-options")
   def getInstalledOptions(self):
      return self.factory.services['database'].getInstalledOptions()


   @exportRpc("login-request")
   def loginRequest(self, username):
      """
      Challenge-response authentication request.
      """
      if type(username) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for agument username, but got %s" % str(type(username)))

      username = username.encode("utf-8")
      if username != "admin":
         raise Exception(URI_ERROR + "invalid-user", "User %s not known" % str(username))

      self.authChallenge = ''.join([random.choice("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_") for i in xrange(16)])
      self.authChallengeUser = username
      return self.authChallenge


   def _login(self, txn, authResponse, stayLoggedIn):

      if self.authChallenge is None:
         raise Exception(URI_ERROR + "login-without-previous-request", "Login attempt without previous login request.")

      txn.execute("SELECT value FROM config WHERE key = ?", ['admin-password'])
      res = txn.fetchone()
      if res:
         pw = str(json_loads(res[0]))
         h = hmac.new(pw, self.authChallenge, hashlib.sha256)
         v = binascii.b2a_base64(h.digest()).strip()
         if v == str(authResponse):
            self.authUser = self.authChallengeUser
            if stayLoggedIn:
               cookie = ''.join([random.choice("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_") for i in xrange(64)])
               now = utcnow()
               txn.execute("INSERT INTO cookie (created, username, value) VALUES (?, ?, ?)", [now, "admin", cookie])
               self.authCookie = cookie
               res = cookie
            else:
               res = None
            self.onLogin()
            return res
         else:
            raise Exception(URI_ERROR + "login-failed", "Login failed.")
      else:
         raise Exception(URI_ERROR + "internal-error", "Could not retrieve admin password from database.")


   @exportRpc("login")
   def login(self, authResponse, stayLoggedIn = False):
      """
      Login the user via a response to a previous authentication challenge.
      """
      if self.authUser is not None:
         raise Exception(URI_ERROR + "already-authenticated", "Connection is already authenticated")
      return self.dbpool.runInteraction(self._login, authResponse, stayLoggedIn)


   def _cookieLogin(self, txn, cookie):
      if type(cookie) not in [str, unicode]:
         raise Exception(URI_ERROR + "illegal-argument", "Expected type str/unicode for argument cookie, but got %s" % str(type(cookie)))

      txn.execute("SELECT created, username FROM cookie WHERE value = ?", [cookie])
      res = txn.fetchone()
      if res is not None:
         created = parseutc(res[0])
         now = datetime.datetime.utcnow()
         lifetime = (now - created).total_seconds()
         expiration = self.factory.services["config"].get("auth-cookie-lifetime", 600)
         if expiration > 0 and lifetime > expiration:
            txn.execute("DELETE FROM cookie WHERE value = ?", [cookie])
            raise Exception(URI_ERROR + "expired-cookie", "Authentication cookie expired.")
         self.authUser = str(res[1])
         self.authCookie = cookie
         self.onLogin()
      else:
         raise Exception(URI_ERROR + "bad-cookie", "Invalid authentication cookie.")


   @exportRpc("cookie-login")
   def cookieLogin(self, cookie):
      """
      Login the user via a cookie.
      """
      if self.authUser is not None:
         raise Exception(URI_ERROR + "already-authenticated", "Connection is already authenticated")
      return self.dbpool.runInteraction(self._cookieLogin, cookie)


   def getAuthPermissions(self, authKey, authExtra):
      ## return permissions which will be granted for the auth key
      ## when the authentication succeeds
      return {'permissions': {}}


   def _getAuthSecret(self, txn):
      txn.execute("SELECT value FROM config WHERE key = ?", ['admin-password'])
      res = txn.fetchone()
      if res:
         pw = str(json_loads(res[0]))
         return pw
      else:
         raise Exception(URI_ERROR + "internal-error", "Could not retrieve admin password from database.")


   def getAuthSecret(self, authKey):
      ## return the auth secret for the given auth key or None when the auth key
      ## does not exist
      if authKey != "admin":
         return None
      else:
         return self.dbpool.runInteraction(self._getAuthSecret)


   def onAuthenticated(self, authKey, perms):
      """
      Called when user was logged in. Register the full set of
      RPCs and PubSub topics.
      """
      self.authUser = authKey

      licenseOpts = self.factory.services["database"].getLicenseOptions()

      #self.serviceConfig = ServiceConfig(self)
      self.registerForRpc(self.serviceConfig, URI_API)

      self.appCreds = AppCreds(self)
      self.registerForRpc(self.appCreds, URI_API)

      if licenseOpts["hana"]:
         self.hanaConnects = HanaConnects(self)
         self.registerForRpc(self.hanaConnects, URI_API)

         self.hanaPushRules = HanaPushRules(self)
         self.registerForRpc(self.hanaPushRules, URI_API)

         self.hanaRemotes = HanaRemotes(self)
         self.registerForRpc(self.hanaRemotes, URI_API)

      if licenseOpts["postgresql"]:
         self.pgConnects = PgConnects(self)
         self.registerForRpc(self.pgConnects, URI_API)

         self.pgPushRules = PgPushRules(self)
         self.registerForRpc(self.pgPushRules, URI_API)

         self.pgRemotes = PgRemotes(self)
         self.registerForRpc(self.pgRemotes, URI_API)

      if licenseOpts["oracle"]:
         self.oraConnects = OraConnects(self)
         self.registerForRpc(self.oraConnects, URI_API)

         self.oraPushRules = OraPushRules(self)
         self.registerForRpc(self.oraPushRules, URI_API)

         self.oraRemotes = OraRemotes(self)
         self.registerForRpc(self.oraRemotes, URI_API)

      self.postRules = PostRules(self)
      self.registerForRpc(self.postRules, URI_API)

      self.ftpUsers = FtpUsers(self)
      self.registerForRpc(self.ftpUsers, URI_API)

      self.serviceKeys = ServiceKeys(self)
      self.registerForRpc(self.serviceKeys, URI_API)

      self.clientPerms = ClientPerms(self)
      self.registerForRpc(self.clientPerms, URI_API)

      self.extDirectRemotes = ExtDirectRemotes(self)
      self.registerForRpc(self.extDirectRemotes, URI_API)

      self.restRemotes = RestRemotes(self)
      self.registerForRpc(self.restRemotes, URI_API)

      self.serviceStatus = ServiceStatus(self)
      self.registerForRpc(self.serviceStatus, URI_API)

      self.serviceControl = ServiceControl(self)
      self.registerForRpc(self.serviceControl, URI_API)

      self.registerForRpc(self, URI_API)

      ## register prefix URI_EVENT for topics
      self.registerForPubSub(URI_EVENT, True)

      ## register prefix URI_WIRETAP_EVENT for topics
      self.registerForPubSub(URI_WIRETAP_EVENT, True)


   def onLogout(self):
      """
      Called when user is logged out. Automatically close WebSocket connection.
      """
      self.sendClose(WebSocketProtocol.CLOSE_STATUS_CODE_NORMAL, "logged out")


   def _logout(self, txn):
      if self.authCookie is not None:
         txn.execute("DELETE FROM cookie WHERE value = ?", [self.authCookie])
      self.dispatch(URI_EVENT + "on-logout", self.authCookie, eligible = [self])
      self.authUser = None
      self.authCookie = None
      self.onLogout()


   @exportRpc("logout")
   def logout(self):
      """
      Logout the user. If the user was authenticated via a cookie, the cookie
      is expired/deleted.
      """
      self.raiseIfNotAuthenticated()
      return self.dbpool.runInteraction(self._logout)


   def _setPassword(self, txn, password1, password2):
      txn.execute("SELECT value FROM config WHERE key = ?", ['admin-password'])
      res = txn.fetchone()
      if res:
         pw = json_loads(res[0])
         if pw is not None:
            raise Exception((URI_ERROR + "invalid-invocation", "Initial password already set."))
      else:
         raise Exception(URI_ERROR + "internal-error", "Could not retrieve admin password from database.")

      attrs = {"password1": (True,
                             [str, unicode],
                             AdminWebSocketProtocol.USER_PASSWORD_MIN_LENGTH,
                             AdminWebSocketProtocol.USER_PASSWORD_MAX_LENGTH,
                             AdminWebSocketProtocol.USER_PASSWORD_PATTERN),
               "password2": (True,
                             [str, unicode],
                             AdminWebSocketProtocol.USER_PASSWORD_MIN_LENGTH,
                             AdminWebSocketProtocol.USER_PASSWORD_MAX_LENGTH,
                             AdminWebSocketProtocol.USER_PASSWORD_PATTERN)}

      errcnt, errs = self.checkDictArg("user password", {"password1": password1, "password2": password2}, attrs)

      if password1 != password2:
         errcnt += 1
         if not errs.has_key('password1') or errs.has_key('password2'):
            p = 'password1'
         else:
            p = 'password2'
         if not errs.has_key(p):
            errs[p] = []
         errs[p].append((self.shrink(URI_ERROR + "invalid-attribute-value"), "Passwords do not match"))

      if errcnt:
         raise Exception(URI_ERROR + "illegal-argument", "one or more illegal arguments (%d errors)" % errcnt, errs)

      txn.execute("UPDATE config SET value = ? WHERE key = ?", [json_dumps(password1), "admin-password"])


   @exportRpc("set-password")
   def setPassword(self, password1, password2):
      """
      Set initial password.
      """
      return self.dbpool.runInteraction(self._setPassword, password1, password2)


   def _changePassword(self, txn, oldpassword, newpassword1, newpassword2):
      attrs = {"oldpassword": (True,
                               [str, unicode],
                               AdminWebSocketProtocol.USER_PASSWORD_MIN_LENGTH,
                               AdminWebSocketProtocol.USER_PASSWORD_MAX_LENGTH,
                               AdminWebSocketProtocol.USER_PASSWORD_PATTERN),
               "newpassword1": (True,
                                [str, unicode],
                                AdminWebSocketProtocol.USER_PASSWORD_MIN_LENGTH,
                                AdminWebSocketProtocol.USER_PASSWORD_MAX_LENGTH,
                                AdminWebSocketProtocol.USER_PASSWORD_PATTERN),
               "newpassword2": (True,
                                [str, unicode],
                                AdminWebSocketProtocol.USER_PASSWORD_MIN_LENGTH,
                                AdminWebSocketProtocol.USER_PASSWORD_MAX_LENGTH,
                                AdminWebSocketProtocol.USER_PASSWORD_PATTERN)}

      errcnt, errs = self.checkDictArg("user password",
                                       {"oldpassword": oldpassword,
                                        "newpassword1": newpassword1,
                                        "newpassword2": newpassword2},
                                       attrs)

      if newpassword1 != newpassword2:
         errcnt += 1
         if not errs.has_key('newpassword1') or errs.has_key('newpassword2'):
            p = 'newpassword1'
         else:
            p = 'newpassword2'
         if not errs.has_key(p):
            errs[p] = []
         errs[p].append((self.shrink(URI_ERROR + "invalid-attribute-value"), "New password values do not match"))

      if errcnt:
         raise Exception(URI_ERROR + "illegal-argument", "one or more illegal arguments (%d errors)" % errcnt, errs)

      txn.execute("SELECT value FROM config WHERE key = ?", ['admin-password'])
      res = txn.fetchone()
      if res:
         pw = str(json_loads(res[0]))
         if pw == oldpassword:
            if newpassword1 != oldpassword:
               txn.execute("UPDATE config SET value = ? WHERE key = ?", [json_dumps(newpassword1), "admin-password"])
            else:
               raise Exception(URI_ERROR + "illegal-argument",
                               "one or more illegal arguments (%d errors)" % 2,
                               {'newpassword1': [(self.shrink(URI_ERROR + "attribute-value-unchanged"), "Password unchanged")],
                                'newpassword2': [(self.shrink(URI_ERROR + "attribute-value-unchanged"), "Password unchanged")]})
         else:
            raise Exception(URI_ERROR + "illegal-argument",
                            "one or more illegal arguments (%d errors)" % 1,
                            {'oldpassword': [(self.shrink(URI_ERROR + "invalid-attribute-value"), "Old password is invalid")]})
      else:
         raise Exception(URI_ERROR + "internal-error", "Could not retrieve admin password from database.")


   @exportRpc("change-password")
   def changePassword(self, oldpassword, newpassword1, newpassword2):
      """
      Change the password of the currently logged in user.
      """
      self.raiseIfNotAuthenticated()
      return self.dbpool.runInteraction(self._changePassword, oldpassword, newpassword1, newpassword2)


   def raiseIfNotAuthenticated(self):
      if self.authUser is None:
         raise Exception(URI_ERROR + "not-authenticated", "Connection is not authenticated")



   ##################################################################################################
   ## FIXME: REFACTOR THE FOLLOWING


   def uriToId(self, uri):
      """
      Create object ID within database (which is a UUID) from a object URI.
      """
      return uri[uri.rfind("/") + 1:]


   def validateUri(self, uri, allowEmptyNetworkLocation = True):

      ## valid URI: absolute URI from http(s) scheme, no query component
      ##
      errs = []
      normalizedUri = None
      try:
         p = urlparse.urlparse(uri)

         if p.scheme == "":
            errs.append((self.shrink(URI_ERROR + "missing-uri-scheme"),
                         "URI '%s' does not contain a scheme." % uri))
         else:
            if p.scheme not in ['http', 'https']:
               errs.append((self.shrink(URI_ERROR + "invalid-uri-scheme"),
                            "URI '%s' scheme '%s' is invalid (only 'http' or 'https' allowed." % (uri, p.scheme)))

         if p.netloc == "" and not allowEmptyNetworkLocation:
            errs.append((self.shrink(URI_ERROR + "missing-uri-network-location"),
                         "URI '%s' does not contain a network location." % uri))

         if p.query != "":
            errs.append((self.shrink(URI_ERROR + "uri-contains-query-component"),
                         "URI '%s' contains a query component '%s'." % (uri, p.query)))

         normalizedUri = urlparse.urlunparse(p)

      except Exception, e:
         errs.append((self.shrink(URI_ERROR + "invalid-uri"),
                      "Invalid URI '%s' - could not parse URI (%s)" % (uri, str(e))))

      return (normalizedUri, errs)


   def cleanErrs(self, errs):
      acnt = 0
      tcnt = 0
      cerrs = {}
      for e in errs:
         l = len(errs[e])
         if l > 0:
            cerrs[e] = errs[e]
            tcnt += l
            acnt += 1
      return (cerrs, acnt, tcnt)


   def raiseDictArgException(self, errs):
      cerrs, acnt, tcnt = self.cleanErrs(errs)
      if tcnt:
         raise Exception(URI_ERROR + "illegal-argument", "one or more illegal arguments (%d errors in %d attributes)" % (tcnt, acnt), cerrs)


   def checkDictArg(self, argname, arg, attrs):
      """
      Check a dict of attributes "arg" for attribute spec "attrs".
      Return errorDetails = {errorLocUri: [(errorTypeUri, errorDesc)]}
      """
      if type(arg) != dict:
         raise Exception(URI_ERROR + "illegal-argument-type",
                         "Expected argument of type dict for %s, got %s" % (argname, str(type(arg))))
      errs = {}
      errcnt = 0
      for a in attrs.keys():
         errs[a] = []
         if attrs[a][0] and not arg.has_key(a):
            errs[a].append((self.shrink(URI_ERROR + "missing-attribute"),
                            "Missing mandatory attribute '%s' in %s" % (a, argname)))
            errcnt += 1
         if arg.has_key(a):

            ## check value type and do graceful conversion where possible
            ##
            go = False
            if type(arg[a]) not in attrs[a][1]:
               try:
                  ## graceful conversion to first accepted value type of spec
                  val = attrs[a][1][0](arg[a])
                  arg[a] = val
                  go = True
               except:
                  errs[a].append((self.shrink(URI_ERROR + "illegal-attribute-type"),
                                  "Expected type %s for %s attribute '%s', got %s" % (" or ".join([str(x) for x in attrs[a][1]]), argname, a, str(type(arg[a])))))
                  errcnt += 1
            else:
               go = True

            ## check value
            ##
            if go:
               if type(arg[a]) in [str, unicode]:
                  if len(attrs[a]) == 3 and type(attrs[a][2]) == list:
                     if str(arg[a]) not in attrs[a][2]:
                        errs[a].append((self.shrink(URI_ERROR + "invalid-attribute-value"),
                                        "Attribute '%s' value invalid (must be one of %s, was %s)" % (a, str(sorted(attrs[a][2])), str(arg[a])),
                                        sorted(attrs[a][2])))
                        errcnt += 1
                  elif len(attrs[a]) >= 4:
                     l = len(arg[a])
                     if l < attrs[a][2]:
                        errs[a].append((self.shrink(URI_ERROR + "attribute-value-too-short"),
                                        "Attribute '%s' value too short (must be at least %d, was %d)" % (a, attrs[a][2], l),
                                        attrs[a][2],
                                        attrs[a][3]))
                        errcnt += 1
                     elif l > attrs[a][3]:
                        errs[a].append((self.shrink(URI_ERROR + "attribute-value-too-long"),
                                        "Attribute '%s' value too long (must be at most %d, was %d)" % (a, attrs[a][3], l),
                                        attrs[a][2],
                                        attrs[a][3]))
                        errcnt += 1
                  if len(attrs[a]) >= 5:
                     if attrs[a][4]:
                        pat = re.compile(attrs[a][4])
                        if not pat.match(arg[a]):
                           errs[a].append((self.shrink(URI_ERROR + "attribute-value-invalid-characters"),
                                           "Attribute '%s' value contains invalid characters (must only contain characters from %s)" % (a, attrs[a][4]),
                                           attrs[a][4]))
                           errcnt += 1
               elif type(arg[a]) in [int, long, float]:
                  if len(attrs[a]) >= 4:
                     l = arg[a]
                     if l < attrs[a][2]:
                        errs[a].append((self.shrink(URI_ERROR + "out-of-range"),
                                        "Attribute '%s' value too small (must be at least %s, was %s)" % (a, attrs[a][2], l),
                                        attrs[a][2],
                                        attrs[a][3]))
                        errcnt += 1
                     elif l > attrs[a][3]:
                        errs[a].append((self.shrink(URI_ERROR + "out-of-range"),
                                        "Attribute '%s' value too large (must be at most %s, was %s)" % (a, attrs[a][3], l),
                                        attrs[a][2],
                                        attrs[a][3]))
                        errcnt += 1
                  elif len(attrs[a]) == 3 and type(attrs[a][2]) == list:
                     if arg[a] not in attrs[a][2]:
                        errs[a].append((self.shrink(URI_ERROR + "invalid-attribute-value"),
                                        "Attribute '%s' value invalid (must be one of %s, was %s)" % (a, str(sorted(attrs[a][2])), arg[a]),
                                        sorted(attrs[a][2])))
                        errcnt += 1
      for a in arg.keys():
         if not attrs.has_key(a):
            errs[a] = [(self.shrink(URI_ERROR + "unknown-attribute"),
                        "Unknown attribute '%s' in %s" % (a, argname))]
            errcnt += 1
      return errcnt, errs


   def cleanStripDictArg(self, arg, attrs):
      for a in attrs:
         if arg.has_key(a):
            s = arg[a].strip()
            if s!= "":
               arg[a] = s
            else:
               arg[a] = None



class AdminWebSocketFactory(WampServerFactory):

   protocol = AdminWebSocketProtocol

   def __init__(self, url, dbpool, services):
      WampServerFactory.__init__(self, url, debugApp = False)
      self.dbpool = dbpool
      self.services = services
      self.restartRequired = False


   #def _serialize(self, obj):
   #   return json_dumps(obj, cls = CustomJsonEncoder)


   def startFactory(self):
      WampServerFactory.startFactory(self)
      log.msg("AdminWebSocketFactory started [speaking %s]" % self.protocols)

      log.msg("debugWamp: %s" % self.debugWamp)
      log.msg("debugApp: %s" % self.debugApp)

      self.updateAvailable = {"update-available": False}
      self.autocheckForUpdates()

      #self.debugWamp = True


   def stopFactory(self):
      log.msg("AdminWebSocketFactory stopped")
      WampServerFactory.stopFactory(self)


   def dispatchAdminEvent(self, topicuri, event):
      return self.dispatch(topicuri, event)


   def issueRestartRequired(self):
      if not self.restartRequired:
         self.restartRequired = True
         self.dispatch(URI_EVENT + "on-restart-required", True, [])


   def getRestartRequired(self):
      return self.restartRequired


   def _autocheckForUpdates(self, result, delay):
      if isinstance(result, Failure):
         log.err("update check: failed! (%s)" % result)
      else:
         self.updateAvailable = result
         self.updateAvailable["checked"] = utcnow()
         if result["update-available"]:
            log.msg("update check: updates found! [%s]" % self.updateAvailable)
            self.dispatch(URI_EVENT + "on-update-available", self.updateAvailable, [])
         else:
            log.msg("update check: ok, no updates found.")
      if delay > 0:
         self.reactor.callLater(delay, self.autocheckForUpdates)
      return self.updateAvailable


   def autocheckForUpdates(self):
      delay = self.services["config"].get("update-check-interval", 600)
      if delay > 0:
         d = self._checkForUpdates()
         d.addBoth(self._autocheckForUpdates, delay)


   def checkForUpdatesNow(self):
      d = self._checkForUpdates()
      d.addBoth(self._autocheckForUpdates, 0)
      return d


   def _checkForUpdatesSuccess(self, index):
      p = re.compile(r'href="(crossbar.*?\.egg)"')
      ab_eggs = p.findall(index)
      versions = sorted([tuple([int(x) for x in s.split("-")[1].split(".")]) for s in ab_eggs])
      if len(versions) > 0:
         latest = versions[-1]
      else:
         latest = []
      installed = tuple([int(x) for x in crossbar.version.split('.')])
      return {"installed": '.'.join([str(x) for x in installed]),
              "latest": '.'.join([str(x) for x in latest]),
              "update-available": installed < latest}


   def _checkForUpdatesFailed(self, error):
      log.msg("check for software updates failed (%s)" % error.value)
      return {"update-available": False}


   def _checkForUpdates(self):

      ## avoid module-level reactor import
      from twisted.web.client import getPage

      update_url = str(self.services["config"].get("update-url"))
      d = getPage(url = update_url,
                  method = 'GET',
                  timeout = 5,
                  followRedirect = False)
      d.addCallbacks(self._checkForUpdatesSuccess, self._checkForUpdatesFailed)
      return d


class AdminWebSocketService(service.Service):

   SERVICENAME = "Admin WebSocket"

   def __init__(self, dbpool, services):
      self.dbpool = dbpool
      self.services = services
      self.isRunning = False
      self.factory = None
      self.listener = None


   def dispatchAdminEvent(self, topic, event):
      if self.factory:
         self.factory.dispatchAdminEvent(topic, event)


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)

      if self.services["config"]["admin-websocket-tls"]:
         contextFactory = TlsContextFactory(self.services["config"]["admin-websocket-tlskey-pem"],
                                            self.services["config"]["admin-websocket-tlscert-pem"],
                                            dhParamFilename = self.services['master'].dhParamFilename)

         uri = "wss://localhost:%d" % self.services["config"]["admin-websocket-port"]
      else:
         contextFactory = None

         uri = "ws://localhost:%d" % self.services["config"]["admin-websocket-port"]

      self.factory = AdminWebSocketFactory(uri, self.dbpool, self.services)
      self.listener = listenWS(self.factory,
                               contextFactory,
                               backlog = self.services["config"]["ws-accept-queue-size"])

      if self.services.has_key("logger"):
         self.services["logger"].setDispatch(self.dispatchAdminEvent)
      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      if self.listener:
         self.listener.stopListening()
         self.listener = None
         self.factory = None
      self.isRunning = False

########NEW FILE########
__FILENAME__ = cgiresource
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import sys, os

from twisted.python import log
from twisted.python.filepath import FilePath
from twisted.web.resource import Resource, NoResource

## trigers module level reactor import
## https://twistedmatrix.com/trac/ticket/6849#comment:5
from twisted.web.twcgi import CGIScript, CGIProcessProtocol

## triggers module level reactor import
## https://twistedmatrix.com/trac/ticket/6849#comment:4
from twisted.web.static import File


class CgiScript(CGIScript):

   def __init__(self, filename, filter):
      CGIScript.__init__(self, filename)
      self.filter = filter

   def runProcess(self, env, request, qargs = []):
      p = CGIProcessProtocol(request)
      from twisted.internet import reactor
      reactor.spawnProcess(p, self.filter, [self.filter, self.filename], env, os.path.dirname(self.filename))


class CgiDirectory(Resource, FilePath):

   cgiscript = CgiScript

   def __init__(self, pathname, filter):
      Resource.__init__(self)
      FilePath.__init__(self, pathname)
      self.filter = filter

   def getChild(self, path, request):
      fnp = self.child(path)
      print fnp.path
      if not fnp.exists():
         return File.childNotFound
      elif fnp.isdir():
         return CgiDirectory(fnp.path, self.filter)
      else:
         return self.cgiscript(fnp.path, self.filter)
      return NoResource()

   def render(self, request):
      notFound = NoResource("CGI directories do not support directory listing.")
      return notFound.render(request)

########NEW FILE########
__FILENAME__ = echowebsocket
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import math

from twisted.python import log
from twisted.application import service

from autobahn.websocket import WebSocketServerFactory, \
                               WebSocketServerProtocol, \
                               listenWS

from autobahn.compress import *

from crossbar.tlsctx import TlsContextFactory
from crossbar.adminwebmodule.uris import *



class EchoWebSocketProtocol(WebSocketServerProtocol):
   """
   Simple WebSocket echo service protocol.
   """

   def onMessage(self, msg, binary):
      self.sendMessage(msg, binary)
      self.factory.onEchoMessage(binary, len(msg))


   def connectionMade(self):
      WebSocketServerProtocol.connectionMade(self)
      self.factory.onConnectionCountChanged()


   def connectionLost(self, reason):
      WebSocketServerProtocol.connectionLost(self, reason)
      self.factory.onConnectionCountChanged()



class EchoWebSocketFactory(WebSocketServerFactory):
   """
   Simple WebSocket echo service protocol.
   """

   protocol = EchoWebSocketProtocol

   def __init__(self, url, dbpool, services, reactor = None):
      WebSocketServerFactory.__init__(self, url, debug = False, debugCodePaths = False, reactor = reactor)

      self.dbpool = dbpool
      self.services = services

      ## reset Echo endpoint stats
      ##
      self.stats = {'wsecho-connections': 0,
                    'wsecho-echos-text-count': 0,
                    'wsecho-echos-text-bytes': 0,
                    'wsecho-echos-binary-count': 0,
                    'wsecho-echos-binary-bytes': 0}
      self.statsChanged = False


   def setOptionsFromConfig(self):
      c = self.services["config"]

      versions = []
      if c.get("ws-allow-version-0"):
         versions.append(0)
      if c.get("ws-allow-version-8"):
         versions.append(8)
      if c.get("ws-allow-version-13"):
         versions.append(13)

      ## FIXME: enforce!!
      ##
      self.connectionCap = c.get("ws-max-connections")

      self.setProtocolOptions(versions = versions,
                              allowHixie76 = c.get("ws-allow-version-0"),
                              webStatus = c.get("ws-enable-webstatus"),
                              utf8validateIncoming = c.get("ws-validate-utf8"),
                              maskServerFrames = c.get("ws-mask-server-frames"),
                              requireMaskedClientFrames = c.get("ws-require-masked-client-frames"),
                              applyMask = c.get("ws-apply-mask"),
                              maxFramePayloadSize = c.get("ws-max-frame-size"),
                              maxMessagePayloadSize = c.get("ws-max-message-size"),
                              autoFragmentSize = c.get("ws-auto-fragment-size"),
                              failByDrop = c.get("ws-fail-by-drop"),
                              echoCloseCodeReason = c.get("ws-echo-close-codereason"),
                              openHandshakeTimeout = c.get("ws-open-handshake-timeout"),
                              closeHandshakeTimeout = c.get("ws-close-handshake-timeout"),
                              tcpNoDelay = c.get("ws-tcp-nodelay"))

      ## permessage-compression WS extension
      ##
      if c.get("ws-enable-permessage-deflate"):

         windowSize = c.get("ws-permessage-deflate-window-size")
         windowBits = int(math.log(windowSize, 2)) if windowSize != 0 else 0
         requireWindowSize = c.get("ws-permessage-deflate-require-window-size")

         def accept(offers):
            for offer in offers:
               if isinstance(offer, PerMessageDeflateOffer):
                  if windowBits != 0 and offer.acceptMaxWindowBits:
                     return PerMessageDeflateOfferAccept(offer,
                                                         requestMaxWindowBits = windowBits,
                                                         windowBits = windowBits)
                  elif windowBits == 0 or not requireWindowSize:
                     return PerMessageDeflateOfferAccept(offer)

         self.setProtocolOptions(perMessageCompressionAccept = accept)


   def startFactory(self):
      WebSocketServerFactory.startFactory(self)
      self.setOptionsFromConfig()
      log.msg("EchoWebSocketFactory started [speaking WebSocket versions %s]" % self.versions)
      self.publishStats()


   def getStats(self):
      return self.stats


   def publishStats(self):
      if self.statsChanged:
         self.services["adminws"].dispatchAdminEvent(URI_EVENT + "on-wsechostat", self.stats)
         self.statsChanged = False
      self.reactor.callLater(0.2, self.publishStats)


   def onConnectionCountChanged(self):
      self.stats["wsecho-connections"] = self.getConnectionCount()
      self.statsChanged = True


   def onEchoMessage(self, binary, length):
      if binary:
         self.stats['wsecho-echos-binary-count'] += 1
         self.stats['wsecho-echos-binary-bytes'] += length
      else:
         self.stats['wsecho-echos-text-count'] += 1
         self.stats['wsecho-echos-text-bytes'] += length
      self.statsChanged = True



class EchoWebSocketService(service.Service):

   SERVICENAME = "Echo WebSocket"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False
      self.factory = None
      self.listener = None


   def setOptionsFromConfig(self):
      if self.factory:
         self.factory.setOptionsFromConfig()


   def getStats(self):
      if self.isRunning and self.factory:
         return self.factory.getStats()


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)
      if self.services["config"]["echo-websocket-tls"]:
         contextFactory = TlsContextFactory(self.services["config"]["echo-websocket-tlskey-pem"],
                                            self.services["config"]["echo-websocket-tlscert-pem"],
                                            dhParamFilename = self.services['master'].dhParamFilename)

         uri = "wss://localhost:%d" % self.services["config"]["echo-websocket-port"]
      else:
         contextFactory = None

         uri = "ws://localhost:%d" % self.services["config"]["echo-websocket-port"]

      self.factory = EchoWebSocketFactory(uri, self.dbpool, self.services, self.reactor)
      self.listener = listenWS(self.factory,
                               contextFactory,
                               backlog = self.services["config"]["ws-accept-queue-size"])
      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      if self.listener:
         self.listener.stopListening()
         self.listener = None
         self.factory = None
      self.isRunning = False

########NEW FILE########
__FILENAME__ = flashpolicy
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################

from twisted.python import log
from twisted.application.internet import TCPServer

from autobahn.flashpolicy import FlashPolicyFactory



class FlashPolicyService(TCPServer):

   SERVICENAME = "Flash Policy File"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False

      port = services["config"]["flash-policy-port"]
      allowedPort = services["config"]["hub-websocket-port"]
      factory = FlashPolicyFactory(allowedPort, reactor)
      TCPServer.__init__(self, port, factory)

   def startService(self):
      log.msg("Starting %s service .." % self.SERVICENAME)
      TCPServer.startService(self)
      self.isRunning = True

   def stopService(self):
      log.msg("Stopping %s service .." % self.SERVICENAME)
      TCPServer.stopService(self)
      self.isRunning = False

########NEW FILE########
__FILENAME__ = ftpserver
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from zope.interface import implements

from twisted.python import failure, log
from twisted.internet import defer
from twisted.application import service
from twisted.protocols.ftp import FTPFactory, FTPRealm

from twisted.cred.portal import Portal
from twisted.cred.checkers import ICredentialsChecker
from twisted.cred.credentials import IUsernamePassword
from twisted.cred import error, credentials

from crossbar.txutil import CustomFTPFactory


class FtpUserDb:
   """
   Database backed FTP credentials checker.
   """

   implements(ICredentialsChecker)

   credentialInterfaces = (IUsernamePassword, )

   def __init__(self, service):
      self.service = service

   def _cbPasswordMatch(self, matched, username):
      if matched:
         # return user directory within FTP root dir
         return ""
         #return username
      else:
         log.msg("invalid password for FTP login '%s'" % username)
         return failure.Failure(error.UnauthorizedLogin())

   def _getSecretOk(self, res, c):
      if len(res) == 0:
         log.msg("unauthorized FTP login for '%s'" % c.username)
         return failure.Failure(error.UnauthorizedLogin())
      else:
         secret = res[0][0]
         return defer.maybeDeferred(c.checkPassword, secret).addCallback(self._cbPasswordMatch, c.username)

   def _getSecretFailed(self, err):
      log.msg("FTP user authentication internal error")
      log.msg(err)
      return failure.Failure(error.UnauthorizedLogin())

   def requestAvatarId(self, c):
      d = self.service.dbpool.runQuery("SELECT password FROM ftpuser WHERE user = ?", [c.username])
      d.addCallbacks(self._getSecretOk, self._getSecretFailed, [c])
      return d


class FtpService(service.Service):
   """
   Embedded FTP service.
   """

   SERVICENAME = "FTP"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False

      self.port = services["config"]["ftp-port"]
      self.passivePortStart = services["config"]["ftp-passive-port-start"]
      self.passivePortEnd = services["config"]["ftp-passive-port-end"]
      self.passivePublicIp = str(services["config"]["ftp-passive-public-ip"]) if services["config"]["ftp-passive-public-ip"] else None
      self.homedir = str(self.services["master"].webdata)

      self.listener = None

   def startService(self):
      log.msg("Starting %s service .." % self.SERVICENAME)
      p = Portal(FTPRealm(anonymousRoot = '/dev/null', userHome = self.homedir), [FtpUserDb(self)])
      f = CustomFTPFactory(p)
      f.allowAnonymous = False
      f.passivePortRange = xrange(self.passivePortStart, self.passivePortEnd + 1)
      f.welcomeMessage = "crossbar.io FTP at your service."
      f.passivePublicIp = self.passivePublicIp
      self.listener = self.reactor.listenTCP(self.port, f)
      self.isRunning = True
      log.msg("embedded FTP server running on port %d (passive FTP ports %d - %d, homedir %s)" % (self.port, self.passivePortStart, self.passivePortEnd, self.homedir))

   def stopService(self):
      log.msg("Stopping %s service .." % self.SERVICENAME)
      if self.listener:
         self.listener.stopListening()
         self.listener = None
      self.isRunning = False

########NEW FILE########
__FILENAME__ = hubwebresource
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import datetime, os
from collections import deque

from twisted.python import log
from twisted.application import service
from twisted.web.resource import Resource

from autobahn.util import utcnow, parseutc
from autobahn.wamp import json_loads

from crossbar.adminwebmodule.uris import URI_EVENT
from crossbar.tlsctx import TlsContextFactory


class HubWebResource(Resource):
   """
   A Twisted/Web resource that receives events via HTTP/POSTs and
   dispatches to subscribed WebSockets clients.
   """

   def __init__(self, dbpool, services, reactor = None):
      Resource.__init__(self)

      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services

      logdir = self.services["config"].get("log-dir")

      ## create log dir when not there
      if not os.path.isdir(logdir):
         os.mkdir(logdir)

      ## create/open log files
      self.dispatch_log_file = open(os.path.join(logdir, "dispatch.log"), 'ab')
      self.error_log_file = open(os.path.join(logdir, "error.log"), 'ab')

      ## in-memory log queues
      self.dispatch_log = deque()
      self.error_log = deque()

      ## current statistics
      self.stats = {'uri': None,
                    'publish-allowed': 0,
                    'publish-denied': 0,
                    'dispatch-success': 0,
                    'dispatch-failed': 0}
      self.statsChanged = False

      ## the config is not yet load at this point
      #self.writeLog()
      self.reactor.callLater(10, self.writeLog)

      self.publishStats()


   def getStats(self):
      return [self.stats]


   def publishStats(self):
      if self.statsChanged:
         self.services["adminws"].dispatchAdminEvent(URI_EVENT + "on-restpusherstat", [self.stats])
         self.statsChanged = False
      self.reactor.callLater(0.2, self.publishStats)


   def writeLog(self):
      """
      Write buffered log records to database.
      """
      n = 0
      while True:
         try:
            rec = self.error_log.popleft()
            s = ','.join([str(x) for x in rec]) + '\n'
            self.error_log_file.write(s)
            n += 1
         except IndexError:
            break
      if n > 0:
         self.error_log_file.flush()
         log.msg("%d buffered records written to error log" % n)

      n = 0
      while True:
         try:
            rec = self.dispatch_log.popleft()
            s = ','.join([str(x) for x in rec]) + '\n'
            self.dispatch_log_file.write(s)
            n += 1
         except IndexError:
            break
      if n > 0:
         self.dispatch_log_file.flush()
         log.msg("%d buffered records written to dispatch log" % n)

      self.reactor.callLater(self.services["config"].get("log-write-interval", 60), self.writeLog)


   def _getContentLengthLimit(self):
      return self.services["config"].get("post-body-limit", 4096)


   def _getTimestampDeltaLimit(self):
      return self.services["config"].get("sig-timestamp-delta-limit", 300)


   def deny(self, request, code, reason):
      """
      Called when HTTP/POST is denied.
      """
      headers = request.getAllHeaders()
      user_agent = headers.get("user-agent", "unknown")
      client_ip = request.getClientIP()
      is_secure = request.isSecure()

      self.error_log.append([utcnow(), user_agent, client_ip, is_secure, code, reason])
      self.stats['publish-denied'] += 1
      self.statsChanged = True

      request.setResponseCode(code)
      return "%s\n" % str(reason)


   def log(self, user_agent, client_ip, is_secure, topic, content_length, postrule_id, receiver_count, requested_count):
      """
      Log successful HTTP/POST to WebSockets PubSub event dispatch.
      """
      logrec = [utcnow(), user_agent, client_ip, is_secure, topic, content_length, receiver_count]
      self.dispatch_log.append(logrec)
      self.stats['dispatch-success'] += receiver_count
      error_count = requested_count - receiver_count
      if error_count > 0:
         self.stats['dispatch-failed'] += error_count
      self.statsChanged = True


   def render(self, request):
      if request.method != "POST":
         return self.deny(request, 405, "HTTP/%s not allowed" % request.method)
      else:
         return self.render_POST(request)


   def render_POST(self, request):
      """
      The HTTP/POST to WebSockets hub Twisted/Web resource main method.
      """
      try:
         path = request.path
         args = request.args
         headers = request.getAllHeaders()

         if headers.get("content-type", "missing") != 'application/x-www-form-urlencoded':
            return self.deny(request, 400, "bad or missing content type ('%s')" % headers.get("content-type", "missing"))

         ## FIXME: post-body-limit
         ##
         content_length = int(headers.get("content-length", 0))
         if content_length > self._getContentLengthLimit():
            return self.deny(request, 400, "content length (%d) exceeds maximum (%d)" % (content_length, self._getContentLengthLimit()))

         if not args.has_key("topic"):
            return self.deny(request, 400, "missing query parameter 'topic'")
         topic = args["topic"][0]

         appkey = args.get("appkey", [False])[0]
         signature = args.get("signature", [False])[0]
         timestamp_str = args.get("timestamp", [False])[0]
         if appkey or signature or timestamp_str:
            if not (appkey and signature and timestamp_str):
               return self.deny(request, 400, "either all or none of parameters 'appkey', 'signature' and 'timestamp' must be present")

         if timestamp_str:
            # '2011-10-14T12:59:51Z'
            timestamp = parseutc(timestamp_str)
            if timestamp is None:
               return self.deny(request, 400, "invalid timestamp '%s' (must be i.e. '2011-10-14T16:59:51Z'" % timestamp_str)
            delta = int(round(abs(timestamp - datetime.datetime.utcnow()).total_seconds()))
            if delta > self._getTimestampDeltaLimit():
               return self.deny(request, 400, "timestamp expired (delta %d seconds)" % delta)
         else:
            timestamp = None

         if args.has_key('event'):
            json_str = args['event'][0]
         else:
            json_str = request.content.read()

         if appkey:
            sig = self.services["restpusher"].signature(topic, appkey, timestamp_str, json_str)
            if sig is None:
               return self.deny(request, 400, "unknown application key '%s'" % appkey)
            if sig != signature:
               return self.deny(request, 401, "invalid request signature (expected %s, got %s)" % (sig, signature))

         user_agent = headers.get("user-agent", "unknown")
         client_ip = request.getClientIP()
         is_secure = request.isSecure()

         auth = self.services["restpusher"].authorize(topic, client_ip, appkey)
         if auth[0]:

            try:
               event = json_loads(json_str)
            except:
               return self.deny(request, 400, "invalid JSON in request body")

            if args.has_key("exclude"):
               exclude = [x.strip() for x in args["exclude"][0].split(",")]
            else:
               exclude = []

            if args.has_key("eligible"):
               eligible = [x.strip() for x in args["eligible"][0].split(",")]
            else:
               eligible = None

            ## dispatch & log event
            d = self.services["appws"].dispatchHubEvent(topic, event, exclude, eligible)
            d.addCallback(lambda res: self.log(user_agent,
                                               client_ip,
                                               is_secure,
                                               topic,
                                               content_length,
                                               postrule_id = auth[1],
                                               receiver_count = res[0],
                                               requested_count = res[1]))
            self.stats['publish-allowed'] += 1
            self.statsChanged = True

            ## signal success to submitter
            request.setResponseCode(202)
            return ""
         else:
            return self.deny(request, 401, "not authorized (denied by post rule %s: %s)" % (auth[1], auth[2]))

      except Exception, e:
         ## catch all .. should not happen (usually)
         return self.deny(request, 500, "internal server error ('%s')" % str(e))



class HubWebService(service.Service):

   SERVICENAME = "Hub Web"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False
      self.factory = None
      self.root = None
      self.listener = None


   def getStats(self):
      if self.isRunning and self.root:
         return self.root.children[""].getStats()


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)

      ## avoid module level reactor import
      from twisted.web.static import File
      from twisted.web.server import Site

      self.root = Resource()
      self.root.putChild("", HubWebResource(self.dbpool, self.services))

      self.factory = Site(self.root)
      self.factory.log = lambda _: None # disable any logging

      cfg = self.services["config"]

      port = cfg["hub-web-port"]
      if cfg["hub-web-tls"]:
         contextFactory = TlsContextFactory(cfg["hub-web-tlskey-pem"],
                                            cfg["hub-web-tlscert-pem"],
                                            dhParamFilename = self.services['master'].dhParamFilename)
         self.listener = self.reactor.listenSSL(port, self.factory, contextFactory)
      else:
         self.listener = self.reactor.listenTCP(port, self.factory)

      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      if self.listener:
         self.listener.stopListening()
         self.listener = None
         self.factory = None
         self.root = None
      self.isRunning = False

########NEW FILE########
__FILENAME__ = hubwebsocket
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import math, os, socket

from pprint import pformat, pprint

from twisted.python import log
from twisted.application import service
from twisted.internet.defer import gatherResults

from autobahn.compress import *

from autobahn.wamp import WampCraServerProtocol, WampServerFactory
from autobahn.wamp import exportRpc

import crossbar
from crossbar.tlsctx import TlsContextFactory

from crossbar.adminwebmodule.uris import *

from crossbar.bridge.extdirectremoter import ExtDirectRemoter
from crossbar.bridge.restremoter import RestRemoter

from crossbar.bridge.hanaremoter import HanaRemoter
from crossbar.bridge.pgremoter import PgRemoter
from crossbar.bridge.oraremoter import OraRemoter


import json
from crossbar.customjson import CustomJsonEncoder

from autobahn.util import newid, utcnow
import Cookie

import jinja2
import pkg_resources


class SessionInfo:
   def __init__(self, sessionId = None, authenticatedAs = None):
      self.sessionId = sessionId
      self.authenticatedAs = authenticatedAs
      self.data = {}


RPC_SUCCESS_TIMINGS = [('RECV', 'onMessageBegin', 'onBeforeCall'),
                       ('CALL', 'onBeforeCall', 'onAfterCallSuccess'),
                       ('RCLL', 'onBeforeRemoteCall', 'onAfterRemoteCallSuccess'),
                       ('SEND', 'onAfterCallSuccess', 'onAfterSendCallSuccess')]

RPC_ERROR_TIMINGS = [('RECV', 'onMessageBegin', 'onBeforeCall'),
                     ('CALL', 'onBeforeCall', 'onAfterCallError'),
                     ('RCLL', 'onBeforeRemoteCall', 'onAfterRemoteCallError'),
                     ('SEND', 'onAfterCallError', 'onAfterSendCallError')]


RPC_SUCCESS_TIMINGS = [('RECV', 'onMessageBegin', 'onBeforeCall'),
                       ('UMSH', 'onBeforeCall', 'onBeforeRemoteCall'),
                       ('RCLL', 'onBeforeRemoteCall', 'onAfterRemoteCallReceiveSuccess'),
                       ('RCLF', 'onAfterRemoteCallReceiveSuccess', 'onAfterRemoteCallSuccess'),
                       ('MRSH', 'onAfterRemoteCallSuccess', 'onAfterCallSuccess'),
                       ('SEND', 'onAfterCallSuccess', 'onAfterSendCallSuccess')]


class HubWebSocketProtocol(WampCraServerProtocol):
   """
   Autobahn WebSockets Hub Twisted/Protocol.

   Topic URIs in client permissions must have the following forms:

      http://example.com/simple
      http://example.com/foo/%(myattribute1)s/bar
      http://example.com/users/%(user)s/inbox

   and may have attached filter expression of the following form

      role == 'editor' or role == 'author'

   or

      role in ['editor', 'author'] or is_developer or age > 10
   """

   RPC_ECHO = True
   RPC_PING = True

   TESTEE_API = True


   def sendServerStatus(self, redirectUrl = None, redirectAfter = 0):
      """
      Used to send out server status/version upon receiving a HTTP/GET without
      upgrade to WebSocket header (and option serverStatus is True).
      """
      config = self.factory.services['config']
      #port = config.get('hub-websocket-port')
      #tls = config.get('hub-websocket-tls')
      wsUri = self.factory.url
      wsPath = config.get('ws-websocket-path')
      if wsPath:
         wsUri += "/" + wsPath

      try:
         page = self.factory.service.templates.get_template('cb_ws_status.html')
         self.sendHtml(page.render(redirectUrl = redirectUrl,
                                   redirectAfter = redirectAfter,
                                   cbVersion = crossbar.__version__,
                                   wsUri = wsUri))
      except Exception, e:
         log.msg("Error rendering WebSocket status page template: %s" % e)


   def testDispatch(self, topic, event, options):
      """
      Simulate a server initiated event controlled by the tester.
      """
      if options.has_key('exclude'):
         exclude = options['exclude']
      else:
         excludeMe = options.get('excludeMe', None)
         if excludeMe is None or excludeMe == True:
             exclude = [self.session_id]
         else:
             exclude = []

      exclude = self.factory.sessionIdsToProtos(exclude)

      eligible = options.get('eligible', None)
      if eligible:
         eligible = self.factory.sessionIdsToProtos(eligible)

      self.factory.dispatch(topic, event, exclude = exclude, eligible = eligible)


   def formatWiretapTimings(self, call, tdef):
      print call, tdef
      print call.timings
      print self.trackedTimings
      s = " %s | " % call.callid
      for t in tdef:
         s += t[0]
         s += ": "
         s += call.timings.diff(t[1], t[2])
         s += " | "
      s += "%s" % call.uri
      return s


   def onAfterSendCallSuccess(self, msg, call):
      if self.dispatchWiretap and call.timings:
         s = self.formatWiretapTimings(call, RPC_SUCCESS_TIMINGS)
         self.dispatchWiretap(s)


   def onAfterSendCallError(self, msg, call):
      if self.dispatchWiretap and call.timings:
         s = self.formatWiretapTimings(call, RPC_ERROR_TIMINGS)
         self.dispatchWiretap(s)


   def setWiretapMode(self, enable):
      if enable and self.factory.services.has_key("adminws"):
         def dispatchWiretap(event):
            self.factory.services["adminws"].dispatchAdminEvent(URI_WIRETAP_EVENT + self.session_id, event)
         self.dispatchWiretap = dispatchWiretap
         self.setTrackTimings(True)
         log.msg("Wiretap mode enabled on session %s" % self.session_id)
      else:
         self.dispatchWiretap = None
         self.setTrackTimings(False)
         log.msg("Wiretap mode disabled on session %s" % self.session_id)


   def getWiretapMode(self):
      return hasattr(self, 'dispatchWiretap') and self.dispatchWiretap is not None


   def onConnect(self, connectionRequest):
      protocol, headers = WampCraServerProtocol.onConnect(self, connectionRequest)
      #pprint(connectionRequest.headers)

      ua = connectionRequest.headers.get('user-agent', None)
      origin = connectionRequest.headers.get('origin', None)

      ## Crossbar.io Tracking ID
      ##
      cbtid = None
      if connectionRequest.headers.has_key('cookie'):
         try:
            cookie = Cookie.SimpleCookie()
            cookie.load(str(connectionRequest.headers['cookie']))
         except Cookie.CookieError:
            pass
         else:
            if cookie.has_key('cbtid'):
               _cbtid = cookie['cbtid'].value
               if self.factory.trackingCookies.has_key(_cbtid):
                  cbtid = _cbtid
                  #log.msg("Crossbar.io tracking ID already in cookie: %s" % cbtid)

      if cbtid is None:

         cbtid = newid()
         maxAge = 86400

         cbtData = {'created': utcnow(),
                    'maxAge': maxAge,
                    'sessions': []}

         self.factory.trackingCookies[cbtid] = cbtData

         ## do NOT add the "secure" cookie attribute! "secure" refers to the
         ## scheme of the Web page that triggered the WS, not WS itself!!
         ##
         headers['Set-Cookie'] = 'cbtid=%s;max-age=%d' % (cbtid, maxAge)
         #log.msg("Setting new Crossbar.io tracking ID in cookie: %s" % cbtid)

      self._cbtid = cbtid
      cbSessionData = {'cbtid': cbtid,
                       'ua': ua,
                       'origin': origin,
                       'connected': utcnow()}

      i = len(self.factory.trackingCookies[cbtid]['sessions'])

      self.factory.trackingCookies[cbtid]['sessions'].append(cbSessionData)
      self._cbSession = self.factory.trackingCookies[cbtid]['sessions'][i]

      return (protocol, headers)


   def onSessionOpen(self):

      self.includeTraceback = True
      self.setWiretapMode(False)
      self.sessionInfo = SessionInfo(self.session_id)

      self._cbSession['wampSessionId'] = self.session_id

      self.dbpool = self.factory.dbpool
      self.authenticatedAs = None

      if self.RPC_PING:
         self.registerForRpc(self, URI_WAMP_RPC, [HubWebSocketProtocol.ping])

      if self.RPC_ECHO:
         self.registerForRpc(self, URI_WAMP_RPC, [HubWebSocketProtocol.echo])

      if self.TESTEE_API:
         ##
         ## FIXME:
         ##   - let the user enable/disable the built-in testsuite API
         ##   - let this method be overidden, e.g. when testing Oracle integration (probably based on appkey?)
         ##
         TESTEE_CONTROL_DISPATCH = "http://api.testsuite.wamp.ws/autobahn/testee/control#dispatch"
         #TESTEE_CONTROL_DISPATCH = "http://api.testsuite.wamp.ws/testee/control#dispatch"

         self.registerMethodForRpc(TESTEE_CONTROL_DISPATCH, self, HubWebSocketProtocol.testDispatch)

      ## global client auth options
      ##
      self.clientAuthTimeout = self.factory.services["config"].get("client-auth-timeout", 0)
      self.clientAuthAllowAnonymous = self.factory.services["config"].get("client-auth-allow-anonymous", False)

      WampCraServerProtocol.onSessionOpen(self)


   def getAuthPermissions(self, authKey, authExtra):
      ## we fill in permissions here
      perms = {'permissions': {}}

      for k in ['cookies', 'referrer', 'href']:
         if authExtra.has_key(k):
            perms[k] = authExtra[k]

      ## PubSub permissions
      ##
      perms['permissions']['pubsub'] = self.factory.services["clientfilter"].getPermissions(authKey, authExtra)

      ## RPC permissions
      ##
      perms['permissions']['rpc'] = []

      if self.RPC_PING:
         perms['permissions']['rpc'].append({'uri': URI_WAMP_RPC + "ping", 'call': True})

      if self.RPC_ECHO:
         perms['permissions']['rpc'].append({'uri': URI_WAMP_RPC + "echo", 'call': True})


      remotes = []

      ## fill in REST, Ext.Direct, SAP HANA, PostgreSQL, Oracle Remoting
      ##
      for remoter in ["restremoter",
                      "extdirectremoter",
                      "hanaremoter",
                      "pgremoter",
                      "oraremoter"]:
         if self.factory.services.has_key(remoter):
            remotes.append(self.factory.services[remoter].getRemotes(authKey, authExtra))

      d = gatherResults(remotes)

      def processRemotes(rlist):
         for r in rlist:
            rtype = r[0]
            procs = r[1]
            perms[rtype] = procs
            for k in procs:
               perms['permissions']['rpc'].append({'uri': k, 'call': True})
         return perms

      d.addCallback(processRemotes)

      return d


   def getAuthSecret(self, authKey):
      return self.factory.services["clientfilter"].getAppSecret(authKey)


   def onAuthenticated(self, authKey, perms):
      """
      WAMP session authenticated. Register PubSub topics and RPC handlers.
      """
      self.authenticatedAs = authKey
      self.cookies = perms.get('cookies', None)

      self.sessionInfo.authenticatedAs = authKey

      self._cbSession['authenticated'] = utcnow()
      self._cbSession['href'] = perms.get('href', None)
      self._cbSession['referrer'] = perms.get('referrer', None)

      self.registerForPubSubFromPermissions(perms['permissions'])

      for remoter, key, method in [("restremoter", "rest", RestRemoter.remoteCall),
                                   ("extdirectremoter", "extdirect", ExtDirectRemoter.remoteCall),
                                   ("hanaremoter", "hana", HanaRemoter.remoteCall),
                                   ("pgremoter", "pg", PgRemoter.remoteCall),
                                   ("oraremoter", "ora", OraRemoter.remoteCall),
                                   ]:
         if self.factory.services.has_key(remoter):
            r = perms[key]
            for uri in r:
               self.registerHandlerMethodForRpc(uri,
                                                self.factory.services[remoter],
                                                method,
                                                r[uri])

      self.factory.dispatch("http://analytics.tavendo.de#enter", self._cbSession)


   @exportRpc("ping")
   def ping(self):
      """
      RPC call with no arguments returning nothing.
      This can be used even before session authentication to measure RTTs to servers.
      """
      return


   @exportRpc("echo")
   def echo(self, arg):
      """
      RPC call returning echo.
      This can be used even before session authentication to measure RTTs to servers.
      """
      return arg


   def connectionMade(self):
      """
      Client connected. Check connection cap, and if allowed update stats.
      """
      WampCraServerProtocol.connectionMade(self)
      self.factory.onConnectionCountChanged()


   def connectionLost(self, reason):
      """
      Client disconnected. Update stats.
      """
      WampCraServerProtocol.connectionLost(self, reason)
      self.factory.onConnectionCountChanged()

      self._cbSession['lost'] = utcnow()

      self.factory.dispatch("http://analytics.tavendo.de#leave", self._cbSession)

      #print
      #pprint(self._cbSession)
      #print
      #pprint(self.factory.trackingCookies)
      #print

      #log.msg("\n\nTraffic stats on closed connection:\n\n" + pformat(self.trafficStats.__json__()) + "\n")



class HubWebSocketFactory(WampServerFactory):
   """
   Autobahn WebSockets Hub Twisted/Factory.
   """

   protocol = HubWebSocketProtocol

   def __init__(self, url, dbpool, service, services):
      WampServerFactory.__init__(self, url, debug = False, debugWamp = False)
      self.dbpool = dbpool
      self.service = service
      self.services = services
      self.stats = {'ws-connections': 0,
                    'ws-publications': 0,
                    'ws-dispatched-success': 0,
                    'ws-dispatched-failed': 0}
      self.statsChanged = False

      self.trackingCookies = {}


   #def _serialize(self, obj):
   #   return json.dumps(obj, cls = CustomJsonEncoder)


   def setOptionsFromConfig(self):
      c = self.services["config"]

      versions = []
      if c.get("ws-allow-version-0"):
         versions.append(0)
      if c.get("ws-allow-version-8"):
         versions.append(8)
      if c.get("ws-allow-version-13"):
         versions.append(13)

      ## FIXME: enforce!!
      ##
      self.connectionCap = c.get("ws-max-connections")

      self.setProtocolOptions(versions = versions,
                              allowHixie76 = c.get("ws-allow-version-0"),
                              webStatus = c.get("ws-enable-webstatus"),
                              utf8validateIncoming = c.get("ws-validate-utf8"),
                              maskServerFrames = c.get("ws-mask-server-frames"),
                              requireMaskedClientFrames = c.get("ws-require-masked-client-frames"),
                              applyMask = c.get("ws-apply-mask"),
                              maxFramePayloadSize = c.get("ws-max-frame-size"),
                              maxMessagePayloadSize = c.get("ws-max-message-size"),
                              autoFragmentSize = c.get("ws-auto-fragment-size"),
                              failByDrop = c.get("ws-fail-by-drop"),
                              echoCloseCodeReason = c.get("ws-echo-close-codereason"),
                              openHandshakeTimeout = c.get("ws-open-handshake-timeout"),
                              closeHandshakeTimeout = c.get("ws-close-handshake-timeout"),
                              tcpNoDelay = c.get("ws-tcp-nodelay"))

      ## permessage-compression WS extension
      ##
      if c.get("ws-enable-permessage-deflate"):

         windowSize = c.get("ws-permessage-deflate-window-size")
         windowBits = int(math.log(windowSize, 2)) if windowSize != 0 else 0
         requireWindowSize = c.get("ws-permessage-deflate-require-window-size")

         def accept(offers):
            for offer in offers:
               if isinstance(offer, PerMessageDeflateOffer):
                  if windowBits != 0 and offer.acceptMaxWindowBits:
                     return PerMessageDeflateOfferAccept(offer,
                                                         requestMaxWindowBits = windowBits,
                                                         windowBits = windowBits)
                  elif windowBits == 0 or not requireWindowSize:
                     return PerMessageDeflateOfferAccept(offer)

         self.setProtocolOptions(perMessageCompressionAccept = accept)


   def startFactory(self):
      WampServerFactory.startFactory(self)
      self.setOptionsFromConfig()
      log.msg("HubWebSocketFactory started [speaking %s, %s]" % (self.protocols, self.versions))
      self.publishStats()


   def dispatchHubEvent(self, topicuri, event, exclude = [], eligible = None):
      """
      Dispatch from a REST API Push.
      """
      if exclude:
         exclude = self.sessionIdsToProtos(exclude)
      if eligible:
         eligible = self.sessionIdsToProtos(eligible)
      return WampServerFactory.dispatch(self, topicuri, event, exclude, eligible)


   def dispatch(self, topicUri, event, exclude = [], eligible = None):
      """
      Normal dispatch from a WAMP client publish.
      """
      d = WampServerFactory.dispatch(self, topicUri, event, exclude, eligible)
      d.addCallback(self.logNormalDispatch)
      return d


   def logNormalDispatch(self, r):
      delivered, requested = r
      self.stats['ws-publications'] += 1
      self.stats['ws-dispatched-success'] += delivered
      error_count = requested - delivered
      if error_count > 0:
         self.stats['ws-dispatched-failed'] += error_count
      self.statsChanged = True


   def getStats(self):
      return self.stats


   def publishStats(self):
      if self.statsChanged:
         self.services["adminws"].dispatchAdminEvent(URI_EVENT + "on-wsstat", self.stats)
         self.statsChanged = False
      self.reactor.callLater(0.2, self.publishStats)


   def onConnectionCountChanged(self):
      self.stats["ws-connections"] = self.getConnectionCount()
      self.statsChanged = True



class HubWebSocketService(service.Service):

   SERVICENAME = "App WebSocket/Web"

   def __init__(self, dbpool, services, reactor = None):
      ## lazy import to avoid reactor install upon module import
      if reactor is None:
         from twisted.internet import reactor
      self.reactor = reactor

      self.dbpool = dbpool
      self.services = services
      self.isRunning = False
      self.factory = None
      self.wsfactory = None
      self.listener = None
      self.enableAppWeb = False

      ## Jinja2 templates for Web (like WS status page et al)
      ##
      templates_dir = os.path.abspath(pkg_resources.resource_filename("crossbar", "web/templates"))
      log.msg("Using Crossbar.io web templates from %s" % templates_dir)
      self.templates = jinja2.Environment(loader = jinja2.FileSystemLoader(templates_dir))


   def setOptionsFromConfig(self):
      if self.wsfactory:
         self.wsfactory.setOptionsFromConfig()


   def getStats(self):
      if self.isRunning and self.wsfactory:
         return self.wsfactory.getStats()


   def dispatchHubEvent(self, topicuri, event, exclude = [], eligible = None):
      if self.isRunning and self.wsfactory:
         return self.wsfactory.dispatchHubEvent(topicuri, event, exclude, eligible)


   def setWiretapMode(self, sessionid, enable):
      if self.wsfactory:
         proto = self.wsfactory.sessionIdToProto(sessionid)
         if proto:
            return proto.setWiretapMode(enable)
         else:
            raise Exception("no such session")
      else:
         raise Exception("WebSocket factory not running")


   def startService(self):
      log.msg("Starting %s service ..." % self.SERVICENAME)

      ## this is here to avoid module level reactor imports
      ## https://twistedmatrix.com/trac/ticket/6849
      ##
      from twisted.web.server import Site
      from twisted.web.static import File
      from twisted.web.resource import Resource

      from cgiresource import CgiDirectory
      from portconfigresource import addPortConfigResource

      issecure = self.services["config"]["hub-websocket-tls"]
      port = self.services["config"]["hub-websocket-port"]
      hostname = socket.getfqdn()

      ## hostname
      ## externalTls
      ## externalPort
      ## externalHostname

      acceptqueue = self.services["config"]["ws-accept-queue-size"]

      if issecure:
         contextFactory = TlsContextFactory(self.services["config"]["hub-websocket-tlskey-pem"],
                                            self.services["config"]["hub-websocket-tlscert-pem"],
                                            dhParamFilename = self.services['master'].dhParamFilename)

         uri = "wss://%s:%d" % (hostname, port)
      else:
         contextFactory = None

         uri = "ws://%s:%d" % (hostname, port)

      self.wsfactory = HubWebSocketFactory(uri, self.dbpool, self, self.services)
      #self.wsfactory.trackTimings = True

      self.enableAppWeb = self.services["config"]["service-enable-appweb"]

      if self.enableAppWeb:

         ## avoid module level reactor import
         from autobahn.resource import WebSocketResource

         ## FIXME: Site.start/stopFactory should start/stop factories wrapped as Resources
         self.wsfactory.startFactory()
         resource = WebSocketResource(self.wsfactory)
         appwebDir = self.services["master"].webdata

         templates = self.templates

         config = self.services['config']

         wsUri = uri
         wsPath = config.get('ws-websocket-path')
         if wsPath:
            wsUri += "/" + wsPath

         restUri = "dfs"
         if config.get('service-enable-restpusher'):
            restUri = ''.join(['https://' if config.get('hub-web-tls') else 'http://',
                               hostname,
                               ':',
                               str(config.get('hub-web-port'))])

         class Resource404(Resource):
            """
            Custom error page (404).
            """
            def render_GET(self, request):
               page = templates.get_template('cb_web_404.html')
               s = page.render(cbVersion = crossbar.__version__,
                               wsUri = wsUri,
                               restUri = restUri)
               return s.encode('utf8')

         ## Web directory static file serving
         ##
         root = File(appwebDir)

         ## render 404 page on any concrete path not found
         root.childNotFound = Resource404()

         ## disable directory listing and render 404
         root.directoryListing = lambda: root.childNotFound

         ## WebSocket/WAMP resource
         ##
         root.putChild(self.services["config"]["ws-websocket-path"], resource)

         ## CGI resource
         ##
         cgienable = self.services["config"]["appweb-cgi-enable"]
         cgipath = self.services["config"]["appweb-cgi-path"]
         cgiprocessor = self.services["config"]["appweb-cgi-processor"]
         if cgienable and cgipath is not None and cgipath.strip() != "" and cgiprocessor is not None and cgiprocessor.strip() != "":
            cgipath = cgipath.strip()
            cgidir = os.path.join(appwebDir, cgipath)
            cgiprocessor = cgiprocessor.strip()
            cgiresource = CgiDirectory(cgidir, cgiprocessor)
            root.putChild(cgipath, cgiresource)
            log.msg("CGI configured on path '%s' using processor '%s'" % (cgipath, cgiprocessor))
         else:
            log.msg("No CGI configured")


         ## void module level reactor import
         from autobahn.resource import HTTPChannelHixie76Aware

         factory = Site(root)
         factory.log = lambda _: None # disable any logging
         factory.protocol = HTTPChannelHixie76Aware # needed if Hixie76 is to be supported

         ## REST interface to get config values
         ##
         configPath = self.services["config"]["ws-websocket-path"] + "config"
         addPortConfigResource(self.services["config"], root, configPath)
      else:
         factory = self.wsfactory

      self.factory = factory

      if issecure:
         self.listener = self.reactor.listenSSL(port, factory, contextFactory, backlog = acceptqueue)
      else:
         self.listener = self.reactor.listenTCP(port, factory, backlog = acceptqueue)

      self.isRunning = True


   def stopService(self):
      log.msg("Stopping %s service ..." % self.SERVICENAME)
      if self.listener:
         self.listener.stopListening()
         self.listener = None
         self.factory = None
         self.wsfactory = None
         self.enableAppWeb = False
      self.isRunning = False

########NEW FILE########
__FILENAME__ = portconfigresource
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.web.resource import Resource

from autobahn.wamp import json_dumps

from crossbar.database import Database


class PortConfigResource(Resource):
   """
   REST interface to read port configuration from the database.
   """

   def __init__(self, config, port):
      Resource.__init__(self)
      self.config = config
      self.port = port

   def render_GET(self, request):
      port = self.config.get(self.port + "-port", None)
      tls = self.config.get(self.port + "-tls", None)
      if self.port == "hub-websocket":
         path = self.config.get("ws-websocket-path", "")
         res = (port, tls, path)
      else:
         res = (port, tls)
      return json_dumps(res)


def addPortConfigResource(config, root, path):
   """
   Add port configuration Twisted Web resource to path hierachy.

   :param config: Reference to config service.
   :type config: obj
   :param root: Twisted Web root resource where to add child resources.
   :type root: obj
   :param path: Base path under which to add port resources.
   :type path: str
   """
   cfg = Resource()
   root.putChild(path, cfg)
   for port in Database.NETPORTS_TLS_PREFIXES:
      cfg.putChild(port, PortConfigResource(config, port))

########NEW FILE########
__FILENAME__ = platform
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import sys

if sys.platform.startswith('freebsd'):

   ## FreeBSD

   from freebsd.platform import PlatformService
   from freebsd.vmstat import VmstatService
   from freebsd.netstat import NetstatService
   SYSCMD_ZIP = '/usr/local/bin/zip'
   SYSCMD_SQLITE3 = '/usr/local/bin/sqlite3'

elif sys.platform.startswith('linux'):

   ## Amazon Linux

   from linux.platform import PlatformService
   from linux.vmstat import VmstatService
   from linux.netstat import NetstatService
   SYSCMD_ZIP = '/usr/bin/zip'
   SYSCMD_SQLITE3 = '/usr/bin/sqlite3'

else:

   ## Fake Platform
#   raise ImportError("my module doesn't support this system")
#   print "Using FakeOS platform module!"
   from fakeos.platform import PlatformService
   from fakeos.vmstat import VmstatService
   from fakeos.netstat import NetstatService
   SYSCMD_ZIP = 'zip'
   SYSCMD_SQLITE3 = 'sqlite3'

########NEW FILE########
__FILENAME__ = service
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import os, datetime, sys, time

import OpenSSL
import twisted

from twisted.python import log, usage
from twisted.application.service import MultiService

from crossbar.logger import Logger
from crossbar.database import Database
from crossbar.config import Config

from crossbar.clientfilter import ClientFilter

from crossbar.bridge.extdirectremoter import ExtDirectRemoter

from crossbar.bridge.restpusher import RestPusher
from crossbar.bridge.restremoter import RestRemoter

from crossbar.bridge.hanaremoter import HanaRemoter
from crossbar.bridge.hanapusher import HanaPusher

from crossbar.bridge.pgremoter import PgRemoter
from crossbar.bridge.pgpusher import PgPusher

from crossbar.bridge.oraremoter import OraRemoter
from crossbar.bridge.orapusher import OraPusher

from crossbar.netservice.hubwebresource import HubWebService
from crossbar.netservice.hubwebsocket import HubWebSocketService
from crossbar.netservice.adminwebresource import AdminWebService
from crossbar.netservice.adminwebsocket import AdminWebSocketService

from crossbar.netservice.echowebsocket import EchoWebSocketService
from crossbar.netservice.flashpolicy import FlashPolicyService

from crossbar.platform import PlatformService
from crossbar.platform import NetstatService
from crossbar.platform import VmstatService


class CrossbarService(MultiService):
   """
   Root service for Crossbar.io.

   Some notes on implementing twistd plugins:

      http://chrismiles.livejournal.com/23399.html
      https://bitbucket.org/jerub/twisted-plugin-example/src
      http://twistedmatrix.com/documents/current/core/howto/tap.html
      http://twistedmatrix.com/documents/current/core/howto/plugin.html
   """

   def __init__(self, logger, cbdata, webdata = None, debug = False, isExe = False):
      MultiService.__init__(self)
      self.logger = logger
      self.cbdata = cbdata
      self.webdata = webdata
      self.debug = debug
      self.isExe = isExe


   def startService(self):
      """
      Main entry point to startup the Crossbar.io service.
      """
      try:
         s = self._startService()
         return s
      except Exception, e:
         print
         es = " ERROR "
         l1 = (80 - len(es)) / 2
         l2 = 80 - l1 - len(es)
         print "*" * l1 + es  + "*" * l2
         print
         if isinstance(e, twisted.internet.error.CannotListenError):
            print "Could not listen on port %d. Is there another program listening on the port already?" % e.port
            print
            print "[%s]" % e.socketError
         else:
            print e
         print
         print "*" * 80
         print

         ## delay exit ..
         d = 5
         print "Exciting in %d seconds .." % d
         time.sleep(d)

         raise e


   def _startService(self):

      ## this is here, since it triggers a reactor import
      from crossbar.netservice.ftpserver import FtpService

      cfg = None
      dbpool = None
      services = {}

      ## Master Service and logger
      ##
      services["master"] = self
      services["logger"] = self.logger

      ## remember service start time
      ##
      self.started = datetime.datetime.utcnow()

      ## make sure we have full absolute path to data dir
      ##
      self.cbdata = os.path.abspath(self.cbdata)

      ## initialize database
      ##
      db = Database(services)
      #db.setName("database")
      #db.setServiceParent(self)
      services["database"] = db
      db.startService()

      cfg = db.getConfig(includeTls = True)
      dbpool = db.createPool()

      ## Log OpenSSL info
      ##
      log.msg("Using pyOpenSSL %s on OpenSSL %s" % (OpenSSL.__version__, OpenSSL.SSL.SSLeay_version(OpenSSL.SSL.SSLEAY_VERSION)))

      ## Generate DH param set (primes ..)
      ##
      ## http://linux.die.net/man/3/ssl_ctx_set_tmp_dh
      ## http://linux.die.net/man/1/dhparam
      ##
      self.dhParamFilename = os.path.join(self.cbdata, 'dh_param.pem')
      if not os.path.exists(self.dhParamFilename):
         os.system("openssl dhparam -out %s -2 1024" % self.dhParamFilename)
         log.msg("Generated DH param file %s" % self.dhParamFilename)
      else:
         log.msg("Using existing DH param file %s" % self.dhParamFilename)

      ## License options
      ##
      self.licenseOptions = db.getLicenseOptions()

      ## Installed options
      ##
      self.installedOptions = db.getInstalledOptions()

      if self.webdata is None:
         self.webdata = os.path.join(self.cbdata, db.getConfig('web-dir'))
         print "Crossbar.io Web directory unspecified - using %s." % self.webdata

      ## Print out core information to log
      ##
      log.msg("")
      log.msg('*' * 80)
      log.msg("")
      log.msg("  You can access the management console of crossbar.io at")
      log.msg("")
      log.msg("  >>>>>>>>>  %s" % db.getWebAdminURL())
      log.msg("")
      log.msg("  from your browser (Google Chrome, Mozilla Firefox or Microsoft IE10+)")
      log.msg("")
      log.msg("")
      log.msg("  You can access the static Web content served by crossbar.io at")
      log.msg("")
      log.msg("  >>>>>>>>>  %s" % self.webdata)
      log.msg("")
      log.msg("  on the filesystem of your instance.")
      log.msg("")
      log.msg('*' * 80)
      log.msg("")

      ## Setup services hierarchy
      ##
      SERVICES = [(None, None, [("config", Config)]),
                  (None, None, [("platform", PlatformService)]),
                  (None, None, [("netstat", NetstatService)]),
                  (None, None, [("vmstat", VmstatService)]),
                  (None, None, [("appws", HubWebSocketService)]),
                  (None, None, [("echows", EchoWebSocketService)]),
                  (None, None, [("flashpolicy", FlashPolicyService)]),
                  (None, None, [("ftp", FtpService)]),
                  (None, None, [("clientfilter", ClientFilter)]),
                  (None, None, [("hubweb", HubWebService)]),
                  (None, None, [("adminweb", AdminWebService)]),
                  (None, None, [("adminws", AdminWebSocketService)]),
                  (None, "rest", [("restpusher", RestPusher), ("restremoter", RestRemoter)]),
                  (None, "extdirect", [("extdirectremoter", ExtDirectRemoter)]),
                  ("postgresql", "postgresql", [("pgpusher", PgPusher), ("pgremoter", PgRemoter)]),
                  ("oracle", "oracle", [("orapusher", OraPusher), ("oraremoter", OraRemoter)]),
                  ("hana", "hana", [("hanapusher", HanaPusher), ("hanaremoter", HanaRemoter)])
                  ]

      for sdef in SERVICES:

         installedOptionName, licenseOptionName, serviceList = sdef
         installed = installedOptionName is None or self.installedOptions[installedOptionName]
         licensed = licenseOptionName is None or self.licenseOptions[licenseOptionName]

         for s in serviceList:
            if installed:
               if licensed:
                  enabled = cfg.get("service-enable-%s" % s[0], True)
                  if enabled:
                     svc = s[1](dbpool, services)
                     svc.setName(s[0])
                     svc.setServiceParent(self)
                     services[s[0]] = svc
                  else:
                     log.msg("Skipping %s (service disabled)!" % s[1].SERVICENAME)
               else:
                  log.msg("Skipping %s (service not licensed)!" % s[1].SERVICENAME)
            else:
               log.msg("Skipping %s (service not installed)!" % s[1].SERVICENAME)


      ## Start whole service hierarchy
      ##
      MultiService.startService(self)

########NEW FILE########
__FILENAME__ = servicefactory
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


__all__ = ['LONGDESC', 'Options', 'makeService']


import os
from twisted.python import log
from twisted.python import usage


## keep in sync with LONGDESC in "setup.py"
##
LONGDESC = """
Crossbar.io - The open-source multi-protocol application router.
Documentation, community and source-code at http://crossbar.io

Created by Tavendo GmbH. Get in contact at http://tavendo.com

Open-source licensed under the GNU Affero General Public License version 3
https://github.com/crossbario/crossbar/blob/master/crossbar/LICENSE
"""


class Options(usage.Options):
   """
   Crossbar.io command line options when run from twistd as plugin.
   """
   longdesc = LONGDESC

   optFlags = [['debug', 'd', 'Emit debug messages']]
   optParameters = [["cbdata", "c", None, "Crossbar.io data directory (overrides environment variable CROSSBAR_DATA)."],
                    ["webdata", "w", None, "Crossbar.io static Web directory (overrides default CROSSBAR_DATA/web)."]]


def makeService(options = {}):
   """
   Main entry point into Crossbar.io application.
   This creates an instance CrossbarService which can be run under twistd
   as a plugin or directly.
   """
   ## We need to monkey patch in the new Python IO
   ## because of http://www.freebsd.org/cgi/query-pr.cgi?pr=148581
   ## when using the kqueue reactor and twistd.
   ##
   import io, __builtin__
   __builtin__.open = io.open


   ## install our log observer before anything else is done
   ##
   from crossbar.logger import Logger
   logger = Logger()
   log.addObserver(logger)
   #print "Log observers", log.theLogPublisher.observers

   ## suggest a background thread pool size
   ##
   from twisted.internet import reactor
   reactor.suggestThreadPoolSize(30)

   ## massage options
   ##
   if not options.has_key('cbdata') or not options['cbdata']:
      if os.environ.has_key("CROSSBAR_DATA"):
         options['cbdata'] = os.environ["CROSSBAR_DATA"]
         log.msg("Crossbar.io service data directory %s set from environment variable CROSSBAR_DATA." % options['cbdata'])
      else:
         options['cbdata'] = os.path.join(os.getcwd(), 'cbdata')
         log.msg("Crossbar.io service directory unspecified - using %s." % options['cbdata'])
   else:
      log.msg("Crossbar.io application data directory %s set via command line option." % options['cbdata'])

   if not options.has_key('webdata') or not options['webdata']:
      if os.environ.has_key("CROSSBAR_DATA_WEB"):
         options['webdata'] = os.environ["CROSSBAR_DATA_WEB"]
         log.msg("Crossbar.io static Web directory %s set from environment variable CROSSBAR_DATA_WEB." % options['webdata'])
      else:
         options['webdata'] = None
   else:
      log.msg("Crossbar.io static Web directory %s set via command line option." % options['webdata'])

   options['debug'] = True if options.get('debug') else False

   ## now create the Crossbar.io service object
   ##
   from crossbar.service import CrossbarService
   svc = CrossbarService(logger, options['cbdata'], options['webdata'], options['debug'])

   #from twisted.python.log import ILogObserver, FileLogObserver
   #from twisted.python.logfile import DailyLogFile

   #application = Application("myapp")
   #logfile = DailyLogFile("my.log", "/tmp")
   #application.setComponent(ILogObserver, FileLogObserver(logfile).emit)
   #svc.setComponent(ILogObserver, None)


   return svc

########NEW FILE########
__FILENAME__ = tlsctx
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import tempfile

from OpenSSL import crypto, SSL
from twisted.internet.ssl import DefaultOpenSSLContextFactory

from twisted.python import log

## Monkey patch missing constants
##
## See:
##   - https://bugs.launchpad.net/pyopenssl/+bug/1244201
##   - https://www.openssl.org/docs/ssl/SSL_CTX_set_options.html
##
SSL.OP_NO_COMPRESSION                         = 0x00020000L
SSL.OP_CIPHER_SERVER_PREFERENCE               = 0x00400000L
SSL.OP_SINGLE_ECDH_USE                        = 0x00080000L
SSL.OP_SINGLE_DH_USE                          = 0x00100000L
SSL.OP_DONT_INSERT_EMPTY_FRAGMENTS            = 0x00000800L
SSL.OP_NO_TLSv1                               = 0x04000000L
SSL.OP_NO_SESSION_RESUMPTION_ON_RENEGOTIATION = 0x00010000L
SSL.OP_NO_TICKET                              = 0x00004000L

SSL_DEFAULT_OPTIONS = SSL.OP_NO_SSLv2 | \
                      SSL.OP_NO_SSLv3 | \
                      SSL.OP_NO_COMPRESSION | \
                      SSL.OP_CIPHER_SERVER_PREFERENCE | \
                      SSL.OP_SINGLE_ECDH_USE | \
                      SSL.OP_SINGLE_DH_USE | \
                      SSL.OP_DONT_INSERT_EMPTY_FRAGMENTS | \
                      SSL.OP_NO_SESSION_RESUMPTION_ON_RENEGOTIATION | \
                      SSL.OP_NO_TICKET

## List of available ciphers
##
## Check via: https://www.ssllabs.com/ssltest/analyze.html?d=myserver.com
##
## http://www.openssl.org/docs/apps/ciphers.html#CIPHER_LIST_FORMAT
##

# http://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/
#SSL_DEFAULT_CIPHERS = 'ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AES:RSA+3DES:!ADH:!AECDH:!MD5:!DSS'

## We prefer to make every single cipher (6 in total) _explicit_ (to reduce chances either we or the pattern-matching
## language inside OpenSSL messes up) and drop support for Windows XP (we do WebSocket anyway).
## We don't use AES256 and SHA384, to reduce number of ciphers and since the additional security gain seems
## to worth the additional performance drain.
##
SSL_DEFAULT_CIPHERS = 'ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA'

## Resorted to prioritize ECDH (hence favor performance over cipher strength) - no gain in practice, that doesn't
## change the effectively accepted cipher with common browsers/clients
#SSL_DEFAULT_CIPHERS = 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA'


## Named curves built into OpenSSL .. can be listed using:
##
##  openssl ecparam -list_curves
##
## Only some of those are exposed in pyOpenSSL
##
## http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf

## curves over binary fields
##
SSL.SN_X9_62_c2pnb163v1      = "c2pnb163v1"
SSL.NID_X9_62_c2pnb163v1     = 684

SSL.SN_X9_62_c2pnb163v2      = "c2pnb163v2"
SSL.NID_X9_62_c2pnb163v2     = 685

SSL.SN_X9_62_c2pnb163v3      = "c2pnb163v3"
SSL.NID_X9_62_c2pnb163v3     = 686

SSL.SN_X9_62_c2pnb176v1      = "c2pnb176v1"
SSL.NID_X9_62_c2pnb176v1     = 687

SSL.SN_X9_62_c2tnb191v1      = "c2tnb191v1"
SSL.NID_X9_62_c2tnb191v1     = 688

SSL.SN_X9_62_c2tnb191v2      = "c2tnb191v2"
SSL.NID_X9_62_c2tnb191v2     = 689

SSL.SN_X9_62_c2tnb191v3      = "c2tnb191v3"
SSL.NID_X9_62_c2tnb191v3     = 690

SSL.SN_X9_62_c2onb191v4      = "c2onb191v4"
SSL.NID_X9_62_c2onb191v4     = 691

SSL.SN_X9_62_c2onb191v5      = "c2onb191v5"
SSL.NID_X9_62_c2onb191v5     = 692

SSL.SN_X9_62_c2pnb208w1      = "c2pnb208w1"
SSL.NID_X9_62_c2pnb208w1     = 693

SSL.SN_X9_62_c2tnb239v1      = "c2tnb239v1"
SSL.NID_X9_62_c2tnb239v1     = 694

SSL.SN_X9_62_c2tnb239v2      = "c2tnb239v2"
SSL.NID_X9_62_c2tnb239v2     = 695

SSL.SN_X9_62_c2tnb239v3      = "c2tnb239v3"
SSL.NID_X9_62_c2tnb239v3     = 696

SSL.SN_X9_62_c2onb239v4      = "c2onb239v4"
SSL.NID_X9_62_c2onb239v4     = 697

SSL.SN_X9_62_c2onb239v5      = "c2onb239v5"
SSL.NID_X9_62_c2onb239v5     = 698

SSL.SN_X9_62_c2pnb272w1      = "c2pnb272w1"
SSL.NID_X9_62_c2pnb272w1     = 699

SSL.SN_X9_62_c2pnb304w1      = "c2pnb304w1"
SSL.NID_X9_62_c2pnb304w1     = 700

SSL.SN_X9_62_c2tnb359v1      = "c2tnb359v1"
SSL.NID_X9_62_c2tnb359v1     = 701

SSL.SN_X9_62_c2pnb368w1      = "c2pnb368w1"
SSL.NID_X9_62_c2pnb368w1     = 702

SSL.SN_X9_62_c2tnb431r1      = "c2tnb431r1"
SSL.NID_X9_62_c2tnb431r1     = 703

## curves over prime fields
##
SSL.SN_X9_62_prime192v1      = "prime192v1"
SSL.NID_X9_62_prime192v1     = 409
SSL.SN_X9_62_prime192v2      = "prime192v2"
SSL.NID_X9_62_prime192v2     = 410
SSL.SN_X9_62_prime192v3      = "prime192v3"
SSL.NID_X9_62_prime192v3     = 411
SSL.SN_X9_62_prime239v1      = "prime239v1"
SSL.NID_X9_62_prime239v1     = 412
SSL.SN_X9_62_prime239v2      = "prime239v2"
SSL.NID_X9_62_prime239v2     = 413
SSL.SN_X9_62_prime239v3      = "prime239v3"
SSL.NID_X9_62_prime239v3     = 414
SSL.SN_X9_62_prime256v1      = "prime256v1"
SSL.NID_X9_62_prime256v1     = 415

## map of curve name to curve NID
##
ELLIPTIC_CURVES = {
   SSL.SN_X9_62_c2pnb163v1: SSL.NID_X9_62_c2pnb163v1,
   SSL.SN_X9_62_c2pnb163v2: SSL.NID_X9_62_c2pnb163v2,
   SSL.SN_X9_62_c2pnb163v3: SSL.NID_X9_62_c2pnb163v3,
   SSL.SN_X9_62_c2pnb176v1: SSL.NID_X9_62_c2pnb176v1,
   SSL.SN_X9_62_c2tnb191v1: SSL.NID_X9_62_c2tnb191v1,
   SSL.SN_X9_62_c2tnb191v2: SSL.NID_X9_62_c2tnb191v2,
   SSL.SN_X9_62_c2tnb191v3: SSL.NID_X9_62_c2tnb191v3,
   SSL.SN_X9_62_c2onb191v4: SSL.NID_X9_62_c2onb191v4,
   SSL.SN_X9_62_c2onb191v5: SSL.NID_X9_62_c2onb191v5,
   SSL.SN_X9_62_c2pnb208w1: SSL.NID_X9_62_c2pnb208w1,
   SSL.SN_X9_62_c2tnb239v1: SSL.NID_X9_62_c2tnb239v1,
   SSL.SN_X9_62_c2tnb239v2: SSL.NID_X9_62_c2tnb239v2,
   SSL.SN_X9_62_c2tnb239v3: SSL.NID_X9_62_c2tnb239v3,
   SSL.SN_X9_62_c2onb239v4: SSL.NID_X9_62_c2onb239v4,
   SSL.SN_X9_62_c2onb239v5: SSL.NID_X9_62_c2onb239v5,
   SSL.SN_X9_62_c2pnb272w1: SSL.NID_X9_62_c2pnb272w1,
   SSL.SN_X9_62_c2pnb304w1: SSL.NID_X9_62_c2pnb304w1,
   SSL.SN_X9_62_c2tnb359v1: SSL.NID_X9_62_c2tnb359v1,
   SSL.SN_X9_62_c2pnb368w1: SSL.NID_X9_62_c2pnb368w1,
   SSL.SN_X9_62_c2tnb431r1: SSL.NID_X9_62_c2tnb431r1,

   SSL.SN_X9_62_prime192v1: SSL.NID_X9_62_prime192v1,
   SSL.SN_X9_62_prime192v2: SSL.NID_X9_62_prime192v2,
   SSL.SN_X9_62_prime192v3: SSL.NID_X9_62_prime192v3,
   SSL.SN_X9_62_prime239v1: SSL.NID_X9_62_prime239v1,
   SSL.SN_X9_62_prime239v2: SSL.NID_X9_62_prime239v2,
   SSL.SN_X9_62_prime239v3: SSL.NID_X9_62_prime239v3,
   SSL.SN_X9_62_prime256v1: SSL.NID_X9_62_prime256v1
}

## prime256v1: X9.62/SECG curve over a 256 bit prime field
##
## This is elliptic curve "NIST P-256" from here
## http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf
##
## This seems to be the most widely used curve
##
##   http://crypto.stackexchange.com/questions/11310/with-openssl-and-ecdhe-how-to-show-the-actual-curve-being-used
##
## and researchers think it is "ok" (other than wrt timing attacks etc)
##
##   https://twitter.com/hyperelliptic/status/394258454342148096
##
ECDH_DEFAULT_CURVE = ELLIPTIC_CURVES["prime256v1"]


class TlsContextFactory(DefaultOpenSSLContextFactory):
   """
   TLS context factory for use with Twisted.

   Like the default

      http://twistedmatrix.com/trac/browser/tags/releases/twisted-11.1.0/twisted/internet/ssl.py#L42

   but loads key/cert from string, not file and supports chained certificates.

   See also:

      http://pyopenssl.sourceforge.net/pyOpenSSL.html/openssl-context.html
      http://www.openssl.org/docs/ssl/SSL_CTX_use_certificate.html

   Chained certificates:
      The certificates must be in PEM format and must be sorted starting with
      the subject's certificate (actual client or server certificate), followed
      by intermediate CA certificates if applicable, and ending at the
      highest level (root) CA.

   Hardening:
      http://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/
      https://www.ssllabs.com/ssltest/analyze.html?d=www.example.com
   """

   def __init__(self, privateKeyString, certificateString, chainedCertificate = True, dhParamFilename = None):
      self.privateKeyString = str(privateKeyString)
      self.certificateString = str(certificateString)
      self.chainedCertificate = chainedCertificate
      self.dhParamFilename = dhParamFilename

      ## do a SSLv2-compatible handshake even for TLS
      ##
      self.sslmethod = SSL.SSLv23_METHOD

      self._contextFactory = SSL.Context
      self.cacheContext()

   def cacheContext(self):
      if self._context is None:
         ctx = self._contextFactory(self.sslmethod)

         ## SSL hardening
         ##
         ctx.set_options(SSL_DEFAULT_OPTIONS)
         ctx.set_cipher_list(SSL_DEFAULT_CIPHERS)


         ## Activate DH(E)
         ##
         ## http://linux.die.net/man/3/ssl_ctx_set_tmp_dh
         ## http://linux.die.net/man/1/dhparam
         ##
         if self.dhParamFilename:
            try:
               ctx.load_tmp_dh(self.dhParamFilename)
            except Exception, e:
               log.msg("Error: OpenSSL DH modes not active - failed to load DH parameter file [%s]" % e)
         else:
            log.msg("Warning: OpenSSL DH modes not active - missing DH param file")


         ## Activate ECDH(E)
         ##
         ## This needs pyOpenSSL with patch applied from
         ## https://bugs.launchpad.net/pyopenssl/+bug/1233810
         ##
         try:
            ## without setting a curve, ECDH won't be available even if listed
            ## in SSL_DEFAULT_CIPHERS!
            ##
            ctx.set_tmp_ecdh_by_curve_name(ECDH_DEFAULT_CURVE)
         except Exception, e:
            log.msg("Failed to set ECDH default curve [%s]" % e)


         ## load certificate (chain) into context
         ##
         if not self.chainedCertificate:
            cert = crypto.load_certificate(crypto.FILETYPE_PEM, self.certificateString)
            ctx.use_certificate(cert)
         else:
            # http://pyopenssl.sourceforge.net/pyOpenSSL.html/openssl-context.html
            # there is no "use_certificate_chain" function, so we need to create
            # a temporary file writing the certificate chain file
            f = tempfile.NamedTemporaryFile(delete = False)
            f.write(self.certificateString)
            f.close()
            ctx.use_certificate_chain_file(f.name)


         ## load private key into context
         ##
         key = crypto.load_privatekey(crypto.FILETYPE_PEM, self.privateKeyString)
         ctx.use_privatekey(key)
         ctx.check_privatekey()


         ## set cached context
         ##
         self._context = ctx

########NEW FILE########
__FILENAME__ = txutil
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import re
from urlparse import urlunparse

from zope.interface import implements
from twisted.python import log

## the following does a module level import of reactor
## http://twistedmatrix.com/trac/browser/tags/releases/twisted-13.2.0/twisted/web/client.py#L31
## https://twistedmatrix.com/trac/ticket/6849
##
# from twisted.web.client import HTTPClientFactory

from twisted.internet.defer import succeed
from twisted.web.iweb import IBodyProducer
from twisted.internet.protocol import Protocol

## the following does a module level import of reactor
## http://twistedmatrix.com/trac/browser/tags/releases/twisted-13.2.0/twisted/protocols/ftp.py#L28
## https://twistedmatrix.com/trac/ticket/6849
##
#from twisted.protocols.ftp import FTPFactory, FTP, DTPFactory, ENTERING_PASV_MODE, encodeHostPort


## Starting from Twisted 13.1, this is removed. We replicate the code here. FIXME.
## http://twistedmatrix.com/trac/browser/tags/releases/twisted-13.0.0/twisted/web/client.py?format=txt

#from twisted.web.client import _parse
#from twisted.web import http


def _parse(url, defaultPort=None):
    """
    Split the given URL into the scheme, host, port, and path.

    @type url: C{bytes}
    @param url: An URL to parse.

    @type defaultPort: C{int} or C{None}
    @param defaultPort: An alternate value to use as the port if the URL does
    not include one.

    @return: A four-tuple of the scheme, host, port, and path of the URL.  All
    of these are C{bytes} instances except for port, which is an C{int}.
    """
    url = url.strip()
    parsed = http.urlparse(url)
    scheme = parsed[0]
    path = urlunparse((b'', b'') + parsed[2:])

    if defaultPort is None:
        if scheme == b'https':
            defaultPort = 443
        else:
            defaultPort = 80

    host, port = parsed[1], defaultPort
    if b':' in host:
        host, port = host.split(b':')
        try:
            port = int(port)
        except ValueError:
            port = defaultPort

    if path == b'':
        path = b'/'

    return (scheme, host, port, path)


def getDomain(str):
   try:
      import tldextract

      r = tldextract.extract(str)
      return r.domain + ("." + r.tld if r.tld != "" else "")
   except:
      return '.'.join(str.split('.')[-2:])


def isValidHostname(hostname):
   ## http://stackoverflow.com/a/2532344/884770
   if len(hostname) > 255:
      return False
   if hostname[-1:] == ".":
      hostname = hostname[:-1] # strip exactly one dot from the right, if present
   allowed = re.compile("(?!-)[A-Z\d-]{1,63}(?<!-)$", re.IGNORECASE)
   return all(allowed.match(x) for x in hostname.split("."))


class StringReceiver(Protocol):
   def __init__(self, finished):
      self.finished = finished
      self.response = []

   def dataReceived(self, bytes):
      #print bytes
      self.response.append(bytes)

   def connectionLost(self, reason):
      self.finished.callback("".join(self.response))


class StringProducer(object):
   implements(IBodyProducer)

   def __init__(self, body):
      self.body = body
      if body:
         self.length = len(body)
      else:
         self.length = 0

   def startProducing(self, consumer):
      if self.body:
         consumer.write(self.body)
      return succeed(None)

   def pauseProducing(self):
      pass

   def stopProducing(self):
      pass


def _makeGetterFactory(url, factoryFactory, contextFactory=None,
                       *args, **kwargs):
    """
    Create and connect an HTTP page getting factory.

    Any additional positional or keyword arguments are used when calling
    C{factoryFactory}.

    @param factoryFactory: Factory factory that is called with C{url}, C{args}
        and C{kwargs} to produce the getter

    @param contextFactory: Context factory to use when creating a secure
        connection, defaulting to C{None}

    @return: The factory created by C{factoryFactory}
    """
    scheme, host, port, path = _parse(url)

    ## extract connection timeout if present
    ##
    _kwargs = {}
    if kwargs.has_key('connectionTimeout'):
       _kwargs['timeout'] = kwargs['connectionTimeout']
       del kwargs['connectionTimeout']

    factory = factoryFactory(url, *args, **kwargs)

    from twisted.internet import reactor

    if scheme == 'https':
        from twisted.internet import ssl
        if contextFactory is None:
            contextFactory = ssl.ClientContextFactory()
        reactor.connectSSL(host, port, factory, contextFactory, **_kwargs)
    else:
        reactor.connectTCP(host, port, factory, **_kwargs)
    return factory


def getPage(url, contextFactory=None, *args, **kwargs):
    """
    Download a web page as a string.

    Download a page. Return a deferred, which will callback with a
    page (as a string) or errback with a description of the error.

    See L{HTTPClientFactory} to see what extra arguments can be passed.
    """
    return _makeGetterFactory(
        url,
        HTTPClientFactory,
        contextFactory=contextFactory,
        *args, **kwargs).deferred



class CustomFTP(object):
#class CustomFTP(FTP):
   def ftp_PASV(self):
      # if we have a DTP port set up, lose it.
      if self.dtpFactory is not None:
          # cleanupDTP sets dtpFactory to none.  Later we'll do
          # cleanup here or something.
          self.cleanupDTP()
      self.dtpFactory = DTPFactory(pi=self)
      self.dtpFactory.setTimeout(self.dtpTimeout)
      self.dtpPort = self.getDTPPort(self.dtpFactory)

      if self.factory.passivePublicIp is not None:
         # use explicit public IP for passive mode (when behind load-balancer or such)
         host = self.factory.passivePublicIp
         log.msg("using explicit public IP %s" % host)
      else:
         # use transport IP
         host = self.transport.getHost().host
         log.msg("using transport IP %s" % host)

      port = self.dtpPort.getHost().port
      self.reply(ENTERING_PASV_MODE, encodeHostPort(host, port))
      return self.dtpFactory.deferred.addCallback(lambda ign: None)


class CustomFTPFactory(object):
#class CustomFTPFactory(FTPFactory):
   protocol = CustomFTP
   passivePublicIp = None

########NEW FILE########
__FILENAME__ = x509util
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


import hashlib, datetime
from OpenSSL import crypto
from Crypto.PublicKey import RSA


ZERODIGEST = ('00:' * (160/8))[:-1]


def dotted(s):
   """
   Dotted hex from hex string.
   """
   ss = ':'.join(s[pos:pos+2] for pos in range(0, len(s), 2))
   return ss.upper() # do NOT change to lower() !


def fingerprint(key):
   """
   Compute SHA1 fingerprint from key in DER format.

   :param key: Key in DER format.
   :type key: str
   :returns str -- Fingerprint of key in dotted hex format.
   """
   digest = hashlib.sha1(key).hexdigest()
   return dotted(digest)


def fill_x509name_from_info(name, info):
   """
   Fill X509 name object from info dictionary.

   :param name: The X509 name object to be filled.
   :type name: crypto.X509Name instance
   :param info: An info dictionary.
   :type info: dict
   """
   if info.has_key("common-name") and type(info["common-name"]) in [str, unicode]:
      name.CN = info["common-name"].encode("utf8")
   if info.has_key("country-name") and type(info["country-name"]) in [str, unicode]:
      name.C = info["country-name"].encode("utf8")
   if info.has_key("state-or-province-name") and type(info["state-or-province-name"]) in [str, unicode]:
      name.ST = info["state-or-province-name"].encode("utf8")
   if info.has_key("locality-name") and type(info["locality-name"]) in [str, unicode]:
      name.L = info["locality-name"].encode("utf8")
   if info.has_key("organization-name") and type(info["organization-name"]) in [str, unicode]:
      name.O = info["organization-name"].encode("utf8")
   if info.has_key("organization-unit-name") and type(info["organization-unit-name"]) in [str, unicode]:
      name.OU = info["organization-unit-name"].encode("utf8")
   if info.has_key("email-address") and type(info["email-address"]) in [str, unicode]:
      name.emailAddress = info["email-address"].encode("utf8")


def extract_info_from_x509name(name):
   """
   Create info dictionary from X509 name object.

   :param name: The X509 name object from which to extract info.
   :type name: crypto.X509Name instance
   :returns dict -- Info dictionary for X509 entity.
   """
   info = {}
   if name.CN:
      info["common-name"] = name.CN
   else:
      info["common-name"] = ""
   if name.C:
      info["country-name"] = name.C
   else:
      info["country-name"] = ""
   if name.ST:
      info["state-or-province-name"] = name.ST
   else:
      info["state-or-province-name"] = ""
   if name.L:
      info["locality-name"] = name.L
   else:
      info["locality-name"] = ""
   if name.O:
      info["organization-name"] = name.O
   else:
      info["organization-name"] = ""
   if name.OU:
      info["organization-unit-name"] = name.OU
   else:
      info["organization-unit-name"] = ""
   if name.emailAddress:
      info["email-address"] = name.emailAddress
   else:
      info["email-address"] = ""
   return info


def generate_rsa_key(length = 1024):
   """
   Generate new RSA key pair.

   :param length: Length of key, must be one of 1024, 2048 or 4096.
   :type length: int
   :returns tuple -- (Key PEM, Public Key PEM, Key Fingerprint).
   """
   pkey = crypto.PKey()
   pkey.generate_key(crypto.TYPE_RSA, length)

   keypem = crypto.dump_privatekey(crypto.FILETYPE_PEM, pkey)

   # FIXME: pyOpenSSL lacks a dump_publickey method, so we use pyCrypto for that
   pkey2 = RSA.importKey(keypem).publickey()
   pub_keypem = pkey2.exportKey()

   # FIXME: pyOpenSSL lacks a fingerprint method, so we use pyCrypto for that
   fp = fingerprint(pkey2.exportKey(format = 'DER'))

   return (keypem, pub_keypem, fp)


def check_rsa_key(keyPem):
   """
   Load and checks a private RSA key.

   :param keyPem: Subject private RSA key in PEM format.
   :type keyPem: str
   :returns tuple -- (key length, key fingerprint).
   """
   key = crypto.load_privatekey(crypto.FILETYPE_PEM, keyPem)
   key.check()

   # FIXME: pyOpenSSL lacks a dump_publickey method, so we use pyCrypto for that
   pkey2 = RSA.importKey(keyPem).publickey()
   pub_keypem = pkey2.exportKey()

   # FIXME: pyOpenSSL lacks a fingerprint method, so we use pyCrypto for that
   fp = fingerprint(pkey2.exportKey(format = 'DER'))

   return (pub_keypem, key.bits(), fp)


def create_certificate_signing_request(subjectKey,
                                       subjectInfo,
                                       version = 0,
                                       hash = 'sha1'):
   """
   Create a certificate signing request (CSR) and return CSR
   in PEM and text formats.

   :param subjectKey: Subject private RSA key in PEM format.
   :type subjectKey: str
   :param subjectInfo: Subject information.
   :type subjectInfo: dict
   :returns tuple -- (CSR in PEM format, CSR as Text).
   """
   skey = crypto.load_privatekey(crypto.FILETYPE_PEM, subjectKey)

   req = crypto.X509Req()
   subj = req.get_subject()
   fill_x509name_from_info(subj, subjectInfo)
   req.set_pubkey(skey)
   req.set_version(version)
   req.sign(skey, hash)

   csr_pem = crypto.dump_certificate_request(crypto.FILETYPE_PEM, req)

   # FIXME: needs crypto.FILETYPE_TEXT
   csr_text = '???'
   return (csr_pem, csr_text)


def create_certificate(issuerKeyPem,
                       issuerCertPem,
                       csrPem,
                       validForDays,
                       serial,
                       version = 0,
                       digest = 'sha1'):
   """
   Create a certificate and return certificate (PEM, text, fingerprint).

   :param subjectPrivKey: Subject private RSA key in PEM format.
   :type subjectPrivKey: str
   :param subjectInfo: Subject information.
   :type subjectInfo: dict
   :returns tuple -- (CSR in PEM format, CSR as text).
   """
   issuerKey = crypto.load_privatekey(crypto.FILETYPE_PEM, issuerKeyPem)
   issuerCert = crypto.load_certificate(crypto.FILETYPE_PEM, issuerCertPem)
   csr = crypto.load_certificate_request(crypto.FILETYPE_PEM, csrPem)

   cert = crypto.X509()
   cert.set_serial_number(serial)
   cert.set_version(version)
   cert.gmtime_adj_notBefore(0)
   cert.gmtime_adj_notAfter(60 * 60 * 24 * validForDays)
   cert.set_issuer(issuerCert.get_subject())
   cert.set_subject(csr.get_subject())
   cert.set_pubkey(csr.get_pubkey())
   cert.sign(issuerKey, digest)

   certPem = crypto.dump_certificate(crypto.FILETYPE_PEM, cert)
   certText = '???'
   certFingerprint = cert.digest(digest)

   return (certPem, certText, certFingerprint)


def create_selfsigned_certificate(entityPrivKey,
                                  entityInfo,
                                  validForDays,
                                  serial = 0,
                                  version = 0,
                                  digest = 'sha1'):
   """
   Create a self-signed certificate and return certificate (PEM, text, fingerprint).
   """
   ekey = crypto.load_privatekey(crypto.FILETYPE_PEM, entityPrivKey)

   req = crypto.X509Req()
   subj = req.get_subject()
   fill_x509name_from_info(subj, entityInfo)
   req.set_pubkey(ekey)
   req.sign(ekey, digest)

   cert = crypto.X509()
   cert.set_serial_number(serial)
   cert.set_version(version)
   cert.gmtime_adj_notBefore(0)
   cert.gmtime_adj_notAfter(60 * 60 * 24 * validForDays)
   cert.set_issuer(req.get_subject())
   cert.set_subject(req.get_subject())
   cert.set_pubkey(req.get_pubkey())
   cert.sign(ekey, digest)

   certPem = crypto.dump_certificate(crypto.FILETYPE_PEM, cert)
   certText = '???'
   certFingerprint = cert.digest(digest)

   return (certPem, certText, certFingerprint)


def unpack_certificate(certificatePem):
   """
   Unpack X509 PEM-encoded certificate.

   :param certificatePem: PEM encoded X509 certificate.
   :type certificatePem: str
   :returns tuple -- (Dict of detailed information from the certificate, Certificate Text).
   """
   cert = crypto.load_certificate(crypto.FILETYPE_PEM, certificatePem)

   res = {}

   ## we include the reserialized PEM encoding (which in principle
   ## should be identical to certificatePem .. but who knows .. this
   ## is x509 crap)
   res["pem"] = crypto.dump_certificate(crypto.FILETYPE_PEM, cert)
   res["fingerprint"] = cert.digest('sha1')

   ## we convert this to dotted hex, since the version
   ## might be a unsigned long (8 bytes) which i.e. JavaScript
   ## can't consume
   serial = "0x%x" % cert.get_serial_number()
   res["serial"] = dotted(serial[2:])

   res["version"] = cert.get_version()
   res["issuer"] = extract_info_from_x509name(cert.get_issuer())
   res["subject"] = extract_info_from_x509name(cert.get_subject())

   # ASN1 GENERALIZEDTIME : YYYYMMDDhhmmssZ
   ASN1_TIMESTAMP_FORMAT = "%Y%m%d%H%M%SZ"
   not_before = datetime.datetime.strptime(cert.get_notBefore(), ASN1_TIMESTAMP_FORMAT)
   not_after = datetime.datetime.strptime(cert.get_notAfter(), ASN1_TIMESTAMP_FORMAT)

   UTC_TIMESTAMP_FORMAT = "%Y-%m-%dT%H:%M:%SZ"
   res["not-valid-before"] = not_before.strftime(UTC_TIMESTAMP_FORMAT)
   res["not-valid-after"] = not_after.strftime(UTC_TIMESTAMP_FORMAT)

   now = datetime.datetime.utcnow()
   res["expired"] = not (not_before <= now and now <= not_after)

   pubkey = cert.get_pubkey()

   res["public-key"] = {"length": pubkey.bits(),
                        "fingerprint": ZERODIGEST} # FIXME

   # FIXME
   #res["is-selfsigned"] = True if cert.verify(pubkey) == 1 else False

   text = """Version: %(version)s
Serial: %(serial)s
Fingerprint: %(fingerprint)s
Validity: %(not-valid-before)s - %(not-valid-after)s
Expired: %(expired)s
""" % res

   for k in [("Issuer", "issuer"), ("Subject", "subject")]:
      text += "\n" + k[0] + "\n"
      text += """   Common Name: %(common-name)s
   Country: %(country-name)s
   State/Province: %(state-or-province-name)s
   Locality: %(locality-name)s
   Organization: %(organization-name)s
   Organization Unit: %(organization-unit-name)s
   Email: %(email-address)s
""" % res[k[1]]

   return res, text


if __name__ == '__main__':

   ## create self-signed CA key/cert
   ##
   ca_info = {'common-name': 'Certificate Authority',
              'organization-name': 'Tavendo GmbH',
              'country-name': 'DE'}

   (ca_key, ca_keypub, ca_fingerprint) = generate_rsa_key(1024)
   (ca_cert, ca_cert_text, ca_cert_fingperint) = create_selfsigned_certificate(ca_key, ca_info, 365)

   ## create server key/CSR
   ##
   s1_info = {'common-name': 'www.tavendo.de',
              'organization-name': 'Tavendo GmbH',
              'country-name': 'DE'}

   (s1_key, s1_keypub, s1_fingerprint) = generate_rsa_key(1024)
   (s1_csr, s1_csr_text) = create_certificate_signing_request(s1_key, s1_info)

   ## create server cert
   ##
   (s1_cert, s1_cert_text, s1_cert_fingperint) = create_certificate(ca_key, ca_cert, s1_csr, 365, 1)
   print unpack_certificate(s1_cert)

########NEW FILE########
__FILENAME__ = _version
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


__version__ = "0.8.3"

########NEW FILE########
__FILENAME__ = crossbar_plugin
###############################################################################
##
##  Copyright (C) 2011-2013 Tavendo GmbH
##
##  This program is free software: you can redistribute it and/or modify
##  it under the terms of the GNU Affero General Public License, version 3,
##  as published by the Free Software Foundation.
##
##  This program is distributed in the hope that it will be useful,
##  but WITHOUT ANY WARRANTY; without even the implied warranty of
##  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
##  GNU Affero General Public License for more details.
##
##  You should have received a copy of the GNU Affero General Public License
##  along with this program. If not, see <http://www.gnu.org/licenses/>.
##
###############################################################################


from twisted.application.service import ServiceMaker

serviceMaker = ServiceMaker('crossbar',
                            'crossbar.servicefactory',
                            'Crossbar.io multi-protocol application router',
                            'crossbar')

########NEW FILE########
