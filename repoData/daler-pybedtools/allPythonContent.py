__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# pybedtools documentation build configuration file, created by
# sphinx-quickstart on Wed Dec 22 17:39:12 2010.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('../..'))

from pybedtools import __version__ as version

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.autosummary',
              'sphinx.ext.doctest', 'sphinx.ext.todo',
              'sphinx.ext.coverage','sphinx.ext.viewcode', 'numpydoc']

doctest_test_doctest_blocks = 'default'

# From http://stackoverflow.com/questions/12206334/\
# sphinx-autosummary-toctree-contains-refere\
# nce-to-nonexisting-document-warnings
numpydoc_show_class_members = False

# this is needed to get the autodoc_source.rst doctests to run
doctest_global_setup = """
from pybedtools import *
import pybedtools
"""

autosummary_generate = True

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'pybedtools'
copyright = u'2010, Ryan Dale'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = version
# The full version, including alpha/beta/rc tags.
release = version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all documents.
default_role = 'file'

# If true, '()' will be appended to :func: etc. cross-reference text.
add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'
highlight_language = 'python'
html_use_smartypants = False

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'nature'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = ['_themes']

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
#html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = ''

# Output file base name for HTML help builder.
htmlhelp_basename = 'pybedtoolsdoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'pybedtools.tex', u'pybedtools Documentation',
   u'Ryan Dale', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
latex_use_parts = True

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'pybedtools', u'pybedtools Documentation',
     [u'Ryan Dale'], 1)
]

########NEW FILE########
__FILENAME__ = bedtool
import tempfile
import shutil
import subprocess
import operator
import os
import sys
import random
import string
import pprint
from itertools import islice
import multiprocessing

from pybedtools.helpers import get_tempdir, _tags,\
    History, HistoryStep, call_bedtools, _flatten_list, \
    _check_sequence_stderr, isBAM, isBGZIP, BEDToolsError, \
    _call_randomintersect
import helpers
from cbedtools import IntervalFile, IntervalIterator
import pybedtools
import settings


_implicit_registry = {}
_other_registry = {}
_bam_registry = {}


def _wraps(prog=None, implicit=None, bam=None, other=None, uses_genome=False,
           make_tempfile_for=None, check_stderr=None, add_to_bedtool=None,
           nonbam=None, force_bam=False, genome_none_if=None, genome_if=None,
           genome_ok_if=None, does_not_return_bedtool=None):
    """
    Do-it-all wrapper, to be used as a decorator.

    *prog* is the name of the BEDTools program that will be called.  The help
    for this program will also be added to the decorated method's docstring.

    *implicit* is the BEDTools program arg that should be filled in
    automatically.

    *bam* will disable the implicit substitution if *bam* is in the kwargs.
    This is typically 'abam' or 'ibam' if the program accepts BAM input.

    *other* is the BEDTools program arg that is passed in as the second input,
    if supported.  Within the semantics of BEDTools, the typical case will be
    that if implicit='a' then other='b'; if implicit='i' then other=None.

    *uses_genome*, if True, will check for 'g' and/or 'genome' args and
    retrieve the corresponding genome files as needed.

    *make_tempfile_for* is used for the sequence methods and indicates which
    kwarg should have a tempfile made for it if it's not provided ('fo' for the
    sequence methods)

    *check_stderr*, if not None, is a function that accepts a string (which
    will be anything written to stdout when calling the wrapped program).  This
    function should return True if the string is OK, and False if it should
    truly be considered an error.  This is needed for wrapping fastaFromBed,
    which will report to stderr that it's creating an index file.

    *add_to_bedtool* is used for sequence methods.  It is a dictionary mapping
    kwargs to attributes to be created in the resulting BedTool.  Typically it
    is {'fo':'seqfn'} which will add the resulting sequence name to the
    BedTool's .seqfn attribute. If *add_to_bedtool* is not None, then the
    returned BedTool will be *self* with the added attribute.  If a key is
    "stdout" (e.g., {"stdout": attr_name}), then save the stdout of the command
    as a tempfile and store the tempfile's name in the attribute.  This is
    required for linksBed and bedToIgv.

    *nonbam* is a kwarg that even if the input file was a BAM, the output will
    *not* be BAM format.  For example, the `-bed` arg for intersectBed will
    cause the output to be in BED format, not BAM.  If not None, this can be a
    string, a list of strings, or the special string "ALL", which means that
    the wrapped program will never return BAM output.

    *force_bam*, if True, will force the output to be BAM.  This is used for
    bedToBam.

    *genome_none_if* is a list of arguments that will ignore the requirement
    for a genome.  This is needed for window_maker, where -b and -g are
    mutually exclusive.

    *genome_ok_if* is a list of arguments that, if they are in
    *genome_none_if*, are still OK to pass in.  This is needed for bedtool
    genomecov, where -g is not needed if -ibam is specified...but it's still OK
    if the user passes a genome arg.

    *genome_if* is a list of arguments that will trigger the requirement for
    a genome; otherwise no genome needs to be specified.

    *does_not_return_bedtool*, if not None, should be a function that handles
    the returned output.  Its signature should be ``func(output, kwargs)``,
    where `output` is the output from the [possibly streaming] call to BEDTools
    and `kwargs` are passed verbatim from the wrapped method call. This is used
    for jaccard and reldist methods.
    """
    not_implemented = False

    # Call the program with -h to get help, which prints to stderr.
    try:
        p = subprocess.Popen(helpers._version_2_15_plus_names(prog) + ['-h'],
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)
        help_str = p.communicate()[1]

        # underscores throw off ReStructuredText syntax of docstrings, so
        # replace 'em
        help_str = help_str.replace('_', '**')

        # indent
        help_str = help_str.split('\n')
        help_str = ['\n\n**Original BEDTools help:**::'] \
            + ['\t' + i for i in help_str]
        help_str = '\n'.join(help_str) + '\n'

    # If the program can't be found, then we'll eventually replace the method
    # with a version that does nothing but raise a NotImplementedError (plus
    # a helpful message).
    except OSError:
        help_str = '"%s" does not appear to be installed '\
            'or on the path, so this method is '\
            'disabled.  Please install a more recent '\
            'version of BEDTools and re-import to '\
            'use this method.' % prog
        not_implemented = True

    def decorator(func):
        """
        Accepts a function to be wrapped; discards the original and returns a
        new, rebuilt-from-scratch function based on the kwargs passed to
        _wraps().
        """
        # Register the implicit (as well as bam and other) args in the global
        # registry.  BedTool.handle_kwargs() will access these at runtime.  The
        # registry is keyed by program name (like intersectBed).
        _implicit_registry[prog] = implicit
        if other is not None:
            _other_registry[prog] = other
        if bam is not None:
            _bam_registry[prog] = bam

        # Here's where we replace an unable-to-be-found program's method with
        # one that only returns a NotImplementedError
        if not_implemented:
            def not_implemented_func(*args, **kwargs):
                raise NotImplementedError(help_str)
            return not_implemented_func

        _add_doc = []
        if implicit:
            _add_doc.append(
        """
        For convenience, the file or stream this BedTool points to is
        implicitly passed as the `-%s` argument to `%s`""" % (implicit, prog))

        if uses_genome:
            _add_doc.append(
        """
        There are two alternatives for supplying a genome.  Use
        `g="genome.filename"` if you have a genome's chrom sizes saved
        as a file. This is the what BEDTools expects when using it from
        the command line. Alternatively, use the `genome="assembly.name"`
        (for example, `genome="hg19"`) to use chrom sizes for that 
        assembly without having to manage a separate file.  The `genome`
        argument triggers a call `pybedtools.chromsizes`, so see that method
        for more details.
        """)

        def wrapped(self, *args, **kwargs):
            """
            A newly created function that will be returned by the _wraps()
            decorator
            """

            # Only one non-keyword argument is supported; this is then assumed
            # to be "other" (e.g., `-b` for intersectBed)
            if len(args) > 0:
                assert len(args) == 1
                kwargs[other] = args[0]

            # Add the implicit values to kwargs.  If the current BedTool is
            # BAM, it will automatically be passed to the appropriate
            # BAM-support arg (like `-abam`).  But this also allows the user to
            # explicitly specify the abam kwarg, which will override the
            # auto-substitution.
            # Note: here, `implicit` is something like "a"; `bam` is something
            # like "abam"
            if (implicit not in kwargs) \
                    and (bam not in kwargs) and (implicit is not None):
                if not self._isbam:
                    kwargs[implicit] = self.fn
                else:
                    # It is a bam file.  If this program supports BAM as the
                    # first input, then we set it here
                    if bam is not None:
                        kwargs[bam] = self.fn

                    # Otherwise, BEDTools can't currently handle it, so raise
                    # an exception.
                    else:
                        raise BEDToolsError(
                            '"%s" currently can\'t handle BAM '
                            'input, please use bam_to_bed() first.' % prog)

            # Should this function handle genome files?
            check_for_genome = uses_genome
            if uses_genome:
                if genome_none_if:
                    for i in genome_none_if:
                        if i in kwargs or i == implicit:
                            check_for_genome = False

                    # for genomecov, if -ibam then -g is optional.  So it's OK
                    # for the user to provide genome or g kwargs, even if
                    # -ibam.
                    if genome_ok_if:
                        for i in genome_ok_if:
                            if i in kwargs or i == implicit:
                                if ('g' in kwargs) or ('genome' in kwargs):
                                    check_for_genome = True
                if genome_if:
                    check_for_genome = False
                    for i in genome_if:
                        if (i in kwargs) or (i == implicit):
                            check_for_genome = True
            if check_for_genome:
                kwargs = self.check_genome(**kwargs)

            # For sequence methods, we may need to make a tempfile that will
            # hold the resulting sequence.  For example, fastaFromBed needs to
            # make a tempfile for 'fo' if no 'fo' was explicitly specified by
            # the user.
            if make_tempfile_for is not None:
                if make_tempfile_for not in kwargs:
                    kwargs[make_tempfile_for] = self._tmp()

            # At runtime, this will parse the kwargs, convert streams to
            # tempfiles if needed, and return all the goodies
            cmds, tmp, stdin = self.handle_kwargs(prog=prog, **kwargs)

            # Do the actual call
            stream = call_bedtools(cmds, tmp, stdin=stdin,
                                   check_stderr=check_stderr)

            if does_not_return_bedtool:
                return does_not_return_bedtool(stream, **kwargs)

            # Post-hoc editing of the BedTool -- for example, this is used for
            # the sequence methods to add a `seqfn` attribute to the resulting
            # BedTool.
            if add_to_bedtool is not None:
                for kw, attr in add_to_bedtool.items():
                    if kw == 'stdout':
                        value = stream
                    else:
                        value = kwargs[kw]
                    setattr(self, attr, value)
                    result = self
            else:
                result = BedTool(stream)

            # Decide whether the output is BAM format or not.
            result_is_bam = False

            # By default, if the current BedTool is BAM, then the result should
            # be, too.
            if self._isbam:
                result_is_bam = True

            # If nonbam is "ALL", then this method will never return BAM
            # output.
            if nonbam == 'ALL':
                result_is_bam = False

            # If any of the `nonbam` args are found in kwargs, then result is
            # not a BAM.  Side note: the _nonbam name mangling is necessary to
            # keep the nonbam arg passed into the original _wraps() decorator
            # in scope.
            if nonbam is not None and nonbam != 'ALL':
                if isinstance(nonbam, basestring):
                    _nonbam = [nonbam]
                else:
                    _nonbam = nonbam
                for i in _nonbam:
                    if i in kwargs:
                        result_is_bam = False
                        break

            if force_bam:
                result_is_bam = True

            result._isbam = result_is_bam
            result._cmds = cmds
            #result._kwargs = kwargs
            del kwargs
            return result

        # Now add the edited docstring (original Python doctring plus BEDTools
        # help) to the newly created method above
        if func.__doc__ is None:
            orig = ''
        else:
            orig = func.__doc__

        wrapped.__doc__ = orig + "\n".join(_add_doc) + help_str

        # Add the original method's name to a new attribute so we can access it
        # when logging history
        wrapped._name = func.__name__

        return wrapped

    return decorator


class BedTool(object):
    TEMPFILES = []

    def __init__(self, fn=None, from_string=False, remote=False):
        """
        Wrapper around Aaron Quinlan's ``BEDtools`` suite of programs
        (https://github.com/arq5x/bedtools); also contains many useful
        methods for more detailed work with BED files.

        *fn* is typically the name of a BED-like file, but can also be
        one of the following:

            * a string filename
            * another BedTool object
            * an iterable of Interval objects
            * an open file object
            * a "file contents" string (see below)

        If *from_string* is True, then you can pass a string that contains
        the contents of the BedTool you want to create.  This will treat all
        spaces as TABs and write to tempfile, treating whatever you pass as
        *fn* as the contents of the bed file.  This also strips empty lines.

        Typical usage is to point to an existing file::

            a = BedTool('a.bed')

        But you can also create one from scratch from a string::

            >>> s = '''
            ... chrX  1  100
            ... chrX 25  800
            ... '''
            >>> a = BedTool(s,from_string=True)

        Or use examples that come with pybedtools::

             >>> example_files = pybedtools.list_example_files()
             >>> assert 'a.bed' in example_files
             >>> a = pybedtools.example_bedtool('a.bed')

        """
        self.remote = remote
        self._isbam = False
        self._bam_header = ""

        if from_string:
            bed_contents = fn
            fn = self._tmp()
            fout = open(fn, 'w')
            for line in bed_contents.splitlines():
                if len(line.strip()) == 0:
                    continue
                line = '\t'.join(line.split()) + '\n'
                fout.write(line)
            fout.close()

        else:
            # our work is already done
            if isinstance(fn, BedTool):
                fn = fn.fn

            # from_string=False, so assume it's a filename
            elif isinstance(fn, basestring):
                if remote:
                    self._isbam = True
                else:
                    if not os.path.exists(fn):
                        raise ValueError('File "%s" does not exist' % fn)
                    self._isbam = isBAM(fn)

            # If tuple or list, then save as file first
            # (fixes #73)
            elif isinstance(fn, (list, tuple)):
                fn = BedTool(iter(fn)).saveas().fn

            # Otherwise assume iterator, say an open file as from
            # subprocess.PIPE
            else:
                fn = fn

        if isinstance(fn, unicode):
            fn = str(fn)

        self.fn = fn

        if self._isbam and isinstance(self.fn, basestring):
            if not self.remote:
                try:
                    self._bam_header = ''.join(BAM(self.fn, header_only=True))

                # BAM reader will raise ValueError for BGZIPed files that are
                # not BAM format (e.g., plain BED files that have been BGZIPed
                # for tabix)
                except ValueError:
                    self._isbam = False
        else:
            self._bam_header = ""

        tag = ''.join([random.choice(string.lowercase) for _ in xrange(8)])
        self._tag = tag
        _tags[tag] = self
        self._hascounts = False
        self._file_type = None
        self.history = History()

    def split(self, func, *args, **kwargs):
        """
        Split each feature using a user-defined function.

        Calls the provided function `func` with each interval.  In contrast to
        `each` (which does something similar), this method expects `func` to
        return an *iterable* of Interval objects.

        args and kwargs are passed directly to `func`.

        Returns a new BedTool.
        """
        def generator():
            for orig_interval in self:
                for interval in func(orig_interval, *args, **kwargs):
                    yield interval
        return BedTool(generator())

    def truncate_to_chrom(self, genome):
        """
        Ensure all features fall within chromosome limits.

        Some peak-callers extend peaks such that the boundaries overstep
        chromosome coordinates.  Upon uploading such a file to a genome browser
        like UCSC, this results in an error like::

            Error line 101 of custom track: chromEnd larger than chrom chr2
            size

        Use this method to clean your file, truncating any out-of-bounds
        features to fit within the chromosome coordinates of `genome`.

        `genome` can be either an assembly name ('dm3') or a dictionary where
        keys are chrom and values are (start, stop) tuples.
        """
        if isinstance(genome, dict):
            chromdict = genome
        else:
            assert isinstance(genome, basestring)
            chromdict = pybedtools.chromsizes(genome)

        tmp = self._tmp()
        fout = open(tmp, 'w')
        for chrom, coords in chromdict.items():
            start, stop = coords
            start = str(start)
            stop = str(stop)
            fout.write('\t'.join([chrom, start, stop]) + '\n')
        fout.close()
        return self.intersect(tmp)

    def tabix_intervals(self, interval_or_string):
        """
        Retrieve all intervals within cooridnates from a "tabixed" BedTool.

        Given either a string in "chrom:start-stop" format, or an interval-like
        object with chrom, start, stop attributes, return a *streaming* BedTool
        of the features in this BedTool that overlap the provided interval.
        """
        if not self._tabixed():
            raise ValueError(
                "This BedTool has not been indexed for tabix "
                "-- please use the .tabix() method")

        # NOTE: tabix expects 1-based coords, but BEDTools works with
        # zero-based.
        interval = helpers.string_to_interval(interval_or_string)
        coords = '%s:%s-%s' % (
            interval.chrom,
            interval.start + 1,  # convert to 1-based coords
            interval.stop)
        cmds = ['tabix', self.fn, coords]
        p = subprocess.Popen(cmds, stdout=subprocess.PIPE)
        return BedTool(p.stdout)

    def tabix(self, in_place=True, force=False, is_sorted=False):
        """
        Prepare a BedTool for use with Tabix.

        Returns a new BedTool that has been BGZIP compressed
        and indexed by tabix.

        Parameters
        ----------

        in_place : bool
            If True (default), then assume the file is already sorted and
            replace the existing file with the BGZIPed version.

        force : bool
            If True (default is False), then overwrite both the index and the
            BGZIP file.

        is_sorted : bool
            If True (default is False), then assume the file is already sorted
            so that BedTool.bgzip() doesn't have to do that work.

        """
        if not settings._tabix_installed:
            helpers._check_for_tabix()
        if force:
            force_arg = "-f"
        else:
            force_arg = ""

        # Return quickly if nothing to do
        if self._tabixed() and not force:
            return self

        # Make sure it's BGZIPed
        fn = self.bgzip(in_place=in_place, force=force)

        # Create the index
        cmds = [os.path.join(settings._tabix_path, 'tabix'),
                force_arg, '-p', self.file_type, fn]
        os.system(' '.join(cmds))
        return BedTool(fn)

    def _tabixed(self):
        """
        Verifies that we're working with a tabixed file: a string filename
        pointing to a BGZIPed file with a .tbi file in the same dir.
        """
        if (
            isinstance(self.fn, basestring)
            and
            isBGZIP(self.fn)
            and
            os.path.exists(self.fn + '.tbi')
        ):
            return True

    def bgzip(self, in_place=True, force=False, is_sorted=False):
        """
        Helper function for more control over "tabixed" BedTools.

        Checks to see if we already have a BGZIP file; if not then prepare one.
        Always leaves the original file alone.  You can always just make a
        BedTool out of an already sorted and BGZIPed file to avoid this step.

        `in_place` will put the BGZIPed file in the same dir (possibly after
        sorting to tempfile).

        If `is_sorted`, then assume the file is already sorted.

        `force` will overwrite without asking.
        """
        if force:
            force_arg = "-f"
        else:
            force_arg = ""

        # It may already be BGZIPed...
        if isinstance(self.fn, basestring) and not force:
            if isBGZIP(self.fn):
                return self.fn

        # If not in_place, then make a tempfile for the BGZIPed version
        if not in_place:
            # Get tempfile name, sorted or not
            if not is_sorted:
                fn = self.sort().fn
            else:
                fn = self._tmp()

            # Register for later deletion
            outfn = fn + '.gz'
            BedTool.TEMPFILES.append(outfn)

            # Creates tempfile.gz
            cmds = ['bgzip', force_arg, fn]
            os.system(' '.join(cmds))
            return outfn

        # Otherwise, make sure the BGZIPed version has a similar name to the
        # current BedTool's file
        if in_place:
            if not is_sorted:
                fn = self.sort().saveas().fn
            else:
                fn = self.fn
            outfn = self.fn + '.gz'
            cmds = ['bgzip', '-c', force_arg, fn, '>', outfn]
            os.system(' '.join(cmds))
            return outfn

    def delete_temporary_history(self, ask=True, raw_input_func=None):
        """
        Use at your own risk!  This method will delete temp files. You will be
        prompted for deletion of files unless you specify *ask=False*.

        Deletes all temporary files created during the history of this BedTool
        up to but not including the file this current BedTool points to.

        Any filenames that are in the history and have the following pattern
        will be deleted::

            <TEMP_DIR>/pybedtools.*.tmp

        (where <TEMP_DIR> is the result from get_tempdir() and is by default
        "/tmp")

        Any files that don't have this format will be left alone.

        (*raw_input_func* is used for testing)
        """
        flattened_history = _flatten_list(self.history)
        to_delete = []
        tempdir = get_tempdir()
        for i in flattened_history:
            fn = i.fn
            if fn.startswith(os.path.join(os.path.abspath(tempdir),
                                          'pybedtools')):
                if fn.endswith('.tmp'):
                    to_delete.append(fn)

        if raw_input_func is None:
            raw_input_func = raw_input

        str_fns = '\n\t'.join(to_delete)
        if ask:
            answer = raw_input_func(
                'Delete these files?\n\t%s\n(y/N) ' % str_fns)

            if not answer.lower()[0] == 'y':
                print('OK, not deleting.')
                return
        for fn in to_delete:
            os.unlink(fn)
        return

    def _log_to_history(method):
        """
        Decorator to add a method and its kwargs to the history.

        Assumes that you only add this decorator to bedtool instances that
        return other bedtool instances
        """
        def decorated(self, *args, **kwargs):

            # this calls the actual method in the first place; *result* is
            # whatever you get back
            result = method(self, *args, **kwargs)

            # add appropriate tags
            parent_tag = self._tag
            result_tag = result._tag

            # log the sucka
            history_step = HistoryStep(method, args, kwargs, self, parent_tag,
                                       result_tag)

            # only add the current history to the new bedtool if there's
            # something to add
            if len(self.history) > 0:
                result.history.append(self.history)

            # but either way, add this history step to the result.
            result.history.append(history_step)

            return result

        decorated.__doc__ = method.__doc__
        return decorated

    def filter(self, func, *args, **kwargs):
        """
        Filter features by user-defined function.

        Takes a function *func* that is called for each feature in the
        `BedTool` object and returns only those for which the function returns
        True.

        *args and **kwargs are passed directly to *func*.

        Returns a streaming BedTool; if you want the filename then use the
        .saveas() method.

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> subset = a.filter(lambda b: b.chrom == 'chr1' and b.start < 150)
        >>> len(a), len(subset)
        (4, 2)

        so it has extracted 2 records from the original 4.

        """
        return BedTool((f for f in self if func(f, *args, **kwargs)))

    def field_count(self, n=10):
        """
        Number of fields in each line of this BedTool (checks `n` lines)

        Return the number of fields in the features this file contains.  Checks
        the first *n* features.

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> a.field_count()
        6
        """
        i = 0
        fields = set([])
        for feat in self:
            if i > n:
                break
            i += 1
            # TODO: make this more efficient.
            fields.update([len(feat.fields)])
        assert len(fields) == 1, fields
        return list(fields)[0]

    def each(self, func, *args, **kwargs):
        """
        Modify each feature with a user-defined function.

        Applies user-defined function *func* to each feature.  *func* must
        accept an Interval as its first argument; *args and **kwargs will be
        passed to *func*.

        *func* must return an Interval object OR a value that evaluates to
        False, in which case the original feature will be removed from the
        output.  This way, an additional "filter" call is not necessary.

        >>> def truncate_feature(feature, limit=0):
        ...     feature.score = str(len(feature))
        ...     if len(feature) > limit:
        ...         feature.stop = feature.start + limit
        ...         feature.name = feature.name + '.short'
        ...     return feature

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> b = a.each(truncate_feature, limit=100)
        >>> print b #doctest: +NORMALIZE_WHITESPACE
        chr1	1	100	feature1	99	+
        chr1	100	200	feature2	100	+
        chr1	150	250	feature3.short	350	-
        chr1	900	950	feature4	50	+
        <BLANKLINE>

        """
        def _generator():
            for f in self:
                result = func(f, *args, **kwargs)
                if result:
                    yield result

        return BedTool(_generator())

    def introns(self, gene="gene", exon="exon"):
        """
        Create intron features (requires specific input format).

        Given a BED12 or a GFF with exons, create a new `BedTool` with just
        introns.  The output is a bed6 file with the score column (5) being one
        of 'intron'/'utr5'/'utr3'
        """
        # iterate over all the features in the gene.
        s = self.sort()
        if self.file_type == "gff":
            exon_iter = BedTool((f for f in s if f[2] == gene)).saveas()
            gene_iter = BedTool((f for f in s if f[2] == exon)).saveas()

        elif self.file_type == "bed":
            if s.field_count() == 12:
                exon_iter = s.bed6().saveas()
                gene_iter = s.saveas()
            else:
                # TODO: bed6. groupby on name and find smallest start,
                # largest stop.
                exon_iter = s
                gene_iter = None
                raise NotImplementedError('.introns() only supported for bed12'
                                          'and GFF')

        else:
            raise NotImplementedError(
                '.introns() only supported for BED and GFF')

        fh = open(BedTool._tmp(), "w")

        # group on the name.
        exon_intervals = exon_iter.intervals
        for g in gene_iter:
            # search finds all, but we just want the ones that completely
            # overlap this gene.
            exons = [
                e for e in exon_intervals.search(g, same_strand=True)
                if e.start >= g.start and e.end <= g.end]

            for i, exon in enumerate(exons):
                # 5' utr between gene start and first intron
                if i == 0 and exon.start > g.start:
                    utr = {"+": "utr5", "-": "utr3"}[g.strand]
                    print >>fh, "%s\t%i\t%i\t%s\t%s\t%s" \
                        % (g.chrom, g.start, exon.start, g.name, utr, g.strand)
                elif i == len(exons) - 1 and exon.end < g.end:
                    utr = {"+": "utr3", "-": "utr5"}[g.strand]
                    print >>fh, "%s\t%i\t%i\t%s\t%s\t%s" \
                        % (g.chrom, exon.end, g.end, g.name, utr, g.strand)
                elif i != len(exons) - 1:
                    istart = exon.end
                    iend = exons[i + 1].start
                    print >>fh, "%s\t%i\t%i\t%s\tintron\t%s" \
                        % (g.chrom, istart, iend, g.name, g.strand)
        fh.close()
        return BedTool(fh.name)

    def features(self):
        """
        Returns an iterable of features
        """
        return iter(self)

    @property
    def file_type(self):
        """
        Return the type of the current file.  One of ('bed','vcf','gff', 'bam',
        'sam', 'empty').

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> a.file_type
        'bed'
        """
        if self._file_type is None:
            if not isinstance(self.fn, basestring):
                raise ValueError('Checking file_type not supported for '
                                 'non-file BedTools. Use .saveas() to '
                                 'save as a temp file first.')
            if self._isbam:
                self._file_type = 'bam'
            else:
                try:
                    self._file_type = IntervalFile(self.fn).file_type
                except StopIteration:
                    self._file_type = 'empty'
                except ValueError:
                    self._file_type = IntervalIterator(open(self.fn))\
                        .next().file_type
        return self._file_type

    def cut(self, indexes, stream=False):
        """
        Analagous to unix `cut`.

        Similar to unix `cut` except indexes are 0-based, must be a list
        and the columns are returned in the order requested.

        This method returns a BedTool of results, which means that the indexes
        returned must be valid GFF/GTF/BED/SAM features.

        If you would like arbitrary columns -- say, just chrom and featuretype
        of a GFF, which would not comprise a valid feature -- then instead of
        this method, simply use indexes on each feature, e.g,

        >>> gff = pybedtools.example_bedtool('d.gff')
        >>> results = [(f[0], f[2]) for f in gff]

        In addition, `indexes` can contain keys of the GFF/GTF attributes, in
        which case the values are returned. e.g. 'gene_name' will return the
        corresponding name from a GTF, or 'start' will return the start
        attribute of a BED Interval.
        """
        if stream:
            return BedTool(([f[attr] for attr in indexes] for f in self))
        else:
            fh = open(self._tmp(), "w")
            for f in self:
                print >>fh, "\t".join(map(str, [f[attr] for attr in indexes]))
            fh.close()
            return BedTool(fh.name)

    @classmethod
    def _tmp(self):
        '''
        Makes a tempfile and registers it in the BedTool.TEMPFILES class
        variable.  Adds a "pybedtools." prefix and ".tmp" extension for easy
        deletion if you forget to call pybedtools.cleanup().
        '''
        tmpfn = tempfile.NamedTemporaryFile(prefix=settings.tempfile_prefix,
                                            suffix=settings.tempfile_suffix,
                                            delete=False)
        tmpfn = tmpfn.name
        BedTool.TEMPFILES.append(tmpfn)
        return tmpfn

    def __iter__(self):
        """
        Dispatches the right iterator depending on how this BedTool was
        created
        """
        # Plain ol' filename
        if isinstance(self.fn, basestring):
            if self._isbam:
                # Note: BAM class takes filename or stream, so self.fn is OK
                # here
                return IntervalIterator(BAM(self.fn))

            # TODO: Sort of a hack, cause we can't use IntervalFile as a SAM
            # iterator [yet]
            elif self.file_type == 'sam':
                return IntervalIterator(open(self.fn))

            # Easy case: BED/GFF/VCF, as a file
            else:
                return IntervalFile(self.fn)

        # Open file, like subprocess.PIPE.
        if isinstance(self.fn, file):
            if self._isbam:
                return IntervalIterator(BAM(self.fn))
            else:
                # Note: even if this is a SAM, the filetype handling eventually
                # gets passed to create_interval_from_fields.
                return IntervalIterator(self.fn)

        if isinstance(self.fn, (IntervalIterator, IntervalFile)):
            return self.fn

        return IntervalIterator(self.fn)

    @property
    def intervals(self):
        return iter(self)

    def __repr__(self):
        if isinstance(self.fn, file):
            return '<BedTool(stream)>'
        if isinstance(self.fn, basestring):
            if os.path.exists(self.fn) or self.remote:
                return '<BedTool(%s)>' % self.fn
            else:
                return '<BedTool(MISSING FILE: %s)>' % self.fn
        else:
            return repr(self.fn)

    def __str__(self):
        """
        Different methods to return the string, depending on how the BedTool
        was created.  If self.fn is anything but a basestring, the iterable
        will be consumed.
        """
        if isinstance(self.fn, basestring) and not self._isbam:
            return open(self.fn).read()

        return ''.join(str(i) for i in iter(self))

    def __len__(self):
        return self.count()

    def __eq__(self, other):
        if isinstance(other, basestring):
            other_str = other
        elif isinstance(other, BedTool):
            if (not isinstance(self.fn, basestring) or
                not isinstance(
                    other.fn, basestring)):
                raise NotImplementedError('Testing equality only supported for'
                                          ' BedTools that point to files')
        if str(self) == str(other):
            return True
        return False

    def __ne__(self, other):
        return not self.__eq__(other)

    def __getitem__(self, key):
        if isinstance(key, slice):
            return islice(self, key.start, key.stop, key.step)
        elif isinstance(key, int):
            return list(islice(self, key, key + 1))[0]
        else:
            raise ValueError('Only slices or integers allowed for indexing '
                             'into a BedTool')

    def __add__(self, other):
        try:
            result = self.intersect(other, u=True)
        except BEDToolsError:
            # BEDTools versions <2.20 would raise BEDToolsError
            if (self.file_type == 'empty') or (other.file_type == 'empty'):
                result = pybedtools.BedTool("", from_string=True)
        return result


    def __sub__(self, other):
        try:
            result = self.intersect(other, v=True)
        except BEDToolsError:
            # BEDTools versions <2.20 would raise BEDToolsError

            if (self.file_type == 'empty') and (other.file_type == 'empty'):
                result = pybedtools.BedTool("", from_string=True)
            elif other.file_type == 'empty':
                result = self.saveas()
            elif self.file_type == 'empty':
                result = pybedtools.BedTool("", from_string=True)
        return result

    def head(self, n=10, as_string=False):
        """
        Prints the first *n* lines or returns them if as_string is True

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> a.head(2) #doctest: +NORMALIZE_WHITESPACE
        chr1	1	100	feature1	0	+
        chr1	100	200	feature2	0	+
        <BLANKLINE>

        """
        if not isinstance(self.fn, basestring):
            raise NotImplementedError(
                'head() not supported for non file-based BedTools')
        if as_string:
            return ''.join(str(line) for line in self[:n])
        else:
            for i, line in enumerate(iter(self)):
                if i == (n):
                    break
                print line,

    def set_chromsizes(self, chromsizes):
        """
        Prepare BedTool for operations that require chromosome coords.

        Set the chromsizes for this genome. If *chromsizes* is a string, it
        will be considered a genome assembly name.  If that assembly name is
        not available in pybedtools.genome_registry, then it will be searched
        for on the UCSC Genome Browser.

        Example usage:

            >>> hg19 = pybedtools.chromsizes('hg19')
            >>> a = pybedtools.example_bedtool('a.bed')
            >>> a = a.set_chromsizes(hg19)
            >>> print a.chromsizes['chr1']
            (0, 249250621)

        """
        if isinstance(chromsizes, basestring):
            self.chromsizes = pybedtools.chromsizes(chromsizes)
        elif isinstance(chromsizes, dict):
            self.chromsizes = chromsizes
        else:
            raise ValueError("Need to specify chromsizes either as a string"
                             " (assembly name) or a dictionary")
        return self

    def _collapse(self, iterable, fn=None, trackline=None):
        """
        Collapses an iterable into file *fn* (or a new tempfile if *fn* is
        None).

        Returns the newly created filename.
        """
        if fn is None:
            fn = self._tmp()

        fout = open(fn, 'w')

        # special case: if BAM-format BedTool is provided, no trackline should
        # be supplied, and don't iterate -- copy the file wholesale
        if isinstance(iterable, BedTool) and iterable._isbam:
            if trackline:
                raise ValueError("trackline provided, but input is a BAM "
                                 "file, which takes no track line")
            fout.write(open(self.fn).read())
            fout.close()
            return fn

        if trackline:
            fout.write(trackline.strip() + '\n')

        for i in iterable:
            fout.write(str(i))
        fout.close()
        return fn

    def handle_kwargs(self, prog, **kwargs):
        """
        Handle most cases of BEDTool program calls, but leave the specifics
        up to individual methods.

        *prog* is a BEDTools program name, e.g., 'intersectBed'.

        *kwargs* are passed directly from the calling method (like
        self.intersect).

        This method figures out, given how this BedTool was constructed, what
        to send to BEDTools programs -- for example, an open file to stdin with
        the `-` argument, or a filename with the `-a` argument.
        """
        pybedtools.logger.debug(
            'BedTool.handle_kwargs() got these kwargs:\n%s',
            pprint.pformat(kwargs))

        # If you pass in a list, how should it be converted to a BedTools arg?
        default_list_delimiter = ' '
        list_delimiters = {
            'annotateBed': ' ',
            'getOverlap': ',',
            'groupBy': ',',
            'multiIntersectBed': ' ',
            'mergeBed': ',',
        }
        stdin = None

        # -----------------------------------------------------------------
        # Decide how to send instream1 to BEDTools.  If there's no implicit
        # instream1 arg, then do nothing.
        #
        try:
            # e.g., 'a' for intersectBed
            if self._isbam:
                inarg1 = _bam_registry[prog]
            else:
                inarg1 = _implicit_registry[prog]

            # e.g., self.fn or 'a.bed' or an iterator...
            instream1 = kwargs[inarg1]

            # If it's a BedTool, then get underlying stream
            if isinstance(instream1, BedTool):
                instream1 = instream1.fn

            # Filename? No pipe, just provide the file
            if isinstance(instream1, basestring):
                kwargs[inarg1] = instream1
                stdin = None

            # Open file? Pipe it
            elif isinstance(instream1, file):
                kwargs[inarg1] = 'stdin'
                stdin = instream1

            # A generator or iterator: pipe it as a generator of lines
            else:
                kwargs[inarg1] = 'stdin'
                stdin = (str(i) for i in instream1)
        except KeyError:
            pass

        # -----------------------------------------------------------------
        # Decide how to send instream2 to BEDTools.
        try:
            # e.g., 'b' for intersectBed
            inarg2 = _other_registry[prog]

            # e.g., another BedTool
            instream2 = kwargs[inarg2]

            # Get stream if BedTool
            if isinstance(instream2, BedTool):
                instream2 = instream2.fn

            # Filename
            if isinstance(instream2, basestring):
                kwargs[inarg2] = instream2

            # Otherwise we need to collapse it in order to send to BEDTools
            # programs
            else:
                kwargs[inarg2] = self._collapse(instream2)

        except KeyError:
            pass

        # If stream not specified, then a tempfile will be created
        if kwargs.pop('stream', None):
                tmp = None
        else:
            output = kwargs.pop('output', None)
            if output:
                tmp = output
            else:
                tmp = self._tmp()

        additional_args = kwargs.pop('additional_args', None)

        # Parse the kwargs into BEDTools-ready args
        cmds = [prog]
        for key, value in kwargs.items():
            if isinstance(value, bool):
                if value:
                    cmds.append('-' + key)
                else:
                    continue
            elif isinstance(value, list) or isinstance(value, tuple):
                value = map(str, value)
                try:
                    delim = list_delimiters[prog]
                except KeyError:
                    delim = default_list_delimiter

                if delim == ' ':
                    cmds.append('-' + key)
                    cmds.extend(value)

                # make comma-separated list if that's what's needed
                else:
                    cmds.append('-' + key)
                    cmds.append(delim.join(value))

            else:
                cmds.append('-' + key)
                cmds.append(str(value))

        if additional_args:
            cmds.append(additional_args)

        return cmds, tmp, stdin

    def check_genome(self, **kwargs):
        """
        Handles the different ways of specifying a genome in kwargs:

        g='genome.file' specifies a file directly
        genome='dm3' gets the file from genome registry
        self.chromsizes could be a dict.\
        """

        # If both g and genome are missing, assume self.chromsizes
        if ('g' not in kwargs) and ('genome' not in kwargs):
            if hasattr(self, 'chromsizes'):
                kwargs['g'] = self.chromsizes
            else:
                raise ValueError('No genome specified. Use the "g" or '
                                 '"genome" kwargs, or use the '
                                 '.set_chromsizes() method')

        # If both specified, rather than make an implicit decision, raise an
        # exception
        if 'g' in kwargs and 'genome' in kwargs:
            raise ValueError('Cannot specify both "g" and "genome"')

        # Something like genome='dm3' was specified
        if 'g' not in kwargs and 'genome' in kwargs:
            if isinstance(kwargs['genome'], dict):
                genome_dict = kwargs['genome']
            else:
                genome_dict = pybedtools.chromsizes(kwargs['genome'])
            genome_file = pybedtools.chromsizes_to_file(genome_dict)
            kwargs['g'] = genome_file
            del kwargs['genome']

        # By the time we get here, 'g' is specified.

        # If a dict was provided, convert to tempfile here
        if isinstance(kwargs['g'], dict):
            kwargs['g'] = pybedtools.chromsizes_to_file(kwargs['g'])

        if not os.path.exists(kwargs['g']):
            raise ValueError('Genome file "%s" does not exist')

        return kwargs

    @_log_to_history
    def remove_invalid(self):
        """
        Remove invalid features that may break BEDTools programs.

        >>> a = pybedtools.BedTool("chr1 10 100\\nchr1 10 1",
        ... from_string=True)
        >>> print a.remove_invalid() #doctest: +NORMALIZE_WHITESPACE
        chr1	10	100
        <BLANKLINE>

        """
        tmp = self._tmp()
        fout = open(tmp, 'w')

        # If it's a file-based BedTool -- which is likely, if we're trying to
        # remove invalid features -- then we need to parse it line by line.
        if isinstance(self.fn, basestring):
            i = IntervalIterator(open(self.fn))
        else:
            i = IntervalIterator(self.fn)

        def _generator():
            while True:
                try:
                    feature = i.next()
                    if feature.start <= feature.stop:
                        yield feature
                    else:
                        continue
                except pybedtools.MalformedBedLineError:
                    continue
                except OverflowError:
                    # This can happen if coords are negative
                    continue
                except IndexError:
                    continue
                except StopIteration:
                    break
        return BedTool(_generator())

    def all_hits(self, interval, same_strand=False, overlap=0.0):
        """
        Return all intervals that overlap `interval`.

        Calls the `all_hits` method of an IntervalFile to return all intervals
        in this current BedTool that overlap `interval`.

        Require that overlaps have the same strand with same_strand=True.

        Notes:
                If this current BedTool is generator-based, it will be
                converted into a file first.

                If this current BedTool refers to a BAM file, it will be
                converted to a BED file first using default arguments.  If you
                don't want this to happen, please convert to BED first before
                using this method.
        """
        fn = self.fn
        if not isinstance(fn, basestring):
            fn = self.saveas().fn
        if self._isbam:
            fn = self.bam_to_bed().fn
        interval_file = pybedtools.IntervalFile(fn)
        return interval_file.all_hits(interval, same_strand, overlap)

    def any_hits(self, interval, same_strand=False, overlap=0.0):
        """
        Return whether or not any intervals overlap `interval`.

        Calls the `any_hits` method of an IntervalFile.  If there were any hits
        within `interval` in this BedTool, then return 1; otherwise 0.

        Require that overlaps have the same strand with same_strand=True.

        Notes:
                If this current BedTool is generator-based, it will be
                converted into a file first.

                If this current BedTool refers to a BAM file, it will be
                converted to a BED file first using default arguments.  If you
                don't want this to happen, please convert to BED first before
                using this method.
        """
        fn = self.fn
        if not isinstance(fn, basestring):
            fn = self.saveas().fn
        if self._isbam:
            fn = self.bam_to_bed().fn
        interval_file = pybedtools.IntervalFile(fn)
        return interval_file.any_hits(interval, same_strand, overlap)

    def count_hits(self, interval, same_strand=False, overlap=0.0):
        """
        Return the number of intervals that overlap `interval`.

        Calls the `count_hits` method of an IntervalFile.  Returns the number
        of valid hits in this BedTool that overlap `interval`.

        Require that overlaps have the same strand with same_strand=True.

        Notes:
                If this current BedTool is generator-based, it will be
                converted into a file first.

                If this current BedTool refers to a BAM file, it will be
                converted to a BED file first using default arguments.  If you
                don't want this to happen, please convert to BED first before
                using this method.
        """
        fn = self.fn
        if not isinstance(fn, basestring):
            fn = self.saveas().fn
        if self._isbam:
            fn = self.bam_to_bed().fn
        interval_file = pybedtools.IntervalFile(fn)
        return interval_file.count_hits(interval, same_strand, overlap)

    @_log_to_history
    @_wraps(prog='bed12ToBed6', implicit='i', bam=None, other=None)
    def bed6(self, **kwargs):
        """
        Wraps `bed12ToBed6` (v2.15+: `bedtools bed12tobed6`).
        """
        pass

    @_log_to_history
    @_wraps(prog='bamToBed', implicit='i', other=None, nonbam='ALL', bam='i')
    def bam_to_bed(self, **kwargs):
        """
        Wraps `bamToBed` (v2.15+: `bedtools bamtobed`).
        """

    @_wraps(prog='bedToBam', implicit='i', uses_genome=True, force_bam=True)
    def _bed_to_bam(self):
        """
        Wraps bedToBam and is called internally for BED/GFF/VCF files by
        self.to_bam (which needs to do something different for SAM files...)
        """

    @_log_to_history
    def to_bam(self, **kwargs):
        """
        Wraps `bedToBam` (v2.15+: `bedtools bedtobam`)

        If self.fn is in BED/VCF/GFF format, call BEDTools' bedToBam.  If
        self.fn is in SAM format, then create a header out of the genome file
        and then convert using `samtools`.
        """
        if self.file_type == 'bam':
            return self
        if self.file_type in ('bed', 'gff', 'vcf'):
            return self._bed_to_bam(**kwargs)
        if self.file_type == 'sam':

            if not settings._samtools_installed:
                helpers._check_for_samtools()

            # construct a genome out of whatever kwargs were passed in
            kwargs = self.check_genome(**kwargs)

            cmds = [os.path.join(settings._samtools_path, 'samtools'),
                    'view',
                    '-S',
                    '-b',
                    '-t', kwargs['g'],
                    '-']
            tmp = self._tmp()
            p = subprocess.Popen(cmds,
                                 stdout=open(tmp, 'w'),
                                 stderr=subprocess.PIPE,
                                 stdin=subprocess.PIPE,
                                 bufsize=1)
            for line in self:
                p.stdin.write(str(line) + '\n')
            stdout, stderr = p.communicate()
            new_bedtool = BedTool(tmp)
            new_bedtool._isbam = True
            return new_bedtool

    @_log_to_history
    @_wraps(prog='intersectBed', implicit='a', other='b', bam='abam',
            nonbam='bed')
    def intersect(self):
        """
        Wraps `intersectBed` (v2.15+: `bedtools intersect`).
        """

    @_log_to_history
    @_wraps(prog='fastaFromBed', implicit='bed', bam=None, other='fi',
            make_tempfile_for='fo', check_stderr=_check_sequence_stderr,
            add_to_bedtool={'fo': 'seqfn'})
    def sequence(self):
        '''
        Wraps `fastaFromBed` (v2.15+: `bedtools getfasta`).

        *fi* is passed in by the user; *bed* is automatically passed in as the
        bedfile of this object; *fo* by default is a temp file.  Use
        save_seqs() to save as a file.

        The end result is that this BedTool will have an attribute, self.seqfn,
        that points to the new fasta file.

        Example usage:

        >>> a = pybedtools.BedTool("""
        ... chr1 1 10
        ... chr1 50 55""", from_string=True)
        >>> fasta = pybedtools.example_filename('test.fa')
        >>> a = a.sequence(fi=fasta)
        >>> print open(a.seqfn).read()
        >chr1:1-10
        GATGAGTCT
        >chr1:50-55
        CCATC
        <BLANKLINE>

        '''

    @staticmethod
    def seq(loc, fasta):
        """
        Return just the sequence from a region string or a single location
        >>> fn = pybedtools.example_filename('test.fa')
        >>> BedTool.seq('chr1:2-10', fn)
        'GATGAGTCT'
        >>> BedTool.seq(('chr1', 1, 10), fn)
        'GATGAGTCT'

        """
        if isinstance(loc, basestring):
            chrom, start_end = loc.split(":")
            start, end = map(int, start_end.split("-"))
            start -= 1
        else:
            chrom, start, end = loc[0], loc[1], loc[2]

        loc = BedTool("%s\t%i\t%i" % (chrom, start, end), from_string=True)
        lseq = loc.sequence(fi=fasta)
        return "".join([l.rstrip() for l in open(lseq.seqfn) if l[0] != ">"])

    @_log_to_history
    @_wraps(prog='nucBed', implicit='bed', other='fi')
    def nucleotide_content(self):
        """
        Wraps `nucBed` (v2.15+: `bedtools nuc`).

        Profiles nucleotide content.  The returned BED file contains extra
        information about the nucleotide content
        """

    @_log_to_history
    @_wraps(prog='multiBamCov', implicit='bed')
    def multi_bam_coverage(self):
        """
        Wraps `multiBamCov` (v2.15+: `bedtools multicov`).

        Pass a list of sorted and indexed BAM files as `bams`
        """

    @_log_to_history
    @_wraps(prog='subtractBed', implicit='a', other='b', bam=None)
    def subtract(self):
        """
        Wraps `subtractBed` (v2.15+: `bedtools subtract`).

        Subtracts from another BED file and returns a new BedTool object.

        Example usage:

            >>> a = pybedtools.example_bedtool('a.bed')
            >>> b = pybedtools.example_bedtool('b.bed')

            Do a "stranded" subtraction:

            >>> c = a.subtract(b, s=True)

            Require 50% of features in `a` to overlap:

            >>> c = a.subtract(b, f=0.5)
        """
        kwargs['b'] = b

        if 'a' not in kwargs:
            kwargs['a'] = self.fn

        cmds, tmp, stdin = self.handle_kwargs(prog='subtractBed', **kwargs)
        stream = call_bedtools(cmds, tmp, stdin=stdin)
        return BedTool(stream)

    @_log_to_history
    @_wraps(prog='slopBed', implicit='i', other=None, bam=None,
            uses_genome=True)
    def slop(self):
        """
        Wraps `slopBed` (v2.15+: `bedtools slop`).

        If *g* is a dictionary (for example, return values from
        pybedtools.chromsizes() ) it will be converted to a temp file for use
        with slopBed.  If it is a string, then it is assumed to be a filename.

        Alternatively, use *genome* to indicate a pybedtools-created genome.
        Example usage:

            >>> a = pybedtools.example_bedtool('a.bed')

            Increase the size of features by 100 bp in either direction.  Note
            that you need to specify either a dictionary of chromsizes or a
            filename containing chromsizes for the genome that your bed file
            corresponds to:

            >>> c = a.slop(g=pybedtools.chromsizes('hg19'), b=100)

            Grow features by 10 bp upstream and 500 bp downstream, using a
            genome file you already have constructed called 'hg19.genome'

            First, create the file:

            >>> fout = open('hg19.genome','w')
            >>> chromdict = pybedtools.get_chromsizes_from_ucsc('hg19')
            >>> for chrom, size in chromdict.items():
            ...     fout.write("%s\\t%s\\n" % (chrom, size[1]))
            >>> fout.close()

            Then use it:

            >>> c = a.slop(g='hg19.genome', l=10, r=500, s=True)

            Clean up afterwards:

            >>> os.unlink('hg19.genome')
        """

    @_log_to_history
    @_wraps(prog='mergeBed', implicit='i', other=None, bam=None)
    def merge(self):
        """
        Wraps `mergeBed` (v2.15+: `bedtools merge`).

        Merge overlapping features together. Returns a new BedTool object.

        Example usage:

            >>> a = pybedtools.example_bedtool('a.bed')

            Merge:

            >>> c = a.merge()

            Allow merging of features 500 bp apart:

            >>> c = a.merge(d=500)

        """

    @_log_to_history
    @_wraps(prog='closestBed', implicit='a', other='b', bam=None)
    def closest(self):
        """
        Wraps `closestBed` (v2.15+: `bedtools closest`).

        Return a new BedTool object containing closest features in *b*.  Note
        that the resulting file is no longer a valid BED format; use the
        special "_closest" methods to work with the resulting file.

        Example usage::

            a = BedTool('in.bed')

            # get the closest feature in 'other.bed' on the same strand
            b = a.closest('other.bed', s=True)

        """

    @_log_to_history
    @_wraps(prog='windowBed', implicit='a', other='b', bam='abam',
            nonbam='bed')
    def window(self):
        """
        Wraps `windowBed` (v2.15+: `bedtools window`).

        Example usage::

            >>> a = pybedtools.example_bedtool('a.bed')
            >>> b = pybedtools.example_bedtool('b.bed')
            >>> print a.window(b, w=1000) #doctest: +NORMALIZE_WHITESPACE
            chr1	1	100	feature1	0	+	chr1	155	200	feature5	0	-
            chr1	1	100	feature1	0	+	chr1	800	901	feature6	0	+
            chr1	100	200	feature2	0	+	chr1	155	200	feature5	0	-
            chr1	100	200	feature2	0	+	chr1	800	901	feature6	0	+
            chr1	150	500	feature3	0	-	chr1	155	200	feature5	0	-
            chr1	150	500	feature3	0	-	chr1	800	901	feature6	0	+
            chr1	900	950	feature4	0	+	chr1	155	200	feature5	0	-
            chr1	900	950	feature4	0	+	chr1	800	901	feature6	0	+
            <BLANKLINE>
        """

    @_log_to_history
    @_wraps(prog='shuffleBed', implicit='i', other=None, bam=None,
            uses_genome=True)
    def shuffle(self):
        """
        Wraps `shuffleBed` (v2.15+: `bedtools shuffle`).

        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> seed = 1 # so this test always returns the same results
        >>> b = a.shuffle(genome='hg19', chrom=True, seed=seed)
        >>> print b #doctest: +NORMALIZE_WHITESPACE
        chr1	59535036	59535135	feature1	0	+
        chr1	99179023	99179123	feature2	0	+
        chr1	186189051	186189401	feature3	0	-
        chr1	219133189	219133239	feature4	0	+
        <BLANKLINE>
        """

    @_log_to_history
    @_wraps(prog='sortBed', implicit='i')
    def sort(self):
        """
        Wraps `sortBed` (v2.15+: `bedtools sort`).

        Note that chromosomes are sorted lexograpically, so chr12 will come
        before chr9.

        Example usage:

        >>> a = pybedtools.BedTool('''
        ... chr9 300 400
        ... chr1 100 200
        ... chr1 1 50
        ... chr12 1 100
        ... chr9 500 600
        ... ''', from_string=True)
        >>> print a.sort() #doctest: +NORMALIZE_WHITESPACE
        chr1	1	50
        chr1	100	200
        chr12	1	100
        chr9	300	400
        chr9	500	600
        <BLANKLINE>
        """

    @_log_to_history
    @_wraps(prog='annotateBed', implicit='i')
    def annotate(self):
        """
        Wraps `annotateBed` (v2.15+: `bedtools annotate`).

        Annotate this BedTool with a list of other files.
        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> b_fn = pybedtools.example_filename('b.bed')
        >>> print a.annotate(files=b_fn) #doctest: +NORMALIZE_WHITESPACE
        chr1	1	100	feature1	0	+	0.000000
        chr1	100	200	feature2	0	+	0.450000
        chr1	150	500	feature3	0	-	0.128571
        chr1	900	950	feature4	0	+	0.020000
        <BLANKLINE>
        """

    @_log_to_history
    @_wraps(prog='flankBed', implicit='i', uses_genome=True)
    def flank(self):
        """
        Wraps `flankBed` (v2.15+: `bedtools flank`).

        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> print a.flank(genome='hg19', b=100) #doctest: +NORMALIZE_WHITESPACE
        chr1	0	1	feature1	0	+
        chr1	100	200	feature1	0	+
        chr1	0	100	feature2	0	+
        chr1	200	300	feature2	0	+
        chr1	50	150	feature3	0	-
        chr1	500	600	feature3	0	-
        chr1	800	900	feature4	0	+
        chr1	950	1050	feature4	0	+
        <BLANKLINE>

        """
        kwargs = self.check_genome(**kwargs)

        if 'i' not in kwargs:
            kwargs['i'] = self.fn

        cmds, tmp, stdin = self.handle_kwargs(prog='flankBed', **kwargs)
        stream = call_bedtools(cmds, tmp, stdin=stdin)
        return BedTool(stream)

    @_log_to_history
    @_wraps(prog='genomeCoverageBed', implicit='i', bam='ibam',
            genome_none_if=['ibam'], genome_ok_if=['ibam'], uses_genome=True,
            nonbam='ALL')
    def genome_coverage(self):
        """
        Wraps `genomeCoverageBed` (v2.15+: `bedtools genomecov`).

        Example usage:

        BAM file input does not require a genome:

        >>> a = pybedtools.example_bedtool('x.bam')
        >>> b = a.genome_coverage(bg=True)
        >>> b.head(3) #doctest: +NORMALIZE_WHITESPACE
        chr2L	9329	9365	1
        chr2L	10212	10248	1
        chr2L	10255	10291	1

        Other input does require a genome:

        >>> a = pybedtools.example_bedtool('x.bed')
        >>> b = a.genome_coverage(bg=True, genome='dm3')
        >>> b.head(3) #doctest: +NORMALIZE_WHITESPACE
        chr2L	9329	9365	1
        chr2L	10212	10248	1
        chr2L	10255	10291	1



        """

    @_log_to_history
    @_wraps(prog='coverageBed', implicit='a', other='b', bam='abam',
            nonbam='ALL')
    def coverage(self):
        """
        Wraps `coverageBed` (v2.15+: `bedtools coverage`).

        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> b = pybedtools.example_bedtool('b.bed')
        >>> c = a.coverage(b)
        >>> c.head(3) #doctest: +NORMALIZE_WHITESPACE
        chr1	155	200	feature5	0	-	2	45	45	1.0000000
        chr1	800	901	feature6	0	+	1	1	101	0.0099010
        """

    @_log_to_history
    @_wraps(prog='maskFastaFromBed', implicit='bed', other='fi',
            make_tempfile_for='fo', add_to_bedtool={'fo': 'seqfn'},
            check_stderr=_check_sequence_stderr)
    def mask_fasta(self):
        """
        Wraps `maskFastaFromBed` (v2.15+: `bedtools maskfasta`).

        Masks a fasta file at the positions in a BED file and saves result as
        'out' and stores the filename in seqfn.

        >>> a = pybedtools.BedTool('chr1 100 110', from_string=True)
        >>> fasta_fn = pybedtools.example_filename('test.fa')
        >>> a = a.mask_fasta(fi=fasta_fn, fo='masked.fa.example')
        >>> b = a.slop(b=2, genome='hg19')
        >>> b = b.sequence(fi=a.seqfn)
        >>> print open(b.seqfn).read()
        >chr1:98-112
        TTNNNNNNNNNNAT
        <BLANKLINE>
        >>> os.unlink('masked.fa.example')
        >>> if os.path.exists('masked.fa.example.fai'):
        ...     os.unlink('masked.fa.example.fai')
        """

    @_log_to_history
    @_wraps(prog='complementBed', implicit='i', uses_genome=True)
    def complement(self):
        """
        Wraps `complementBed` (v2.15+: `bedtools complement`)

        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> a.complement(genome='hg19').head(5) #doctest: +NORMALIZE_WHITESPACE
        chr1	0	1
        chr1	500	900
        chr1	950	249250621
        chr10	0	135534747
        chr11	0	135006516
        """

    @_log_to_history
    @_wraps(prog='getOverlap', implicit='i')
    def overlap(self):
        """
        Wraps `overlap` (v2.15+: `bedtools overlap`)

        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> b = pybedtools.example_bedtool('b.bed')
        >>> c = a.window(b, w=10).overlap(cols=[2,3,8,9])
        >>> print c #doctest: +NORMALIZE_WHITESPACE
        chr1	100	200	feature2	0	+	chr1	155	200	feature5	0	-	45
        chr1	150	500	feature3	0	-	chr1	155	200	feature5	0	-	45
        chr1	900	950	feature4	0	+	chr1	800	901	feature6	0	+	1
        <BLANKLINE>
        """

    # TODO: needs test files and doctests written
    @_log_to_history
    @_wraps(prog='pairToBed', implicit='a', other='b', bam='abam',
            nonbam='bedpe')
    def pair_to_bed(self):
        """
        Wraps `pairToBed` (v2.15+: `bedtools pairtobed`).
        """

    @_log_to_history
    @_wraps(prog='pairToPair', implicit='a', other='b')
    def pair_to_pair(self):
        """
        Wraps `pairToPair` (v2.15+: `bedtools pairtopair`).
        """

    @_log_to_history
    @_wraps(prog='groupBy', implicit='i')
    def groupby(self):
        """
        Wraps `groupBy` (v2.15+: `bedtools groupby`).

        Example usage:

        >>> a = pybedtools.example_bedtool('gdc.gff')
        >>> b = pybedtools.example_bedtool('gdc.bed')
        >>> c = a.intersect(b, c=True)
        >>> d = c.groupby(g=[1, 4, 5], c=10, ops=['sum'])
        >>> print d #doctest: +NORMALIZE_WHITESPACE
        chr2L	41	70	0
        chr2L	71	130	2
        chr2L	131	170	4
        chr2L	171	200	0
        chr2L	201	220	1
        chr2L	41	130	2
        chr2L	171	220	1
        chr2L	41	220	7
        chr2L	161	230	6
        chr2L	41	220	7
        <BLANKLINE>

        """

    @_log_to_history
    @_wraps(prog='tagBam', implicit='i', bam='i')
    def tag_bam(self):
        """
        Wraps `tagBam` (v2.15+: `bedtools tag`).

        `files` and `labels` should lists of equal length.

        """

    @_log_to_history
    @_wraps(prog='mapBed', implicit='a', other='b')
    def map(self):
        """
        Wraps `mapBed` (v2.15+: `bedtools map`); See also :meth:`BedTool.each`.
        """

    @_log_to_history
    @_wraps(prog='multiIntersectBed', uses_genome=True, genome_if=['empty'])
    def multi_intersect(self):
        """
        Wraps `multiIntersectBed` (v2.15+: `bedtools multiintersect`)

        Provide a list of filenames as the "i" argument. e.g. if you already
        have BedTool objects then use their `.fn` attribute, like this::

            >>> x = pybedtools.BedTool()
            >>> a = pybedtools.example_bedtool('a.bed')
            >>> b = pybedtools.example_bedtool('b.bed')
            >>> result = x.multi_intersect(i=[a.fn, b.fn])
            >>> print result   #doctest: +NORMALIZE_WHITESPACE
            chr1	1	155	1	1	1	0
            chr1	155	200	2	1,2	1	1
            chr1	200	500	1	1	1	0
            chr1	800	900	1	2	0	1
            chr1	900	901	2	1,2	1	1
            chr1	901	950	1	1	1	0
            <BLANKLINE>

        """

    @_log_to_history
    @_wraps(prog='randomBed', uses_genome=True)
    def random(self):
        """
        Wraps `randomBed` (v2.15+: `bedtools random`)

        Since this method does not operate on an existing file, create
        a BedTool with no arguments and then call this method, e.g.,

        >>> x = BedTool()
        >>> y = x.random(l=100, n=10, genome='hg19')
        """

    @_log_to_history
    @_wraps('bedpeToBam', implicit='i', uses_genome=True, force_bam=True)
    def bedpe_to_bam(self):
        """
        Wraps `bedpeToBam` (v2.15+: `bedtools bedpetobam`)
        """

    @_log_to_history
    @_wraps(prog='clusterBed', implicit='i')
    def cluster(self):
        """
        Wraps `clusterBed` (v2.15+: `bedtools cluster`)
        """

    @_log_to_history
    @_wraps(prog='unionBedGraphs')
    def union_bedgraphs(self):
        """
        Wraps `unionBedGraphs` (v2.15+: `bedtools unionbedg`)

        Warning: using the `header=True` kwarg will result in a file that is
        not in true BED format, which may break downstream analysis.
        """

    @_log_to_history
    @_wraps(prog='windowMaker', uses_genome=True, genome_none_if=['b'],
            other='b')
    def window_maker(self):
        """
        Wraps `windowMaker` (v2.15+: `bedtools makewindows`)
        """

    @_log_to_history
    @_wraps(prog='expandCols', implicit='i')
    def expand(self):
        """
        Wraps `expandCols` (v2.15+: `bedtools expand`)
        """

    @_log_to_history
    @_wraps(prog='linksBed', implicit='i',
            add_to_bedtool={'stdout': 'links_html'})
    def links(self):
        """
        Wraps `linksBed` (v2.15+: `bedtools links`)

        The resulting BedTool will have a new attribute `links_html`.  This
        attribute is a temp filename containing the HTML links.
        """

    @_log_to_history
    @_wraps(prog='bedToIgv', implicit='i',
            add_to_bedtool={'stdout': 'igv_script'})
    def igv(self):
        """
        Wraps `bedToIgv` (v2.15+: `bedtools igv`)

        The resulting BedTool will have a new attribute `igv_script`.  This
        attribute is a temp filename containing the IGV script.
        """

    @_log_to_history
    @_wraps(prog='bamToFastq', implicit='i', bam='i', make_tempfile_for='fq',
            add_to_bedtool={'fq': 'fastq'})
    def bam_to_fastq(self):
        """
        Wraps `bamToFastq` (v2.15+: `bedtools bamtofastq`)

        The `fq` argument is required.

        The resulting BedTool will have a new attribute, `fastq`.
        """

    @_wraps(prog='jaccard', implicit='a', other='b',
            does_not_return_bedtool=helpers._jaccard_output_to_dict)
    def jaccard(self):
        """
        Returns a dictionary with keys (intersection, union, jaccard).
        """

    @_wraps(prog='reldist', implicit='a', other='b',
            does_not_return_bedtool=helpers._reldist_output_handler)
    def reldist(self):
        """
        If detail=False, then return a dictionary with keys (reldist, count,
        total, fraction), which is the summary of the bedtools reldist.

        Otherwise return a BedTool, with the relative distance for each
        interval in A in the last column.
        """

    @_wraps(prog='sample', implicit='i', bam='i')
    def sample(self):
        """
        Wraps 'sample'.
        """

    def count(self):
        """
        Count the number features in this BedTool.

        Number of features in BED file. Does the same thing as len(self), which
        actually just calls this method.

        Only counts the actual features.  Ignores any track lines, browser
        lines, lines starting with a "#", or blank lines.

        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> a.count()
        4
        """
        return sum(1 for _ in self)

    def print_sequence(self):
        """
        Print the sequence that was retrieved by BedTool.sequence.

        See usage example in :meth:`BedTool.sequence`.
        """
        if not hasattr(self, 'seqfn'):
            raise ValueError('Use .sequence(fasta) to get the sequence first')
        f = open(self.seqfn)
        s = f.read()
        f.close()
        return s

    def save_seqs(self, fn):
        """
        Save sequences, after calling BedTool.sequence.

        In order to use this function, you need to have called
        the :meth:`BedTool.sequence()` method.

        A new BedTool object is returned which references the newly saved file.

        Example usage:

        >>> a = pybedtools.BedTool('''
        ... chr1 1 10
        ... chr1 50 55''', from_string=True)
        >>> fasta = pybedtools.example_filename('test.fa')
        >>> a = a.sequence(fi=fasta)
        >>> print open(a.seqfn).read()
        >chr1:1-10
        GATGAGTCT
        >chr1:50-55
        CCATC
        <BLANKLINE>
        >>> b = a.save_seqs('example.fa')
        >>> assert open(b.fn).read() == open(a.fn).read()
        >>> if os.path.exists('example.fa'):
        ...     os.unlink('example.fa')
        """

        if not hasattr(self, 'seqfn'):
            raise ValueError('Use .sequence(fasta) to get the sequence first')
        fout = open(fn, 'w')
        fout.write(open(self.seqfn).read())
        fout.close()
        new_bedtool = BedTool(self.fn)
        new_bedtool.seqfn = fn
        return new_bedtool

    def randomstats(self, other, iterations, new=False, genome_fn=None,
                    include_distribution=False, **kwargs):
        """
        Dictionary of results from many randomly shuffled intersections.

        Sends args and kwargs to :meth:`BedTool.randomintersection` and
        compiles results into a dictionary with useful stats.  Requires
        numpy.

        If `include_distribution` is True, then the dictionary will include the
        full distribution; otherwise, the distribution is deleted and cleaned
        up to save on memory usage.

        This is one possible way of assigning significance to overlaps between
        two files. See, for example:

            Negre N, Brown CD, Shah PK, Kheradpour P, Morrison CA, et al. 2010
            A Comprehensive Map of Insulator Elements for the Drosophila
            Genome. PLoS Genet 6(1): e1000814. doi:10.1371/journal.pgen.1000814

        Example usage:

        Make chromsizes a very small genome for this example:

        >>> chromsizes = {'chr1':(1,1000)}
        >>> a = pybedtools.example_bedtool('a.bed').set_chromsizes(chromsizes)
        >>> b = pybedtools.example_bedtool('b.bed')
        >>> try:
        ...     results = a.randomstats(b, 100, debug=True)
        ... except ImportError:
        ...     pass

        *results* is a dictionary that you can inspect.

        (Note that the following examples are not run as part of the doctests
        to avoid forcing users to install NumPy just to pass tests)

        The actual overlap::

            print results['actual']
            3

        The median of all randomized overlaps::

            print results['median randomized']
            2.0

        The percentile of the actual overlap in the distribution of randomized
        overlaps, which can be used to get an empirical p-value::

            print results['percentile']
            90.0
        """
        if ('intersect_kwargs' not in kwargs) or \
                (kwargs['intersect_kwargs'] is None):
            kwargs['intersect_kwargs'] = {'u': True}
        try:
            import numpy as np
        except ImportError:
            raise ImportError("Need to install NumPy for stats...")

        def percentileofscore(a, score):
            """
            copied from scipy.stats.percentileofscore, to avoid dependency on
            scipy.
            """
            a = np.array(a)
            n = len(a)

            if not(np.any(a == score)):
                a = np.append(a, score)
                a_len = np.array(range(len(a)))
            else:
                a_len = np.array(range(len(a))) + 1.0

            a = np.sort(a)
            idx = [a == score]
            pct = (np.mean(a_len[idx]) / n) * 100.0
            return pct

        if isinstance(other, basestring):
            other = BedTool(other)
        else:
            assert isinstance(other, BedTool),\
                'Either filename or another BedTool instance required'

        # Actual (unshuffled) counts.
        i_kwargs = kwargs['intersect_kwargs']
        actual = len(self.intersect(other, **i_kwargs))

        # List of counts from randomly shuffled versions.
        # Length of counts == *iterations*.

        if not new:
            distribution = self.randomintersection(
                other, iterations=iterations, **kwargs)
        else:
            # use new mechanism
            if genome_fn is None:
                raise ValueError(
                    '`genome_fn` must be provided if using the '
                    'new _randomintersection mechanism')
            distribution = self._randomintersection(
                other, iterations=iterations, genome_fn=genome_fn, **kwargs)

        distribution = np.array(list(distribution))

        # Median of distribution
        med_count = np.median(distribution)

        n = float(len(distribution))

        frac_above = sum(distribution > actual) / n
        frac_below = sum(distribution < actual) / n

        normalized = actual / med_count

        lower_thresh = 2.5
        upper_thresh = 97.5
        lower, upper = np.percentile(
            distribution, [lower_thresh, upper_thresh])

        actual_percentile = percentileofscore(distribution, actual)
        d = {
            'iterations': iterations,
            'actual': actual,
            'file_a': self.fn,
            'file_b': other.fn,
            self.fn: len(self),
            other.fn: len(other),
            'self': len(self),
            'other': len(other),
            'frac randomized above actual': frac_above,
            'frac randomized below actual': frac_below,
            'median randomized': med_count,
            'normalized': normalized,
            'percentile': actual_percentile,
            'lower_%sth' % lower_thresh: lower,
            'upper_%sth' % upper_thresh: upper,
        }
        if include_distribution:
            d['distribution'] = distribution
        else:
            del distribution
        return d

    def random_op(self, *args, **kwargs):
        """
        For backwards compatibility; see BedTool.parallel_apply instead.
        """
        return self.parallel_apply(*args, **kwargs)

    def parallel_apply(self, iterations, func, func_args, func_kwargs,
                       processes=1, _orig_pool=None):
        """
        Generalized method for applying a function in parallel.

        Typically used when having to do many random shufflings.

        `func_args` and `func_kwargs` will be passed to `func` each time in
        `iterations`, and these iterations will be split across `processes`
        processes.

        Notes on the function, `func`:

            * the function should manually remove any tempfiles created.  This
              is because the BedTool.TEMPFILES list of auto-created tempfiles
              does not share state across processes, so things will not get
              cleaned up automatically as they do in a single-process
              pybedtools session.

            * this includes deleting any "chromsizes" or genome files --
              generally it will be best to require a genome filename in
              `func_kwargs` if you'll be using any BedTool methods that accept
              the `g` kwarg.

            * the function should be a module-level function (rather than a
              class method) because class methods can't be pickled across
              process boundaries

            * the function can have any signature and have any return value

        `_orig_pool` can be a previously-created multiprocessing.Pool instance;
        otherwise, a new Pool will be created with `processes`
        """
        if processes == 1:
            for it in range(iterations):
                yield func(*func_args, **func_kwargs)
            raise StopIteration

        if _orig_pool:
            p = _orig_pool
        else:
            p = multiprocessing.Pool(processes)
        iterations_each = [iterations / processes] * processes
        iterations_each[-1] += iterations % processes

        # FYI some useful info on apply_async:
        # http://stackoverflow.com/questions/8533318/
        #      python-multiprocessing-pool-when-to-use-apply-apply-async-or-map
        #
        # Here, we don't care about the order, and don't want the subprocesses
        # to block.
        results = [
            p.apply_async(func, func_args, func_kwargs)
            for it in range(iterations)]
        for r in results:
            yield r.get()
        raise StopIteration

    def random_jaccard(self, other, genome_fn=None, iterations=None,
                       processes=1, _orig_pool=None, shuffle_kwargs=None,
                       jaccard_kwargs=None):
        """
        Computes the naive Jaccard statistic (intersection divided by union).

        .. note::

            If you don't need the randomization functionality of this method,
            you can use the simpler BedTool.jaccard method instead.

        See Favorov et al. (2012) PLoS Comput Biol 8(5): e1002529 for more
        info on the Jaccard statistic for intersections.

        If `iterations` is None, then do not perform random shufflings.

        If `iterations` is an integer, perform `iterations` random shufflings,
        each time computing the Jaccard statistic to build an empirical
        distribution.  `genome_fn` will also be needed; optional `processes`
        will split the iteations across multiple CPUs.

        Returns a tuple of the observed Jaccard statistic and a list of the
        randomized statistics (which will be an empty list if `iterations` was
        None).
        """
        if shuffle_kwargs is None:
            shuffle_kwargs = {}
        if jaccard_kwargs is None:
            jaccard_kwargs = {}
        if not genome_fn:
            raise ValueError(
                "Need a genome filename in order to perform randomization")
        return list(
            self.parallel_apply(
                iterations=iterations,
                func=pybedtools.stats.random_jaccard,
                func_args=(self, other),
                func_kwargs=dict(
                    genome_fn=genome_fn,
                    shuffle_kwargs=shuffle_kwargs,
                    jaccard_kwargs=jaccard_kwargs),
                processes=processes,
                _orig_pool=_orig_pool,
            )
        )

    def _randomintersection(self, other, iterations, genome_fn,
                            intersect_kwargs=None, _orig_pool=None,
                            shuffle_kwargs=None, processes=1):
        """
        Re-implementation of BedTool.randomintersection using the new
        `random_op` method
        """
        if shuffle_kwargs is None:
            shuffle_kwargs = {}
        if intersect_kwargs is None:
            intersect_kwargs = dict(u=True)
        if not genome_fn:
            raise ValueError(
                "Need a genome filename in order to perform randomization")
        return list(
            self.parallel_apply(
                iterations=iterations,
                func=pybedtools.stats.random_intersection,
                func_args=(self, other),
                func_kwargs=dict(
                    genome_fn=genome_fn,
                    shuffle_kwargs=shuffle_kwargs,
                    intersect_kwargs=intersect_kwargs),
                processes=processes,
                _orig_pool=_orig_pool,
            )
        )

    def randomintersection_bp(self, other, iterations, genome_fn,
                              intersect_kwargs=None, shuffle_kwargs=None,
                              processes=1, _orig_pool=None):
        """
        Like randomintersection, but return the bp overlap instead of the
        number of intersecting intervals.
        """
        if shuffle_kwargs is None:
            shuffle_kwargs = {}
        if intersect_kwargs is None:
            intersect_kwargs = {}
        if not genome_fn:
            raise ValueError(
                "Need a genome filename in order to perform randomization")
        return list(
            self.parallel_apply(
                iterations=iterations,
                func=pybedtools.stats.random_intersection_bp,
                func_args=(self, other),
                func_kwargs=dict(
                    genome_fn=genome_fn,
                    shuffle_kwargs=shuffle_kwargs,
                    intersect_kwargs=intersect_kwargs),
                processes=processes,
                _orig_pool=_orig_pool,
            )
        )

    def randomintersection(self, other, iterations, intersect_kwargs=None,
                           shuffle_kwargs=None, debug=False,
                           report_iterations=False, processes=None,
                           _orig_processes=None):
        """
        Perform `iterations` shufflings, each time intersecting with `other`.

        Returns a generator of integers where each integer is the number of
        intersections of a shuffled file with *other*. This distribution can
        be used in downstream analysis for things like empirical p-values.

        *intersect_kwargs* and *shuffle_kwargs* are passed to self.intersect()
        and self.shuffle() respectively.  By default for intersect, u=True is
        specified -- but s=True might be a useful option for strand-specific
        work.

        Useful kwargs for *shuffle_kwargs* are chrom, excl, or incl.  If you
        use the "seed" kwarg, that seed will be used *each* time shuffleBed is
        called -- so all your randomization results will be identical for each
        iteration.  To get around this and to allow for tests, debug=True will
        set the seed to the iteration number.  You may also break up the
        intersections across multiple processes with *processes* > 1.

        Example usage:

            >>> chromsizes = {'chr1':(0, 1000)}
            >>> a = pybedtools.example_bedtool('a.bed')
            >>> a = a.set_chromsizes(chromsizes)
            >>> b = pybedtools.example_bedtool('b.bed')
            >>> results = a.randomintersection(b, 10, debug=True)
            >>> print list(results)
            [2, 2, 3, 0, 3, 3, 0, 0, 2, 4]

        """
        if processes is not None:
            p = multiprocessing.Pool(processes)
            iterations_each = [iterations / processes] * processes
            iterations_each[-1] += iterations % processes
            results = [
                p.apply_async(
                    _call_randomintersect, (self, other, it),
                    dict(intersect_kwargs=intersect_kwargs,
                         shuffle_kwargs=shuffle_kwargs,
                         debug=debug,
                         report_iterations=report_iterations,
                         _orig_processes=processes
                         )
                )
                for it in iterations_each]
            for r in results:
                for value in r.get():
                    yield value
            raise StopIteration

        if shuffle_kwargs is None:
            shuffle_kwargs = {}
        if intersect_kwargs is None:
            intersect_kwargs = {'u': True}

        if not 'u' in intersect_kwargs:
            intersect_kwargs['u'] = True

        resort = intersect_kwargs.get('sorted', False)

        for i in range(iterations):
            if debug:
                shuffle_kwargs['seed'] = i
            if report_iterations:
                if _orig_processes > 1:
                    msg = '\rapprox (total across %s processes): %s' \
                        % (_orig_processes, i * _orig_processes)
                else:
                    msg = '\r%s' % i
                sys.stderr.write(msg)
                sys.stderr.flush()

            # Re-sort if sorted=True in kwargs
            if resort:
                tmp0 = self.shuffle(**shuffle_kwargs)
                tmp = tmp0.sort()
            else:
                tmp = self.shuffle(**shuffle_kwargs)

            tmp2 = tmp.intersect(other, stream=True, **intersect_kwargs)

            yield len(tmp2)

            # Close the open stdouts from subprocess.Popen calls.  Note: doing
            # this in self.__del__ doesn't fix the open file limit bug; it
            # needs to be done here.
            #if resort:
            #    tmp0.fn.close()
            #tmp.fn.close()
            tmp2.fn.close()
            del(tmp)
            del(tmp2)

    @_log_to_history
    def cat(self, *others, **kwargs):
        """
        Concatenate interval files together.

        Concatenates two BedTool objects (or an object and a file) and does an
        optional post-merge of the features.

        Use *postmerge=False* if you want to keep features separate.
        Use *force_truncate=True* to truncate all files to chrom, start, stop

        TODO:

            force_truncate=True currently truncates at BED3 format!

        other kwargs are sent to :meth:`BedTool.merge`.

        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> b = pybedtools.example_bedtool('b.bed')
        >>> print a.cat(b) #doctest: +NORMALIZE_WHITESPACE
        chr1	1	500
        chr1	800	950
        <BLANKLINE>
        >>> print a.cat(*[b,b],
        ...   postmerge=False) #doctest: +NORMALIZE_WHITESPACE
        chr1	1	100	feature1	0	+
        chr1	100	200	feature2	0	+
        chr1	150	500	feature3	0	-
        chr1	900	950	feature4	0	+
        chr1	155	200	feature5	0	-
        chr1	800	901	feature6	0	+
        chr1	155	200	feature5	0	-
        chr1	800	901	feature6	0	+
        <BLANKLINE>
        """
        assert len(others) > 0, 'You must specify at least one other bedfile!'
        other_beds = []
        for other in others:
            if isinstance(other, basestring):
                other = BedTool(other)
            else:
                assert isinstance(other, BedTool),\
                    'Either filename or another BedTool instance required'
            other_beds.append(other)
        tmp = self._tmp()
        TMP = open(tmp, 'w')

        # postmerge and force_trucate don't get passed on to merge
        postmerge = kwargs.pop('postmerge', True)
        force_truncate = kwargs.pop('force_truncate', False)

        stream_merge = kwargs.get('stream', False)
        if stream_merge and postmerge:
            raise ValueError(
                "The post-merge step in the `cat()` method "
                "perfoms a sort, which uses stream=True.  Using "
                "stream=True for the merge as well will result in a "
                "deadlock!")

        # if filetypes and field counts are the same, don't truncate
        if not force_truncate:
            try:
                a_type = self.file_type

                files = [self] + other_beds
                filetypes = set(
                    [self.file_type]
                    + [i.file_type for i in other_beds]).difference(['empty'])
                field_nums = set(
                    [i.field_count for i in other_beds]).difference([None])
                same_field_num = len(field_nums) == 1
                same_type = len(set(filetypes)) == 1
            except ValueError:
                raise ValueError(
                    "Can't check filetype or field count -- "
                    "is one of the files you're merging a 'streaming' "
                    "BedTool?  If so, use .saveas() to save to file first")

        if not force_truncate and same_type and same_field_num:
            for f in self:
                TMP.write(str(f))
            for other in other_beds:
                for f in other:
                    TMP.write(str(f))

        # otherwise, truncate
        else:
            for f in self:
                TMP.write('%s\t%i\t%i\n' % (f.chrom, f.start, f.end))
            for other in other_beds:
                for f in other:
                    TMP.write('%s\t%i\t%i\n' % (f.chrom, f.start, f.end))

        TMP.close()
        c = BedTool(tmp)
        if postmerge:
            d = c.sort(stream=True).merge(**kwargs)

            # Explicitly delete -- needed when using multiprocessing
            os.unlink(tmp)
            return d
        else:
            return c

    @_log_to_history
    def saveas(self, fn=None, trackline=None):
        """
        Make a copy of the BedTool.

        Optionally adds `trackline` to the beginning of the file.

        Returns a new BedTool for the newly saved file.

        A newline is automatically added to the trackline if it does not
        already have one.

        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> b = a.saveas('other.bed')
        >>> b.fn
        'other.bed'
        >>> print b == a
        True

        >>> b = a.saveas('other.bed', trackline="name='test run' color=0,55,0")
        >>> open(b.fn).readline()
        "name='test run' color=0,55,0\\n"
        >>> if os.path.exists('other.bed'):
        ...     os.unlink('other.bed')
        """
        if fn is None:
            fn = self._tmp()

        fn = self._collapse(self, fn=fn, trackline=trackline)
        return BedTool(fn)

    @_log_to_history
    def moveto(self, fn=None):
        """
        Move to a new filename (can be much quicker than BedTool.saveas())

        Move BED file to new filename, `fn`.

        Returns a new BedTool for the new file.

        Example usage:

        >>> # make a copy so we don't mess up the example file
        >>> a = pybedtools.example_bedtool('a.bed').saveas()
        >>> a_contents = str(a)
        >>> b = a.moveto('other.bed')
        >>> b.fn
        'other.bed'
        >>> b == a_contents
        True
        """
        if not isinstance(self.fn, basestring):
            fn = self._collapse(self, fn=fn)
        else:
            shutil.move(self.fn, fn)
        return BedTool(fn)

    @_log_to_history
    def random_subset(self, n, seed=None):
        '''
        Return a BedTool containing a random subset.

        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')
        >>> b = a.random_subset(2)
        >>> len(b)
        2
        '''
        idxs = range(len(self))
        if seed is not None:
            random.seed(seed)
        random.shuffle(idxs)
        idxs = idxs[:n]

        tmpfn = self._tmp()
        tmp = open(tmpfn, 'w')
        for i, f in enumerate(self):
            if i in idxs:
                tmp.write(str(f) + '\n')
        tmp.close()
        return BedTool(tmpfn)

    def total_coverage(self):
        """
        Return the total number of bases covered by this interval file.

        Does a self.merge() first to remove potentially multiple-counting
        bases.

        Example usage:

        >>> a = pybedtools.example_bedtool('a.bed')

        This does a merge() first, so this is what the total coverage is
        counting:

        >>> print a.merge() #doctest: +NORMALIZE_WHITESPACE
        chr1	1	500
        chr1	900	950
        <BLANKLINE>

        >>> print a.total_coverage()
        549
        """
        b = self.merge()
        total_bp = 0
        for feature in b.features():
            total_bp += len(feature)
        return total_bp

    @_log_to_history
    def with_attrs(self, **kwargs):
        """
        Helper method for adding attributes in the middle of a pipeline.

        Given arbitrary keyword arguments, turns the keys and values into
        attributes.  Useful for labeling BedTools at creation time.

        Example usage:

        >>> # add a "label" attribute to each BedTool
        >>> a = pybedtools.example_bedtool('a.bed')\
                                   .with_attrs(label='transcription factor 1')
        >>> b = pybedtools.example_bedtool('b.bed')\
                                   .with_attrs(label='transcription factor 2')
        >>> for i in [a, b]:
        ...     print i.count(), 'features for', i.label
        4 features for transcription factor 1
        2 features for transcription factor 2

        """
        for key, value in kwargs.items():
            setattr(self, key, value)
        return self

    def as_intervalfile(self):
        """
        Returns an IntervalFile of this BedTool for low-level interface.
        """
        if not isinstance(self.fn, basestring):
            fn = self._collapse(self.fn)
        else:
            fn = self.fn
        return IntervalFile(fn)

    def liftover(self, chainfile, unmapped=None, liftover_args=""):
        """
        Returns a new BedTool of the liftedOver features, saving the unmapped
        ones as `unmapped`.  If `unmapped` is None, then discards the unmapped
        features.

        `liftover_args` is a string of additional args that is passed,
        verbatim, to liftOver.

        Needs `liftOver` from UCSC to be on the path and a `chainfile`
        downloaded from UCSC.
        """
        result = BedTool._tmp()
        if unmapped is None:
            unmapped = BedTool._tmp()
        cmds = ['liftOver', liftover_args, self.fn, chainfile, result,
                unmapped]
        os.system(' '.join(cmds))
        return BedTool(result)

    def absolute_distance(self, other, closest_kwargs=None,
                          use_midpoints=False):
        """
        Returns an iterator of the *absolute* distances between features in
        self and other.

        If `use_midpoints` is True, then only use the midpoints of features
        (which will return values where features are overlapping).  Otherwise,
        when features overlap the value will always be zero.

        `closest_kwargs` are passed to self.closest(); either `d` or
        'D` are required in order to get back distance values (`d=True` is
        default)
        """
        from featurefuncs import midpoint

        if closest_kwargs is None:
            closest_kwargs = {'d': True}

        if 'D' not in closest_kwargs:
            closest_kwargs.update(dict(d=True))

        if use_midpoints:
            mid_self = self.each(midpoint).saveas()
            mid_other = other.each(midpoint).saveas()
            c = mid_self.closest(mid_other, stream=True, **closest_kwargs)
        else:
            c = self.closest(other, stream=True, **closest_kwargs)
        for i in c:
            yield int(i[-1])

    def relative_distance(self, other, genome=None, g=None):
        """
        Returns an iterator of relative distances between features in self and
        other.

        First computes the midpoints of self and other, then returns distances
        of each feature in `other` relative to the distance between `self`
        features.

        Requires either `genome` (dictionary of chromsizes or assembly name) or
        `g` (filename of chromsizes file).
        """
        if (genome is None) and (g is None):
            raise ValueError(
                'Need either `genome` or `g` arg for relative distance')
        if genome and g:
            raise ValueError('Please specify only one of `genome` or `g`')

        if genome:
            g_dict = dict(genome=genome)
        if g:
            g_dict = dict(g=g)

        from featurefuncs import midpoint

        # This gets the space between features in self.
        c = self.each(midpoint).complement(**g_dict)

        mid_other = other.each(midpoint).saveas()

        hits = c.intersect(other, wao=True, stream=True)
        for i in hits:
            yield float(i[-1]) / len(i)

    def colormap_normalize(self, vmin=None, vmax=None, log=False):
        """
        Returns a normalization instance for use by featurefuncs.add_color().

        `vmin` and `vmax` set the colormap bounds; if not specified then these
        will be determined from the scores in the BED file.

        `log`, if True, will put the scores on a log scale; of course be
        careful if you have negative scores
        """
        field_count = self.field_count()
        if (self.file_type != 'bed') or (field_count < 5):
            raise ValueError('colorizing only works for BED files with score '
                             'fields')
        import matplotlib
        import numpy as np

        if log:
            norm = matplotlib.colors.LogNorm()
        else:
            norm = matplotlib.colors.Normalize()

        if (vmin is not None) and (vmax is not None):
            norm.vmin = vmin
            norm.vmax = vmax

        else:
            scores = np.array([i.score for i in self], dtype=float)
            scores = scores[np.isfinite(scores)]
            norm.autoscale(scores)

        return norm

    def at(self, inds):
        """
        Returns a new BedTool with only intervals at lines `inds`
        """
        length = len(inds)

        def _gen():
            k = 0
            for i, feature in enumerate(self):
                if i == inds[k]:
                    yield feature
                    k += 1
                    if k == length:
                        break
        return BedTool(_gen()).saveas()


class BAM(object):
    def __init__(self, stream, header_only=False):
        """
        Wraps samtools to iterate over a BAM, yielding lines.
        """
        self.stream = stream
        self.header_only = header_only
        if not settings._samtools_installed:
            helpers._check_for_samtools()

        if isinstance(self.stream, basestring):
            self.cmds = [os.path.join(settings._samtools_path, 'samtools'),
                         'view', stream]
            if header_only:
                self.cmds.append('-H')
            self.p = subprocess.Popen(self.cmds,
                                      stdout=subprocess.PIPE,
                                      stderr=subprocess.PIPE,
                                      bufsize=1)
        else:
            # Streaming . . .
            self.cmds = [os.path.join(settings._samtools_path, 'samtools'),
                         'view', '-']
            if header_only:
                self.cmds.append('-H')
            self.p = subprocess.Popen(self.cmds,
                                      stdout=subprocess.PIPE,
                                      stdin=subprocess.PIPE,
                                      stderr=subprocess.PIPE,
                                      bufsize=0)
            # Can't iterate (for i in stream) cause we're dealing with a binary
            # BAM file here.  So read the whole thing in at once.
            self.p.stdin.write(stream.read())

    def __iter__(self):
        return self

    def next(self):
        line = self.p.stdout.next()

        # If we only want the header, then short-circuit once we're out of
        # header lines
        if self.header_only:
            if line[0] != '@':
                raise StopIteration

        return line

if __name__ == "__main__":
    import doctest
    doctest.testmod(optionflags=doctest.ELLIPSIS |
                    doctest.NORMALIZE_WHITESPACE)

########NEW FILE########
__FILENAME__ = bigbed
import os
import subprocess
import pybedtools


def bigbed(x, genome, output, blockSize=256, itemsPerSlot=512, bedtype=None, _as=None, unc=False, tab=False):
    """
    Converts a BedTool object to a bigBed format and returns the new filename.

    `x` is a BedTool object

    `genome` is an assembly string

    `output` is the name of the bigBed file to create.

    Other args are passed to bedToBigBed.  In particular, `bedtype` (which
    becomes the "-type=" argument) is automatically handled for you if it is
    kept as the default None.

    Assumes that a recent version of bedToBigBed from UCSC is on the path.
    """
    if isinstance(x, basestring):
        x = pybedtools.BedTool(x)
    if not isinstance(x.fn, basestring):
        x = x.saveas()
    chromsizes = pybedtools.chromsizes_to_file(pybedtools.chromsizes(genome))
    if bedtype is None:
        bedtype = 'bed%s' % x.field_count()
    cmds = [
        'bedToBigBed',
        x.fn,
        chromsizes,
        output,
        '-blockSize=%s' % blockSize,
        '-itemsPerSlot=%s' % itemsPerSlot,
        '-type=%s' % bedtype
    ]
    if unc:
        cmds.append('-unc')
    if tab:
        cmds.append('-tab')
    if _as:
        cmds.append('-as=%s' % _as)
    p = subprocess.Popen(cmds, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = p.communicate()
    if p.returncode:
        raise ValueError("cmds: %s\nstderr:%s\nstdout:%s"
                         % (" ".join(cmds), stderr, stdout))

    return output

def bigbed_to_bed(fn, chrom=None, start=None, end=None, maxItems=None):
    cmds = [
        'bigBedToBed',
        fn]
    if chrom is not None:
        cmds.extend(['-chrom', chrom])
    if start is not None:
        cmds.extend(['-start', start])
    if end is not None:
        cmds.extend(['-end', end])
    if maxItems is not None:
        cmds.extend(['-maxItems', maxItems])

    outfn = pybedtools.BedTool._tmp()
    cmds.append(outfn)

    p = subprocess.Popen(cmds, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = p.communicate()
    if p.returncode:
        raise ValueError("cmds: %s\nstderr:%s\nstdout:%s"
                         % (" ".join(cmds), stderr, stdout))
    return pybedtools.BedTool(outfn)

########NEW FILE########
__FILENAME__ = bigwig
"""
Module to help create scaled bigWig files from BAM
"""
import pybedtools
import os
import subprocess


def mapped_read_count(bam, force=False):
    """
    Scale is cached in a bam.scale file containing the number of mapped reads.
    Use force=True to override caching.
    """
    scale_fn = bam + '.scale'
    if os.path.exists(scale_fn) and not force:
        for line in open(scale_fn):
            if line.startswith('#'):
                continue
            readcount = float(line.strip())
            return readcount

    cmds = ['samtools',
            'view',
            '-c',
            '-F', '0x4',
            bam]
    p = subprocess.Popen(cmds, stdout=subprocess.PIPE,
                         stderr=subprocess.PIPE)
    stdout, stderr = p.communicate()
    if stderr:
        raise ValueError('samtools says: %s' % stderr)

    readcount = float(stdout)

    # write to file so the next time you need the lib size you can access
    # it quickly
    if not os.path.exists(scale_fn):
        fout = open(scale_fn, 'w')
        fout.write(str(readcount) + '\n')
        fout.close()
    return readcount


def bedgraph_to_bigwig(bedgraph, genome, output):
    genome_file = pybedtools.chromsizes_to_file(pybedtools.chromsizes(genome))
    cmds = [
        'bedGraphToBigWig',
        bedgraph.fn,
        genome_file,
        output]
    os.system(' '.join(cmds))
    return output


def wig_to_bigwig(wig, genome, output):
    genome_file = pybedtools.chromsizes_to_file(pybedtools.chromsizes(genome))
    cmds = [
        'wigToBigWig',
        wig.fn,
        genome_file,
        output]
    os.system(' '.join(cmds))
    return output


def bam_to_bigwig(bam, genome, output, scale=False):
    """
    Given a BAM file `bam` and assembly `genome`, create a bigWig file scaled
    such that the values represent scaled reads -- that is, reads per million
    mapped reads.

    (Disable this scaling step with scale=False; in this case values will
    indicate number of reads)

    Assumes that `bedGraphToBigWig` from UCSC tools is installed; see
    http://genome.ucsc.edu/goldenPath/help/bigWig.html for more details on the
    format.
    """
    genome_file = pybedtools.chromsizes_to_file(pybedtools.chromsizes(genome))
    kwargs = dict(bg=True, split=True, g=genome_file)
    if scale:
        readcount = mapped_read_count(bam)
        _scale = 1 / (readcount / 1e6)
        kwargs['scale'] = _scale
    x = pybedtools.BedTool(bam).genome_coverage(**kwargs)
    cmds = [
        'bedGraphToBigWig',
        x.fn,
        genome_file,
        output]
    os.system(' '.join(cmds))

########NEW FILE########
__FILENAME__ = classifier
import os
import pybedtools
import itertools
from collections import defaultdict


class BasePairClassifier(object):
    def __init__(self, bed, annotations, genome, sample_name='sample',
                 names=None, prefix='split_'):
        """
        Classifies files using bedtools multiinter.

        The results from this class split up the bp in `bed` in to classes as
        annotated in `annotations`.  Note that this is different from counting
        the number of features in `bed` that fall within `annotations`; for
        this latter functionality, see the FeatureClassifier class in this same
        module.

        `bed` must be a BED/VCF/GFF/GTF BedTool object or filename -- not
        a BAM.  This is because `bedtools multiinter`, the program called here,
        does not accept BAM as input. If you want to use reads from a BAM file,
        first convert to bed, i.e.,::

            bed = pybedtools.BedTool('reads.bam').bam_to_bed(split=True).fn

        `annotations` will be used to classify the features in `bed`.

            If `annotations` is a list, then use those annotations directly.

            If `annotations` is a BedTool or string, then split the annotations
            into multiple files based on the featuretype (assumes GFF/GTF
            format).  Each of these new filenames will get the `prefix`
            supplied.

        `sample_name` is the name of the sample. It is used internally, but it
        needs to be a unique name that is not the name of a featuretype in the
        annotations file (i.e., sample_name="exon" would not be a good choice).

        `names` is an optional list of names that correspond to `annotations`
        if it is a list, OR a function that maps items in `annotations` to
        a featuretype name -- e.g.::

            names=lambda x: x.replace('.gff', '')

        `genome` is the string assembly name, or dictionary of {chrom: (start,
        stop)} coordinates for each chromosome.  It is used to determine the
        "unannotated" space of the genome.

        After running the `classify()` method, the results BedTool is available
        as self.results, and these are parsed into two dictionaries,
        1) self.class_genome_bp, which holds the total number of annotated
        genomic bp for each class, and 2) self.class_sample_bp, which holds the
        total number of bp in the sample that overlapped each class.

        The table() method offers a means to filter/merge these
        fully-classified dictionaries such that they only contain featuretypes
        of interest (by using the `include` kwarg).

        The print_table() method prints a nice, optionally-filtered/merged
        table of the results, sorted by total sample bp.

        Example usage::

            >>> bam = pybedtools.example_bedtool('x.bam')
            >>> bed = bam.bam_to_bed(split=True).sort()
            >>> anno = pybedtools.example_filename('dm3-chr2L-5M.gff.gz')
            >>> names, fns = MultiClassifier.split_annotations(anno)

            >>> # Example method of making a name converter.
            >>> # (note that the split `fns` have the form 'split_exon.gff')
            >>> def f(x):
            ...     return x.split('_')[-1]

            >>> c = MultiClassifier(bed, fns, names=f, genome='dm3')
            >>> c.classify()
            >>> inc = ['exon', 'intron']
            >>> table = c.print_table(include=inc)
            >>> print table #doctest: +NORMALIZE_WHITESPACE
            class	sample	genome
            exon	361971	1188410
            unannotated	19103	19841604
            exon, intron	14250	177913
            intron	10657	1803617

            >>> # Clean up the split files.
            >>> for fn in fns:
            ...     os.unlink(fn)

        """
        self.bed = pybedtools.BedTool(bed)
        self.sample_name = sample_name
        self.genome = genome

        # If a list of annotation files was provided, then use them directly,
        # ensuring that they are BedTools objects
        if isinstance(annotations, (list, tuple)):
            annotations = [pybedtools.BedTool(i).fn for i in annotations]

            # ... name-munge as necessary
            if names is None:
                names = annotations
            if hasattr(names, '__call__'):
                names = [names(i) for i in annotations]

        # Otherwise, split the single annotation file into a form suitible for
        # use by multiintersect
        else:
            names, files = self.split_annotations(annotations)
            annotations = list(files)
            names = list(names)

        # multiintersect still needs the input file (e.g., peaks)
        self.annotations = [self.bed.fn] + annotations
        self.names = [self.sample_name] + names

        self.class_sample_bp = defaultdict(int)
        self.class_genome_bp = defaultdict(int)

    @classmethod
    def split_annotations(self, annotations, prefix='split_', name_func=None):
        """
        Given an annotation file in GFF format, split into different files --
        each file containing only one type of feature.

        `prefix` will be added to each featuretype to construct the filenames.

        `name_func`, by default, will use the feature type field of a GTF/GFF
        file, or the feature.name attribute of another format.  Supply a custom
        function that accepts a pybedtools.Interval instance for more control.
        """
        # dict of open files, one for each featuretype found
        files = {}
        annotations = pybedtools.BedTool(annotations)
        ft = annotations.file_type
        if name_func is None:
            if ft == 'gff':
                name_func = lambda x: x[2]
            else:
                name_func = lambda x: x.name
        for feature in annotations:
            featuretype = name_func(feature)
            if featuretype not in files:
                filename = '%s%s' % (prefix, featuretype)
                files[featuretype] = open(filename, 'w')
            files[featuretype].write(str(feature))
        for f in files.values():
            f.close()
        return zip(*[(featuretype, f.name)
                   for (featuretype, f) in files.items()])

    def classify(self, **kwargs):
        """
        Classify the features in self.bed, populating several dictionaries in
        self.  `kwargs` are passed on to BedTool.multi_intersect.  The
        "empty=True" kwarg to multi_intersect is always provided to make sure
        the classification works correctly.
        """
        self.results = self.bed.multi_intersect(
            i=self.annotations,
            names=self.names,
            genome=self.genome,
            empty=True)

        sample = set([self.sample_name])

        for i in self.results:
            # Even if there were multiple annotations, only report *that* there
            # was a hit, e.g., "exon,exon,exon,5'UTR" -> (exon, 5'UTR)
            full_class = frozenset(i[4].split(','))

            # Including sample name in class name would be redundant, so remove
            # it
            class_name = full_class.difference(sample)

            # Only report if sample was in the class
            if self.sample_name in full_class:
                self.class_sample_bp[class_name] += len(i)

            # But always report the presence of the class, regardless of if
            # there was a hit in the sample or not.
            self.class_genome_bp[class_name] += len(i)

        # Genomic unannotated has the key ["none"]; sample unannotated as the
        # key [] (because it was set-differenced out)
        self.class_genome_bp[frozenset(['unannotated'])] = \
            self.class_genome_bp.pop(frozenset(['none']), 0) \
            + self.class_genome_bp.pop(frozenset([]), 0)

        self.class_sample_bp[frozenset(['unannotated'])] = \
            self.class_sample_bp.pop(frozenset([]), 0)

    def table(self, include=None):
        """
        If `include` is not None, then return versions of self.class_genome_bp
        and self.class_sample_bp that only look at the featuretypes in
        `include`.

        Otherwise, simply return these dictionaries unchanged (and including
        all available featuretypes)
        """
        if not include:
            return self.class_sample_bp, self.class_genome_bp

        d = defaultdict(int)
        s = defaultdict(int)
        include = set(include)
        for key in self.class_genome_bp:
            # orig data
            seq_bp = self.class_genome_bp[key]
            bed_bp = self.class_sample_bp[key]

            # create a merged class name by keeping only featuretypes in
            # `include`
            merged_class = frozenset(set(key).intersection(include))

            # update the new dictionaries
            d[merged_class] += bed_bp
            s[merged_class] += seq_bp

        return d, s

    def hierarchical_table(self, order, include=None,
                           include_unannotated=True):
        """
        Returns a hierarchically-ordered table, using the specified `order`.

        For example the order::

                ['TSS', 'five_prime_UTR', 'CDS', 'intron', 'three_prime_UTR',
                'TTS']

        would weight the classes from the 5'-most end of the gene.

        This summarizes the classes based on the highest-priority featuretype
        in the hierarchy.

        For example, using the above hierarchy, the following summary-class
        assignments will be made::

            (TSS, five_prime_UTR)          -> TSS
            (intron, CDS, TSS)             -> TSS
            (intron, CDS, three_prime_UTR) -> CDS

        The table has the following format, where the "classes" list is ordered
        by sample bp.

            {
                'TSS': [
                        (<class name 1>, <sample bp>, <genomic bp>),
                        (<class name 2>, <sample bp>, <genomic bp>),
                        ...
                        ],

                'five_prime_UTR': [
                        (<class name 1>, <sample bp>, <genomic bp>),
                        (<class name 2>, <sample bp>, <genomic bp>),
                        ...
                        ],
                ...

            }
        """
        sample, genomic = self.table(include=include)
        sample = sample.copy()
        genomic = genomic.copy()
        keys = list(set(sample.keys() + genomic.keys()))
        table = {}
        for h in order:
            classes = []
            for k in keys:
                if h in k:
                    try:
                        sample_bp = sample.pop(k, 0)
                        genomic_bp = genomic.pop(k, 0)
                        classes.append(
                            (k, sample_bp, genomic_bp)
                        )
                    except KeyError:
                        # already popped
                        continue
            table[h] = sorted(classes, key=lambda x: x[1], reverse=True)
        if include_unannotated:
            table['unannotated'] = [(frozenset(['unannotated']),
                                     sum(sample.values()),
                                     sum(genomic.values()))]
        return table

    def print_table(self, include=None):
        """
        Returns a string containing a tab-delimited table, including header,
        with classes sorted by total bp in each class.
        """
        d, s = self.table(include)
        out = []
        out.append('class\tsample\tgenome')
        for cls in sorted(d.keys(), key=lambda x: d[x], reverse=True):
            if len(cls) == 0:
                label = 'unannotated'
            else:
                label = ', '.join(sorted(cls))

            out.append('%s\t%s\t%s' % (label, d[cls], s[cls]))
        return '\n'.join(out)

MultiClassifier = BasePairClassifier


class Classifier(object):
    """
    Classify intervals in one file by featuretypes in another.
    """
    def __init__(self, bed, annotations):
        """
        Classify features in `bed` -- typically a BED or SAM/BAM but can be any
        format supported by BedTools -- into classes based on the featuretypes
        in the GFF/GTF file, `annotations`.

        For example, you can classify ChIP-seq peaks in a BED file by intron,
        exon, or whatever is annotated in the GFF file.  If you want to
        consider promoter regions, you'll have to add these features yourself.

        The `class_counts` dictionary has its keys as sets of featuretypes
        (each one can be considered a "class" of features) and the value is the
        number of features in that class.  The special empty set class contains
        features that did not fall in an annotated region.

        You can access the individual features in the `class_features`
        dictionary, which contains the same keys but instead of counts, it
        contains the features themselves.  This is nice for saving the features
        in a separate BED file, e.g.,

        Furthermore, you can look up the class of any feature in the original
        BED file using the `feature_classes` dictionary::


        Example usage::

            >>> bed = pybedtools.example_filename('gdc.bed')
            >>> gff = pybedtools.example_filename('gdc.gff')
            >>> c = pybedtools.contrib.classifier.Classifier(bed, gff)
            >>> c.classify(include=['intron', 'exon'])
            >>> results = c.class_counts
            >>> results == {
            ... frozenset([]): 1,
            ... frozenset(['exon']): 3,
            ... frozenset(['intron']): 3,
            ... frozenset(['intron', 'exon']): 1}
            True
            >>> key = frozenset(['intron'])
            >>> features = c.class_features[key]
            >>> pybedtools.BedTool(iter(features)).saveas() #doctest: +ELLIPSIS
            <BedTool(...)>
            >>> feature = pybedtools.BedTool(bed)[2]
            >>> c.feature_classes[feature] == set(['intron', '.'])
            True

        """
        self.bed = pybedtools.BedTool(bed)
        self.annotations = pybedtools.BedTool(annotations)
        if self.annotations.file_type != 'gff':
            raise ValueError('Annotations file must be a GFF or GTF file; '
                             '%s appears to be a %s file' % (
                                 annotations,
                                 self.annotations.file_type))

    def available_featuretypes(self):
        """
        List the featuretypes available in the annotations file.
        """
        featuretypes = set()
        for i in self.annotations:
            featuretypes.update([i[2]])
        return list(featuretypes)

    def classify(self, include=None, exclude=None, stranded=False):
        """
        Perform classification, populating dictionaries in `self`.

        Intersect the BED file with the annotations file and return
        a dictionary where keys are BED features and values are the set of
        featuretypes that BED feature was found in.


        `include` is an optional list of featuretypes to restrict the
        classification to

        `exclude` is an optional list of featuretypes to exclude from
        classification (all other featuretypes will be used).

        To see what's available, use available_featuretypes().

        When run, this method creates the following dictionaries as attributes
        of this object:

         :feature_classes:
            keys are Intervals from `bed`; values are sets of featuretypes from
            `annotations`

         :class_features:
            keys are frozensets of featuretypes from `annotations`; values are
            lists of Intervals from `bed`;

         :class_counts:
            keys are frozensets of featuretypes from annotations`; values are
            number of features -- so the length of values in the class_features
            dictionary.

        """
        if include and exclude:
            raise ValueError('Can only specify one of `include` or `exclude`')
        if exclude:
            exclude = set(exclude)
        if include:
            include = set(include)

        # Figure out the index of the featuretype field in the output
        bed_fields = self.bed.field_count()
        featuretype_idx = bed_fields + 2

        self.feature_classes = defaultdict(set)

        x = self.bed.intersect(self.annotations,
                               wao=True,
                               s=stranded,
                               stream=True)
        for feature in x:
            featuretype = feature[featuretype_idx]

            # If we're not supposed to consider this featuretype, then reset to
            # the standard GFF empty field string of "."
            if (include and featuretype not in include) \
                    or (exclude and featuretype in exclude):
                featuretype = '.'

            # the original query is in the first `bed_fields` items.  Construct
            # a new feature out of this and use it as the key.
            key = pybedtools.create_interval_from_list(
                feature.fields[:bed_fields])
            self.feature_classes[key].update([featuretype])

        self.class_features = defaultdict(list)
        self.class_counts = defaultdict(int)

        for feature, featuretypes in self.feature_classes.items():
            # get rid of "unannotated"
            ft = featuretypes.difference(['.'])
            key = frozenset(ft)
            self.class_features[key].append(feature)
            self.class_counts[key] += 1

        # convert defaultdicts to regular dicts
        self.class_features = dict(self.class_features)
        self.class_counts = dict(self.class_counts)
        self.feature_classes = dict(self.feature_classes)

    def features_to_file(self, prefix="", suffix=""):
        """
        Writes a set of files, one for each class.

        The filenames will be constructed based on the class names, track lines
        will be added to indicate classes, and `prefix` and `suffix` will be
        added to the filenames.
        """
        def make_filename(klass):
            return prefix + '_'.join(sorted(list(klass))) + suffix

        def make_trackline(klass):
            return 'track name="%s"' % (' '.join(sorted(list(klass))))

        for klass, features in self.class_features.iteritems():
            pybedtools.BedTool(features)\
                .saveas(make_filename(klass), make_trackline(klass))

    def hierarchical_table(self, order, include=None,
                           include_unannotated=True):
        """
        Returns a hierarchically-ordered table, using the specified `order`.

        For example the order::

            ['TSS', 'five_prime_UTR', 'CDS', 'intron', 'three_prime_UTR',
            'TTS']

        would weight the classes from the 5'-most end of the gene.

        This summarizes the classes based on the highest-priority featuretype
        in the hierarchy.

        For example, using the above hierarchy, the following summary-class
        assignments will be made::

            (TSS, five_prime_UTR)          -> TSS
            (intron, CDS, TSS)             -> TSS
            (intron, CDS, three_prime_UTR) -> CDS

        The table has the following format, where the "classes" list is ordered
        by sample bp.

            {
                'TSS': [
                        (<class name 1>, count),
                        (<class name 2>, count),
                        ...
                        ],

                'five_prime_UTR': [
                        (<class name 1>, count),
                        (<class name 2>, count),
                        ...
                        ],
                ...

            }
        """
        counts = self.table(include=include)
        counts = counts.copy()
        keys = counts.keys()
        table = {}
        for h in order:
            classes = []
            for k in keys:
                if h in k:
                    try:
                        count = counts.pop(k)
                        classes.append((k, count))
                    except KeyError:
                        # i.e., already popped off
                        continue
            table[h] = sorted(classes, key=lambda x: x[1], reverse=True)
        if include_unannotated:
            table['unannotated'] = [(frozenset(['unannotated']), sum(counts.values()))]
        return table

    def table(self, include=None):
        """
        If `include` is not None, then return a copy of self.class_counts that
        only have at the featuretypes in `include`.

        Otherwise, return a simple copy.
        """
        if not include:
            return self.class_counts.copy()

        d = defaultdict(int)
        s = defaultdict(int)
        include = set(include)
        for key in self.class_counts:
            # orig data
            c = self.class_counts[key]

            # create a merged class name by keeping only featuretypes in
            # `include`.  If none of the members were in `include`, then the
            # counts are appended to entry keyed by set().
            merged_class = frozenset(set(key).intersection(include))

            # update the new dictionaries
            d[merged_class] += c

        return d


    def pie(self, hierarchical_table, ax=None, order=None, **kwargs):
        """
        `hierarchical_table` is the result of calling self.hierarchical_table()`.

        `ax` is an optional Axes object to plot onto, otherwise a new figure and axes will be created.

        `order`, if None, will sort the items from largest to smallest.
        Otherwise, `order` is the order of keys in `hierarchical_table` in
        which they should be plotted, counter-clockwise from the positive
        x axis.

        Additional args are passed to ax.pie.
        """
        from matplotlib import pyplot as plt

        # restructure the table so that it's a dict of class sums (rather than
        # having every class)
        d = {}
        for k, v in hierarchical_table.items():
            d[k] = sum(i[1] for i in v)

        total = float(sum(d.values()))
        if ax is None:
            fig = plt.figure()
            ax = fig.add_subplot(111)
            ax.axis('equal')

        if order:
            items = [(k, d[k]) for k in order]
        else:
            items = sorted(d.items(), key=lambda x: x[1])

        newlabels, labels, counts = [], [], []
        for label, count in items:
            labels.append(label)
            counts.append(count)
            frac = count / total * 100.
            newlabels.append('{label}: {count} ({frac:.1f}%)'.format(**locals()))
        ax.pie(
            x=counts, labels=newlabels, labeldistance=1.2, **kwargs)
        return ax

########NEW FILE########
__FILENAME__ = intersection_matrix
import os
import sys
import sqlite3
import pybedtools
import time
import collections


def now():
    return time.time()


def get_name(fname):
    return os.path.splitext(os.path.basename(fname))[0]


class IntersectionMatrix(object):
    """
    Class to handle many pairwise comparisons of interval files
    """
    def __init__(self, beds, genome, iterations, dbfn=None, force=False):
        """
        Class to handle and keep track of many pairwise comparisons of interval
        files.

        A lightweight database approach is used to minimize computational time.

        The database stores filenames and calculation timestamps;
        re-calculating a matrix using the same interval files will only
        re-calculate values for those files whose modification times are newer
        than the timestamp in the database.

        `beds` is a list of bed files.

        `genome` is the string assembly name, e.g., "hg19" or "dm3".

        `dbfn` is the filename of the database you'd like to use to track
        what's been completed.

        Example usage:

        First, get a list of bed files to use:
        #>>> beds = [
        #... pybedtools.example_filename(i) for i in  [
        #... 'Cp190_Kc_Bushey_2009.bed',
        #... 'CTCF_Kc_Bushey_2009.bed',
        #... 'SuHw_Kc_Bushey_2009.bed',
        #... 'BEAF_Kc_Bushey_2009.bed'
        #... ]]

        Set some parameters.  "dm3" is the genome to use; info will be stored
        in "ex.db".  `force=True` means to overwrite what's in the database
        #>>> # In practice, you'll want many more iterations...
        #>>> im = IntersectionMatrix(beds, 'dm3',
        #...            dbfn='ex.db', iterations=3, force=True)
        #>>> # Use 4 CPUs for randomization
        #>>> matrix = im.create_matrix(verbose=True, processes=4)
        """
        self.beds = beds
        self.genome = genome
        self.dbfn = dbfn
        self.iterations = iterations

        if self.dbfn:
            self._init_db(force)
            self.conn = sqlite3.connect(dbfn)
            self.conn.row_factory = sqlite3.Row
            self.c = self.conn.cursor()

    def _init_db(self, force=False):
        """
        Prepare the database if it doesn't already exist
        """
        if self.dbfn is None:
            return
        if os.path.exists(self.dbfn) and not force:
            return
        conn = sqlite3.connect(self.dbfn)
        c = conn.cursor()
        if force:
            c.execute('DROP TABLE IF EXISTS intersections;')
        c.executescript("""
        CREATE TABLE intersections (
            filea TEXT,
            fileb TEXT,
            timestamp FLOAT,
            actual FLOAT,
            median FLOAT,
            iterations INT,
            self INT,
            other INT,
            fractionabove FLOAT,
            fractionbelow FLOAT,
            percentile FLOAT,
            PRIMARY KEY (filea, fileb, iterations));
        """)
        conn.commit()

    def get_row(self, fa, fb, iterations):
        """
        Return the sqlite3.Row from the database corresponding to files `fa`
        and `fb`; returns None if not found.
        """
        if self.dbfn is None:
            return

        results = list(self.c.execute(
                """
                SELECT * FROM intersections
                WHERE
                filea=:fa AND fileb=:fb AND iterations=:iterations
                """, locals()))
        if len(results) == 0:
            return
        assert len(results) == 1
        return results[0]

    def done(self, fa, fb, iterations):
        """
        Retrieves row from db and only returns True if there's something in
        there and the timestamp is newer than the input files.
        """
        row = self.get_row(fa, fb, iterations)
        if row:
            tfa = os.path.getmtime(fa)
            tfb = os.path.getmtime(fb)
            if (row['timestamp'] > tfa) and (row['timestamp'] > tfb):
                return True
        return False

    def run_and_insert(self, fa, fb, **kwargs):
        a = pybedtools.BedTool(fa).set_chromsizes(self.genome)
        kwargs['iterations'] = self.iterations
        results = a.randomstats(fb, **kwargs)
        self.add_row(results)

    def add_row(self, results):
        """
        Inserts data into db.  `results` is a dictionary as returned by
        BedTool.randomstats with keys like::

            'iterations'
            'actual'
            'file_a'
            'file_b'
            self.fn
            other.fn
            'self'
            'other'
            'frac randomized above actual'
            'frac randomized below actual'
            'median randomized'
            'normalized'
            'percentile'
            'lower_%sth' % lower_thresh
            'upper_%sth' % upper_thresh
        """
        # translate results keys into db-friendly versions
        translations = [
                ('file_a', 'filea'),
                ('file_b', 'fileb'),
                ('median randomized', 'median'),
                ('frac randomized above actual', 'fractionabove'),
                ('frac randomized below actual', 'fractionbelow'),
                ]
        for orig, new in translations:
            results[new] = results[orig]

        results['timestamp'] = now()

        sql = """
        INSERT OR REPLACE INTO intersections (

            filea,
            fileb,
            timestamp,
            actual,
            median,
            iterations,
            self,
            other,
            fractionabove,
            fractionbelow,
            percentile)

            VALUES (

            :filea,
            :fileb,
            :timestamp,
            :actual,
            :median,
            :iterations,
            :self,
            :other,
            :fractionabove,
            :fractionbelow,
            :percentile)

        """
        self.c.execute(sql, results)
        self.conn.commit()

    def create_matrix(self, verbose=False, **kwargs):
        """
        Matrix (implemented as a dictionary), where the final values are
        sqlite3.ROW objects from the database::

            {
                filea: {
                            filea: ROW,
                            fileb: ROW,
                            ...},
                fileb: {
                            filea: ROW,
                            fileb: ROW,
                            ...},

                        }
            }
        """
        nfiles = len(self.beds)
        total = nfiles ** 2
        i = 0
        matrix = collections.defaultdict(dict)
        for fa in self.beds:
            for fb in self.beds:
                i += 1

                if verbose:
                    sys.stderr.write(
                            '%(i)s of %(total)s: %(fa)s + %(fb)s\n' % locals())
                    sys.stderr.flush()

                if not self.done(fa, fb, self.iterations):
                    self.run_and_insert(fa, fb, **kwargs)

                matrix[get_name(fa)][get_name(fb)] = \
                        self.get_row(fa, fb, self.iterations)

        return matrix

    def print_matrix(self, matrix, key):
        """
        Prints a pairwise matrix of values. `matrix` is a dict-of-dicts from
        create_matrix(), and `key` is a field name from the database -- one of:

        ['filea', 'fileb', 'timestamp', 'actual', 'median', 'iterations',
        'self', 'other', 'fractionabove', 'fractionbelow', 'percentile']
        """


########NEW FILE########
__FILENAME__ = plotting
import os
from collections import defaultdict
import matplotlib
from matplotlib import collections
from matplotlib import pyplot as plt
import numpy as np
import pybedtools


class Track(collections.PolyCollection):
    def __init__(self, features, chrom=None, ybase=0, yheight=1,
            visibility='dense', stranded=True, **kwargs):
        """
        Subclass of matplotlib's PolyCollection that can be added to an Axes.

        :param features:
            Can be an existing BedTool, or anything than can be used to create
            a BedTool (e.g., a filename or a generator of Interval objects)

        :param ybase:
            y-coord of the bottom edge of the track (in data coordinates)

        :param yheight:
            How high each feature will be, in data coordinates

        :param visibility:
            Mimics the settings in the UCSC Genome Browser:

            * "dense" is the default; overlapping features can be seen if you
              set alpha < 1.

            * "squish" prevents adjacent features from overlapping.  This keeps
              `yheight` for all features, so if you have a lot of features
              piling up, the track will be a lot higher on the y-axis than
              `yheight`.

        :param stranded:
            If boolean and True, will draw arrrow-shaped features to indicate
            direction (where the point is 10% of the total gene length)

            If a dictionary, map strands to colors, e.g., {'+': 'r', '-': 'b'}.

        :param kwargs:
            Additional keyword args are passed to
            matplotlib.collections.PolyCollection.

        Notes:

        After creating a track, use the `ymax` attribute to get the max y-value
        used in the track -- useful if you've created a "squish" track but
        would like to stack another track on top, and need to calculate what
        the new Track's `ybase` should be.

        The returned PolyCollection will have the `features` attribute, which
        contains the BedTool it was created from -- so you can write callback
        functions for event handling, e.g.::

            def callback(event):
                '''
                prints the feature's line when clicked in the plot
                '''
                coll = event.artist
                for i in event.ind:
                    print coll.features[i]

            fig.canvas.mpl_connect('on_pick', callback)


        >>> a = pybedtools.example_bedtool('a.bed')
        >>> track = pybedtools.contrib.plotting.Track(a, alpha=0.5, picker=5)
        >>> import matplotlib.pyplot as plt
        >>> fig = plt.figure()
        >>> ax = fig.add_subplot(111)
        >>> ax.add_collection(track) #doctest: +ELLIPSIS
        <pybedtools.contrib.plotting.Track object at 0x...>
        >>> limits = ax.axis('tight')
        """
        if isinstance(features, pybedtools.BedTool)\
                and isinstance(features.fn, basestring):
            self.features = features
        else:
            self.features = pybedtools.BedTool(features).saveas()
        self._visibility = visibility
        self._ybase = ybase
        self._yheight = yheight
        self.stranded = stranded
        self._check_stranded_dict()
        facecolors = self._colors()
        kwargs.update(dict(facecolors=facecolors))
        collections.PolyCollection.__init__(
                self, verts=self._get_verts(), **kwargs)

    def _shape(self, feature, ybase, yheight):
        if self.stranded and not isinstance(self.stranded, dict):
            offset = len(feature) * 0.1
            if feature.strand == '-':
                return [
                        (feature.stop, ybase),
                        (feature.stop, ybase + yheight),
                        (feature.start + offset, ybase + yheight),
                        (feature.start, ybase + yheight * 0.5),
                        (feature.start + offset, ybase)
                        ]

            elif feature.strand == '+':
                return [
                        (feature.start, ybase),
                        (feature.start, ybase + yheight),
                        (feature.stop - offset, ybase + yheight),
                        (feature.stop, ybase + yheight * 0.5),
                        (feature.stop - offset, ybase)
                        ]
        return [
                (feature.start, ybase),
                (feature.start, ybase + yheight),
                (feature.stop, ybase + yheight),
                (feature.stop, ybase)
                ]

    def _get_verts(self):
        verts = []

        if self._visibility == 'dense':
            for feature in self.features:
                verts.append(self._shape(feature, self._ybase, self._yheight))
            self.ymax = self._ybase + self._yheight

        if self._visibility == 'squish':
            # Using "squish" mode will create multiple "strata" of features.
            # The stack keeps track of the end coord of the longest feature in
            # each strata
            #
            # Reasonably efficient -- <2s to plot 15K multiply-overlapping
            # features
            stack = []
            ybase = self._ybase
            self.ymax = self._ybase + self._yheight
            for feature in self.features:
                ybase = None
                for i, s in enumerate(stack):
                    if feature.start > s:
                        ybase = self._ybase + i * self._yheight
                        stack[i] = feature.stop
                        break
                if ybase is None:
                    ybase = self._ybase + len(stack) * self._yheight
                    stack.append(feature.end)
                verts.append(self._shape(feature, ybase, self._yheight))
            self.ymax = self._ybase + len(stack) * self._yheight

        return verts

    def _check_stranded_dict(self):
        if not isinstance(self.stranded, dict):
            return True
        if '+' not in self.stranded:
            raise ValueError('stranded dict "%s" does not have required '
                    'key "+"' % self.stranded)
        if '-' not in self.stranded:
            raise ValueError('stranded dict "%s" does not have required '
                    'key "-"' % self.stranded)
        return True

    def _colors(self):
        if not isinstance(self.stranded, dict):
            return None
        colors = []
        for feature in self.features:
            try:
                colors.append(self.stranded[feature.strand])
            except KeyError:
                raise KeyError('strand color dict "%s" does not have a key '
                        'for strand "%s"' % (self.stranded, feature.strand))
        return colors

    def get_xlims(self, ax):
        """
        Needs `ax` to convert to transData coords
        """
        bb = self.get_datalim(ax.transData)
        return (bb.xmin, bb.xmax)

    @property
    def midpoint(self):
        return self._ybase + (self.ymax - self._ybase) / 2.0


class BinaryHeatmap(object):
    """
    Class-based version of the `binary_heatmap` function for more flexibility.
    """

    def __init__(self, bts, names):
        self.bts = bts
        self.names = names

        # Be flexible about input types
        _bts = []
        for bt in bts:
            if isinstance(bt, pybedtools.BedTool):
                if not isinstance(bt.fn, basestring):
                    bt = bt.saveas()
                _bts.append(bt.fn)
            elif isinstance(bt, basestring):
                _bts.append(bt)

        # Do the multi-intersection.
        self.results = pybedtools.BedTool().multi_intersect(
                i=_bts,
                names=names,
                cluster=True)

        # If 4 files were provided with labels 'a', 'b', 'c', and 'd, each line
        # would look something like:
        #
        #   chr2L    65716    65765    4    a,b,c,d    1    1    1    1
        #   chr2L    71986    72326    1    c          0    0    1    0
        #
        # The last four columns will become the matrix; save the class labels (5th
        # column) for a printed out report
        self.class_counts = defaultdict(int)
        _classified_intervals = defaultdict(list)
        self.matrix = []
        for item in self.results:
            cls = item[4]
            self.class_counts[cls] += 1
            self.matrix.append(item[5:])
            _classified_intervals[cls].append(item)

        self.classified_intervals = {}
        for k, v in _classified_intervals.items():
            self.classified_intervals[k] = pybedtools.BedTool(v)

        self.matrix = np.array(self.matrix, dtype=int)
        self.sort_ind = sort_binary_matrix(self.matrix)

    def plot(self, ax=None):
        if ax is None:
            fig = plt.figure(figsize=(3, 10))
            ax = fig.add_subplot(111)
        # matplotlib.cm.binary: 1 = black, 0 = white; force origin='upper' so
        # that array's [0,0] is in the upper left corner.
        mappable = ax.imshow(self.matrix[self.sort_ind], aspect='auto', interpolation='nearest',
                cmap=matplotlib.cm.binary, origin='upper')
        ax.set_xticks(range(len(self.names)))
        ax.set_xticklabels(self.names, rotation=90)
        if ax is None:
            fig.subplots_adjust(left=0.25)
        return ax


def binary_heatmap(bts, names, plot=True, cluster=True):
    """
    Plots a "binary heatmap", showing the results of a multi-intersection.

    Each row is a different genomic region found in at least one of the input
    BedTools; each column represents a different file.  Black indicates whether
    a feature was found at that particular site.  Rows with black all the way
    across indicates that all features were colocalized at those sites.

    `bts` is an iterable of BedTool objects or filenames; `names` is a list of
    labels to use in the plot and is exactly the same length as `bts`.

    If `plot=True`, then plot the sorted, labeled matrix with matplotlib.

    Returns (summary, m) where `summary` is a dictionary summarizing the
    results and `m` is the sorted NumPy array.  See source for further details.
    """
    bh = BinaryHeatmap(bts=bts, names=names)
    if plot:
        bh.plot()

    return bh.class_counts, bh.matrix


def sort_binary_matrix(m):
    """
    Performs a column-weighted sort on a binary matrix, returning the new index
    """
    # To impart some order in the matrix, give columns increasingly higher
    # weights...
    weights = [2 ** i for i in range(1, m.shape[1] + 1)[::-1]]

    # ...then create scores...
    score_mat = m * weights

    # ...and re-sort the matrix based on row sums (reversed so that highest
    # scores are on top)
    ind = np.argsort(score_mat.sum(axis=1))[::-1]
    return ind


def binary_summary(d):
    """
    Convenience function useful printing the results from binary_heatmap().
    """
    s = []
    for item in sorted(d.items(), key=lambda x: x[1], reverse=True):
        s.append('%s : %s' % (item))
    return '\n'.join(s)


class TrackCollection(object):
    def __init__(self, config, yheight=1, figsize=None, padding=0.1):
        """
        Handles multiple tracks on the same figure.

        :param config:
            A list of tuples that configures tracks.

            Each tuple contains a filename, BedTool object, or other
            iterable of pybedtools.Interval objects and a dictionary of
            keyword args that will be used to create a corresponding Track
            object, e.g.::

                [
                    ('a.bed',
                        dict(color='r', alpha=0.5, label='a')),
                    (BedTool('a.bed').intersect('b.bed'),
                        dict(color='g', label='b')),
                ]

            In this dictionary, do not specify `ybase`, since that will be
            handled for you.  Also do not specify `yheight` in these
            dictionaries -- `yheight` should be provided as a separate kwarg to
            so that the `padding` kwarg works correctly.

        :param figsize:
            Figure size tuple of (width, height), in inches.

        :param padding:
            Amount of padding to place in between tracks, as a fraction of
            `yheight`
        """
        self.config = config
        self.figsize = figsize
        self.yheight = yheight
        self.padding = padding

        for features, kwargs in self.config:
            if 'ybase' in kwargs:
                raise ValueError('Please do not specify "ybase"; this '
                'is handled automatically by the %s class' \
                        % self.__class__.__name__)
            if 'yheight' in kwargs:
                raise ValueError('Please do not specify "yheight", '
                        'this should be a separate arg to the %s '
                        'constructor' % self.__class__.__name__)

    def plot(self, ax=None):
        """
        If `ax` is None, create a new figure.  Otherwise, plot on `ax`.
        Iterates through the configuration, plotting each BedTool-like object
        as a separate track.
        """
        if ax is None:
            fig = plt.figure(figsize=self.figsize)
            ax = fig.add_subplot(111)
        yticks = []
        yticklabels = []
        ybase = 0
        i = 0
        padding = self.yheight * self.padding

        # Reverse config because incremental Track plotting works from bottom
        # up; this plots user-provided tracks in order from top down
        for features, kwargs in self.config[::-1]:
            t = Track(features, yheight=self.yheight, ybase=ybase, **kwargs)
            ybase = t.ymax + padding
            ax.add_collection(t)
            if 'label' in kwargs:
                yticklabels.append(kwargs['label'])
            else:
                yticklabels.append(str(i))
                i += 1
            yticks.append(t.midpoint)

        ax.set_yticks(yticks)
        ax.set_yticklabels(yticklabels)

        ax.axis('tight')
        return ax


class BedToolsDemo(TrackCollection):
    def __init__(self, config, method, data_path=None,
            result_kwargs=None, method_kwargs=None, title_kwargs=None,
            new_style=True, subplots_adjust=None, *args, **kwargs):
        """
        Class to handle BEDTools demos in a way that maintains flexibility.

        If the `config` list contains only one item, assume the method is one
        of the "-i" tools that only operate on one file.

        If the `config` list contains two items, then use the first as "-a" and
        the second as "-b".

        :param config:
            Either a list of (filename, options) tuples -- see docstring for
            TrackCollection for more info.

        :param method:
            Method of `BedTool` object to use, e.g., 'intersect'

        :param data_path:
            If not None, this path will be prepended to the files listed in
            `config`

        :param result_kwargs:
            Configuration for the results track.  This isn't added to the
            config list because the results haven't been created yet...

        :param method_kwargs:
            Keyword argument that are passed to the method, e.g., `u=True`

        :param title_kwargs:
            Keyword args for plot title (the text itself will come from the
            command that was run; this is for things like font size)

        :param new_style:
            Edit commands so that they use the "new style" BEDTools calls
            ("bedtools intersect" rather than "intersectBed")

        :param subplots_adjust:
            Additional kwargs sent to the figure's subplots_adjust() method,
            e.g., `dict(top=0.7)`


        :param args:
            Addtional arguments sent to TrackCollection

        :param kwargs:
            Additional keyword arguments sent to TrackCollection
        """
        if method_kwargs is None:
            method_kwargs = {}
        if result_kwargs is None:
            result_kwargs = {}
        if title_kwargs is None:
            title_kwargs = {}
        self.title_kwargs = title_kwargs
        self.new_style = new_style
        self.subplots_adjust = subplots_adjust

        # convert lists to tuples, cause we're going to edit the paths
        config = [list(i) for i in config]
        if data_path:
            for conf in config:
                if not isinstance(conf[0], basestring):
                    raise ValueError("data_path was specified, so you need "
                            "filenames in the config")
                conf[0] = os.path.join(data_path, conf[0])

        bt1 = pybedtools.BedTool(config[0][0])
        method = getattr(bt1, method)
        if len(config) == 2:
            result = method(config[1][0], **method_kwargs)
        elif len(config) == 1:
            result = method(**method_kwargs)
        else:
            raise ValueError("`config` must have length 1 (for '-i' tools) or "
                    "length 2 (for '-a -b' tools).")

        config.append((result, result_kwargs))
        self.result = result
        super(BedToolsDemo, self).__init__(config, *args, **kwargs)

    def plot(self, ax=None):
        ax = super(BedToolsDemo, self).plot(ax)
        cmds = self.result._cmds[:]
        if self.new_style:
            cmds[0] = "bedtools %s" \
                    % pybedtools.settings._prog_names[
                            os.path.basename(cmds[0])]
        ax.set_title(
                ' '.join([os.path.basename(i) for i in cmds]),
                **self.title_kwargs)
        if self.subplots_adjust:
            ax.figure.subplots_adjust(**self.subplots_adjust)
        return ax


class ConfiguredBedToolsDemo(BedToolsDemo):
    def __init__(self, yaml_config, method, method_kwargs, **kwargs):
        """
        Wrapper around BedToolsDemo class that reads in a YAML config file.
        Useful for using the same "style" configuration many times.

        Contents of `yaml_config` must be YAML versions of BedToolsDemo args
        and kwargs **except** `method` and `method_kwargs`.
        """
        import yaml
        conf = yaml.load(open(yaml_config))

        disallowed = ['method', 'method_kwargs']
        for dis in disallowed:
            if dis in conf:
                raise ValueError(
                        "'%s' cannot be provided in the YAML config" % dis)

        conf['method'] = method
        conf['method_kwargs'] = method_kwargs
        conf.update(kwargs)
        super(ConfiguredBedToolsDemo, self).__init__(**conf)


if __name__ == "__main__":
    """
    bts = [
            pybedtools.example_bedtool('BEAF_Kc_Bushey_2009.bed'),
            pybedtools.example_bedtool('CTCF_Kc_Bushey_2009.bed'),
            pybedtools.example_bedtool('Cp190_Kc_Bushey_2009.bed'),
            pybedtools.example_bedtool('SuHw_Kc_Bushey_2009.bed'),
        ]
    names = ['BEAF', 'CTCF', 'Cp190', 'Su(Hw)']

    #bts = [
    #        pybedtools.example_bedtool('a.bed'),
    #        pybedtools.example_bedtool('b.bed')]
    #names = ['a','b']
    d, m = binary_heatmap(bts, names)
    print binary_summary(d)
    """
    conf_file = pybedtools.example_filename('democonfig.yaml')
    data_path = pybedtools.example_filename("")  # dir name
    ax1 = ConfiguredBedToolsDemo(conf_file, method='intersect', method_kwargs={},
            data_path=data_path).plot()
    ax2 = ConfiguredBedToolsDemo(conf_file, method='intersect', method_kwargs=dict(u=True),
            data_path=data_path).plot()
    plt.show()

########NEW FILE########
__FILENAME__ = venn_maker
"""
Interface between pybedtools and the R package VennDiagram.

Rather than depend on the user to have rpy2 installed, this simply writes an
R script that can be edited and tweaked by the user before being run in R.
"""
import os
import string
import pybedtools
from pybedtools import helpers
import subprocess
from collections import OrderedDict

# really just fill in x and filename...leave the rest up to the user.
#
# Note that the closing parentheses is missing -- that's so the user can add
# kwargs from the calling function
template = string.Template("""
library(VennDiagram)
venn.diagram(
    x=$x,
    filename=$filename,
    category.names = $names
""")


def _list_to_R_syntax(x):
    """
    Convert items in `x` to a string, and replace tabs with pipes in Interval
    string representations.  Put everything into an R vector and return as one
    big string.
    """
    items = []
    for i in x:
        if isinstance(i, pybedtools.Interval):
            i = str(i).replace('\t', '|')
        items.append('"%s"' % i)
    return 'c(%s)' % ','.join(items)


def _dict_to_R_named_list(d):
    """
    Calls _list_to_R_syntax for each item.  Returns one big string.
    """
    items = []
    for key, val in d.items():
        items.append('"%s" = %s' % (key, _list_to_R_syntax(val)))
    return 'list(%s)' % ', '.join(items)


def truncator(feature):
    """
    Convert a feature of any format into a BED3 format.
    """
    return pybedtools.create_interval_from_list(
            [feature.chrom, str(feature.start), str(feature.stop)])


def cleaned_intersect(items):
    """
    Perform interval intersections such that the end products have identical \
    features for overlapping intervals.

    The VennDiagram package does *set* intersection, not *interval*
    intersection.  So the goal here is to represent intersecting intervals as
    intersecting sets of strings.

    Doing a simple BEDTools intersectBed call doesn't do the trick (even with
    the -u argument).  As a concrete example, what would the string be for an
    intersection of the feature "chr1:1-100" in file `x` and "chr1:50-200" in
    file `y`?

    The method used here is to substitute the intervals in `y` that overlap `x`
    with the corresponding elements in `x`.  This means that in the resulting
    sets, the overlapping features are identical.  To follow up with the
    example, both `x` and `y` would have an item "chr1:50-200" in their sets,
    simply indicating *that* one interval overlapped.

    Venn diagrams are not well suited for nested overlaps or multi-overlaps.
    To illustrate, try drawing the 2-way Venn diagram of the following two
    files. Specifically, what number goes in the middle -- the number of
    features in `x` that intersect `y` (1) or the number of features in `y`
    that intersect `x` (2)?::

        x:
            chr1  1  100
            chr1 500 6000

        y:
            chr1 50 100
            chr1 80 200
            chr9 777 888

    In this case, this function will return the following sets::

        x:
            chr1:1-100
            chr1:500-6000

        y:
            chr1:1-100
            chr9:777-888

    This means that while `x` does not change in length, `y` can.  For example,
    if there are 2 features in `x` that overlap one feature in `y`, then `y`
    will gain those two features in place of its single original feature.

    This strategy is extended for multiple intersections -- see the source for
    details.
    """
    if len(items) == 2:
        x = items[0].each(truncator).saveas()
        y = items[1].each(truncator).saveas()

        # Combine the unique-to-y intervals with the shared-with-x intervals.
        # Since x is first in x+y, resulting features are from x.
        new_y = (y - x).cat(x + y)
        return x, new_y

    if len(items) == 3:
        x = items[0].each(truncator).saveas()
        y = items[1].each(truncator).saveas()
        z = items[2].each(truncator).saveas()

        # Same as above.  Don't care about z yet; this means that y will not
        # change because of z.
        new_y = (y - x).cat(x + y)

        # Combine:
        #  unique-to-z
        #  shared-with-any-x
        #  shared-with-unique-to-y
        new_z = (z - y - x).cat(x + z).cat((y - x) + z)
        return x, new_y, new_z

    if len(items) == 4:
        x = items[0].each(truncator).saveas()
        y = items[1].each(truncator).saveas()
        z = items[2].each(truncator).saveas()
        q = items[3].each(truncator).saveas()

        # Same as 2-way
        new_y = (y - x).cat(x + y)

        # Same as 3-way
        new_z = (z - y - x).cat(x + z).cat((y - x) + z)

        # Combine:
        #  unique-to-q
        #  shared-with-any-x
        #  shared-with-unique-to-y
        #  shared-with-unique-to-z
        new_q = (q - z - y - x)\
                .cat(x + q)\
                .cat((y - x) + q)\
                .cat((z - y - x) + q)

        return x, new_y, new_z, new_q


def venn_maker(beds, names=None, figure_filename=None, script_filename=None,
        additional_args=None, run=False):
    """
    Given a list of interval files, write an R script to create a Venn \
    diagram of overlaps (and optionally run it).

    The R script calls the venn.diagram function of the R package VennDiagram
    for extremely flexible Venn and Euler diagram creation.  Uses
    `cleaned_intersect()` to create string representations of shared intervals.

    `beds` is a list of up to 4 filenames or BedTools.

    `names` is a list of names to use for the Venn diagram, in the same order
    as `beds`. Default is "abcd"[:len(beds)].

    `figure_filename` is the TIFF file to save the figure as.

    `script_filename` is the optional filename to write the R script to

    `additional_args` is list that will be inserted into the R script,
    verbatim.  For example, to use scaled Euler diagrams with different colors,
    use::

        additional_args = ['euler.d=TRUE',
                           'scaled=TRUE',
                           'cat.col=c("red","blue")']

    If `run` is True, then assume R is installed, is on the path, and has
    VennDiagram installed . . . and run the script.  The resulting filename
    will be saved as `figure_filename`.
    """

    if figure_filename is None:
        figure_filename = 'NULL'
    else:
        figure_filename = '"%s"' % figure_filename

    if names is None:
        names = "abcd"[:len(beds)]

    _beds = []
    for bed in beds:
        if not isinstance(bed, pybedtools.BedTool):
            bed = pybedtools.BedTool(bed)
        _beds.append(bed)

    cleaned = cleaned_intersect(_beds)
    results = OrderedDict(zip(names, cleaned))

    s = template.substitute(
            x=_dict_to_R_named_list(results),
            filename=figure_filename,
            names=_list_to_R_syntax(names))
    if additional_args:
        s += ',' + ', '.join(additional_args)

    s += ")"

    if not script_filename:
        fn = pybedtools.BedTool._tmp()
    else:
        fn = script_filename

    fout = open(fn, 'w')
    fout.write(s)
    fout.close()

    out = fn + '.Rout'
    if run:

        if not pybedtools.settings._R_installed:
            helpers._check_for_R()

        cmds = [os.path.join(pybedtools.settings._R_path, 'R'), 'CMD', 'BATCH',
                fn, out]
        p = subprocess.Popen(
                cmds, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        stdout, stderr = p.communicate()
        if stdout or stderr:
            print "stdout:", stdout
            print "stderr:", stderr

    if not script_filename:
        return s

    return None

########NEW FILE########
__FILENAME__ = genome_registry
"""
Chromsize dictionaries, as downloaded from UCSC.  Need more? Use::

    pybedtools.get_chromsizes_from_ucsc('assemblyname')

"""
# Figure out which version of OrderedDict we want....
import sys
if (sys.version_info[0] == 2) and (sys.version_info[1] < 7):
    from ordereddict import OrderedDict
else:
    from collections import OrderedDict


dm3 = OrderedDict((
    ('chr2L', (0, 23011544)),
    ('chr2R', (0, 21146708)),
    ('chr3L', (0, 24543557)),
    ('chr3R', (0, 27905053)),
    ('chr4', (0, 1351857)),
    ('chrX', (0, 22422827)),
    ('chr2LHet', (0, 368872)),
    ('chr2RHet', (0, 3288761)),
    ('chr3LHet', (0, 2555491)),
    ('chr3RHet', (0, 2517507)),
    ('chrM', (0, 19517)),
    ('chrU', (0, 10049037)),
    ('chrUextra', (0, 29004656)),
    ('chrXHet', (0, 204112)),
    ('chrYHet', (0, 347038)),
))

# No chrUextra or chrM
dm3.default = OrderedDict()
for chrom, size in dm3.items():
    if chrom in ['chrUextra', 'chrM']:
        continue
    dm3.default[chrom] = size

# No chrU*, chr*Het, or chrM
dm3.euchromatic = OrderedDict()
for chrom, size in dm3.default.items():
    if 'chrU' in chrom:
        continue
    if 'Het' in chrom:
        continue
    dm3.euchromatic[chrom] = size


mm9 = OrderedDict((
    ('chr1', (0, 197195432)),
    ('chr2', (0, 181748087)),
    ('chr3', (0, 159599783)),
    ('chr4', (0, 155630120)),
    ('chr5', (0, 152537259)),
    ('chr6', (0, 149517037)),
    ('chr7', (0, 152524553)),
    ('chr8', (0, 131738871)),
    ('chr9', (0, 124076172)),
    ('chr10', (0, 129993255)),
    ('chr11', (0, 121843856)),
    ('chr12', (0, 121257530)),
    ('chr13', (0, 120284312)),
    ('chr14', (0, 125194864)),
    ('chr15', (0, 103494974)),
    ('chr16', (0, 98319150)),
    ('chr17', (0, 95272651)),
    ('chr18', (0, 90772031)),
    ('chr19', (0, 61342430)),
    ('chrX', (0, 166650296)),
    ('chrY', (0, 15902555)),
    ('chrM', (0, 16299)),
    ('chr13_random', (0, 400311)),
    ('chr16_random', (0, 3994)),
    ('chr17_random', (0, 628739)),
    ('chr1_random', (0, 1231697)),
    ('chr3_random', (0, 41899)),
    ('chr4_random', (0, 160594)),
    ('chr5_random', (0, 357350)),
    ('chr7_random', (0, 362490)),
    ('chr8_random', (0, 849593)),
    ('chr9_random', (0, 449403)),
    ('chrUn_random', (0, 5900358)),
    ('chrX_random', (0, 1785075)),
    ('chrY_random', (0, 58682461)),
))

mm9.default = OrderedDict()
for chrom, size in mm9.items():
    if '_random' in chrom:
        continue
    if chrom == 'chrM':
        continue
    mm9.default[chrom] = size


hg18 = OrderedDict((
    ('chr1', (0, 247249719)),
    ('chr2', (0, 242951149)),
    ('chr3', (0, 199501827)),
    ('chr4', (0, 191273063)),
    ('chr5', (0, 180857866)),
    ('chr6', (0, 170899992)),
    ('chr7', (0, 158821424)),
    ('chr8', (0, 146274826)),
    ('chr9', (0, 140273252)),
    ('chr10', (0, 135374737)),
    ('chr11', (0, 134452384)),
    ('chr12', (0, 132349534)),
    ('chr13', (0, 114142980)),
    ('chr14', (0, 106368585)),
    ('chr15', (0, 100338915)),
    ('chr16', (0, 88827254)),
    ('chr17', (0, 78774742)),
    ('chr18', (0, 76117153)),
    ('chr19', (0, 63811651)),
    ('chr20', (0, 62435964)),
    ('chr21', (0, 46944323)),
    ('chr22', (0, 49691432)),
    ('chrX', (0, 154913754)),
    ('chrY', (0, 57772954)),
    ('chrM', (0, 16571)),
    ('chr10_random', (0, 113275)),
    ('chr11_random', (0, 215294)),
    ('chr13_random', (0, 186858)),
    ('chr15_random', (0, 784346)),
    ('chr16_random', (0, 105485)),
    ('chr17_random', (0, 2617613)),
    ('chr18_random', (0, 4262)),
    ('chr19_random', (0, 301858)),
    ('chr1_random', (0, 1663265)),
    ('chr21_random', (0, 1679693)),
    ('chr22_h2_hap1', (0, 63661)),
    ('chr22_random', (0, 257318)),
    ('chr2_random', (0, 185571)),
    ('chr3_random', (0, 749256)),
    ('chr4_random', (0, 842648)),
    ('chr5_h2_hap1', (0, 1794870)),
    ('chr5_random', (0, 143687)),
    ('chr6_cox_hap1', (0, 4731698)),
    ('chr6_qbl_hap2', (0, 4565931)),
    ('chr6_random', (0, 1875562)),
    ('chr7_random', (0, 549659)),
    ('chr8_random', (0, 943810)),
    ('chr9_random', (0, 1146434)),
    ('chrX_random', (0, 1719168)),
))

hg18.default = OrderedDict()
for chrom, size in hg18.items():
    if '_' in chrom:
        continue
    if chrom == 'chrM':
        continue
    hg18.default[chrom] = size


hg19 = OrderedDict((
    ('chr1', (0, 249250621)),
    ('chr2', (0, 243199373)),
    ('chr3', (0, 198022430)),
    ('chr4', (0, 191154276)),
    ('chr5', (0, 180915260)),
    ('chr6', (0, 171115067)),
    ('chr7', (0, 159138663)),
    ('chr8', (0, 146364022)),
    ('chr9', (0, 141213431)),
    ('chr10', (0, 135534747)),
    ('chr11', (0, 135006516)),
    ('chr12', (0, 133851895)),
    ('chr13', (0, 115169878)),
    ('chr14', (0, 107349540)),
    ('chr15', (0, 102531392)),
    ('chr16', (0, 90354753)),
    ('chr17', (0, 81195210)),
    ('chr18', (0, 78077248)),
    ('chr19', (0, 59128983)),
    ('chr20', (0, 63025520)),
    ('chr21', (0, 48129895)),
    ('chr22', (0, 51304566)),
    ('chrX', (0, 155270560)),
    ('chrY', (0, 59373566)),
    ('chrM', (0, 16571)),
    ('chr6_ssto_hap7', (0, 4928567)),
    ('chr6_mcf_hap5', (0, 4833398)),
    ('chr6_cox_hap2', (0, 4795371)),
    ('chr6_mann_hap4', (0, 4683263)),
    ('chr6_apd_hap1', (0, 4622290)),
    ('chr6_qbl_hap6', (0, 4611984)),
    ('chr6_dbb_hap3', (0, 4610396)),
    ('chr17_ctg5_hap1', (0, 1680828)),
    ('chr4_ctg9_hap1', (0, 590426)),
    ('chr1_gl000192_random', (0, 547496)),
    ('chrUn_gl000225', (0, 211173)),
    ('chr4_gl000194_random', (0, 191469)),
    ('chr4_gl000193_random', (0, 189789)),
    ('chr9_gl000200_random', (0, 187035)),
    ('chrUn_gl000222', (0, 186861)),
    ('chrUn_gl000212', (0, 186858)),
    ('chr7_gl000195_random', (0, 182896)),
    ('chrUn_gl000223', (0, 180455)),
    ('chrUn_gl000224', (0, 179693)),
    ('chrUn_gl000219', (0, 179198)),
    ('chr17_gl000205_random', (0, 174588)),
    ('chrUn_gl000215', (0, 172545)),
    ('chrUn_gl000216', (0, 172294)),
    ('chrUn_gl000217', (0, 172149)),
    ('chr9_gl000199_random', (0, 169874)),
    ('chrUn_gl000211', (0, 166566)),
    ('chrUn_gl000213', (0, 164239)),
    ('chrUn_gl000220', (0, 161802)),
    ('chrUn_gl000218', (0, 161147)),
    ('chr19_gl000209_random', (0, 159169)),
    ('chrUn_gl000221', (0, 155397)),
    ('chrUn_gl000214', (0, 137718)),
    ('chrUn_gl000228', (0, 129120)),
    ('chrUn_gl000227', (0, 128374)),
    ('chr1_gl000191_random', (0, 106433)),
    ('chr19_gl000208_random', (0, 92689)),
    ('chr9_gl000198_random', (0, 90085)),
    ('chr17_gl000204_random', (0, 81310)),
    ('chrUn_gl000233', (0, 45941)),
    ('chrUn_gl000237', (0, 45867)),
    ('chrUn_gl000230', (0, 43691)),
    ('chrUn_gl000242', (0, 43523)),
    ('chrUn_gl000243', (0, 43341)),
    ('chrUn_gl000241', (0, 42152)),
    ('chrUn_gl000236', (0, 41934)),
    ('chrUn_gl000240', (0, 41933)),
    ('chr17_gl000206_random', (0, 41001)),
    ('chrUn_gl000232', (0, 40652)),
    ('chrUn_gl000234', (0, 40531)),
    ('chr11_gl000202_random', (0, 40103)),
    ('chrUn_gl000238', (0, 39939)),
    ('chrUn_gl000244', (0, 39929)),
    ('chrUn_gl000248', (0, 39786)),
    ('chr8_gl000196_random', (0, 38914)),
    ('chrUn_gl000249', (0, 38502)),
    ('chrUn_gl000246', (0, 38154)),
    ('chr17_gl000203_random', (0, 37498)),
    ('chr8_gl000197_random', (0, 37175)),
    ('chrUn_gl000245', (0, 36651)),
    ('chrUn_gl000247', (0, 36422)),
    ('chr9_gl000201_random', (0, 36148)),
    ('chrUn_gl000235', (0, 34474)),
    ('chrUn_gl000239', (0, 33824)),
    ('chr21_gl000210_random', (0, 27682)),
    ('chrUn_gl000231', (0, 27386)),
    ('chrUn_gl000229', (0, 19913)),
    ('chrUn_gl000226', (0, 15008)),
    ('chr18_gl000207_random', (0, 4262)),
))

hg19.default = OrderedDict()
for chrom, size in hg19.items():
    if '_' in chrom:
        continue
    if chrom == 'chrM':
        continue
    hg19.default[chrom] = size

########NEW FILE########
__FILENAME__ = helpers
import sys
import os
import tempfile
import subprocess
import random
import string
import glob
import struct
import atexit
import pybedtools

import settings

BUFSIZE = 1

_tags = {}


def _check_for_bedtools(program_to_check='intersectBed', force_check=False):
    """
    Checks installation as well as version (based on whether or not "bedtools
    intersect" works, or just "intersectBed")
    """
    if settings._bedtools_installed and not force_check:
        return True

    try:
        p = subprocess.Popen(
            [os.path.join(settings._bedtools_path, 'bedtools'),
             settings._prog_names[program_to_check]],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        settings._bedtools_installed = True
        settings._v_2_15_plus = True

    except (OSError, KeyError) as err:

        try:
            p = subprocess.Popen(
                [os.path.join(settings._bedtools_path, program_to_check)],
                stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            settings._bedtools_installed = True
            settings._v_2_15_plus = False

        except OSError as err:
            if err.errno == 2:
                if settings._bedtools_path:
                    add_msg = "(tried path '%s')" % settings._bedtools_path
                else:
                    add_msg = ""
                raise OSError("Please make sure you have installed BEDTools"
                              "(https://github.com/arq5x/bedtools) and that "
                              "it's on the path. %s" % add_msg)


def _check_for_tabix():
    try:
        p = subprocess.Popen(
            [os.path.join(settings._tabix_path, 'tabix')],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        stdout, stderr = p.communicate()
        settings._tabix_installed = True
    except OSError:
        if settings._tabix_path:
            add_msg = "(tried path '%s')" % settings._tabix_path
        else:
            add_msg = ""
        raise ValueError(
            'Please install tabix and ensure it is on your path %s'
            % add_msg)


def _check_for_samtools():
    try:
        p = subprocess.Popen(
            [os.path.join(settings._samtools_path, 'samtools')],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        settings._samtools_installed = True
    except OSError:
        if settings._samtools_path:
            add_msg = "(tried path '%s')" % settings._samtools_path
        else:
            add_msg = ""
        raise ValueError(
            'Please install samtools and ensure it is on your path %s'
            % add_msg)


def _check_for_R():
    try:
        p = subprocess.Popen(
            [os.path.join(settings._R_path, 'R'), '--version'],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        settings._R_installed = True
    except OSError:
        if settings._R_path:
            add_msg = "(tried path '%s')" % settings._R_path
        else:
            add_msg = ""
        raise ValueError(
            'Please install R and ensure it is on your path %s' % add_msg)


class Error(Exception):
    """Base class for this module's exceptions"""
    pass


class BEDToolsError(Error):
    def __init__(self, cmd, msg):
        self.cmd = str(cmd)
        self.msg = str(msg)

    def __str__(self):
        m = '\nCommand was:\n\n\t' + self.cmd + '\n' + \
            '\nError message was:\n' + self.msg
        return m


def isBGZIP(fn):
    """
    Reads a filename to see if it's a BGZIPed file or not.
    """
    header_str = open(fn).read(15)
    if len(header_str) < 15:
        return False

    header = struct.unpack_from('BBBBiBBHBBB', header_str)

    id1, id2, cm, flg, mtime, xfl, os_, xlen, si1, si2, slen = header
    if (id1 == 31) and (id2 == 139) and (cm == 8) and (flg == 4) and \
       (si1 == 66) and (si2 == 67) and (slen == 2):
        return True
    return False


def isBAM(fn):
    if not isBGZIP(fn):
        return False

    # Need to differentiate between BAM and plain 'ol BGZIP. Try reading header
    # . . .
    if not settings._samtools_installed:
        _check_for_samtools()

    cmds = ['samtools', 'view', '-H', fn]
    try:

        # Silence the output, we want to check the return code
        with open(os.devnull, "w") as out:
            subprocess.check_call(cmds, stdout=out, stderr=out)
        return True

    except subprocess.CalledProcessError:
        # Non-0 return code, it means we have an error
        return False

    except OSError:
        raise OSError(
            'SAMtools (http://samtools.sourceforge.net/) '
            'needs to be installed for BAM support')


def find_tagged(tag):
    """
    Returns the bedtool object with tagged with *tag*.  Useful for tracking
    down bedtools you made previously.
    """
    for key, item in _tags.iteritems():
        try:
            if item._tag == tag:
                return item
        except AttributeError:
            pass
    raise ValueError('tag "%s" not found' % tag)


def _flatten_list(x):
    nested = True
    while nested:
        check_again = False
        flattened = []

        for element in x:
            if isinstance(element, list):
                flattened.extend(element)
                check_again = True
            else:
                flattened.append(element)
        nested = check_again
        x = flattened[:]
    return x


class History(list):
    def __init__(self):
        """
        Represents one or many HistorySteps.  Mostly used for nicely formatting
        a series of HistorySteps.
        """
        list.__init__(self)


class HistoryStep(object):
    def __init__(self, method, args, kwargs, bedtool_instance,
                 parent_tag, result_tag):
        """
        Class to represent one step in the history.

        Mostly used for its __repr__ method, to try and exactly replicate code
        that can be pasted to re-do history steps
        """
        try:
            self.method = method._name
        except AttributeError:
            self.method = method.func_name
        self.args = args
        self.kwargs = kwargs
        self.fn = bedtool_instance.fn
        tag = ''.join(random.choice(string.lowercase) for _ in xrange(8))
        self.parent_tag = parent_tag
        self.result_tag = result_tag

    def _clean_arg(self, arg):
        """
        Wrap strings in quotes and convert bedtool instances to filenames.
        """
        if isinstance(arg, pybedtools.BedTool):
            arg = arg.fn
        if isinstance(arg, basestring):
            arg = '"%s"' % arg
        return arg

    def __repr__(self):
        # Still not sure whether to use pybedtools.bedtool() or bedtool()
        s = ''
        s += '<HistoryStep> '
        if os.path.exists(self.fn):
            s += 'BedTool("%(fn)s").%(method)s(%%s%%s)' % self.__dict__
        else:
            s += 'BedTool("MISSING FILE: %(fn)s")' % self.__dict__
            s += '.%(method)s(%%s%%s)' % self.__dict__

        # Format args and kwargs
        args_string = ','.join(map(self._clean_arg, self.args))
        kwargs_string = ','.join(
            ['%s=%s' % (i[0], self._clean_arg(i[1]))
             for i in self.kwargs.items()])
        # stick a comma on the end if there's something here
        if len(args_string) > 0:
            args_string += ', '

        s = s % (args_string, kwargs_string)
        s += ', parent tag: %s' % self.parent_tag
        s += ', result tag: %s' % self.result_tag
        return s


def set_tempdir(tempdir):
    """
    Set the directory for temp files.

    Useful for clusters that use a /scratch partition rather than a /tmp dir.
    Convenience function to simply set tempfile.tempdir.
    """
    if not os.path.exists(tempdir):
        errstr = 'The tempdir you specified, %s, does not exist' % tempdir
        raise ValueError(errstr)
    tempfile.tempdir = tempdir


def get_tempdir():
    """
    Gets the current tempdir for the module.
    """
    return tempfile.gettempdir()


def cleanup(verbose=False, remove_all=False):
    """
    Deletes all temp files from the current session (or optionally *all* \
            sessions)

    If *verbose*, reports what it's doing

    If *remove_all*, then ALL files matching "pybedtools.*.tmp" in the temp dir
    will be deleted.
    """
    if settings.KEEP_TEMPFILES:
        return
    for fn in pybedtools.BedTool.TEMPFILES:
        if verbose:
            print 'removing', fn
        if os.path.exists(fn):
            os.unlink(fn)
    if remove_all:
        fns = glob.glob(os.path.join(get_tempdir(), 'pybedtools.*.tmp'))
        for fn in fns:
            os.unlink(fn)


def _version_2_15_plus_names(prog_name):
    if not settings._bedtools_installed:
        _check_for_bedtools()
    if not settings._v_2_15_plus:
        return [prog_name]
    try:
        prog_name = settings._prog_names[prog_name]
    except KeyError:
        if prog_name in settings._new_names:
            pass
        raise BEDToolsError(
            prog_name, prog_name + 'not a recognized BEDTools program')
    return [os.path.join(settings._bedtools_path, 'bedtools'), prog_name]


def call_bedtools(cmds, tmpfn=None, stdin=None, check_stderr=None):
    """
    Use subprocess.Popen to call BEDTools and catch any errors.

    Output goes to *tmpfn*, or, if None, output stays in subprocess.PIPE and
    can be iterated over.

    *stdin* is an optional file-like object that will be sent to
    subprocess.Popen.

    Prints some useful help upon getting common errors.

    *check_stderr* is a function that takes the stderr string as input and
    returns True if it's OK (that is, it's not really an error).  This is
    needed, e.g., for calling fastaFromBed which will report that it has to
    make a .fai for a fasta file.
    """
    input_is_stream = stdin is not None
    output_is_stream = tmpfn is None

    _orig_cmds = cmds[:]
    cmds = []
    cmds.extend(_version_2_15_plus_names(_orig_cmds[0]))
    cmds.extend(_orig_cmds[1:])

    try:
        # coming from an iterator, sending as iterator
        if input_is_stream and output_is_stream:
            pybedtools.logger.debug(
                'helpers.call_bedtools(): input is stream, output is '
                'stream')
            pybedtools.logger.debug(
                'helpers.call_bedtools(): cmds=%s', ' '.join(cmds))
            p = subprocess.Popen(cmds,
                                 stdout=subprocess.PIPE,
                                 stderr=subprocess.PIPE,
                                 stdin=subprocess.PIPE,
                                 bufsize=BUFSIZE)
            for line in stdin:
                p.stdin.write(line)

            # This is important to prevent deadlocks
            p.stdin.close()

            output = p.stdout
            stderr = None

        # coming from an iterator, writing to file
        if input_is_stream and not output_is_stream:
            pybedtools.logger.debug(
                'helpers.call_bedtools(): input is stream, output is file')
            pybedtools.logger.debug(
                'helpers.call_bedtools(): cmds=%s', ' '.join(cmds))
            outfile = open(tmpfn, 'w')
            p = subprocess.Popen(cmds,
                                 stdout=outfile,
                                 stderr=subprocess.PIPE,
                                 stdin=subprocess.PIPE,
                                 bufsize=BUFSIZE)
            if isinstance(stdin, file):
                stdout, stderr = p.communicate(stdin.read())
            else:
                for item in stdin:
                    p.stdin.write(item)
                stdout, stderr = p.communicate()
            output = tmpfn
            outfile.close()

        # coming from a file, sending as iterator
        if not input_is_stream and output_is_stream:
            pybedtools.logger.debug(
                'helpers.call_bedtools(): input is filename, '
                'output is stream')
            pybedtools.logger.debug(
                'helpers.call_bedtools(): cmds=%s', ' '.join(cmds))
            p = subprocess.Popen(cmds,
                                 stdout=subprocess.PIPE,
                                 stderr=subprocess.PIPE,
                                 bufsize=BUFSIZE)
            output = p.stdout
            stderr = None

        # file-to-file
        if not input_is_stream and not output_is_stream:
            pybedtools.logger.debug(
                'helpers.call_bedtools(): input is filename, output '
                'is filename (%s)', tmpfn)
            pybedtools.logger.debug(
                'helpers.call_bedtools(): cmds=%s', ' '.join(cmds))
            outfile = open(tmpfn, 'w')
            p = subprocess.Popen(cmds,
                                 stdout=outfile,
                                 stderr=subprocess.PIPE,
                                 bufsize=BUFSIZE)
            stdout, stderr = p.communicate()
            output = tmpfn
            outfile.close()

        # Check if it's OK using a provided function to check stderr. If it's
        # OK, dump it to sys.stderr so it's printed, and reset it to None so we
        # don't raise an exception
        if check_stderr is not None:
            if check_stderr(stderr):
                sys.stderr.write(stderr)
                stderr = None

        if stderr:
            raise BEDToolsError(subprocess.list2cmdline(cmds), stderr)

    except (OSError, IOError) as err:
        print '%s: %s' % (type(err), os.strerror(err.errno))
        print 'The command was:\n\n\t%s\n' % subprocess.list2cmdline(cmds)

        problems = {
            2: ('* Did you spell the command correctly?',
                '* Do you have BEDTools installed and on the path?'),
            13: ('* Do you have permission to write '
                 'to the output file ("%s")?' % tmpfn,),
            24: ('* Too many files open -- please submit '
                 'a bug report so that this can be fixed',)
        }

        print 'Things to check:'
        print '\n\t' + '\n\t'.join(problems[err.errno])
        raise OSError('See above for commands that gave the error')

    return output


def set_bedtools_path(path=""):
    """
    Explicitly set path to `BEDTools` installation dir.

    If BEDTools is not available on your system path, specify the path to the
    dir containing the BEDTools executables (intersectBed, subtractBed, etc)
    with this function.

    To reset and use the default system path, call this function with no
    arguments or use path="".
    """
    settings._bedtools_path = path


def set_samtools_path(path=""):
    """
    Explicitly set path to `samtools` installation dir.

    If samtools is not available on the path, then it can be explicitly
    specified here.

    Use path="" to reset to default system path.
    """
    settings._samtools_path = path


def set_tabix_path(path=""):
    """
    Explicitly set path to `tabix` installation dir.

    If tabix is not available on the path, then it can be explicitly
    specified here.

    Use path="" to reset to default system path.
    """
    settings._tabix_path = path


def set_R_path(path=""):
    """
    Explicitly set path to `R` installation dir.

    If R is not available on the path, then it can be explicitly
    specified here.

    Use path="" to reset to default system path.
    """
    settings._R_path = path


def _check_sequence_stderr(x):
    """
    If stderr created by fastaFromBed starst with 'index file', then don't
    consider it an error.
    """
    if x.startswith('index file'):
        return True
    if x.startswith("WARNING"):
        return True
    return False


def _call_randomintersect(_self, other, iterations, intersect_kwargs,
                          shuffle_kwargs, report_iterations, debug,
                          _orig_processes):
    """
    Helper function that list-ifies the output from randomintersection, s.t.
    it can be pickled across a multiprocess Pool.
    """
    return list(
        _self.randomintersection(
            other, iterations,
            intersect_kwargs=intersect_kwargs,
            shuffle_kwargs=shuffle_kwargs,
            report_iterations=report_iterations,
            debug=False, processes=None,
            _orig_processes=_orig_processes)
    )


def close_or_delete(*args):
    """
    Single function that can be used to get rid of a BedTool, whether it's a
    streaming or file-based version.
    """
    for x in args:
        if isinstance(x.fn, basestring):
            os.unlink(x.fn)
        elif hasattr(x.fn, 'close'):
            x.fn.close()
        if hasattr(x.fn, 'throw'):
            x.fn.throw(StopIteration)

def _jaccard_output_to_dict(s, **kwargs):
    """
    jaccard method doesn't return an interval file, rather, it returns a short
    summary of results.  Here, we simply parse it into a dict for convenience.
    """
    if isinstance(s, basestring):
        s = open(s).read()
    if hasattr(s, 'next'):
        s = ''.join(i for i in s)
    header, data = s.splitlines()
    header = header.split()
    data = data.split()
    data[0] = int(data[0])
    data[1] = int(data[1])
    data[2] = float(data[2])
    data[3] = int(data[3])
    return dict(zip(header, data))


def _reldist_output_handler(s, **kwargs):
    """
    reldist, if called with -detail, returns a valid BED file with the relative
    distance as the last field.  In that case, return the BedTool immediately.
    If not -detail, then the results are a table, in which case here we parse
    into a dict for convenience.
    """
    if 'detail' in kwargs:
        return pybedtools.BedTool(s)
    if isinstance(s, basestring):
        iterable = open(s)
    if hasattr(s, 'next'):
        iterable = s
    header = iterable.next().split()
    results = {}
    for h in header:
        results[h] = []
    for i in iterable:
        reldist, count, total, fraction = i.split()
        data = [
            float(reldist),
            int(count),
            int(total),
            float(fraction)
        ]
        for h, d in zip(header, data):
            results[h].append(d)
    return results


def n_open_fds():
    pid = os.getpid()
    procs = subprocess.check_output(
        ['lsof', '-w', '-Ff', '-p', str(pid)])
    nprocs = 0
    for i in procs.splitlines():
        if i[1:].isdigit() and i[0] == 'f':
            nprocs += 1
    return nprocs


import re
coord_re = re.compile(
    r"""
    (?P<chrom>.+):
    (?P<start>\d+)-
    (?P<stop>\d+)
    (?:\[(?P<strand>.)\])?""", re.VERBOSE)


def string_to_interval(s):
    """
    Convert string of the form "chrom:start-stop" or "chrom:start-stop[strand]"
    to an interval.

    Assumes zero-based coords.

    If it's already an interval, then return it as-is.
    """
    if isinstance(s, basestring):
        m = coord_re.search(s)
        if m.group('strand'):
            return pybedtools.create_interval_from_list([
                m.group('chrom'),
                m.group('start'),
                m.group('stop'),
                '.',
                '0',
                m.group('strand')])
        else:
            return pybedtools.create_interval_from_list([
                m.group('chrom'),
                m.group('start'),
                m.group('stop'),
            ])
    return s

atexit.register(cleanup)

########NEW FILE########
__FILENAME__ = parallel
import sys
import multiprocessing
import helpers
import pybedtools


def _parallel_wrap(orig_bedtool, shuffle_kwargs, genome_fn, method,
                   method_args, method_kwargs, sort=False, shuffle=True,
                   reduce_func=None):
    """
    Given a BedTool object `orig_bedtool`, call its `method` with `args` and
    `kwargs` and then call `reduce_func` on the results.

    See parallel_apply docstring for details

    """

    # note: be careful about cleaning up tempfiles
    if not shuffle:
        to_use = orig_bedtool
    else:
        shuffled = orig_bedtool.shuffle(g=genome_fn, **shuffle_kwargs)
        if sort:
            to_use = shuffled.sort()
            helpers.close_or_delete(shuffled)
        else:
            to_use = shuffled

    result = getattr(to_use, method)(*method_args, **method_kwargs)

    if shuffle:
        helpers.close_or_delete(to_use)

    if reduce_func:
        reduced = reduce_func(result)
        if isinstance(result, pybedtools.BedTool):
            helpers.close_or_delete(result)
        return reduced
    else:
        return result


def parallel_apply(orig_bedtool, method, genome=None, genome_fn=None,
                   method_args=None, method_kwargs=None, shuffle_kwargs=None,
                   shuffle=True, reduce_func=None, processes=1, sort=False,
                   _orig_pool=None, iterations=1000, debug=False,
                   report_iterations=False):
    """
    Call an arbitrary BedTool method many times in parallel.

    An example use-case is to generate a null distribution of intersections,
    and then compare this to the actual intersections::

        >>> # set up example BedTools
        >>> a = pybedtools.example_bedtool('a.bed')
        >>> b = pybedtools.example_bedtool('b.bed')

        >>> #Method of `a` to call:
        >>> method = 'intersect'

        >>> # Kwargs provided to `a.intersect` each iteration
        >>> method_kwargs = dict(b=b, u=True)

        >>> # Function that will be called on the results of
        >>> # `a.intersect(**method_kwargs)`.
        >>> def reduce_func(x):
        ...     return sum(1 for _ in open(x.fn))

    **Important:** due to a known file handle leak in BedTool.__len__, it's
    best to simply check the number of lines in the file, as in the above
    function. This works because BEDTools programs strip any non-interval lines
    in the results.

        >>> # Create a small artificial genome for this test (generally you'd
        >>> # use an assembly name, like "hg19"):
        >>> genome = dict(chr1=(0, 1000))

        >>> # Do 10 iterations using 1 process for this test (generally you'd
        >>> # use 1000+ iterations, and as many processes as you have CPUs)
        >>> results = parallel_apply(a, method, genome=genome,
        ... method_kwargs=method_kwargs, iterations=10, processes=1,
        ... reduce_func=reduce_func, debug=True, report_iterations=True)

        >>> # get results
        >>> print list(results)
        [2, 2, 3, 0, 3, 3, 0, 0, 2, 4]

    We can compare this to the actual intersection:

        >>> reduce_func(a.intersect(**method_kwargs))
        3

    Alternatively, we could use the `a.jaccard` method, which already does the
    reduction to a dictionary.  However, the Jaccard method requires the input
    to be sorted.  Here, we specify `sort=True` to sort each shuffled BedTool
    before calling its `jaccard` method.

        >>> from pybedtools.parallel import parallel_apply
        >>> results = parallel_apply(a, method='jaccard', method_args=(b,),
        ... genome=genome, iterations=3, processes=1, sort=True, debug=True)
        >>> for i in results:
        ...     print sorted(i.items())
        [('intersection', 15), ('jaccard', 0.0238095), ('n_intersections', 2), ('union-intersection', 630)]
        [('intersection', 15), ('jaccard', 0.0238095), ('n_intersections', 2), ('union-intersection', 630)]
        [('intersection', 45), ('jaccard', 0.0818182), ('n_intersections', 1), ('union-intersection', 550)]

    Parameters
    ----------
    orig_bedtool : BedTool

    method : str
        The method of `orig_bedtool` to run

    method_args : tuple
        Passed directly to getattr(orig_bedtool, method)()

    method_kwargs : dict
        Passed directly to getattr(orig_bedtool, method)()

    shuffle : bool
        If True, then `orig_bedtool` will be shuffled at each iteration and
        that shuffled version's `method` will be called with `method_args` and
        `method_kwargs`.

    shuffle_kwargs : dict
        If `shuffle` is True, these are passed to `orig_bedtool.shuffle()`.
        You do not need to pass the genome here; that's handled separately by
        the `genome` and `genome_fn` kwargs.

    iterations : int
        Number of iterations to perform

    genome : string or dict
        If string, then assume it is the assembly name (e.g., hg19) and get
        a dictionary of chromsizes for that assembly, then converts to a filename.

    genome_fn : str
        Mutually exclusive with `genome`; `genome_fn` must be an existing
        filename with the chromsizes.  Use the `genome` kwarg instead if you'd
        rather supply an assembly or dict.

    reduce_func : callable
        Function or other callable object that accepts, as its only argument,
        the results from `orig_bedtool.method()`.  For example, if you care
        about the number of results, then you can use `reduce_func=len`.

    processes : int
        Number of processes to run.  If `processes=1`, then multiprocessing is
        not used (making it much easier to debug).  This argument is ignored if
        `_orig_pool` is provided.

    sort : bool
        If both `shuffle` and `sort` are True, then the shuffled BedTool will
        then be sorted.  Use this if `method` requires sorted input.

    _orig_pool : multiprocessing.Pool instance
        If provided, uses `_orig_pool` instead of creating one.  In this case,
        `processes` will be ignored.

    debug : bool
        If True, then use the current iteration index as the seed to shuffle.

    report_iterations : bool
        If True, then report the number of iterations to stderr.
    """

    shuffle_kwargs = shuffle_kwargs or {}
    method_args = method_args or ()
    method_kwargs = method_kwargs or {}

    if genome_fn and genome:
        raise ValueError("only of of genome_fn or genome should be provided")

    if shuffle:
        if not genome_fn:
            if not genome:
                raise ValueError("shuffle=True, so either genome_fn"
                                 " or genome must be provided")
            genome_fn = pybedtools.chromsizes_to_file(genome)

    _parallel_wrap_kwargs = dict(
        orig_bedtool=orig_bedtool,
        shuffle_kwargs=shuffle_kwargs,
        genome_fn=genome_fn,
        method=method,
        method_args=method_args,
        method_kwargs=method_kwargs,
        shuffle=shuffle,
        reduce_func=reduce_func,
        sort=sort,
    )

    def add_seed(i, kwargs):
        if debug and shuffle:
            kwargs['shuffle_kwargs']['seed'] = i
        return kwargs

    if processes == 1:
        for it in range(iterations):
            yield _parallel_wrap(**add_seed(it, _parallel_wrap_kwargs))
        raise StopIteration

    if _orig_pool:
        p = _orig_pool
    else:
        p = multiprocessing.Pool(processes)

    results = [
        p.apply_async(_parallel_wrap, (), add_seed(it, _parallel_wrap_kwargs))
        for it in range(iterations)]
    for i, r in enumerate(results):
        yield r.get()
        if report_iterations:
            sys.stderr.write('%s\r' % i)
            sys.stderr.flush()
    raise StopIteration

########NEW FILE########
__FILENAME__ = annotate
"""
annotate a file with the neearest features in another.

    %prog [options]

if --upstream and --downstream are not specified only 2 colummns are
added to the [a] file: nearest_name, nearest_distance.
if they are specified upstream_names, downstream_names are specified.
if --report-distance is included, the format will be:

   gene:dist,gene2:dist2

for each of the up and downstream columns.
"""

import argparse
import sys
from pybedtools import BedTool
from pybedtools.cbedtools import Attributes
import collections

# PYTHONPATH=$PYTHONPATH:. python scripts/annotate.py -a data/new.regions.bed
# -b data/Homo_sapiens.hg18.gtf --upstream 5000

# $ pybedtools annotate -a regions.bed -b knownGene.bed --upstream 10000
#                  --downstream 5000 --report-distance
# a bed: regions.bed and another:
# annotation.bed, it would add 4 columns to regions.bed:
# nearest-feature, nearest-distance, upstream-features, downstream-features
# where the up/downstream features are determined by a distance
# parameter, e.g. like --upstream 10000 --downstream 5000


def get_gff_name(field):
    attrs = Attributes(field)
    for key in ("ID", "gene_name", "transcript_id", "gene_id", "Parent"):
        if key in attrs:
            return attrs[key]


def gen_get_name(b, afields):
    btype = b.file_type
    if btype == "bed":
        get_name = lambda fields: fields[afields + 3]
    elif btype == "gff":
        def get_name(fields):
            return get_gff_name(fields[afields + 7])
    else:
        raise Exception("not implemented")
    return get_name


def add_closest(aname, bname):
    a, b = BedTool(aname), BedTool(bname)

    afields = a.field_count()
    c = a.closest(b, d=True)
    get_name = gen_get_name(b, afields)

    dbed = open(BedTool._tmp(), "w")
    # keep the name and distance
    seen_by_line = collections.defaultdict(list)
    for feat in c:
        key = "\t".join(feat[:afields])
        seen_by_line[key].append([feat[-1], get_name(feat)])

    for key, dist_names in seen_by_line.iteritems():
        if len(dist_names) > 0:
            assert len(set([d[0] for d in dist_names])) == 1
        names = ",".join(sorted(set(d[1] for d in dist_names)))
        new_line = "\t".join([key] + [names] + [dist_names[0][0]])
        dbed.write(new_line + "\n")
    dbed.close()
    d = BedTool(dbed.name)
    assert len(d) == len(a)
    return d


def add_xstream(a, b, dist, updown, report_distance=False):
    # run a window up or downstream.
    dir = dict(up="l", down="r")[updown]
    kwargs = {'sw': True, dir: dist}

    # have to set the other to 0
    if "l" in kwargs:
        kwargs["r"] = 0
    else:
        kwargs["l"] = 0

    c = a.window(b, **kwargs)
    afields = a.field_count()

    get_name = gen_get_name(b, afields)

    seen = collections.defaultdict(set)
    # condense to unique names.
    for row in c:
        key = "\t".join(row[:afields])
        seen[key].update([get_name(row)])

    d = open(BedTool._tmp(), "w")
    for row in seen:
        d.write(row + "\t" + ",".join(sorted(seen[row])) + "\n")

    # write the entries that did not appear in the window'ed Bed
    for row in a:
        key = "\t".join(row[:afields])
        if key in seen:
            continue
        d.write(str(row) + "\t.\n")

    d.close()
    dbed = BedTool(d.name)
    assert len(dbed) == len(a)
    return dbed


def main():
    """
    annotate a file with the neearest features in another.
    """
    p = argparse.ArgumentParser(description=__doc__, prog=sys.argv[0])
    p.add_argument("-a", dest="a", help="file to annotate")
    p.add_argument("-b", dest="b", help="file with annotations")
    p.add_argument("--upstream", dest="upstream", type=int, default=None,
                   help="distance upstream of [a] to look for [b]")
    p.add_argument("--downstream", dest="downstream", type=int, default=None,
                   help="distance downstream of [a] to look for [b]")
    p.add_argument("--report-distance", dest="report_distance", default=False,
                   help="report the distance, not just the genes",
                   action="store_true")
    args = p.parse_args()
    if (args.a is None or args.b is None):
        sys.exit(not p.print_help())

    c = add_closest(args.a, args.b)
    b = BedTool(args.b)
    # TODO: support --report-distance for up/downstream.
    if args.upstream:
        c = add_xstream(c, b, args.upstream, "up", args.report_distance)
    if args.downstream:
        c = add_xstream(c, b, args.downstream, "down",
                        args.report_distance)

    for row in c.sort():
        print(row)

if __name__ == "__main__":
    import doctest
    if doctest.testmod(optionflags=doctest.ELLIPSIS).failed == 0:
        main()

########NEW FILE########
__FILENAME__ = pbt_plotting_example
import time
import os
import pybedtools
from pybedtools.contrib import plotting
from matplotlib import pyplot as plt

colors = ['r', 'b', 'g']


def plot_a_b_tool(a, b, method, **kwargs):
    """
    Use for BEDTools programs that use -a and -b input arguments.  Filenames
    `a` and `b` are used for `method` of the BedTool class, and `kwargs` are
    sent to that method.

    The result is a plot of `a`, `b`, and the result, with the commandline
    argument as the plot title.
    """
    a = pybedtools.BedTool(a)
    b = pybedtools.BedTool(b)
    kwargs['b'] = b
    result = getattr(a, method)(**kwargs)

    fig = plt.figure(figsize=(8, 2))
    ax = fig.add_subplot(111)
    ybase = 0
    yheight = 1
    ylabels = []
    yticks = []
    for color, bt, label in zip(
            colors,
            [result, b, a],
            ['result', os.path.basename(b.fn), os.path.basename(a.fn)]):
        ylabels.append(label)
        track = plotting.Track(
                bt, visibility='squish', alpha=0.5, ybase=ybase, color=color)
        yticks.append(track.midpoint)
        ybase = track.ymax + 0.1
        ax.add_collection(track)
    ax.set_yticklabels(ylabels)
    ax.set_yticks(yticks)
    ax.set_title(' '.join([os.path.basename(i) for i in result._cmds]))
    ax.axis('tight')
    fig.subplots_adjust(top=0.8, bottom=0.15)
    return ax


def plot_i_tool(i, method, **kwargs):
    a = pybedtools.BedTool(i)
    result = getattr(a, method)(**kwargs)
    fig = plt.figure(figsize=(8, 2))
    ax = fig.add_subplot(111)
    res_track = plotting.Track(result, color='r', alpha=0.5, ybase=0, visibility='squish')
    a_track = plotting.Track(a, color='b', alpha=0.5, ybase=1.1, visibility='squish')
    ax.add_collection(res_track)
    ax.add_collection(a_track)
    ax.set_yticks([res_track.midpoint, a_track.midpoint])
    ax.set_yticklabels(['result', os.path.basename(a.fn)])
    ax.axis('tight')
    ax.set_title(' '.join([os.path.basename(k) for k in result._cmds]))
    fig.subplots_adjust(top=0.8, bottom=0.15)
    return ax




if __name__ == "__main__":
    a = pybedtools.example_filename('a.bed')
    b = pybedtools.example_filename('b.bed')

    plot_a_b_tool(a, b, 'intersect', u=True)
    plot_a_b_tool(a, b, 'intersect')
    plot_a_b_tool(a, b, 'subtract')

    plot_i_tool(a, 'merge')



    # Check performance -- should be <2s for 15k features
    t0 = time.time()
    fig = plt.figure(figsize=(8,2))
    ax = fig.add_subplot(111)
    big = pybedtools.example_bedtool('dm3-chr2L-5M.gff.gz')
    gene_track = plotting.Track(
            big.filter(lambda x: x[2] == 'gene'),
            color='k', visibility='squish', alpha=0.5, label='genes')
    exon_track = plotting.Track(
            big.filter(lambda x: x[2] == 'exon'),
            color='r', visibility='squish', alpha=0.5, ybase=gene_track.ymax,
            label='exons')
    ax.add_collection(gene_track)
    ax.add_collection(exon_track)

    ax.legend(loc='best')
    ax.axis('tight')

    print'%.2fs' % (time.time() - t0)


    plt.show()

########NEW FILE########
__FILENAME__ = intersection_matrix
#!/usr/bin/python
"""
Create a matrix of many pairwise intersections; see \
:mod:`pybedtools.contrib.IntersectionMatrix` for more flexibility
"""

import collections
import time
import sys
import os.path as op
import argparse
import pybedtools
from pybedtools import BedTool, example_filename

usage = """

    Send in a list of `N` bed files, and this script will create an N by
    N matrix of their intersections, or optionally, co-localization scores.

    Run the example with::

        %s --test > matrix.txt

    You can then plot a quick heatmap in R with::

        > m = as.matrix(read.table("matrix.txt"))
        > heatmap(m)

""" % sys.argv[0]


def get_name(fname):
    return op.splitext(op.basename(fname))[0]


def actual_intersection(a, b):
    return len(a.intersect(b, u=True))


def frac_of_a(a, b):
    len_a = float(len(a))
    return len(a.intersect(b, u=True)) / len_a


def enrichment_score(a, b, genome_fn, iterations=None, processes=None):
    results = a\
            .randomstats(b, new=True, genome_fn=genome_fn, iterations=iterations, processes=processes)
    return (results['actual'] + 1) / (results['median randomized'] + 1)


def create_matrix(beds, func, verbose=False, **kwargs):
    nfiles = len(beds)
    total = nfiles ** 2
    i = 0
    matrix = collections.defaultdict(dict)
    for fa in beds:
        a = BedTool(fa)
        for fb in beds:
            i += 1
            b = BedTool(fb)

            if verbose:
                sys.stderr.write(
                        '%(i)s of %(total)s: %(fa)s + %(fb)s\n' % locals())
                sys.stderr.flush()

            matrix[get_name(fa)][get_name(fb)] = func(a, b, **kwargs)

    return matrix


def main():
    """
    Creates a pairwise matrix containing overlapping feature counts for many
    BED files
    """
    ap = argparse.ArgumentParser(usage=usage)
    ap.add_argument('beds', nargs="*", help='BED/GTF/GFF/VCF filenames, e.g., '
                    'in a directory of bed files, you can use *.bed')
    ap.add_argument('--frac', action='store_true',
                    help='Instead of counts, report fraction overlapped')
    ap.add_argument('--enrichment', action='store_true',
                    help='Run randomizations (default 1000, specify otherwise '
                    'with --iterations) on each pairwise comparison and '
                    'compute the enrichment score as '
                    '(actual intersection count + 1) / (median randomized + 1)'
                    )
    ap.add_argument('--genome', help='Required argument if --enrichment is '
                    'used. Needs to be a string assembly name like "dm3" or '
                    '"hg19"')
    ap.add_argument('--iterations', default=1000, type=int,
                    help='Number of randomizations to perform for enrichement '
                    'scores')
    ap.add_argument('--processes', default=None, type=int,
                    help='Number of CPUs to use for randomization')
    ap.add_argument('--test', action='store_true', help='Ignore any input BED '
                    'files and use test BED files')
    ap.add_argument('-v', '--verbose', action='store_true',
                    help='Be verbose: print which files are '
                    'currently being intersected and timing info at the end.')
    args = ap.parse_args()

    if not args.beds and not args.test:
        ap.print_help()
        sys.exit(1)

    if args.test:
        # insulator binding sites from ChIP-chip -- 4 proteins, 2 cell types
        # Genes Dev. 2009 23(11):1338-1350
        args.beds = [example_filename(i) for i in  [
                'Cp190_Kc_Bushey_2009.bed',
                'Cp190_Mbn2_Bushey_2009.bed',
                'CTCF_Kc_Bushey_2009.bed',
                'CTCF_Mbn2_Bushey_2009.bed',
                'SuHw_Kc_Bushey_2009.bed',
                'SuHw_Mbn2_Bushey_2009.bed',
                'BEAF_Mbn2_Bushey_2009.bed',
                'BEAF_Kc_Bushey_2009.bed'
                ]]

    if args.enrichment:
        FUNC = enrichment_score
        genome_fn = pybedtools.chromsizes_to_file(pybedtools.chromsizes(args.genome))
        kwargs = dict(genome_fn=genome_fn, iterations=args.iterations,
                processes=args.processes)

    elif args.frac:
        FUNC = frac_of_a
        kwargs = {}
    else:
        FUNC = actual_intersection
        kwargs = {}

    t0 = time.time()
    matrix = create_matrix(beds=args.beds, func=FUNC, verbose=args.verbose, **kwargs)
    t1 = time.time()

    nfiles = len(args.beds)

    if args.verbose:
        sys.stderr.write('Time to construct %s x %s matrix: %.1fs' \
                % (nfiles, nfiles, (t1 - t0)) + '\n')
    keys = sorted(matrix.keys())

    sys.stdout.write("\t" + "\t".join(keys) + '\n')
    for k in keys:
        sys.stdout.write(k)
        for j in keys:
            sys.stdout.write('\t' + str(matrix[k][j]))
        sys.stdout.write('\n')

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = intron_exon_reads
#!/usr/bin/env python

"""
Example from pybedtools documentation (:ref:`third example`) to count \
reads in introns and exons using multiple CPUs.
"""

import pybedtools
import argparse
import os
import sys
import multiprocessing


def featuretype_filter(feature, featuretype):
    """
    Only passes features with the specified *featuretype*
    """
    if feature[2] == featuretype:
        return True
    return False


def subset_featuretypes(featuretype):
    return g.filter(featuretype_filter, featuretype).saveas()


def count_reads_in_features(features):
    """
    Callback function to count reads in features
    """
    return features.intersect(abam=bam,
                             b=features.fn,
                             s=stranded,
                             bed=True,
                             stream=True).count()


def main():
    """
    Third quick example from the documentation -- count reads introns and
    exons, in parallel
    """
    ap = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]),
                                 usage=__doc__)
    ap.add_argument('--gff', required=True,
                    help='GFF or GTF file containing annotations')
    ap.add_argument('--bam', required=True,
                    help='BAM file containing reads to be counted')
    ap.add_argument('--stranded', action='store_true',
                    help='Use strand-specific merging and overlap. '
                         'Default is to ignore strand')
    ap.add_argument('--no-parallel', dest='noparallel', action='store_true',
                    help='Disables parallel computation')
    ap.add_argument('-o', '--output',
                    help='Optional file to which results will be written; '
                         'default is stdout')
    ap.add_argument('-v', '--verbose', action='store_true',
                    help='Verbose (goes to stderr)')
    args = ap.parse_args()

    gff = args.gff
    bam = args.bam
    stranded = args.stranded
    parallel = not args.noparallel

    # Some GFF files have invalid entries -- like chromosomes with negative
    # coords or features of length = 0.  This line removes them and saves the
    # result in a tempfile
    g = pybedtools.BedTool(gff).remove_invalid().saveas()

    # Decide which version of map to use.  If parallel, we only need 3
    # processes.
    pool = multiprocessing.Pool(processes=3)

    # Get separate files for introns and exons in parallel (if specified)
    featuretypes = ('intron', 'exon')
    introns, exons = pool.map(subset_featuretypes, featuretypes)

    # Perform some genome algebra to get unique and shared regions
    exon_only = exons.subtract(introns).merge().remove_invalid().saveas()
    intron_only = introns.subtract(exons).merge().remove_invalid().saveas()
    intron_and_exon = exons\
            .intersect(introns).merge().remove_invalid().saveas()

    # Do intersections with BAM file in parallel
    features = (exon_only, intron_only, intron_and_exon)
    results = pool.map(count_reads_in_features, features)

    labels = ('      exon only:',
              '    intron only:',
              'intron and exon:')

    for label, reads in zip(labels, results):
        print '%s %s' % (label, reads)

    pybedtools.cleanup(verbose=False)

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = peak_pie
#!/usr/bin/env python
"""
Make a pie chart where peaks fall in annotations; see \
:mod:`pybedtools.contrib.Classifier` for more flexibility.

The results here are similar to CEAS (http://liulab.dfci.harvard.edu/CEAS/).

However, multi-featuretype classes are reported.  That is, if a peak falls in
an exon in one isoform and an intron in another isoform, the class is "exon,
intron".
"""

import sys
import urllib
import urllib2
import argparse
import pybedtools
from collections import defaultdict


def make_pie(bed, gff, stranded=False, out='out.png',
             include=None, exclude=None, thresh=0):

    a = pybedtools.BedTool(bed)
    b = pybedtools.BedTool(gff).remove_invalid()

    c = a.intersect(b,
                    wao=True,
                    s=stranded,
                    stream=True)

    # So we can grab just `a` features later...
    afields = a.field_count()

    # Where we can find the featuretype in the -wao output.  Assumes GFF.
    type_idx = afields + 2

    # 3 different code paths depending on include/exclude to cut down on
    # if/else checks.
    #
    # For un-included featuretypes, put them in the '.' category (unnannotated)
    if include and exclude:
        raise ValueError('Can only specify one of `include` or `exclude`.')
    d = defaultdict(set)
    if include:
        for feature in c:
            featuretype = feature[type_idx]
            key = '\t'.join(feature[:afields])
            if featuretype in include:
                d[key].update([featuretype])
            else:
                d[key].update(['.'])
    elif exclude:
        for feature in c:
            featuretype = feature[type_idx]
            key = '\t'.join(feature[:afields])
            if featuretype not in exclude:
                d[key].update([featuretype])
            else:
                d[key].update(['.'])
    else:
        for feature in c:
            featuretype = feature[type_idx]
            key = '\t'.join(feature[:afields])
            d[key].update([featuretype])

    def labelmaker(x):
        x.difference_update('.')
        label = []
        for i in list(x):
            if i == 'three_prime_UTR':
                i = "3' UTR"
            if i == 'five_prime_UTR':
                i = "5' UTR"
            label.append(i)
        return ', '.join(sorted(label))

    # Prepare results for Google Charts API
    npeaks = float(len(d))
    count_d = defaultdict(int)
    for peak, featuretypes in d.items():
        if featuretypes == set('.'):
            featuretype = 'unannotated'
        else:
            featuretype = labelmaker(featuretypes)
        count_d[featuretype] += 1

    results = count_d.items()
    results.sort(key=lambda x: x[1])
    labels, counts = zip(*results)

    labels = []
    counts_to_use = []
    for label, count in results:
        perc = count / npeaks * 100
        if perc > thresh:
            labels.append('%s: %s (%.1f%%)' % (label,
                                               count,
                                               perc))
            counts_to_use.append(perc)

    # Set up the Gchart data
    data = {'cht': 'p',
            'chs': '750x350',
            'chd': 't:' + ','.join(map(str, counts_to_use)),
            'chl': '|'.join(labels)}

    # Encode it correctly
    encoded_data = urllib.urlencode(data)

    # Send request and get data; write to file
    url = 'https://chart.googleapis.com/chart?'
    req = urllib2.Request(url, encoded_data)
    response = urllib2.urlopen(req)
    f = open(out, 'w')
    f.write(response.read())
    f.close()


def main():
    """
    Make a pie chart of features overlapping annotations (e.g., peaks in
    introns, exons, etc)
    """
    ap = argparse.ArgumentParser(description=__doc__,
                          formatter_class=argparse.RawDescriptionHelpFormatter)
    ap.add_argument('--bed', help='BED file of e.g. peaks')
    ap.add_argument('--gff', help='GFF file of e.g. annotations')
    ap.add_argument('--out', default='out.png', help='Output PNG file')
    ap.add_argument('--stranded', action='store_true',
                    help='Use strand-specific intersections')
    ap.add_argument('--include', nargs='*', help='Featuretypes to include')
    ap.add_argument('--exclude', nargs='*', help='Featuretypes to exclude')
    ap.add_argument('--thresh', type=float,
                    help='Threshold percentage below which output will be '
                    'suppressed')
    ap.add_argument('--test', action='store_true',
                    help='Run test, overwriting all other args. Result will '
                    'be "out.png" in current directory.')
    args = ap.parse_args()

    if not (args.bed and args.gff) and not args.test:
        ap.print_help()
        sys.exit(1)

    if not args.test:
        if args.include and args.exclude:
            raise ValueError('Cannot specify both --include and --exclude')

        make_pie(bed=args.bed,
                 gff=args.gff,
                 out=args.out,
                 thresh=args.thresh,
                 stranded=args.stranded,
                 include=args.include,
                 exclude=args.exclude)
    else:
        make_pie(bed=pybedtools.example_filename('gdc.bed'),
                 gff=pybedtools.example_filename('gdc.gff'),
                 stranded=True,
                 out='out.png',
                 include=['exon',
                          'CDS',
                          'intron',
                          'five_prime_UTR',
                          'three_prime_UTR'])


if __name__ == "__main__":
    import doctest
    if doctest.testmod(optionflags=doctest.ELLIPSIS).failed == 0:
        main()

########NEW FILE########
__FILENAME__ = pybedtools_demo
#!/usr/bin/python

"""
Example pybedtools usage; please read script and comments for more info
"""
from pybedtools import BedTool
import pybedtools
import os
import time


def main():
    """
    Quick demo of some pybedtools functionality
    """

    print """

    Quick demo of some pybedtools functionality

    """

    # In order to locate files on disk, this script uses pybedtools'
    # example_filename() method to locate filenames of example data.
    #
    # To save space, example data only consists of the parts needed for this
    # script to run

    # has genes from chr1 and chr21
    gff_fn = pybedtools.example_filename('hg19.gff')

    # dbSNP 128, all of chr21 and first part of chr1
    snps_fn = pybedtools.example_filename('snps.bed.gz')

    # chr21 sequence
    fasta_fn = pybedtools.example_filename('chr21.fa')

    # tiny BAM file
    bam_fn = pybedtools.example_filename('reads.bam')

    # a couple of example exons
    exon_fn = pybedtools.example_filename('exons.gff')

    # subset and sequences will be saved as tempfiles that won't get
    # auto-deleted
    subset_fn = os.path.join(pybedtools.tempfile.gettempdir(),
                          'chr21-genes-with-snps.gff')
    seq_fn = os.path.join(pybedtools.tempfile.gettempdir(),
                          'chr21-genes-with-snps.fa')

    genes = pybedtools.example_bedtool(gff_fn)
    snps = pybedtools.example_bedtool(snps_fn)

    print '''
    Using files:
        genes:%(gff_fn)s
        snps:%(snps_fn)s
        fasta:%(fasta_fn)s
        bam:%(bam_fn)s
        exons:%(exon_fn)s
    ''' % locals()

    print 'Intersecting genes with SNPs...'
    genes_with_snps = genes.intersect(snps, u=True)
    for g in genes_with_snps[:5]:
        print g.chrom, g.start, g.end, len(g)
    print '... (only showing 5)'
    print

    def chrom_filt(g):
        return g.chrom == 'chr21'

    print 'Subsetting on chr21...',
    subset = genes_with_snps.filter(chrom_filt)
    subset = subset.saveas(subset_fn)
    print '(check saved results in "%s")' % subset_fn
    print

    print 'Extracting sequences...',
    subset.sequence(fasta_fn).\
           save_seqs(seq_fn)
    print '(check sequences in "%s")' % seq_fn
    print

    print 'Finding closest genes to intergenic SNPs...'
    intergenic_snps = (snps - genes)
    nearby = genes.closest(intergenic_snps,
                           d=True,
                           stream=True)

    # set a limit; only show 5 nearby genes.
    limit = 4
    for i, gene in enumerate(nearby):
        if i > limit:
            break
        if int(gene[-1]) < 5000:
            print gene.name
    print '... (only showing 5)'
    print

    t0 = time.time()

    reads = pybedtools.BedTool(bam_fn)
    exons = pybedtools.BedTool(exon_fn)
    on_target = reads.intersect(exons)

    print 'Coverage bedGraph of reads...'
    bedgraph = reads.genome_coverage(genome='hg19',
                                     bg=True)
    for feature in bedgraph[:5]:
        print feature
    print '... (only showing 5)'
    print

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = py_ms_example
#!/usr/bin/python
"""
Example from the manuscript; see sh_ms_example.sh for the shell script \
equivalent.

Prints the names of genes that are <5000 bp away from intergenic SNPs.
"""
from os import path
from pybedtools import BedTool


def main():
    """
    Runs Python example from the manuscript
    """
    bedtools_dir = path.split(__file__)[0]
    snps = BedTool(path.join(bedtools_dir, '../test/data/snps.bed.gz'))
    genes = BedTool(path.join(bedtools_dir, '../test/data/hg19.gff'))

    intergenic_snps = (snps - genes)

    nearby = genes.closest(intergenic_snps, d=True, stream=True)

    for gene in nearby:
        if int(gene[-1]) < 5000:
            print gene.name

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = venn_gchart
#!/usr/bin/env python
"""
Given 3 files, creates a 3-way Venn diagram of intersections using the Google \
Chart API; see :mod:`pybedtools.contrib.venn_maker` for more flexibility.

The values in the diagram assume:

    * unstranded intersections
    * no features that are nested inside larger features
"""

import argparse
import sys
import pybedtools
import urllib
import urllib2


def venn_gchart(a, b, c=None, colors=None, labels=None, size='300x300'):
    """
    a, b, and c are filenames to BED-like files.

    *colors* is a list of 3 hex colors

    *labels* is a list of 3 labels

    *outfn* is the output PNG you want to create.

    *size* is the size in pixels for the PNG
    """
    a = pybedtools.BedTool(a)
    b = pybedtools.BedTool(b)
    if c:
        c = pybedtools.BedTool(c)

    # The order of values is meaningful to the API, see
    # http://code.google.com/apis/chart/docs/gallery/venn_charts.html
    if c:
        vals = [len(a),
                len(b),
                len(c),
                len(a + b),
                len(a + c),
                len(b + c),
                len(a + b + c)]
    else:
        # insert 0 for size of 3rd circle.
        vals = [len(a), len(b), 0, len(a + b)]
        labels = labels[:2]
    # API doesn't seem to like large numbers, so get fractions instead, then
    # join make a comma-separated list of values.
    mx = float(max(vals))
    vals = [i / mx for i in vals]
    valstr = ','.join(map(str, vals))

    data = {'cht': 'v',
            'chs': size,
            'chd': 't:' + valstr}

    # Add the optional data, if specified
    if labels:
        data['chdl'] = '|'.join(labels)
    if colors:
        data['chco'] = ','.join(colors)
    return data


def gchart(data, outfn='out.png'):
    """
    Sends data to Google Chart API
    """
    data = urllib.urlencode(data)

    url = 'https://chart.googleapis.com/chart?'

    # Request and get the PNG
    req = urllib2.Request(url, data)
    print url + data
    response = urllib2.urlopen(req)
    f = open(outfn, 'w')
    f.write(response.read())
    f.close()


def main():
    """Create a 3-way Venn diagram using Google Charts API
    """

    op = argparse.ArgumentParser(description=__doc__, prog=sys.argv[0])
    op.add_argument('-a', help='File to use for the left-most circle')
    op.add_argument('-b', help='File to use for the right-most circle')
    op.add_argument('-c', help='File to use for the bottom circle')
    op.add_argument('--colors', help='Optional comma-separated list of hex '
                    'colors for circles a, b, and c.  E.g. %(default)s',
                     default='00FF00,FF0000,0000FF')
    op.add_argument('--labels',
            help='Optional comma-separated list of labels for a, b, and c',
                    default='a,b,c')
    op.add_argument('--size', default='300x300',
                  help='Optional size of PNG, in pixels.  Default is '
                  '"%(default)s"')
    op.add_argument('-o', default='out.png',
                  help='Output file to save as, in PNG format')
    op.add_argument('--test', action='store_true',
            help='run test, overriding all other options.')
    options = op.parse_args()

    reqd_args = ['a', 'b']
    if not options.test:
        for ra in reqd_args:
            if not getattr(options, ra):
                op.print_help()
                sys.stderr.write('Missing required arg "%s"\n' % ra)
                sys.exit(1)

    if options.test:
        # Example data
        pybedtools.bedtool.random.seed(1)
        a = pybedtools.example_bedtool('rmsk.hg18.chr21.small.bed')
        b = pybedtools.example_bedtool('venn.b.bed')
        c = pybedtools.example_bedtool('venn.c.bed')
        options.a = a.fn
        options.b = b.fn
        options.c = c.fn
        options.colors = '00FF00,FF0000,0000FF'
        options.o = 'out.png'
        options.labels = 'a,b,c'

    data = venn_gchart(a=options.a, b=options.b, c=options.c,
                       colors=options.colors.split(','),
                       labels=options.labels.split(','),
                       size=options.size)
    gchart(data, outfn=options.o)

if __name__ == "__main__":
    import doctest
    if doctest.testmod(optionflags=doctest.ELLIPSIS).failed == 0:
        main()

########NEW FILE########
__FILENAME__ = venn_mpl
#!/usr/bin/env python
"""
Given 3 files, creates a 3-way Venn diagram of intersections using matplotlib; \
see :mod:`pybedtools.contrib.venn_maker` for more flexibility.

Numbers are placed on the diagram.  If you don't have matplotlib installed.
try venn_gchart.py to use the Google Chart API instead.

The values in the diagram assume:

    * unstranded intersections
    * no features that are nested inside larger features
"""

import argparse
import sys
import os
import pybedtools

def venn_mpl(a, b, c, colors=None, outfn='out.png', labels=None):
    """
    *a*, *b*, and *c* are filenames to BED-like files.

    *colors* is a list of matplotlib colors for the Venn diagram circles.

    *outfn* is the resulting output file.  This is passed directly to
    fig.savefig(), so you can supply extensions of .png, .pdf, or whatever your
    matplotlib installation supports.

    *labels* is a list of labels to use for each of the files; by default the
    labels are ['a','b','c']
    """
    try:
        import matplotlib.pyplot as plt
        from matplotlib.patches import Circle
    except ImportError:
        sys.stderr.write('matplotlib is required to make a Venn diagram with %s\n' % os.path.basename(sys.argv[0]))
        sys.exit(1)

    a = pybedtools.BedTool(a)
    b = pybedtools.BedTool(b)
    c = pybedtools.BedTool(c)

    if colors is None:
        colors = ['r','b','g']

    radius = 6.0
    center = 0.0
    offset = radius / 2

    if labels is None:
        labels = ['a','b','c']

    circle_a = Circle(xy = (center-offset, center+offset), radius=radius, edgecolor=colors[0], label=labels[0])
    circle_b = Circle(xy = (center+offset, center+offset), radius=radius, edgecolor=colors[1], label=labels[1])
    circle_c = Circle(xy = (center,        center-offset), radius=radius, edgecolor=colors[2], label=labels[2])


    fig = plt.figure(facecolor='w')
    ax = fig.add_subplot(111)

    for circle in (circle_a, circle_b, circle_c):
        circle.set_facecolor('none')
        circle.set_linewidth(3)
        ax.add_patch(circle)

    ax.axis('tight')
    ax.axis('equal')
    ax.set_axis_off()


    kwargs = dict(horizontalalignment='center')

    # Unique to A
    ax.text( center-2*offset, center+offset, str((a - b - c).count()), **kwargs)

    # Unique to B
    ax.text( center+2*offset, center+offset, str((b - a - c).count()), **kwargs)

    # Unique to C
    ax.text( center, center-2*offset, str((c - a - b).count()), **kwargs)

    # A and B not C
    ax.text( center, center+2*offset-0.5*offset, str((a + b - c).count()), **kwargs)

    # A and C not B
    ax.text( center-1.2*offset, center-0.5*offset, str((a + c - b).count()), **kwargs)

    # B and C not A
    ax.text( center+1.2*offset, center-0.5*offset, str((b + c - a).count()), **kwargs)

    # all
    ax.text( center, center, str((a + b + c).count()), **kwargs)

    ax.legend(loc='best')

    fig.savefig(outfn)

    plt.close(fig)

def main():
    """Create a 3-way Venn diagram, using matplotlib"""
    op = argparse.ArgumentParser(description=__doc__, prog=sys.argv[0])
    op.add_argument('-a', help='File to use for the left-most circle')
    op.add_argument('-b', help='File to use for the right-most circle')
    op.add_argument('-c', help='File to use for the bottom circle')
    op.add_argument('--labels',
                  help='Optional comma-separated list of '
                       'labels for a, b, and c', default='a,b,c')
    op.add_argument('--colors', default='r,b,g',
                  help='Comma-separated list of matplotlib-valid colors '
                       'for circles a, b, and c.  E.g., --colors=r,b,k')
    op.add_argument('-o', default='out.png', 
                  help='Output file to save as.  Extension is '
                       'meaningful, e.g., out.pdf, out.png, out.svg.  Default is "%(default)s"')
    op.add_argument('--test', action='store_true', help='run test, overriding all other options.')
    options = op.parse_args()

    reqd_args = ['a','b','c']
    if not options.test:
        for ra in reqd_args:
            if not getattr(options,ra):
                op.print_help()
                sys.stderr.write('Missing required arg "%s"\n' % ra)
                sys.exit(1)

    if options.test:
        pybedtools.bedtool.random.seed(1)
        a = pybedtools.example_bedtool('rmsk.hg18.chr21.small.bed')
        b = pybedtools.example_bedtool('venn.b.bed')
        c = pybedtools.example_bedtool('venn.c.bed')
        options.a = a.fn
        options.b = b.fn
        options.c = c.fn
        options.colors='r,b,g'
        options.o = 'out.png'
        options.labels = 'a,b,c'

    venn_mpl(a=options.a, b=options.b, c=options.c, 
             colors=options.colors.split(','),
             labels=options.labels.split(','), 
             outfn=options.o)

if __name__ == "__main__":
    import doctest
    if doctest.testmod(optionflags=doctest.ELLIPSIS).failed == 0:
        main()

########NEW FILE########
__FILENAME__ = settings
_bedtools_path = ""
_samtools_path = ""
_tabix_path = ""
_R_path = ""

tempfile_prefix = 'pybedtools.'
tempfile_suffix = '.tmp'


# Checking for BEDTools will happen when creating the first BedTool; other
# checks happen at first use (BAM object creation; tabix-ing a BedTool)
_bedtools_installed = False
_samtools_installed = False
_tabix_installed = False
_R_installed = False
_v_2_15_plus = False

KEEP_TEMPFILES = False
_DEBUG = True

# Check calls against these names to only allow calls to known BEDTools
# programs (basic security)
#
_prog_names = {

    # Genome arithmetic
    'intersectBed': 'intersect',
    'windowBed': 'window',
    'closestBed': 'closest',
    'coverageBed': 'coverage',
    'mapBed': 'map',
    'genomeCoverageBed': 'genomecov',
    'mergeBed': 'merge',
    'clusterBed': 'cluster',
    'complementBed': 'complement',
    'subtractBed': 'subtract',
    'slopBed': 'slop',
    'flankBed': 'flank',
    'sortBed': 'sort',
    'randomBed': 'random',
    'shuffleBed': 'shuffle',
    'annotateBed': 'annotate',

    # multi-way
    'multiIntersectBed': 'multiinter',
    'unionBedGraphs': 'unionbedg',

    # PE
    'pairToBed': 'pairtobed',
    'pairToPair': 'pairtopair',

    # format conversion
    'bamToBed': 'bamtobed',
    'bedToBam': 'bedtobam',
    'bedpeToBam': 'bedpetobam',
    'bed12ToBed6': 'bed12tobed6',
    'bamToFastq': 'bamtofastq',

    # fasta
    'fastaFromBed': 'getfasta',
    'maskFastaFromBed': 'maskfasta',
    'nucBed': 'nuc',

    # bam-centric
    'multiBamCov': 'multicov',
    'tagBam': 'tag',

    # stats
    'jaccard': 'jaccard',
    'reldist': 'reldist',

    # misc
    'getOverlap': 'overlap',
    'bedToIgv': 'igv',
    'linksBed': 'links',
    'windowMaker': 'makewindows',
    'groupBy': 'groupby',
    'expandCols': 'expand',
    'sample': 'sample',
}

_old_names = _prog_names.keys()
_new_names = _prog_names.values()

########NEW FILE########
__FILENAME__ = stats
import multiprocessing
import helpers
import pybedtools


def random_jaccard(x, y, genome_fn, shuffle_kwargs, jaccard_kwargs):
    z = x.shuffle(g=genome_fn, **shuffle_kwargs).sort()
    result = z.jaccard(y, **jaccard_kwargs)
    helpers.close_or_delete(z)
    return result


def random_intersection(x, y, genome_fn, shuffle_kwargs, intersect_kwargs):
    z = x.shuffle(g=genome_fn, **shuffle_kwargs)
    zz = z.intersect(y, stream=True, **intersect_kwargs)
    result = len(zz)
    helpers.close_or_delete(z, zz)
    return result


def random_intersection_bp(x, y, genome_fn, shuffle_kwargs, intersect_kwargs):
    z = x.shuffle(g=genome_fn, **shuffle_kwargs)
    zz = z.intersect(y, stream=True, **intersect_kwargs)
    result = sum(len(i) for i in zz)
    helpers.close_or_delete(z, zz)
    return result

########NEW FILE########
__FILENAME__ = regression_tests
"""
when bugs are identified post-release, put tests here to make sure they don't
happen again
"""

import pybedtools
import pybedtools.featurefuncs


def test_midpoint():
    """
    regression test for #98
    """
    a = """chr1 3052874 3053149
    chr1 3333690 3333915
    chr1 3472838 3473382
    chr1 3639053 3639356
    """

    def nothing(f):
        return f

    input_bed = pybedtools.BedTool(
        a, from_string=True).saveas("test_input.bed")

    for func in [pybedtools.featurefuncs.midpoint, pybedtools.featurefuncs.center, nothing]:
        input_bed_mid = input_bed.each(func)
        assert len(input_bed_mid) == 4

########NEW FILE########
__FILENAME__ = test1
import pybedtools
import os, difflib, sys
from nose import with_setup
from nose.tools import assert_raises, raises
from pybedtools.helpers import BEDToolsError
from pybedtools import featurefuncs
from tfuncs import setup, teardown, testdir, test_tempdir, unwriteable


def fix(x):
    """
    Replaces spaces with tabs, removes spurious newlines, and lstrip()s each
    line. Makes it really easy to create BED files on the fly for testing and
    checking.
    """
    s = ""
    for i in  x.splitlines():
        i = i.lstrip()
        if i.endswith('\t'):
            add_tab = '\t'
        else:
            add_tab = ''
        if len(i) == 0:
            continue
        i = i.split()
        i = '\t'.join(i) + add_tab + '\n'
        s += i
    return s


# ----------------------------------------------------------------------------
# Tabix support tests
# ----------------------------------------------------------------------------

def make_unwriteable():
    """
    Make a directory that cannot be written to and set the pybedtools tempdir
    to it. This is used to isolate "streaming" tests to ensure they do not
    write to disk.
    """
    if os.path.exists(unwriteable):
        os.system('rm -rf %s' % unwriteable)
    os.system('mkdir -p %s' % unwriteable)
    os.system('chmod -w %s' % unwriteable)
    pybedtools.set_tempdir(unwriteable)

def cleanup_unwriteable():
    """
    Reset to normal tempdir operation....
    """
    if os.path.exists(unwriteable):
        os.system('rm -rf %s' % unwriteable)
    pybedtools.set_tempdir(test_tempdir)

def test_interval_index():
    """
    supplement to the more general test in test_cbedtools.IntervalTest.testGetItemNegative
    """
    iv = pybedtools.create_interval_from_list('chr21   9719768 9721892 ALR/Alpha       1004    +'.split())
    assert iv[-1] == '+'
    assert iv[2:-1] == ['9721892', 'ALR/Alpha', '1004']

    iv = pybedtools.create_interval_from_list(
            ['chr1', 'ucb', 'gene', '465', '805', '.', '+', '.',
                'ID=thaliana_1_465_805;match=scaffold_801404.1;rname=thaliana_1_465_805'])
    print iv[4:-3]
    assert iv[4:-3] == ['805', '.']

def test_tuple_creation():
    # everything as a string
    t = [
            ("chr1", "1", "100", "feature1", "0", "+"),
            ("chr1", "100", "200", "feature2", "0", "+"),
            ("chr1", "150", "500", "feature3", "0", "-"),
            ("chr1", "900", "950", "feature4", "0", "+")
        ]
    x = pybedtools.BedTool(t).saveas()
    assert pybedtools.example_bedtool('a.bed') == x

    t = [
            ("chr1", 1, 100, "feature1", 0, "+"),
            ("chr1", 100, 200, "feature2", 0, "+"),
            ("chr1", 150, 500, "feature3", 0, "-"),
            ("chr1", 900, 950, "feature4", 0, "+")
        ]
    x = pybedtools.BedTool(t).saveas()
    assert pybedtools.example_bedtool('a.bed') == x

    t = [
            ("chr1", "fake", "gene", "50", "300", ".", "+", ".", "ID=gene1"),
            ("chr1", "fake", "mRNA", "50", "300", ".", "+", ".", "ID=mRNA1;Parent=gene1;"),
            ("chr1", "fake", "CDS", "75", "150", ".", "+", ".", "ID=CDS1;Parent=mRNA1;"),
            ("chr1", "fake", "CDS", "200", "275", ".", "+", ".", "ID=CDS2;Parent=mRNA1;"),
            ("chr1", "fake", "rRNA", "1200", "1275", ".", "+", ".", "ID=rRNA1;"),]
    x = pybedtools.BedTool(t).saveas()

    # Make sure that x has actual Intervals and not plain tuples or something
    assert isinstance(x[0], pybedtools.Interval)
    assert repr(x[0]) == "Interval(chr1:49-300)"
    assert x[0]['ID'] == 'gene1'


def test_tabix():
    a = pybedtools.example_bedtool('a.bed')
    t = a.tabix()
    assert t._tabixed()
    results = str(t.tabix_intervals('chr1:99-200'))
    print results
    assert results == fix("""
    chr1	1	100	feature1	0	+
    chr1	100	200	feature2	0	+
    chr1	150	500	feature3	0	-""")

    assert str(t.tabix_intervals(a[2])) == fix("""
    chr1	100	200	feature2	0	+
    chr1	150	500	feature3	0	-""")

    # clean up
    fns = [
            pybedtools.example_filename('a.bed.gz'),
            pybedtools.example_filename('a.bed.gz.tbi'),
          ]
    for fn in fns:
        if os.path.exists(fn):
            os.unlink(fn)

def test_tabix_intervals():
    a = pybedtools.BedTool('chr1 25 30', from_string=True).tabix()
    assert len(a.tabix_intervals('chr1:30-35')) == 0
    assert len(a.tabix_intervals('chr1:29-30')) == 1

    # make sure it works OK even if strand was provided
    assert len(a.tabix_intervals('chr1:30-35[-]')) == 0
    assert len(a.tabix_intervals('chr1:29-30[-]')) == 1

# ----------------------------------------------------------------------------
# Streaming and non-file BedTool tests
# ----------------------------------------------------------------------------

@with_setup(make_unwriteable, cleanup_unwriteable)
def test_stream():
    """
    Stream and file-based equality, both whole-file and Interval by
    Interval
    """
    cleanup_unwriteable()

    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    c = a.intersect(b)

    # this should really not be written anywhere
    d = a.intersect(b, stream=True)

    assert_raises(NotImplementedError, c.__eq__, d)
    d_contents = d.fn.read()
    c_contents = open(c.fn).read()
    assert d_contents == c_contents

    # reconstruct d and check Interval-by-Interval equality
    make_unwriteable()
    d = a.intersect(b, stream=True)

    for i,j in zip(c, d):
        assert str(i) == str(j)

    # Now do something similar with GFF files.
    a = pybedtools.example_bedtool('a.bed')
    f = pybedtools.example_bedtool('d.gff')

    # file-based
    cleanup_unwriteable()
    g1 = f.intersect(a)

    # streaming
    make_unwriteable()
    g2 = f.intersect(a, stream=True)

    for i,j in zip(g1, g2):
        assert str(i) == str(j)

    # this was segfaulting at one point, just run to make sure
    g3 = f.intersect(a, stream=True)
    for i in iter(g3):
        print i

    for row in a.cut([0, 1, 2, 5], stream=True):
        row[0], row[1], row[2]
        assert_raises(IndexError, row.__getitem__, 4)

def test_stream_of_stream():
    """
    Second-level streaming using self-intersections
    """
    a = pybedtools.example_bedtool('a.bed')

    # Ensure non-stream and stream equality of self-intersection
    nonstream1 = a.intersect(a, u=True)
    stream1    = a.intersect(a, u=True, stream=True)
    nonstream1_str = str(nonstream1)
    stream1_str    = str(stream1)
    a_str          = str(a)
    assert nonstream1_str == stream1_str == a_str

    # Have to reconstruct stream1 cause it was consumed in the str() call
    nonstream1 = a.intersect(a, u=True)
    stream1    = a.intersect(a, u=True, stream=True)
    nonstream2 = a.intersect(nonstream1, u=True)
    stream2    = a.intersect(stream1, u=True, stream=True)
    nonstream2_str = str(nonstream2)
    stream2_str    = str(stream2)
    assert nonstream2_str == stream2_str == nonstream1_str == stream1_str == a_str

def test_generator():
    """
    Equality of BedTools created from file, iter(), and generator
    """
    # Test creation from file vs
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.BedTool(iter(a))
    assert str(a) == str(b)

    # Ensure that streams work well too
    b1 = a.intersect(a, stream=True)
    b2 = pybedtools.BedTool((i for i in a)).intersect(a)
    assert str(b1) == str(b2)

def test_stream_of_generator():
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    b1 = a.intersect(a, stream=True)
    b2 = pybedtools.BedTool((i for i in a)).intersect(a, stream=True)
    sb1 = str(b1)
    sb2 = str(b2)
    print sb1
    print sb2
    assert sb1 == sb2

def test_many_files():
    """regression test to make sure many files can be created
    """
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    # Previously, IntervalFile would leak open files and would cause OSError
    # (too many open files) at iteration 1010 or so.
    for i in xrange(1100):
        c = a.intersect(b)

def test_malformed():
    """
    Malformed BED lines should raise MalformedBedLineError
    """
    a = pybedtools.BedTool("""
    chr1 100 200
    chr1 100 90
    chr1 100 200
    chr1 100 200
    chr1 100 200
    chr1 100 200
    """, from_string=True)
    a_i = iter(a)

    # first feature is OK
    print a_i.next()

    # but next one is not and should raise exception
    assert_raises(pybedtools.MalformedBedLineError, a_i.next)

def test_remove_invalid():
    """
    Remove_invalid() removes invalid lines, track lines, and comments
    """
    a = pybedtools.BedTool("""
    chr1 100 200
    chr1 100 90
    track name='try to break parser'
    chr1 100 200
    chr1 100 200
    chr1 100 200
    #
    chr1 100 200
    """, from_string=True)

    b = a.remove_invalid()

    cleaned = pybedtools.BedTool("""
    chr1 100 200
    chr1 100 200
    chr1 100 200
    chr1 100 200
    chr1 100 200""", from_string=True)

    assert_raises(NotImplementedError, b.__eq__, cleaned)
    assert str(b) == str(cleaned)

def test_create_from_list_long_features():
    """
    Iterator handles extra fields from long features (BED+GFF -wao intersection)
    """
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('c.gff')
    c = a.intersect(b, wao=True, stream=False)
    d = a.intersect(b, wao=True, stream=True)

    print b.closest(a)

    for i in d:
        print i

def test_iterator():
    """
    Iterator should ignore non-BED lines
    """
    s = """
    track name="test"


    browser position chrX:1-100
    # comment line
    chrX  1 10
    # more comments
    track name="another"


    """
    a = pybedtools.BedTool(s, from_string=True)
    results = list(a)
    print results[0]
    assert str(results[0]) == 'chrX\t1\t10\n', results

def test_indexing():
    """
    Indexing into BedTools
    """
    a = pybedtools.example_bedtool('a.bed')

    # This is the first line
    interval = pybedtools.Interval('chr1', 1, 100, 'feature1', '0', '+')

    # just to make sure
    assert interval == iter(a).next()

    # test slice behavior
    results = list(a[0:2])
    assert len(results) == 2
    assert results[0] == interval

    # test single-integer indexing
    assert a[0] == interval

    # only slices and integers allowed....
    assert_raises(ValueError, a.__getitem__, 'key')

def test_repr_and_printing():
    """
    Missing files and streams should say so in repr()
    """
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    c = a+b
    d = a.intersect(b, stream=True)
    os.unlink(c.fn)
    assert 'a.bed' in repr(a)
    assert 'b.bed' in repr(b)
    assert 'MISSING FILE' in repr(c)
    assert 'stream' in repr(d)

def test_file_type():
    """
    Regression test on file_type checks

    Previously file_type was creating a new IntervalFile every time it was
    called; now it's cached so an IntervalFile is only created once per
    BedTool.
    """
    a = pybedtools.example_bedtool('a.bed')
    for i in range(5000):
        a.file_type

# ----------------------------------------------------------------------------
# BEDTools wrapper tests --
#   See test_iter.py, which uses YAML test case definitions, for more complete
#   tests of BEDTools wrapper methods.
#
#   Here, we assert exception raises and more complicated things that can't be
#   easily described in YAML
# ----------------------------------------------------------------------------

def test_introns():
    a = pybedtools.example_bedtool('mm9.bed12')
    b = pybedtools.BedTool((f for f in a if f.name == "Tcea1,uc007afj.1")).saveas()
    bfeat = iter(b).next()

    bi = b.introns()
    # b[9] is the exonCount from teh bed12 file. there should be
    # b[9] -1 introns assuming no utrs.
    assert len(bi) == int(bfeat[9]) - 1, (len(bi), len(b))

def test_slop():
    """
    Calling slop with no genome should raise ValueError
    """
    a = pybedtools.example_bedtool('a.bed')

    # Make sure it complains if no genome is set
    assert_raises(ValueError, a.slop, **dict(l=100, r=1))

def test_closest():
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    r = a.closest(b)
    assert len(r) == len(a)

# TODO: there's enough stuff in here that it's probably worth it to eventually
# make a TestSequenceStuff class
def test_sequence():
    """
    From UCSC:

    chromStart - The starting position of the feature in the chromosome or
    scaffold. The first base in a chromosome is numbered 0.

    chromEnd - The ending position of the feature in the chromosome or
    scaffold. The chromEnd base is not included in the display of the feature.
    For example, the first 100 bases of a chromosome are defined as
    chromStart=0, chromEnd=100, and span the bases numbered 0-99. """

    fi = os.path.join(testdir, 'test.fasta')

    s = """
    chrX 9  16 . . +
    chrX 9  16 . . -
    chrY 1  4  . . +
    chrZ 28 31 . . +
    """

    fasta = """
    >chrX
    AAAAAAAAATGCACTGAAAAAAAAAAAAAAA
    >chrY
    GCTACCCCCCCCCCCCCCCCCCCCCCCCCCC
    >chrZ
    AAAAAAAAAAAAAAAAAAAAAAAAAAAATCT
    """
    a = pybedtools.BedTool(s, from_string=True)
    assert_raises(ValueError, a.save_seqs, ('none',))

    fout = open(fi,'w')
    for line in fasta.splitlines(True):
        fout.write(line.lstrip())
    fout.close()

    # redirect stderr for the call to .sequence(), which reports the creation
    # of an index file
    tmp = open(a._tmp(),'w')
    orig_stderr = sys.stderr
    sys.stderr = tmp

    f = a.sequence(fi=fi)

    sys.stderr = orig_stderr

    assert f.fn == f.fn
    seqs = open(f.seqfn).read()
    print seqs
    expected = """>chrX:9-16
TGCACTG
>chrX:9-16
TGCACTG
>chrY:1-4
CTA
>chrZ:28-31
TCT
"""
    print ''.join(difflib.ndiff(seqs,expected))
    print expected
    assert seqs == expected

    f = a.sequence(fi=fi,s=True)
    seqs = open(f.seqfn).read()
    expected = """>chrX:9-16(+)
TGCACTG
>chrX:9-16(-)
CAGTGCA
>chrY:1-4(+)
CTA
>chrZ:28-31(+)
TCT
"""
    print seqs
    print expected
    print ''.join(difflib.ndiff(seqs,expected))
    assert seqs == expected

    f = f.save_seqs('deleteme.fa')
    assert open('deleteme.fa').read() == expected
    assert f.print_sequence() == expected
    os.unlink('deleteme.fa')

    fresh_a = pybedtools.BedTool(s, from_string=True)
    assert fresh_a == f

    os.unlink(fi)
    if os.path.exists(fi+'.fai'):
        os.unlink(fi+'.fai')

# ----------------------------------------------------------------------------
# Operator tests
# ----------------------------------------------------------------------------
def test_add_subtract():
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    assert a.intersect(b,u=True) == (a+b)
    assert a.intersect(b,v=True) == (a-b)

def test_subset():
    a = pybedtools.example_bedtool('a.bed')
    import random
    random.seed(1)

    s = list(a.random_subset(1).features())
    assert len(s) == 1
    assert isinstance(s[0], pybedtools.Interval)

    s2 = list(a.random_subset(len(a)).features())
    print len(s2)
    assert len(s2) == len(a)

def test_eq():
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('a.bed')

    # BedTool to BedTool
    assert a == b

    # BedTool to string
    s= """chr1	1	100	feature1	0	+
chr1	100	200	feature2	0	+
chr1	150	500	feature3	0	-
chr1	900	950	feature4	0	+
"""
    assert a == s
    # Test not equa on bedtool
    b = pybedtools.example_bedtool('b.bed')
    assert b != a

    # and string
    assert a != "blah"

    # Don't allow testing equality on streams
    c = a.intersect(b, stream=True)
    d = a.intersect(b)
    assert_raises(NotImplementedError, c.__eq__, d)
    assert_raises(NotImplementedError, d.__eq__, c)

    # Test it on iterator, too....
    e = pybedtools.BedTool((i for i in a))
    assert_raises(NotImplementedError, e.__eq__, a)
    assert_raises(NotImplementedError, a.__eq__, e)

    # Make sure that if we force the iterator to be consumed, it is in fact
    # equal
    s = str(e)
    print str(a).splitlines(True)
    print s.splitlines(True)
    assert a == s

def test_hash():
    a = pybedtools.example_bedtool('a.bed')
    d = {}
    for i in a:
        d[i] = 1


# ----------------------------------------------------------------------------
# Other BedTool method tests
# ----------------------------------------------------------------------------

def test_count_bed():
    a = pybedtools.example_bedtool('a.bed')
    assert a.count() == 4
    assert len(a) == 4

def test_feature_centers():
    from pybedtools import featurefuncs
    a = pybedtools.BedTool("""
                           chr1 1 100
                           chr5 3000 4000
                           """, from_string=True)
    b = a.each(featurefuncs.center, 1)
    results = list(b.features())

    print results

    assert results[0].start == 50
    assert results[0].stop == 51
    assert results[0].chrom == 'chr1'

    assert results[1].start == 3500
    assert results[1].stop == 3501
    assert results[1].chrom == 'chr5'

def test_bedtool_creation():
    # make sure we can make a bedtool from a bedtool and that it points to the
    # same file
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.BedTool(a)
    assert b.fn == a.fn
    assert_raises(ValueError, pybedtools.BedTool,'nonexistent.bed')

    # note that *s* has both tabs and spaces....
    s = """
    chr1	1	100	feature1  0	+
    chr1	100	200	feature2  0	+
    chr1	150	500	feature3  0	-
    chr1	900	950	feature4  0	+
    """
    from_string = pybedtools.BedTool(s, from_string=True)

    # difflib used here to show a bug where a newline was included when using
    # from_string
    print ''.join(difflib.ndiff(str(from_string), str(a)))

    assert str(from_string) == str(a)

def test_special_methods():
    # note that *s* has both tabs and spaces....
    s = """
    chr1	1	100	feature1  0	+
    chr1	100	200	feature2  0	+
    chr1	150	500	feature3  0	-
    chr1	900	950	feature4  0	+
    """
    from_string = pybedtools.BedTool(s, from_string=True)
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')

    assert from_string == a
    assert from_string != b
    assert not from_string == b
    assert not from_string != a

def test_field_count():
    a = pybedtools.example_bedtool('a.bed')
    assert a.field_count() == 6

def test_repr_and_printing():
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    c = a+b
    os.unlink(c.fn)
    assert 'a.bed' in repr(a)
    assert 'b.bed' in repr(b)
    assert 'MISSING FILE' in repr(c)

    print a.head(1)

def test_cut():
    a = pybedtools.example_bedtool('a.bed')
    c = a.cut([0, 1, 2, 4])
    assert c.field_count() == 4, c

def test_filter():
    a = pybedtools.example_bedtool('a.bed')

    b = a.filter(lambda f: f.length < 100 and f.length > 0)
    assert len(b) == 2

def test_random_intersection():
    # TODO:
    return
    N = 4
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    li = list(a.randomintersection(b, N))
    assert len(li) == N, li

def test_cat():
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    b_fn = pybedtools.example_filename('b.bed')
    assert a.cat(b) == a.cat(b_fn)
    expected =  fix("""
    chr1 1   500
    chr1 800 950
    """)
    assert a.cat(b) == expected

    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    c = a.cat(b, postmerge=False)
    assert len(a) + len(b) == len(c), (len(a), len(b), len(c))

    print c
    assert c == fix("""
    chr1	1	100	feature1	0	+
    chr1	100	200	feature2	0	+
    chr1	150	500	feature3	0	-
    chr1	900	950	feature4	0	+
    chr1	155	200	feature5	0	-
    chr1	800	901	feature6	0	+
    """)

def test_randomstats():
    chromsizes = {'chr1':(1,1000)}
    a = pybedtools.example_bedtool('a.bed').set_chromsizes(chromsizes)
    b = pybedtools.example_bedtool('b.bed')
    try:
        results = a.randomstats(b, 100, debug=True)
        assert results['actual'] == 3
        assert results['median randomized'] == 2.0
        assert results['percentile'] == 89.5

    except ImportError:
        # allow doctests to pass if SciPy not installed
        sys.stderr.write('SciPy not installed, so not testing '
                         'BedTool.randomstats().')


# ----------------------------------------------------------------------------
# Interval tests
# ----------------------------------------------------------------------------

def test_gff_stuff():
    s = """
    chr1  fake  gene 1 100 . + . ID=gene1
    chr1  fake  mRNA 1 100 . + . Name=mRNA1
    chr1  fake  CDS 50 90 . + . other=nothing
    """
    d = pybedtools.BedTool(s, from_string=True)
    f1, f2, f3 = d.features()
    assert f1.name == 'gene1', f1.name
    assert f2.name == 'mRNA1', f2.name
    assert f3.name is None, f3.name

def test_name():
    c = iter(pybedtools.example_bedtool('c.gff')).next()
    assert c.name == "thaliana_1_465_805" , c.name

# ----------------------------------------------------------------------------
# Other non-BedTool tests
# ----------------------------------------------------------------------------

def test_flatten():
    from pybedtools.helpers import _flatten_list
    result = _flatten_list([[1,2,3,0,[0,5],9],[100]])
    print result
    assert result == [1, 2, 3, 0, 0, 5, 9, 100]

def test_history_step():
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    c = a.intersect(b)
    d = c.subtract(a)

    tag = c.history[0].result_tag
    assert pybedtools.find_tagged(tag) == c

    assert_raises(ValueError, pybedtools.find_tagged, 'nonexistent')


    print d.history
    d.delete_temporary_history(ask=True, raw_input_func=lambda x: 'n')
    assert os.path.exists(a.fn)
    assert os.path.exists(b.fn)
    assert os.path.exists(c.fn)
    assert os.path.exists(d.fn)

    d.delete_temporary_history(ask=True, raw_input_func=lambda x: 'Yes')
    assert os.path.exists(a.fn)
    assert os.path.exists(b.fn)
    assert not os.path.exists(c.fn) # this is the only thing that should change
    assert os.path.exists(d.fn)

    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    c = a.intersect(b)
    d = c.subtract(a)
    d.delete_temporary_history(ask=False)
    assert os.path.exists(a.fn)
    assert os.path.exists(b.fn)
    assert not os.path.exists(c.fn) # this is the only thing that should change
    assert os.path.exists(d.fn)

def test_kwargs():
    a = pybedtools.example_bedtool('a.bed')
    b = a.intersect(a, s=False)
    c = a.intersect(a)
    assert str(b) == str(c)


# ----------------------------------------------------------------------------
# gzip support tests
# ----------------------------------------------------------------------------

def test_gzip():
    # make new gzipped files on the fly
    agz = pybedtools.BedTool._tmp()
    bgz = pybedtools.BedTool._tmp()
    os.system('gzip -c %s > %s' % (pybedtools.example_filename('a.bed'), agz))
    os.system('gzip -c %s > %s' % (pybedtools.example_filename('b.bed'), bgz))
    agz = pybedtools.BedTool(agz)
    bgz = pybedtools.BedTool(bgz)
    assert agz.file_type == bgz.file_type == 'bed'
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    assert a.intersect(b) == agz.intersect(bgz) == a.intersect(bgz) == agz.intersect(b)

# ----------------------------------------------------------------------------
# BAM support tests
# ----------------------------------------------------------------------------
def test_bam_bedtool_creation():
    x = pybedtools.example_bedtool('x.bam')
    a = pybedtools.example_bedtool('a.bed')
    assert x._isbam
    assert not a._isbam

def test_print_abam():
    x = pybedtools.example_bedtool('gdc.bam')
    expected = fix("""
    None	0	chr2L	11	255	5M	*	0	0	CGACA	IIIII	NM:i:0	NH:i:1
    None	16	chr2L	71	255	5M	*	0	0	TTCTC	IIIII	NM:i:0	NH:i:1
    None	16	chr2L	141	255	5M	*	0	0	CACCA	IIIII	NM:i:0	NH:i:1
    None	16	chr2L	151	255	5M	*	0	0	GTTCA	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	211	255	5M	*	0	0	AAATA	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	71	255	5M	*	0	0	GAGAA	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	141	255	5M	*	0	0	TGGTG	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	161	255	5M	*	0	0	GATAA	IIIII	NM:i:0	NH:i:1""")
    print 'x:'
    print x
    print 'expected:'
    print expected
    assert x == expected

def test_bam_iter():
    x = pybedtools.example_bedtool('gdc.bam')
    s = 'None	0	chr2L	11	255	5M	*	0	0	CGACA	IIIII	NM:i:0	NH:i:1\n'
    assert str(x[0]) == str(iter(x).next()) == s

def test_bam_stream_bed():
    x = pybedtools.example_bedtool('gdc.bam')
    b = pybedtools.example_bedtool('gdc.gff')
    c = x.intersect(b, u=True, bed=True, stream=True)
    str_c = str(c)
    expected = fix("""
    chr2L	70	75	None	255	-	70	75	0,0,0	1	5,	0,
    chr2L	140	145	None	255	-	140	145	0,0,0	1	5,	0,
    chr2L	150	155	None	255	-	150	155	0,0,0	1	5,	0,
    chr2L	210	215	None	255	+	210	215	0,0,0	1	5,	0,
    chr2L	70	75	None	255	+	70	75	0,0,0	1	5,	0,
    chr2L	140	145	None	255	+	140	145	0,0,0	1	5,	0,
    chr2L	160	165	None	255	+	160	165	0,0,0	1	5,	0,
    """)
    assert str_c == expected

def test_bam_stream_bam():
    x = pybedtools.example_bedtool('gdc.bam')
    b = pybedtools.example_bedtool('gdc.gff')
    c = x.intersect(b, u=True, stream=True)
    expected = fix("""
    None	16	chr2L	71	255	5M	*	0	0	TTCTC	IIIII	NM:i:0	NH:i:1
    None	16	chr2L	141	255	5M	*	0	0	CACCA	IIIII	NM:i:0	NH:i:1
    None	16	chr2L	151	255	5M	*	0	0	GTTCA	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	211	255	5M	*	0	0	AAATA	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	71	255	5M	*	0	0	GAGAA	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	141	255	5M	*	0	0	TGGTG	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	161	255	5M	*	0	0	GATAA	IIIII	NM:i:0	NH:i:1""")
    assert str(c) == expected

def test_bam_stream_bam_stream():
    x = pybedtools.example_bedtool('gdc.bam')
    b = pybedtools.example_bedtool('gdc.gff')
    c = x.intersect(b, u=True, stream=True)
    expected = fix("""
    None	16	chr2L	71	255	5M	*	0	0	TTCTC	IIIII	NM:i:0	NH:i:1
    None	16	chr2L	141	255	5M	*	0	0	CACCA	IIIII	NM:i:0	NH:i:1
    None	16	chr2L	151	255	5M	*	0	0	GTTCA	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	211	255	5M	*	0	0	AAATA	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	71	255	5M	*	0	0	GAGAA	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	141	255	5M	*	0	0	TGGTG	IIIII	NM:i:0	NH:i:1
    None	0	chr2L	161	255	5M	*	0	0	GATAA	IIIII	NM:i:0	NH:i:1""")
    d = c.intersect(b)
    print d
    assert str(d) == expected

def test_bam_interval():
    x = pybedtools.example_bedtool('x.bam')
    assert x[0].chrom == 'chr2L'
    assert x[0].start == 9329L
    assert x[0][3] == '9330'
    assert x[0].stop == 9365L
    assert len(x[0][9]) == len(x[0]) == 36

def test_bam_regression():
    # Regression test:  with extra fields, the first item in x.bam was being
    # parsed as gff (cause not ==13 fields).  This does a check to prevent that
    # from happening again.
    x = pybedtools.example_bedtool('x.bam')
    assert x[0].file_type == 'sam'
    assert x[0].chrom == 'chr2L'

def test_sam_filetype():
    # file_type was segfaulting cause IntervalFile couldn't parse SAM
    a = pybedtools.example_bedtool('gdc.bam')
    b = pybedtools.BedTool(i for i in a).saveas()
    assert b.file_type == 'sam'

def test_bam_to_sam_to_bam():
    a = pybedtools.example_bedtool('gdc.bam')
    orig = str(a)
    assert a.file_type == 'bam'

    # saveas should maintain BAM format
    b = a.saveas()
    assert b.file_type == 'bam'

    # Converting to string gets SAM format
    assert str(b) == orig

    # b is a bam; to_bam should return a bam
    c = b.to_bam(genome='dm3')
    assert c.file_type == 'bam'

    # in fact, it should be the same file:
    assert c.fn == b.fn

    # In order to get SAM format, need to print to file.
    d = open(pybedtools.BedTool._tmp(), 'w')
    d.write(str(c))
    d.close()
    d = pybedtools.BedTool(d.name)
    assert d.file_type == 'sam'

    e = d.to_bam(genome='dm3')
    assert e.file_type == 'bam'

    # everybody should be the same
    assert a == b == c == d == e


def test_bam_filetype():
    # regression test -- this was segfaulting before because IntervalFile
    # couldn't parse SAM
    a = pybedtools.example_bedtool('gdc.bam')
    b = pybedtools.example_bedtool('gdc.gff')
    c = a.intersect(b)
    assert c.file_type == 'bam'

def test_bam_header():
    a = pybedtools.example_bedtool('gdc.bam')
    b = pybedtools.example_bedtool('gdc.gff')
    c = a.intersect(b)
    print c._bam_header
    assert c._bam_header == "@SQ	SN:chr2L	LN:23011544\n"

def test_output_kwarg():
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    c = a.intersect(b)
    d = a.intersect(b, output='deleteme.bed')
    assert c == d
    os.unlink('deleteme.bed')

def test_copy():
    a = pybedtools.example_bedtool('a.bed')
    x = a[0]

    # Before adding the __copy__ method to Interval class, making a copy would
    # hang and then segfault
    import copy
    y = copy.copy(x)

    assert y.start == x.start
    assert y.stop == x.stop
    assert y.chrom == x.chrom
    assert y.name == x.name
    assert y.fields == x.fields
    assert y.file_type == x.file_type == 'bed'

    # Make sure it's a real copy (changing something in y doesn't change
    # something in x)
    y.start += 1
    assert y.start == x.start + 1

def test_pickleable():
    interval = pybedtools.create_interval_from_list(
        ['chr1', '1', '100', 'asdf'])
    fn = pybedtools.BedTool._tmp()
    import pickle
    out = open(fn, 'w')
    pickle.dump(interval, out)
    out.close()
    new_interval = pickle.load(open(fn))
    assert str(interval) == str(new_interval)

    interval = pybedtools.create_interval_from_list(
        ['chr1', '1', '100'])
    fn = pybedtools.BedTool._tmp()
    import pickle
    out = open(fn, 'w')
    pickle.dump(interval, out)
    out.close()
    new_interval = pickle.load(open(fn))
    assert str(interval) == str(new_interval)

    interval = pybedtools.create_interval_from_list(
        "chr2L	.	UTR	41	70	0	+	.	ID=mRNA:xs2:UTR:41-70;Parent=mRNA:xs2;".split('\t'))
    fn = pybedtools.BedTool._tmp()
    import pickle
    out = open(fn, 'w')
    pickle.dump(interval, out)
    out.close()
    new_interval = pickle.load(open(fn))
    assert str(interval) == str(new_interval)

def test_split():
    a = pybedtools.example_bedtool('a.bed')

    def func(x, dist1, dist2):
        "shift the features around"

        newstart = x.start + dist1
        newstop = x.stop + dist1
        x.start = newstart
        x.stop = newstop
        yield x

        x.start -= dist2
        x.stop -= dist2

        yield x

    result = str(a.split(func, 1000, 100))
    assert result == fix("""
    chr1	1001	1100	feature1	0	+
    chr1	901	1000	feature1	0	+
    chr1	1100	1200	feature2	0	+
    chr1	1000	1100	feature2	0	+
    chr1	1150	1500	feature3	0	-
    chr1	1050	1400	feature3	0	-
    chr1	1900	1950	feature4	0	+
    chr1	1800	1850	feature4	0	+
    """)

def test_additional_args():
    a = pybedtools.example_bedtool('a.bed')
    expected = fix("""
    chr1	1	2	1
    chr1	100	101	1
    chr1	900	901	1""")
    assert a.genome_coverage(bg=True, strand='+', g=dict(chr1=(1, 1000)), additional_args='-5') == expected

def test_tss():
    a = pybedtools.example_bedtool('a.bed')
    results = str(a.each(featurefuncs.TSS, upstream=3, downstream=5, add_to_name='_TSS'))
    print results
    assert results == fix("""
    chr1	0	6	feature1_TSS	0	+
    chr1	97	105	feature2_TSS	0	+
    chr1	495	503	feature3_TSS	0	-
    chr1	897	905	feature4_TSS	0	+
    """)

def test_extend_fields():
    a = pybedtools.example_bedtool('a.bed')
    results = str(a.each(featurefuncs.extend_fields, 8))
    print results
    assert results == fix("""
    chr1	1	100	feature1	0	+	.	.
    chr1	100	200	feature2	0	+	.	.
    chr1	150	500	feature3	0	-	.	.
    chr1	900	950	feature4	0	+	.	.
    """)

def test_gff2bed():
    a = pybedtools.example_bedtool('d.gff')
    results = str(a.each(featurefuncs.gff2bed, name_field='Parent'))
    assert results == fix("""
    chr1	49	300	.	.	+
    chr1	49	300	gene1	.	+
    chr1	74	150	mRNA1	.	+
    chr1	199	275	mRNA1	.	+
    chr1	1199	1275	.	.	+""")


    results = str(a.each(featurefuncs.gff2bed))
    assert results == fix("""
    chr1	49	300	gene1	.	+
    chr1	49	300	mRNA1	.	+
    chr1	74	150	CDS1	.	+
    chr1	199	275	CDS2	.	+
    chr1	1199	1275	rRNA1	.	+
    """)

    results = str(a.each(featurefuncs.gff2bed, name_field="nonexistent"))
    assert results == fix("""
    chr1	49	300	.	.	+
    chr1	49	300	.	.	+
    chr1	74	150	.	.	+
    chr1	199	275	.	.	+
    chr1	1199	1275	.	.	+
    """)

    results = str(a.each(featurefuncs.gff2bed, name_field=1))
    print results
    assert results == fix("""
    chr1	49	300	fake	.	+
    chr1	49	300	fake	.	+
    chr1	74	150	fake	.	+
    chr1	199	275	fake	.	+
    chr1	1199	1275	fake	.	+""")


def test_add_color():
    try:
        from matplotlib import cm
    except ImportError:
        print "matplotlib not installed; skipping test_add_color"
        return

    def modify_scores(f):
        fields = f.fields
        fields[4] = str(f[2])
        return pybedtools.create_interval_from_list(fields)
    a = pybedtools.example_bedtool('a.bed')
    a = a.each(modify_scores).saveas()
    cmap = cm.jet
    norm = a.colormap_normalize()
    results = str(a.each(featurefuncs.add_color, cmap=cmap, norm=norm))
    print results
    assert results == fix("""
    chr1	1	100	feature1	100	+	1	100	0,0,127
    chr1	100	200	feature2	200	+	100	200	0,0,255
    chr1	150	500	feature3	500	-	150	500	99,255,147
    chr1	900	950	feature4	950	+	900	950	127,0,0""")



#------------------------------------------------------------------------------
# Tests for IntervalFile, as accessed by BedTool objects
#------------------------------------------------------------------------------
def test_any_hits():
    a = pybedtools.example_bedtool('a.bed')

    assert 1 == a.any_hits(pybedtools.create_interval_from_list(
                      ['chr1', '900', '905', '.', '.', '-']))

    assert 0 == a.any_hits(pybedtools.create_interval_from_list(
                      ['chr1', '900', '905', '.', '.', '-']), same_strand=True)

    assert 0 == a.any_hits(pybedtools.create_interval_from_list(
                      ['chr1', '8000', '9000', '.', '.', '-']))

def test_all_hits():
    a = pybedtools.example_bedtool('a.bed')

    assert [a[2], a[3]] == a.all_hits(pybedtools.create_interval_from_list(
                      ['chr1', '450', '905', '.', '.', '-']))

    assert [a[2]] == a.all_hits(pybedtools.create_interval_from_list(
                      ['chr1', '450', '905', '.', '.', '-']), same_strand=True)

def test_count_hits():
    a = pybedtools.example_bedtool('a.bed')

    assert len(a.all_hits(pybedtools.create_interval_from_list(
                      ['chr1', '450', '905', '.', '.', '-']))) == 2

    assert len(a.all_hits(pybedtools.create_interval_from_list(
                      ['chr1', '450', '905', '.', '.', '-']), same_strand=True)) == 1

def test_multi_intersect():
    # Need to test here because "-i" is not a single other-bedtool like other
    # "-i" BEDTools programs, and this throws off the iter testing.
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.example_bedtool('b.bed')
    x = pybedtools.BedTool()
    assert x.multi_intersect(i=[a.fn, b.fn]) == fix("""
        chr1	1	155	1	1	1	0
        chr1	155	200	2	1,2	1	1
        chr1	200	500	1	1	1	0
        chr1	800	900	1	2	0	1
        chr1	900	901	2	1,2	1	1
        chr1	901	950	1	1	1	0""")

    assert x.multi_intersect(i=[a.fn, b.fn], cluster=True) == fix("""
        chr1	155	200	2	1,2	1	1
        chr1	900	901	2	1,2	1	1""")

def test_union_bedgraphs():
    # from unionBedGraphs -examples...

    a = pybedtools.BedTool("""
    chr1  1000    1500    10
    chr1  2000    2100    20
    """, from_string=True)
    b = pybedtools.BedTool("""
    chr1  900 1600    60
    chr1  1700    2050    50
    """, from_string=True)
    c = pybedtools.BedTool("""
    chr1  1980    2070    80
    chr1  2090    2100    20
    """, from_string=True)

    x = pybedtools.BedTool()
    result = x.union_bedgraphs(i=[a.fn, b.fn, c.fn])
    assert result == fix("""
    chr1  900 1000    0   60  0
    chr1  1000    1500    10  60  0
    chr1  1500    1600    0   60  0
    chr1  1700    1980    0   50  0
    chr1  1980    2000    0   50  80
    chr1  2000    2050    20  50  80
    chr1  2050    2070    20  0   80
    chr1  2070    2090    20  0   0
    chr1  2090    2100    20  0   20
    """)

def test_window_maker():
    x = pybedtools.BedTool()
    a = pybedtools.example_bedtool('a.bed')
    result = x.window_maker(b=a.fn, w=50)
    print result
    assert result == fix("""
    chr1	1	51
    chr1	51	100
    chr1	100	150
    chr1	150	200
    chr1	150	200
    chr1	200	250
    chr1	250	300
    chr1	300	350
    chr1	350	400
    chr1	400	450
    chr1	450	500
    chr1	900	950
    """)
    x = pybedtools.BedTool()
    z = x.window_maker(genome='hg19', w=100000)
    assert str(z[0]) == "chr1\t0\t100000\n"
    assert str(z[10000]) == 'chr16\t20800000\t20900000\n'

def test_random():
    a = pybedtools.BedTool()
    result = a.random(l=10, n=10, genome='hg19', seed=1)
    assert result == fix("""
    chr3	11945098	11945108	1	10	+
    chr15	84985693	84985703	2	10	-
    chr2	62691196	62691206	3	10	-
    chr18	18871346	18871356	4	10	+
    chr9	133374407	133374417	5	10	+
    chr9	48958184	48958194	6	10	+
    chrY	41568406	41568416	7	10	-
    chr4	16579517	16579527	8	10	+
    chr1	76589882	76589892	9	10	-
    chr3	55995799	55995809	10	10	-
    """)

def test_links():
    # have to be careful about the path, since it is embedded in the HTML
    # output -- so make a copy of the example file, and delete when done.
    os.system('cp %s a.links.bed' % pybedtools.example_filename('a.bed'))
    a = pybedtools.BedTool('a.links.bed')
    a = a.links()
    exp = open(pybedtools.example_filename('a.links.html')).read()
    obs = open(a.links_html).read()
    print exp
    print obs
    assert exp == obs
    os.unlink('a.links.bed')



def test_igv():
    a = pybedtools.example_bedtool('a.bed')
    a = a.igv()
    obs = open(a.igv_script).read()
    exp = open(pybedtools.example_filename('a.igv_script')).read()
    assert obs == exp

def test_bam_to_fastq():
    x = pybedtools.example_bedtool('small.bam')
    tmpfn = pybedtools.BedTool._tmp()
    y = x.bam_to_fastq(fq=tmpfn)
    assert open(y.fastq).read() == open(pybedtools.example_filename('small.fastq')).read()


def test_gtf_gff_attrs():
    # smoke test.
    #
    # this has always worked:
    gff = ["chr1","fake","mRNA","51", "300",".", "+",".","ID=mRNA1;Parent=gene1;"]
    gff = pybedtools.create_interval_from_list(gff)
    gff.attrs

    # this previously failed because of the "=" in the attr string.
    gff = ['scaffold_52', 'Cufflinks', 'exon', '5478', '5568', '.', '+', '.', 'gene_id "XLOC_017766"; transcript_id "TCONS_00033979"; exon_number "6"; gene_name "g18412"; oId "PAC:26897502"; nearest_ref "PAC:26897502"; class_code "="; tss_id "TSS21210"; p_id "P18851";']
    gff = pybedtools.create_interval_from_list(gff)
    gff.attrs

    # TODO: is it necessary to support GFF vs GTF detection in this case:
    #
    #   GFF:
    #           class_code=" "
    #
    #   GTF:
    #           class_code "="


def test_jaccard():
    x = pybedtools.example_bedtool('a.bed')

    results = x.jaccard(pybedtools.example_bedtool('b.bed'))
    assert results == {'intersection': 46, 'union-intersection': 649, 'jaccard': 0.0708783, 'n_intersections': 2}, results

    results2 = x.jaccard(pybedtools.example_bedtool('b.bed'), stream=True)
    assert results == results2, results2

def test_reldist():
    x = pybedtools.example_bedtool('a.bed')
    results = x.reldist(pybedtools.example_bedtool('b.bed'))
    assert results == {'reldist': [0.15, 0.21, 0.28], 'count': [1, 1, 1], 'total': [3, 3, 3], 'fraction': [0.333, 0.333, 0.333]}, results

    results2 = x.reldist(pybedtools.example_bedtool('b.bed'), detail=True)
    print results2
    assert results2 == fix("""
    chr1	1	100	feature1	0	+	0.282
    chr1	100	200	feature2	0	+	0.153
    chr1	150	500	feature3	0	-	0.220""")

def test_remote_bam():
    x = pybedtools.BedTool(
        ('ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/data/HG00096/'
         'exome_alignment/HG00096.chrom11.ILLUMINA.bwa.GBR.exome.'
         '20120522.bam'),
        remote=True)
    def gen():
        for i, f in enumerate(x.bam_to_bed(stream=True)):
            yield f
            if i == 9:
                break
    results = pybedtools.BedTool(gen()).saveas()
    assert results == fix("""
11	60636	60736	SRR081241.13799221/1	0	+
11	60674	60774	SRR077487.5548889/1	0	+
11	60684	60784	SRR077487.12853301/1	0	+
11	60789	60889	SRR077487.5548889/2	0	-
11	60950	61050	SRR077487.13826494/1	0	+
11	60959	61059	SRR081241.13799221/2	0	-
11	61052	61152	SRR077487.12853301/2	0	-
11	61548	61648	SRR081241.16743804/2	0	+
11	61665	61765	SRR081241.16743804/1	0	-
11	61989	62089	SRR077487.167173/2	0	+"""), results


def test_empty_overloaded_ops():
    a = pybedtools.example_bedtool('a.bed')
    b = pybedtools.BedTool("", from_string=True)
    assert b.file_type == 'empty'

    # NOTE: change in semantics.  Previously, intersecting a BED file with an
    # empty file would return the original BED file.
    assert (a + b) == b
    assert (b + a) == b
    assert (a - b) == a
    assert (b - a) == b
    assert (b - b) == b


########NEW FILE########
__FILENAME__ = test_cbedtools
#!/usr/bin/env python

import unittest
import os
from pybedtools import Interval, IntervalFile
import pybedtools
from nose.tools import assert_raises, raises
from tfuncs import setup, teardown


PATH = os.path.dirname(__file__)

class IntervalFileTest(unittest.TestCase):
    file = "data/rmsk.hg18.chr21.small.bed"
    def setUp(self):
        self.file = os.path.join(PATH, self.file)
        self.bed = IntervalFile(self.file)

    def testFileType(self):
        self.assert_(self.bed.file_type == "bed", (self.bed.file_type, self.file))

        gff = os.path.join(PATH, "data/c.gff")
        i = IntervalFile(gff)
        self.assert_(i.file_type == "gff", (i.file_type, gff))

    def testOverlaps(self):
        i    = Interval("chr21", 9719768, 9739768)
        hits = self.bed.all_hits(i)
        self.assertEqual(len(hits), 8)
        for hit in hits:
            self.assert_(hit.start <= 9739768 and hit.end >= 9719768)

    def testStrands(self):
        i = Interval("chr21", 9719768, 9739768, "+")
        hits = self.bed.all_hits(i, same_strand=True)
        for hit in hits:
            self.assert_(hit.strand == '+')

        i = Interval("chr21", 9719768, 9739768, "-")
        hits = self.bed.all_hits(i, same_strand=True)
        for hit in hits:
            self.assert_(hit.strand == '-')

    def testRichCmp(self):

        # be obsessive . . .
        #
        # ==
        a = Interval("chr21", 100, 200)
        b = Interval("chr21", 100, 200)
        self.assert_(a == b)
        self.assertFalse(a != b)
        self.assert_(a <= b)
        self.assert_(a >= b)
        self.assertFalse(a < b)
        self.assertFalse(a > b)

        a = Interval("chr21", 100, 100)
        b = Interval("chr21", 100, 100)
        self.assert_(a == b)
        self.assertFalse(a != b)
        self.assert_(a <= b)
        self.assert_(a >= b)
        self.assertFalse(a < b)
        self.assertFalse(a > b)


        # != because of strand
        a = Interval("chr21", 100, 200, strand='+')
        b = Interval("chr21", 100, 200, strand='-')
        self.assertFalse(a == b)
        self.assert_(a != b)
        self.assertFalse(a <= b)
        self.assertFalse(a >= b)
        self.assertFalse(a < b)
        self.assertFalse(a > b)

        # a >= b
        a = Interval("chr21", 100, 300)
        b = Interval("chr21", 100, 200)
        self.assertFalse(a == b)
        self.assert_(a != b)
        self.assertFalse(a <= b)
        self.assert_(a >= b)
        self.assertFalse(a < b)
        self.assertFalse(a > b)

        # a <= b
        a = Interval("chr21", 100, 300)
        b = Interval("chr21", 300, 300)
        self.assertFalse(a == b)
        self.assert_(a != b)
        self.assert_(a <= b)
        self.assertFalse(a >= b)
        self.assertFalse(a < b)
        self.assertFalse(a > b)


        # a <= b
        a = Interval("chr21", 100, 300)
        b = Interval("chr21", 250, 300)
        self.assertFalse(a == b)
        self.assert_(a != b)
        self.assert_(a <= b)
        self.assertFalse(a >= b)
        self.assertFalse(a < b)
        self.assertFalse(a > b)

        # a < b
        a = Interval("chr21", 100, 200)
        b = Interval("chr21", 201, 300)
        self.assertFalse(a == b)
        self.assert_(a != b)
        self.assert_(a <= b)
        self.assertFalse(a >= b)
        self.assert_(a < b)
        self.assertFalse(a > b)

        # a > b
        a = Interval("chr21", 201, 300)
        b = Interval("chr21", 100, 200)
        self.assertFalse(a == b)
        self.assert_(a != b)
        self.assertFalse(a <= b)
        self.assert_(a >= b)
        self.assertFalse(a < b)
        self.assert_(a > b)

        # a != b
        a = Interval("none", 1, 100)
        b = Interval("chr21", 1, 100)
        self.assertFalse(a == b)
        self.assert_(a != b)
        self.assertFalse(a <= b)
        self.assertFalse(a >= b)
        self.assertFalse(a < b)
        self.assertFalse(a > b)

        # nested should raise NotImplementedError
        a = Interval("chr21", 100, 200)
        b = Interval("chr21", 50, 300)
        self.assertRaises(NotImplementedError, a.__eq__, b)
        self.assertRaises(NotImplementedError, a.__ne__, b)
        self.assertRaises(NotImplementedError, a.__le__, b)
        self.assertRaises(NotImplementedError, a.__ge__, b)
        self.assertRaises(NotImplementedError, a.__lt__, b)
        self.assertRaises(NotImplementedError, a.__gt__, b)


class IntervalTest(unittest.TestCase):
    file = "data/rmsk.hg18.chr21.small.bed.gz"
    chrpos = 0
    startpos = 1
    stoppos = 2
    fieldcount = 6

    def setUp(self):
        self.file = os.path.join(PATH, self.file)
        start, end, strand = 9719768, 9739768, "-"
        self.i = Interval("chr21", start, end, strand=strand)
        self.start, self.end, self.strand = start, end, strand

    def testLengths(self):
        self.assertEqual(self.end - self.start, self.i.length)
        self.assertEqual(len(self.i), self.i.length)

    def testEnds(self):
        self.assertEqual(self.end, self.i.end)
        self.assertEqual(self.start, self.i.start)

    def testStrand(self):
        self.assertEqual(self.strand, self.i.strand)

    def testGetItem(self):
        "getitem now supports direct access to the line."
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        self.assert_(iv[self.chrpos].startswith("chr"))
        self.assert_(iv[self.startpos].isdigit())
        self.assert_(iv[self.startpos].isdigit())

    def testGetItemNegative(self):
        "test negative indexes to feature."
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        self.assert_(iv[-self.fieldcount+self.chrpos].startswith("chr"), iv[-self.fieldcount+self.chrpos])
        self.assert_(iv[-self.fieldcount+self.startpos].isdigit(), iv[-self.fieldcount+self.startpos])
        self.assert_(iv[-self.fieldcount+self.stoppos].isdigit())

    def testGetItemSlice(self):
        "getitem now supports direct access to the line."
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        seqid, = iv[self.chrpos:self.chrpos+1]
        start, end = iv[self.startpos:self.stoppos+1]
        self.assert_(start.isdigit())

        self.assertEqual(int(end), iv.end)
        self.assertEqual(seqid, iv.chrom)

    def testGetItemSliceNone(self):
        " test support for funky slices."
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        self.assertEqual(len(iv[:3]), 3)
        self.assertEqual(len(iv[3:3]), 0)
        self.assertEqual(len(iv[2:]), self.fieldcount-2, iv[2:])
        
        print len(iv.fields), iv.fields
        self.assertRaises(IndexError, lambda x: iv[x], self.fieldcount+1)

    def testGetItemString(self):
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        self.assertEqual(iv['chrom'], iv.chrom)
        self.assertEqual(iv['start'], iv.start)
        self.assertEqual(iv['end'], iv.end)

    def testSetItemString(self):
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        iv['chrom'] = 'fake'
        self.assertEqual(iv['chrom'], 'fake')
        self.assertEqual(iv.chrom, 'fake')

    #TODO: need some work on getting and setting before running these
    def testSetItem(self):
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        iv.chrom = 'chrfake'
        print iv.fields
        self.assertEqual(iv['chrom'], 'chrfake')
        self.assertEqual(iv.chrom, 'chrfake')

    def testSetAttrs(self):
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        if iv.file_type != 'gff':
            iv.attrs['a'] = 'b'
            self.assertRaises(ValueError, str, iv)
            return
        iv.attrs['ID'] = 'fake'
        iv.attrs['field0'] = 'asdf'
        self.assertEqual(str(iv.attrs), iv[8])
        self.assert_('field0=asdf' in iv[8])
        self.assert_('ID=fake' in iv[8])

    def testAppend(self):
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        print iv.fields
        iv.append('asdf')
        print iv
        self.assertEqual(iv[-1], 'asdf')

    def testName(self):
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        iv.name = "bart simpson"
        self.assertEqual(iv.name, "bart simpson")
        if iv.file_type == "gff":
            self.assert_("bart" in iv.fields[8])

    def testStart(self):
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        orig_string = str(iv)
        orig_start = iv.start
        iv.start = orig_start
        second_string = str(iv)
        second_start = iv.start
        iv.start = second_start
        print '   orig:', '(start=%s)'%orig_start, orig_string
        print ' second:', '(start=%s)'%second_start, second_string
        print 'current:', '(start=%s)'%iv.start, str(iv)
        self.assert_(orig_start == second_start == iv.start)
        self.assert_(orig_string == second_string == str(iv))


class IntervalFileGzTest(IntervalFileTest):
    file = "data/rmsk.hg18.chr21.small.bed.gz"

class IntervalFileGFFTest(IntervalTest):
    file = 'data/d.gff'
    chrpos = 0
    startpos = 3
    stoppos = 4
    fieldcount = 9

    def setUp(self):
        self.file = os.path.join(PATH, self.file)
        start, end, strand = 1, 100, "+"
        self.i = Interval("chr1", start, end, strand=strand)
        self.start, self.end, self.strand = start, end, strand

    # Overwrite IntervalTest.testStart
    def testStart(self):
        ivf = IntervalFile(self.file)
        iv = ivf.next()
        orig_string = str(iv)

        # 0-based.
        orig_start = iv.start

        # Setting .start always sets 0-based coord.
        iv.start = orig_start

        # But for GFF setting .start should also make the .fields[3] the GFF
        # 1-based coord
        assert iv.start == int(iv.fields[3])-1

        second_string = str(iv)
        second_start = iv.start
        iv.start = second_start

        # Check .start and .fields[3] internal consistency again
        assert iv.start == int(iv.fields[3])-1

        print '   orig:', '(start=%s)'%orig_start, orig_string
        print ' second:', '(start=%s)'%second_start, second_string
        print 'current:', '(start=%s)'%iv.start, str(iv)
        self.assert_(orig_start == second_start == iv.start)
        self.assert_(orig_string == second_string == str(iv))


def test_zero_length_regression():
    i = Interval(chrom='chrA', start=1, end=10, name='.', score='0', strand='+')
    iminus = Interval(chrom='chrA', start=1, end=10, name='.', score='0', strand='-')
    m = pybedtools.BedTool('chrA 2 2 . 0 +', from_string=True).intervals

    assert len(m.all_hits(i)) == 1
    assert len(m.all_hits(iminus)) == 1
    assert len(m.all_hits(i, same_strand=False)) == 1
    assert len(m.all_hits(iminus, same_strand=False)) == 1
    assert len(m.all_hits(i, same_strand=True)) == 1
    assert len(m.all_hits(iminus, same_strand=True)) == 0

    assert m.any_hits(i) == 1
    assert m.any_hits(iminus) == 1
    assert m.any_hits(i, same_strand=True) == 1
    assert m.any_hits(i, same_strand=False) == 1
    assert m.any_hits(iminus, same_strand=True) == 0
    assert m.any_hits(iminus, same_strand=False) == 1

    i2 = Interval(chrom='chrA', start=999, end=9999)
    assert len(m.all_hits(i2)) == 0
    assert len(m.all_hits(i2, same_strand=True)) == 0


def test_missing_files():
    """
    previously this would crash the interpreter due to an exit(1) call in
    bedFile.cpp
    """
    a = pybedtools.BedTool('chrA 1 10', from_string=True).saveas("this_file_should_raise_BEDTools_Error")
    result = list(iter(a))
    os.unlink(a.fn)
    from pybedtools.cbedtools import BedToolsFileError
    def crashes():
        list(iter(a))

    assert_raises(BedToolsFileError, crashes)

if __name__ == "__main__":
    unittest.main()
    pybedtools.cleanup(remove_all=True)



########NEW FILE########
__FILENAME__ = test_contrib
"""
tests for contrib module
"""
import sys
import os
import pybedtools
from pybedtools import Interval
#from pybedtools.contrib import Classifier
from tfuncs import setup, teardown, testdir, test_tempdir, unwriteable

# model for gdc.
# chr2L, starts at 1 and spacing is 10bp.
# import gdc
# g = gdc.GenomeModel(chrom_start=1,
#                     chrom='chr2L',
#                     scalar=10,
#                     read_length=5)
"""
#         10       20        30
#123456789012345678901234567890
   >===||||||~~~~|||==@    #mRNA_xs2_g2_+
               <|||||||@   #tRNA_t2_t2_-
$+     -      --     +     #
$      +      + +          #
"""
#^     ^      ^^^    ^
#|     |      |      |- STRANDED: exon, UTR, mRNA, gene
#      |      |         UNSTRANDED: exon, UTR, mRNA, tRNA, gene, CDS (cause gdc considers tRNA's exon as CDS)
#|     |      |||- STRANDED: intron, mRNA, gene
#|     |      |    UNSTRANDED: intron, mRNA, gene, tRNA, CDS (because GDC considers the tRNA's exon as CDS)
#|     |      ||- STRANDED: none
#|     |      |   UNSTRANDED: intron, mRNA, gene
#|     |      |-STRANDED: +: intron, mRNA, gene; -: none
#|     |        UNSTRANDED: intron, mRNA, gene
#|     |- STRANDED: +: exon, CDS, mRNA, gene; -: none
#|        UNSTRANDED: exon, CDS, mRNA, gene
#- STRANDED: none
#  UNSTRANDED: none


def fix(x):
    """
    Replaces spaces with tabs, removes spurious newlines, and lstrip()s each
    line. Makes it really easy to create BED files on the fly for testing and
    checking.
    """
    s = ""
    for i in  x.splitlines():
        i = i.lstrip()
        if i.endswith('\t'):
            add_tab = '\t'
        else:
            add_tab = ''
        if len(i) == 0:
            continue
        i = i.split()
        i = '\t'.join(i) + add_tab + '\n'
        s += i
    return s

def _classifier():

    c = Classifier(
            bed=pybedtools.example_filename('gdc.bed'),
            annotations=pybedtools.example_filename('gdc.gff'))
    c.classify()

    bed = pybedtools.example_bedtool('gdc.bed')

    assert c.class_counts == {
            frozenset(['UTR', 'exon', 'mRNA', 'CDS', 'tRNA', 'gene']): 1,
            frozenset(['intron', 'gene', 'mRNA']): 3,
            frozenset([]): 1,
            frozenset(['gene', 'exon', 'mRNA', 'CDS']): 2,
            frozenset(['exon', 'mRNA', 'CDS', 'tRNA', 'intron', 'gene']): 1}

    assert c.feature_classes == {
            bed[0]: set(['.']),
            bed[1]: set(['gene', 'exon', 'mRNA', 'CDS']),
            bed[2]: set(['intron', 'gene', 'mRNA']),
            bed[3]: set(['intron', 'gene', 'mRNA']),
            bed[4]: set(['tRNA', 'UTR', 'exon', 'mRNA', 'CDS', 'gene']),
            bed[5]: set(['gene', 'exon', 'mRNA', 'CDS']),
            bed[6]: set(['intron', 'gene', 'mRNA']),
            bed[7]: set(['tRNA', 'intron', 'exon', 'mRNA', 'CDS', 'gene']),
            }

    print 'use these indexes for debugging'
    for i, f in enumerate(bed):
        print i, f

    for k, v in c.class_features.items():
        print k
        for i in v:
            print '\t' + str(i)

    assert c.class_features == {
            frozenset([]): [bed[0]],
            frozenset(['intron', 'gene', 'mRNA']): [bed[6], bed[2], bed[3]],
            frozenset(['gene', 'exon', 'mRNA', 'CDS']): [bed[5], bed[1]],
            frozenset(['UTR', 'exon', 'mRNA', 'CDS', 'tRNA', 'gene']): [bed[4]],
            frozenset(['exon', 'mRNA', 'CDS', 'tRNA', 'intron', 'gene']): [bed[7]],
            }

def test_cleaned_intersect():
    x = pybedtools.BedTool("""
    chr1 1 10      1
    chr1 20 30     2
    chr1 100 120   3
    """, from_string=True)
    y = pybedtools.BedTool("""
    chr1 2 7       4
    chr1 110 120   5
    chr1 200 210   6
    """, from_string=True)
    z = pybedtools.BedTool("""
    chr1 25 40     7
    chr1 190 205   8
    chr1 1000 1001 9
    """, from_string=True)

    # Two-way test
    #
    x2, y2 = pybedtools.contrib.venn_maker.cleaned_intersect([x, y])

    # x should be the same -- 1, 2, 3
    # y should have 1, 3, 6

    assert x2 == fix("""
    chr1 1 10
    chr1 20 30
    chr1 100 120
    """)

    assert y2 == fix("""
    chr1 1 10
    chr1 100 120
    chr1 200 210""")

    # Three-way test
    #
    x3, y3, z3 = pybedtools.contrib.venn_maker.cleaned_intersect([x, y, z])

    # x should be the same -- 1, 2, 3
    # y should have 1, 3, 6
    # z should have 2, 6

    assert x3 == fix("""
    chr1 1 10
    chr1 20 30
    chr1 100 120
    """)

    assert y3 == fix("""
    chr1 1 10
    chr1 100 120
    chr1 200 210""")

    assert z3 == fix("""
    chr1 20 30
    chr1 200 210
    chr1 1000 1001""")

    try:
        pybedtools.helpers._check_for_R()
        print pybedtools.contrib.venn_maker.venn_maker(
                beds=[x, y, z],
                names=['x','y','z'],
                figure_filename='out.tiff',
                additional_args = ['euler.d=TRUE', 'scaled=TRUE', 'fill=c("red","blue", "orange")'],
                run=True)
    except ValueError:
        sys.stderr.write('R installation not found; skipping test')

    if os.path.exists('out.tiff'):
        os.unlink('out.tiff')


def test_venn_maker_3way_1empty():
    # Fix issue #95. The problem was that BedTool.cat() failed when checking
    # field counts on an empty file.  The fix was to make cat() aware of empty
    # files when checking field num and field type.
    a = pybedtools.BedTool("""
    chr1 10 100
    chr2 10 100""", from_string=True)
    b = pybedtools.BedTool("""
    chr1 12 80""", from_string=True)
    c = pybedtools.BedTool("""
    chr2 20 40""", from_string=True)
    try:
        pybedtools.contrib.venn_maker.venn_maker([a, b, c], run=True, figure_filename='t.tiff')
    except ValueError:
        print "R not installed, skipping test"
        #os.unlink('t.tiff')

########NEW FILE########
__FILENAME__ = test_helpers
import pybedtools
import sys
import os, difflib
from nose.tools import assert_raises
from tfuncs import setup, teardown, testdir, test_tempdir, unwriteable

def fix(x):
    """
    Replaces spaces with tabs, removes spurious newlines, and lstrip()s each
    line. Makes it really easy to create BED files on the fly for testing and
    checking.
    """
    s = ""
    for i in  x.splitlines():
        i = i.strip()
        if len(i) == 0:
            continue
        i = i.split()
        i = '\t'.join(i)+'\n'
        s += i
    return s


def test_isBAM():
    bam = pybedtools.example_filename('x.bam')
    notabam = pybedtools.example_filename('a.bed')
    open('tiny.txt', 'w').close()
    assert pybedtools.helpers.isBAM(bam)
    assert not pybedtools.helpers.isBAM(notabam)
    assert not pybedtools.helpers.isBAM('tiny.txt')
    os.unlink('tiny.txt')

def test_cleanup():
    """
    make sure the tempdir and cleanup work
    """
    #assert os.path.abspath(pybedtools.get_tempdir()) == os.path.abspath('.')

    # make a fake tempfile, not created during this pybedtools session
    pybedtools.cleanup()

    testfn = os.path.join(test_tempdir, 'pybedtools.TESTING.tmp')
    os.system('touch %s' % testfn)
    assert os.path.exists(testfn)

    # make some temp files
    a = pybedtools.BedTool(os.path.join(testdir, 'data', 'a.bed'))
    b = pybedtools.BedTool(os.path.join(testdir, 'data', 'b.bed'))
    c = a.intersect(b)

    # after standard cleanup, c's fn should be gone but the fake one still
    # there...
    pybedtools.cleanup(verbose=True)
    assert os.path.exists(testfn)
    assert not os.path.exists(c.fn)

    # Unless we force the removal of all temp files.
    pybedtools.cleanup(remove_all=True)
    assert not os.path.exists(testfn)

    # a.fn and b.fn better be there still!
    assert os.path.exists(a.fn)
    assert os.path.exists(b.fn)

def test_bedtools_check():
    # this should run fine (especially since we've already imported pybedtools)
    pybedtools.check_for_bedtools()

    # but this should crap out
    assert_raises(OSError, pybedtools.check_for_bedtools, **dict(program_to_check='nonexistent', force_check=True))

def test_call():
    tmp = os.path.join(pybedtools.get_tempdir(), 'test.output')
    from pybedtools.helpers import call_bedtools, BEDToolsError
    assert_raises(BEDToolsError, call_bedtools, *(['intersectBe'], tmp))

    a = pybedtools.example_bedtool('a.bed')

    # momentarily redirect stderr to file so the error message doesn't spew all
    # over the place when testing
    orig_stderr = sys.stderr
    sys.stderr = open(a._tmp(), 'w')
    #assert_raises(BEDToolsError, a.intersect, a=a.fn, b=a.fn, z=True)
    sys.stderr = orig_stderr

    pybedtools.set_bedtools_path('nonexistent')
    a = pybedtools.example_bedtool('a.bed')
    assert_raises(OSError, a.intersect, a)
    pybedtools.set_bedtools_path()
    assert a.intersect(a,u=True) == a


def test_chromsizes():
    assert_raises(OSError, pybedtools.get_chromsizes_from_ucsc, 'dm3', mysql='wrong path')
    assert_raises(ValueError, pybedtools.get_chromsizes_from_ucsc, 'dm3', timeout=0)
    try:

        print pybedtools.chromsizes('dm3')
        print pybedtools.get_chromsizes_from_ucsc('dm3')
        assert pybedtools.chromsizes('dm3') == pybedtools.get_chromsizes_from_ucsc('dm3')

        hg17 = pybedtools.chromsizes('hg17')

        assert hg17['chr1'] == (0, 245522847)

        fn = pybedtools.chromsizes_to_file(hg17, fn='hg17.genome')
        expected = 'chr1\t245522847\n'
        results = open(fn).readline()
        print results
        assert expected == results

        # make sure the tempfile version works, too
        fn = pybedtools.chromsizes_to_file(hg17, fn=None)
        expected = 'chr1\t245522847\n'
        results = open(fn).readline()
        print results
        assert expected == results

        assert_raises(OSError,
                      pybedtools.get_chromsizes_from_ucsc, 
                      **dict(genome='hg17', mysql='nonexistent'))

        os.unlink('hg17.genome')
    except OSError:
        sys.stdout.write("mysql error -- test for chromsizes from UCSC didn't run")

def test_ff_center():
    from pybedtools.featurefuncs import center
    a = pybedtools.example_bedtool('a.bed')
    b = a.each(center, width=10)
    expected = fix("""
    chr1	45	55	feature1	0	+
    chr1	145	155	feature2	0	+
    chr1	320	330	feature3	0	-
    chr1	920	930	feature4	0	+""")
    assert str(b) == expected

def test_getting_example_beds():
    assert 'a.bed' in pybedtools.list_example_files()

    a_fn = pybedtools.example_filename('a.bed')
    assert a_fn == os.path.join(testdir, 'data', 'a.bed')

    a = pybedtools.example_bedtool('a.bed')
    assert a.fn == os.path.join(testdir, 'data', 'a.bed')

    # complain appropriately if nonexistent paths are asked for
    assert_raises(ValueError, pybedtools.example_filename, 'nonexistent')
    assert_raises(ValueError, pybedtools.example_bedtool, 'nonexistent')
    assert_raises(ValueError, pybedtools.set_tempdir, 'nonexistent')


def teardown():
    # always run this!
    pybedtools.cleanup(remove_all=True)

########NEW FILE########
__FILENAME__ = test_iter
import difflib
import itertools
import yaml
import os
import gzip
import pybedtools
# The functools.partial trick to get descriptions to be valid is from:
#
#   http://code.google.com/p/python-nose/issues/detail?id=244#c1
from functools import partial

this_dir = os.path.dirname(__file__)
config_fn = os.path.join(this_dir, 'test_cases.yaml')

def gz(x):
    """
    Gzips a file to a tempfile, and returns a new BedTool using the gzipped
    version.
    """
    fin = open(x.fn)
    gzfn = pybedtools.BedTool._tmp()
    fout = gzip.open(gzfn, 'wb')
    fout.writelines(fin)
    fout.close()
    fin.close()
    return pybedtools.BedTool(gzfn)

def fix(x):
    """
    Replaces spaces with tabs, removes spurious newlines, and lstrip()s each
    line. Makes it really easy to create BED files on the fly for testing and
    checking.
    """
    s = ""
    for i in x.splitlines():
        i = i.strip('\n\r')
        if len(i) == 0:
            continue

        # If the expected output contains tabs, then use those to split,
        # otherwise space.  This allows you to have expected output with blank
        # fields (e.g., "\t\t")
        if '\t' in i:
            i = i.split('\t')
        else:
            i = i.split()

        i = '\t'.join(i)+'\n'
        s += i
    return s


def parse_yaml(infile):
    x = yaml.load(open(infile).read())
    for test_case in x:
        method = test_case['method']
        send_kwargs = test_case['kwargs']
        expected = test_case['expected']
        yield method, send_kwargs, expected


def run(method, bedtool, expected, **kwargs):
    result = getattr(bedtool, method)(**kwargs)
    res = str(result)
    expected = fix(expected)
    try:
        assert res == expected

    except AssertionError:
        print result.fn
        print 'Method call:'
        args = []
        for key, val in kwargs.items():
            args.append(('%s=%s' % (key, val)).strip())

        args = ', '.join(args)
        print 'BedTool.%(method)s(%(args)s)' % locals()
        print 'Got:'
        print res
        print 'Expected:'
        print expected
        print 'Diff:'
        for i in difflib.unified_diff(res.splitlines(1), expected.splitlines(1)):
            print i,

        # Make tabs and newlines visible
        spec_res = res.replace('\t', '\\t').replace('\n', '\\n\n')
        spec_expected = expected.replace('\t', '\\t').replace('\n', '\\n\n')

        print 'Showing special characters:'
        print 'Got:'
        print spec_res
        print 'Expected:'
        print spec_expected
        print 'Diff:'
        for i in difflib.unified_diff(spec_res.splitlines(1), spec_expected.splitlines(1)):
            print i,
        raise


# List of methods that *only* take BAM as input
bam_methods = ('bam_to_bed',)

# List of supported BedTool construction from BAM files.  Currently only
# file-based.
supported_bam = ('filename', )

converter = {'filename': lambda x: pybedtools.BedTool(x.fn),
             'generator': lambda x: pybedtools.BedTool(i for i in x),
             'stream': lambda x: pybedtools.BedTool(open(x.fn)),
             'gzip': gz,
            }

def test_a_b_methods():
    """
    Generator that yields tests, inserting different versions of `a` and `b` as
    needed
    """
    for method, send_kwargs, expected in parse_yaml(config_fn):
        a_isbam = False
        b_isbam = False

        if 'abam' in send_kwargs:
            send_kwargs['abam'] = pybedtools.example_filename(send_kwargs['abam'])
            send_kwargs['a'] = send_kwargs['abam']
            a_isbam = True

        if not (('a' in send_kwargs) and ('b' in send_kwargs)):
            continue

        # If abam, makes a BedTool out of it anyway.
        orig_a = pybedtools.example_bedtool(send_kwargs['a'])
        orig_b = pybedtools.example_bedtool(send_kwargs['b'])

        del send_kwargs['a']
        del send_kwargs['b']

        if orig_a._isbam:
            a_isbam = True
        if orig_b._isbam:
            b_isbam = True

        for kind_a, kind_b in itertools.permutations(('filename', 'generator', 'stream', 'gzip'), 2):

            if a_isbam and (kind_a not in supported_bam):
                continue

            if b_isbam and (kind_b not in supported_bam):
                continue

            # Convert to file/generator/stream
            bedtool = converter[kind_a](orig_a)
            b = converter[kind_b](orig_b)

            kind = 'a=%(kind_a)s, b=%(kind_b)s abam=%(a_isbam)s bbam=%(b_isbam)s' % locals()

            send_kwargs['b'] = b

            f = partial(run, method, bedtool, expected, **send_kwargs)

            # Meaningful description
            f.description = '%(method)s, %(kind)s, %(send_kwargs)s' % locals()
            yield (f, )

def test_i_methods():
    """
    Generator that yields tests, inserting different versions of `i` as needed
    """
    for method, send_kwargs, expected in parse_yaml(config_fn):
        i_isbam = False
        if 'ibam' in send_kwargs:
            i_isbam = True
            send_kwargs['ibam'] = pybedtools.example_filename(send_kwargs['ibam'])
            send_kwargs['i'] = send_kwargs['ibam']

        if ('a' in send_kwargs) and ('b' in send_kwargs):
            continue

        if ('i' not in send_kwargs) and ('ibam' not in send_kwargs):
            continue

        if 'files' in send_kwargs:
            send_kwargs['files'] = [pybedtools.example_filename(i) for i in send_kwargs['files']]

        orig_i = pybedtools.example_bedtool(send_kwargs['i'])
        if orig_i._isbam:
            i_isbam = True

        del send_kwargs['i']

        done = []
        for kind_i in ('filename', 'generator', 'stream', 'gzip'):
            if i_isbam:
                if (kind_i not in supported_bam):
                    continue
            i = converter[kind_i](orig_i)
            kind = 'i=%(kind_i)s ibam=%(i_isbam)s' % locals()
            f = partial(run, method, i, expected, **send_kwargs)
            f.description = '%(method)s, %(kind)s, %(send_kwargs)s' % locals()
            yield (f, )

def test_bed_methods():
    """
    Generator that yields tests, inserting different versions of `bed` as needed
    """
    for method, send_kwargs, expected in parse_yaml(config_fn):
        ignore = ['a', 'b','abam','i']
        skip_test = False
        for i in ignore:
            if i in send_kwargs:
                skip_test = True
        if skip_test:
            continue
        if 'bed' not in send_kwargs:
            continue

        if 'files' in send_kwargs:
            send_kwargs['files'] = [pybedtools.example_filename(i) for i in send_kwargs['files']]

        if 'bams' in send_kwargs:
            send_kwargs['bams'] = [pybedtools.example_filename(i) for i in send_kwargs['bams']]

        if 'fi' in send_kwargs:
            send_kwargs['fi'] = pybedtools.example_filename(send_kwargs['fi'])

        orig_bed = pybedtools.example_bedtool(send_kwargs['bed'])

        del send_kwargs['bed']

        done = []
        for kind_bed in ('filename', 'generator', 'stream', 'gzip'):
            bed = converter[kind_bed](orig_bed)
            kind = 'i=%(kind_bed)s' % locals()
            f = partial(run, method, bed, expected, **send_kwargs)
            f.description = '%(method)s, %(kind)s, %(send_kwargs)s' % locals()
            yield (f, )

def teardown():
    pybedtools.cleanup(remove_all=True)

########NEW FILE########
__FILENAME__ = test_scripts
import pybedtools
from tfuncs import setup, teardown
from pybedtools.scripts import annotate, venn_mpl, venn_gchart
from nose.tools import assert_raises
import os
import sys


def test_annotate_main():
    # exits after printing help when sys.argv is not as it should be.
    orig_stderr = sys.stderr
    sys.stderr = open('annotmp','w')
    assert_raises(SystemExit, annotate.main)
    sys.stderr = orig_stderr
    os.unlink('annotmp')

def test_annotate_closest():
    a = pybedtools.example_bedtool('m1.bed')
    b = pybedtools.example_bedtool('mm9.bed12')
    c = annotate.add_closest(a, b)
    assert len(a) == len(c), (len(a), len(c), str(c))
    assert a.field_count() == c.field_count() - 2
    # in this test-case, the final column should be exon;intron
    # since m1 completely contains both an exon and an intron.
    f = iter(c).next()
    # waiting for fix to bedtools:
    #assert f.fields[-1] == "exon;intron", f.fields[-1]


def test_annotate_xstream():
    a = pybedtools.example_bedtool('m1.bed')
    b = pybedtools.example_bedtool('mm9.bed12')
    c = annotate.add_xstream(a, b, dist=1000, updown="up")
    assert a.field_count() == c.field_count() - 1
    assert len(a) == len(c)
    d = annotate.add_xstream(c, b, dist=1000, updown="down")
    assert a.field_count() == d.field_count() - 2


def test_venn_mpl():
    """
    compares output image to expected
    """
    try:
        import matplotlib
    except ImportError:
        import sys
        sys.stderr.write('Need matplotlib installed to test venn_mpl')
        return

    here = os.path.dirname(__file__)
    expected_fn = os.path.join(here, 'mpl-expected.png')

    original = pybedtools.example_bedtool('rmsk.hg18.chr21.small.bed').sort().merge()
    a = pybedtools.BedTool(original[:300]).saveas()
    b = pybedtools.BedTool(original[:20]).saveas().cat(pybedtools.BedTool(original[400:500]).saveas())
    c = pybedtools.BedTool(original[15:30]).saveas().cat(pybedtools.BedTool(original[450:650]).saveas())

    outfn = 'mplout.png'
    venn_mpl.venn_mpl(a=a.fn, b=b.fn, c=c.fn, colors=['r','b','g'], outfn=outfn, labels=['a','b','c'])

    # On a different machine, the created image is not visibly different but is
    # numerically different.  Not sure what a reasonable tolerance is, but this
    # seems to work for now....
    o = matplotlib.image.imread(outfn)
    e = matplotlib.image.imread(expected_fn)

    TOLERANCE = 40
    SUM = abs((o - e).sum())
    assert SUM < TOLERANCE, SUM

    os.unlink(outfn)



def test_venn_gchart():
    here = os.path.dirname(__file__)
    expected = open(os.path.join(here, 'gchart-expected.png')).read()

    original = pybedtools.example_bedtool('rmsk.hg18.chr21.small.bed').sort().merge()
    a = pybedtools.BedTool(original[:300]).saveas()
    b = pybedtools.BedTool(original[:20]).saveas().cat(pybedtools.BedTool(original[400:500]).saveas())
    c = pybedtools.BedTool(original[15:30]).saveas().cat(pybedtools.BedTool(original[450:650]).saveas())

    colors='00FF00,FF0000,0000FF'
    outfn = 'gchart_out.png'
    labels = 'a,b,c'

    expected_data = {'chco': '00FF00,FF0000,0000FF',
                     'chd': 't:1.0,0.4,0.716666666667,0.0666666666667,0.05,0.183333333333,0.0166666666667',
                     'chs': '300x300',
                     'cht': 'v',
                     'chdl': 'a|b|c'}

    data = venn_gchart.venn_gchart(a=a.fn,
                            b=b.fn,
                            c=c.fn,
                            colors=colors.split(','),
                            labels=labels.split(','),
                            size='300x300')

    print data
    for key in expected_data.keys():
        e = expected_data[key]
        o = data[key]
        print 'key:', key
        print 'expected:', e
        print 'observed:', o
        assert e == o

    venn_gchart.gchart(data, outfn)

    assert open(outfn).read() == expected
    os.unlink(outfn)

def test_venn_mpl_main():
    orig_stderr = sys.stderr
    sys.stderr = open('mpltmp','w')
    assert_raises(SystemExit, venn_mpl.main)
    sys.stderr = orig_stderr
    os.unlink('mpltmp')

def test_venn_gchart_main():
    orig_stderr = sys.stderr
    sys.stderr = open('gcharttmp','w')
    assert_raises(SystemExit, venn_gchart.main)
    sys.stderr = orig_stderr
    os.unlink('gcharttmp')

########NEW FILE########
__FILENAME__ = tfuncs
import pybedtools
import os

testdir = os.path.dirname(__file__)
test_tempdir = os.path.join(os.path.abspath(testdir), 'tmp')
unwriteable = os.path.join(os.path.abspath(testdir), 'unwriteable')

def setup():
    if not os.path.exists(test_tempdir):
        os.system('mkdir -p %s' % test_tempdir)
    pybedtools.set_tempdir(test_tempdir)

def teardown():
    if os.path.exists(test_tempdir):
        os.system('rm -r %s' % test_tempdir)
    pybedtools.cleanup()

########NEW FILE########
__FILENAME__ = t_len_leak
import pybedtools

fn = pybedtools.example_filename('a.bed')

def show_open_fds(func):
    doc = func.__doc__
    print
    print doc
    print "." * len(doc)
    orig_fds = pybedtools.helpers.n_open_fds()
    print '\t', max(func(fn)) - orig_fds, 'file-based'


def func1(src):
    "create bedtool in loop"
    for i in range(10):
        x = pybedtools.BedTool(src)
        yield pybedtools.helpers.n_open_fds()


def func2(src):
    'create bedtool in loop and check length'
    for i in range(10):
        x = pybedtools.BedTool(src)
        len(x)
        yield pybedtools.helpers.n_open_fds()


def func3(src):
    'create bedtool outside of loop; check length inside'
    x = pybedtools.BedTool(src)
    for i in range(10):
        len(x)
        yield pybedtools.helpers.n_open_fds()


def func4(src):
    'create and len in loop; don\'t assign to var'
    for i in range(10):
        len(pybedtools.BedTool(src))
        yield pybedtools.helpers.n_open_fds()

if __name__ == "__main__":
    for k, v in sorted(locals().items()):
        if k.startswith('func'):
            show_open_fds(v)

########NEW FILE########
__FILENAME__ = version
__version__="0.6.6"

########NEW FILE########
__FILENAME__ = __main__
#!/usr/bin/env python
"""
pybedtools utility scripts:

"""
import sys
import textwrap


def import_module(name):
    __import__("%s" % (name,), globals(), locals(), [], -1)
    return sys.modules[name]


def script_names(module):
    return sorted(
            [script for script in  module.__all__ if not script[:2] == "__"])


def main():
    m = import_module("pybedtools.scripts")
    scripts = script_names(m)
    mods = [import_module("pybedtools.scripts.%s" % s) for s in scripts]

    if (len(sys.argv) != 1 and not sys.argv[1] in scripts) \
       or len(sys.argv) == 1:

        print __doc__.strip() + "\n"
        for name, mod in zip(scripts, mods):
            scriptname = " %-22s:" % name
            padding = ' ' * (len(scriptname) + 1)
            doclines = textwrap.wrap(textwrap.dedent(mod.main.__doc__), 50)
            print scriptname, doclines[0]
            for line in doclines[1:]:
                print padding, line
            print

    else:
        mname = sys.argv.pop(1)
        i = scripts.index(mname)
        module = mods[i]
        module.main()

if __name__ == "__main__":
    main()

########NEW FILE########
