__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Smiley documentation build configuration file, created by
# sphinx-quickstart on Sun May 26 15:02:50 2013.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import subprocess

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Smiley'
copyright = u'2013, Doug Hellmann'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = subprocess.check_output([
    'sh', '-c',
    'cd ../..; python setup.py --version',
])
version = version.strip()
# The full version, including alpha/beta/rc tags.
release = version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Smileydoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Smiley.tex', u'Smiley Documentation',
   u'Doug Hellmann', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'smiley', u'Smiley Documentation',
     [u'Doug Hellmann'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Smiley', u'Smiley Documentation',
   u'Doug Hellmann', 'Smiley', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False

########NEW FILE########
__FILENAME__ = app
import logging
import sys

from cliff import app
from cliff import commandmanager

import pkg_resources


class Smiley(app.App):

    log = logging.getLogger(__name__)

    def __init__(self):
        dist = pkg_resources.get_distribution('smiley')
        super(Smiley, self).__init__(
            description='smiley spies on your apps as they run',
            version=dist.version,
            command_manager=commandmanager.CommandManager('smiley.commands'),
        )


def main(argv=sys.argv[1:]):
    return Smiley().run(argv)


if __name__ == '__main__':
    sys.exit(main(sys.argv[1:]))

########NEW FILE########
__FILENAME__ = list
import logging

from cliff import lister

from smiley import db


def _format_timestamp(t):
    if t is None:
        return ''
    return t.isoformat()


class List(lister.Lister):
    """Query the database and show the existing runs.

    """

    log = logging.getLogger(__name__)

    _cwd = None

    DEFAULT_COLUMNS = (
        'id', 'cwd', 'description',
        'start time', 'end time',
        'error message',
    )

    def get_parser(self, prog_name):
        parser = super(List, self).get_parser(prog_name)
        parser.add_argument(
            '--database',
            default='smiley.db',
            help='filename for the database (%(default)s)',
        )
        parser.add_argument(
            '--errors',
            default=False,
            action='store_true',
            help='only include runs with errors',
        )
        return parser

    def take_action(self, parsed_args):
        self.db = db.DB(parsed_args.database)
        runs = ((r.id, r.cwd,
                 ' '.join(r.description),
                 _format_timestamp(r.start_time),
                 _format_timestamp(r.end_time),
                 r.error_message)
                for r in self.db.get_runs(only_errors=parsed_args.errors))
        return (self.DEFAULT_COLUMNS, runs)

########NEW FILE########
__FILENAME__ = listen_cmd
import abc
import logging

from cliff import command

from smiley import listener


class ListeningCommand(command.Command):
    """Base class for commands that listen for messages from the runner.
    """

    __metaclass__ = abc.ABCMeta

    log = logging.getLogger(__name__)

    def get_parser(self, prog_name):
        parser = super(ListeningCommand, self).get_parser(prog_name)
        parser.add_argument(
            '--socket',
            dest='socket',
            default='tcp://127.0.0.1:5556',
            help='URL for the socket where to monitor on (%(default)s)',
        )
        return parser

    @abc.abstractmethod
    def _process_message(self, msg):
        msg_type, msg_payload = msg
        self.log.debug('MESSAGE: %s %r', msg_type, msg_payload)
        return

    def take_action(self, parsed_args):
        self._parsed_args = parsed_args
        l = listener.Listener(parsed_args.socket)
        l.poll_forever(self._process_message)
        return

########NEW FILE########
__FILENAME__ = monitor
import linecache
import logging
import os

from smiley.commands import listen_cmd
from smiley import output


class Monitor(listen_cmd.ListeningCommand):
    """Listen for running programs and show their progress.
    """

    log = logging.getLogger(__name__)

    def get_parser(self, prog_name):
        parser = super(Monitor, self).get_parser(prog_name)
        parser.add_argument(
            '--exit',
            default=False,
            action='store_true',
            help='Exit monitor when sender exits',
        )
        return parser

    def take_action(self, parsed_args):
        self.out = output.OutputFormatter(linecache.getline)
        super(Monitor, self).take_action(parsed_args)

    def _process_message(self, msg):
        msg_type, msg_payload = msg
        self.log.debug('MESSAGE: %s %r', msg_type, msg_payload)

        if msg_type == 'start_run':
            self.out.start_run(
                msg_payload['run_id'],
                os.getcwd(),
                msg_payload['command_line'],
                msg_payload['timestamp'],
            )

        elif msg_type == 'end_run':
            self.out.end_run(
                msg_payload['run_id'],
                msg_payload['timestamp'],
                msg_payload['message'],
                msg_payload['traceback'],
            )
            if self._parsed_args.exit:
                raise SystemExit()

        else:
            self.out.trace(
                msg_payload['run_id'],
                msg_type,
                msg_payload['func_name'],
                msg_payload['line_no'],
                msg_payload['filename'],
                msg_payload['arg'],
                msg_payload['local_vars'],
                msg_payload['timestamp'],
            )

########NEW FILE########
__FILENAME__ = record
import logging

from smiley import local
from smiley.commands import listen_cmd


class Record(listen_cmd.ListeningCommand):
    """Listen for running programs and record the data to a database for
    later use.

    """

    log = logging.getLogger(__name__)

    _cwd = None

    def get_parser(self, prog_name):
        parser = super(Record, self).get_parser(prog_name)
        parser.add_argument(
            '--database',
            default='smiley.db',
            help='filename for the database (%(default)s)',
        )
        return parser

    def _process_message(self, msg):
        msg_type, msg_payload = msg
        self.log.debug('MESSAGE: %s %r', msg_type, msg_payload)

        if msg_type == 'start_run':
            command_line = ' '.join(msg_payload.get('command_line', []))
            self.log.info(
                'Starting new run: %s',
                command_line,
            )
            self.publisher.start_run(
                run_id=msg_payload['run_id'],
                cwd=self._cwd,
                description=msg_payload.get('command_line', []),
                start_time=msg_payload.get('timestamp'),
            )

        elif msg_type == 'end_run':
            self.log.info('Finished run')
            self.publisher.end_run(
                run_id=msg_payload['run_id'],
                end_time=msg_payload.get('timestamp'),
                message=msg_payload.get('message'),
                traceback=msg_payload.get('traceback'),
            )

        else:
            self.publisher.trace(
                run_id=msg_payload['run_id'],
                call_id=msg_payload['call_id'],
                event=msg_type,
                func_name=msg_payload.get('func_name'),
                line_no=msg_payload.get('line_no'),
                filename=msg_payload.get('filename'),
                trace_arg=msg_payload.get('arg'),
                local_vars=msg_payload.get('local_vars'),
                timestamp=msg_payload.get('timestamp'),
            )

    def take_action(self, parsed_args):
        self.publisher = local.LocalPublisher(parsed_args.database)
        return super(Record, self).take_action(parsed_args)

########NEW FILE########
__FILENAME__ = replay
import logging

from cliff import command

from smiley import db
from smiley import db_linecache
from smiley import output


class Replay(command.Command):
    """Query the database and replay a previously captured run.

    """

    log = logging.getLogger(__name__)

    _cwd = None

    def get_parser(self, prog_name):
        parser = super(Replay, self).get_parser(prog_name)
        parser.add_argument(
            '--database',
            default='smiley.db',
            help='filename for the database (%(default)s)',
        )
        parser.add_argument(
            'run_id',
            help='identifier for the run',
        )
        return parser

    def take_action(self, parsed_args):
        self.db = db.DB(parsed_args.database)
        cache = db_linecache.DBLineCache(self.db, parsed_args.run_id)
        self.out = output.OutputFormatter(cache.getline)

        run_details = self.db.get_run(parsed_args.run_id)
        self.out.start_run(
            run_details.id,
            run_details.cwd,
            run_details.description,
            run_details.start_time,
        )
        for t in self.db.get_trace(parsed_args.run_id):
            self.out.trace(
                t.run_id,
                t.event,
                t.func_name,
                t.line_no,
                t.filename,
                t.trace_arg,
                t.local_vars,
                t.timestamp,
            )
        self.out.end_run(
            run_details.id,
            run_details.end_time,
            run_details.error_message,
            None,  # run_details.traceback,
        )

########NEW FILE########
__FILENAME__ = report
import logging

from cliff import command

from smiley import db
from smiley.report import html


class Report(command.Command):
    """Create an HTML report for a previously captured run.

    """

    log = logging.getLogger(__name__)

    _cwd = None

    def get_parser(self, prog_name):
        parser = super(Report, self).get_parser(prog_name)
        parser.add_argument(
            '--database',
            default='smiley.db',
            help='filename for the database (%(default)s)',
        )
        parser.add_argument(
            '--items-per-page',
            default=100,
            type=int,
            help='steps of execution shown on a page (%(default)s)',
        )
        parser.add_argument(
            '-o', '--output-directory',
            default=None,
            help='location of the output ($run_id)',
        )
        parser.add_argument(
            '--title',
            default='',
            help='title for the report',
        )
        parser.add_argument(
            'run_id',
            help='identifier for the run',
        )
        return parser

    def take_action(self, parsed_args):
        database = db.DB(parsed_args.database)
        output_dir = parsed_args.output_directory or parsed_args.run_id
        report = html.HTMLReport(
            run_id=parsed_args.run_id,
            output_dir=output_dir,
            database=database,
            title=parsed_args.title or parsed_args.run_id,
            per_page=parsed_args.items_per_page,
        )
        report.run()

########NEW FILE########
__FILENAME__ = run
import logging
import os
import sys

from cliff import command

from smiley import local
from smiley import publisher
from smiley import tracer


class Run(command.Command):
    """Run another program with monitoring enabled.
    """

    log = logging.getLogger(__name__)

    def get_parser(self, prog_name):
        parser = super(Run, self).get_parser(prog_name)
        group = parser.add_mutually_exclusive_group()
        group.add_argument(
            '--local',
            action='store_const',
            dest='mode',
            const='local',
            help='write data to a local database',
        )
        group.add_argument(
            '--remote',
            action='store_const',
            dest='mode',
            const='remote',
            default='remote',
            help='send data to the remote monitor (default)',
        )
        include_group = parser.add_argument_group('covering')
        include_group.add_argument(
            '--include-stdlib',
            action='store_true',
            default=False,
            help='trace into standard library modules',
        )
        include_group.add_argument(
            '--no-include-stdlib',
            action='store_false',
            help='trace into standard library modules (default)',
        )
        include_group.add_argument(
            '--include-site-packages',
            action='store_true',
            default=True,
            help='trace into modules from site-packages (default)',
        )
        include_group.add_argument(
            '--no-include-site-packages',
            action='store_false',
            help='skip modules from site-packages',
        )
        include_group.add_argument(
            '--include-package',
            action='append',
            dest='include_packages',
            default=[],
            help='trace into a specific package',
        )
        parser.add_argument(
            '--database',
            default='smiley.db',
            help='filename for the database (%(default)s)',
        )
        parser.add_argument(
            '--socket',
            default='tcp://127.0.0.1:5556',
            help='URL for the socket where the listener will be (%(default)s)',
        )
        parser.add_argument(
            'command',
            nargs='+',
            help='the command to spy on',
        )
        return parser

    def take_action(self, parsed_args):
        # Fix import path
        cwd = os.getcwd()
        if cwd not in sys.path and os.curdir not in sys.path:
            sys.path.insert(0, cwd)

        # Fix command line args
        sys.argv = parsed_args.command

        # Run the app
        if parsed_args.mode == 'remote':
            p = publisher.Publisher(parsed_args.socket)
        else:
            p = local.LocalPublisher(parsed_args.database)
        t = tracer.Tracer(
            p,
            include_stdlib=parsed_args.include_stdlib,
            include_site_packages=parsed_args.include_site_packages,
            include_packages=parsed_args.include_packages,
        )
        t.run(parsed_args.command)
        return

########NEW FILE########
__FILENAME__ = server
import logging
from wsgiref import simple_server

from cliff import command

from pecan import load_app

from smiley.web import config as web_config


class Server(command.Command):
    """Run the web server

    """

    log = logging.getLogger(__name__)

    _cwd = None

    def get_parser(self, prog_name):
        parser = super(Server, self).get_parser(prog_name)
        parser.add_argument(
            '--database',
            default='smiley.db',
            help='filename for the database (%(default)s)',
        )
        parser.add_argument(
            '--host',
            default='0.0.0.0',
            help='IP on which to listen (%(default)s)',
        )
        parser.add_argument(
            '--port',
            default=8080,
            type=int,
            help='port on which to listen (%(default)s)',
        )
        return parser

    def take_action(self, parsed_args):
        config_data = web_config.get_config_dict(
            database_name=parsed_args.database,
            host=parsed_args.host,
            port=parsed_args.port,
        )
        app = load_app(config_data)

        host = config_data['server']['host']
        port = int(config_data['server']['port'])
        srv = simple_server.make_server(host, port, app)
        if host == '0.0.0.0':
            self.log.info(
                'serving on 0.0.0.0:%s, view at http://127.0.0.1:%s',
                port, port,
            )
        else:
            self.log.info("serving on http://%s:%s", host, port)
        try:
            srv.serve_forever()
        except KeyboardInterrupt:
            # allow CTRL+C to shutdown
            pass

########NEW FILE########
__FILENAME__ = stats
import logging
import pstats

from cliff import command

from smiley import db


class StatsShow(command.Command):
    """Show the profile output for a run

    """

    log = logging.getLogger(__name__)

    def get_parser(self, prog_name):
        parser = super(StatsShow, self).get_parser(prog_name)
        parser.add_argument(
            '--database',
            default='smiley.db',
            help='filename for the database (%(default)s)',
        )
        parser.add_argument(
            '--sort-order',
            default='cumulative',
            choices=list(sorted(pstats.Stats.sort_arg_dict_default.keys())),
        )
        parser.add_argument(
            'run_id',
            help='identifier for the run',
        )
        return parser

    def take_action(self, parsed_args):
        self.db = db.DB(parsed_args.database)
        run_details = self.db.get_run(parsed_args.run_id)
        if not run_details.stats:
            print 'No profiling data was collected'
        else:
            run_details.stats.sort_stats(parsed_args.sort_order)
            run_details.stats.print_stats()


class StatsExport(command.Command):
    """Write the profile output for a run to a file

    """

    log = logging.getLogger(__name__)

    def get_parser(self, prog_name):
        parser = super(StatsExport, self).get_parser(prog_name)
        parser.add_argument(
            '--database',
            default='smiley.db',
            help='filename for the database (%(default)s)',
        )
        parser.add_argument(
            'run_id',
            help='identifier for the run',
        )
        parser.add_argument(
            'filename',
            help='the name of the file to use for the data',
        )
        return parser

    def take_action(self, parsed_args):
        self.db = db.DB(parsed_args.database)
        run_details = self.db.get_run(parsed_args.run_id)
        run_details.stats.dump_stats(parsed_args.filename)

########NEW FILE########
__FILENAME__ = db
import base64
import collections
import contextlib
import datetime
import hashlib
import json
import logging
import pkgutil
import pstats
import sqlite3
import tempfile

import six

from smiley import jsonutil
from smiley import processor

LOG = logging.getLogger(__name__)


Run = collections.namedtuple(
    'Run',
    'id cwd description start_time end_time error_message stats',
)


def _make_run(row):
    # HACK: It really is too bad that pstats can't load data from
    # a string.
    if row['stats']:
        with tempfile.NamedTemporaryFile(mode='w') as f:
            f.write(base64.b64decode(row['stats']))
            f.flush()
            stats = pstats.Stats(f.name)
    else:
        stats = None
    return Run(
        row['id'],
        row['cwd'],
        json.loads(row['description']),
        (datetime.datetime.fromtimestamp(row['start_time'])
         if row['start_time'] else None),
        (datetime.datetime.fromtimestamp(row['end_time'])
         if row['end_time'] else None),
        row['error_message'],
        stats,
    )


File = collections.namedtuple(
    'File',
    'name signature run_id',
)


def _make_file(row):
    return File(
        row['name'],
        row['signature'],
        row['run_id'],
    )


Trace = collections.namedtuple(
    'Trace',
    ' '.join(['id', 'run_id', 'call_id', 'event',
              'filename', 'line_no', 'func_name',
              'trace_arg', 'local_vars',
              'timestamp'])
)


def _make_trace(row):
    return Trace(
        id=row['id'],
        run_id=row['run_id'],
        call_id=row['call_id'],
        event=row['event'],
        filename=row['filename'],
        line_no=row['line_no'],
        func_name=row['func_name'],
        trace_arg=json.loads(row['trace_arg']),
        local_vars=json.loads(row['local_vars']),
        timestamp=datetime.datetime.fromtimestamp(row['timestamp']),
    )


@contextlib.contextmanager
def transaction(conn):
    c = conn.cursor()
    try:
        yield c
    except:
        conn.rollback()
        raise
    else:
        conn.commit()


class DB(processor.EventProcessor):
    """Database connection and API.
    """

    def __init__(self, name):
        self.conn = sqlite3.connect(name)
        # Use Row, instead of just lists/tuples
        self.conn.row_factory = sqlite3.Row
        # Try to select some data and create the schema if we can't.
        try:
            cursor = self.conn.cursor()
            cursor.execute(u'select * from run')
            LOG.debug('database already initialized')
        except sqlite3.OperationalError:
            LOG.debug('initializing database')
            schema = pkgutil.get_data('smiley', 'schema.sql').decode('utf-8')
            cursor.executescript(schema)
        return

    def start_run(self, run_id, cwd, description, start_time):
        "Record the beginning of a run."
        with transaction(self.conn) as c:
            c.execute(
                u"""
                INSERT INTO run (id, cwd, description, start_time)
                VALUES (:id, :cwd, :description, :start_time)
                """,
                {'id': run_id,
                 'cwd': cwd,
                 'description': jsonutil.dumps(description),
                 'start_time': start_time}
            )

    def end_run(self, run_id, end_time, message, traceback, stats):
        "Record the end of a run."
        with transaction(self.conn) as c:
            c.execute(
                u"""
                UPDATE run
                SET
                    end_time = :end_time,
                    error_message = :message,
                    traceback = :traceback,
                    stats = :stats
                WHERE id = :id
                """,
                {'id': run_id,
                 'end_time': end_time,
                 'message': message,
                 'traceback': jsonutil.dumps(traceback),
                 'stats': base64.b64encode(stats) if stats else None},
            )

    def get_runs(self, only_errors=False, sort_order='ASC'):
        "Return the run data."
        query = [u"SELECT * FROM run"]
        if only_errors:
            query.append(u"WHERE error_message is not null")
        query.append(u"ORDER BY start_time %s" % sort_order)
        with transaction(self.conn) as c:
            c.execute(u' '.join(query))
            return (_make_run(r) for r in c.fetchall())

    def get_run(self, run_id):
        "Return the run data."
        with transaction(self.conn) as c:
            c.execute(
                u"SELECT * FROM run WHERE id = :run_id",
                {'run_id': run_id},
            )
            return _make_run(c.fetchone())

    def trace(self, run_id, call_id, event,
              func_name, line_no, filename,
              trace_arg, local_vars,
              timestamp):
        "Record an event during a run."
        #LOG.debug('trace(filename=%s)', filename)
        with transaction(self.conn) as c:
            c.execute(
                u"""
                INSERT INTO trace
                (run_id, call_id, event,
                 func_name, line_no, filename,
                 trace_arg, local_vars,
                 timestamp)
                VALUES
                (:run_id, :call_id, :event,
                 :func_name, :line_no, :filename,
                 :trace_arg, :local_vars,
                 :timestamp)
                """,
                {'run_id': run_id,
                 'call_id': call_id,
                 'event': event,
                 'func_name': func_name,
                 'line_no': line_no,
                 'filename': filename,
                 'trace_arg': jsonutil.dumps(trace_arg),
                 'local_vars': jsonutil.dumps(local_vars),
                 'timestamp': timestamp,
                 }
            )

    def get_trace(self, run_id):
        "Return the run data."
        with transaction(self.conn) as c:
            c.execute(
                u"SELECT * FROM trace WHERE run_id = :run_id ORDER BY id",
                {'run_id': run_id},
            )
            return (_make_trace(t)
                    for t in c.fetchall())

    def cache_file_for_run(self, run_id, filename, body):
        signature_maker = hashlib.sha1()
        if isinstance(filename, six.text_type):
            signature_maker.update(filename.encode('utf-8'))
        else:
            signature_maker.update(filename)
        if isinstance(body, six.text_type):
            signature_maker.update(body.encode('utf-8'))
        else:
            signature_maker.update(body)
        signature = signature_maker.hexdigest()
        with transaction(self.conn) as c:
            try:
                c.execute(
                    u"""
                    INSERT INTO file (signature, name, body)
                    VALUES (:signature, :filename, :body)
                    """,
                    {'signature': signature,
                     'filename': filename,
                     'body': body,
                     },
                )
            except sqlite3.IntegrityError:
                pass
            try:
                c.execute(
                    u"""
                    INSERT INTO run_file
                    (run_id, signature)
                    VALUES (:run_id, :signature)
                    """,
                    {'run_id': run_id,
                     'signature': signature,
                     },
                )
            except sqlite3.IntegrityError:
                pass
        return signature

    def get_file_signature(self, run_id, filename):
        """Return the file signature for the named file within the run.
        """
        #LOG.debug('get_file_signature(%s)', filename)
        with transaction(self.conn) as c:
            c.execute(
                u"""
                SELECT signature
                FROM file JOIN run_file USING (signature)
                WHERE
                  name = :filename
                  AND
                  run_id = :run_id
                """,
                {'filename': filename,
                 'run_id': run_id,
                 },
            )
            row = c.fetchone()
            #LOG.debug(' -> %s', row)
            return row['signature'] if row else ''

    def get_files_for_run(self, run_id):
        with transaction(self.conn) as c:
            c.execute(
                u"""
                SELECT name, signature, run_id
                FROM file JOIN run_file USING (signature)
                WHERE
                  run_id = :run_id
                ORDER BY name ASC
                """,
                {'run_id': run_id,
                 },
            )
            return (_make_file(row) for row in c.fetchall())

    def get_cached_file(self, run_id, filename):
        with transaction(self.conn) as c:
            c.execute(
                u"""
                SELECT body
                FROM file JOIN run_file USING (signature)
                WHERE
                  name = :filename
                  AND
                  run_id = :run_id
                """,
                {'filename': filename,
                 'run_id': run_id,
                 },
            )
            row = c.fetchone()
            return row['body'] if row else ''

    def get_cached_file_by_id(self, run_id, file_id):
        with transaction(self.conn) as c:
            c.execute(
                u"""
                SELECT name, body
                FROM file JOIN run_file USING (signature)
                WHERE
                  signature = :signature
                  AND
                  run_id = :run_id
                """,
                {'signature': file_id,
                 'run_id': run_id,
                 },
            )
            row = c.fetchone()
            return (row['name'], row['body']) if row else ('', '')

########NEW FILE########
__FILENAME__ = db_linecache
"""Wrapper around the DB to present a linecache-like interface
for copies of files stored in the db.
"""


class DBLineCache(object):

    def __init__(self, db, run_id):
        self._db = db
        self._run_id = run_id
        self._files = {}

    def _init_file(self, filename):
        if filename not in self._files:
            body = self._db.get_cached_file(self._run_id, filename)
            self._files[filename] = body.splitlines()

    def getline(self, filename, line_no):
        self._init_file(filename)
        try:
            return self._files[filename][line_no-1]
        except IndexError:
            # Line number is out of range
            return ''

    def find_comment_block_start(self, filename, start):
        self._init_file(filename)
        start -= 1  # shift to zero-based index for cache contents
        found_blank = False
        found_comments = False
        search = start - 1
        while search >= 0:
            try:
                line = self._files[filename][search].lstrip()
            except IndexError:
                break
            if not line:
                if found_blank or found_comments:
                    # Stop searching if we find more than one
                    # blank line in a row, or we find a blank line
                    # after having found some comments
                    search += 1
                    break
                else:
                    found_blank = True
                    search -= 1
            elif line[0] == '#':
                found_comments = True
                search -= 1
            else:
                # We didn't find a comment or a blank on this line, so
                # stop looking and use the previously examined line.
                search += 1
                break
        # If we looped around while searching, we can take
        # everything from the start of the file but we don't want
        # a negative index
        if search < 0:
            search = 0
        if found_comments:
            start = search
        return start + 1  # caller is expecting 1-based index

    def getlines(self, filename, start, end, include_comments=False):
        """Return a block of consecutive lines, inclusive.
        """
        if start < 1:
            raise IndexError('start must be >= 1')
        self._init_file(filename)
        if include_comments:
            start = self.find_comment_block_start(filename, start)
        start -= 1  # shift to zero-based index for cache contents
        return '\n'.join(self._files[filename][start:end])

########NEW FILE########
__FILENAME__ = jsonutil
import json
import traceback
import types


def _json_special_types(obj):
    if isinstance(obj, types.TracebackType):
        return traceback.extract_tb(obj)
    if isinstance(obj, type):
        # We don't want to return classes
        return repr(obj)
    try:
        data = dict(vars(obj))
        data['__class__'] = obj.__class__.__name__
        data['__module__'] = obj.__class__.__module__
        if isinstance(obj, Exception) and 'args' not in data:
            try:
                data['args'] = obj.args
            except AttributeError:
                pass
    except Exception:
        data = repr(obj)
    return data


def dumps(data):
    return json.dumps(data, default=_json_special_types)

########NEW FILE########
__FILENAME__ = listener
import json
import logging

import zmq

LOG = logging.getLogger(__name__)


class Listener(object):

    def __init__(self, endpoint):
        self.context = zmq.Context()
        self.sub_socket = self.context.socket(zmq.PULL)
        self.sub_socket.connect(endpoint)
        self.sub_socket.identity = 'subscriber'
        self.poller = zmq.Poller()
        self.poller.register(self.sub_socket, zmq.POLLIN)

    def poll_once(self, timeout=1000):
        for sock, reason in self.poller.poll(timeout):
            if reason != zmq.POLLIN:
                return
            # Receiving data on the subscriber socket
            msg_type, msg_data = self.sub_socket.recv_multipart()
            yield [
                msg_type,
                json.loads(msg_data),
            ]

    def poll_forever(self, callback, timeout=1000):
        LOG.debug('Waiting for incoming data')
        while True:
            try:
                for m in self.poll_once(timeout):
                    callback(m)
            except KeyboardInterrupt:
                break

########NEW FILE########
__FILENAME__ = local
import logging
import os

from smiley import db
from smiley import processor

LOG = logging.getLogger(__name__)


class LocalPublisher(processor.EventProcessor):

    def __init__(self, database):
        self.db = db.DB(database)
        self._reset_cache()

    def _reset_cache(self):
        self._cached_files = set()

    def start_run(self, run_id, cwd, description, start_time):
        """Called when a 'start_run' event is seen.
        """
        self._reset_cache()
        self._cwd = cwd
        if self._cwd:
            self._cwd = self._cwd.rstrip(os.sep) + os.sep
        self.db.start_run(run_id, cwd, description, start_time)

    def end_run(self, run_id, end_time, message, traceback, stats):
        """Called when an 'end_run' event is seen.
        """
        self.db.end_run(run_id, end_time, message, traceback, stats)

    def trace(self, run_id, call_id, event,
              func_name, line_no, filename,
              trace_arg, local_vars,
              timestamp):
        """Called when any other event type is seen.
        """
        self.db.trace(run_id, call_id, event, func_name, line_no,
                      filename, trace_arg, local_vars, timestamp)
        if filename and filename not in self._cached_files:
            # Should we be decoding the text file here?
            with open(filename, 'rb') as f:
                body = f.read()
            self.db.cache_file_for_run(
                run_id,
                filename,
                body,
            )
            # Track the files we have cached so we do not need to
            # re-cache them for the same run.
            self._cached_files.add(filename)

########NEW FILE########
__FILENAME__ = output
import itertools
import logging
import os
import pprint

import prettytable

from smiley import processor


def format_dictionary(d):
    x = prettytable.PrettyTable(field_names=('Variable', 'Value'),
                                print_empty=False)
    x.padding_width = 1
    # Align all columns left because the values are
    # not all the same type.
    x.align['Variable'] = 'l'
    x.align['Value'] = 'l'
    for name, value in sorted(d.items()):
        formatted_value = pprint.pformat(value, width=60)
        pairs = itertools.izip(
            itertools.chain([name], itertools.repeat('')),
            formatted_value.splitlines())
        for name, value in pairs:
            x.add_row((name, value))
    return x.get_string(fields=('Variable', 'Value'))


def dump_table(formatted, write, indent=0):
    # Use the write function we're given, one line at a time.
    indent_spaces = ' ' * 4
    for line in formatted.splitlines():
        write(indent_spaces + line)
    return


def dump_dictionary(d, write, indent=4):
    dump_table(format_dictionary(d), write, indent)


class OutputFormatter(processor.EventProcessor):

    log = logging.getLogger(__name__)

    _cwd = None

    def __init__(self, line_source):
        self._line_source = line_source

    def _get_display_filename(self, filename):
        "Truncate the filename for display."
        if self._cwd and filename.startswith(self._cwd):
            return filename[len(self._cwd):]
        return filename

    def start_run(self, run_id, cwd, description, start_time):
        self.log.info(
            'Starting new run: %s',
            ' '.join(description)
        )
        self._cwd = cwd
        if self._cwd:
            self._cwd = self._cwd.rstrip(os.sep) + os.sep

    def end_run(self, run_id, end_time, message, traceback, stats):
        self.log.info('Finished run')
        if message:
            self.log.info('ERROR in app: %s', message)

    def trace(self, run_id, event,
              func_name, line_no, filename,
              trace_arg, local_vars,
              timestamp):
        line = self._line_source(
            filename,
            line_no,
        ).rstrip()
        display_filename = self._get_display_filename(filename)
        if event in ('line', 'call'):
            self.log.info(
                '%s:%4s: %s',
                display_filename,
                line_no,
                line,
            )
            if local_vars:
                dump_dictionary(local_vars, self.log.info)
        elif event == 'return':
            self.log.info(
                '%s:%4s: return>>> %s',
                display_filename,
                line_no,
                trace_arg,
            )
        elif event == 'exception':
            self.log.warn(
                '%s:%4s: Exception:',
                display_filename,
                line_no,
            )
            exc_type, exc_msg, exc_tb = trace_arg
            for exc_file, exc_line, exc_func, exc_text in exc_tb:
                self.log.info(
                    '    %s:%4s: %s',
                    self._get_display_filename(exc_file), exc_line, exc_text,
                )
        else:
            print 'UNHANDLED EVENT:', event

########NEW FILE########
__FILENAME__ = pagination
import math


def _bounded_int(val, default, low, high):
    try:
        val = int(val)
    except (TypeError, ValueError):
        val = default
    else:
        val = min(val, high)
        val = max(val, low)
    return val


def get_pagination_values(page, per_page, num_items):
    per_page = _bounded_int(per_page, 20, 5, 100)
    num_pages = int(math.ceil(num_items / (per_page * 1.0)))
    page = _bounded_int(page, 1, 1, num_pages)
    start = (page - 1) * per_page
    end = start + per_page

    # We don't want to show every page number, so figure out
    # the ranges we *do* want to show.
    page_ranges = []
    if num_pages <= 7:
        page_ranges.append((1, num_pages))
    elif page <= 5:
        page_ranges.append((1, 5))
        page_ranges.append((num_pages, num_pages))
    elif page >= num_pages - 5 + 1:
        page_ranges.append((1, 1))
        page_ranges.append((num_pages - 5 + 1, num_pages))
    else:
        page_ranges.append((1, 1))
        page_ranges.append((page - 2, page + 2))
        page_ranges.append((num_pages, num_pages))

    return {
        'page': page,
        'per_page': per_page,
        'num_pages': num_pages,
        'start': start,
        'end': end,
        'page_ranges': page_ranges,
    }

########NEW FILE########
__FILENAME__ = stats
import subprocess
import tempfile


def format_data(run_id, stats, db):
    # FIXME(dhellmann): Don't hard-code the sort order
    stats.sort_stats('cumtime')
    ignored, func_list = stats.get_print_list(())
    for func in func_list:
        cc, nc, tt, ct, callers = stats.stats[func]
        yield {
            'ncalls': '%s/%s' % (nc, cc) if nc != cc else str(nc),
            'tottime': tt,
            'percall_nc': (float(tt)/nc) if nc else '',
            'cumtime': ct,
            'percall_cc': (float(ct)/cc) if cc else '',
            'filename': func[0],
            'file_url': db.get_file_signature(run_id, func[0]),
            'lineno': func[1],
            'function': func[2],
        }


def generate_call_graph(stats):
    with tempfile.NamedTemporaryFile(mode='w') as f:
        stats.dump_stats(f.name)
        image_data = subprocess.check_output(
            'gprof2dot -f pstats %s | dot -Tpng' % f.name,
            shell=True,
        )
    return image_data

########NEW FILE########
__FILENAME__ = syntax
"""Wrapper around the DB to present a linecache-like interface
for copies of files stored in the db, with pygments styles applied.
"""
import logging

from pygments import highlight
from pygments.formatters import HtmlFormatter
from pygments.lexers import guess_lexer_for_filename

from smiley import db_linecache

LOG = logging.getLogger(__name__)


def apply_style(filename, body, linenos=True, theme='default'):
    """Apply the syntax highlighter to the given file.
    """
    lexer = guess_lexer_for_filename(filename, body)
    formatter = HtmlFormatter(linenos=linenos)
    return highlight(body, lexer, formatter)


def syntax(body):
    """Filter for applying syntax highlighting to blocks from templates."""
    return apply_style('unknown.py', body, linenos=False)


class StyledLineCache(object):

    def __init__(self, db, run_id):
        self._db = db
        self._run_id = run_id
        self._files = {}
        self._plain_line_cache = db_linecache.DBLineCache(db, run_id)

    EXPECTED_PREFIX = '<div class="highlight"><pre>'
    EXPECTED_SUFFIX = '</pre></div>'

    def _init_file(self, filename):
        if filename not in self._files:
            body = self._db.get_cached_file(self._run_id, filename)
            styled_body = apply_style(filename, body, linenos=False)
            start = len(self.EXPECTED_PREFIX)
            end = -1 * (len(self.EXPECTED_SUFFIX) + 1)
            middle_body = styled_body[start:end].rstrip('\n')
            self._files[filename] = middle_body.splitlines()

    def getline(self, filename, line_no):
        #LOG.debug('getline(%s, %s)', filename, line_no)
        self._init_file(filename)
        try:
            return self._files[filename][line_no-1]
        except IndexError:
            # Line number is out of range
            return ''

    def getlines(self, filename, start, end, include_comments=False):
        """Return a block of consecutive lines.
        """
        if start < 1:
            raise IndexError('start must be >= 1')
        self._init_file(filename)
        if include_comments:
            start = self._plain_line_cache.find_comment_block_start(
                filename,
                start,
            )
        return '\n'.join(self._files[filename][start-1:end])

########NEW FILE########
__FILENAME__ = trace
import logging

from smiley import db
from smiley import util

LOG = logging.getLogger(__name__)


def collapse_trace(trace_iter):
    """Combine closely related trace items.
    """
    accumulate = None
    for t in trace_iter:
        vars_have_changed = False
        if accumulate:
            vars_that_changed = util.get_variable_changes(
                accumulate.local_vars,
                t.local_vars,
            )
            for var, val in vars_that_changed:
                if var in accumulate.local_vars:
                    # The value of an existing variable changed between events
                    vars_have_changed = True
                    break
        do_yield = (
            accumulate  # we have something to yield
            and
            (vars_have_changed
             or
             accumulate.event != 'line'  # that something can't be collapsed
             or
             t.event != 'line'  # the next event can't be combined with it
             or
             t.event != accumulate.event)
        )
        if do_yield:
            # The events do not match or can't be combined
            yield accumulate
            accumulate = None

        if not accumulate:
            accumulate = db.Trace(
                id=t.id,
                run_id=t.run_id,
                call_id=t.call_id,
                event=t.event,
                filename=t.filename,
                line_no=(t.line_no, t.line_no),
                func_name=t.func_name,
                trace_arg=t.trace_arg,
                local_vars=t.local_vars,
                timestamp=t.timestamp,
            )

        else:
            # Combine consecutive line events by updating the line_no
            # range
            accumulate = db.Trace(
                id=accumulate.id,
                run_id=accumulate.run_id,
                call_id=accumulate.call_id,
                event=accumulate.event,
                filename=accumulate.filename,
                line_no=(accumulate.line_no[0], t.line_no),
                func_name=accumulate.func_name,
                trace_arg=accumulate.trace_arg,
                # replace in case variables were added
                local_vars=t.local_vars,
                timestamp=accumulate.timestamp,
            )

    if accumulate:
        yield accumulate

########NEW FILE########
__FILENAME__ = processor
"""Base class for event processors so the APIs are consistent.
"""
import abc


class EventProcessor(object):
    """Base class for things that work with the events from the tracer.
    """

    __metaclass__ = abc.ABCMeta

    @abc.abstractmethod
    def start_run(self, run_id, cwd, description, start_time):
        """Called when a 'start_run' event is seen.
        """

    @abc.abstractmethod
    def end_run(self, run_id, end_time, message, traceback, stats):
        """Called when an 'end_run' event is seen.
        """

    @abc.abstractmethod
    def trace(self, run_id, event,
              func_name, line_no, filename,
              trace_arg, local_vars,
              timestamp):
        """Called when any other event type is seen.
        """

########NEW FILE########
__FILENAME__ = publisher
import logging

import zmq
import sys

from smiley import jsonutil
from smiley import processor

LOG = logging.getLogger(__name__)


class Publisher(processor.EventProcessor):

    def __init__(self, endpoint, high_water_mark=10000):
        self.context = zmq.Context()
        self.pub_socket = self.context.socket(zmq.PUSH)
        self.pub_socket.bind(endpoint)
        self.pub_socket.identity = 'publisher'
        self.pub_socket.hwm = high_water_mark

    def _send(self, msg_type, data):
        old_trace = None
        try:
            old_trace = sys.gettrace()
            sys.settrace(None)
            msg = [
                msg_type,
                jsonutil.dumps(data),
            ]
            LOG.debug('SENDING: %r', msg)
            self.pub_socket.send_multipart(msg)
        finally:
            if old_trace is not None:
                sys.settrace(old_trace)

    def start_run(self, run_id, cwd, description, start_time):
        """Called when a 'start_run' event is seen.
        """
        self._send(
            'start_run',
            {'run_id': run_id,
             'cwd': cwd,
             'command_line': description,
             'timestamp': start_time,
             },
        )

    def end_run(self, run_id, end_time, message, traceback, stats):
        """Called when an 'end_run' event is seen.
        """
        self._send(
            'end_run',
            {'run_id': run_id,
             'timestamp': end_time,
             'message': message,
             'traceback': traceback,
             'stats': stats,
             },
        )

    def trace(self, run_id, call_id, event,
              func_name, line_no, filename,
              trace_arg, local_vars,
              timestamp):
        """Called when any other event type is seen.
        """
        self._send(
            event,
            {'func_name': func_name,
             'line_no': line_no,
             'filename': filename,
             'arg': trace_arg,
             'local_vars': local_vars,
             'timestamp': timestamp,
             'run_id': run_id,
             'call_id': call_id,
             })

########NEW FILE########
__FILENAME__ = html
import functools
import logging
import os
import shutil

from mako.lookup import TemplateLookup

from smiley import db_linecache
from smiley.presentation import pagination
from smiley.presentation import stats
from smiley.presentation import trace
from smiley.presentation import syntax


LOG = logging.getLogger(__name__)


class Page(object):
    TEMPLATE = None

    def __init__(self, report):
        self.context = {
            'subtitle': report.title,
            'run_id': report.run_id,
            'run': report.run_details,
            'getfileid': functools.partial(
                report.db.get_file_signature,
                run_id=report.run_id,
            ),
        }
        if self.TEMPLATE:
            self.template = report.template_lookup.get_template(self.TEMPLATE)
            self.context['active_section'] = self.TEMPLATE.partition('.')[0]
        else:
            self.template = None
            self.context['active_section'] = None

    def render(self):
        return self.template.render_unicode(**self.context)


class IndexPage(Page):
    TEMPLATE = 'index.html'

    def __init__(self, report):
        super(IndexPage, self).__init__(report)


class TracePage(Page):
    TEMPLATE = 'trace.html'

    def __init__(self, report, trace, pagination, getlines):
        super(TracePage, self).__init__(report)
        self.context['trace'] = trace
        self.context.update(pagination)
        self.context['getlines'] = getlines


class FilesPage(Page):
    TEMPLATE = 'files.html'

    def __init__(self, report, files):
        super(FilesPage, self).__init__(report)
        self.context['files'] = files


class FilePage(Page):
    TEMPLATE = 'file.html'

    def __init__(self, report, file_info):
        super(FilePage, self).__init__(report)
        self.context['active_section'] = 'files'
        filename, body = report.db.get_cached_file_by_id(
            report.run_id,
            file_info.signature,
        )
        self.context['styled_body'] = syntax.apply_style(filename, body)


class StatsPage(Page):
    TEMPLATE = 'stats.html'

    def __init__(self, report):
        super(StatsPage, self).__init__(report)
        self.context['stats_data'] = stats.format_data(
            report.run_id,
            report.run_details.stats,
            report.db,
        )


class CallGraphPage(Page):
    TEMPLATE = 'call_graph.html'

    def __init__(self, report):
        super(CallGraphPage, self).__init__(report)
        self.stats_data = report.run_details.stats
        self.image_filename = os.path.join(report.output_dir, 'call_graph.png')

    def render(self):
        image_data = stats.generate_call_graph(self.stats_data)
        with open(self.image_filename, 'w') as f:
            f.write(image_data)
        return super(CallGraphPage, self).render()


class HTMLReport(object):

    def __init__(self, run_id, output_dir, database, title, per_page):
        self.run_id = run_id
        self.output_dir = output_dir
        self.db = database
        self.title = title
        self.per_page = per_page

        self.run_details = self.db.get_run(self.run_id)
        self.line_cache = db_linecache.DBLineCache(self.db, self.run_id)
        self.report_dir = os.path.dirname(__file__)
        self.template_dir = os.path.join(self.report_dir, 'templates')
        self.template_lookup = TemplateLookup(directories=[self.template_dir])
        self.syntax_line_cache = syntax.StyledLineCache(self.db, self.run_id)

    def _render_page(self, page, output_name):
        fullname = os.path.join(self.output_dir, output_name)
        outdir = os.path.dirname(fullname)
        if not os.path.exists(outdir):
            os.makedirs(outdir)
        with open(fullname, 'w') as f:
            LOG.info('writing %s', output_name)
            f.write(page.render().encode('utf-8', 'replace'))

    def _get_file_lines(self, filename, nums):
        start, end = nums
        return self.syntax_line_cache.getlines(
            filename, start, end,
            include_comments=True,
        )

    def _copy_static_files(self):
        static_dir = os.path.join(self.report_dir, 'static')
        for in_dir in os.listdir(static_dir):
            src = os.path.join(static_dir, in_dir)
            dst = os.path.join(self.output_dir, in_dir)
            if os.path.exists(dst):
                LOG.debug('cleaning up %s', dst)
                shutil.rmtree(dst)
            LOG.info('copying static files: %s', in_dir)
            shutil.copytree(src, dst)

    def run(self):
        LOG.info('writing output to %s', self.output_dir)

        # Do some initial calculations to figure out how many pages we
        # have.
        trace_data = list(
            trace.collapse_trace(self.db.get_trace(self.run_id))
        )
        page_vals = pagination.get_pagination_values(
            1, self.per_page, len(trace_data),
        )
        last_page = page_vals['num_pages'] + 1

        # Start producing output pages
        self._render_page(
            IndexPage(
                report=self,
            ),
            'index.html',
        )

        # The trace output is paginated, so we have multiple pages to
        # produce.
        for i in xrange(1, last_page):
            page_vals = pagination.get_pagination_values(
                i, self.per_page, len(trace_data),
            )
            page_name = 'trace-%d.html' % i
            start = page_vals['start']
            end = page_vals['end']
            self._render_page(
                TracePage(
                    report=self,
                    trace=trace_data[start:end],
                    pagination=page_vals,
                    getlines=self._get_file_lines,
                ),
                page_name,
            )

        # The source code from the run
        run_files = list(self.db.get_files_for_run(self.run_id))
        self._render_page(
            FilesPage(self, run_files),
            'files.html',
        )
        for run_file in run_files:
            self._render_page(
                FilePage(self, run_file),
                'file-%s.html' % run_file.signature,
            )

        self._render_page(
            StatsPage(self),
            'stats.html',
        )
        self._render_page(
            CallGraphPage(self),
            'call_graph.html',
        )

        # Make sure we have all of the CSS and JavaScript files needed
        # by the templates.
        self._copy_static_files()

########NEW FILE########
__FILENAME__ = test_pagination
import testscenarios

from smiley.presentation import pagination


class PaginationTest(testscenarios.TestWithScenarios):

    scenarios = [

        ('1 of 20', {'page': 1,
                     'per_page': 5,
                     'num_items': 5 * 20,
                     'expected': [(1, 5), (20, 20)]}),
        ('2 of 20', {'page': 2,
                     'per_page': 5,
                     'num_items': 5 * 20,
                     'expected': [(1, 5), (20, 20)]}),
        ('10 of 20', {'page': 10,
                      'per_page': 5,
                      'num_items': 5 * 20,
                      'expected': [(1, 1), (8, 12), (20, 20)]}),
        ('19 of 20', {'page': 19,
                      'per_page': 5,
                      'num_items': 5 * 20,
                      'expected': [(1, 1), (16, 20)]}),
        ('20 of 20', {'page': 20,
                      'per_page': 5,
                      'num_items': 5 * 20,
                      'expected': [(1, 1), (16, 20)]}),

        ('1 of 5', {'page': 1,
                    'per_page': 5,
                    'num_items': 5 * 5,
                    'expected': [(1, 5)]}),
        ('2 of 5', {'page': 2,
                    'per_page': 5,
                    'num_items': 5 * 5,
                    'expected': [(1, 5)]}),

        ('1 of 7', {'page': 1,
                    'per_page': 5,
                    'num_items': 5 * 7,
                    'expected': [(1, 7)]}),

    ]

    def test(self):
        actual = pagination.get_pagination_values(self.page,
                                                  self.per_page,
                                                  self.num_items)
        self.assertEqual(self.expected, actual['page_ranges'])

########NEW FILE########
__FILENAME__ = test_trace
import testtools

from smiley import db
from smiley.presentation import trace


class CollapseTraceTest(testtools.TestCase):

    def test_consecutive_lines(self):
        trace_data = [
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=1,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=2,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=3,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
        ]
        collapsed = list(trace.collapse_trace(trace_data))
        self.assertEqual(len(collapsed), 1)
        line_nos = [r.line_no for r in collapsed]
        self.assertEqual(line_nos, [(1, 3)])

    def test_non_consecutive_lines(self):
        trace_data = [
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=1,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=20,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=40,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
        ]
        collapsed = list(trace.collapse_trace(trace_data))
        self.assertEqual(len(collapsed), 1)
        line_nos = [r.line_no for r in collapsed]
        self.assertEqual(line_nos, [(1, 40)])

    def test_call_lines_return(self):
        trace_data = [
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='call',
                filename='filename.py',
                line_no=1,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=1,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=2,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='return',
                filename='filename.py',
                line_no=2,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
        ]
        collapsed = list(trace.collapse_trace(trace_data))
        self.assertEqual(len(collapsed), 3)
        line_nos = [r.line_no for r in collapsed]
        self.assertEqual(line_nos, [(1, 1),
                                    (1, 2),
                                    (2, 2)])

    def test_new_var(self):
        trace_data = [
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=1,
                func_name='func',
                trace_arg={},
                local_vars={
                    'v1': 1,
                },
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=2,
                func_name='func',
                trace_arg={},
                local_vars={
                    'v1': 1,
                    'v2': 2,
                },
                timestamp=1,
            ),
        ]
        collapsed = list(trace.collapse_trace(trace_data))
        self.assertEqual(len(collapsed), 1)
        self.assertEqual(collapsed[0].local_vars,
                         {'v1': 1, 'v2': 2})

    def test_changed_var(self):
        trace_data = [
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=1,
                func_name='func',
                trace_arg={},
                local_vars={
                    'v1': 1,
                    'v3': 3,
                },
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=2,
                func_name='func',
                trace_arg={},
                local_vars={
                    'v1': 1,
                    'v2': 2,
                    'v3': 4,
                },
                timestamp=1,
            ),
        ]
        collapsed = list(trace.collapse_trace(trace_data))
        self.assertEqual(len(collapsed), 2)
        self.assertEqual(collapsed[0].local_vars,
                         {'v1': 1, 'v3': 3})
        self.assertEqual(collapsed[1].local_vars,
                         {'v1': 1, 'v2': 2, 'v3': 4})

    def test_changed_var2(self):
        trace_data = [
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=1,
                func_name='func',
                trace_arg={},
                local_vars={
                    'v1': 1,
                    'v3': 3,
                },
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=2,
                func_name='func',
                trace_arg={},
                local_vars={
                    'v1': 1,
                    'v2': 2,
                    'v3': 4,
                },
                timestamp=1,
            ),
            # Force the previous data to be emitted, with the next set
            # of local variables being completely different to verify
            # that the variable change detection resets
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='call',
                filename='filename.py',
                line_no=3,
                func_name='func',
                trace_arg={},
                local_vars={},
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=4,
                func_name='func',
                trace_arg={},
                local_vars={
                    'V1': 1,
                },
                timestamp=1,
            ),
            db.Trace(
                id='1',
                run_id='1',
                call_id='1',
                event='line',
                filename='filename.py',
                line_no=5,
                func_name='func',
                trace_arg={},
                local_vars={
                    'V1': 1,
                    'V2': 2,
                },
                timestamp=1,
            ),
        ]
        collapsed = list(trace.collapse_trace(trace_data))
        self.assertEqual(len(collapsed), 4)
        self.assertEqual(collapsed[0].local_vars,
                         {'v1': 1, 'v3': 3})
        self.assertEqual(collapsed[1].local_vars,
                         {'v1': 1, 'v2': 2, 'v3': 4})
        self.assertEqual(collapsed[3].local_vars,
                         {'V1': 1, 'V2': 2})

########NEW FILE########
__FILENAME__ = test_db
import fixtures
import json
import testtools

import six

from smiley import db


class TransactionTest(testtools.TestCase):

    def setUp(self):
        super(TransactionTest, self).setUp()
        self.useFixture(fixtures.FakeLogger())
        self.db = db.DB(':memory:')

    def test_commit(self):
        with db.transaction(self.db.conn) as c:
            c.execute(
                """
                INSERT INTO run (id, cwd, description, start_time)
                VALUES ('12345', 'cwd-here', 'useful description',
                        1370436103.65)
                """)

            db2 = db.DB(':memory:')
            c2 = db2.conn.cursor()
            c2.execute('select * from run')
            d = c2.fetchall()
            self.assertEqual(d, [])

        c3 = self.db.conn.cursor()
        c3.execute('select * from run')
        d = c3.fetchall()
        self.assertEqual(len(d), 1)

    def test_rollback(self):
        try:
            with db.transaction(self.db.conn) as c:
                c.execute(
                    """
                    INSERT INTO run (id, cwd, description, start_time)
                    VALUES ('12345', 'cwd-here', 'useful description',
                            1370436103.65)
                    """)

                db2 = db.DB(':memory:')
                c2 = db2.conn.cursor()
                c2.execute('select * from run')
                d = c2.fetchall()
                self.assertEqual(d, [])
                raise RuntimeError('testing')
        except RuntimeError as err:
            self.assertEqual(str(err), 'testing')

        c3 = self.db.conn.cursor()
        c3.execute('select * from run')
        d = c3.fetchall()
        self.assertEqual(len(d), 0)


class DBTest(testtools.TestCase):

    def setUp(self):
        super(DBTest, self).setUp()
        self.useFixture(fixtures.FakeLogger())
        self.db = db.DB(':memory:')

    def test_start_run(self):
        self.db.start_run(
            '12345',
            '/no/such/dir',
            'command line would go here',
            1370436103.65,
        )
        c = self.db.conn.cursor()
        c.execute('select * from run')
        data = c.fetchall()
        self.assertEqual(len(data), 1)
        row = data[0]
        self.assertEqual(row['id'], '12345')
        self.assertEqual(row['cwd'], '/no/such/dir')
        self.assertEqual(row['description'], '"command line would go here"')
        self.assertEqual(row['start_time'], 1370436103.65)
        self.assertEqual(row['end_time'], None)
        self.assertEqual(row['error_message'], None)
        self.assertEqual(row['traceback'], None)

    def test_end_run_clean(self):
        self.db.start_run(
            '12345',
            '/no/such/dir',
            'command line would go here',
            1370436103.65,
        )
        self.db.end_run(
            '12345',
            1370436104.65,
            message=None,
            traceback=None,
            stats=None,
        )
        c = self.db.conn.cursor()
        c.execute('select * from run')
        data = c.fetchall()
        self.assertEqual(len(data), 1)
        row = data[0]
        self.assertEqual(row['id'], '12345')
        self.assertEqual(row['start_time'], 1370436103.65)
        self.assertEqual(row['end_time'], 1370436104.65)

    def test_end_run_traceback(self):
        self.db.start_run(
            '12345',
            '/no/such/dir',
            'command line would go here',
            1370436103.65,
        )
        try:
            raise RuntimeError('test exception')
        except RuntimeError as err:
            import sys
            self.db.end_run(
                '12345',
                1370436104.65,
                message=six.text_type(err),
                traceback=sys.exc_info()[-1],
                stats=None,
            )
        c = self.db.conn.cursor()
        c.execute('select * from run')
        data = c.fetchall()
        self.assertEqual(len(data), 1)
        row = data[0]
        self.assertEqual(row['id'], '12345')
        self.assertEqual(row['error_message'], 'test exception')
        # FIXME: Need to serialize the traceback better
        assert 'traceback' in row['traceback']


class TraceTest(testtools.TestCase):

    def setUp(self):
        super(TraceTest, self).setUp()
        self.useFixture(fixtures.FakeLogger())
        self.db = db.DB(':memory:')
        self.db.start_run(
            '12345',
            '/no/such/dir',
            'command line would go here',
            1370436103.65,
        )
        self.local_values = {'name': ['value', 'pairs']}
        self.trace_arg = [{'complex': 'value'}]
        self.db.trace(
            run_id='12345',
            call_id='abcd',
            event='test',
            func_name='test_trace',
            line_no=99,
            filename='test_db.py',
            trace_arg=self.trace_arg,
            local_vars=self.local_values,
            timestamp=1370436104.65,
        )
        self.db.trace(
            run_id='12345',
            call_id='abcd',
            event='test',
            func_name='test_trace',
            line_no=100,
            filename='test_db.py',
            trace_arg=self.trace_arg,
            local_vars=self.local_values,
            timestamp=1370436104.65,
        )

    def test_insertion_order(self):
        c = self.db.conn.cursor()
        c.execute('select * from trace order by id')
        data = c.fetchall()
        line_nos = [r['line_no'] for r in data]
        self.assertEqual(line_nos, [99, 100])

    def test_local_vars(self):
        c = self.db.conn.cursor()
        c.execute('select * from trace order by id')
        row = c.fetchone()
        self.assertEqual(json.loads(row['local_vars']),
                         self.local_values)

    def test_trace_arg(self):
        c = self.db.conn.cursor()
        c.execute('select * from trace order by id')
        row = c.fetchone()
        self.assertEqual(json.loads(row['trace_arg']),
                         self.trace_arg)


class QueryTest(testtools.TestCase):

    def setUp(self):
        super(QueryTest, self).setUp()
        self.useFixture(fixtures.FakeLogger())
        self.db = db.DB(':memory:')
        self.db.start_run(
            '12345',
            '/no/such/dir',
            ['command', 'line', 'would', 'go', 'here'],
            1370436103.65,
        )
        self.local_values = {'name': ['value', 'pairs']}
        self.trace_arg = [{'complex': 'value'}]
        self.db.trace(
            run_id='12345',
            call_id='abcd',
            event='test',
            func_name='test_trace',
            line_no=99,
            filename='test_db.py',
            trace_arg=self.trace_arg,
            local_vars=self.local_values,
            timestamp=1370436104.65,
        )
        self.db.trace(
            run_id='12345',
            call_id='abcd',
            event='test',
            func_name='test_trace',
            line_no=100,
            filename='test_db.py',
            trace_arg=self.trace_arg,
            local_vars=self.local_values,
            timestamp=1370436104.65,
        )
        self.db.start_run(
            '6789',
            '/no/such/dir',
            ['command', 'line', 'would', 'go', 'here'],
            1370436104.65,
        )
        self.db.end_run(
            '6789',
            1370436105.65,
            'error message',
            None,
            stats=None,
        )

    def test_get_runs(self):
        runs = list(self.db.get_runs())
        self.assertEqual(len(runs), 2)
        self.assertEqual(runs[0].id, '12345')
        self.assertEqual(runs[1].id, '6789')

    def test_get_runs_desc(self):
        runs = list(self.db.get_runs(sort_order='DESC'))
        self.assertEqual(len(runs), 2)
        self.assertEqual(runs[0].id, '6789')
        self.assertEqual(runs[1].id, '12345')

    def test_get_runs_errors(self):
        runs = list(self.db.get_runs(True))
        self.assertEqual(len(runs), 1)
        self.assertEqual(runs[0].id, '6789')

    def test_get_run(self):
        run = self.db.get_run('12345')
        self.assertEqual(run.id, '12345')
        self.assertEqual(
            run.description,
            ['command', 'line', 'would', 'go', 'here']
        )

    def test_get_trace(self):
        trace = list(self.db.get_trace('12345'))
        self.assertEqual(len(trace), 2)
        line_nos = [r.line_no for r in trace]
        self.assertEqual(line_nos, [99, 100])


class FileCacheTest(testtools.TestCase):

    def setUp(self):
        super(FileCacheTest, self).setUp()
        self.useFixture(fixtures.FakeLogger())
        self.db = db.DB(':memory:')
        self.db.start_run(
            '12345',
            '/no/such/dir',
            ['command', 'line', 'would', 'go', 'here'],
            1370436103.65,
        )
        self.db.start_run(
            '6789',
            '/no/such/dir',
            ['command', 'line', 'would', 'go', 'here'],
            1370436103.65,
        )

    def test_add_file(self):
        self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body',
        )
        c = self.db.conn.cursor()
        c.execute('select * from file')
        rows = list(c.fetchall())
        self.assertEqual(len(rows), 1)
        row = rows[0]
        self.assertEqual(row['body'], 'this would be the body')
        self.assertEqual(row['name'], 'test-file.txt')

    def test_add_file_twice_same(self):
        self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body',
        )
        self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body',
        )
        c = self.db.conn.cursor()
        c.execute('select * from file')
        rows = list(c.fetchall())
        self.assertEqual(len(rows), 1)
        row = rows[0]
        self.assertEqual(row['body'], 'this would be the body')
        self.assertEqual(row['name'], 'test-file.txt')

    def test_add_file_twice_different(self):
        self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body',
        )
        self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this body has changed',
        )
        c = self.db.conn.cursor()
        c.execute('select * from file')
        rows = list(c.fetchall())
        self.assertEqual(len(rows), 2)

    def test_retrieve_via_name(self):
        self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body',
        )
        body = self.db.get_cached_file(
            '12345',
            'test-file.txt',
        )
        self.assertEqual(body, 'this would be the body')

    def test_retrieve_via_signature(self):
        signature = self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body',
        )
        name, body = self.db.get_cached_file_by_id(
            '12345',
            signature,
        )
        self.assertEqual(name, 'test-file.txt')
        self.assertEqual(body, 'this would be the body')

    def test_retrieve_signature(self):
        signature = self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body',
        )
        actual = self.db.get_file_signature(
            '12345',
            'test-file.txt',
        )
        self.assertEqual(signature, actual)

    def test_retrieve_from_run_bad_id(self):
        self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body',
        )
        body = self.db.get_cached_file(
            '6789',  # wrong run id
            'test-file.txt',
        )
        self.assertEqual(body, '')

    def test_retrieve_from_run_bad_name(self):
        self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body',
        )
        body = self.db.get_cached_file(
            '12345',
            'no-such-file.txt',
        )
        self.assertEqual(body, '')

    def test_list_files(self):
        self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body',
        )
        self.db.cache_file_for_run(
            '12345',
            'test-file2.txt',
            'this would be the body',
        )
        files = list(self.db.get_files_for_run('12345'))
        self.assertEqual(2, len(files))
        names = [f.name for f in files]
        self.assertEqual(['test-file.txt', 'test-file2.txt'], names)

########NEW FILE########
__FILENAME__ = test_db_linecache
import fixtures
import testtools

from smiley import db
from smiley import db_linecache


class DBFileCacheTest(testtools.TestCase):

    def setUp(self):
        super(DBFileCacheTest, self).setUp()
        self.useFixture(fixtures.FakeLogger())
        self.db = db.DB(':memory:')
        self.db.start_run(
            '12345',
            '/no/such/dir',
            ['command', 'line', 'would', 'go', 'here'],
            1370436103.65,
        )
        self.db.cache_file_for_run(
            '12345',
            'test-file.txt',
            'this would be the body\nline two\nline three',
        )
        self.db.cache_file_for_run(
            '12345',
            'with-comments.txt',
            '\n'.join([
                '# start comment',
                'line two',
                '',
                '  # middle comment',
                '',
                'end line',
                '# comment',
                'last line',
            ]),
        )
        self.db.cache_file_for_run(
            '12345',
            'multi-line-comments.txt',
            '\n'.join([
                '# start comment',
                '# comment line 2',
                'non-comment 1',
                '',
                '  # middle comment',
                '  # middle comment line 2',
                '',
                'middle line',
                '# last comment',
                '# last comment line 2',
                'last line',
            ]),
        )
        self.cache = db_linecache.DBLineCache(self.db, '12345')

    def test_file_and_line_exist(self):
        line = self.cache.getline('test-file.txt', 2)
        self.assertEqual(line, 'line two')

    def test_file_does_not_exist(self):
        line = self.cache.getline('no-such-test-file.txt', 2)
        self.assertEqual(line, '')

    def test_line_does_not_exist(self):
        line = self.cache.getline('test-file.txt', 99)
        self.assertEqual(line, '')

    def test_range_exists(self):
        lines = self.cache.getlines('test-file.txt', 2, 3)
        self.assertEqual(lines, 'line two\nline three')

    def test_range_underflow(self):
        self.assertRaises(IndexError,
                          self.cache.getlines,
                          'test-file.txt', 0, 2,
                          )

    def test_range_overflow(self):
        lines = self.cache.getlines('test-file.txt', 2, 4)
        self.assertEqual(lines, 'line two\nline three')

    def test_find_comments_adjascent(self):
        start = self.cache.find_comment_block_start('with-comments.txt', 2)
        self.assertEqual(start, 1)

    def test_comments_adjascent(self):
        lines = self.cache.getlines('with-comments.txt', 2, 2,
                                    include_comments=True)
        self.assertEqual(lines, '# start comment\nline two')

    def test_multi_line_comments_adjascent(self):
        lines = self.cache.getlines('multi-line-comments.txt', 3, 3,
                                    include_comments=True)
        self.assertEqual(
            lines,
            '# start comment\n# comment line 2\nnon-comment 1',
        )

    def test_find_comments_none(self):
        start = self.cache.find_comment_block_start('test-file.txt', 2)
        self.assertEqual(start, 2)

    def test_comments_none(self):
        lines = self.cache.getlines('test-file.txt', 2, 3,
                                    include_comments=True)
        self.assertEqual(lines, 'line two\nline three')

    def test_find_comments_and_blank_line(self):
        start = self.cache.find_comment_block_start('with-comments.txt', 6)
        self.assertEqual(start, 4)

    def test_comments_and_blank_line(self):
        lines = self.cache.getlines('with-comments.txt', 6, 6,
                                    include_comments=True)
        self.assertEqual(lines, '  # middle comment\n\nend line')

    def test_multi_line_comments_and_blank_line(self):
        lines = self.cache.getlines('multi-line-comments.txt', 8, 8,
                                    include_comments=True)
        self.assertEqual(
            lines,
            '  # middle comment\n  # middle comment line 2\n\nmiddle line',
        )

    def test_find_comments_without_blank_line(self):
        start = self.cache.find_comment_block_start('with-comments.txt', 8)
        self.assertEqual(start, 7)

    def test_comments_without_blank_line(self):
        lines = self.cache.getlines('with-comments.txt', 8, 8,
                                    include_comments=True)
        self.assertEqual(lines, '# comment\nlast line')

    def test_multi_line_comments_without_blank_line(self):
        lines = self.cache.getlines('multi-line-comments.txt', 11, 11,
                                    include_comments=True)
        self.assertEqual(
            lines,
            '# last comment\n# last comment line 2\nlast line',
        )

########NEW FILE########
__FILENAME__ = test_jsonutil
import traceback

import fixtures
import testtools

import six

from smiley import jsonutil


class JSONTest(testtools.TestCase):

    def setUp(self):
        super(JSONTest, self).setUp()
        self.useFixture(fixtures.FakeLogger())

    def test_traceback(self):
        try:
            raise RuntimeError('here')
        except RuntimeError:
            import sys
            expected = traceback.extract_tb(sys.exc_info()[-1])
            actual = jsonutil._json_special_types(sys.exc_info()[-1])
        self.assertEqual(actual, expected)

    def test_exception(self):
        try:
            raise RuntimeError('here')
        except RuntimeError as err:
            actual = jsonutil._json_special_types(err)
        if six.PY3:
            expected = {
                '__class__': 'RuntimeError',
                '__module__': 'builtins',
                'args': ('here',),
            }
        else:
            expected = {
                '__class__': 'RuntimeError',
                '__module__': 'exceptions',
                'args': ('here',),
            }
        self.assertEqual(actual, expected)

    def test_arbitrary_object(self):
        class Foo(object):
            def __init__(self):
                self.a = 'A'
                self.b = 'B'
        expected = {
            '__class__': 'Foo',
            '__module__': 'smiley.tests.test_jsonutil',
            'a': 'A',
            'b': 'B',
        }
        actual = jsonutil._json_special_types(Foo())
        self.assertEqual(actual, expected)

    def test_arbitrary_object_old_style(self):
        class Foo:
            def __init__(self):
                self.a = 'A'
                self.b = 'B'
        expected = {
            '__class__': 'Foo',
            '__module__': 'smiley.tests.test_jsonutil',
            'a': 'A',
            'b': 'B',
        }
        actual = jsonutil._json_special_types(Foo())
        self.assertEqual(actual, expected)

########NEW FILE########
__FILENAME__ = test_listener
import json

import fixtures
import mock
import testtools
import zmq

from smiley import listener


class ListenerTest(testtools.TestCase):

    def setUp(self):
        super(ListenerTest, self).setUp()
        self.useFixture(fixtures.FakeLogger())

    @mock.patch('zmq.Context')
    def test_socket_setup(self, context_factory):
        listener.Listener('endpoint')
        context = context_factory.return_value
        context.socket.assert_called_with(zmq.PULL)
        s = context.socket.return_value
        s.connect.assert_called_with('endpoint')

    @mock.patch('zmq.Context')
    @mock.patch('smiley.listener.Listener.poll_once')
    def test_poll_breaks(self, meth, context):
        meth.side_effect = KeyboardInterrupt
        cb = mock.MagicMock()
        cb.side_effect = AssertionError('should not be called')
        l = listener.Listener('endpoint')
        l.poll_forever(cb)

    @mock.patch('zmq.Context.socket')
    @mock.patch('zmq.Poller.poll')
    def test_unpack_message(self, poll, socket):
        poll.return_value = [(socket, zmq.POLLIN)]
        msg = {
            'key': 'value',
            'key2': ['v1', 1],
        }
        socket.return_value.recv_multipart.return_value = (
            'message type name',
            json.dumps(msg),
        )
        l = listener.Listener('endpoint')
        val = next(l.poll_once())
        self.assertEqual(val, ['message type name', msg])

########NEW FILE########
__FILENAME__ = test_publisher
import json

import fixtures
import mock
import testtools
import zmq

from smiley import publisher


class PublisherTest(testtools.TestCase):

    def setUp(self):
        super(PublisherTest, self).setUp()
        self.useFixture(fixtures.FakeLogger())

    @mock.patch('zmq.Context')
    def test_socket_setup(self, context_factory):
        publisher.Publisher('endpoint', 999)
        context = context_factory.return_value
        context.socket.assert_called_with(zmq.PUSH)
        s = context.socket.return_value
        s.bind.assert_called_with('endpoint')
        self.assertEqual(s.hwm, 999)

    @mock.patch('zmq.Context.socket')
    def test_message_format(self, socket):
        p = publisher.Publisher('endpoint', 999)
        msg = {
            'key': 'value',
            'key2': ['v1', 1],
        }
        p._send('message type name', msg)
        s = socket.return_value
        s.send_multipart.assert_called_with(
            ['message type name', json.dumps(msg)]
        )

########NEW FILE########
__FILENAME__ = test_tracer
import atexit
import os
import site

import mock
import testtools

from smiley import tracer


class TracerTest(testtools.TestCase):

    def test_interesting_locals(self):
        def _func():
            pass
        t = tracer.Tracer(None)
        f = mock.Mock()
        f.f_locals = {
            'simple_name': 1,
            'module': tracer,
            'function': _func,
            'method': self.setUp,
            '__magic__': 2,
        }
        interesting = t._get_interesting_locals(f)
        self.assertEqual(interesting, {'simple_name': 1})

    def test_ignore_stdlib_maybe_c(self):
        # The atexit module is implemented in C in python 3.3, so it
        # has a different filename and path than under 2.7. However,
        # on some systems (Linux?) the module is not even a dll, it's
        # a builtin.
        if not hasattr(atexit, '__file__'):
            self.skipTest('atexit is a builtin')
        t = tracer.Tracer(None, include_stdlib=False)
        self.assertTrue(t._should_ignore_file(atexit.__file__))

    def test_ignore_stdlib(self):
        t = tracer.Tracer(None, include_stdlib=False)
        self.assertIn(
            os.path.dirname(os.__file__) + os.sep,
            t._ignore_dirs,
        )
        self.assertTrue(
            t._should_ignore_file(os.__file__),
            'should ignore %s' % os.__file__,
        )

    def test_capture_stdlib(self):
        t = tracer.Tracer(None, include_stdlib=True)
        self.assertFalse(t._should_ignore_file(site.__file__))

    def test_ignore_smiley(self):
        t = tracer.Tracer(None)
        self.assertTrue(t._should_ignore_file(tracer.__file__))

    def test_include_smiley(self):
        t = tracer.Tracer(None, include_packages=['smiley'])
        self.assertFalse(t._should_ignore_file(tracer.__file__))

    def test_ignore_site_packages(self):
        t = tracer.Tracer(None, include_site_packages=False)
        #assert False, mock.__file__
        self.assertTrue(
            t._should_ignore_file(mock.__file__),
            'should ignore %s' % mock.__file__,
        )

    def test_include_site_packages(self):
        t = tracer.Tracer(None, include_site_packages=True)
        self.assertFalse(t._should_ignore_file(mock.__file__))

########NEW FILE########
__FILENAME__ = test_util
from unittest import TestCase

from smiley import util


class TestGetVariableChanges(TestCase):

    def test_addition(self):
        a = {}
        b = {'new': 'value'}
        changes = dict(util.get_variable_changes(a, b))
        self.assertIn('new', changes)

    def test_deletion(self):
        a = {'new': 'value'}
        b = {}
        changes = dict(util.get_variable_changes(a, b))
        self.assertNotIn('new', changes)

    def test_change(self):
        a = {'key': 'value'}
        b = {'key': 'newvalue'}
        changes = dict(util.get_variable_changes(a, b))
        self.assertIn('key', changes)
        self.assertEqual(b['key'], changes['key'])

    def test_change_newkey(self):
        a = {'key': 'value',
             'd': {'dkey': 'dval'}}
        b = {'key': 'value',
             'd': {'dkey': 'dval',
                   'dkey2': 'dval2'}}
        changes = dict(util.get_variable_changes(a, b))
        self.assertIn('d', changes)
        self.assertEqual(b['d'], changes['d'])

########NEW FILE########
__FILENAME__ = test_uuidstack
import testtools

from smiley import uuidstack


class UUIDStackTest(testtools.TestCase):

    def setUp(self):
        self.stack = uuidstack.UUIDStack()
        super(UUIDStackTest, self).setUp()

    def test_empty(self):
        self.assertEqual(self.stack._stack, [])
        self.assertEqual(self.stack.top(), None)

    def test_push(self):
        self.stack.push()
        self.assertEqual(len(self.stack._stack), 1)

    def test_top(self):
        self.stack.push()
        t = self.stack.top()
        self.assertTrue(t)

    def test_pop(self):
        self.stack.push()
        t1 = self.stack.top()
        t2 = self.stack.pop()
        self.assertEqual(t1, t2)
        self.assertEqual(self.stack._stack, [])

########NEW FILE########
__FILENAME__ = test_functional
# from unittest import TestCase
# from webtest import TestApp
from . import FunctionalTest


class TestRootController(FunctionalTest):

    def test_about(self):
        response = self.app.get('/about')
        self.assertEqual(response.status_int, 200)

    def test_index_redirects(self):
        response = self.app.get('/')
        self.assertEqual(response.status_int, 302)

    def test_get_not_found(self):
        response = self.app.get('/a/bogus/url', expect_errors=True)
        self.assertEqual(response.status_int, 404)

########NEW FILE########
__FILENAME__ = test_nav
from unittest import TestCase

from pecan import expose

from smiley.web import nav


class NavDecoratorTest(TestCase):

    def test_active_section_before_expose(self):
        @nav.active_section('test')
        @expose(generic=True, template='index.html')
        def func():
            return {}
        result = func()
        self.assertTrue('active_section' in result)
        self.assertEqual(result['active_section'], 'test')

    def test_active_section_after_expose(self):
        @expose(generic=True, template='index.html')
        @nav.active_section('test')
        def func():
            return {}
        result = func()
        self.assertTrue('active_section' in result)
        self.assertEqual(result['active_section'], 'test')

    def test_active_section_rendered_template(self):
        @nav.active_section('test')
        def func():
            return ''
        result = func()
        self.assertFalse('active_section' in result)

########NEW FILE########
__FILENAME__ = test_units
from unittest import TestCase


class TestUnits(TestCase):

    def test_units(self):
        assert 5 * 5 == 25

########NEW FILE########
__FILENAME__ = tracer
import atexit
import cProfile
import imp
import inspect
import logging
import marshal
import os
import pstats
import random
import site
import socket
import sys
import tempfile
import time
import uuid

import coverage
from coverage.execfile import run_python_file
from coverage.misc import ExceptionDuringRun

import smiley
from smiley import uuidstack

LOG = logging.getLogger(__name__)


class TracerContext(object):

    def __init__(self, tracer):
        self.tracer = tracer
        self.profile = cProfile.Profile()

    def __enter__(self):
        self.profile.enable()
        sys.settrace(self.tracer.trace_calls)
        return self

    def __exit__(self, *args):
        sys.settrace(None)
        self.profile.disable()

    def get_stats_data(self):
        stats = pstats.Stats(self.profile)
        with tempfile.TemporaryFile(mode='r+') as f:
            marshal.dump(stats.stats, f)
            f.flush()
            f.seek(0)
            return f.read()


class Tracer(object):

    def _canonical_path(self, path):
        return path.rstrip(os.sep) + os.sep

    def _canonical_parent(self, filename):
        return self._canonical_path(
            os.path.dirname(os.path.realpath(filename))
        )

    def __init__(self, publisher,
                 include_stdlib=False,
                 include_site_packages=True,
                 include_packages=[]):
        self.publisher = publisher
        # FIXME: Use a thread-local
        self.run_id = None
        self.canonical_filenames = {}
        self.uuid_gen = uuidstack.UUIDStack()

        # Build the list of paths to ignore, based on similar logic
        # from coverage's control.py, by Ned Batchelder, et al.
        #
        # Look at where some standard modules are located. That's the
        # indication for "installed with the interpreter". In some
        # environments (virtualenv, for example), these modules may be
        # spread across a few locations. Look at all the candidate modules
        # we've imported, and take all the different directories.
        self._ignore_dirs = set()
        # Always default to ignoring smiley and the coverage module
        candidates = [smiley, coverage]
        if not include_stdlib:
            stdlibdir = self._canonical_path(os.path.join(
                sys.prefix,
                'lib',
                'python%s.%s' % sys.version_info[:2],
            ))
            LOG.debug('ignoring stdlib %s', stdlibdir)
            self._ignore_dirs.add(stdlibdir)
            candidates.extend([atexit, os, random, socket, site])
        for m in candidates:
            if hasattr(m, "__file__"):
                to_ignore = self._canonical_parent(m.__file__)
                LOG.debug('ignoring packages under %s based on %s',
                          to_ignore, m.__name__)
                self._ignore_dirs.add(to_ignore)
        LOG.debug('ignoring packages from %s', sorted(self._ignore_dirs))

        # Build the list of packages we are always going to
        # include. Since the site-packages directory is under the
        # standard libary location, we have to handle that directory
        # here so it is checked before the standard library location.
        self._include_packages = set()
        for name in include_packages:
            try:
                f, filename, description = imp.find_module(name)
                if f:
                    f.close()
            except ImportError as e:
                LOG.info('Could not find %r to include it: %s',
                         name, e)
            else:
                to_include = self._canonical_parent(filename)
                LOG.debug('including packages under %s', to_include)
                self._include_packages.add(to_include)
        if include_site_packages:
            # Use a package we know we require (so it is likely to be
            # installed) but is not smiley (which will not work in a
            # test environment) to find the site-packages directory.
            import cliff
            site_packages = self._canonical_parent(
                self._canonical_parent(cliff.__file__)
            )
            LOG.debug('including site-packages %s', site_packages)
            self._include_packages.add(site_packages)
        LOG.debug('including packages from %s', sorted(self._include_packages))

    def _get_interesting_locals(self, frame):
        return {
            n: v
            for n, v in frame.f_locals.items()
            # Ignore any modules, methods, or functions that have made
            # their way into the "locals" namespace for this frame.
            if (not inspect.ismodule(v)
                and not inspect.isfunction(v)
                and not inspect.ismethod(v)
                and getattr(getattr(v, '__class__'),
                            '__module__') != '__future__'
                and (n[:2] != '__' and n[-2:] != '__'))
        }

    def _should_ignore_file(self, filename):
        # FIXME: Need to add the ability to explicitly not ignore some
        # things in the stdlib to trace into dependencies.
        if not filename:
            return True
        if filename.endswith('>'):
            # builtins?
            return True
        filename = os.path.realpath(filename)
        for d in self._include_packages:
            if filename.startswith(d):
                return False
        for d in self._ignore_dirs:
            if filename.startswith(d):
                return True
        return False

    def _send_notice(self, frame, event, arg, call_id):
        co = frame.f_code
        func_name = co.co_name
        line_no = frame.f_lineno
        # Expand the filename path to include the full directory so we
        # can decide whether to ignore it or not, and so the remote
        # side knows *exactly* which file we are looking at.
        filename = os.path.abspath(co.co_filename)
        interesting_locals = self._get_interesting_locals(frame)
        self.publisher.trace(
            run_id=self.run_id,
            call_id=call_id,
            event=event,
            func_name=func_name,
            line_no=line_no,
            filename=filename,
            trace_arg=arg,
            local_vars=interesting_locals,
            timestamp=time.time(),
        )

    def trace_calls(self, frame, event, arg):
        co = frame.f_code
        filename = co.co_filename
        if filename is not None:
            canonical = self.canonical_filenames.get(filename)
            if canonical is not None:
                filename = canonical
            else:
                full = os.path.abspath(filename)
                self.canonical_filenames[filename] = full
                filename = full
        if self._should_ignore_file(filename):
            return
        if event == 'call':
            call_id = self.uuid_gen.push()
        elif event == 'return':
            call_id = self.uuid_gen.pop()
        else:
            call_id = self.uuid_gen.top()
        self._send_notice(frame, event, arg, call_id)
        return self.trace_calls

    def run(self, command_line):
        self.run_id = str(uuid.uuid4())
        context = TracerContext(self)
        try:
            with context:
                self.publisher.start_run(
                    self.run_id,
                    os.getcwd(),
                    command_line,
                    time.time(),
                )
                run_python_file(
                    command_line[0],
                    command_line,
                )
        except ExceptionDuringRun as err:
            # Unpack the wrapped exception
            err_type, orig_err, traceback = err.args
            try:
                self.publisher.end_run(
                    self.run_id,
                    end_time=time.time(),
                    message=unicode(orig_err),
                    traceback=traceback,
                    stats=context.get_stats_data(),
                )
            finally:
                del traceback  # remove circular reference for GC
        else:
            self.publisher.end_run(
                self.run_id,
                time.time(),
                message=None,
                traceback=None,
                stats=context.get_stats_data(),
            )
            self.run_id = None

########NEW FILE########
__FILENAME__ = util
"""Utility functions for templates
"""


def get_variable_changes(older, newer):
    """Generate sequence of changes between two dictionaries

    Expects to have two variable/namespace dictionaries
    passed as arguments, and it yields the differences
    assuming the first is the older and the second is
    the newer.
    """
    for name in sorted(newer.keys()):
        if name not in older or older[name] != newer[name]:
            yield name, newer[name]

########NEW FILE########
__FILENAME__ = uuidstack
"""Manage a "stack" of UUID values for unique entries into a function.

The owner of the stack manages when calls enter and exit.

"""

import uuid

import six


class UUIDStack(object):

    def __init__(self):
        self._stack = []

    def top(self):
        if not self._stack:
            return None
        return self._stack[-1]

    def push(self):
        self._stack.append(six.text_type(uuid.uuid4()))

    def pop(self):
        return self._stack.pop()

########NEW FILE########
__FILENAME__ = app
from pecan import make_app
from smiley.web import model
from smiley.web import hooks


def setup_app(config):

    model.init_model()

    return make_app(
        config.app.root,
        static_root=config.app.static_root,
        template_path=config.app.template_path,
        logging={},  # let cliff configure logging, otherwise output repeats
        debug=getattr(config.app, 'debug', False),
        force_canonical=getattr(config.app, 'force_canonical', True),
        guess_content_type_from_ext=getattr(
            config.app,
            'guess_content_type_from_ext',
            True),
        hooks=[
            hooks.DBHook(config.smiley.database_name),
        ],
    )

########NEW FILE########
__FILENAME__ = config
import os

from smiley import web

_web_pkg_dir = os.path.dirname(web.__file__)


def get_config_dict(database_name, host, port):
    return {

        # Server Specific Configurations
        'server': {
            'port': port,
            'host': host,
        },

        # Pecan Application Configurations
        'app': {
            'root': 'smiley.web.controllers.root.RootController',
            'modules': ['smiley.web'],
            'static_root': os.path.join(_web_pkg_dir, 'public'),
            'template_path': os.path.join(_web_pkg_dir, 'templates'),
            'debug': True,
            'errors': {
                404: '/error/404',
                '__force_dict__': True
            },
        },

        'smiley': {
            'database_name': database_name,
        },
    }

########NEW FILE########
__FILENAME__ = files
from pecan import expose, request
from pecan.rest import RestController

from smiley.presentation import syntax
from smiley.web import nav


class FileController(RestController):

    @expose(generic=True, template='file.html')
    @nav.active_section('runs', 'files')
    def get_one(self, run_id, file_id):
        filename, body = request.db.get_cached_file_by_id(run_id, file_id)
        run = request.db.get_run(run_id)

        styled_body = syntax.apply_style(filename, body)

        return {
            'run_id': run_id,
            'run': run,
            'filename': filename,
            'body': body,
            'styled_body': styled_body,
        }

    @expose(generic=True, template='files.html')
    @nav.active_section('runs', 'files')
    def get_all(self, run_id):
        # TODO: Add option to only show error runs
        run = request.db.get_run(run_id)
        return {
            'run': run,
            'files': request.db.get_files_for_run(run_id),
            'run_id': run_id,
        }

########NEW FILE########
__FILENAME__ = root
from pecan import expose, redirect
from webob.exc import status_map

from smiley.web import nav
from smiley.web.controllers.runs import RunController


class RootController(object):

    runs = RunController()

    @expose(generic=True)
    def index(self):
        redirect('/runs')

    @expose('error.html')
    def error(self, status):
        try:
            status = int(status)
        except ValueError:  # pragma: no cover
            status = 500
        message = getattr(status_map.get(status), 'explanation', '')
        return dict(status=status, message=message)

    @expose(generic=True, template='about.html')
    @nav.active_section('about')
    def about(self):
        return {}

########NEW FILE########
__FILENAME__ = runs
import functools
import logging

from pecan import expose, request
from pecan.rest import RestController

from smiley.presentation import pagination
from smiley.presentation import syntax
from smiley.presentation import trace
from smiley.web import nav
from smiley.web.controllers import files
from smiley.web.controllers import stats

LOG = logging.getLogger(__name__)


class RunController(RestController):

    files = files.FileController()
    stats = stats.StatsController()

    _cached_run_id = None
    _cached_trace = None

    @expose(generic=True, template='runs.html')
    @nav.active_section('runs')
    def get_all(self):
        # TODO: Add option to only show error runs
        return {
            'runs': request.db.get_runs(sort_order='DESC'),
        }

    @expose(generic=True, template='run.html')
    @nav.active_section('runs', 'details')
    def get_one(self, run_id, page=1, per_page=20):
        run = request.db.get_run(run_id)

        if run_id == self._cached_run_id and self._cached_trace:
            LOG.debug('using cached trace for %s', run_id)
            trace_data = self._cached_trace
        else:
            LOG.debug('computing trace for %s', run_id)
            trace_data = list(
                trace.collapse_trace(request.db.get_trace(run_id))
            )
            self._cached_run_id = run_id
            self._cached_trace = trace_data
        syntax_line_cache = syntax.StyledLineCache(request.db, run_id)

        page_vals = pagination.get_pagination_values(
            page, per_page, len(trace_data),
        )
        start = page_vals['start']
        end = page_vals['end']

        def getlines(filename, nums):
            start, end = nums
            return syntax_line_cache.getlines(filename, start, end,
                                              include_comments=True)

        context = {
            'run_id': run_id,
            'run': run,
            'trace': trace_data[start:end],
            'getlines': getlines,
            'getfileid': functools.partial(request.db.get_file_signature,
                                           run_id=run_id),
        }
        context.update(page_vals)
        return context

########NEW FILE########
__FILENAME__ = stats
import functools
import logging

from pecan import expose, request

from smiley.web import nav
from smiley.presentation import stats

LOG = logging.getLogger(__name__)


class StatsController(object):

    @expose(generic=True, template='stats.html')
    @nav.active_section('runs', 'stats')
    def index(self, run_id):
        run = request.db.get_run(run_id)
        return {
            'run_id': run_id,
            'run': run,
            'stats_data': stats.format_data(run_id, run.stats, request.db),
            'getfileid': functools.partial(request.db.get_file_signature,
                                           run_id=run_id),
        }

    @expose(generic=True, template='graph.html')
    @nav.active_section('runs', 'graph')
    def graph(self, run_id):
        run = request.db.get_run(run_id)
        return {
            'run_id': run_id,
            'run': run,
        }

    @expose(content_type='image/png')
    @nav.active_section('runs', 'graph')
    def graph_data(self, run_id):
        run = request.db.get_run(run_id)
        try:
            return stats.generate_call_graph(run.stats)
        except:
            LOG.exception('could not generate image')
            raise

########NEW FILE########
__FILENAME__ = hooks
from pecan import hooks

from smiley import db


class DBHook(hooks.PecanHook):
    """Set up database for request.

    Attach a database object to the request so we don't have to create
    a new one each time.

    """

    def __init__(self, database_name):
        super(DBHook, self).__init__()
        self._db = db.DB(database_name)

    def before(self, state):
        state.request.db = self._db

########NEW FILE########
__FILENAME__ = nav
import functools


def active_section(active_section_name, subsection=None):
    """Insert the active section name into the template context.
    """
    def set_active_section(f):
        @functools.wraps(f)
        def decorator(*args, **kwds):
            result = f(*args, **kwds)
            if isinstance(result, dict):
                result['active_section'] = active_section_name
                result['active_subsection'] = subsection
            return result
        return decorator
    return set_active_section

########NEW FILE########
__FILENAME__ = test
import sys

import test_funcs

if __name__ == '__main__':
    print 'Running', __file__
    test_funcs.a()
    if '-e' in sys.argv:
        raise RuntimeError('test exception')

########NEW FILE########
__FILENAME__ = test_funcs
from __future__ import print_function

import sys


def gen(m):
    "docstring"
    for i in xrange(m):
        # inside the for loop
        yield i


def c(input):
    # comment
    print('input =', input)
    data = list(gen(input))
    print('Leaving c()', data)


# pre-function comment
def b(arg):
    val = arg * 5
    c(val)
    print('Leaving b()')
    return val


def produce_error():
    # multi-line
    # comment
    try:
        b('invalid')
    except Exception as err:
        print('Error:', err)


def large_data_structure():
    # another comment
    big_data = {
        'key': {
            'nested_key': 'nested_value',
            'html_data': '<b>this text is an html snippet</b>',
            'further': {
                'deeper': [
                    'lots of values',
                    'in this list',
                ],
            },
        },
    }
    big_data['key2'] = 'key'


def a():
    print('args:', sys.argv)
    b(2)
    produce_error()
    large_data_structure()
    print('Leaving a()')

########NEW FILE########
