__FILENAME__ = basic

########NEW FILE########
__FILENAME__ = column

########NEW FILE########
__FILENAME__ = columnfamily

########NEW FILE########
__FILENAME__ = keyspace

########NEW FILE########
__FILENAME__ = sorting

########NEW FILE########
__FILENAME__ = supercolumn

########NEW FILE########
__FILENAME__ = supercolumnfamily

########NEW FILE########
__FILENAME__ = basic
#!/usr/bin/python
from twisted.internet import defer

from telephus.cassandra.ttypes import (
    ColumnPath, ColumnParent, Column, SuperColumn)
from telephus.client import CassandraClient
from telephus.protocol import ManagedCassandraClientFactory


HOST = 'localhost'
PORT = 9160
KEYSPACE = 'Keyspace1'
CF = 'Standard1'
SCF = 'Super1'
COUNT_CF = 'Counter1'
SUPERCOUNT_CF = 'SuperCounter1'
colname = 'foo'
scname = 'bar'


@defer.inlineCallbacks
def dostuff(client):
    yield client.insert(
        key='test', column_family=CF, value='testval', column=colname)
    yield client.insert(
        key='test', column_family=SCF, value='testval', column=colname,
        super_column=scname)

    res = yield client.get(key='test', column_family=CF, column=colname)
    print 'get', res

    res = yield client.get(
        key='test', column_family=SCF, column=colname, super_column=scname)
    print 'get (super)', res

    res = yield client.get_slice(key='test', column_family=CF)
    print 'get_slice', res

    res = yield client.multiget(
        keys=['test', 'test2'], column_family=CF, column=colname)
    print 'multiget', res

    res = yield client.multiget_slice(keys=['test', 'test2'], column_family=CF)
    print 'multiget_slice', res

    res = yield client.get_count(key='test', column_family=CF)
    print 'get_count', res

    yield client.add(
        key='test', column_family=COUNT_CF, value=1, column='testcounter')
    res = yield client.get(
        key='test', column_family=COUNT_CF, column='testcounter')
    print 'get counter value', res

    yield client.add(
        key='test', column_family=SUPERCOUNT_CF, value=1, column='testcounter',
        super_column='testsuper')
    res = yield client.get(
        key='test', column_family=SUPERCOUNT_CF, column='testcounter',
        super_column='testsuper')
    print 'get super counter value', res

    # batch insert will figure out if you're trying a CF or SCF
    # from the data structure
    res = yield client.batch_insert(
        key='test', column_family=CF, mapping={colname: 'bar'})
    print "batch_insert", res
    res = yield client.batch_insert(
        key='test', column_family=SCF, mapping={'foo': {colname: 'bar'}})
    print "batch_insert", res

    # with ttypes, you pass a list as you would for raw thrift
    # this way you can set custom timestamps
    cols = [Column(colname, 'bar', 1234), Column('bar', 'baz', 54321)]
    res = yield client.batch_insert(key='test', column_family=CF, mapping=cols)
    print "batch_insert", res
    cols = [SuperColumn(name=colname, columns=cols)]

    # of course you don't have to use kwargs if the order is correct
    res = yield client.batch_insert('test', SCF, cols)
    print "batch_insert", res



if __name__ == '__main__':
    import sys
    from twisted.internet import reactor
    from twisted.python import log

    log.startLogging(sys.stdout)
    f = ManagedCassandraClientFactory(KEYSPACE)
    c = CassandraClient(f)
    dostuff(c)
    reactor.connectTCP(HOST, PORT, f)
    reactor.run()

########NEW FILE########
__FILENAME__ = Cassandra
#
# Autogenerated by Thrift Compiler (0.7.0)
#
# DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
#

from thrift.Thrift import *
from ttypes import *
from thrift.Thrift import TProcessor
from thrift.transport import TTransport
from thrift.protocol import TBinaryProtocol, TProtocol
try:
  from thrift.protocol import fastbinary
except:
  fastbinary = None

from zope.interface import Interface, implements
from twisted.internet import defer
from thrift.transport import TTwisted

class Iface(Interface):
  def login(auth_request):
    """
    Parameters:
     - auth_request
    """
    pass

  def set_keyspace(keyspace):
    """
    Parameters:
     - keyspace
    """
    pass

  def get(key, column_path, consistency_level):
    """
    Get the Column or SuperColumn at the given column_path. If no value is present, NotFoundException is thrown. (This is
    the only method that can throw an exception under non-failure conditions.)

    Parameters:
     - key
     - column_path
     - consistency_level
    """
    pass

  def get_slice(key, column_parent, predicate, consistency_level):
    """
    Get the group of columns contained by column_parent (either a ColumnFamily name or a ColumnFamily/SuperColumn name
    pair) specified by the given SlicePredicate. If no matching values are found, an empty list is returned.

    Parameters:
     - key
     - column_parent
     - predicate
     - consistency_level
    """
    pass

  def get_count(key, column_parent, predicate, consistency_level):
    """
    returns the number of columns matching <code>predicate</code> for a particular <code>key</code>,
    <code>ColumnFamily</code> and optionally <code>SuperColumn</code>.

    Parameters:
     - key
     - column_parent
     - predicate
     - consistency_level
    """
    pass

  def multiget_slice(keys, column_parent, predicate, consistency_level):
    """
    Performs a get_slice for column_parent and predicate for the given keys in parallel.

    Parameters:
     - keys
     - column_parent
     - predicate
     - consistency_level
    """
    pass

  def multiget_count(keys, column_parent, predicate, consistency_level):
    """
    Perform a get_count in parallel on the given list<binary> keys. The return value maps keys to the count found.

    Parameters:
     - keys
     - column_parent
     - predicate
     - consistency_level
    """
    pass

  def get_range_slices(column_parent, predicate, range, consistency_level):
    """
    returns a subset of columns for a contiguous range of keys.

    Parameters:
     - column_parent
     - predicate
     - range
     - consistency_level
    """
    pass

  def get_paged_slice(column_family, range, start_column, consistency_level):
    """
    returns a range of columns, wrapping to the next rows if necessary to collect max_results.

    Parameters:
     - column_family
     - range
     - start_column
     - consistency_level
    """
    pass

  def get_indexed_slices(column_parent, index_clause, column_predicate, consistency_level):
    """
    Returns the subset of columns specified in SlicePredicate for the rows matching the IndexClause
    @deprecated use get_range_slices instead with range.row_filter specified

    Parameters:
     - column_parent
     - index_clause
     - column_predicate
     - consistency_level
    """
    pass

  def insert(key, column_parent, column, consistency_level):
    """
    Insert a Column at the given column_parent.column_family and optional column_parent.super_column.

    Parameters:
     - key
     - column_parent
     - column
     - consistency_level
    """
    pass

  def add(key, column_parent, column, consistency_level):
    """
    Increment or decrement a counter.

    Parameters:
     - key
     - column_parent
     - column
     - consistency_level
    """
    pass

  def remove(key, column_path, timestamp, consistency_level):
    """
    Remove data from the row specified by key at the granularity specified by column_path, and the given timestamp. Note
    that all the values in column_path besides column_path.column_family are truly optional: you can remove the entire
    row by just specifying the ColumnFamily, or you can remove a SuperColumn or a single Column by specifying those levels too.

    Parameters:
     - key
     - column_path
     - timestamp
     - consistency_level
    """
    pass

  def remove_counter(key, path, consistency_level):
    """
    Remove a counter at the specified location.
    Note that counters have limited support for deletes: if you remove a counter, you must wait to issue any following update
    until the delete has reached all the nodes and all of them have been fully compacted.

    Parameters:
     - key
     - path
     - consistency_level
    """
    pass

  def batch_mutate(mutation_map, consistency_level):
    """
      Mutate many columns or super columns for many row keys. See also: Mutation.

      mutation_map maps key to column family to a list of Mutation objects to take place at that scope.
    *

    Parameters:
     - mutation_map
     - consistency_level
    """
    pass

  def atomic_batch_mutate(mutation_map, consistency_level):
    """
      Atomically mutate many columns or super columns for many row keys. See also: Mutation.

      mutation_map maps key to column family to a list of Mutation objects to take place at that scope.
    *

    Parameters:
     - mutation_map
     - consistency_level
    """
    pass

  def truncate(cfname):
    """
    Truncate will mark and entire column family as deleted.
    From the user's perspective a successful call to truncate will result complete data deletion from cfname.
    Internally, however, disk space will not be immediatily released, as with all deletes in cassandra, this one
    only marks the data as deleted.
    The operation succeeds only if all hosts in the cluster at available and will throw an UnavailableException if
    some hosts are down.

    Parameters:
     - cfname
    """
    pass

  def describe_schema_versions():
    """
    for each schema version present in the cluster, returns a list of nodes at that version.
    hosts that do not respond will be under the key DatabaseDescriptor.INITIAL_VERSION.
    the cluster is all on the same version if the size of the map is 1.
    """
    pass

  def describe_keyspaces():
    """
    list the defined keyspaces in this cluster
    """
    pass

  def describe_cluster_name():
    """
    get the cluster name
    """
    pass

  def describe_version():
    """
    get the thrift api version
    """
    pass

  def describe_ring(keyspace):
    """
    get the token ring: a map of ranges to host addresses,
    represented as a set of TokenRange instead of a map from range
    to list of endpoints, because you can't use Thrift structs as
    map keys:
    https://issues.apache.org/jira/browse/THRIFT-162

    for the same reason, we can't return a set here, even though
    order is neither important nor predictable.

    Parameters:
     - keyspace
    """
    pass

  def describe_token_map():
    """
    get the mapping between token->node ip
    without taking replication into consideration
    https://issues.apache.org/jira/browse/CASSANDRA-4092
    """
    pass

  def describe_partitioner():
    """
    returns the partitioner used by this cluster
    """
    pass

  def describe_snitch():
    """
    returns the snitch used by this cluster
    """
    pass

  def describe_keyspace(keyspace):
    """
    describe specified keyspace

    Parameters:
     - keyspace
    """
    pass

  def describe_splits(cfName, start_token, end_token, keys_per_split):
    """
    experimental API for hadoop/parallel query support.
    may change violently and without warning.

    returns list of token strings such that first subrange is (list[0], list[1]],
    next is (list[1], list[2]], etc.

    Parameters:
     - cfName
     - start_token
     - end_token
     - keys_per_split
    """
    pass

  def trace_next_query():
    """
    Enables tracing for the next query in this connection and returns the UUID for that trace session
    The next query will be traced idependently of trace probability and the returned UUID can be used to query the trace keyspace
    """
    pass

  def describe_splits_ex(cfName, start_token, end_token, keys_per_split):
    """
    Parameters:
     - cfName
     - start_token
     - end_token
     - keys_per_split
    """
    pass

  def system_add_column_family(cf_def):
    """
    adds a column family. returns the new schema id.

    Parameters:
     - cf_def
    """
    pass

  def system_drop_column_family(column_family):
    """
    drops a column family. returns the new schema id.

    Parameters:
     - column_family
    """
    pass

  def system_add_keyspace(ks_def):
    """
    adds a keyspace and any column families that are part of it. returns the new schema id.

    Parameters:
     - ks_def
    """
    pass

  def system_drop_keyspace(keyspace):
    """
    drops a keyspace and any column families that are part of it. returns the new schema id.

    Parameters:
     - keyspace
    """
    pass

  def system_update_keyspace(ks_def):
    """
    updates properties of a keyspace. returns the new schema id.

    Parameters:
     - ks_def
    """
    pass

  def system_update_column_family(cf_def):
    """
    updates properties of a column family. returns the new schema id.

    Parameters:
     - cf_def
    """
    pass

  def execute_cql_query(query, compression):
    """
    Executes a CQL (Cassandra Query Language) statement and returns a
    CqlResult containing the results.

    Parameters:
     - query
     - compression
    """
    pass

  def execute_cql3_query(query, compression, consistency):
    """
    Parameters:
     - query
     - compression
     - consistency
    """
    pass

  def prepare_cql_query(query, compression):
    """
    Prepare a CQL (Cassandra Query Language) statement by compiling and returning
    - the type of CQL statement
    - an id token of the compiled CQL stored on the server side.
    - a count of the discovered bound markers in the statement

    Parameters:
     - query
     - compression
    """
    pass

  def prepare_cql3_query(query, compression):
    """
    Parameters:
     - query
     - compression
    """
    pass

  def execute_prepared_cql_query(itemId, values):
    """
    Executes a prepared CQL (Cassandra Query Language) statement by passing an id token and  a list of variables
    to bind and returns a CqlResult containing the results.

    Parameters:
     - itemId
     - values
    """
    pass

  def execute_prepared_cql3_query(itemId, values, consistency):
    """
    Parameters:
     - itemId
     - values
     - consistency
    """
    pass

  def set_cql_version(version):
    """
    @deprecated This is now a no-op. Please use the CQL3 specific methods instead.

    Parameters:
     - version
    """
    pass


class Client:
  implements(Iface)

  def __init__(self, transport, oprot_factory):
    self._transport = transport
    self._oprot_factory = oprot_factory
    self._seqid = 0
    self._reqs = {}

  def login(self, auth_request):
    """
    Parameters:
     - auth_request
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_login(auth_request)
    return d

  def send_login(self, auth_request):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('login', TMessageType.CALL, self._seqid)
    args = login_args()
    args.auth_request = auth_request
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_login(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = login_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.authnx is not None:
      return d.errback(result.authnx)
    if result.authzx is not None:
      return d.errback(result.authzx)
    return d.callback(None)

  def set_keyspace(self, keyspace):
    """
    Parameters:
     - keyspace
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_set_keyspace(keyspace)
    return d

  def send_set_keyspace(self, keyspace):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('set_keyspace', TMessageType.CALL, self._seqid)
    args = set_keyspace_args()
    args.keyspace = keyspace
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_set_keyspace(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = set_keyspace_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.ire is not None:
      return d.errback(result.ire)
    return d.callback(None)

  def get(self, key, column_path, consistency_level):
    """
    Get the Column or SuperColumn at the given column_path. If no value is present, NotFoundException is thrown. (This is
    the only method that can throw an exception under non-failure conditions.)

    Parameters:
     - key
     - column_path
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_get(key, column_path, consistency_level)
    return d

  def send_get(self, key, column_path, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('get', TMessageType.CALL, self._seqid)
    args = get_args()
    args.key = key
    args.column_path = column_path
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_get(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = get_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.nfe is not None:
      return d.errback(result.nfe)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "get failed: unknown result"))

  def get_slice(self, key, column_parent, predicate, consistency_level):
    """
    Get the group of columns contained by column_parent (either a ColumnFamily name or a ColumnFamily/SuperColumn name
    pair) specified by the given SlicePredicate. If no matching values are found, an empty list is returned.

    Parameters:
     - key
     - column_parent
     - predicate
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_get_slice(key, column_parent, predicate, consistency_level)
    return d

  def send_get_slice(self, key, column_parent, predicate, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('get_slice', TMessageType.CALL, self._seqid)
    args = get_slice_args()
    args.key = key
    args.column_parent = column_parent
    args.predicate = predicate
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_get_slice(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = get_slice_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "get_slice failed: unknown result"))

  def get_count(self, key, column_parent, predicate, consistency_level):
    """
    returns the number of columns matching <code>predicate</code> for a particular <code>key</code>,
    <code>ColumnFamily</code> and optionally <code>SuperColumn</code>.

    Parameters:
     - key
     - column_parent
     - predicate
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_get_count(key, column_parent, predicate, consistency_level)
    return d

  def send_get_count(self, key, column_parent, predicate, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('get_count', TMessageType.CALL, self._seqid)
    args = get_count_args()
    args.key = key
    args.column_parent = column_parent
    args.predicate = predicate
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_get_count(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = get_count_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "get_count failed: unknown result"))

  def multiget_slice(self, keys, column_parent, predicate, consistency_level):
    """
    Performs a get_slice for column_parent and predicate for the given keys in parallel.

    Parameters:
     - keys
     - column_parent
     - predicate
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_multiget_slice(keys, column_parent, predicate, consistency_level)
    return d

  def send_multiget_slice(self, keys, column_parent, predicate, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('multiget_slice', TMessageType.CALL, self._seqid)
    args = multiget_slice_args()
    args.keys = keys
    args.column_parent = column_parent
    args.predicate = predicate
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_multiget_slice(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = multiget_slice_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "multiget_slice failed: unknown result"))

  def multiget_count(self, keys, column_parent, predicate, consistency_level):
    """
    Perform a get_count in parallel on the given list<binary> keys. The return value maps keys to the count found.

    Parameters:
     - keys
     - column_parent
     - predicate
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_multiget_count(keys, column_parent, predicate, consistency_level)
    return d

  def send_multiget_count(self, keys, column_parent, predicate, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('multiget_count', TMessageType.CALL, self._seqid)
    args = multiget_count_args()
    args.keys = keys
    args.column_parent = column_parent
    args.predicate = predicate
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_multiget_count(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = multiget_count_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "multiget_count failed: unknown result"))

  def get_range_slices(self, column_parent, predicate, range, consistency_level):
    """
    returns a subset of columns for a contiguous range of keys.

    Parameters:
     - column_parent
     - predicate
     - range
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_get_range_slices(column_parent, predicate, range, consistency_level)
    return d

  def send_get_range_slices(self, column_parent, predicate, range, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('get_range_slices', TMessageType.CALL, self._seqid)
    args = get_range_slices_args()
    args.column_parent = column_parent
    args.predicate = predicate
    args.range = range
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_get_range_slices(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = get_range_slices_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "get_range_slices failed: unknown result"))

  def get_paged_slice(self, column_family, range, start_column, consistency_level):
    """
    returns a range of columns, wrapping to the next rows if necessary to collect max_results.

    Parameters:
     - column_family
     - range
     - start_column
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_get_paged_slice(column_family, range, start_column, consistency_level)
    return d

  def send_get_paged_slice(self, column_family, range, start_column, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('get_paged_slice', TMessageType.CALL, self._seqid)
    args = get_paged_slice_args()
    args.column_family = column_family
    args.range = range
    args.start_column = start_column
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_get_paged_slice(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = get_paged_slice_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "get_paged_slice failed: unknown result"))

  def get_indexed_slices(self, column_parent, index_clause, column_predicate, consistency_level):
    """
    Returns the subset of columns specified in SlicePredicate for the rows matching the IndexClause
    @deprecated use get_range_slices instead with range.row_filter specified

    Parameters:
     - column_parent
     - index_clause
     - column_predicate
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_get_indexed_slices(column_parent, index_clause, column_predicate, consistency_level)
    return d

  def send_get_indexed_slices(self, column_parent, index_clause, column_predicate, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('get_indexed_slices', TMessageType.CALL, self._seqid)
    args = get_indexed_slices_args()
    args.column_parent = column_parent
    args.index_clause = index_clause
    args.column_predicate = column_predicate
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_get_indexed_slices(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = get_indexed_slices_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "get_indexed_slices failed: unknown result"))

  def insert(self, key, column_parent, column, consistency_level):
    """
    Insert a Column at the given column_parent.column_family and optional column_parent.super_column.

    Parameters:
     - key
     - column_parent
     - column
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_insert(key, column_parent, column, consistency_level)
    return d

  def send_insert(self, key, column_parent, column, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('insert', TMessageType.CALL, self._seqid)
    args = insert_args()
    args.key = key
    args.column_parent = column_parent
    args.column = column
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_insert(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = insert_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.callback(None)

  def add(self, key, column_parent, column, consistency_level):
    """
    Increment or decrement a counter.

    Parameters:
     - key
     - column_parent
     - column
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_add(key, column_parent, column, consistency_level)
    return d

  def send_add(self, key, column_parent, column, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('add', TMessageType.CALL, self._seqid)
    args = add_args()
    args.key = key
    args.column_parent = column_parent
    args.column = column
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_add(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = add_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.callback(None)

  def remove(self, key, column_path, timestamp, consistency_level):
    """
    Remove data from the row specified by key at the granularity specified by column_path, and the given timestamp. Note
    that all the values in column_path besides column_path.column_family are truly optional: you can remove the entire
    row by just specifying the ColumnFamily, or you can remove a SuperColumn or a single Column by specifying those levels too.

    Parameters:
     - key
     - column_path
     - timestamp
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_remove(key, column_path, timestamp, consistency_level)
    return d

  def send_remove(self, key, column_path, timestamp, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('remove', TMessageType.CALL, self._seqid)
    args = remove_args()
    args.key = key
    args.column_path = column_path
    args.timestamp = timestamp
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_remove(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = remove_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.callback(None)

  def remove_counter(self, key, path, consistency_level):
    """
    Remove a counter at the specified location.
    Note that counters have limited support for deletes: if you remove a counter, you must wait to issue any following update
    until the delete has reached all the nodes and all of them have been fully compacted.

    Parameters:
     - key
     - path
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_remove_counter(key, path, consistency_level)
    return d

  def send_remove_counter(self, key, path, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('remove_counter', TMessageType.CALL, self._seqid)
    args = remove_counter_args()
    args.key = key
    args.path = path
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_remove_counter(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = remove_counter_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.callback(None)

  def batch_mutate(self, mutation_map, consistency_level):
    """
      Mutate many columns or super columns for many row keys. See also: Mutation.

      mutation_map maps key to column family to a list of Mutation objects to take place at that scope.
    *

    Parameters:
     - mutation_map
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_batch_mutate(mutation_map, consistency_level)
    return d

  def send_batch_mutate(self, mutation_map, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('batch_mutate', TMessageType.CALL, self._seqid)
    args = batch_mutate_args()
    args.mutation_map = mutation_map
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_batch_mutate(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = batch_mutate_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.callback(None)

  def atomic_batch_mutate(self, mutation_map, consistency_level):
    """
      Atomically mutate many columns or super columns for many row keys. See also: Mutation.

      mutation_map maps key to column family to a list of Mutation objects to take place at that scope.
    *

    Parameters:
     - mutation_map
     - consistency_level
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_atomic_batch_mutate(mutation_map, consistency_level)
    return d

  def send_atomic_batch_mutate(self, mutation_map, consistency_level):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('atomic_batch_mutate', TMessageType.CALL, self._seqid)
    args = atomic_batch_mutate_args()
    args.mutation_map = mutation_map
    args.consistency_level = consistency_level
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_atomic_batch_mutate(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = atomic_batch_mutate_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.callback(None)

  def truncate(self, cfname):
    """
    Truncate will mark and entire column family as deleted.
    From the user's perspective a successful call to truncate will result complete data deletion from cfname.
    Internally, however, disk space will not be immediatily released, as with all deletes in cassandra, this one
    only marks the data as deleted.
    The operation succeeds only if all hosts in the cluster at available and will throw an UnavailableException if
    some hosts are down.

    Parameters:
     - cfname
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_truncate(cfname)
    return d

  def send_truncate(self, cfname):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('truncate', TMessageType.CALL, self._seqid)
    args = truncate_args()
    args.cfname = cfname
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_truncate(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = truncate_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    return d.callback(None)

  def describe_schema_versions(self, ):
    """
    for each schema version present in the cluster, returns a list of nodes at that version.
    hosts that do not respond will be under the key DatabaseDescriptor.INITIAL_VERSION.
    the cluster is all on the same version if the size of the map is 1.
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_schema_versions()
    return d

  def send_describe_schema_versions(self, ):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_schema_versions', TMessageType.CALL, self._seqid)
    args = describe_schema_versions_args()
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_schema_versions(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_schema_versions_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_schema_versions failed: unknown result"))

  def describe_keyspaces(self, ):
    """
    list the defined keyspaces in this cluster
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_keyspaces()
    return d

  def send_describe_keyspaces(self, ):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_keyspaces', TMessageType.CALL, self._seqid)
    args = describe_keyspaces_args()
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_keyspaces(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_keyspaces_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_keyspaces failed: unknown result"))

  def describe_cluster_name(self, ):
    """
    get the cluster name
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_cluster_name()
    return d

  def send_describe_cluster_name(self, ):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_cluster_name', TMessageType.CALL, self._seqid)
    args = describe_cluster_name_args()
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_cluster_name(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_cluster_name_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_cluster_name failed: unknown result"))

  def describe_version(self, ):
    """
    get the thrift api version
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_version()
    return d

  def send_describe_version(self, ):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_version', TMessageType.CALL, self._seqid)
    args = describe_version_args()
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_version(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_version_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_version failed: unknown result"))

  def describe_ring(self, keyspace):
    """
    get the token ring: a map of ranges to host addresses,
    represented as a set of TokenRange instead of a map from range
    to list of endpoints, because you can't use Thrift structs as
    map keys:
    https://issues.apache.org/jira/browse/THRIFT-162

    for the same reason, we can't return a set here, even though
    order is neither important nor predictable.

    Parameters:
     - keyspace
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_ring(keyspace)
    return d

  def send_describe_ring(self, keyspace):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_ring', TMessageType.CALL, self._seqid)
    args = describe_ring_args()
    args.keyspace = keyspace
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_ring(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_ring_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_ring failed: unknown result"))

  def describe_token_map(self, ):
    """
    get the mapping between token->node ip
    without taking replication into consideration
    https://issues.apache.org/jira/browse/CASSANDRA-4092
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_token_map()
    return d

  def send_describe_token_map(self, ):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_token_map', TMessageType.CALL, self._seqid)
    args = describe_token_map_args()
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_token_map(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_token_map_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_token_map failed: unknown result"))

  def describe_partitioner(self, ):
    """
    returns the partitioner used by this cluster
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_partitioner()
    return d

  def send_describe_partitioner(self, ):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_partitioner', TMessageType.CALL, self._seqid)
    args = describe_partitioner_args()
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_partitioner(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_partitioner_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_partitioner failed: unknown result"))

  def describe_snitch(self, ):
    """
    returns the snitch used by this cluster
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_snitch()
    return d

  def send_describe_snitch(self, ):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_snitch', TMessageType.CALL, self._seqid)
    args = describe_snitch_args()
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_snitch(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_snitch_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_snitch failed: unknown result"))

  def describe_keyspace(self, keyspace):
    """
    describe specified keyspace

    Parameters:
     - keyspace
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_keyspace(keyspace)
    return d

  def send_describe_keyspace(self, keyspace):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_keyspace', TMessageType.CALL, self._seqid)
    args = describe_keyspace_args()
    args.keyspace = keyspace
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_keyspace(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_keyspace_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.nfe is not None:
      return d.errback(result.nfe)
    if result.ire is not None:
      return d.errback(result.ire)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_keyspace failed: unknown result"))

  def describe_splits(self, cfName, start_token, end_token, keys_per_split):
    """
    experimental API for hadoop/parallel query support.
    may change violently and without warning.

    returns list of token strings such that first subrange is (list[0], list[1]],
    next is (list[1], list[2]], etc.

    Parameters:
     - cfName
     - start_token
     - end_token
     - keys_per_split
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_splits(cfName, start_token, end_token, keys_per_split)
    return d

  def send_describe_splits(self, cfName, start_token, end_token, keys_per_split):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_splits', TMessageType.CALL, self._seqid)
    args = describe_splits_args()
    args.cfName = cfName
    args.start_token = start_token
    args.end_token = end_token
    args.keys_per_split = keys_per_split
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_splits(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_splits_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_splits failed: unknown result"))

  def trace_next_query(self, ):
    """
    Enables tracing for the next query in this connection and returns the UUID for that trace session
    The next query will be traced idependently of trace probability and the returned UUID can be used to query the trace keyspace
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_trace_next_query()
    return d

  def send_trace_next_query(self, ):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('trace_next_query', TMessageType.CALL, self._seqid)
    args = trace_next_query_args()
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_trace_next_query(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = trace_next_query_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "trace_next_query failed: unknown result"))

  def describe_splits_ex(self, cfName, start_token, end_token, keys_per_split):
    """
    Parameters:
     - cfName
     - start_token
     - end_token
     - keys_per_split
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_describe_splits_ex(cfName, start_token, end_token, keys_per_split)
    return d

  def send_describe_splits_ex(self, cfName, start_token, end_token, keys_per_split):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('describe_splits_ex', TMessageType.CALL, self._seqid)
    args = describe_splits_ex_args()
    args.cfName = cfName
    args.start_token = start_token
    args.end_token = end_token
    args.keys_per_split = keys_per_split
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_describe_splits_ex(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = describe_splits_ex_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "describe_splits_ex failed: unknown result"))

  def system_add_column_family(self, cf_def):
    """
    adds a column family. returns the new schema id.

    Parameters:
     - cf_def
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_system_add_column_family(cf_def)
    return d

  def send_system_add_column_family(self, cf_def):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('system_add_column_family', TMessageType.CALL, self._seqid)
    args = system_add_column_family_args()
    args.cf_def = cf_def
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_system_add_column_family(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = system_add_column_family_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.sde is not None:
      return d.errback(result.sde)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "system_add_column_family failed: unknown result"))

  def system_drop_column_family(self, column_family):
    """
    drops a column family. returns the new schema id.

    Parameters:
     - column_family
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_system_drop_column_family(column_family)
    return d

  def send_system_drop_column_family(self, column_family):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('system_drop_column_family', TMessageType.CALL, self._seqid)
    args = system_drop_column_family_args()
    args.column_family = column_family
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_system_drop_column_family(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = system_drop_column_family_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.sde is not None:
      return d.errback(result.sde)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "system_drop_column_family failed: unknown result"))

  def system_add_keyspace(self, ks_def):
    """
    adds a keyspace and any column families that are part of it. returns the new schema id.

    Parameters:
     - ks_def
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_system_add_keyspace(ks_def)
    return d

  def send_system_add_keyspace(self, ks_def):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('system_add_keyspace', TMessageType.CALL, self._seqid)
    args = system_add_keyspace_args()
    args.ks_def = ks_def
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_system_add_keyspace(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = system_add_keyspace_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.sde is not None:
      return d.errback(result.sde)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "system_add_keyspace failed: unknown result"))

  def system_drop_keyspace(self, keyspace):
    """
    drops a keyspace and any column families that are part of it. returns the new schema id.

    Parameters:
     - keyspace
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_system_drop_keyspace(keyspace)
    return d

  def send_system_drop_keyspace(self, keyspace):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('system_drop_keyspace', TMessageType.CALL, self._seqid)
    args = system_drop_keyspace_args()
    args.keyspace = keyspace
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_system_drop_keyspace(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = system_drop_keyspace_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.sde is not None:
      return d.errback(result.sde)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "system_drop_keyspace failed: unknown result"))

  def system_update_keyspace(self, ks_def):
    """
    updates properties of a keyspace. returns the new schema id.

    Parameters:
     - ks_def
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_system_update_keyspace(ks_def)
    return d

  def send_system_update_keyspace(self, ks_def):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('system_update_keyspace', TMessageType.CALL, self._seqid)
    args = system_update_keyspace_args()
    args.ks_def = ks_def
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_system_update_keyspace(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = system_update_keyspace_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.sde is not None:
      return d.errback(result.sde)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "system_update_keyspace failed: unknown result"))

  def system_update_column_family(self, cf_def):
    """
    updates properties of a column family. returns the new schema id.

    Parameters:
     - cf_def
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_system_update_column_family(cf_def)
    return d

  def send_system_update_column_family(self, cf_def):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('system_update_column_family', TMessageType.CALL, self._seqid)
    args = system_update_column_family_args()
    args.cf_def = cf_def
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_system_update_column_family(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = system_update_column_family_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.sde is not None:
      return d.errback(result.sde)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "system_update_column_family failed: unknown result"))

  def execute_cql_query(self, query, compression):
    """
    Executes a CQL (Cassandra Query Language) statement and returns a
    CqlResult containing the results.

    Parameters:
     - query
     - compression
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_execute_cql_query(query, compression)
    return d

  def send_execute_cql_query(self, query, compression):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('execute_cql_query', TMessageType.CALL, self._seqid)
    args = execute_cql_query_args()
    args.query = query
    args.compression = compression
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_execute_cql_query(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = execute_cql_query_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    if result.sde is not None:
      return d.errback(result.sde)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "execute_cql_query failed: unknown result"))

  def execute_cql3_query(self, query, compression, consistency):
    """
    Parameters:
     - query
     - compression
     - consistency
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_execute_cql3_query(query, compression, consistency)
    return d

  def send_execute_cql3_query(self, query, compression, consistency):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('execute_cql3_query', TMessageType.CALL, self._seqid)
    args = execute_cql3_query_args()
    args.query = query
    args.compression = compression
    args.consistency = consistency
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_execute_cql3_query(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = execute_cql3_query_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    if result.sde is not None:
      return d.errback(result.sde)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "execute_cql3_query failed: unknown result"))

  def prepare_cql_query(self, query, compression):
    """
    Prepare a CQL (Cassandra Query Language) statement by compiling and returning
    - the type of CQL statement
    - an id token of the compiled CQL stored on the server side.
    - a count of the discovered bound markers in the statement

    Parameters:
     - query
     - compression
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_prepare_cql_query(query, compression)
    return d

  def send_prepare_cql_query(self, query, compression):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('prepare_cql_query', TMessageType.CALL, self._seqid)
    args = prepare_cql_query_args()
    args.query = query
    args.compression = compression
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_prepare_cql_query(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = prepare_cql_query_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "prepare_cql_query failed: unknown result"))

  def prepare_cql3_query(self, query, compression):
    """
    Parameters:
     - query
     - compression
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_prepare_cql3_query(query, compression)
    return d

  def send_prepare_cql3_query(self, query, compression):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('prepare_cql3_query', TMessageType.CALL, self._seqid)
    args = prepare_cql3_query_args()
    args.query = query
    args.compression = compression
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_prepare_cql3_query(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = prepare_cql3_query_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "prepare_cql3_query failed: unknown result"))

  def execute_prepared_cql_query(self, itemId, values):
    """
    Executes a prepared CQL (Cassandra Query Language) statement by passing an id token and  a list of variables
    to bind and returns a CqlResult containing the results.

    Parameters:
     - itemId
     - values
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_execute_prepared_cql_query(itemId, values)
    return d

  def send_execute_prepared_cql_query(self, itemId, values):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('execute_prepared_cql_query', TMessageType.CALL, self._seqid)
    args = execute_prepared_cql_query_args()
    args.itemId = itemId
    args.values = values
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_execute_prepared_cql_query(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = execute_prepared_cql_query_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    if result.sde is not None:
      return d.errback(result.sde)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "execute_prepared_cql_query failed: unknown result"))

  def execute_prepared_cql3_query(self, itemId, values, consistency):
    """
    Parameters:
     - itemId
     - values
     - consistency
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_execute_prepared_cql3_query(itemId, values, consistency)
    return d

  def send_execute_prepared_cql3_query(self, itemId, values, consistency):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('execute_prepared_cql3_query', TMessageType.CALL, self._seqid)
    args = execute_prepared_cql3_query_args()
    args.itemId = itemId
    args.values = values
    args.consistency = consistency
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_execute_prepared_cql3_query(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = execute_prepared_cql3_query_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.success is not None:
      return d.callback(result.success)
    if result.ire is not None:
      return d.errback(result.ire)
    if result.ue is not None:
      return d.errback(result.ue)
    if result.te is not None:
      return d.errback(result.te)
    if result.sde is not None:
      return d.errback(result.sde)
    return d.errback(TApplicationException(TApplicationException.MISSING_RESULT, "execute_prepared_cql3_query failed: unknown result"))

  def set_cql_version(self, version):
    """
    @deprecated This is now a no-op. Please use the CQL3 specific methods instead.

    Parameters:
     - version
    """
    self._seqid += 1
    d = self._reqs[self._seqid] = defer.Deferred()
    self.send_set_cql_version(version)
    return d

  def send_set_cql_version(self, version):
    oprot = self._oprot_factory.getProtocol(self._transport)
    oprot.writeMessageBegin('set_cql_version', TMessageType.CALL, self._seqid)
    args = set_cql_version_args()
    args.version = version
    args.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def recv_set_cql_version(self, iprot, mtype, rseqid):
    d = self._reqs.pop(rseqid)
    if mtype == TMessageType.EXCEPTION:
      x = TApplicationException()
      x.read(iprot)
      iprot.readMessageEnd()
      return d.errback(x)
    result = set_cql_version_result()
    result.read(iprot)
    iprot.readMessageEnd()
    if result.ire is not None:
      return d.errback(result.ire)
    return d.callback(None)


class Processor(TProcessor):
  implements(Iface)

  def __init__(self, handler):
    self._handler = Iface(handler)
    self._processMap = {}
    self._processMap["login"] = Processor.process_login
    self._processMap["set_keyspace"] = Processor.process_set_keyspace
    self._processMap["get"] = Processor.process_get
    self._processMap["get_slice"] = Processor.process_get_slice
    self._processMap["get_count"] = Processor.process_get_count
    self._processMap["multiget_slice"] = Processor.process_multiget_slice
    self._processMap["multiget_count"] = Processor.process_multiget_count
    self._processMap["get_range_slices"] = Processor.process_get_range_slices
    self._processMap["get_paged_slice"] = Processor.process_get_paged_slice
    self._processMap["get_indexed_slices"] = Processor.process_get_indexed_slices
    self._processMap["insert"] = Processor.process_insert
    self._processMap["add"] = Processor.process_add
    self._processMap["remove"] = Processor.process_remove
    self._processMap["remove_counter"] = Processor.process_remove_counter
    self._processMap["batch_mutate"] = Processor.process_batch_mutate
    self._processMap["atomic_batch_mutate"] = Processor.process_atomic_batch_mutate
    self._processMap["truncate"] = Processor.process_truncate
    self._processMap["describe_schema_versions"] = Processor.process_describe_schema_versions
    self._processMap["describe_keyspaces"] = Processor.process_describe_keyspaces
    self._processMap["describe_cluster_name"] = Processor.process_describe_cluster_name
    self._processMap["describe_version"] = Processor.process_describe_version
    self._processMap["describe_ring"] = Processor.process_describe_ring
    self._processMap["describe_token_map"] = Processor.process_describe_token_map
    self._processMap["describe_partitioner"] = Processor.process_describe_partitioner
    self._processMap["describe_snitch"] = Processor.process_describe_snitch
    self._processMap["describe_keyspace"] = Processor.process_describe_keyspace
    self._processMap["describe_splits"] = Processor.process_describe_splits
    self._processMap["trace_next_query"] = Processor.process_trace_next_query
    self._processMap["describe_splits_ex"] = Processor.process_describe_splits_ex
    self._processMap["system_add_column_family"] = Processor.process_system_add_column_family
    self._processMap["system_drop_column_family"] = Processor.process_system_drop_column_family
    self._processMap["system_add_keyspace"] = Processor.process_system_add_keyspace
    self._processMap["system_drop_keyspace"] = Processor.process_system_drop_keyspace
    self._processMap["system_update_keyspace"] = Processor.process_system_update_keyspace
    self._processMap["system_update_column_family"] = Processor.process_system_update_column_family
    self._processMap["execute_cql_query"] = Processor.process_execute_cql_query
    self._processMap["execute_cql3_query"] = Processor.process_execute_cql3_query
    self._processMap["prepare_cql_query"] = Processor.process_prepare_cql_query
    self._processMap["prepare_cql3_query"] = Processor.process_prepare_cql3_query
    self._processMap["execute_prepared_cql_query"] = Processor.process_execute_prepared_cql_query
    self._processMap["execute_prepared_cql3_query"] = Processor.process_execute_prepared_cql3_query
    self._processMap["set_cql_version"] = Processor.process_set_cql_version

  def process(self, iprot, oprot):
    (name, type, seqid) = iprot.readMessageBegin()
    if name not in self._processMap:
      iprot.skip(TType.STRUCT)
      iprot.readMessageEnd()
      x = TApplicationException(TApplicationException.UNKNOWN_METHOD, 'Unknown function %s' % (name))
      oprot.writeMessageBegin(name, TMessageType.EXCEPTION, seqid)
      x.write(oprot)
      oprot.writeMessageEnd()
      oprot.trans.flush()
      return defer.succeed(None)
    else:
      return self._processMap[name](self, seqid, iprot, oprot)

  def process_login(self, seqid, iprot, oprot):
    args = login_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = login_result()
    d = defer.maybeDeferred(self._handler.login, args.auth_request)
    d.addCallback(self.write_results_success_login, result, seqid, oprot)
    d.addErrback(self.write_results_exception_login, result, seqid, oprot)
    return d

  def write_results_success_login(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("login", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_login(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except AuthenticationException, authnx:
      result.authnx = authnx
    except AuthorizationException, authzx:
      result.authzx = authzx
    oprot.writeMessageBegin("login", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_set_keyspace(self, seqid, iprot, oprot):
    args = set_keyspace_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = set_keyspace_result()
    d = defer.maybeDeferred(self._handler.set_keyspace, args.keyspace)
    d.addCallback(self.write_results_success_set_keyspace, result, seqid, oprot)
    d.addErrback(self.write_results_exception_set_keyspace, result, seqid, oprot)
    return d

  def write_results_success_set_keyspace(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("set_keyspace", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_set_keyspace(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("set_keyspace", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_get(self, seqid, iprot, oprot):
    args = get_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = get_result()
    d = defer.maybeDeferred(self._handler.get, args.key, args.column_path, args.consistency_level)
    d.addCallback(self.write_results_success_get, result, seqid, oprot)
    d.addErrback(self.write_results_exception_get, result, seqid, oprot)
    return d

  def write_results_success_get(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("get", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_get(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except NotFoundException, nfe:
      result.nfe = nfe
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("get", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_get_slice(self, seqid, iprot, oprot):
    args = get_slice_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = get_slice_result()
    d = defer.maybeDeferred(self._handler.get_slice, args.key, args.column_parent, args.predicate, args.consistency_level)
    d.addCallback(self.write_results_success_get_slice, result, seqid, oprot)
    d.addErrback(self.write_results_exception_get_slice, result, seqid, oprot)
    return d

  def write_results_success_get_slice(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("get_slice", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_get_slice(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("get_slice", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_get_count(self, seqid, iprot, oprot):
    args = get_count_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = get_count_result()
    d = defer.maybeDeferred(self._handler.get_count, args.key, args.column_parent, args.predicate, args.consistency_level)
    d.addCallback(self.write_results_success_get_count, result, seqid, oprot)
    d.addErrback(self.write_results_exception_get_count, result, seqid, oprot)
    return d

  def write_results_success_get_count(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("get_count", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_get_count(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("get_count", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_multiget_slice(self, seqid, iprot, oprot):
    args = multiget_slice_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = multiget_slice_result()
    d = defer.maybeDeferred(self._handler.multiget_slice, args.keys, args.column_parent, args.predicate, args.consistency_level)
    d.addCallback(self.write_results_success_multiget_slice, result, seqid, oprot)
    d.addErrback(self.write_results_exception_multiget_slice, result, seqid, oprot)
    return d

  def write_results_success_multiget_slice(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("multiget_slice", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_multiget_slice(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("multiget_slice", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_multiget_count(self, seqid, iprot, oprot):
    args = multiget_count_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = multiget_count_result()
    d = defer.maybeDeferred(self._handler.multiget_count, args.keys, args.column_parent, args.predicate, args.consistency_level)
    d.addCallback(self.write_results_success_multiget_count, result, seqid, oprot)
    d.addErrback(self.write_results_exception_multiget_count, result, seqid, oprot)
    return d

  def write_results_success_multiget_count(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("multiget_count", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_multiget_count(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("multiget_count", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_get_range_slices(self, seqid, iprot, oprot):
    args = get_range_slices_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = get_range_slices_result()
    d = defer.maybeDeferred(self._handler.get_range_slices, args.column_parent, args.predicate, args.range, args.consistency_level)
    d.addCallback(self.write_results_success_get_range_slices, result, seqid, oprot)
    d.addErrback(self.write_results_exception_get_range_slices, result, seqid, oprot)
    return d

  def write_results_success_get_range_slices(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("get_range_slices", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_get_range_slices(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("get_range_slices", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_get_paged_slice(self, seqid, iprot, oprot):
    args = get_paged_slice_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = get_paged_slice_result()
    d = defer.maybeDeferred(self._handler.get_paged_slice, args.column_family, args.range, args.start_column, args.consistency_level)
    d.addCallback(self.write_results_success_get_paged_slice, result, seqid, oprot)
    d.addErrback(self.write_results_exception_get_paged_slice, result, seqid, oprot)
    return d

  def write_results_success_get_paged_slice(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("get_paged_slice", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_get_paged_slice(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("get_paged_slice", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_get_indexed_slices(self, seqid, iprot, oprot):
    args = get_indexed_slices_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = get_indexed_slices_result()
    d = defer.maybeDeferred(self._handler.get_indexed_slices, args.column_parent, args.index_clause, args.column_predicate, args.consistency_level)
    d.addCallback(self.write_results_success_get_indexed_slices, result, seqid, oprot)
    d.addErrback(self.write_results_exception_get_indexed_slices, result, seqid, oprot)
    return d

  def write_results_success_get_indexed_slices(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("get_indexed_slices", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_get_indexed_slices(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("get_indexed_slices", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_insert(self, seqid, iprot, oprot):
    args = insert_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = insert_result()
    d = defer.maybeDeferred(self._handler.insert, args.key, args.column_parent, args.column, args.consistency_level)
    d.addCallback(self.write_results_success_insert, result, seqid, oprot)
    d.addErrback(self.write_results_exception_insert, result, seqid, oprot)
    return d

  def write_results_success_insert(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("insert", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_insert(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("insert", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_add(self, seqid, iprot, oprot):
    args = add_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = add_result()
    d = defer.maybeDeferred(self._handler.add, args.key, args.column_parent, args.column, args.consistency_level)
    d.addCallback(self.write_results_success_add, result, seqid, oprot)
    d.addErrback(self.write_results_exception_add, result, seqid, oprot)
    return d

  def write_results_success_add(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("add", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_add(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("add", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_remove(self, seqid, iprot, oprot):
    args = remove_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = remove_result()
    d = defer.maybeDeferred(self._handler.remove, args.key, args.column_path, args.timestamp, args.consistency_level)
    d.addCallback(self.write_results_success_remove, result, seqid, oprot)
    d.addErrback(self.write_results_exception_remove, result, seqid, oprot)
    return d

  def write_results_success_remove(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("remove", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_remove(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("remove", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_remove_counter(self, seqid, iprot, oprot):
    args = remove_counter_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = remove_counter_result()
    d = defer.maybeDeferred(self._handler.remove_counter, args.key, args.path, args.consistency_level)
    d.addCallback(self.write_results_success_remove_counter, result, seqid, oprot)
    d.addErrback(self.write_results_exception_remove_counter, result, seqid, oprot)
    return d

  def write_results_success_remove_counter(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("remove_counter", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_remove_counter(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("remove_counter", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_batch_mutate(self, seqid, iprot, oprot):
    args = batch_mutate_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = batch_mutate_result()
    d = defer.maybeDeferred(self._handler.batch_mutate, args.mutation_map, args.consistency_level)
    d.addCallback(self.write_results_success_batch_mutate, result, seqid, oprot)
    d.addErrback(self.write_results_exception_batch_mutate, result, seqid, oprot)
    return d

  def write_results_success_batch_mutate(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("batch_mutate", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_batch_mutate(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("batch_mutate", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_atomic_batch_mutate(self, seqid, iprot, oprot):
    args = atomic_batch_mutate_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = atomic_batch_mutate_result()
    d = defer.maybeDeferred(self._handler.atomic_batch_mutate, args.mutation_map, args.consistency_level)
    d.addCallback(self.write_results_success_atomic_batch_mutate, result, seqid, oprot)
    d.addErrback(self.write_results_exception_atomic_batch_mutate, result, seqid, oprot)
    return d

  def write_results_success_atomic_batch_mutate(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("atomic_batch_mutate", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_atomic_batch_mutate(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("atomic_batch_mutate", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_truncate(self, seqid, iprot, oprot):
    args = truncate_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = truncate_result()
    d = defer.maybeDeferred(self._handler.truncate, args.cfname)
    d.addCallback(self.write_results_success_truncate, result, seqid, oprot)
    d.addErrback(self.write_results_exception_truncate, result, seqid, oprot)
    return d

  def write_results_success_truncate(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("truncate", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_truncate(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    oprot.writeMessageBegin("truncate", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_schema_versions(self, seqid, iprot, oprot):
    args = describe_schema_versions_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_schema_versions_result()
    d = defer.maybeDeferred(self._handler.describe_schema_versions, )
    d.addCallback(self.write_results_success_describe_schema_versions, result, seqid, oprot)
    d.addErrback(self.write_results_exception_describe_schema_versions, result, seqid, oprot)
    return d

  def write_results_success_describe_schema_versions(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_schema_versions", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_describe_schema_versions(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("describe_schema_versions", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_keyspaces(self, seqid, iprot, oprot):
    args = describe_keyspaces_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_keyspaces_result()
    d = defer.maybeDeferred(self._handler.describe_keyspaces, )
    d.addCallback(self.write_results_success_describe_keyspaces, result, seqid, oprot)
    d.addErrback(self.write_results_exception_describe_keyspaces, result, seqid, oprot)
    return d

  def write_results_success_describe_keyspaces(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_keyspaces", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_describe_keyspaces(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("describe_keyspaces", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_cluster_name(self, seqid, iprot, oprot):
    args = describe_cluster_name_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_cluster_name_result()
    d = defer.maybeDeferred(self._handler.describe_cluster_name, )
    d.addCallback(self.write_results_success_describe_cluster_name, result, seqid, oprot)
    return d

  def write_results_success_describe_cluster_name(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_cluster_name", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_version(self, seqid, iprot, oprot):
    args = describe_version_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_version_result()
    d = defer.maybeDeferred(self._handler.describe_version, )
    d.addCallback(self.write_results_success_describe_version, result, seqid, oprot)
    return d

  def write_results_success_describe_version(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_version", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_ring(self, seqid, iprot, oprot):
    args = describe_ring_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_ring_result()
    d = defer.maybeDeferred(self._handler.describe_ring, args.keyspace)
    d.addCallback(self.write_results_success_describe_ring, result, seqid, oprot)
    d.addErrback(self.write_results_exception_describe_ring, result, seqid, oprot)
    return d

  def write_results_success_describe_ring(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_ring", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_describe_ring(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("describe_ring", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_token_map(self, seqid, iprot, oprot):
    args = describe_token_map_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_token_map_result()
    d = defer.maybeDeferred(self._handler.describe_token_map, )
    d.addCallback(self.write_results_success_describe_token_map, result, seqid, oprot)
    d.addErrback(self.write_results_exception_describe_token_map, result, seqid, oprot)
    return d

  def write_results_success_describe_token_map(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_token_map", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_describe_token_map(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("describe_token_map", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_partitioner(self, seqid, iprot, oprot):
    args = describe_partitioner_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_partitioner_result()
    d = defer.maybeDeferred(self._handler.describe_partitioner, )
    d.addCallback(self.write_results_success_describe_partitioner, result, seqid, oprot)
    return d

  def write_results_success_describe_partitioner(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_partitioner", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_snitch(self, seqid, iprot, oprot):
    args = describe_snitch_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_snitch_result()
    d = defer.maybeDeferred(self._handler.describe_snitch, )
    d.addCallback(self.write_results_success_describe_snitch, result, seqid, oprot)
    return d

  def write_results_success_describe_snitch(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_snitch", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_keyspace(self, seqid, iprot, oprot):
    args = describe_keyspace_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_keyspace_result()
    d = defer.maybeDeferred(self._handler.describe_keyspace, args.keyspace)
    d.addCallback(self.write_results_success_describe_keyspace, result, seqid, oprot)
    d.addErrback(self.write_results_exception_describe_keyspace, result, seqid, oprot)
    return d

  def write_results_success_describe_keyspace(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_keyspace", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_describe_keyspace(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except NotFoundException, nfe:
      result.nfe = nfe
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("describe_keyspace", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_splits(self, seqid, iprot, oprot):
    args = describe_splits_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_splits_result()
    d = defer.maybeDeferred(self._handler.describe_splits, args.cfName, args.start_token, args.end_token, args.keys_per_split)
    d.addCallback(self.write_results_success_describe_splits, result, seqid, oprot)
    d.addErrback(self.write_results_exception_describe_splits, result, seqid, oprot)
    return d

  def write_results_success_describe_splits(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_splits", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_describe_splits(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("describe_splits", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_trace_next_query(self, seqid, iprot, oprot):
    args = trace_next_query_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = trace_next_query_result()
    d = defer.maybeDeferred(self._handler.trace_next_query, )
    d.addCallback(self.write_results_success_trace_next_query, result, seqid, oprot)
    return d

  def write_results_success_trace_next_query(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("trace_next_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_describe_splits_ex(self, seqid, iprot, oprot):
    args = describe_splits_ex_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = describe_splits_ex_result()
    d = defer.maybeDeferred(self._handler.describe_splits_ex, args.cfName, args.start_token, args.end_token, args.keys_per_split)
    d.addCallback(self.write_results_success_describe_splits_ex, result, seqid, oprot)
    d.addErrback(self.write_results_exception_describe_splits_ex, result, seqid, oprot)
    return d

  def write_results_success_describe_splits_ex(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("describe_splits_ex", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_describe_splits_ex(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("describe_splits_ex", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_system_add_column_family(self, seqid, iprot, oprot):
    args = system_add_column_family_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = system_add_column_family_result()
    d = defer.maybeDeferred(self._handler.system_add_column_family, args.cf_def)
    d.addCallback(self.write_results_success_system_add_column_family, result, seqid, oprot)
    d.addErrback(self.write_results_exception_system_add_column_family, result, seqid, oprot)
    return d

  def write_results_success_system_add_column_family(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("system_add_column_family", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_system_add_column_family(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except SchemaDisagreementException, sde:
      result.sde = sde
    oprot.writeMessageBegin("system_add_column_family", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_system_drop_column_family(self, seqid, iprot, oprot):
    args = system_drop_column_family_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = system_drop_column_family_result()
    d = defer.maybeDeferred(self._handler.system_drop_column_family, args.column_family)
    d.addCallback(self.write_results_success_system_drop_column_family, result, seqid, oprot)
    d.addErrback(self.write_results_exception_system_drop_column_family, result, seqid, oprot)
    return d

  def write_results_success_system_drop_column_family(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("system_drop_column_family", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_system_drop_column_family(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except SchemaDisagreementException, sde:
      result.sde = sde
    oprot.writeMessageBegin("system_drop_column_family", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_system_add_keyspace(self, seqid, iprot, oprot):
    args = system_add_keyspace_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = system_add_keyspace_result()
    d = defer.maybeDeferred(self._handler.system_add_keyspace, args.ks_def)
    d.addCallback(self.write_results_success_system_add_keyspace, result, seqid, oprot)
    d.addErrback(self.write_results_exception_system_add_keyspace, result, seqid, oprot)
    return d

  def write_results_success_system_add_keyspace(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("system_add_keyspace", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_system_add_keyspace(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except SchemaDisagreementException, sde:
      result.sde = sde
    oprot.writeMessageBegin("system_add_keyspace", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_system_drop_keyspace(self, seqid, iprot, oprot):
    args = system_drop_keyspace_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = system_drop_keyspace_result()
    d = defer.maybeDeferred(self._handler.system_drop_keyspace, args.keyspace)
    d.addCallback(self.write_results_success_system_drop_keyspace, result, seqid, oprot)
    d.addErrback(self.write_results_exception_system_drop_keyspace, result, seqid, oprot)
    return d

  def write_results_success_system_drop_keyspace(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("system_drop_keyspace", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_system_drop_keyspace(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except SchemaDisagreementException, sde:
      result.sde = sde
    oprot.writeMessageBegin("system_drop_keyspace", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_system_update_keyspace(self, seqid, iprot, oprot):
    args = system_update_keyspace_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = system_update_keyspace_result()
    d = defer.maybeDeferred(self._handler.system_update_keyspace, args.ks_def)
    d.addCallback(self.write_results_success_system_update_keyspace, result, seqid, oprot)
    d.addErrback(self.write_results_exception_system_update_keyspace, result, seqid, oprot)
    return d

  def write_results_success_system_update_keyspace(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("system_update_keyspace", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_system_update_keyspace(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except SchemaDisagreementException, sde:
      result.sde = sde
    oprot.writeMessageBegin("system_update_keyspace", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_system_update_column_family(self, seqid, iprot, oprot):
    args = system_update_column_family_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = system_update_column_family_result()
    d = defer.maybeDeferred(self._handler.system_update_column_family, args.cf_def)
    d.addCallback(self.write_results_success_system_update_column_family, result, seqid, oprot)
    d.addErrback(self.write_results_exception_system_update_column_family, result, seqid, oprot)
    return d

  def write_results_success_system_update_column_family(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("system_update_column_family", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_system_update_column_family(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except SchemaDisagreementException, sde:
      result.sde = sde
    oprot.writeMessageBegin("system_update_column_family", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_execute_cql_query(self, seqid, iprot, oprot):
    args = execute_cql_query_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = execute_cql_query_result()
    d = defer.maybeDeferred(self._handler.execute_cql_query, args.query, args.compression)
    d.addCallback(self.write_results_success_execute_cql_query, result, seqid, oprot)
    d.addErrback(self.write_results_exception_execute_cql_query, result, seqid, oprot)
    return d

  def write_results_success_execute_cql_query(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("execute_cql_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_execute_cql_query(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    except SchemaDisagreementException, sde:
      result.sde = sde
    oprot.writeMessageBegin("execute_cql_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_execute_cql3_query(self, seqid, iprot, oprot):
    args = execute_cql3_query_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = execute_cql3_query_result()
    d = defer.maybeDeferred(self._handler.execute_cql3_query, args.query, args.compression, args.consistency)
    d.addCallback(self.write_results_success_execute_cql3_query, result, seqid, oprot)
    d.addErrback(self.write_results_exception_execute_cql3_query, result, seqid, oprot)
    return d

  def write_results_success_execute_cql3_query(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("execute_cql3_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_execute_cql3_query(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    except SchemaDisagreementException, sde:
      result.sde = sde
    oprot.writeMessageBegin("execute_cql3_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_prepare_cql_query(self, seqid, iprot, oprot):
    args = prepare_cql_query_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = prepare_cql_query_result()
    d = defer.maybeDeferred(self._handler.prepare_cql_query, args.query, args.compression)
    d.addCallback(self.write_results_success_prepare_cql_query, result, seqid, oprot)
    d.addErrback(self.write_results_exception_prepare_cql_query, result, seqid, oprot)
    return d

  def write_results_success_prepare_cql_query(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("prepare_cql_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_prepare_cql_query(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("prepare_cql_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_prepare_cql3_query(self, seqid, iprot, oprot):
    args = prepare_cql3_query_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = prepare_cql3_query_result()
    d = defer.maybeDeferred(self._handler.prepare_cql3_query, args.query, args.compression)
    d.addCallback(self.write_results_success_prepare_cql3_query, result, seqid, oprot)
    d.addErrback(self.write_results_exception_prepare_cql3_query, result, seqid, oprot)
    return d

  def write_results_success_prepare_cql3_query(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("prepare_cql3_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_prepare_cql3_query(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("prepare_cql3_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_execute_prepared_cql_query(self, seqid, iprot, oprot):
    args = execute_prepared_cql_query_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = execute_prepared_cql_query_result()
    d = defer.maybeDeferred(self._handler.execute_prepared_cql_query, args.itemId, args.values)
    d.addCallback(self.write_results_success_execute_prepared_cql_query, result, seqid, oprot)
    d.addErrback(self.write_results_exception_execute_prepared_cql_query, result, seqid, oprot)
    return d

  def write_results_success_execute_prepared_cql_query(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("execute_prepared_cql_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_execute_prepared_cql_query(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    except SchemaDisagreementException, sde:
      result.sde = sde
    oprot.writeMessageBegin("execute_prepared_cql_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_execute_prepared_cql3_query(self, seqid, iprot, oprot):
    args = execute_prepared_cql3_query_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = execute_prepared_cql3_query_result()
    d = defer.maybeDeferred(self._handler.execute_prepared_cql3_query, args.itemId, args.values, args.consistency)
    d.addCallback(self.write_results_success_execute_prepared_cql3_query, result, seqid, oprot)
    d.addErrback(self.write_results_exception_execute_prepared_cql3_query, result, seqid, oprot)
    return d

  def write_results_success_execute_prepared_cql3_query(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("execute_prepared_cql3_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_execute_prepared_cql3_query(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    except UnavailableException, ue:
      result.ue = ue
    except TimedOutException, te:
      result.te = te
    except SchemaDisagreementException, sde:
      result.sde = sde
    oprot.writeMessageBegin("execute_prepared_cql3_query", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def process_set_cql_version(self, seqid, iprot, oprot):
    args = set_cql_version_args()
    args.read(iprot)
    iprot.readMessageEnd()
    result = set_cql_version_result()
    d = defer.maybeDeferred(self._handler.set_cql_version, args.version)
    d.addCallback(self.write_results_success_set_cql_version, result, seqid, oprot)
    d.addErrback(self.write_results_exception_set_cql_version, result, seqid, oprot)
    return d

  def write_results_success_set_cql_version(self, success, result, seqid, oprot):
    result.success = success
    oprot.writeMessageBegin("set_cql_version", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()

  def write_results_exception_set_cql_version(self, error, result, seqid, oprot):
    try:
      error.raiseException()
    except InvalidRequestException, ire:
      result.ire = ire
    oprot.writeMessageBegin("set_cql_version", TMessageType.REPLY, seqid)
    result.write(oprot)
    oprot.writeMessageEnd()
    oprot.trans.flush()


# HELPER FUNCTIONS AND STRUCTURES

class login_args:
  """
  Attributes:
   - auth_request
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'auth_request', (AuthenticationRequest, AuthenticationRequest.thrift_spec), None, ), # 1
  )

  def __init__(self, auth_request=None,):
    self.auth_request = auth_request

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.auth_request = AuthenticationRequest()
          self.auth_request.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('login_args')
    if self.auth_request is not None:
      oprot.writeFieldBegin('auth_request', TType.STRUCT, 1)
      self.auth_request.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.auth_request is None:
      raise TProtocol.TProtocolException(message='Required field auth_request is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class login_result:
  """
  Attributes:
   - authnx
   - authzx
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'authnx', (AuthenticationException, AuthenticationException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'authzx', (AuthorizationException, AuthorizationException.thrift_spec), None, ), # 2
  )

  def __init__(self, authnx=None, authzx=None,):
    self.authnx = authnx
    self.authzx = authzx

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.authnx = AuthenticationException()
          self.authnx.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.authzx = AuthorizationException()
          self.authzx.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('login_result')
    if self.authnx is not None:
      oprot.writeFieldBegin('authnx', TType.STRUCT, 1)
      self.authnx.write(oprot)
      oprot.writeFieldEnd()
    if self.authzx is not None:
      oprot.writeFieldBegin('authzx', TType.STRUCT, 2)
      self.authzx.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class set_keyspace_args:
  """
  Attributes:
   - keyspace
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'keyspace', None, None, ), # 1
  )

  def __init__(self, keyspace=None,):
    self.keyspace = keyspace

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.keyspace = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('set_keyspace_args')
    if self.keyspace is not None:
      oprot.writeFieldBegin('keyspace', TType.STRING, 1)
      oprot.writeString(self.keyspace)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.keyspace is None:
      raise TProtocol.TProtocolException(message='Required field keyspace is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class set_keyspace_result:
  """
  Attributes:
   - ire
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
  )

  def __init__(self, ire=None,):
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('set_keyspace_result')
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_args:
  """
  Attributes:
   - key
   - column_path
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'key', None, None, ), # 1
    (2, TType.STRUCT, 'column_path', (ColumnPath, ColumnPath.thrift_spec), None, ), # 2
    (3, TType.I32, 'consistency_level', None,     1, ), # 3
  )

  def __init__(self, key=None, column_path=None, consistency_level=thrift_spec[3][4],):
    self.key = key
    self.column_path = column_path
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.column_path = ColumnPath()
          self.column_path.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_args')
    if self.key is not None:
      oprot.writeFieldBegin('key', TType.STRING, 1)
      oprot.writeString(self.key)
      oprot.writeFieldEnd()
    if self.column_path is not None:
      oprot.writeFieldBegin('column_path', TType.STRUCT, 2)
      self.column_path.write(oprot)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 3)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.key is None:
      raise TProtocol.TProtocolException(message='Required field key is unset!')
    if self.column_path is None:
      raise TProtocol.TProtocolException(message='Required field column_path is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_result:
  """
  Attributes:
   - success
   - ire
   - nfe
   - ue
   - te
  """

  thrift_spec = (
    (0, TType.STRUCT, 'success', (ColumnOrSuperColumn, ColumnOrSuperColumn.thrift_spec), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'nfe', (NotFoundException, NotFoundException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 3
    (4, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 4
  )

  def __init__(self, success=None, ire=None, nfe=None, ue=None, te=None,):
    self.success = success
    self.ire = ire
    self.nfe = nfe
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRUCT:
          self.success = ColumnOrSuperColumn()
          self.success.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.nfe = NotFoundException()
          self.nfe.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRUCT, 0)
      self.success.write(oprot)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.nfe is not None:
      oprot.writeFieldBegin('nfe', TType.STRUCT, 2)
      self.nfe.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 3)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 4)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_slice_args:
  """
  Attributes:
   - key
   - column_parent
   - predicate
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'key', None, None, ), # 1
    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
    (4, TType.I32, 'consistency_level', None,     1, ), # 4
  )

  def __init__(self, key=None, column_parent=None, predicate=None, consistency_level=thrift_spec[4][4],):
    self.key = key
    self.column_parent = column_parent
    self.predicate = predicate
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.column_parent = ColumnParent()
          self.column_parent.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.predicate = SlicePredicate()
          self.predicate.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_slice_args')
    if self.key is not None:
      oprot.writeFieldBegin('key', TType.STRING, 1)
      oprot.writeString(self.key)
      oprot.writeFieldEnd()
    if self.column_parent is not None:
      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
      self.column_parent.write(oprot)
      oprot.writeFieldEnd()
    if self.predicate is not None:
      oprot.writeFieldBegin('predicate', TType.STRUCT, 3)
      self.predicate.write(oprot)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.key is None:
      raise TProtocol.TProtocolException(message='Required field key is unset!')
    if self.column_parent is None:
      raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
    if self.predicate is None:
      raise TProtocol.TProtocolException(message='Required field predicate is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_slice_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
  """

  thrift_spec = (
    (0, TType.LIST, 'success', (TType.STRUCT,(ColumnOrSuperColumn, ColumnOrSuperColumn.thrift_spec)), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, success=None, ire=None, ue=None, te=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.LIST:
          self.success = []
          (_etype171, _size168) = iprot.readListBegin()
          for _i172 in xrange(_size168):
            _elem173 = ColumnOrSuperColumn()
            _elem173.read(iprot)
            self.success.append(_elem173)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_slice_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.LIST, 0)
      oprot.writeListBegin(TType.STRUCT, len(self.success))
      for iter174 in self.success:
        iter174.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_count_args:
  """
  Attributes:
   - key
   - column_parent
   - predicate
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'key', None, None, ), # 1
    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
    (4, TType.I32, 'consistency_level', None,     1, ), # 4
  )

  def __init__(self, key=None, column_parent=None, predicate=None, consistency_level=thrift_spec[4][4],):
    self.key = key
    self.column_parent = column_parent
    self.predicate = predicate
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.column_parent = ColumnParent()
          self.column_parent.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.predicate = SlicePredicate()
          self.predicate.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_count_args')
    if self.key is not None:
      oprot.writeFieldBegin('key', TType.STRING, 1)
      oprot.writeString(self.key)
      oprot.writeFieldEnd()
    if self.column_parent is not None:
      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
      self.column_parent.write(oprot)
      oprot.writeFieldEnd()
    if self.predicate is not None:
      oprot.writeFieldBegin('predicate', TType.STRUCT, 3)
      self.predicate.write(oprot)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.key is None:
      raise TProtocol.TProtocolException(message='Required field key is unset!')
    if self.column_parent is None:
      raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
    if self.predicate is None:
      raise TProtocol.TProtocolException(message='Required field predicate is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_count_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
  """

  thrift_spec = (
    (0, TType.I32, 'success', None, None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, success=None, ire=None, ue=None, te=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.I32:
          self.success = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_count_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.I32, 0)
      oprot.writeI32(self.success)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class multiget_slice_args:
  """
  Attributes:
   - keys
   - column_parent
   - predicate
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.LIST, 'keys', (TType.STRING,None), None, ), # 1
    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
    (4, TType.I32, 'consistency_level', None,     1, ), # 4
  )

  def __init__(self, keys=None, column_parent=None, predicate=None, consistency_level=thrift_spec[4][4],):
    self.keys = keys
    self.column_parent = column_parent
    self.predicate = predicate
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.LIST:
          self.keys = []
          (_etype178, _size175) = iprot.readListBegin()
          for _i179 in xrange(_size175):
            _elem180 = iprot.readString();
            self.keys.append(_elem180)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.column_parent = ColumnParent()
          self.column_parent.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.predicate = SlicePredicate()
          self.predicate.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('multiget_slice_args')
    if self.keys is not None:
      oprot.writeFieldBegin('keys', TType.LIST, 1)
      oprot.writeListBegin(TType.STRING, len(self.keys))
      for iter181 in self.keys:
        oprot.writeString(iter181)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.column_parent is not None:
      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
      self.column_parent.write(oprot)
      oprot.writeFieldEnd()
    if self.predicate is not None:
      oprot.writeFieldBegin('predicate', TType.STRUCT, 3)
      self.predicate.write(oprot)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.keys is None:
      raise TProtocol.TProtocolException(message='Required field keys is unset!')
    if self.column_parent is None:
      raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
    if self.predicate is None:
      raise TProtocol.TProtocolException(message='Required field predicate is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class multiget_slice_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
  """

  thrift_spec = (
    (0, TType.MAP, 'success', (TType.STRING,None,TType.LIST,(TType.STRUCT,(ColumnOrSuperColumn, ColumnOrSuperColumn.thrift_spec))), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, success=None, ire=None, ue=None, te=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.MAP:
          self.success = {}
          (_ktype183, _vtype184, _size182 ) = iprot.readMapBegin() 
          for _i186 in xrange(_size182):
            _key187 = iprot.readString();
            _val188 = []
            (_etype192, _size189) = iprot.readListBegin()
            for _i193 in xrange(_size189):
              _elem194 = ColumnOrSuperColumn()
              _elem194.read(iprot)
              _val188.append(_elem194)
            iprot.readListEnd()
            self.success[_key187] = _val188
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('multiget_slice_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.MAP, 0)
      oprot.writeMapBegin(TType.STRING, TType.LIST, len(self.success))
      for kiter195,viter196 in self.success.items():
        oprot.writeString(kiter195)
        oprot.writeListBegin(TType.STRUCT, len(viter196))
        for iter197 in viter196:
          iter197.write(oprot)
        oprot.writeListEnd()
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class multiget_count_args:
  """
  Attributes:
   - keys
   - column_parent
   - predicate
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.LIST, 'keys', (TType.STRING,None), None, ), # 1
    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
    (4, TType.I32, 'consistency_level', None,     1, ), # 4
  )

  def __init__(self, keys=None, column_parent=None, predicate=None, consistency_level=thrift_spec[4][4],):
    self.keys = keys
    self.column_parent = column_parent
    self.predicate = predicate
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.LIST:
          self.keys = []
          (_etype201, _size198) = iprot.readListBegin()
          for _i202 in xrange(_size198):
            _elem203 = iprot.readString();
            self.keys.append(_elem203)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.column_parent = ColumnParent()
          self.column_parent.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.predicate = SlicePredicate()
          self.predicate.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('multiget_count_args')
    if self.keys is not None:
      oprot.writeFieldBegin('keys', TType.LIST, 1)
      oprot.writeListBegin(TType.STRING, len(self.keys))
      for iter204 in self.keys:
        oprot.writeString(iter204)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.column_parent is not None:
      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
      self.column_parent.write(oprot)
      oprot.writeFieldEnd()
    if self.predicate is not None:
      oprot.writeFieldBegin('predicate', TType.STRUCT, 3)
      self.predicate.write(oprot)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.keys is None:
      raise TProtocol.TProtocolException(message='Required field keys is unset!')
    if self.column_parent is None:
      raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
    if self.predicate is None:
      raise TProtocol.TProtocolException(message='Required field predicate is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class multiget_count_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
  """

  thrift_spec = (
    (0, TType.MAP, 'success', (TType.STRING,None,TType.I32,None), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, success=None, ire=None, ue=None, te=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.MAP:
          self.success = {}
          (_ktype206, _vtype207, _size205 ) = iprot.readMapBegin() 
          for _i209 in xrange(_size205):
            _key210 = iprot.readString();
            _val211 = iprot.readI32();
            self.success[_key210] = _val211
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('multiget_count_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.MAP, 0)
      oprot.writeMapBegin(TType.STRING, TType.I32, len(self.success))
      for kiter212,viter213 in self.success.items():
        oprot.writeString(kiter212)
        oprot.writeI32(viter213)
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_range_slices_args:
  """
  Attributes:
   - column_parent
   - predicate
   - range
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'range', (KeyRange, KeyRange.thrift_spec), None, ), # 3
    (4, TType.I32, 'consistency_level', None,     1, ), # 4
  )

  def __init__(self, column_parent=None, predicate=None, range=None, consistency_level=thrift_spec[4][4],):
    self.column_parent = column_parent
    self.predicate = predicate
    self.range = range
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.column_parent = ColumnParent()
          self.column_parent.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.predicate = SlicePredicate()
          self.predicate.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.range = KeyRange()
          self.range.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_range_slices_args')
    if self.column_parent is not None:
      oprot.writeFieldBegin('column_parent', TType.STRUCT, 1)
      self.column_parent.write(oprot)
      oprot.writeFieldEnd()
    if self.predicate is not None:
      oprot.writeFieldBegin('predicate', TType.STRUCT, 2)
      self.predicate.write(oprot)
      oprot.writeFieldEnd()
    if self.range is not None:
      oprot.writeFieldBegin('range', TType.STRUCT, 3)
      self.range.write(oprot)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.column_parent is None:
      raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
    if self.predicate is None:
      raise TProtocol.TProtocolException(message='Required field predicate is unset!')
    if self.range is None:
      raise TProtocol.TProtocolException(message='Required field range is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_range_slices_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
  """

  thrift_spec = (
    (0, TType.LIST, 'success', (TType.STRUCT,(KeySlice, KeySlice.thrift_spec)), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, success=None, ire=None, ue=None, te=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.LIST:
          self.success = []
          (_etype217, _size214) = iprot.readListBegin()
          for _i218 in xrange(_size214):
            _elem219 = KeySlice()
            _elem219.read(iprot)
            self.success.append(_elem219)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_range_slices_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.LIST, 0)
      oprot.writeListBegin(TType.STRUCT, len(self.success))
      for iter220 in self.success:
        iter220.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_paged_slice_args:
  """
  Attributes:
   - column_family
   - range
   - start_column
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'column_family', None, None, ), # 1
    (2, TType.STRUCT, 'range', (KeyRange, KeyRange.thrift_spec), None, ), # 2
    (3, TType.STRING, 'start_column', None, None, ), # 3
    (4, TType.I32, 'consistency_level', None,     1, ), # 4
  )

  def __init__(self, column_family=None, range=None, start_column=None, consistency_level=thrift_spec[4][4],):
    self.column_family = column_family
    self.range = range
    self.start_column = start_column
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.column_family = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.range = KeyRange()
          self.range.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRING:
          self.start_column = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_paged_slice_args')
    if self.column_family is not None:
      oprot.writeFieldBegin('column_family', TType.STRING, 1)
      oprot.writeString(self.column_family)
      oprot.writeFieldEnd()
    if self.range is not None:
      oprot.writeFieldBegin('range', TType.STRUCT, 2)
      self.range.write(oprot)
      oprot.writeFieldEnd()
    if self.start_column is not None:
      oprot.writeFieldBegin('start_column', TType.STRING, 3)
      oprot.writeString(self.start_column)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.column_family is None:
      raise TProtocol.TProtocolException(message='Required field column_family is unset!')
    if self.range is None:
      raise TProtocol.TProtocolException(message='Required field range is unset!')
    if self.start_column is None:
      raise TProtocol.TProtocolException(message='Required field start_column is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_paged_slice_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
  """

  thrift_spec = (
    (0, TType.LIST, 'success', (TType.STRUCT,(KeySlice, KeySlice.thrift_spec)), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, success=None, ire=None, ue=None, te=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.LIST:
          self.success = []
          (_etype224, _size221) = iprot.readListBegin()
          for _i225 in xrange(_size221):
            _elem226 = KeySlice()
            _elem226.read(iprot)
            self.success.append(_elem226)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_paged_slice_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.LIST, 0)
      oprot.writeListBegin(TType.STRUCT, len(self.success))
      for iter227 in self.success:
        iter227.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_indexed_slices_args:
  """
  Attributes:
   - column_parent
   - index_clause
   - column_predicate
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'index_clause', (IndexClause, IndexClause.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'column_predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
    (4, TType.I32, 'consistency_level', None,     1, ), # 4
  )

  def __init__(self, column_parent=None, index_clause=None, column_predicate=None, consistency_level=thrift_spec[4][4],):
    self.column_parent = column_parent
    self.index_clause = index_clause
    self.column_predicate = column_predicate
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.column_parent = ColumnParent()
          self.column_parent.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.index_clause = IndexClause()
          self.index_clause.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.column_predicate = SlicePredicate()
          self.column_predicate.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_indexed_slices_args')
    if self.column_parent is not None:
      oprot.writeFieldBegin('column_parent', TType.STRUCT, 1)
      self.column_parent.write(oprot)
      oprot.writeFieldEnd()
    if self.index_clause is not None:
      oprot.writeFieldBegin('index_clause', TType.STRUCT, 2)
      self.index_clause.write(oprot)
      oprot.writeFieldEnd()
    if self.column_predicate is not None:
      oprot.writeFieldBegin('column_predicate', TType.STRUCT, 3)
      self.column_predicate.write(oprot)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.column_parent is None:
      raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
    if self.index_clause is None:
      raise TProtocol.TProtocolException(message='Required field index_clause is unset!')
    if self.column_predicate is None:
      raise TProtocol.TProtocolException(message='Required field column_predicate is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class get_indexed_slices_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
  """

  thrift_spec = (
    (0, TType.LIST, 'success', (TType.STRUCT,(KeySlice, KeySlice.thrift_spec)), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, success=None, ire=None, ue=None, te=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.LIST:
          self.success = []
          (_etype231, _size228) = iprot.readListBegin()
          for _i232 in xrange(_size228):
            _elem233 = KeySlice()
            _elem233.read(iprot)
            self.success.append(_elem233)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('get_indexed_slices_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.LIST, 0)
      oprot.writeListBegin(TType.STRUCT, len(self.success))
      for iter234 in self.success:
        iter234.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class insert_args:
  """
  Attributes:
   - key
   - column_parent
   - column
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'key', None, None, ), # 1
    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'column', (Column, Column.thrift_spec), None, ), # 3
    (4, TType.I32, 'consistency_level', None,     1, ), # 4
  )

  def __init__(self, key=None, column_parent=None, column=None, consistency_level=thrift_spec[4][4],):
    self.key = key
    self.column_parent = column_parent
    self.column = column
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.column_parent = ColumnParent()
          self.column_parent.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.column = Column()
          self.column.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('insert_args')
    if self.key is not None:
      oprot.writeFieldBegin('key', TType.STRING, 1)
      oprot.writeString(self.key)
      oprot.writeFieldEnd()
    if self.column_parent is not None:
      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
      self.column_parent.write(oprot)
      oprot.writeFieldEnd()
    if self.column is not None:
      oprot.writeFieldBegin('column', TType.STRUCT, 3)
      self.column.write(oprot)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.key is None:
      raise TProtocol.TProtocolException(message='Required field key is unset!')
    if self.column_parent is None:
      raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
    if self.column is None:
      raise TProtocol.TProtocolException(message='Required field column is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class insert_result:
  """
  Attributes:
   - ire
   - ue
   - te
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, ire=None, ue=None, te=None,):
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('insert_result')
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class add_args:
  """
  Attributes:
   - key
   - column_parent
   - column
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'key', None, None, ), # 1
    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'column', (CounterColumn, CounterColumn.thrift_spec), None, ), # 3
    (4, TType.I32, 'consistency_level', None,     1, ), # 4
  )

  def __init__(self, key=None, column_parent=None, column=None, consistency_level=thrift_spec[4][4],):
    self.key = key
    self.column_parent = column_parent
    self.column = column
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.column_parent = ColumnParent()
          self.column_parent.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.column = CounterColumn()
          self.column.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('add_args')
    if self.key is not None:
      oprot.writeFieldBegin('key', TType.STRING, 1)
      oprot.writeString(self.key)
      oprot.writeFieldEnd()
    if self.column_parent is not None:
      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
      self.column_parent.write(oprot)
      oprot.writeFieldEnd()
    if self.column is not None:
      oprot.writeFieldBegin('column', TType.STRUCT, 3)
      self.column.write(oprot)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.key is None:
      raise TProtocol.TProtocolException(message='Required field key is unset!')
    if self.column_parent is None:
      raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
    if self.column is None:
      raise TProtocol.TProtocolException(message='Required field column is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class add_result:
  """
  Attributes:
   - ire
   - ue
   - te
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, ire=None, ue=None, te=None,):
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('add_result')
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class remove_args:
  """
  Attributes:
   - key
   - column_path
   - timestamp
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'key', None, None, ), # 1
    (2, TType.STRUCT, 'column_path', (ColumnPath, ColumnPath.thrift_spec), None, ), # 2
    (3, TType.I64, 'timestamp', None, None, ), # 3
    (4, TType.I32, 'consistency_level', None,     1, ), # 4
  )

  def __init__(self, key=None, column_path=None, timestamp=None, consistency_level=thrift_spec[4][4],):
    self.key = key
    self.column_path = column_path
    self.timestamp = timestamp
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.column_path = ColumnPath()
          self.column_path.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.I64:
          self.timestamp = iprot.readI64();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('remove_args')
    if self.key is not None:
      oprot.writeFieldBegin('key', TType.STRING, 1)
      oprot.writeString(self.key)
      oprot.writeFieldEnd()
    if self.column_path is not None:
      oprot.writeFieldBegin('column_path', TType.STRUCT, 2)
      self.column_path.write(oprot)
      oprot.writeFieldEnd()
    if self.timestamp is not None:
      oprot.writeFieldBegin('timestamp', TType.I64, 3)
      oprot.writeI64(self.timestamp)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.key is None:
      raise TProtocol.TProtocolException(message='Required field key is unset!')
    if self.column_path is None:
      raise TProtocol.TProtocolException(message='Required field column_path is unset!')
    if self.timestamp is None:
      raise TProtocol.TProtocolException(message='Required field timestamp is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class remove_result:
  """
  Attributes:
   - ire
   - ue
   - te
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, ire=None, ue=None, te=None,):
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('remove_result')
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class remove_counter_args:
  """
  Attributes:
   - key
   - path
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'key', None, None, ), # 1
    (2, TType.STRUCT, 'path', (ColumnPath, ColumnPath.thrift_spec), None, ), # 2
    (3, TType.I32, 'consistency_level', None,     1, ), # 3
  )

  def __init__(self, key=None, path=None, consistency_level=thrift_spec[3][4],):
    self.key = key
    self.path = path
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.path = ColumnPath()
          self.path.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('remove_counter_args')
    if self.key is not None:
      oprot.writeFieldBegin('key', TType.STRING, 1)
      oprot.writeString(self.key)
      oprot.writeFieldEnd()
    if self.path is not None:
      oprot.writeFieldBegin('path', TType.STRUCT, 2)
      self.path.write(oprot)
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 3)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.key is None:
      raise TProtocol.TProtocolException(message='Required field key is unset!')
    if self.path is None:
      raise TProtocol.TProtocolException(message='Required field path is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class remove_counter_result:
  """
  Attributes:
   - ire
   - ue
   - te
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, ire=None, ue=None, te=None,):
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('remove_counter_result')
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class batch_mutate_args:
  """
  Attributes:
   - mutation_map
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.MAP, 'mutation_map', (TType.STRING,None,TType.MAP,(TType.STRING,None,TType.LIST,(TType.STRUCT,(Mutation, Mutation.thrift_spec)))), None, ), # 1
    (2, TType.I32, 'consistency_level', None,     1, ), # 2
  )

  def __init__(self, mutation_map=None, consistency_level=thrift_spec[2][4],):
    self.mutation_map = mutation_map
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.MAP:
          self.mutation_map = {}
          (_ktype236, _vtype237, _size235 ) = iprot.readMapBegin() 
          for _i239 in xrange(_size235):
            _key240 = iprot.readString();
            _val241 = {}
            (_ktype243, _vtype244, _size242 ) = iprot.readMapBegin() 
            for _i246 in xrange(_size242):
              _key247 = iprot.readString();
              _val248 = []
              (_etype252, _size249) = iprot.readListBegin()
              for _i253 in xrange(_size249):
                _elem254 = Mutation()
                _elem254.read(iprot)
                _val248.append(_elem254)
              iprot.readListEnd()
              _val241[_key247] = _val248
            iprot.readMapEnd()
            self.mutation_map[_key240] = _val241
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('batch_mutate_args')
    if self.mutation_map is not None:
      oprot.writeFieldBegin('mutation_map', TType.MAP, 1)
      oprot.writeMapBegin(TType.STRING, TType.MAP, len(self.mutation_map))
      for kiter255,viter256 in self.mutation_map.items():
        oprot.writeString(kiter255)
        oprot.writeMapBegin(TType.STRING, TType.LIST, len(viter256))
        for kiter257,viter258 in viter256.items():
          oprot.writeString(kiter257)
          oprot.writeListBegin(TType.STRUCT, len(viter258))
          for iter259 in viter258:
            iter259.write(oprot)
          oprot.writeListEnd()
        oprot.writeMapEnd()
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 2)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.mutation_map is None:
      raise TProtocol.TProtocolException(message='Required field mutation_map is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class batch_mutate_result:
  """
  Attributes:
   - ire
   - ue
   - te
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, ire=None, ue=None, te=None,):
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('batch_mutate_result')
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class atomic_batch_mutate_args:
  """
  Attributes:
   - mutation_map
   - consistency_level
  """

  thrift_spec = (
    None, # 0
    (1, TType.MAP, 'mutation_map', (TType.STRING,None,TType.MAP,(TType.STRING,None,TType.LIST,(TType.STRUCT,(Mutation, Mutation.thrift_spec)))), None, ), # 1
    (2, TType.I32, 'consistency_level', None,     1, ), # 2
  )

  def __init__(self, mutation_map=None, consistency_level=thrift_spec[2][4],):
    self.mutation_map = mutation_map
    self.consistency_level = consistency_level

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.MAP:
          self.mutation_map = {}
          (_ktype261, _vtype262, _size260 ) = iprot.readMapBegin() 
          for _i264 in xrange(_size260):
            _key265 = iprot.readString();
            _val266 = {}
            (_ktype268, _vtype269, _size267 ) = iprot.readMapBegin() 
            for _i271 in xrange(_size267):
              _key272 = iprot.readString();
              _val273 = []
              (_etype277, _size274) = iprot.readListBegin()
              for _i278 in xrange(_size274):
                _elem279 = Mutation()
                _elem279.read(iprot)
                _val273.append(_elem279)
              iprot.readListEnd()
              _val266[_key272] = _val273
            iprot.readMapEnd()
            self.mutation_map[_key265] = _val266
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.I32:
          self.consistency_level = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('atomic_batch_mutate_args')
    if self.mutation_map is not None:
      oprot.writeFieldBegin('mutation_map', TType.MAP, 1)
      oprot.writeMapBegin(TType.STRING, TType.MAP, len(self.mutation_map))
      for kiter280,viter281 in self.mutation_map.items():
        oprot.writeString(kiter280)
        oprot.writeMapBegin(TType.STRING, TType.LIST, len(viter281))
        for kiter282,viter283 in viter281.items():
          oprot.writeString(kiter282)
          oprot.writeListBegin(TType.STRUCT, len(viter283))
          for iter284 in viter283:
            iter284.write(oprot)
          oprot.writeListEnd()
        oprot.writeMapEnd()
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.consistency_level is not None:
      oprot.writeFieldBegin('consistency_level', TType.I32, 2)
      oprot.writeI32(self.consistency_level)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.mutation_map is None:
      raise TProtocol.TProtocolException(message='Required field mutation_map is unset!')
    if self.consistency_level is None:
      raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class atomic_batch_mutate_result:
  """
  Attributes:
   - ire
   - ue
   - te
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, ire=None, ue=None, te=None,):
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('atomic_batch_mutate_result')
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class truncate_args:
  """
  Attributes:
   - cfname
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'cfname', None, None, ), # 1
  )

  def __init__(self, cfname=None,):
    self.cfname = cfname

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.cfname = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('truncate_args')
    if self.cfname is not None:
      oprot.writeFieldBegin('cfname', TType.STRING, 1)
      oprot.writeString(self.cfname)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.cfname is None:
      raise TProtocol.TProtocolException(message='Required field cfname is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class truncate_result:
  """
  Attributes:
   - ire
   - ue
   - te
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
  )

  def __init__(self, ire=None, ue=None, te=None,):
    self.ire = ire
    self.ue = ue
    self.te = te

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('truncate_result')
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_schema_versions_args:

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_schema_versions_args')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_schema_versions_result:
  """
  Attributes:
   - success
   - ire
  """

  thrift_spec = (
    (0, TType.MAP, 'success', (TType.STRING,None,TType.LIST,(TType.STRING,None)), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
  )

  def __init__(self, success=None, ire=None,):
    self.success = success
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.MAP:
          self.success = {}
          (_ktype286, _vtype287, _size285 ) = iprot.readMapBegin() 
          for _i289 in xrange(_size285):
            _key290 = iprot.readString();
            _val291 = []
            (_etype295, _size292) = iprot.readListBegin()
            for _i296 in xrange(_size292):
              _elem297 = iprot.readString();
              _val291.append(_elem297)
            iprot.readListEnd()
            self.success[_key290] = _val291
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_schema_versions_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.MAP, 0)
      oprot.writeMapBegin(TType.STRING, TType.LIST, len(self.success))
      for kiter298,viter299 in self.success.items():
        oprot.writeString(kiter298)
        oprot.writeListBegin(TType.STRING, len(viter299))
        for iter300 in viter299:
          oprot.writeString(iter300)
        oprot.writeListEnd()
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_keyspaces_args:

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_keyspaces_args')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_keyspaces_result:
  """
  Attributes:
   - success
   - ire
  """

  thrift_spec = (
    (0, TType.LIST, 'success', (TType.STRUCT,(KsDef, KsDef.thrift_spec)), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
  )

  def __init__(self, success=None, ire=None,):
    self.success = success
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.LIST:
          self.success = []
          (_etype304, _size301) = iprot.readListBegin()
          for _i305 in xrange(_size301):
            _elem306 = KsDef()
            _elem306.read(iprot)
            self.success.append(_elem306)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_keyspaces_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.LIST, 0)
      oprot.writeListBegin(TType.STRUCT, len(self.success))
      for iter307 in self.success:
        iter307.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_cluster_name_args:

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_cluster_name_args')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_cluster_name_result:
  """
  Attributes:
   - success
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
  )

  def __init__(self, success=None,):
    self.success = success

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_cluster_name_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_version_args:

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_version_args')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_version_result:
  """
  Attributes:
   - success
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
  )

  def __init__(self, success=None,):
    self.success = success

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_version_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_ring_args:
  """
  Attributes:
   - keyspace
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'keyspace', None, None, ), # 1
  )

  def __init__(self, keyspace=None,):
    self.keyspace = keyspace

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.keyspace = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_ring_args')
    if self.keyspace is not None:
      oprot.writeFieldBegin('keyspace', TType.STRING, 1)
      oprot.writeString(self.keyspace)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.keyspace is None:
      raise TProtocol.TProtocolException(message='Required field keyspace is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_ring_result:
  """
  Attributes:
   - success
   - ire
  """

  thrift_spec = (
    (0, TType.LIST, 'success', (TType.STRUCT,(TokenRange, TokenRange.thrift_spec)), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
  )

  def __init__(self, success=None, ire=None,):
    self.success = success
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.LIST:
          self.success = []
          (_etype311, _size308) = iprot.readListBegin()
          for _i312 in xrange(_size308):
            _elem313 = TokenRange()
            _elem313.read(iprot)
            self.success.append(_elem313)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_ring_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.LIST, 0)
      oprot.writeListBegin(TType.STRUCT, len(self.success))
      for iter314 in self.success:
        iter314.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_token_map_args:

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_token_map_args')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_token_map_result:
  """
  Attributes:
   - success
   - ire
  """

  thrift_spec = (
    (0, TType.MAP, 'success', (TType.STRING,None,TType.STRING,None), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
  )

  def __init__(self, success=None, ire=None,):
    self.success = success
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.MAP:
          self.success = {}
          (_ktype316, _vtype317, _size315 ) = iprot.readMapBegin() 
          for _i319 in xrange(_size315):
            _key320 = iprot.readString();
            _val321 = iprot.readString();
            self.success[_key320] = _val321
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_token_map_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.MAP, 0)
      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.success))
      for kiter322,viter323 in self.success.items():
        oprot.writeString(kiter322)
        oprot.writeString(viter323)
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_partitioner_args:

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_partitioner_args')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_partitioner_result:
  """
  Attributes:
   - success
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
  )

  def __init__(self, success=None,):
    self.success = success

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_partitioner_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_snitch_args:

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_snitch_args')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_snitch_result:
  """
  Attributes:
   - success
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
  )

  def __init__(self, success=None,):
    self.success = success

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_snitch_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_keyspace_args:
  """
  Attributes:
   - keyspace
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'keyspace', None, None, ), # 1
  )

  def __init__(self, keyspace=None,):
    self.keyspace = keyspace

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.keyspace = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_keyspace_args')
    if self.keyspace is not None:
      oprot.writeFieldBegin('keyspace', TType.STRING, 1)
      oprot.writeString(self.keyspace)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.keyspace is None:
      raise TProtocol.TProtocolException(message='Required field keyspace is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_keyspace_result:
  """
  Attributes:
   - success
   - nfe
   - ire
  """

  thrift_spec = (
    (0, TType.STRUCT, 'success', (KsDef, KsDef.thrift_spec), None, ), # 0
    (1, TType.STRUCT, 'nfe', (NotFoundException, NotFoundException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 2
  )

  def __init__(self, success=None, nfe=None, ire=None,):
    self.success = success
    self.nfe = nfe
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRUCT:
          self.success = KsDef()
          self.success.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.nfe = NotFoundException()
          self.nfe.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_keyspace_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRUCT, 0)
      self.success.write(oprot)
      oprot.writeFieldEnd()
    if self.nfe is not None:
      oprot.writeFieldBegin('nfe', TType.STRUCT, 1)
      self.nfe.write(oprot)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 2)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_splits_args:
  """
  Attributes:
   - cfName
   - start_token
   - end_token
   - keys_per_split
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'cfName', None, None, ), # 1
    (2, TType.STRING, 'start_token', None, None, ), # 2
    (3, TType.STRING, 'end_token', None, None, ), # 3
    (4, TType.I32, 'keys_per_split', None, None, ), # 4
  )

  def __init__(self, cfName=None, start_token=None, end_token=None, keys_per_split=None,):
    self.cfName = cfName
    self.start_token = start_token
    self.end_token = end_token
    self.keys_per_split = keys_per_split

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.cfName = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.start_token = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRING:
          self.end_token = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.keys_per_split = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_splits_args')
    if self.cfName is not None:
      oprot.writeFieldBegin('cfName', TType.STRING, 1)
      oprot.writeString(self.cfName)
      oprot.writeFieldEnd()
    if self.start_token is not None:
      oprot.writeFieldBegin('start_token', TType.STRING, 2)
      oprot.writeString(self.start_token)
      oprot.writeFieldEnd()
    if self.end_token is not None:
      oprot.writeFieldBegin('end_token', TType.STRING, 3)
      oprot.writeString(self.end_token)
      oprot.writeFieldEnd()
    if self.keys_per_split is not None:
      oprot.writeFieldBegin('keys_per_split', TType.I32, 4)
      oprot.writeI32(self.keys_per_split)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.cfName is None:
      raise TProtocol.TProtocolException(message='Required field cfName is unset!')
    if self.start_token is None:
      raise TProtocol.TProtocolException(message='Required field start_token is unset!')
    if self.end_token is None:
      raise TProtocol.TProtocolException(message='Required field end_token is unset!')
    if self.keys_per_split is None:
      raise TProtocol.TProtocolException(message='Required field keys_per_split is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_splits_result:
  """
  Attributes:
   - success
   - ire
  """

  thrift_spec = (
    (0, TType.LIST, 'success', (TType.STRING,None), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
  )

  def __init__(self, success=None, ire=None,):
    self.success = success
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.LIST:
          self.success = []
          (_etype327, _size324) = iprot.readListBegin()
          for _i328 in xrange(_size324):
            _elem329 = iprot.readString();
            self.success.append(_elem329)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_splits_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.LIST, 0)
      oprot.writeListBegin(TType.STRING, len(self.success))
      for iter330 in self.success:
        oprot.writeString(iter330)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class trace_next_query_args:

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('trace_next_query_args')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class trace_next_query_result:
  """
  Attributes:
   - success
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
  )

  def __init__(self, success=None,):
    self.success = success

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('trace_next_query_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_splits_ex_args:
  """
  Attributes:
   - cfName
   - start_token
   - end_token
   - keys_per_split
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'cfName', None, None, ), # 1
    (2, TType.STRING, 'start_token', None, None, ), # 2
    (3, TType.STRING, 'end_token', None, None, ), # 3
    (4, TType.I32, 'keys_per_split', None, None, ), # 4
  )

  def __init__(self, cfName=None, start_token=None, end_token=None, keys_per_split=None,):
    self.cfName = cfName
    self.start_token = start_token
    self.end_token = end_token
    self.keys_per_split = keys_per_split

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.cfName = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.start_token = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRING:
          self.end_token = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.keys_per_split = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_splits_ex_args')
    if self.cfName is not None:
      oprot.writeFieldBegin('cfName', TType.STRING, 1)
      oprot.writeString(self.cfName)
      oprot.writeFieldEnd()
    if self.start_token is not None:
      oprot.writeFieldBegin('start_token', TType.STRING, 2)
      oprot.writeString(self.start_token)
      oprot.writeFieldEnd()
    if self.end_token is not None:
      oprot.writeFieldBegin('end_token', TType.STRING, 3)
      oprot.writeString(self.end_token)
      oprot.writeFieldEnd()
    if self.keys_per_split is not None:
      oprot.writeFieldBegin('keys_per_split', TType.I32, 4)
      oprot.writeI32(self.keys_per_split)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.cfName is None:
      raise TProtocol.TProtocolException(message='Required field cfName is unset!')
    if self.start_token is None:
      raise TProtocol.TProtocolException(message='Required field start_token is unset!')
    if self.end_token is None:
      raise TProtocol.TProtocolException(message='Required field end_token is unset!')
    if self.keys_per_split is None:
      raise TProtocol.TProtocolException(message='Required field keys_per_split is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class describe_splits_ex_result:
  """
  Attributes:
   - success
   - ire
  """

  thrift_spec = (
    (0, TType.LIST, 'success', (TType.STRUCT,(CfSplit, CfSplit.thrift_spec)), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
  )

  def __init__(self, success=None, ire=None,):
    self.success = success
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.LIST:
          self.success = []
          (_etype334, _size331) = iprot.readListBegin()
          for _i335 in xrange(_size331):
            _elem336 = CfSplit()
            _elem336.read(iprot)
            self.success.append(_elem336)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('describe_splits_ex_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.LIST, 0)
      oprot.writeListBegin(TType.STRUCT, len(self.success))
      for iter337 in self.success:
        iter337.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_add_column_family_args:
  """
  Attributes:
   - cf_def
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'cf_def', (CfDef, CfDef.thrift_spec), None, ), # 1
  )

  def __init__(self, cf_def=None,):
    self.cf_def = cf_def

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.cf_def = CfDef()
          self.cf_def.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_add_column_family_args')
    if self.cf_def is not None:
      oprot.writeFieldBegin('cf_def', TType.STRUCT, 1)
      self.cf_def.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.cf_def is None:
      raise TProtocol.TProtocolException(message='Required field cf_def is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_add_column_family_result:
  """
  Attributes:
   - success
   - ire
   - sde
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
  )

  def __init__(self, success=None, ire=None, sde=None,):
    self.success = success
    self.ire = ire
    self.sde = sde

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.sde = SchemaDisagreementException()
          self.sde.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_add_column_family_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.sde is not None:
      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
      self.sde.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_drop_column_family_args:
  """
  Attributes:
   - column_family
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'column_family', None, None, ), # 1
  )

  def __init__(self, column_family=None,):
    self.column_family = column_family

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.column_family = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_drop_column_family_args')
    if self.column_family is not None:
      oprot.writeFieldBegin('column_family', TType.STRING, 1)
      oprot.writeString(self.column_family)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.column_family is None:
      raise TProtocol.TProtocolException(message='Required field column_family is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_drop_column_family_result:
  """
  Attributes:
   - success
   - ire
   - sde
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
  )

  def __init__(self, success=None, ire=None, sde=None,):
    self.success = success
    self.ire = ire
    self.sde = sde

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.sde = SchemaDisagreementException()
          self.sde.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_drop_column_family_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.sde is not None:
      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
      self.sde.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_add_keyspace_args:
  """
  Attributes:
   - ks_def
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ks_def', (KsDef, KsDef.thrift_spec), None, ), # 1
  )

  def __init__(self, ks_def=None,):
    self.ks_def = ks_def

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ks_def = KsDef()
          self.ks_def.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_add_keyspace_args')
    if self.ks_def is not None:
      oprot.writeFieldBegin('ks_def', TType.STRUCT, 1)
      self.ks_def.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.ks_def is None:
      raise TProtocol.TProtocolException(message='Required field ks_def is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_add_keyspace_result:
  """
  Attributes:
   - success
   - ire
   - sde
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
  )

  def __init__(self, success=None, ire=None, sde=None,):
    self.success = success
    self.ire = ire
    self.sde = sde

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.sde = SchemaDisagreementException()
          self.sde.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_add_keyspace_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.sde is not None:
      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
      self.sde.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_drop_keyspace_args:
  """
  Attributes:
   - keyspace
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'keyspace', None, None, ), # 1
  )

  def __init__(self, keyspace=None,):
    self.keyspace = keyspace

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.keyspace = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_drop_keyspace_args')
    if self.keyspace is not None:
      oprot.writeFieldBegin('keyspace', TType.STRING, 1)
      oprot.writeString(self.keyspace)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.keyspace is None:
      raise TProtocol.TProtocolException(message='Required field keyspace is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_drop_keyspace_result:
  """
  Attributes:
   - success
   - ire
   - sde
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
  )

  def __init__(self, success=None, ire=None, sde=None,):
    self.success = success
    self.ire = ire
    self.sde = sde

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.sde = SchemaDisagreementException()
          self.sde.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_drop_keyspace_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.sde is not None:
      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
      self.sde.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_update_keyspace_args:
  """
  Attributes:
   - ks_def
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ks_def', (KsDef, KsDef.thrift_spec), None, ), # 1
  )

  def __init__(self, ks_def=None,):
    self.ks_def = ks_def

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ks_def = KsDef()
          self.ks_def.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_update_keyspace_args')
    if self.ks_def is not None:
      oprot.writeFieldBegin('ks_def', TType.STRUCT, 1)
      self.ks_def.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.ks_def is None:
      raise TProtocol.TProtocolException(message='Required field ks_def is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_update_keyspace_result:
  """
  Attributes:
   - success
   - ire
   - sde
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
  )

  def __init__(self, success=None, ire=None, sde=None,):
    self.success = success
    self.ire = ire
    self.sde = sde

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.sde = SchemaDisagreementException()
          self.sde.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_update_keyspace_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.sde is not None:
      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
      self.sde.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_update_column_family_args:
  """
  Attributes:
   - cf_def
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'cf_def', (CfDef, CfDef.thrift_spec), None, ), # 1
  )

  def __init__(self, cf_def=None,):
    self.cf_def = cf_def

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.cf_def = CfDef()
          self.cf_def.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_update_column_family_args')
    if self.cf_def is not None:
      oprot.writeFieldBegin('cf_def', TType.STRUCT, 1)
      self.cf_def.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.cf_def is None:
      raise TProtocol.TProtocolException(message='Required field cf_def is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class system_update_column_family_result:
  """
  Attributes:
   - success
   - ire
   - sde
  """

  thrift_spec = (
    (0, TType.STRING, 'success', None, None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
  )

  def __init__(self, success=None, ire=None, sde=None,):
    self.success = success
    self.ire = ire
    self.sde = sde

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRING:
          self.success = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.sde = SchemaDisagreementException()
          self.sde.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('system_update_column_family_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRING, 0)
      oprot.writeString(self.success)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.sde is not None:
      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
      self.sde.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class execute_cql_query_args:
  """
  Attributes:
   - query
   - compression
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'query', None, None, ), # 1
    (2, TType.I32, 'compression', None, None, ), # 2
  )

  def __init__(self, query=None, compression=None,):
    self.query = query
    self.compression = compression

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.query = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.I32:
          self.compression = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('execute_cql_query_args')
    if self.query is not None:
      oprot.writeFieldBegin('query', TType.STRING, 1)
      oprot.writeString(self.query)
      oprot.writeFieldEnd()
    if self.compression is not None:
      oprot.writeFieldBegin('compression', TType.I32, 2)
      oprot.writeI32(self.compression)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.query is None:
      raise TProtocol.TProtocolException(message='Required field query is unset!')
    if self.compression is None:
      raise TProtocol.TProtocolException(message='Required field compression is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class execute_cql_query_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
   - sde
  """

  thrift_spec = (
    (0, TType.STRUCT, 'success', (CqlResult, CqlResult.thrift_spec), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
    (4, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 4
  )

  def __init__(self, success=None, ire=None, ue=None, te=None, sde=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te
    self.sde = sde

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRUCT:
          self.success = CqlResult()
          self.success.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRUCT:
          self.sde = SchemaDisagreementException()
          self.sde.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('execute_cql_query_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRUCT, 0)
      self.success.write(oprot)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    if self.sde is not None:
      oprot.writeFieldBegin('sde', TType.STRUCT, 4)
      self.sde.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class execute_cql3_query_args:
  """
  Attributes:
   - query
   - compression
   - consistency
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'query', None, None, ), # 1
    (2, TType.I32, 'compression', None, None, ), # 2
    (3, TType.I32, 'consistency', None, None, ), # 3
  )

  def __init__(self, query=None, compression=None, consistency=None,):
    self.query = query
    self.compression = compression
    self.consistency = consistency

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.query = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.I32:
          self.compression = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.I32:
          self.consistency = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('execute_cql3_query_args')
    if self.query is not None:
      oprot.writeFieldBegin('query', TType.STRING, 1)
      oprot.writeString(self.query)
      oprot.writeFieldEnd()
    if self.compression is not None:
      oprot.writeFieldBegin('compression', TType.I32, 2)
      oprot.writeI32(self.compression)
      oprot.writeFieldEnd()
    if self.consistency is not None:
      oprot.writeFieldBegin('consistency', TType.I32, 3)
      oprot.writeI32(self.consistency)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.query is None:
      raise TProtocol.TProtocolException(message='Required field query is unset!')
    if self.compression is None:
      raise TProtocol.TProtocolException(message='Required field compression is unset!')
    if self.consistency is None:
      raise TProtocol.TProtocolException(message='Required field consistency is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class execute_cql3_query_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
   - sde
  """

  thrift_spec = (
    (0, TType.STRUCT, 'success', (CqlResult, CqlResult.thrift_spec), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
    (4, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 4
  )

  def __init__(self, success=None, ire=None, ue=None, te=None, sde=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te
    self.sde = sde

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRUCT:
          self.success = CqlResult()
          self.success.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRUCT:
          self.sde = SchemaDisagreementException()
          self.sde.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('execute_cql3_query_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRUCT, 0)
      self.success.write(oprot)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    if self.sde is not None:
      oprot.writeFieldBegin('sde', TType.STRUCT, 4)
      self.sde.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class prepare_cql_query_args:
  """
  Attributes:
   - query
   - compression
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'query', None, None, ), # 1
    (2, TType.I32, 'compression', None, None, ), # 2
  )

  def __init__(self, query=None, compression=None,):
    self.query = query
    self.compression = compression

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.query = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.I32:
          self.compression = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('prepare_cql_query_args')
    if self.query is not None:
      oprot.writeFieldBegin('query', TType.STRING, 1)
      oprot.writeString(self.query)
      oprot.writeFieldEnd()
    if self.compression is not None:
      oprot.writeFieldBegin('compression', TType.I32, 2)
      oprot.writeI32(self.compression)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.query is None:
      raise TProtocol.TProtocolException(message='Required field query is unset!')
    if self.compression is None:
      raise TProtocol.TProtocolException(message='Required field compression is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class prepare_cql_query_result:
  """
  Attributes:
   - success
   - ire
  """

  thrift_spec = (
    (0, TType.STRUCT, 'success', (CqlPreparedResult, CqlPreparedResult.thrift_spec), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
  )

  def __init__(self, success=None, ire=None,):
    self.success = success
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRUCT:
          self.success = CqlPreparedResult()
          self.success.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('prepare_cql_query_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRUCT, 0)
      self.success.write(oprot)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class prepare_cql3_query_args:
  """
  Attributes:
   - query
   - compression
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'query', None, None, ), # 1
    (2, TType.I32, 'compression', None, None, ), # 2
  )

  def __init__(self, query=None, compression=None,):
    self.query = query
    self.compression = compression

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.query = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.I32:
          self.compression = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('prepare_cql3_query_args')
    if self.query is not None:
      oprot.writeFieldBegin('query', TType.STRING, 1)
      oprot.writeString(self.query)
      oprot.writeFieldEnd()
    if self.compression is not None:
      oprot.writeFieldBegin('compression', TType.I32, 2)
      oprot.writeI32(self.compression)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.query is None:
      raise TProtocol.TProtocolException(message='Required field query is unset!')
    if self.compression is None:
      raise TProtocol.TProtocolException(message='Required field compression is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class prepare_cql3_query_result:
  """
  Attributes:
   - success
   - ire
  """

  thrift_spec = (
    (0, TType.STRUCT, 'success', (CqlPreparedResult, CqlPreparedResult.thrift_spec), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
  )

  def __init__(self, success=None, ire=None,):
    self.success = success
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRUCT:
          self.success = CqlPreparedResult()
          self.success.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('prepare_cql3_query_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRUCT, 0)
      self.success.write(oprot)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class execute_prepared_cql_query_args:
  """
  Attributes:
   - itemId
   - values
  """

  thrift_spec = (
    None, # 0
    (1, TType.I32, 'itemId', None, None, ), # 1
    (2, TType.LIST, 'values', (TType.STRING,None), None, ), # 2
  )

  def __init__(self, itemId=None, values=None,):
    self.itemId = itemId
    self.values = values

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.I32:
          self.itemId = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.LIST:
          self.values = []
          (_etype341, _size338) = iprot.readListBegin()
          for _i342 in xrange(_size338):
            _elem343 = iprot.readString();
            self.values.append(_elem343)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('execute_prepared_cql_query_args')
    if self.itemId is not None:
      oprot.writeFieldBegin('itemId', TType.I32, 1)
      oprot.writeI32(self.itemId)
      oprot.writeFieldEnd()
    if self.values is not None:
      oprot.writeFieldBegin('values', TType.LIST, 2)
      oprot.writeListBegin(TType.STRING, len(self.values))
      for iter344 in self.values:
        oprot.writeString(iter344)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.itemId is None:
      raise TProtocol.TProtocolException(message='Required field itemId is unset!')
    if self.values is None:
      raise TProtocol.TProtocolException(message='Required field values is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class execute_prepared_cql_query_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
   - sde
  """

  thrift_spec = (
    (0, TType.STRUCT, 'success', (CqlResult, CqlResult.thrift_spec), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
    (4, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 4
  )

  def __init__(self, success=None, ire=None, ue=None, te=None, sde=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te
    self.sde = sde

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRUCT:
          self.success = CqlResult()
          self.success.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRUCT:
          self.sde = SchemaDisagreementException()
          self.sde.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('execute_prepared_cql_query_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRUCT, 0)
      self.success.write(oprot)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    if self.sde is not None:
      oprot.writeFieldBegin('sde', TType.STRUCT, 4)
      self.sde.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class execute_prepared_cql3_query_args:
  """
  Attributes:
   - itemId
   - values
   - consistency
  """

  thrift_spec = (
    None, # 0
    (1, TType.I32, 'itemId', None, None, ), # 1
    (2, TType.LIST, 'values', (TType.STRING,None), None, ), # 2
    (3, TType.I32, 'consistency', None, None, ), # 3
  )

  def __init__(self, itemId=None, values=None, consistency=None,):
    self.itemId = itemId
    self.values = values
    self.consistency = consistency

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.I32:
          self.itemId = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.LIST:
          self.values = []
          (_etype348, _size345) = iprot.readListBegin()
          for _i349 in xrange(_size345):
            _elem350 = iprot.readString();
            self.values.append(_elem350)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.I32:
          self.consistency = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('execute_prepared_cql3_query_args')
    if self.itemId is not None:
      oprot.writeFieldBegin('itemId', TType.I32, 1)
      oprot.writeI32(self.itemId)
      oprot.writeFieldEnd()
    if self.values is not None:
      oprot.writeFieldBegin('values', TType.LIST, 2)
      oprot.writeListBegin(TType.STRING, len(self.values))
      for iter351 in self.values:
        oprot.writeString(iter351)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.consistency is not None:
      oprot.writeFieldBegin('consistency', TType.I32, 3)
      oprot.writeI32(self.consistency)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.itemId is None:
      raise TProtocol.TProtocolException(message='Required field itemId is unset!')
    if self.values is None:
      raise TProtocol.TProtocolException(message='Required field values is unset!')
    if self.consistency is None:
      raise TProtocol.TProtocolException(message='Required field consistency is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class execute_prepared_cql3_query_result:
  """
  Attributes:
   - success
   - ire
   - ue
   - te
   - sde
  """

  thrift_spec = (
    (0, TType.STRUCT, 'success', (CqlResult, CqlResult.thrift_spec), None, ), # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
    (4, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 4
  )

  def __init__(self, success=None, ire=None, ue=None, te=None, sde=None,):
    self.success = success
    self.ire = ire
    self.ue = ue
    self.te = te
    self.sde = sde

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 0:
        if ftype == TType.STRUCT:
          self.success = CqlResult()
          self.success.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.ue = UnavailableException()
          self.ue.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.te = TimedOutException()
          self.te.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRUCT:
          self.sde = SchemaDisagreementException()
          self.sde.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('execute_prepared_cql3_query_result')
    if self.success is not None:
      oprot.writeFieldBegin('success', TType.STRUCT, 0)
      self.success.write(oprot)
      oprot.writeFieldEnd()
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    if self.ue is not None:
      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
      self.ue.write(oprot)
      oprot.writeFieldEnd()
    if self.te is not None:
      oprot.writeFieldBegin('te', TType.STRUCT, 3)
      self.te.write(oprot)
      oprot.writeFieldEnd()
    if self.sde is not None:
      oprot.writeFieldBegin('sde', TType.STRUCT, 4)
      self.sde.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class set_cql_version_args:
  """
  Attributes:
   - version
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'version', None, None, ), # 1
  )

  def __init__(self, version=None,):
    self.version = version

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.version = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('set_cql_version_args')
    if self.version is not None:
      oprot.writeFieldBegin('version', TType.STRING, 1)
      oprot.writeString(self.version)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.version is None:
      raise TProtocol.TProtocolException(message='Required field version is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class set_cql_version_result:
  """
  Attributes:
   - ire
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
  )

  def __init__(self, ire=None,):
    self.ire = ire

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.ire = InvalidRequestException()
          self.ire.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('set_cql_version_result')
    if self.ire is not None:
      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
      self.ire.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

########NEW FILE########
__FILENAME__ = constants
#
# Autogenerated by Thrift Compiler (0.7.0)
#
# DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
#

from thrift.Thrift import *
from ttypes import *

VERSION = "19.35.0"

########NEW FILE########
__FILENAME__ = ttypes
#
# Autogenerated by Thrift Compiler (0.7.0)
#
# DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
#

from thrift.Thrift import *

from thrift.transport import TTransport
from thrift.protocol import TBinaryProtocol, TProtocol
try:
  from thrift.protocol import fastbinary
except:
  fastbinary = None


class ConsistencyLevel:
  """
  The ConsistencyLevel is an enum that controls both read and write
  behavior based on the ReplicationFactor of the keyspace.  The
  different consistency levels have different meanings, depending on
  if you're doing a write or read operation.

  If W + R > ReplicationFactor, where W is the number of nodes to
  block for on write, and R the number to block for on reads, you
  will have strongly consistent behavior; that is, readers will
  always see the most recent write. Of these, the most interesting is
  to do QUORUM reads and writes, which gives you consistency while
  still allowing availability in the face of node failures up to half
  of <ReplicationFactor>. Of course if latency is more important than
  consistency then you can use lower values for either or both.

  Some ConsistencyLevels (ONE, TWO, THREE) refer to a specific number
  of replicas rather than a logical concept that adjusts
  automatically with the replication factor.  Of these, only ONE is
  commonly used; TWO and (even more rarely) THREE are only useful
  when you care more about guaranteeing a certain level of
  durability, than consistency.

  Write consistency levels make the following guarantees before reporting success to the client:
    ANY          Ensure that the write has been written once somewhere, including possibly being hinted in a non-target node.
    ONE          Ensure that the write has been written to at least 1 node's commit log and memory table
    TWO          Ensure that the write has been written to at least 2 node's commit log and memory table
    THREE        Ensure that the write has been written to at least 3 node's commit log and memory table
    QUORUM       Ensure that the write has been written to <ReplicationFactor> / 2 + 1 nodes
    LOCAL_QUORUM Ensure that the write has been written to <ReplicationFactor> / 2 + 1 nodes, within the local datacenter (requires NetworkTopologyStrategy)
    EACH_QUORUM  Ensure that the write has been written to <ReplicationFactor> / 2 + 1 nodes in each datacenter (requires NetworkTopologyStrategy)
    ALL          Ensure that the write is written to <code>&lt;ReplicationFactor&gt;</code> nodes before responding to the client.

  Read consistency levels make the following guarantees before returning successful results to the client:
    ANY          Not supported. You probably want ONE instead.
    ONE          Returns the record obtained from a single replica.
    TWO          Returns the record with the most recent timestamp once two replicas have replied.
    THREE        Returns the record with the most recent timestamp once three replicas have replied.
    QUORUM       Returns the record with the most recent timestamp once a majority of replicas have replied.
    LOCAL_QUORUM Returns the record with the most recent timestamp once a majority of replicas within the local datacenter have replied.
    EACH_QUORUM  Returns the record with the most recent timestamp once a majority of replicas within each datacenter have replied.
    ALL          Returns the record with the most recent timestamp once all replicas have replied (implies no replica may be down)..
  """
  ONE = 1
  QUORUM = 2
  LOCAL_QUORUM = 3
  EACH_QUORUM = 4
  ALL = 5
  ANY = 6
  TWO = 7
  THREE = 8

  _VALUES_TO_NAMES = {
    1: "ONE",
    2: "QUORUM",
    3: "LOCAL_QUORUM",
    4: "EACH_QUORUM",
    5: "ALL",
    6: "ANY",
    7: "TWO",
    8: "THREE",
  }

  _NAMES_TO_VALUES = {
    "ONE": 1,
    "QUORUM": 2,
    "LOCAL_QUORUM": 3,
    "EACH_QUORUM": 4,
    "ALL": 5,
    "ANY": 6,
    "TWO": 7,
    "THREE": 8,
  }

class IndexOperator:
  EQ = 0
  GTE = 1
  GT = 2
  LTE = 3
  LT = 4

  _VALUES_TO_NAMES = {
    0: "EQ",
    1: "GTE",
    2: "GT",
    3: "LTE",
    4: "LT",
  }

  _NAMES_TO_VALUES = {
    "EQ": 0,
    "GTE": 1,
    "GT": 2,
    "LTE": 3,
    "LT": 4,
  }

class IndexType:
  KEYS = 0
  CUSTOM = 1
  COMPOSITES = 2

  _VALUES_TO_NAMES = {
    0: "KEYS",
    1: "CUSTOM",
    2: "COMPOSITES",
  }

  _NAMES_TO_VALUES = {
    "KEYS": 0,
    "CUSTOM": 1,
    "COMPOSITES": 2,
  }

class Compression:
  """
  CQL query compression
  """
  GZIP = 1
  NONE = 2

  _VALUES_TO_NAMES = {
    1: "GZIP",
    2: "NONE",
  }

  _NAMES_TO_VALUES = {
    "GZIP": 1,
    "NONE": 2,
  }

class CqlResultType:
  ROWS = 1
  VOID = 2
  INT = 3

  _VALUES_TO_NAMES = {
    1: "ROWS",
    2: "VOID",
    3: "INT",
  }

  _NAMES_TO_VALUES = {
    "ROWS": 1,
    "VOID": 2,
    "INT": 3,
  }


class Column:
  """
  Basic unit of data within a ColumnFamily.
  @param name, the name by which this column is set and retrieved.  Maximum 64KB long.
  @param value. The data associated with the name.  Maximum 2GB long, but in practice you should limit it to small numbers of MB (since Thrift must read the full value into memory to operate on it).
  @param timestamp. The timestamp is used for conflict detection/resolution when two columns with same name need to be compared.
  @param ttl. An optional, positive delay (in seconds) after which the column will be automatically deleted.

  Attributes:
   - name
   - value
   - timestamp
   - ttl
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'name', None, None, ), # 1
    (2, TType.STRING, 'value', None, None, ), # 2
    (3, TType.I64, 'timestamp', None, None, ), # 3
    (4, TType.I32, 'ttl', None, None, ), # 4
  )

  def __init__(self, name=None, value=None, timestamp=None, ttl=None,):
    self.name = name
    self.value = value
    self.timestamp = timestamp
    self.ttl = ttl

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.name = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.value = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.I64:
          self.timestamp = iprot.readI64();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.ttl = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('Column')
    if self.name is not None:
      oprot.writeFieldBegin('name', TType.STRING, 1)
      oprot.writeString(self.name)
      oprot.writeFieldEnd()
    if self.value is not None:
      oprot.writeFieldBegin('value', TType.STRING, 2)
      oprot.writeString(self.value)
      oprot.writeFieldEnd()
    if self.timestamp is not None:
      oprot.writeFieldBegin('timestamp', TType.I64, 3)
      oprot.writeI64(self.timestamp)
      oprot.writeFieldEnd()
    if self.ttl is not None:
      oprot.writeFieldBegin('ttl', TType.I32, 4)
      oprot.writeI32(self.ttl)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.name is None:
      raise TProtocol.TProtocolException(message='Required field name is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class SuperColumn:
  """
  A named list of columns.
  @param name. see Column.name.
  @param columns. A collection of standard Columns.  The columns within a super column are defined in an adhoc manner.
                  Columns within a super column do not have to have matching structures (similarly named child columns).

  Attributes:
   - name
   - columns
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'name', None, None, ), # 1
    (2, TType.LIST, 'columns', (TType.STRUCT,(Column, Column.thrift_spec)), None, ), # 2
  )

  def __init__(self, name=None, columns=None,):
    self.name = name
    self.columns = columns

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.name = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.LIST:
          self.columns = []
          (_etype3, _size0) = iprot.readListBegin()
          for _i4 in xrange(_size0):
            _elem5 = Column()
            _elem5.read(iprot)
            self.columns.append(_elem5)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('SuperColumn')
    if self.name is not None:
      oprot.writeFieldBegin('name', TType.STRING, 1)
      oprot.writeString(self.name)
      oprot.writeFieldEnd()
    if self.columns is not None:
      oprot.writeFieldBegin('columns', TType.LIST, 2)
      oprot.writeListBegin(TType.STRUCT, len(self.columns))
      for iter6 in self.columns:
        iter6.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.name is None:
      raise TProtocol.TProtocolException(message='Required field name is unset!')
    if self.columns is None:
      raise TProtocol.TProtocolException(message='Required field columns is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class CounterColumn:
  """
  Attributes:
   - name
   - value
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'name', None, None, ), # 1
    (2, TType.I64, 'value', None, None, ), # 2
  )

  def __init__(self, name=None, value=None,):
    self.name = name
    self.value = value

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.name = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.I64:
          self.value = iprot.readI64();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('CounterColumn')
    if self.name is not None:
      oprot.writeFieldBegin('name', TType.STRING, 1)
      oprot.writeString(self.name)
      oprot.writeFieldEnd()
    if self.value is not None:
      oprot.writeFieldBegin('value', TType.I64, 2)
      oprot.writeI64(self.value)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.name is None:
      raise TProtocol.TProtocolException(message='Required field name is unset!')
    if self.value is None:
      raise TProtocol.TProtocolException(message='Required field value is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class CounterSuperColumn:
  """
  Attributes:
   - name
   - columns
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'name', None, None, ), # 1
    (2, TType.LIST, 'columns', (TType.STRUCT,(CounterColumn, CounterColumn.thrift_spec)), None, ), # 2
  )

  def __init__(self, name=None, columns=None,):
    self.name = name
    self.columns = columns

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.name = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.LIST:
          self.columns = []
          (_etype10, _size7) = iprot.readListBegin()
          for _i11 in xrange(_size7):
            _elem12 = CounterColumn()
            _elem12.read(iprot)
            self.columns.append(_elem12)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('CounterSuperColumn')
    if self.name is not None:
      oprot.writeFieldBegin('name', TType.STRING, 1)
      oprot.writeString(self.name)
      oprot.writeFieldEnd()
    if self.columns is not None:
      oprot.writeFieldBegin('columns', TType.LIST, 2)
      oprot.writeListBegin(TType.STRUCT, len(self.columns))
      for iter13 in self.columns:
        iter13.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.name is None:
      raise TProtocol.TProtocolException(message='Required field name is unset!')
    if self.columns is None:
      raise TProtocol.TProtocolException(message='Required field columns is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class ColumnOrSuperColumn:
  """
  Methods for fetching rows/records from Cassandra will return either a single instance of ColumnOrSuperColumn or a list
  of ColumnOrSuperColumns (get_slice()). If you're looking up a SuperColumn (or list of SuperColumns) then the resulting
  instances of ColumnOrSuperColumn will have the requested SuperColumn in the attribute super_column. For queries resulting
  in Columns, those values will be in the attribute column. This change was made between 0.3 and 0.4 to standardize on
  single query methods that may return either a SuperColumn or Column.

  If the query was on a counter column family, you will either get a counter_column (instead of a column) or a
  counter_super_column (instead of a super_column)

  @param column. The Column returned by get() or get_slice().
  @param super_column. The SuperColumn returned by get() or get_slice().
  @param counter_column. The Counterolumn returned by get() or get_slice().
  @param counter_super_column. The CounterSuperColumn returned by get() or get_slice().

  Attributes:
   - column
   - super_column
   - counter_column
   - counter_super_column
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'column', (Column, Column.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'super_column', (SuperColumn, SuperColumn.thrift_spec), None, ), # 2
    (3, TType.STRUCT, 'counter_column', (CounterColumn, CounterColumn.thrift_spec), None, ), # 3
    (4, TType.STRUCT, 'counter_super_column', (CounterSuperColumn, CounterSuperColumn.thrift_spec), None, ), # 4
  )

  def __init__(self, column=None, super_column=None, counter_column=None, counter_super_column=None,):
    self.column = column
    self.super_column = super_column
    self.counter_column = counter_column
    self.counter_super_column = counter_super_column

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.column = Column()
          self.column.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.super_column = SuperColumn()
          self.super_column.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.counter_column = CounterColumn()
          self.counter_column.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRUCT:
          self.counter_super_column = CounterSuperColumn()
          self.counter_super_column.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('ColumnOrSuperColumn')
    if self.column is not None:
      oprot.writeFieldBegin('column', TType.STRUCT, 1)
      self.column.write(oprot)
      oprot.writeFieldEnd()
    if self.super_column is not None:
      oprot.writeFieldBegin('super_column', TType.STRUCT, 2)
      self.super_column.write(oprot)
      oprot.writeFieldEnd()
    if self.counter_column is not None:
      oprot.writeFieldBegin('counter_column', TType.STRUCT, 3)
      self.counter_column.write(oprot)
      oprot.writeFieldEnd()
    if self.counter_super_column is not None:
      oprot.writeFieldBegin('counter_super_column', TType.STRUCT, 4)
      self.counter_super_column.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class NotFoundException(Exception):
  """
  A specific column was requested that does not exist.
  """

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('NotFoundException')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __str__(self):
    return repr(self)

  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class InvalidRequestException(Exception):
  """
  Invalid request could mean keyspace or column family does not exist, required parameters are missing, or a parameter is malformed.
  why contains an associated error message.

  Attributes:
   - why
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'why', None, None, ), # 1
  )

  def __init__(self, why=None,):
    self.why = why

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.why = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('InvalidRequestException')
    if self.why is not None:
      oprot.writeFieldBegin('why', TType.STRING, 1)
      oprot.writeString(self.why)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.why is None:
      raise TProtocol.TProtocolException(message='Required field why is unset!')
    return


  def __str__(self):
    return repr(self)

  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class UnavailableException(Exception):
  """
  Not all the replicas required could be created and/or read.
  """

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('UnavailableException')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __str__(self):
    return repr(self)

  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class TimedOutException(Exception):
  """
  RPC timeout was exceeded.  either a node failed mid-operation, or load was too high, or the requested op was too large.

  Attributes:
   - acknowledged_by: if a write operation was acknowledged by some replicas but not by enough to
  satisfy the required ConsistencyLevel, the number of successful
  replies will be given here. In case of atomic_batch_mutate method this field
  will be set to -1 if the batch was written to the batchlog and to 0 if it wasn't.
   - acknowledged_by_batchlog: in case of atomic_batch_mutate method this field tells if the batch was written to the batchlog.
  """

  thrift_spec = (
    None, # 0
    (1, TType.I32, 'acknowledged_by', None, None, ), # 1
    (2, TType.BOOL, 'acknowledged_by_batchlog', None, None, ), # 2
  )

  def __init__(self, acknowledged_by=None, acknowledged_by_batchlog=None,):
    self.acknowledged_by = acknowledged_by
    self.acknowledged_by_batchlog = acknowledged_by_batchlog

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.I32:
          self.acknowledged_by = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.BOOL:
          self.acknowledged_by_batchlog = iprot.readBool();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('TimedOutException')
    if self.acknowledged_by is not None:
      oprot.writeFieldBegin('acknowledged_by', TType.I32, 1)
      oprot.writeI32(self.acknowledged_by)
      oprot.writeFieldEnd()
    if self.acknowledged_by_batchlog is not None:
      oprot.writeFieldBegin('acknowledged_by_batchlog', TType.BOOL, 2)
      oprot.writeBool(self.acknowledged_by_batchlog)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __str__(self):
    return repr(self)

  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class AuthenticationException(Exception):
  """
  invalid authentication request (invalid keyspace, user does not exist, or credentials invalid)

  Attributes:
   - why
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'why', None, None, ), # 1
  )

  def __init__(self, why=None,):
    self.why = why

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.why = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('AuthenticationException')
    if self.why is not None:
      oprot.writeFieldBegin('why', TType.STRING, 1)
      oprot.writeString(self.why)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.why is None:
      raise TProtocol.TProtocolException(message='Required field why is unset!')
    return


  def __str__(self):
    return repr(self)

  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class AuthorizationException(Exception):
  """
  invalid authorization request (user does not have access to keyspace)

  Attributes:
   - why
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'why', None, None, ), # 1
  )

  def __init__(self, why=None,):
    self.why = why

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.why = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('AuthorizationException')
    if self.why is not None:
      oprot.writeFieldBegin('why', TType.STRING, 1)
      oprot.writeString(self.why)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.why is None:
      raise TProtocol.TProtocolException(message='Required field why is unset!')
    return


  def __str__(self):
    return repr(self)

  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class SchemaDisagreementException(Exception):
  """
  NOTE: This up outdated exception left for backward compatibility reasons,
  no actual schema agreement validation is done starting from Cassandra 1.2

  schemas are not in agreement across all nodes
  """

  thrift_spec = (
  )

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('SchemaDisagreementException')
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __str__(self):
    return repr(self)

  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class ColumnParent:
  """
  ColumnParent is used when selecting groups of columns from the same ColumnFamily. In directory structure terms, imagine
  ColumnParent as ColumnPath + '/../'.

  See also <a href="cassandra.html#Struct_ColumnPath">ColumnPath</a>

  Attributes:
   - column_family
   - super_column
  """

  thrift_spec = (
    None, # 0
    None, # 1
    None, # 2
    (3, TType.STRING, 'column_family', None, None, ), # 3
    (4, TType.STRING, 'super_column', None, None, ), # 4
  )

  def __init__(self, column_family=None, super_column=None,):
    self.column_family = column_family
    self.super_column = super_column

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 3:
        if ftype == TType.STRING:
          self.column_family = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRING:
          self.super_column = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('ColumnParent')
    if self.column_family is not None:
      oprot.writeFieldBegin('column_family', TType.STRING, 3)
      oprot.writeString(self.column_family)
      oprot.writeFieldEnd()
    if self.super_column is not None:
      oprot.writeFieldBegin('super_column', TType.STRING, 4)
      oprot.writeString(self.super_column)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.column_family is None:
      raise TProtocol.TProtocolException(message='Required field column_family is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class ColumnPath:
  """
  The ColumnPath is the path to a single column in Cassandra. It might make sense to think of ColumnPath and
  ColumnParent in terms of a directory structure.

  ColumnPath is used to looking up a single column.

  @param column_family. The name of the CF of the column being looked up.
  @param super_column. The super column name.
  @param column. The column name.

  Attributes:
   - column_family
   - super_column
   - column
  """

  thrift_spec = (
    None, # 0
    None, # 1
    None, # 2
    (3, TType.STRING, 'column_family', None, None, ), # 3
    (4, TType.STRING, 'super_column', None, None, ), # 4
    (5, TType.STRING, 'column', None, None, ), # 5
  )

  def __init__(self, column_family=None, super_column=None, column=None,):
    self.column_family = column_family
    self.super_column = super_column
    self.column = column

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 3:
        if ftype == TType.STRING:
          self.column_family = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRING:
          self.super_column = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 5:
        if ftype == TType.STRING:
          self.column = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('ColumnPath')
    if self.column_family is not None:
      oprot.writeFieldBegin('column_family', TType.STRING, 3)
      oprot.writeString(self.column_family)
      oprot.writeFieldEnd()
    if self.super_column is not None:
      oprot.writeFieldBegin('super_column', TType.STRING, 4)
      oprot.writeString(self.super_column)
      oprot.writeFieldEnd()
    if self.column is not None:
      oprot.writeFieldBegin('column', TType.STRING, 5)
      oprot.writeString(self.column)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.column_family is None:
      raise TProtocol.TProtocolException(message='Required field column_family is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class SliceRange:
  """
  A slice range is a structure that stores basic range, ordering and limit information for a query that will return
  multiple columns. It could be thought of as Cassandra's version of LIMIT and ORDER BY

  @param start. The column name to start the slice with. This attribute is not required, though there is no default value,
                and can be safely set to '', i.e., an empty byte array, to start with the first column name. Otherwise, it
                must a valid value under the rules of the Comparator defined for the given ColumnFamily.
  @param finish. The column name to stop the slice at. This attribute is not required, though there is no default value,
                 and can be safely set to an empty byte array to not stop until 'count' results are seen. Otherwise, it
                 must also be a valid value to the ColumnFamily Comparator.
  @param reversed. Whether the results should be ordered in reversed order. Similar to ORDER BY blah DESC in SQL.
  @param count. How many columns to return. Similar to LIMIT in SQL. May be arbitrarily large, but Thrift will
                materialize the whole result into memory before returning it to the client, so be aware that you may
                be better served by iterating through slices by passing the last value of one call in as the 'start'
                of the next instead of increasing 'count' arbitrarily large.

  Attributes:
   - start
   - finish
   - reversed
   - count
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'start', None, None, ), # 1
    (2, TType.STRING, 'finish', None, None, ), # 2
    (3, TType.BOOL, 'reversed', None, False, ), # 3
    (4, TType.I32, 'count', None, 100, ), # 4
  )

  def __init__(self, start=None, finish=None, reversed=thrift_spec[3][4], count=thrift_spec[4][4],):
    self.start = start
    self.finish = finish
    self.reversed = reversed
    self.count = count

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.start = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.finish = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.BOOL:
          self.reversed = iprot.readBool();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.count = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('SliceRange')
    if self.start is not None:
      oprot.writeFieldBegin('start', TType.STRING, 1)
      oprot.writeString(self.start)
      oprot.writeFieldEnd()
    if self.finish is not None:
      oprot.writeFieldBegin('finish', TType.STRING, 2)
      oprot.writeString(self.finish)
      oprot.writeFieldEnd()
    if self.reversed is not None:
      oprot.writeFieldBegin('reversed', TType.BOOL, 3)
      oprot.writeBool(self.reversed)
      oprot.writeFieldEnd()
    if self.count is not None:
      oprot.writeFieldBegin('count', TType.I32, 4)
      oprot.writeI32(self.count)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.start is None:
      raise TProtocol.TProtocolException(message='Required field start is unset!')
    if self.finish is None:
      raise TProtocol.TProtocolException(message='Required field finish is unset!')
    if self.reversed is None:
      raise TProtocol.TProtocolException(message='Required field reversed is unset!')
    if self.count is None:
      raise TProtocol.TProtocolException(message='Required field count is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class SlicePredicate:
  """
  A SlicePredicate is similar to a mathematic predicate (see http://en.wikipedia.org/wiki/Predicate_(mathematical_logic)),
  which is described as "a property that the elements of a set have in common."

  SlicePredicate's in Cassandra are described with either a list of column_names or a SliceRange.  If column_names is
  specified, slice_range is ignored.

  @param column_name. A list of column names to retrieve. This can be used similar to Memcached's "multi-get" feature
                      to fetch N known column names. For instance, if you know you wish to fetch columns 'Joe', 'Jack',
                      and 'Jim' you can pass those column names as a list to fetch all three at once.
  @param slice_range. A SliceRange describing how to range, order, and/or limit the slice.

  Attributes:
   - column_names
   - slice_range
  """

  thrift_spec = (
    None, # 0
    (1, TType.LIST, 'column_names', (TType.STRING,None), None, ), # 1
    (2, TType.STRUCT, 'slice_range', (SliceRange, SliceRange.thrift_spec), None, ), # 2
  )

  def __init__(self, column_names=None, slice_range=None,):
    self.column_names = column_names
    self.slice_range = slice_range

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.LIST:
          self.column_names = []
          (_etype17, _size14) = iprot.readListBegin()
          for _i18 in xrange(_size14):
            _elem19 = iprot.readString();
            self.column_names.append(_elem19)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.slice_range = SliceRange()
          self.slice_range.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('SlicePredicate')
    if self.column_names is not None:
      oprot.writeFieldBegin('column_names', TType.LIST, 1)
      oprot.writeListBegin(TType.STRING, len(self.column_names))
      for iter20 in self.column_names:
        oprot.writeString(iter20)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.slice_range is not None:
      oprot.writeFieldBegin('slice_range', TType.STRUCT, 2)
      self.slice_range.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class IndexExpression:
  """
  Attributes:
   - column_name
   - op
   - value
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'column_name', None, None, ), # 1
    (2, TType.I32, 'op', None, None, ), # 2
    (3, TType.STRING, 'value', None, None, ), # 3
  )

  def __init__(self, column_name=None, op=None, value=None,):
    self.column_name = column_name
    self.op = op
    self.value = value

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.column_name = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.I32:
          self.op = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRING:
          self.value = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('IndexExpression')
    if self.column_name is not None:
      oprot.writeFieldBegin('column_name', TType.STRING, 1)
      oprot.writeString(self.column_name)
      oprot.writeFieldEnd()
    if self.op is not None:
      oprot.writeFieldBegin('op', TType.I32, 2)
      oprot.writeI32(self.op)
      oprot.writeFieldEnd()
    if self.value is not None:
      oprot.writeFieldBegin('value', TType.STRING, 3)
      oprot.writeString(self.value)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.column_name is None:
      raise TProtocol.TProtocolException(message='Required field column_name is unset!')
    if self.op is None:
      raise TProtocol.TProtocolException(message='Required field op is unset!')
    if self.value is None:
      raise TProtocol.TProtocolException(message='Required field value is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class IndexClause:
  """
  @deprecated use a KeyRange with row_filter in get_range_slices instead

  Attributes:
   - expressions
   - start_key
   - count
  """

  thrift_spec = (
    None, # 0
    (1, TType.LIST, 'expressions', (TType.STRUCT,(IndexExpression, IndexExpression.thrift_spec)), None, ), # 1
    (2, TType.STRING, 'start_key', None, None, ), # 2
    (3, TType.I32, 'count', None, 100, ), # 3
  )

  def __init__(self, expressions=None, start_key=None, count=thrift_spec[3][4],):
    self.expressions = expressions
    self.start_key = start_key
    self.count = count

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.LIST:
          self.expressions = []
          (_etype24, _size21) = iprot.readListBegin()
          for _i25 in xrange(_size21):
            _elem26 = IndexExpression()
            _elem26.read(iprot)
            self.expressions.append(_elem26)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.start_key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.I32:
          self.count = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('IndexClause')
    if self.expressions is not None:
      oprot.writeFieldBegin('expressions', TType.LIST, 1)
      oprot.writeListBegin(TType.STRUCT, len(self.expressions))
      for iter27 in self.expressions:
        iter27.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.start_key is not None:
      oprot.writeFieldBegin('start_key', TType.STRING, 2)
      oprot.writeString(self.start_key)
      oprot.writeFieldEnd()
    if self.count is not None:
      oprot.writeFieldBegin('count', TType.I32, 3)
      oprot.writeI32(self.count)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.expressions is None:
      raise TProtocol.TProtocolException(message='Required field expressions is unset!')
    if self.start_key is None:
      raise TProtocol.TProtocolException(message='Required field start_key is unset!')
    if self.count is None:
      raise TProtocol.TProtocolException(message='Required field count is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class KeyRange:
  """
  The semantics of start keys and tokens are slightly different.
  Keys are start-inclusive; tokens are start-exclusive.  Token
  ranges may also wrap -- that is, the end token may be less
  than the start one.  Thus, a range from keyX to keyX is a
  one-element range, but a range from tokenY to tokenY is the
  full ring.

  Attributes:
   - start_key
   - end_key
   - start_token
   - end_token
   - row_filter
   - count
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'start_key', None, None, ), # 1
    (2, TType.STRING, 'end_key', None, None, ), # 2
    (3, TType.STRING, 'start_token', None, None, ), # 3
    (4, TType.STRING, 'end_token', None, None, ), # 4
    (5, TType.I32, 'count', None, 100, ), # 5
    (6, TType.LIST, 'row_filter', (TType.STRUCT,(IndexExpression, IndexExpression.thrift_spec)), None, ), # 6
  )

  def __init__(self, start_key=None, end_key=None, start_token=None, end_token=None, row_filter=None, count=thrift_spec[5][4],):
    self.start_key = start_key
    self.end_key = end_key
    self.start_token = start_token
    self.end_token = end_token
    self.row_filter = row_filter
    self.count = count

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.start_key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.end_key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRING:
          self.start_token = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRING:
          self.end_token = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 6:
        if ftype == TType.LIST:
          self.row_filter = []
          (_etype31, _size28) = iprot.readListBegin()
          for _i32 in xrange(_size28):
            _elem33 = IndexExpression()
            _elem33.read(iprot)
            self.row_filter.append(_elem33)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 5:
        if ftype == TType.I32:
          self.count = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('KeyRange')
    if self.start_key is not None:
      oprot.writeFieldBegin('start_key', TType.STRING, 1)
      oprot.writeString(self.start_key)
      oprot.writeFieldEnd()
    if self.end_key is not None:
      oprot.writeFieldBegin('end_key', TType.STRING, 2)
      oprot.writeString(self.end_key)
      oprot.writeFieldEnd()
    if self.start_token is not None:
      oprot.writeFieldBegin('start_token', TType.STRING, 3)
      oprot.writeString(self.start_token)
      oprot.writeFieldEnd()
    if self.end_token is not None:
      oprot.writeFieldBegin('end_token', TType.STRING, 4)
      oprot.writeString(self.end_token)
      oprot.writeFieldEnd()
    if self.count is not None:
      oprot.writeFieldBegin('count', TType.I32, 5)
      oprot.writeI32(self.count)
      oprot.writeFieldEnd()
    if self.row_filter is not None:
      oprot.writeFieldBegin('row_filter', TType.LIST, 6)
      oprot.writeListBegin(TType.STRUCT, len(self.row_filter))
      for iter34 in self.row_filter:
        iter34.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.count is None:
      raise TProtocol.TProtocolException(message='Required field count is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class KeySlice:
  """
  A KeySlice is key followed by the data it maps to. A collection of KeySlice is returned by the get_range_slice operation.

  @param key. a row key
  @param columns. List of data represented by the key. Typically, the list is pared down to only the columns specified by
                  a SlicePredicate.

  Attributes:
   - key
   - columns
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'key', None, None, ), # 1
    (2, TType.LIST, 'columns', (TType.STRUCT,(ColumnOrSuperColumn, ColumnOrSuperColumn.thrift_spec)), None, ), # 2
  )

  def __init__(self, key=None, columns=None,):
    self.key = key
    self.columns = columns

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.LIST:
          self.columns = []
          (_etype38, _size35) = iprot.readListBegin()
          for _i39 in xrange(_size35):
            _elem40 = ColumnOrSuperColumn()
            _elem40.read(iprot)
            self.columns.append(_elem40)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('KeySlice')
    if self.key is not None:
      oprot.writeFieldBegin('key', TType.STRING, 1)
      oprot.writeString(self.key)
      oprot.writeFieldEnd()
    if self.columns is not None:
      oprot.writeFieldBegin('columns', TType.LIST, 2)
      oprot.writeListBegin(TType.STRUCT, len(self.columns))
      for iter41 in self.columns:
        iter41.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.key is None:
      raise TProtocol.TProtocolException(message='Required field key is unset!')
    if self.columns is None:
      raise TProtocol.TProtocolException(message='Required field columns is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class KeyCount:
  """
  Attributes:
   - key
   - count
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'key', None, None, ), # 1
    (2, TType.I32, 'count', None, None, ), # 2
  )

  def __init__(self, key=None, count=None,):
    self.key = key
    self.count = count

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.I32:
          self.count = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('KeyCount')
    if self.key is not None:
      oprot.writeFieldBegin('key', TType.STRING, 1)
      oprot.writeString(self.key)
      oprot.writeFieldEnd()
    if self.count is not None:
      oprot.writeFieldBegin('count', TType.I32, 2)
      oprot.writeI32(self.count)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.key is None:
      raise TProtocol.TProtocolException(message='Required field key is unset!')
    if self.count is None:
      raise TProtocol.TProtocolException(message='Required field count is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class Deletion:
  """
  Note that the timestamp is only optional in case of counter deletion.

  Attributes:
   - timestamp
   - super_column
   - predicate
  """

  thrift_spec = (
    None, # 0
    (1, TType.I64, 'timestamp', None, None, ), # 1
    (2, TType.STRING, 'super_column', None, None, ), # 2
    (3, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
  )

  def __init__(self, timestamp=None, super_column=None, predicate=None,):
    self.timestamp = timestamp
    self.super_column = super_column
    self.predicate = predicate

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.I64:
          self.timestamp = iprot.readI64();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.super_column = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRUCT:
          self.predicate = SlicePredicate()
          self.predicate.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('Deletion')
    if self.timestamp is not None:
      oprot.writeFieldBegin('timestamp', TType.I64, 1)
      oprot.writeI64(self.timestamp)
      oprot.writeFieldEnd()
    if self.super_column is not None:
      oprot.writeFieldBegin('super_column', TType.STRING, 2)
      oprot.writeString(self.super_column)
      oprot.writeFieldEnd()
    if self.predicate is not None:
      oprot.writeFieldBegin('predicate', TType.STRUCT, 3)
      self.predicate.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class Mutation:
  """
  A Mutation is either an insert (represented by filling column_or_supercolumn) or a deletion (represented by filling the deletion attribute).
  @param column_or_supercolumn. An insert to a column or supercolumn (possibly counter column or supercolumn)
  @param deletion. A deletion of a column or supercolumn

  Attributes:
   - column_or_supercolumn
   - deletion
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRUCT, 'column_or_supercolumn', (ColumnOrSuperColumn, ColumnOrSuperColumn.thrift_spec), None, ), # 1
    (2, TType.STRUCT, 'deletion', (Deletion, Deletion.thrift_spec), None, ), # 2
  )

  def __init__(self, column_or_supercolumn=None, deletion=None,):
    self.column_or_supercolumn = column_or_supercolumn
    self.deletion = deletion

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRUCT:
          self.column_or_supercolumn = ColumnOrSuperColumn()
          self.column_or_supercolumn.read(iprot)
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRUCT:
          self.deletion = Deletion()
          self.deletion.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('Mutation')
    if self.column_or_supercolumn is not None:
      oprot.writeFieldBegin('column_or_supercolumn', TType.STRUCT, 1)
      self.column_or_supercolumn.write(oprot)
      oprot.writeFieldEnd()
    if self.deletion is not None:
      oprot.writeFieldBegin('deletion', TType.STRUCT, 2)
      self.deletion.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class EndpointDetails:
  """
  Attributes:
   - host
   - datacenter
   - rack
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'host', None, None, ), # 1
    (2, TType.STRING, 'datacenter', None, None, ), # 2
    (3, TType.STRING, 'rack', None, None, ), # 3
  )

  def __init__(self, host=None, datacenter=None, rack=None,):
    self.host = host
    self.datacenter = datacenter
    self.rack = rack

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.host = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.datacenter = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRING:
          self.rack = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('EndpointDetails')
    if self.host is not None:
      oprot.writeFieldBegin('host', TType.STRING, 1)
      oprot.writeString(self.host)
      oprot.writeFieldEnd()
    if self.datacenter is not None:
      oprot.writeFieldBegin('datacenter', TType.STRING, 2)
      oprot.writeString(self.datacenter)
      oprot.writeFieldEnd()
    if self.rack is not None:
      oprot.writeFieldBegin('rack', TType.STRING, 3)
      oprot.writeString(self.rack)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class TokenRange:
  """
  A TokenRange describes part of the Cassandra ring, it is a mapping from a range to
  endpoints responsible for that range.
  @param start_token The first token in the range
  @param end_token The last token in the range
  @param endpoints The endpoints responsible for the range (listed by their configured listen_address)
  @param rpc_endpoints The endpoints responsible for the range (listed by their configured rpc_address)

  Attributes:
   - start_token
   - end_token
   - endpoints
   - rpc_endpoints
   - endpoint_details
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'start_token', None, None, ), # 1
    (2, TType.STRING, 'end_token', None, None, ), # 2
    (3, TType.LIST, 'endpoints', (TType.STRING,None), None, ), # 3
    (4, TType.LIST, 'rpc_endpoints', (TType.STRING,None), None, ), # 4
    (5, TType.LIST, 'endpoint_details', (TType.STRUCT,(EndpointDetails, EndpointDetails.thrift_spec)), None, ), # 5
  )

  def __init__(self, start_token=None, end_token=None, endpoints=None, rpc_endpoints=None, endpoint_details=None,):
    self.start_token = start_token
    self.end_token = end_token
    self.endpoints = endpoints
    self.rpc_endpoints = rpc_endpoints
    self.endpoint_details = endpoint_details

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.start_token = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.end_token = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.LIST:
          self.endpoints = []
          (_etype45, _size42) = iprot.readListBegin()
          for _i46 in xrange(_size42):
            _elem47 = iprot.readString();
            self.endpoints.append(_elem47)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.LIST:
          self.rpc_endpoints = []
          (_etype51, _size48) = iprot.readListBegin()
          for _i52 in xrange(_size48):
            _elem53 = iprot.readString();
            self.rpc_endpoints.append(_elem53)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 5:
        if ftype == TType.LIST:
          self.endpoint_details = []
          (_etype57, _size54) = iprot.readListBegin()
          for _i58 in xrange(_size54):
            _elem59 = EndpointDetails()
            _elem59.read(iprot)
            self.endpoint_details.append(_elem59)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('TokenRange')
    if self.start_token is not None:
      oprot.writeFieldBegin('start_token', TType.STRING, 1)
      oprot.writeString(self.start_token)
      oprot.writeFieldEnd()
    if self.end_token is not None:
      oprot.writeFieldBegin('end_token', TType.STRING, 2)
      oprot.writeString(self.end_token)
      oprot.writeFieldEnd()
    if self.endpoints is not None:
      oprot.writeFieldBegin('endpoints', TType.LIST, 3)
      oprot.writeListBegin(TType.STRING, len(self.endpoints))
      for iter60 in self.endpoints:
        oprot.writeString(iter60)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.rpc_endpoints is not None:
      oprot.writeFieldBegin('rpc_endpoints', TType.LIST, 4)
      oprot.writeListBegin(TType.STRING, len(self.rpc_endpoints))
      for iter61 in self.rpc_endpoints:
        oprot.writeString(iter61)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.endpoint_details is not None:
      oprot.writeFieldBegin('endpoint_details', TType.LIST, 5)
      oprot.writeListBegin(TType.STRUCT, len(self.endpoint_details))
      for iter62 in self.endpoint_details:
        iter62.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.start_token is None:
      raise TProtocol.TProtocolException(message='Required field start_token is unset!')
    if self.end_token is None:
      raise TProtocol.TProtocolException(message='Required field end_token is unset!')
    if self.endpoints is None:
      raise TProtocol.TProtocolException(message='Required field endpoints is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class AuthenticationRequest:
  """
  Authentication requests can contain any data, dependent on the IAuthenticator used

  Attributes:
   - credentials
  """

  thrift_spec = (
    None, # 0
    (1, TType.MAP, 'credentials', (TType.STRING,None,TType.STRING,None), None, ), # 1
  )

  def __init__(self, credentials=None,):
    self.credentials = credentials

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.MAP:
          self.credentials = {}
          (_ktype64, _vtype65, _size63 ) = iprot.readMapBegin() 
          for _i67 in xrange(_size63):
            _key68 = iprot.readString();
            _val69 = iprot.readString();
            self.credentials[_key68] = _val69
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('AuthenticationRequest')
    if self.credentials is not None:
      oprot.writeFieldBegin('credentials', TType.MAP, 1)
      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.credentials))
      for kiter70,viter71 in self.credentials.items():
        oprot.writeString(kiter70)
        oprot.writeString(viter71)
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.credentials is None:
      raise TProtocol.TProtocolException(message='Required field credentials is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class ColumnDef:
  """
  Attributes:
   - name
   - validation_class
   - index_type
   - index_name
   - index_options
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'name', None, None, ), # 1
    (2, TType.STRING, 'validation_class', None, None, ), # 2
    (3, TType.I32, 'index_type', None, None, ), # 3
    (4, TType.STRING, 'index_name', None, None, ), # 4
    (5, TType.MAP, 'index_options', (TType.STRING,None,TType.STRING,None), None, ), # 5
  )

  def __init__(self, name=None, validation_class=None, index_type=None, index_name=None, index_options=None,):
    self.name = name
    self.validation_class = validation_class
    self.index_type = index_type
    self.index_name = index_name
    self.index_options = index_options

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.name = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.validation_class = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.I32:
          self.index_type = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRING:
          self.index_name = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 5:
        if ftype == TType.MAP:
          self.index_options = {}
          (_ktype73, _vtype74, _size72 ) = iprot.readMapBegin() 
          for _i76 in xrange(_size72):
            _key77 = iprot.readString();
            _val78 = iprot.readString();
            self.index_options[_key77] = _val78
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('ColumnDef')
    if self.name is not None:
      oprot.writeFieldBegin('name', TType.STRING, 1)
      oprot.writeString(self.name)
      oprot.writeFieldEnd()
    if self.validation_class is not None:
      oprot.writeFieldBegin('validation_class', TType.STRING, 2)
      oprot.writeString(self.validation_class)
      oprot.writeFieldEnd()
    if self.index_type is not None:
      oprot.writeFieldBegin('index_type', TType.I32, 3)
      oprot.writeI32(self.index_type)
      oprot.writeFieldEnd()
    if self.index_name is not None:
      oprot.writeFieldBegin('index_name', TType.STRING, 4)
      oprot.writeString(self.index_name)
      oprot.writeFieldEnd()
    if self.index_options is not None:
      oprot.writeFieldBegin('index_options', TType.MAP, 5)
      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.index_options))
      for kiter79,viter80 in self.index_options.items():
        oprot.writeString(kiter79)
        oprot.writeString(viter80)
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.name is None:
      raise TProtocol.TProtocolException(message='Required field name is unset!')
    if self.validation_class is None:
      raise TProtocol.TProtocolException(message='Required field validation_class is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class CfDef:
  """
  Attributes:
   - keyspace
   - name
   - column_type
   - comparator_type
   - subcomparator_type
   - comment
   - read_repair_chance
   - column_metadata
   - gc_grace_seconds
   - default_validation_class
   - id
   - min_compaction_threshold
   - max_compaction_threshold
   - replicate_on_write
   - key_validation_class
   - key_alias
   - compaction_strategy
   - compaction_strategy_options
   - compression_options
   - bloom_filter_fp_chance
   - caching
   - dclocal_read_repair_chance
   - row_cache_size: @deprecated
   - key_cache_size: @deprecated
   - row_cache_save_period_in_seconds: @deprecated
   - key_cache_save_period_in_seconds: @deprecated
   - memtable_flush_after_mins: @deprecated
   - memtable_throughput_in_mb: @deprecated
   - memtable_operations_in_millions: @deprecated
   - merge_shards_chance: @deprecated
   - row_cache_provider: @deprecated
   - row_cache_keys_to_save: @deprecated
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'keyspace', None, None, ), # 1
    (2, TType.STRING, 'name', None, None, ), # 2
    (3, TType.STRING, 'column_type', None, "Standard", ), # 3
    None, # 4
    (5, TType.STRING, 'comparator_type', None, "BytesType", ), # 5
    (6, TType.STRING, 'subcomparator_type', None, None, ), # 6
    None, # 7
    (8, TType.STRING, 'comment', None, None, ), # 8
    (9, TType.DOUBLE, 'row_cache_size', None, None, ), # 9
    None, # 10
    (11, TType.DOUBLE, 'key_cache_size', None, None, ), # 11
    (12, TType.DOUBLE, 'read_repair_chance', None, None, ), # 12
    (13, TType.LIST, 'column_metadata', (TType.STRUCT,(ColumnDef, ColumnDef.thrift_spec)), None, ), # 13
    (14, TType.I32, 'gc_grace_seconds', None, None, ), # 14
    (15, TType.STRING, 'default_validation_class', None, None, ), # 15
    (16, TType.I32, 'id', None, None, ), # 16
    (17, TType.I32, 'min_compaction_threshold', None, None, ), # 17
    (18, TType.I32, 'max_compaction_threshold', None, None, ), # 18
    (19, TType.I32, 'row_cache_save_period_in_seconds', None, None, ), # 19
    (20, TType.I32, 'key_cache_save_period_in_seconds', None, None, ), # 20
    (21, TType.I32, 'memtable_flush_after_mins', None, None, ), # 21
    (22, TType.I32, 'memtable_throughput_in_mb', None, None, ), # 22
    (23, TType.DOUBLE, 'memtable_operations_in_millions', None, None, ), # 23
    (24, TType.BOOL, 'replicate_on_write', None, None, ), # 24
    (25, TType.DOUBLE, 'merge_shards_chance', None, None, ), # 25
    (26, TType.STRING, 'key_validation_class', None, None, ), # 26
    (27, TType.STRING, 'row_cache_provider', None, None, ), # 27
    (28, TType.STRING, 'key_alias', None, None, ), # 28
    (29, TType.STRING, 'compaction_strategy', None, None, ), # 29
    (30, TType.MAP, 'compaction_strategy_options', (TType.STRING,None,TType.STRING,None), None, ), # 30
    (31, TType.I32, 'row_cache_keys_to_save', None, None, ), # 31
    (32, TType.MAP, 'compression_options', (TType.STRING,None,TType.STRING,None), None, ), # 32
    (33, TType.DOUBLE, 'bloom_filter_fp_chance', None, None, ), # 33
    (34, TType.STRING, 'caching', None, "keys_only", ), # 34
    None, # 35
    None, # 36
    (37, TType.DOUBLE, 'dclocal_read_repair_chance', None, 0, ), # 37
  )

  def __init__(self, keyspace=None, name=None, column_type=thrift_spec[3][4], comparator_type=thrift_spec[5][4], subcomparator_type=None, comment=None, read_repair_chance=None, column_metadata=None, gc_grace_seconds=None, default_validation_class=None, id=None, min_compaction_threshold=None, max_compaction_threshold=None, replicate_on_write=None, key_validation_class=None, key_alias=None, compaction_strategy=None, compaction_strategy_options=None, compression_options=None, bloom_filter_fp_chance=None, caching=thrift_spec[34][4], dclocal_read_repair_chance=thrift_spec[37][4], row_cache_size=None, key_cache_size=None, row_cache_save_period_in_seconds=None, key_cache_save_period_in_seconds=None, memtable_flush_after_mins=None, memtable_throughput_in_mb=None, memtable_operations_in_millions=None, merge_shards_chance=None, row_cache_provider=None, row_cache_keys_to_save=None,):
    self.keyspace = keyspace
    self.name = name
    self.column_type = column_type
    self.comparator_type = comparator_type
    self.subcomparator_type = subcomparator_type
    self.comment = comment
    self.read_repair_chance = read_repair_chance
    self.column_metadata = column_metadata
    self.gc_grace_seconds = gc_grace_seconds
    self.default_validation_class = default_validation_class
    self.id = id
    self.min_compaction_threshold = min_compaction_threshold
    self.max_compaction_threshold = max_compaction_threshold
    self.replicate_on_write = replicate_on_write
    self.key_validation_class = key_validation_class
    self.key_alias = key_alias
    self.compaction_strategy = compaction_strategy
    self.compaction_strategy_options = compaction_strategy_options
    self.compression_options = compression_options
    self.bloom_filter_fp_chance = bloom_filter_fp_chance
    self.caching = caching
    self.dclocal_read_repair_chance = dclocal_read_repair_chance
    self.row_cache_size = row_cache_size
    self.key_cache_size = key_cache_size
    self.row_cache_save_period_in_seconds = row_cache_save_period_in_seconds
    self.key_cache_save_period_in_seconds = key_cache_save_period_in_seconds
    self.memtable_flush_after_mins = memtable_flush_after_mins
    self.memtable_throughput_in_mb = memtable_throughput_in_mb
    self.memtable_operations_in_millions = memtable_operations_in_millions
    self.merge_shards_chance = merge_shards_chance
    self.row_cache_provider = row_cache_provider
    self.row_cache_keys_to_save = row_cache_keys_to_save

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.keyspace = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.name = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRING:
          self.column_type = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 5:
        if ftype == TType.STRING:
          self.comparator_type = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 6:
        if ftype == TType.STRING:
          self.subcomparator_type = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 8:
        if ftype == TType.STRING:
          self.comment = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 12:
        if ftype == TType.DOUBLE:
          self.read_repair_chance = iprot.readDouble();
        else:
          iprot.skip(ftype)
      elif fid == 13:
        if ftype == TType.LIST:
          self.column_metadata = []
          (_etype84, _size81) = iprot.readListBegin()
          for _i85 in xrange(_size81):
            _elem86 = ColumnDef()
            _elem86.read(iprot)
            self.column_metadata.append(_elem86)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 14:
        if ftype == TType.I32:
          self.gc_grace_seconds = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 15:
        if ftype == TType.STRING:
          self.default_validation_class = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 16:
        if ftype == TType.I32:
          self.id = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 17:
        if ftype == TType.I32:
          self.min_compaction_threshold = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 18:
        if ftype == TType.I32:
          self.max_compaction_threshold = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 24:
        if ftype == TType.BOOL:
          self.replicate_on_write = iprot.readBool();
        else:
          iprot.skip(ftype)
      elif fid == 26:
        if ftype == TType.STRING:
          self.key_validation_class = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 28:
        if ftype == TType.STRING:
          self.key_alias = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 29:
        if ftype == TType.STRING:
          self.compaction_strategy = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 30:
        if ftype == TType.MAP:
          self.compaction_strategy_options = {}
          (_ktype88, _vtype89, _size87 ) = iprot.readMapBegin() 
          for _i91 in xrange(_size87):
            _key92 = iprot.readString();
            _val93 = iprot.readString();
            self.compaction_strategy_options[_key92] = _val93
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 32:
        if ftype == TType.MAP:
          self.compression_options = {}
          (_ktype95, _vtype96, _size94 ) = iprot.readMapBegin() 
          for _i98 in xrange(_size94):
            _key99 = iprot.readString();
            _val100 = iprot.readString();
            self.compression_options[_key99] = _val100
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 33:
        if ftype == TType.DOUBLE:
          self.bloom_filter_fp_chance = iprot.readDouble();
        else:
          iprot.skip(ftype)
      elif fid == 34:
        if ftype == TType.STRING:
          self.caching = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 37:
        if ftype == TType.DOUBLE:
          self.dclocal_read_repair_chance = iprot.readDouble();
        else:
          iprot.skip(ftype)
      elif fid == 9:
        if ftype == TType.DOUBLE:
          self.row_cache_size = iprot.readDouble();
        else:
          iprot.skip(ftype)
      elif fid == 11:
        if ftype == TType.DOUBLE:
          self.key_cache_size = iprot.readDouble();
        else:
          iprot.skip(ftype)
      elif fid == 19:
        if ftype == TType.I32:
          self.row_cache_save_period_in_seconds = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 20:
        if ftype == TType.I32:
          self.key_cache_save_period_in_seconds = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 21:
        if ftype == TType.I32:
          self.memtable_flush_after_mins = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 22:
        if ftype == TType.I32:
          self.memtable_throughput_in_mb = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 23:
        if ftype == TType.DOUBLE:
          self.memtable_operations_in_millions = iprot.readDouble();
        else:
          iprot.skip(ftype)
      elif fid == 25:
        if ftype == TType.DOUBLE:
          self.merge_shards_chance = iprot.readDouble();
        else:
          iprot.skip(ftype)
      elif fid == 27:
        if ftype == TType.STRING:
          self.row_cache_provider = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 31:
        if ftype == TType.I32:
          self.row_cache_keys_to_save = iprot.readI32();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('CfDef')
    if self.keyspace is not None:
      oprot.writeFieldBegin('keyspace', TType.STRING, 1)
      oprot.writeString(self.keyspace)
      oprot.writeFieldEnd()
    if self.name is not None:
      oprot.writeFieldBegin('name', TType.STRING, 2)
      oprot.writeString(self.name)
      oprot.writeFieldEnd()
    if self.column_type is not None:
      oprot.writeFieldBegin('column_type', TType.STRING, 3)
      oprot.writeString(self.column_type)
      oprot.writeFieldEnd()
    if self.comparator_type is not None:
      oprot.writeFieldBegin('comparator_type', TType.STRING, 5)
      oprot.writeString(self.comparator_type)
      oprot.writeFieldEnd()
    if self.subcomparator_type is not None:
      oprot.writeFieldBegin('subcomparator_type', TType.STRING, 6)
      oprot.writeString(self.subcomparator_type)
      oprot.writeFieldEnd()
    if self.comment is not None:
      oprot.writeFieldBegin('comment', TType.STRING, 8)
      oprot.writeString(self.comment)
      oprot.writeFieldEnd()
    if self.row_cache_size is not None:
      oprot.writeFieldBegin('row_cache_size', TType.DOUBLE, 9)
      oprot.writeDouble(self.row_cache_size)
      oprot.writeFieldEnd()
    if self.key_cache_size is not None:
      oprot.writeFieldBegin('key_cache_size', TType.DOUBLE, 11)
      oprot.writeDouble(self.key_cache_size)
      oprot.writeFieldEnd()
    if self.read_repair_chance is not None:
      oprot.writeFieldBegin('read_repair_chance', TType.DOUBLE, 12)
      oprot.writeDouble(self.read_repair_chance)
      oprot.writeFieldEnd()
    if self.column_metadata is not None:
      oprot.writeFieldBegin('column_metadata', TType.LIST, 13)
      oprot.writeListBegin(TType.STRUCT, len(self.column_metadata))
      for iter101 in self.column_metadata:
        iter101.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.gc_grace_seconds is not None:
      oprot.writeFieldBegin('gc_grace_seconds', TType.I32, 14)
      oprot.writeI32(self.gc_grace_seconds)
      oprot.writeFieldEnd()
    if self.default_validation_class is not None:
      oprot.writeFieldBegin('default_validation_class', TType.STRING, 15)
      oprot.writeString(self.default_validation_class)
      oprot.writeFieldEnd()
    if self.id is not None:
      oprot.writeFieldBegin('id', TType.I32, 16)
      oprot.writeI32(self.id)
      oprot.writeFieldEnd()
    if self.min_compaction_threshold is not None:
      oprot.writeFieldBegin('min_compaction_threshold', TType.I32, 17)
      oprot.writeI32(self.min_compaction_threshold)
      oprot.writeFieldEnd()
    if self.max_compaction_threshold is not None:
      oprot.writeFieldBegin('max_compaction_threshold', TType.I32, 18)
      oprot.writeI32(self.max_compaction_threshold)
      oprot.writeFieldEnd()
    if self.row_cache_save_period_in_seconds is not None:
      oprot.writeFieldBegin('row_cache_save_period_in_seconds', TType.I32, 19)
      oprot.writeI32(self.row_cache_save_period_in_seconds)
      oprot.writeFieldEnd()
    if self.key_cache_save_period_in_seconds is not None:
      oprot.writeFieldBegin('key_cache_save_period_in_seconds', TType.I32, 20)
      oprot.writeI32(self.key_cache_save_period_in_seconds)
      oprot.writeFieldEnd()
    if self.memtable_flush_after_mins is not None:
      oprot.writeFieldBegin('memtable_flush_after_mins', TType.I32, 21)
      oprot.writeI32(self.memtable_flush_after_mins)
      oprot.writeFieldEnd()
    if self.memtable_throughput_in_mb is not None:
      oprot.writeFieldBegin('memtable_throughput_in_mb', TType.I32, 22)
      oprot.writeI32(self.memtable_throughput_in_mb)
      oprot.writeFieldEnd()
    if self.memtable_operations_in_millions is not None:
      oprot.writeFieldBegin('memtable_operations_in_millions', TType.DOUBLE, 23)
      oprot.writeDouble(self.memtable_operations_in_millions)
      oprot.writeFieldEnd()
    if self.replicate_on_write is not None:
      oprot.writeFieldBegin('replicate_on_write', TType.BOOL, 24)
      oprot.writeBool(self.replicate_on_write)
      oprot.writeFieldEnd()
    if self.merge_shards_chance is not None:
      oprot.writeFieldBegin('merge_shards_chance', TType.DOUBLE, 25)
      oprot.writeDouble(self.merge_shards_chance)
      oprot.writeFieldEnd()
    if self.key_validation_class is not None:
      oprot.writeFieldBegin('key_validation_class', TType.STRING, 26)
      oprot.writeString(self.key_validation_class)
      oprot.writeFieldEnd()
    if self.row_cache_provider is not None:
      oprot.writeFieldBegin('row_cache_provider', TType.STRING, 27)
      oprot.writeString(self.row_cache_provider)
      oprot.writeFieldEnd()
    if self.key_alias is not None:
      oprot.writeFieldBegin('key_alias', TType.STRING, 28)
      oprot.writeString(self.key_alias)
      oprot.writeFieldEnd()
    if self.compaction_strategy is not None:
      oprot.writeFieldBegin('compaction_strategy', TType.STRING, 29)
      oprot.writeString(self.compaction_strategy)
      oprot.writeFieldEnd()
    if self.compaction_strategy_options is not None:
      oprot.writeFieldBegin('compaction_strategy_options', TType.MAP, 30)
      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.compaction_strategy_options))
      for kiter102,viter103 in self.compaction_strategy_options.items():
        oprot.writeString(kiter102)
        oprot.writeString(viter103)
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.row_cache_keys_to_save is not None:
      oprot.writeFieldBegin('row_cache_keys_to_save', TType.I32, 31)
      oprot.writeI32(self.row_cache_keys_to_save)
      oprot.writeFieldEnd()
    if self.compression_options is not None:
      oprot.writeFieldBegin('compression_options', TType.MAP, 32)
      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.compression_options))
      for kiter104,viter105 in self.compression_options.items():
        oprot.writeString(kiter104)
        oprot.writeString(viter105)
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.bloom_filter_fp_chance is not None:
      oprot.writeFieldBegin('bloom_filter_fp_chance', TType.DOUBLE, 33)
      oprot.writeDouble(self.bloom_filter_fp_chance)
      oprot.writeFieldEnd()
    if self.caching is not None:
      oprot.writeFieldBegin('caching', TType.STRING, 34)
      oprot.writeString(self.caching)
      oprot.writeFieldEnd()
    if self.dclocal_read_repair_chance is not None:
      oprot.writeFieldBegin('dclocal_read_repair_chance', TType.DOUBLE, 37)
      oprot.writeDouble(self.dclocal_read_repair_chance)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.keyspace is None:
      raise TProtocol.TProtocolException(message='Required field keyspace is unset!')
    if self.name is None:
      raise TProtocol.TProtocolException(message='Required field name is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class KsDef:
  """
  Attributes:
   - name
   - strategy_class
   - strategy_options
   - replication_factor: @deprecated ignored
   - cf_defs
   - durable_writes
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'name', None, None, ), # 1
    (2, TType.STRING, 'strategy_class', None, None, ), # 2
    (3, TType.MAP, 'strategy_options', (TType.STRING,None,TType.STRING,None), None, ), # 3
    (4, TType.I32, 'replication_factor', None, None, ), # 4
    (5, TType.LIST, 'cf_defs', (TType.STRUCT,(CfDef, CfDef.thrift_spec)), None, ), # 5
    (6, TType.BOOL, 'durable_writes', None, True, ), # 6
  )

  def __init__(self, name=None, strategy_class=None, strategy_options=None, replication_factor=None, cf_defs=None, durable_writes=thrift_spec[6][4],):
    self.name = name
    self.strategy_class = strategy_class
    self.strategy_options = strategy_options
    self.replication_factor = replication_factor
    self.cf_defs = cf_defs
    self.durable_writes = durable_writes

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.name = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.strategy_class = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.MAP:
          self.strategy_options = {}
          (_ktype107, _vtype108, _size106 ) = iprot.readMapBegin() 
          for _i110 in xrange(_size106):
            _key111 = iprot.readString();
            _val112 = iprot.readString();
            self.strategy_options[_key111] = _val112
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.I32:
          self.replication_factor = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 5:
        if ftype == TType.LIST:
          self.cf_defs = []
          (_etype116, _size113) = iprot.readListBegin()
          for _i117 in xrange(_size113):
            _elem118 = CfDef()
            _elem118.read(iprot)
            self.cf_defs.append(_elem118)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 6:
        if ftype == TType.BOOL:
          self.durable_writes = iprot.readBool();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('KsDef')
    if self.name is not None:
      oprot.writeFieldBegin('name', TType.STRING, 1)
      oprot.writeString(self.name)
      oprot.writeFieldEnd()
    if self.strategy_class is not None:
      oprot.writeFieldBegin('strategy_class', TType.STRING, 2)
      oprot.writeString(self.strategy_class)
      oprot.writeFieldEnd()
    if self.strategy_options is not None:
      oprot.writeFieldBegin('strategy_options', TType.MAP, 3)
      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.strategy_options))
      for kiter119,viter120 in self.strategy_options.items():
        oprot.writeString(kiter119)
        oprot.writeString(viter120)
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.replication_factor is not None:
      oprot.writeFieldBegin('replication_factor', TType.I32, 4)
      oprot.writeI32(self.replication_factor)
      oprot.writeFieldEnd()
    if self.cf_defs is not None:
      oprot.writeFieldBegin('cf_defs', TType.LIST, 5)
      oprot.writeListBegin(TType.STRUCT, len(self.cf_defs))
      for iter121 in self.cf_defs:
        iter121.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.durable_writes is not None:
      oprot.writeFieldBegin('durable_writes', TType.BOOL, 6)
      oprot.writeBool(self.durable_writes)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.name is None:
      raise TProtocol.TProtocolException(message='Required field name is unset!')
    if self.strategy_class is None:
      raise TProtocol.TProtocolException(message='Required field strategy_class is unset!')
    if self.cf_defs is None:
      raise TProtocol.TProtocolException(message='Required field cf_defs is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class CqlRow:
  """
  Row returned from a CQL query

  Attributes:
   - key
   - columns
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'key', None, None, ), # 1
    (2, TType.LIST, 'columns', (TType.STRUCT,(Column, Column.thrift_spec)), None, ), # 2
  )

  def __init__(self, key=None, columns=None,):
    self.key = key
    self.columns = columns

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.key = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.LIST:
          self.columns = []
          (_etype125, _size122) = iprot.readListBegin()
          for _i126 in xrange(_size122):
            _elem127 = Column()
            _elem127.read(iprot)
            self.columns.append(_elem127)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('CqlRow')
    if self.key is not None:
      oprot.writeFieldBegin('key', TType.STRING, 1)
      oprot.writeString(self.key)
      oprot.writeFieldEnd()
    if self.columns is not None:
      oprot.writeFieldBegin('columns', TType.LIST, 2)
      oprot.writeListBegin(TType.STRUCT, len(self.columns))
      for iter128 in self.columns:
        iter128.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.key is None:
      raise TProtocol.TProtocolException(message='Required field key is unset!')
    if self.columns is None:
      raise TProtocol.TProtocolException(message='Required field columns is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class CqlMetadata:
  """
  Attributes:
   - name_types
   - value_types
   - default_name_type
   - default_value_type
  """

  thrift_spec = (
    None, # 0
    (1, TType.MAP, 'name_types', (TType.STRING,None,TType.STRING,None), None, ), # 1
    (2, TType.MAP, 'value_types', (TType.STRING,None,TType.STRING,None), None, ), # 2
    (3, TType.STRING, 'default_name_type', None, None, ), # 3
    (4, TType.STRING, 'default_value_type', None, None, ), # 4
  )

  def __init__(self, name_types=None, value_types=None, default_name_type=None, default_value_type=None,):
    self.name_types = name_types
    self.value_types = value_types
    self.default_name_type = default_name_type
    self.default_value_type = default_value_type

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.MAP:
          self.name_types = {}
          (_ktype130, _vtype131, _size129 ) = iprot.readMapBegin() 
          for _i133 in xrange(_size129):
            _key134 = iprot.readString();
            _val135 = iprot.readString();
            self.name_types[_key134] = _val135
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.MAP:
          self.value_types = {}
          (_ktype137, _vtype138, _size136 ) = iprot.readMapBegin() 
          for _i140 in xrange(_size136):
            _key141 = iprot.readString();
            _val142 = iprot.readString();
            self.value_types[_key141] = _val142
          iprot.readMapEnd()
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.STRING:
          self.default_name_type = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRING:
          self.default_value_type = iprot.readString();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('CqlMetadata')
    if self.name_types is not None:
      oprot.writeFieldBegin('name_types', TType.MAP, 1)
      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.name_types))
      for kiter143,viter144 in self.name_types.items():
        oprot.writeString(kiter143)
        oprot.writeString(viter144)
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.value_types is not None:
      oprot.writeFieldBegin('value_types', TType.MAP, 2)
      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.value_types))
      for kiter145,viter146 in self.value_types.items():
        oprot.writeString(kiter145)
        oprot.writeString(viter146)
      oprot.writeMapEnd()
      oprot.writeFieldEnd()
    if self.default_name_type is not None:
      oprot.writeFieldBegin('default_name_type', TType.STRING, 3)
      oprot.writeString(self.default_name_type)
      oprot.writeFieldEnd()
    if self.default_value_type is not None:
      oprot.writeFieldBegin('default_value_type', TType.STRING, 4)
      oprot.writeString(self.default_value_type)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.name_types is None:
      raise TProtocol.TProtocolException(message='Required field name_types is unset!')
    if self.value_types is None:
      raise TProtocol.TProtocolException(message='Required field value_types is unset!')
    if self.default_name_type is None:
      raise TProtocol.TProtocolException(message='Required field default_name_type is unset!')
    if self.default_value_type is None:
      raise TProtocol.TProtocolException(message='Required field default_value_type is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class CqlResult:
  """
  Attributes:
   - type
   - rows
   - num
   - schema
  """

  thrift_spec = (
    None, # 0
    (1, TType.I32, 'type', None, None, ), # 1
    (2, TType.LIST, 'rows', (TType.STRUCT,(CqlRow, CqlRow.thrift_spec)), None, ), # 2
    (3, TType.I32, 'num', None, None, ), # 3
    (4, TType.STRUCT, 'schema', (CqlMetadata, CqlMetadata.thrift_spec), None, ), # 4
  )

  def __init__(self, type=None, rows=None, num=None, schema=None,):
    self.type = type
    self.rows = rows
    self.num = num
    self.schema = schema

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.I32:
          self.type = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.LIST:
          self.rows = []
          (_etype150, _size147) = iprot.readListBegin()
          for _i151 in xrange(_size147):
            _elem152 = CqlRow()
            _elem152.read(iprot)
            self.rows.append(_elem152)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.I32:
          self.num = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.STRUCT:
          self.schema = CqlMetadata()
          self.schema.read(iprot)
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('CqlResult')
    if self.type is not None:
      oprot.writeFieldBegin('type', TType.I32, 1)
      oprot.writeI32(self.type)
      oprot.writeFieldEnd()
    if self.rows is not None:
      oprot.writeFieldBegin('rows', TType.LIST, 2)
      oprot.writeListBegin(TType.STRUCT, len(self.rows))
      for iter153 in self.rows:
        iter153.write(oprot)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.num is not None:
      oprot.writeFieldBegin('num', TType.I32, 3)
      oprot.writeI32(self.num)
      oprot.writeFieldEnd()
    if self.schema is not None:
      oprot.writeFieldBegin('schema', TType.STRUCT, 4)
      self.schema.write(oprot)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.type is None:
      raise TProtocol.TProtocolException(message='Required field type is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class CqlPreparedResult:
  """
  Attributes:
   - itemId
   - count
   - variable_types
   - variable_names
  """

  thrift_spec = (
    None, # 0
    (1, TType.I32, 'itemId', None, None, ), # 1
    (2, TType.I32, 'count', None, None, ), # 2
    (3, TType.LIST, 'variable_types', (TType.STRING,None), None, ), # 3
    (4, TType.LIST, 'variable_names', (TType.STRING,None), None, ), # 4
  )

  def __init__(self, itemId=None, count=None, variable_types=None, variable_names=None,):
    self.itemId = itemId
    self.count = count
    self.variable_types = variable_types
    self.variable_names = variable_names

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.I32:
          self.itemId = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.I32:
          self.count = iprot.readI32();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.LIST:
          self.variable_types = []
          (_etype157, _size154) = iprot.readListBegin()
          for _i158 in xrange(_size154):
            _elem159 = iprot.readString();
            self.variable_types.append(_elem159)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      elif fid == 4:
        if ftype == TType.LIST:
          self.variable_names = []
          (_etype163, _size160) = iprot.readListBegin()
          for _i164 in xrange(_size160):
            _elem165 = iprot.readString();
            self.variable_names.append(_elem165)
          iprot.readListEnd()
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('CqlPreparedResult')
    if self.itemId is not None:
      oprot.writeFieldBegin('itemId', TType.I32, 1)
      oprot.writeI32(self.itemId)
      oprot.writeFieldEnd()
    if self.count is not None:
      oprot.writeFieldBegin('count', TType.I32, 2)
      oprot.writeI32(self.count)
      oprot.writeFieldEnd()
    if self.variable_types is not None:
      oprot.writeFieldBegin('variable_types', TType.LIST, 3)
      oprot.writeListBegin(TType.STRING, len(self.variable_types))
      for iter166 in self.variable_types:
        oprot.writeString(iter166)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    if self.variable_names is not None:
      oprot.writeFieldBegin('variable_names', TType.LIST, 4)
      oprot.writeListBegin(TType.STRING, len(self.variable_names))
      for iter167 in self.variable_names:
        oprot.writeString(iter167)
      oprot.writeListEnd()
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.itemId is None:
      raise TProtocol.TProtocolException(message='Required field itemId is unset!')
    if self.count is None:
      raise TProtocol.TProtocolException(message='Required field count is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

class CfSplit:
  """
  Represents input splits used by hadoop ColumnFamilyRecordReaders

  Attributes:
   - start_token
   - end_token
   - row_count
  """

  thrift_spec = (
    None, # 0
    (1, TType.STRING, 'start_token', None, None, ), # 1
    (2, TType.STRING, 'end_token', None, None, ), # 2
    (3, TType.I64, 'row_count', None, None, ), # 3
  )

  def __init__(self, start_token=None, end_token=None, row_count=None,):
    self.start_token = start_token
    self.end_token = end_token
    self.row_count = row_count

  def read(self, iprot):
    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
      return
    iprot.readStructBegin()
    while True:
      (fname, ftype, fid) = iprot.readFieldBegin()
      if ftype == TType.STOP:
        break
      if fid == 1:
        if ftype == TType.STRING:
          self.start_token = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 2:
        if ftype == TType.STRING:
          self.end_token = iprot.readString();
        else:
          iprot.skip(ftype)
      elif fid == 3:
        if ftype == TType.I64:
          self.row_count = iprot.readI64();
        else:
          iprot.skip(ftype)
      else:
        iprot.skip(ftype)
      iprot.readFieldEnd()
    iprot.readStructEnd()

  def write(self, oprot):
    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
      return
    oprot.writeStructBegin('CfSplit')
    if self.start_token is not None:
      oprot.writeFieldBegin('start_token', TType.STRING, 1)
      oprot.writeString(self.start_token)
      oprot.writeFieldEnd()
    if self.end_token is not None:
      oprot.writeFieldBegin('end_token', TType.STRING, 2)
      oprot.writeString(self.end_token)
      oprot.writeFieldEnd()
    if self.row_count is not None:
      oprot.writeFieldBegin('row_count', TType.I64, 3)
      oprot.writeI64(self.row_count)
      oprot.writeFieldEnd()
    oprot.writeFieldStop()
    oprot.writeStructEnd()

  def validate(self):
    if self.start_token is None:
      raise TProtocol.TProtocolException(message='Required field start_token is unset!')
    if self.end_token is None:
      raise TProtocol.TProtocolException(message='Required field end_token is unset!')
    if self.row_count is None:
      raise TProtocol.TProtocolException(message='Required field row_count is unset!')
    return


  def __repr__(self):
    L = ['%s=%r' % (key, value)
      for key, value in self.__dict__.iteritems()]
    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

  def __eq__(self, other):
    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

  def __ne__(self, other):
    return not (self == other)

########NEW FILE########
__FILENAME__ = client
from collections import defaultdict
import time

from twisted.internet import defer, reactor

from telephus.cassandra import ttypes
from telephus.protocol import ManagedThriftRequest


ConsistencyLevel = ttypes.ConsistencyLevel

class requirekwargs:
    def __init__(self, *args):
        self.required = args

    def __call__(self, f):
        def wrapper(*args, **kwargs):
            for arg in self.required:
                if arg in kwargs and kwargs[arg] is None:
                    raise TypeError("'%s' argument must not be None" % arg)
            return f(*args, **kwargs)
        wrapper.__doc__ = f.__doc__
        return wrapper


class CassandraClient(object):
    def __init__(self, manager, consistency=ConsistencyLevel.ONE):
        self.manager = manager
        self.consistency = consistency

    def _time(self):
        return int(time.time() * 1000000)

    def _getparent(self, columnParentOrCF, super_column=None):
        if isinstance(columnParentOrCF, str):
            return ttypes.ColumnParent(columnParentOrCF, super_column=super_column)
        else:
            return columnParentOrCF

    def _getpath(self, columnPathOrCF, col, super_column=None):
        if isinstance(columnPathOrCF, str):
            return ttypes.ColumnPath(
                columnPathOrCF, super_column=super_column, column=col)
        else:
            return columnPathOrCF

    def _mkpred(self, names, start, finish, reverse, count):
        if names:
            srange = None
        else:
            srange = ttypes.SliceRange(start, finish, reverse, count)
        return ttypes.SlicePredicate(names, srange)

    @defer.inlineCallbacks
    def _wait_for_schema_agreement(self):
        agreement = False
        while not agreement:
            result = yield self.describe_schema_versions()
            live_vers = [skey for (skey, nlist) in result.items()
                         if skey != 'UNREACHABLE']
            agreement = len(live_vers) == 1
            d = defer.Deferred()
            reactor.callLater(0.1, d.callback, True)
            yield d

    @defer.inlineCallbacks
    def _push_system_request(self, req, retries=None, block=True):
        result = yield self.manager.pushRequest(req, retries=retries)
        if block:
            yield self._wait_for_schema_agreement()
        defer.returnValue(result)

    @requirekwargs('key', 'column_family')
    def get(self, key=None, column_family=None, column=None, super_column=None,
            consistency=None, retries=None):
        cp = self._getpath(column_family, column, super_column)
        consistency = consistency or self.consistency
        req = ManagedThriftRequest('get', key, cp, consistency)
        return self.manager.pushRequest(req, retries=retries)

    @requirekwargs('key', 'column_family')
    def get_slice(self, key=None, column_family=None, names=None, start='',
                  finish='', reverse=False, count=100, consistency=None,
                  super_column=None, retries=None):
        cp = self._getparent(column_family, super_column)
        consistency = consistency or self.consistency
        pred = self._mkpred(names, start, finish, reverse, count)
        req = ManagedThriftRequest('get_slice', key, cp, pred, consistency)
        return self.manager.pushRequest(req, retries=retries)

    def multiget(self, keys=None, column_family=None, column=None,
                 super_column=None, consistency=None, retries=None):
        return self.multiget_slice(
            keys, column_family, names=[column], count=100,
            consistency=consistency, retries=retries,
            super_column=super_column)

    @requirekwargs('keys', 'column_family')
    def multiget_slice(self, keys=None, column_family=None, names=None,
                       start='', finish='', reverse=False, count=100,
                       consistency=None, super_column=None, retries=None):
        cp = self._getparent(column_family, super_column)
        consistency = consistency or self.consistency
        pred = self._mkpred(names, start, finish, reverse, count)
        req = ManagedThriftRequest(
            'multiget_slice', keys, cp, pred, consistency)
        return self.manager.pushRequest(req, retries=retries)

    @requirekwargs('keys', 'column_family')
    def multiget_count(self, keys=None, column_family=None, super_column=None,
                       start='', finish='', consistency=None, retries=None):
        cp = self._getparent(column_family, super_column)
        pred = self._mkpred(None, start, finish, False, 2147483647)
        consistency = consistency or self.consistency
        req = ManagedThriftRequest(
            'multiget_count', keys, cp, pred, consistency)
        return self.manager.pushRequest(req, retries=retries)

    @requirekwargs('key', 'column_family')
    def get_count(self, key=None, column_family=None, super_column=None,
                  start='', finish='', consistency=None, retries=None):
        cp = self._getparent(column_family, super_column)
        pred = self._mkpred(None, start, finish, False, 2147483647)
        consistency = consistency or self.consistency
        req = ManagedThriftRequest('get_count', key, cp, pred, consistency)
        return self.manager.pushRequest(req, retries=retries)

    def get_key_range(self, columnParent, **kwargs):
        return self.get_range_slices(columnParent, **kwargs)

    def get_range_slice(self, columnParent, **kwargs):
        return self.get_range_slices(columnParent, **kwargs)

    @requirekwargs('column_family')
    def get_range_slices(self, column_family=None, start='', finish='',
                         column_start='', column_finish='', names=None,
                         count=100, column_count=100, reverse=False,
                         use_tokens=False, consistency=None, super_column=None,
                         retries=None):
        cp = self._getparent(column_family, super_column)
        consistency = consistency or self.consistency
        if not use_tokens:
            krange = ttypes.KeyRange(
                start_key=start, end_key=finish, count=count)
        else:
            krange = ttypes.KeyRange(
                start_token=start, end_token=finish, count=count)
        pred = self._mkpred(
            names, column_start, column_finish, reverse, column_count)
        req = ManagedThriftRequest(
            'get_range_slices', cp, pred, krange, consistency)
        return self.manager.pushRequest(req, retries=retries)

    @requirekwargs('column_family', 'expressions')
    def get_indexed_slices(self, column_family=None, expressions=None,
                           start_key='', column_start='', column_finish='',
                           names=None, count=100, column_count=100,
                           reverse=False, consistency=None, super_column=None,
                           retries=None):
        idx_clause = ttypes.IndexClause(expressions, start_key, count)
        cp = self._getparent(column_family, super_column)
        consistency = consistency or self.consistency
        pred = self._mkpred(
            names, column_start, column_finish, reverse, column_count)
        req = ManagedThriftRequest(
            'get_indexed_slices', cp, idx_clause, pred, consistency)
        return self.manager.pushRequest(req, retries=retries)

    @requirekwargs('key', 'column_family', 'value')
    def insert(self, key=None, column_family=None, value=None, column=None,
               super_column=None, timestamp=None, consistency=None,
               retries=None, ttl=None):
        timestamp = timestamp or self._time()
        cp = self._getparent(column_family, super_column)
        consistency = consistency or self.consistency
        req = ManagedThriftRequest(
            'insert', key, cp, ttypes.Column(column, value, timestamp, ttl),
            consistency)
        return self.manager.pushRequest(req, retries=retries)

    @requirekwargs('key', 'column_family', 'value', 'column')
    def add(self, key=None, column_family=None, value=None, column=None,
            super_column=None, consistency=None, retries=None):
        cp = self._getparent(column_family, super_column)
        consistency = consistency or self.consistency
        req = ManagedThriftRequest(
            'add', key, cp, ttypes.CounterColumn(column, value), consistency)
        return self.manager.pushRequest(req, retries=retries)

    @requirekwargs('key', 'column_family')
    def remove(self, key=None, column_family=None, column=None,
               super_column=None, timestamp=None, consistency=None,
               retries=None):
        cp = self._getpath(column_family, column, super_column)
        timestamp = timestamp or self._time()
        consistency = consistency or self.consistency
        req = ManagedThriftRequest('remove', key, cp, timestamp, consistency)
        return self.manager.pushRequest(req, retries=retries)

    @requirekwargs('key', 'column_family', 'column')
    def remove_counter(self, key=None, column_family=None, column=None,
                       super_column=None, consistency=None, retries=None):
        cp = self._getpath(column_family, column, super_column)
        consistency = consistency or self.consistency
        req = ManagedThriftRequest('remove_counter', key, cp, consistency)
        return self.manager.pushRequest(req, retries=retries)

    @requirekwargs('key', 'column_family', 'mapping')
    def batch_insert(self, key=None, column_family=None, mapping=None,
                     timestamp=None, consistency=None, retries=None, ttl=None,
                     atomic=False):

        if isinstance(mapping, list) and timestamp is not None:
            raise RuntimeError(
                'Timestamp cannot be specified with a list of Mutations')
        timestamp = timestamp or self._time()
        consistency = consistency or self.consistency
        mutmap = {key:
            {column_family: self._mk_cols_or_supers(mapping, timestamp, ttl)}}
        return self.batch_mutate(
            mutmap, timestamp=timestamp, consistency=consistency,
            retries=retries, atomic=atomic)

    @requirekwargs('cfmap')
    def batch_remove(self, cfmap=None, start='', finish='', count=100,
                     names=None, reverse=False, consistency=None,
                     timestamp=None, supercolumn=None, retries=None,
                     atomic=False):
        timestamp = timestamp or self._time()
        consistency = consistency or self.consistency
        mutmap = defaultdict(dict)
        for cf, keys in cfmap.iteritems():
            pred = self._mkpred(names, start, finish, reverse, count)
            for key in keys:
                mutmap[key][cf] = [ttypes.Mutation(
                    deletion=ttypes.Deletion(timestamp, supercolumn, pred))]

        method = 'atomic_batch_mutate' if atomic else 'batch_mutate'
        req = ManagedThriftRequest(method, mutmap, consistency)
        return self.manager.pushRequest(req, retries=retries)

    @requirekwargs('mutationmap')
    def batch_mutate(self, mutationmap=None, timestamp=None, consistency=None,
                     retries=None, ttl=None, atomic=False):
        timestamp = timestamp or self._time()
        consistency = consistency or self.consistency
        mutmap = defaultdict(dict)
        for key, cfmap in mutationmap.iteritems():
            for cf, colmap in cfmap.iteritems():
                cols_or_supers_or_deletions = self._mk_cols_or_supers(
                    colmap, timestamp, ttl, make_deletions=True)
                muts = []
                for c in cols_or_supers_or_deletions:
                    if isinstance(c, ttypes.SuperColumn):
                        muts.append(
                            ttypes.Mutation(
                                ttypes.ColumnOrSuperColumn(super_column=c)))
                    elif isinstance(c, ttypes.Column):
                        muts.append(
                                ttypes.Mutation(
                                    ttypes.ColumnOrSuperColumn(column=c)))
                    elif isinstance(c, ttypes.Deletion):
                        muts.append(ttypes.Mutation(deletion=c))
                    else:
                        muts.append(c)
                mutmap[key][cf] = muts

        method = 'atomic_batch_mutate' if atomic else 'batch_mutate'
        req = ManagedThriftRequest(method, mutmap, consistency)
        return self.manager.pushRequest(req, retries=retries)

    def _mk_cols_or_supers(self, mapping, timestamp, ttl=None,
                           make_deletions=False):
        if isinstance(mapping, list):
            return mapping
        colsorsupers = []
        if isinstance(mapping, dict):
            first = mapping.keys()[0]
            if isinstance(mapping[first], dict):
                for name in mapping:
                    cols = []
                    for col, val in mapping[name].iteritems():
                        cols.append(ttypes.Column(col, val, timestamp, ttl))
                    colsorsupers.append(
                            ttypes.SuperColumn(name=name, columns=cols))
            else:
                cols2delete = []
                for col, val in mapping.iteritems():
                    if val is None and make_deletions:
                        cols2delete.append(col)
                    else:
                        colsorsupers.append(ttypes.Column(col, val, timestamp, ttl))
                if cols2delete:
                    colsorsupers.append(ttypes.Deletion(
                        timestamp, None, ttypes.SlicePredicate(
                            column_names=cols2delete)))
        else:
            raise TypeError('dict (of dicts) or list of '
                            'Columns/SuperColumns expected')
        return colsorsupers

    def set_keyspace(self, keyspace):
        return self.manager.set_keyspace(keyspace)

    def login(self, credentials):
        return self.manager.login(credentials)

    def describe_keyspaces(self, retries=None):
        req = ManagedThriftRequest('describe_keyspaces')
        return self.manager.pushRequest(req, retries=retries)

    def describe_keyspace(self, keyspace, retries=None):
        req = ManagedThriftRequest('describe_keyspace', keyspace)
        return self.manager.pushRequest(req, retries=retries)

    def describe_cluster_name(self, retries=None):
        req = ManagedThriftRequest('describe_cluster_name')
        return self.manager.pushRequest(req, retries=retries)

    def describe_partitioner(self, retries=None):
        req = ManagedThriftRequest('describe_partitioner')
        return self.manager.pushRequest(req, retries=retries)

    def describe_snitch(self, retries=None):
        req = ManagedThriftRequest('describe_snitch')
        return self.manager.pushRequest(req, retries=retries)

    def describe_ring(self, keyspace, retries=None):
        req = ManagedThriftRequest('describe_ring', keyspace)
        return self.manager.pushRequest(req, retries=retries)

    def describe_token_map(self, retries=None):
        req = ManagedThriftRequest('describe_token_map')
        return self.manager.pushRequest(req, retries=retries)

    def describe_splits(self, cfName, start_token, end_token, keys_per_split,
                        retries=None):
        req = ManagedThriftRequest('describe_splits', cfName, start_token,
                                   end_token, keys_per_split)
        return self.manager.pushRequest(req, retries=retries)

    def truncate(self, cfName, retries=None):
        req = ManagedThriftRequest('truncate', cfName)
        return self.manager.pushRequest(req, retries=retries)

    def describe_schema_versions(self, retries=None):
        req = ManagedThriftRequest('describe_schema_versions')
        return self.manager.pushRequest(req, retries=retries)

    def system_drop_column_family(self, cfName, retries=None, block=True):
        req = ManagedThriftRequest('system_drop_column_family', cfName)
        return self._push_system_request(req, retries=retries, block=block)

    def system_drop_keyspace(self, keyspace, retries=None, block=True):
        req = ManagedThriftRequest('system_drop_keyspace', keyspace)
        return self._push_system_request(req, retries=retries, block=block)

    if 0:
        # these are disabled in Cassandra 0.7 right now
        def system_rename_column_family(self, oldname, newname, retries=None,
                                        block=True):
            if block:
                self._wait_for_schema_agreement()
            req = ManagedThriftRequest(
                'system_rename_column_family', oldname, newname)
            return self._push_system_request(req, retries=retries, block=block)

        def system_rename_keyspace(self, oldname, newname, retries=None,
                                   block=True):
            req = ManagedThriftRequest(
                'system_rename_keyspace', oldname, newname)
            return self._push_system_request(req, retries=retries, block=block)

    # TODO: make friendly
    def system_add_column_family(self, cfDef, retries=None, block=True):
        req = ManagedThriftRequest('system_add_column_family', cfDef)
        return self._push_system_request(req, retries=retries, block=block)

    def system_update_column_family(self, cfDef, retries=None, block=True):
        req = ManagedThriftRequest('system_update_column_family', cfDef)
        return self._push_system_request(req, retries=retries, block=block)

    def system_add_keyspace(self, ksDef, retries=None, block=True):
        req = ManagedThriftRequest('system_add_keyspace', ksDef)
        return self._push_system_request(req, retries=retries, block=block)

    def system_update_keyspace(self, ksDef, retries=None, block=True):
        req = ManagedThriftRequest('system_update_keyspace', ksDef)
        return self._push_system_request(req, retries=retries, block=block)

    def describe_version(self, retries=None):
        req = ManagedThriftRequest('describe_version')
        return self.manager.pushRequest(req, retries=retries)

    def set_cql_version(self, version, retries=None):
        req = ManagedThriftRequest('set_cql_version', version)
        return self.manager.pushRequest(req, retries=retries)

    def execute_cql_query(self, query, compression=ttypes.Compression.NONE, retries=None):
        req = ManagedThriftRequest('execute_cql_query', query, compression)
        return self.manager.pushRequest(req, retries=retries)

    def execute_cql3_query(self, query, consistency=None, compression=ttypes.Compression.NONE, retries=None):
        consistency = consistency or self.consistency
        req = ManagedThriftRequest('execute_cql3_query', query, compression, consistency)
        return self.manager.pushRequest(req, retries=retries)

########NEW FILE########
__FILENAME__ = pool
# pool.py
#
# spread requests among connections to multiple nodes in a Cassandra cluster

"""
Quick start:

>>> my_seed_nodes = ['192.168.2.14', '192.168.2.15', '192.168.2.16']
>>> mypool = CassandraClusterPool(
...   my_seed_nodes, keyspace='MyKeyspace', pool_size=10)
>>> mypool.startService()
>>> mypool.get('Key12345', 'SomeCF')
<Deferred at 0x1b2b248>

CassandraClusterPool will respond to all the methods on CassandraClient, but
if you prefer to have separate CassandraClient instances, set your pool object
as their manager.

Some of the most useful additional methods on CassandraClusterPool:

   adjustPoolSize(newsize)      # change the size of the connection pool,
                                #   without interrupting ongoing requests
   addNode((address, port))     # manually add another node to the pool.
                                #   Normally this shouldn't be necessary; once
                                #   the pool can connect to one or more of your
                                #   your seed nodes, it can inspect the ring
                                #   and find the rest of the nodes.
   removeNode((address, port))  # manually remove a node from the pool. It will
                                #   be re-added later if it shows up in the
                                #   ring with a subsequent connection, though.
   set_keyspace(ksname)         # change the keyspace used for future requests
                                #   on this pool

TODO:

    * check cluster name on connecting to each new host, to make sure it's
      actually in the same cluster
    * take node error/connection history into account with add_connection_score
    * remove nodes that have been missing or unconnectable for too long
    * when seed node list is shofter than requested pool size, don't try to
      fill the pool completely until after a seed node is contacted and an
      initial live-node list collected

"""

import sys
import random
import socket
from time import time
from itertools import izip, groupby
from warnings import warn
from functools import partial

from twisted.application import service
from twisted.internet import defer, protocol, error
from twisted.python import failure, log
from thrift import Thrift
from thrift.transport import TTwisted, TTransport
from thrift.protocol import TBinaryProtocol

from telephus.protocol import (ManagedThriftRequest, ClientBusy,
                               InvalidThriftRequest)
from telephus.cassandra import ttypes, Cassandra
from telephus.client import CassandraClient
from telephus._sasl import ThriftSASLClientProtocol

ConsistencyLevel = ttypes.ConsistencyLevel


noop = lambda *a, **kw: None


SYSTEM_KEYSPACES = ("system", "system_traces", "system_auth", "dse_auth")


class NoKeyspacesAvailable(UserWarning):
    """
    Indicates CassandraClusterPool could not collect information about the
    cluster ring, in order to automatically add nodes to the pool.

    When Cassandra's thrift interface allows specifying null for describe_ring
    (like the underlying java interface already does), we can remove this.
    """


class NoNodesAvailable(Exception):
    """
    Indicates there are nodes to which we are allowed to make another immediate
    connection. The argument to this exception should be the expected number
    of seconds before a node /will/ be available.

    This should be handled internally; user code is not expected to see or
    handle this type of exception.
    """


def lame_log_insufficient_nodes(poolsize, pooltarget, pending_reqs, waittime):
    msg = ('(No candidate nodes to expand pool to target size %d from %d; '
           'there are %d pending requests.' % (
            pooltarget, poolsize, pending_reqs))
    if waittime is None:
        msg += ')'
    else:
        msg += ' Expected candidate node retry in %.1f seconds.)' % waittime
    log.msg(msg)


class CassandraPoolParticipantClient(TTwisted.ThriftClientProtocol):
    thriftFactory = TBinaryProtocol.TBinaryProtocolAcceleratedFactory

    def __init__(self):
        TTwisted.ThriftClientProtocol.__init__(self, Cassandra.Client,
                                               self.thriftFactory())

    def connectionMade(self):
        TTwisted.ThriftClientProtocol.connectionMade(self)
        self.factory.clientConnectionMade(self)

    def connectionLost(self, reason):
        # the TTwisted version of this call does not account for the
        # possibility of other things happening during the errback.
        tex = TTransport.TTransportException(
            type=TTransport.TTransportException.END_OF_FILE,
            message='Connection closed (%s)' % reason)
        while self.client._reqs:
            k = iter(self.client._reqs).next()
            v = self.client._reqs.pop(k)
            v.errback(tex)
        del self.client._reqs
        del self.client


class CassandraPoolParticipantSASLClient(ThriftSASLClientProtocol):
    thriftFactory = TBinaryProtocol.TBinaryProtocolAcceleratedFactory

    def __init__(self, sasl_cred_factory):
        ThriftSASLClientProtocol.__init__(self, Cassandra.Client,
                                          self.thriftFactory())
        self.sasl_cred_factory = sasl_cred_factory

    @defer.inlineCallbacks
    def connectionMade(self):
        # Get host-specific creds so we can properly # create the sasl client
        peer = self.transport.getPeer()
        sasl_kwargs = yield defer.maybeDeferred(
                self.sasl_cred_factory, peer.host, peer.port)
        self.createSASLClient(**sasl_kwargs)
        try:
            yield ThriftSASLClientProtocol.connectionMade(self)
        except Exception, exc:
            self.transport.loseConnection()
            self.factory.clientConnectionFailed(self.factory.connector, failure.Failure(exc))
        else:
            self.factory.clientConnectionMade(self)

    def connectionLost(self, reason):
        # the TTwisted version of this call does not account for the
        # possibility of other things happening during the errback.
        tex = TTransport.TTransportException(
            type=TTransport.TTransportException.END_OF_FILE,
            message='Connection closed (%s)' % reason)
        if self.client:
            while self.client._reqs:
                k = iter(self.client._reqs).next()
                v = self.client._reqs.pop(k)
                v.errback(tex)
            del self.client._reqs
            del self.client


class CassandraPoolReconnectorFactory(protocol.ClientFactory):
    connector = None
    last_error = None
    noisy = False

    # store the keyspace this connection is set to. we will take thrift
    # requests along with the keyspace in which they expect to be made, and
    # change keyspaces if necessary. this is done this way to avoid having
    # another layer of queueing for requests in this class (in addition to the
    # queue in CassandraClusterPool), or special logic here to pass on
    # set_keyspace calls from the service at the right time (so already-queued
    # requests still get made in their right keyspaces).
    keyspace = None

    def __init__(self, node, service, sasl_cred_factory=None):
        self.node = node
        # if self.service is None, don't bother doing anything. nobody loves
        # us.
        self.service = service
        self.my_proto = None
        self.job_d = self.jobphase = None
        if not sasl_cred_factory:
            self.protocol = partial(CassandraPoolParticipantClient)
        else:
            self.protocol = partial(CassandraPoolParticipantSASLClient, sasl_cred_factory)

    def clientConnectionMade(self, proto):
        assert self.my_proto is None
        assert self.jobphase is None, 'jobphase=%r' % (self.jobphase,)
        if self.service is None:
            proto.transport.loseConnection()
        else:
            self.my_proto = proto
            self.service.client_conn_made(self)

    def clientConnectionFailed(self, connector, reason):
        assert self.my_proto is None
        assert self.jobphase is None, 'jobphase=%r' % (self.jobphase,)
        self.my_proto = None
        if self.service is not None:
            self.connector = connector
            self.service.client_conn_failed(reason, self)

    def clientConnectionLost(self, connector, reason):
        self.logstate('clientConnectionLost')
        p = self.my_proto
        self.my_proto = None
        self.stop_working_on_queue()
        if p is not None and self.service is not None:
            self.connector = connector
            self.service.client_conn_lost(self, reason)

    def stopFactory(self):
        # idempotent
        self.logstate('stopFactory')
        protocol.ClientFactory.stopFactory(self)
        if self.connector:
            try:
                self.connector.stopConnecting()
            except error.NotConnectingError:
                pass
        self.connector = None
        p = self.my_proto
        self.my_proto = None
        self.stop_working_on_queue()
        if p is not None and p.transport is not None:
            p.transport.loseConnection()

    def isConnecting(self):
        if self.connector is None:
            if self.my_proto is None:
                # initial connection attempt
                return True
            else:
                # initial connection succeeded and hasn't died
                return False
        return self.connector.state == 'connecting'

    def retry(self):
        """
        Retry this factory's connection. It is assumed that a previous
        connection was attempted and failed- either before or after a
        successful connection.
        """

        if self.connector is None:
            raise ValueError("No connector to retry")
        if self.service is None:
            return
        self.connector.connect()

    def prep_connection(self, creds=None, keyspace=None, node_auto_discovery=True):
        """
        Do login and set_keyspace tasks as necessary, and also check this
        node's idea of the Cassandra ring. Expects that our connection is
        alive.

        Return a Deferred that will fire with the ring information, or be
        errbacked if something goes wrong.
        """
        d = defer.succeed(None)

        if creds is not None:
            d.addCallback(lambda _: self.my_login(creds))
        if keyspace is not None:
            d.addCallback(lambda _: self.my_set_keyspace(keyspace))
        if node_auto_discovery:
            d.addCallback(lambda _: self.my_describe_ring(keyspace))

        return d

    # The following my_* methods are for internal use, to facilitate the
    # management of the pool and the queries we get. The user should make
    # use of the methods on CassandraClient.

    def my_login(self, creds):
        req = ttypes.AuthenticationRequest(credentials=creds)
        return self.execute(ManagedThriftRequest('login', req))

    def my_set_keyspace(self, keyspace):
        return self.execute(ManagedThriftRequest('set_keyspace', keyspace))

    def my_describe_ring(self, keyspace=None):
        if keyspace is None or keyspace in SYSTEM_KEYSPACES:
            d = self.my_pick_non_system_keyspace()
        else:
            d = defer.succeed(keyspace)
        d.addCallback(lambda k: self.execute(ManagedThriftRequest(
            'describe_ring', k)))

        def suppress_no_keyspaces_error(f):
            f.trap(NoKeyspacesAvailable)
            return ()

        d.addErrback(suppress_no_keyspaces_error)
        return d

    def my_describe_version(self):
        return self.execute(ManagedThriftRequest('describe_version'))

    def my_describe_keyspaces(self):
        return self.execute(ManagedThriftRequest('describe_keyspaces'))

    def my_pick_non_system_keyspace(self):
        """
        Find a keyspace in the cluster which is not 'system', for the purpose
        of getting a valid ring view. Can't use 'system' or null.
        """
        d = self.my_describe_keyspaces()

        def pick_non_system(klist):
            for k in klist:
                if k.name not in SYSTEM_KEYSPACES:
                    return k.name
            err = NoKeyspacesAvailable("Can't gather information about the "
                                       "Cassandra ring; no non-system "
                                       "keyspaces available")
            warn(err)
            raise err
        d.addCallback(pick_non_system)
        return d

    def store_successful_keyspace_set(self, val, ksname):
        self.keyspace = ksname
        return val

    def execute(self, req, keyspace=None):
        if self.my_proto is None:
            return defer.fail(error.ConnectionClosed(
                                    'Lost connection before %s request could be made'
                                    % (req.method,)))
        method = getattr(self.my_proto.client, req.method, None)
        if method is None:
            raise InvalidThriftRequest(
                "don't understand %s request" % req.method)

        d = defer.succeed(0)

        if req.method == 'set_keyspace':
            newksname = req.args[0]
            d.addCallback(lambda _: method(newksname))
            d.addCallback(self.store_successful_keyspace_set, newksname)
        else:
            if keyspace is not None and keyspace != self.keyspace:
                d.addCallback(lambda _: self.my_set_keyspace(keyspace))
            d.addCallback(lambda _: method(*(req.args)))
        return d

    def clear_job(self, x):
        self.logstate('clear job %s (result %r)', self.jobphase, x)
        self.jobphase = None
        self.job_d = None
        return x

    def job(self, _name, _func, *args, **kw):
        self.logstate('start job %s' % _name)
        if self.jobphase is not None:
            raise ClientBusy('Tried to start job phase %s while in %s'
                             % (_name, self.jobphase))
        self.jobphase = _name
        d = defer.maybeDeferred(_func, *args, **kw)
        self.job_d = d
        d.addBoth(self.clear_job)
        return d

    def process_request_error(self, err, req, keyspace, req_d, retries):
        self.logstate('process_request_error: %s, retries=%d' % (err, retries))
        self.last_error = err
        if (retries > 0 and self.service is not None and
            err.check(*self.service.retryables)):
            self.logstate('-- resubmit --')
            assert self.jobphase is None, \
                    'Factory might retry its own fatal error'
            self.service.resubmit(req, keyspace, req_d, retries - 1)
        else:
            self.logstate('-- giving up [retries=%d service=%s err=%s] --'
                          % (retries, self.service, err.value))
            req_d.errback(err)

    def work_on_request(self, reqtuple):
        req, keyspace, req_d, retries = reqtuple
        if req_d.called:
            # cancelled while pending in the queue
            return
        d = self.job('pending_request', self.execute, req, keyspace)
        d.addCallback(req_d.callback)
        d.addErrback(self.process_request_error, req, keyspace, req_d, retries)
        return d

    def maybe_do_more_work(self, _, q):
        # it's possible this is being called as part of the immediate callback
        # chain after the protocol's connectionLost errbacking. if so, our own
        # connectionLost hasn't been called yet. allow all current processing
        # to finish before deciding whether we get to do more.
        def _real_maybe_do_more_work():
            if not self.keep_working:
                self.stopFactory()
            elif self.service is not None:
                self.work_on_queue(q)
        if self.service is not None:
            self.service.reactor.callLater(0, _real_maybe_do_more_work)

    def scream_like_a_little_girl(self, fail):
        if self.service is not None:
            complain = self.service.err
        else:
            complain = log.err
        complain(fail, "Factory for connection to %s had problems dealing with"
                       " the queue" % (self.node,))
        # don't process more requests

    def work_on_queue(self, q):
        self.logstate('work_on_queue')
        self.keep_working = True
        d = self.job('queue_getter', q.get)
        d.addCallback(self.work_on_request)
        d.addCallback(self.maybe_do_more_work, q)
        d.addErrback(lambda f: f.trap(defer.CancelledError))
        d.addErrback(self.scream_like_a_little_girl)
        return d

    def stop_working_on_queue(self):
        self.logstate('stop_working_on_queue [jobphase=%s]' % self.jobphase)
        self.keep_working = False
        if self.jobphase == 'queue_getter':
            self.job_d.cancel()

    def finish_and_die(self):
        """
        If there is a request pending, let it finish and be handled, then
        disconnect and die. If not, cancel any pending queue requests and
        just die.
        """
        self.logstate('finish_and_die')
        self.stop_working_on_queue()
        if self.jobphase != 'pending_request':
            self.stopFactory()

    def logstate(self, msg, *args):
        if getattr(self, 'debugging', False):
            if msg and args: msg = msg % args
            log.msg('CPRF 0x%x (node %s) [%s]: %s'
                    % (id(self), self.node, self.jobphase, msg))


class CassandraKeyspaceConnection:
    """
    Glue class which acts as a manager for CassandraClient but passes requests
    on to a CassandraClusterPool- in the case where you want all requests
    through this manager to be guaranteed to go to the same keyspace,
    regardless of what other consumers of the CassandraClusterPool might do.
    """

    def __init__(self, pool, keyspace):
        self.pool = pool
        self.keyspace = keyspace

    def pushRequest(self, req, retries=None):
        return self.pool.pushRequest(
            req, retries=retries, keyspace=self.keyspace)

    def set_keyspace(self, keyspace):
        raise RuntimeError("Don't call set_keyspace on a "
                           "CassandraKeyspaceConnection")

    def login(self, credentials):
        return self.pool.login(credentials)


class CassandraNode:
    """
    Represent a Cassandra node, in the same sense Cassandra uses.

    Keep track of connection success and failure history for some time, so
    that smarter decisions can be made about where to make new connections
    within a pool.

    Implement exponential backoff in reconnect time when connections fail.

    @ivar history_interval: Keep history entries for at least this many seconds

    @ivar max_delay: Forced delay between connection attempts will not exceed
        this value (although actual connection attempts may be farther apart
        than this, if the pool has enough connections without it)
    """

    history_interval = 86400
    max_delay = 180
    initial_delay = 0.05

    # NIST backoff factors
    factor = protocol.ReconnectingClientFactory.factor
    jitter = protocol.ReconnectingClientFactory.jitter

    def __init__(self, host, port):
        self.host = host
        self.port = port
        self.reconnect_delay = self.initial_delay
        self.can_reconnect_at = 0

        # a list of (timestamp, error) tuples, least recent first.
        # (timestamp, None) tuples will be inserted on a successful connection.
        self.history = []

    def record_hist(self, value):
        now = time()
        if (self.history and
            self.history[0][0] < (now - self.history_interval * 2)):
            # it has been 2x history_interval; prune history
            cutoff = now - self.history_interval
            for n, (tstamp, hval) in enumerate(self.history):
                if tstamp > cutoff:
                    break
            self.history = self.history[n:]
        self.history.append((now, value))

    def conn_success(self):
        self.reconnect_delay = self.initial_delay
        self.can_reconnect_at = 0
        self.record_hist(None)

    def conn_fail(self, reason):
        # these tend to come in clusters. if the same error was received
        # recently (before the reconnect delay expired), return False to
        # indicate the event is not 'notable', and don't bump the delay
        # to a higher level.
        is_notable = self.is_failure_notable(reason)
        self.record_hist(reason.value)
        if is_notable:
            newdelay = min(self.reconnect_delay * self.factor, self.max_delay)
            if self.jitter:
                newdelay = random.normalvariate(
                    newdelay, newdelay * self.jitter)
            self.reconnect_delay = newdelay
            self.can_reconnect_at = time() + newdelay
        else:
            # reset but use the same delay
            self.can_reconnect_at = time() + self.reconnect_delay
        return is_notable

    def is_failure_notable(self, reason):
        try:
            tstamp, last_err = self.history[-1]
        except IndexError:
            pass
        else:
            if type(last_err) is type(reason.value):
                if time() < self.can_reconnect_at:
                    return False
        return True

    def seconds_until_connect_ok(self):
        return self.can_reconnect_at - time()

    def __str__(self):
        return '<%s %s:%s @0x%x>' % (self.__class__.__name__,
                                     self.host, self.port, id(self))

    __repr__ = __str__

    def __eq__(self, other):
        return self.__class__ == other.__class__ \
           and self.host == other.host \
           and self.port == other.port

    def __cmp__(self, other):
        return cmp((self.host, self.port), (other.host, other.port))

    def __hash__(self):
        return hash((self.__class__, self.host, self.port))


def get_endpoints_from_tokenrange(tokenrange):
    if hasattr(tokenrange, "rpc_endpoints") and tokenrange.rpc_endpoints:
        def good_addr(ep, rpc):
            return rpc if not rpc.startswith("0.0.0.0") else ep
        return map(good_addr, tokenrange.endpoints, tokenrange.rpc_endpoints)
    else:
        return tokenrange.endpoints


class CassandraClusterPool(service.Service, object):
    """
    Manage a pool of connections to nodes in a Cassandra cluster.

    Requests made to the pool will go to whichever host is the least loaded (as
    far as this class can tell). If the requests specify multiple retries, the
    retries will be executed on different hosts if possible.

    Will periodically check an unparticular connection to see if new nodes can
    be found, and add them to the pool.

    Note that like most Services, the pool will not start until startService is
    called. If you have a parent Service (like a
    L{twisted.service.application.Application} instance), set that to be this
    service's parent:

        >>> cluster_pool.setServiceParent(application)

    and the startService() and stopService() methods will be called when
    appropriate.

    @ivar default_cassandra_thrift_port: just what it says on the tin

    @ivar max_connections_per_node: do our best not not to exceed this many
        connections to a single Cassandra endpoint

    @type max_connections_per_node: int

    @ivar on_insufficient_nodes: if set to a callback, this will be called
        in the event that there are no valid places to connect to expand
        the pool to its target size. Regardless of actions taken by this
        callback, the service will wait until a node is expected to be
        available and then check again.

    @type on_insufficient_nodes: callback taking four arguments: the current
        size of the connection pool, the target size of the pool, the
        number of pending requests, and the number of seconds before a
        candidate node will be available to try connecting (or None, if no
        candidate is in sight).

    @ivar on_insufficient_conns: if set to a callback, this will be called
        when a request is made and all current connections are busy. The
        request will still be expected to go through, once another connection
        is available, but it may be helpful to know how often this is
        happening and possibly expand the pool

    @type on_insufficient_conns: callback taking two arguments: the current
        size of the connection pool, and the number of requests which are
        pending in the CassandraClusterPool queue

    @ivar request_retries: the default number of retries which will be
        performed for requests when the retry number is unspecified

    @type request_retries: int

    @ivar retryables: A list of Exception types which, if they are raised in
        the course of a Cassandra Thrift operation, mean both that (a) the
        request can be tried again on another connection, and that (b) if the
        connection was lost right after this error, it can be retried
        immediately
    """

    default_cassandra_thrift_port = 9160
    max_connections_per_node = 25
    on_insufficient_nodes = staticmethod(lame_log_insufficient_nodes)
    on_insufficient_conns = staticmethod(noop)
    request_retries = 4
    conn_factory = CassandraPoolReconnectorFactory

    retryables = [IOError, socket.error, Thrift.TException,
                  TTransport.TTransportException]

    def __init__(self, seed_list, keyspace=None, creds=None, thrift_port=None,
                 pool_size=None, conn_timeout=10, bind_address=None,
                 log_cb=log.msg, reactor=None, ssl_ctx_factory=None,
                 sasl_cred_factory=None, auto_node_discovery=True):
        """
        Initialize a CassandraClusterPool.

        @param keyspace: If given and not None, determines the keyspace to
            which all connections in this pool will be made.

        @param creds: Credentials to use to authenticate Cassandra connections

        @type creds: A dict (or other mapping) of strings to strings

        @param seed_list: An initial set of host addresses which, if
            connectable, are part of this cluster.

        @type seed_list: iterable

        @param thrift_port: The port to use for connections to Cassandra nodes

        @param pool_size: The target size for the connection pool. Naturally,
            the actual size may be higher or lower as nodes connect and
            disconnect, but an effort will be made to adjust toward this size.

        @type pool_size: int

        @param conn_timeout: The number of seconds before a pending connection
            is deemed unsuccessful and aborted. Of course, when a connection
            error can be detected before this time, the connection will be
            aborted appropriately.

        @type conn_timeout: float

        @param bind_address: The local interface to which to bind when making
            outbound connections. Default: determined by the system's socket
            layer.

        @type bind_address: str

        @param log_cb: A callable which is expected to work like
            L{twisted.python.log.msg}. Will be used when certain connection
            and disconnection events occur. The default is log.msg.

        @param reactor: The reactor instance to use when starting thrift
            connections or setting timers.

        @param ssl_ctx_factory: A L{twisted.internet.ssl.ClientContextFactory}
            instance. If not None, SSL connections will be opened using
            the provided context factory; if None, SSL will not be used.

        @param sasl_cred_factory: A callable which, when called with two
            parameters, a host and port, returns a dictionary of keyword
            arguments to be used for the L{puresasl.client.SASLClient}
            constructor. If supplied, the ThriftSASLClientProtocol will
            be used.

        @param auto_node_discovery: Bool that Enables/Disables node
            auto-discovery, defaults to True
        """

        self.seed_list = list(seed_list)
        if thrift_port is None:
            thrift_port = self.default_cassandra_thrift_port
        self.thrift_port = thrift_port
        if pool_size is None:
            pool_size = len(self.seed_list)
        self.target_pool_size = pool_size
        self.log = log_cb
        self.conn_timeout = conn_timeout
        self.bind_address = bind_address
        self.keyspace = keyspace
        self.creds = creds
        self.ssl_ctx_factory = ssl_ctx_factory
        self.sasl_cred_factory = sasl_cred_factory
        self.request_queue = defer.DeferredQueue()
        self.future_fill_pool = None
        self.removed_nodes = set()
        self._client_instance = CassandraClient(self)
        self.auto_node_discovery = auto_node_discovery

        if reactor is None:
            from twisted.internet import reactor
        self.reactor = reactor

        self.retryables.extend((ttypes.TimedOutException,
                                ttypes.UnavailableException))

        # A set of CassandraNode instances representing known nodes. This
        # includes nodes from the initial seed list, nodes seen in
        # describe_ring calls to existing nodes, and nodes explicitly added
        # by the addNode() method. Nodes are only removed from this set if
        # no connections have been successful in self.forget_node_interval
        # seconds, or by an explicit call to removeNode().
        self.nodes = set()

        # A set of CassandraPoolReconnectorFactory instances corresponding to
        # connections which are either live or pending. Failed attempts to
        # connect will remove a connector from this set. When connections are
        # lost, an immediate reconnect will be attempted.
        self.connectors = set()

        # A collection of objects from self.connectors corresponding to
        # existing, working (as far as we know) connections. This will be
        # derivable from self.connectors, but hopefully will be maintained to
        # present a good snapshot of what is alive, now, and what is not.
        # This is stored in a deque so that it can be efficiently rotated
        # to distribute requests.
        self.good_conns = set()

        # A set of CassandraPoolReconnectorFactory instances, formerly in
        # self.connectors, the connections for which are draining. No new
        # requests should be fed to these instances; they are tracked only so
        # that they can be terminated more fully in case this service is shut
        # down before they finish.
        self.dying_conns = set()

    def startService(self):
        service.Service.startService(self)
        for addr in self.seed_list:
            if isinstance(addr, tuple) and len(addr) == 2:
                self.addNode(addr)
            else:
                self.addNode((addr, self.thrift_port))
        self.fill_pool()

    def stopService(self):
        service.Service.stopService(self)
        if (self.future_fill_pool is not None and
            self.future_fill_pool.active()):
            self.future_fill_pool.cancel()
        for factory in self.connectors.copy():
            factory.service = None
            factory.stopFactory()
        self.connectors = set()
        self.good_conns = set()
        self.dying_conns = set()

    def addNode(self, node):
        if not isinstance(node, CassandraNode):
            node = CassandraNode(*node)
        if node in self.nodes:
            raise ValueError("%s is already known" % (node,))
        if node in self.removed_nodes:
            self.removed_nodes.remove(node)
        self.nodes.add(node)

    def removeNode(self, node):
        if not isinstance(node, CassandraNode):
            node = CassandraNode(*node)
        for f in self.all_connectors_to(node):
            f.stopFactory()
            self.remove_connector(f)
        for f in self.dying_conns.copy():
            if f.node == node:
                f.stopFactory()
                self.remove_connector(f)
        self.removed_nodes.add(node)
        self.nodes.remove(node)
        self.fill_pool()

    def err(self, _stuff=None, _why=None, **kw):
        if _stuff is None:
            _stuff = failure.Failure()
        kw['isError'] = True
        kw['why'] = _why
        if isinstance(_stuff, failure.Failure):
            self.log(failure=_stuff, **kw)
        elif isinstance(_stuff, Exception):
            self.log(failure=failure.Failure(_stuff), **kw)
        else:
            self.log(repr(_stuff), **kw)

    # methods for inspecting current connection state
    def all_connectors(self):
        return self.connectors.copy()

    def num_connectors(self):
        """
        Return the total number of current connectors, including both live and
        pending connections.
        """
        return len(self.connectors)

    def all_connectors_to(self, node):
        return [f for f in self.connectors if f.node == node]

    def num_connectors_to(self, host):
        return len(self.all_connectors_to(host))

    def all_active_conns(self):
        return self.good_conns.copy()

    def num_active_conns(self):
        return len(self.good_conns)

    def all_active_conns_to(self, node):
        return [f for f in self.good_conns if f.node == node]

    def num_active_conns_to(self, node):
        return len(self.all_active_conns_to(node))

    def all_working_conns(self):
        return [f for f in self.good_conns if f.jobphase == 'pending_request']

    def num_working_conns(self):
        return len(self.all_working_conns())

    def all_pending_conns(self):
        return self.connectors - self.good_conns

    def num_pending_conns(self):
        return len(self.all_pending_conns())

    def all_pending_conns_to(self, node):
        return [f for f in self.all_pending_conns() if f.node == node]

    def num_pending_conns_to(self, node):
        return len(self.all_pending_conns_to(node))

    def add_connection_score(self, node):
        """
        Return a numeric value that determines this node's score for adding
        a new connection. A negative value indicates that no connections
        should be made to this node for at least that number of seconds.
        A value of -inf indicates no connections should be made to this
        node for the foreseeable future.

        This score should ideally take into account the connectedness of
        available nodes, so that those with less current connections will
        get more.
        """

        # TODO: this should ideally take node history into account

        conntime = node.seconds_until_connect_ok()
        if conntime > 0:
            self.log("not considering %r for new connection; has %r left on "
                     "connect blackout" % (node, conntime))
            return -conntime
        numconns = self.num_connectors_to(node)
        if numconns >= self.max_connections_per_node:
            return float('-Inf')
        return sys.maxint - numconns

    def adjustPoolSize(self, newsize):
        """
        Change the target pool size. If we have too many connections already,
        ask some to finish what they're doing and die (preferring to kill
        connections to the node that already has the most connections). If
        we have too few, create more.
        """

        if newsize < 0:
            raise ValueError("pool size must be nonnegative")
        self.log("Adjust pool size from %d to %d." % (
            self.target_pool_size, newsize))
        self.target_pool_size = newsize
        self.kill_excess_pending_conns()
        self.kill_excess_conns()
        self.fill_pool()

    def update_known_nodes(self, ring):
        for tokenrange in ring:
            endpoints = get_endpoints_from_tokenrange(tokenrange)
            for addr in endpoints:
                if ':' in addr:
                    addr, port = addr.split(':', 1)
                    port = int(port)
                else:
                    port = self.thrift_port
                node = CassandraNode(addr, port)
                if node not in self.removed_nodes and node not in self.nodes:
                    self.addNode(node)

    def choose_nodes_to_connect(self):
        while True:
            nodes = list(self.nodes)
            scores = map(self.add_connection_score, nodes)
            bestscore, bestnode = max(zip(scores, nodes))
            if bestscore < 0:
                raise NoNodesAvailable(-bestscore)
            yield bestnode

    def choose_pending_conns_to_kill(self):
        # prefer to junk pending conns to most-redundantly-connected node
        while True:
            pending_conns = self.all_pending_conns()
            if len(pending_conns) == 0:
                break
            yield max(
                pending_conns, key=lambda f: self.num_connectors_to(f.node))

    def choose_conns_to_kill(self):
        nodegetter = lambda f: f.node
        # prefer to junk conns to most-redundantly-connected node
        while True:
            active_conns = self.all_active_conns()
            if len(active_conns) == 0:
                break

            nodes_and_conns = groupby(
                sorted(active_conns, key=nodegetter), nodegetter)
            nodes_and_counts = (
                (n, len(list(conns))) for (n, conns) in nodes_and_conns)
            bestnode, bestcount = max(
                nodes_and_counts, key=lambda (n, count): count)
            # should be safe from IndexError
            yield self.all_active_conns_to(bestnode)[0]

    def kill_excess_pending_conns(self):
        killnum = self.num_connectors() - self.target_pool_size
        if killnum <= 0:
            return
        for n, f in izip(xrange(killnum), self.choose_pending_conns_to_kill()):
            self.log("Aborting pending conn to %r" % (f.node,))
            f.stopFactory()
            self.remove_connector(f)

    def kill_excess_conns(self):
        need_to_kill = self.num_active_conns() - self.target_pool_size
        if need_to_kill <= 0:
            return
        for n, f in izip(xrange(need_to_kill), self.choose_conns_to_kill()):
            self.log("Draining conn to %r" % (f.node,))
            f.finish_and_die()
            self.remove_connector(f)
            self.dying_conns.add(f)

    def fill_pool(self):
        """
        Add connections as necessary to meet the target pool size. If there
        are no nodes to connect to (because we maxed out connections-per-node
        on all active connections and any unconnected nodes have pending
        reconnect timers), call the on_insufficient_nodes callback.
        """

        need = self.target_pool_size - self.num_connectors()
        if need <= 0:
            return
        try:
            for num, node in izip(
                xrange(need), self.choose_nodes_to_connect()):
                self.make_conn(node)
        except NoNodesAvailable, e:
            waittime = e.args[0]
            if waittime == float('Inf'):
                waittime = None
            pending_requests = len(self.request_queue.pending)
            if self.on_insufficient_nodes:
                self.on_insufficient_nodes(
                    self.num_active_conns(), self.target_pool_size,
                    pending_requests, waittime)
            self.schedule_future_fill_pool(e.args[0])
            if self.num_connectors() == 0 and pending_requests > 0:
                if self.on_insufficient_conns:
                    self.on_insufficient_conns(self.num_connectors(),
                                               pending_requests)

    def schedule_future_fill_pool(self, seconds):
        if seconds == float('Inf'):
            return
        if self.future_fill_pool is None or not self.future_fill_pool.active():
            self.future_fill_pool = self.reactor.callLater(
                seconds, self.fill_pool)
        else:
            self.future_fill_pool.reset(seconds)

    def make_conn(self, node):
        self.log('Adding connection to %s' % (node,))
        f = self.conn_factory(node, self, self.sasl_cred_factory)
        bindaddr = self.bind_address
        if bindaddr is not None and isinstance(bindaddr, str):
            bindaddr = (bindaddr, 0)
        if self.ssl_ctx_factory:
            self.reactor.connectSSL(node.host, node.port, f,
                                    contextFactory=self.ssl_ctx_factory,
                                    timeout=self.conn_timeout,
                                    bindAddress=bindaddr)
        else:
            self.reactor.connectTCP(node.host, node.port, f,
                                    timeout=self.conn_timeout,
                                    bindAddress=bindaddr)
        self.connectors.add(f)

    def remove_good_conn(self, f):
        try:
            self.good_conns.remove(f)
        except KeyError:
            pass

    def remove_connector(self, f):
        self.remove_good_conn(f)
        try:
            self.connectors.remove(f)
        except KeyError:
            try:
                self.dying_conns.remove(f)
            except KeyError:
                pass

    def client_conn_failed(self, reason, f):
        is_notable = f.node.conn_fail(reason)
        f.stopFactory()
        self.remove_connector(f)
        if is_notable:
            self.err(reason, 'Thrift pool connection to %s failed' % (f.node,))
        self.fill_pool()

    def client_conn_made(self, f):
        d = f.prep_connection(self.creds, self.keyspace, self.auto_node_discovery)
        d.addCallback(self.client_ready, f)
        d.addErrback(self.client_conn_failed, f)

    def client_ready(self, ring, f):
        # when auto_node_discovery is false, ring will not be populated
        if ring:
            self.update_known_nodes(ring)

        f.node.conn_success()
        self.good_conns.add(f)
        self.log('Successfully added connection to %s to the pool' % (f.node,))
        f.work_on_queue(self.request_queue)

    def client_conn_lost(self, f, reason):
        if reason.check(error.ConnectionDone):
            self.log(
                'Thrift pool connection to %s failed (cleanly)' % (f.node,))
        else:
            self.err(
                reason, 'Thrift pool connection to %s was lost' % (f.node,))
        if f.last_error is None or f.last_error.check(*self.retryables):
            self.log('Retrying connection right away')
            self.remove_good_conn(f)
            f.retry()
        else:
            f.node.conn_fail(reason)
            f.stopFactory()
            self.remove_connector(f)
            self.fill_pool()

    def pushRequest(self, req, retries=None, keyspace=None):
        if keyspace is None:
            keyspace = self.keyspace
        retries = retries if retries is not None else self.request_retries
        req_d = defer.Deferred()
        self.pushRequest_really(req, keyspace, req_d, retries)
        return req_d

    def pushRequest_really(self, req, keyspace, req_d, retries):
        call_insuff_conns = False
        if len(self.request_queue.waiting) == 0:
            # no workers are immediately available
            if self.on_insufficient_conns:
                call_insuff_conns = True
        self.request_queue.put((req, keyspace, req_d, retries))
        if call_insuff_conns:
            self.on_insufficient_conns(self.num_connectors(),
                                       len(self.request_queue.pending))

    def resubmit(self, req, keyspace, req_d, retries):
        """
        Push this request to the front of the line, just to be a jerk.
        """
        self.log('resubmitting %s request' % (req.method,))
        self.pushRequest_really(req, keyspace, req_d, retries)
        try:
            self.request_queue.pending.remove((req, keyspace, req_d, retries))
        except ValueError:
            # it's already been scooped up
            pass
        else:
            self.request_queue.pending.insert(
                0, (req, keyspace, req_d, retries))

    def set_keyspace(self, keyspace):
        """
        Change the keyspace which will be used for subsequent requests to this
        CassandraClusterPool, and return a Deferred that will fire once it can
        be verified that connections can successfully use that keyspace.

        If something goes wrong trying to change a connection to that keyspace,
        the Deferred will errback, and the keyspace to be used for future
        requests will not be changed.

        Requests made between the time this method is called and the time that
        the returned Deferred is fired may be made in either the previous
        keyspace or the new keyspace. If you may need to make use of multiple
        keyspaces at the same time in the same app, consider using the
        specialized CassandraKeyspaceConnection interface provided by the
        keyspaceConnection method.
        """

        # push a real set_keyspace on some (any) connection; the idea is that
        # if it succeeds there, it is likely to succeed everywhere, and vice
        # versa.  don't bother waiting for all connections to change- some of
        # them may be doing long blocking tasks and by the time they're done,
        # the keyspace might be changed again anyway
        d = self.pushRequest(ManagedThriftRequest('set_keyspace', keyspace))

        def store_keyspace(_):
            self.keyspace = keyspace
        d.addCallback(store_keyspace)
        return d

    def __getattr__(self, name):
        """
        Make CassandraClusterPool act like its own CassandraClient when
        the user wants to use it that way
        """
        return getattr(self._client_instance, name)

    def get_consistency(self):
        return self._client_instance.consistency

    def set_consistency(self, value):
        self._client_instance.consistency = value

    consistency = property(get_consistency, set_consistency)

    def keyspaceConnection(self, keyspace, consistency=ConsistencyLevel.ONE):
        """
        Return a CassandraClient instance which uses this CassandraClusterPool
        by way of a CassandraKeyspaceConnection, so that all requests made
        through it are guaranteed to go to the given keyspace, no matter what
        other consumers of this pool may do.
        """
        conn = CassandraKeyspaceConnection(self, keyspace)
        return CassandraClient(conn, consistency=consistency)

    def __str__(self):
        return '<%s: [%d nodes known] [%d connections]>' \
               % (self.__class__.__name__, len(self.nodes),
                  self.num_active_conns())

    __repr__ = __str__

########NEW FILE########
__FILENAME__ = protocol
from sys import exc_info

from thrift.transport import TTwisted
from thrift.protocol import TBinaryProtocol
from twisted.internet.protocol import ReconnectingClientFactory
from twisted.internet import defer
from twisted.internet.error import UserError
from twisted.python import failure

from telephus.cassandra import Cassandra, ttypes
from telephus._sasl import ThriftSASLClientProtocol


class ClientBusy(Exception):
    pass


class InvalidThriftRequest(Exception):
    pass


class ManagedThriftRequest(object):
    def __init__(self, method, *args):
        self.method = method
        self.args = args


class ManagedThriftClientProtocol(TTwisted.ThriftClientProtocol):

    # used for connectionMade() and connectionLost(), change these for
    # custom behavior
    _parent_protocol = TTwisted.ThriftClientProtocol

    def __init__(self, iprot_factory, oprot_factory=None, keyspace=None):
        TTwisted.ThriftClientProtocol.__init__(
            self, Cassandra.Client, iprot_factory, oprot_factory)
        self.iprot_factory = iprot_factory
        self.deferred = None
        self.aborted = False
        self.keyspace = keyspace

    @defer.inlineCallbacks
    def connectionMade(self):
        try:
            yield defer.maybeDeferred(self._parent_protocol.connectionMade, self)
        except Exception:
            self.transport.loseConnection()
            raise

        # self.started is created and fired by ThriftClientProtocol
        yield self.started

        # self.client is created in ThriftClientProtocol.connectionMade()
        self.client.protocol = self

        self.setupConnection() \
            .addCallbacks(self.setupComplete, self.setupFailed)

    def connectionLost(self, reason=None):
        if not self.aborted:
            # don't allow parent class to raise unhandled TTransport
            # exceptions, the manager handled our failure
            self._parent_protocol.connectionLost(self, reason)
        self.factory.clientGone(self)

    def setupConnection(self):
        if self.keyspace:
            return self.client.set_keyspace(self.keyspace)
        else:
            return defer.succeed(None)

    def setupComplete(self, res=None):
        self.factory.resetDelay()
        self.factory.clientIdle(self, res)

    def setupFailed(self, err):
        self.transport.loseConnection()
        self.factory.clientSetupFailed(err)

    def _complete(self, res=None):
        self.deferred = None
        self.factory.clientIdle(self)
        return res

    def submitRequest(self, request):
        if self.deferred:
            raise ClientBusy

        fun = getattr(self.client, request.method, None)
        if not fun:
            raise InvalidThriftRequest

        self.deferred = fun(*(request.args))
        return self.deferred.addBoth(self._complete)

    def abort(self):
        self.aborted = True
        self.transport.loseConnection()


class AuthenticatedThriftClientProtocol(ManagedThriftClientProtocol):

    def __init__(self, keyspace, credentials, iprot_factory,
                 oprot_factory=None, **kwargs):
        ManagedThriftClientProtocol.__init__(
            self, iprot_factory, oprot_factory, keyspace=keyspace, **kwargs)
        self.credentials = credentials

    def setupConnection(self):
        auth = ttypes.AuthenticationRequest(credentials=self.credentials)
        d = self.client.login(auth)
        return d.addCallback(
            lambda _: ManagedThriftClientProtocol.setupConnection(self))


class SASLThriftClientProtocol(ManagedThriftClientProtocol, ThriftSASLClientProtocol):

    _parent_protocol = ThriftSASLClientProtocol

    def __init__(self, iprot_factory, oprot_factory=None, keyspace=None, **sasl_kwargs):
        ThriftSASLClientProtocol.__init__(self, Cassandra.Client,
                iprot_factory, oprot_factory, **sasl_kwargs)
        ManagedThriftClientProtocol.__init__(self, iprot_factory, oprot_factory, keyspace)

    dataReceived = ThriftSASLClientProtocol.dataReceived
    stringReceived = ThriftSASLClientProtocol.stringReceived
    dispatch = ThriftSASLClientProtocol.dispatch


class ManagedCassandraClientFactory(ReconnectingClientFactory):
    maxDelay = 45
    thriftFactory = TBinaryProtocol.TBinaryProtocolAcceleratedFactory
    protocol = ManagedThriftClientProtocol

    def __init__(self, keyspace=None, retries=0, credentials=None, sasl_kwargs=None):
        self.deferred = defer.Deferred()
        self.queue = defer.DeferredQueue()
        self.continueTrying = True
        self._protos = []
        self._pending = []
        self.request_retries = retries
        self.keyspace = keyspace
        self.credentials = credentials
        self.sasl_kwargs = sasl_kwargs
        if credentials:
            self.protocol = AuthenticatedThriftClientProtocol
        elif sasl_kwargs:
            self.protocol = SASLThriftClientProtocol

    def _errback(self, reason=None):
        if self.deferred:
            self.deferred.errback(reason)
            self.deferred = None

    def _callback(self, value=None):
        if self.deferred:
            self.deferred.callback(value)
            self.deferred = None

    def clientConnectionFailed(self, connector, reason):
        ReconnectingClientFactory.clientConnectionFailed(
            self, connector, reason)
        self._errback(reason)

    def clientSetupFailed(self, reason):
        self._errback(reason)

    def clientIdle(self, proto, result=True):
        if proto not in self._protos:
            self._protos.append(proto)
        self.submitRequest(proto)
        self._callback(result)

    def buildProtocol(self, addr):
        if self.credentials:
            p = self.protocol(self.keyspace,
                              self.credentials,
                              self.thriftFactory())
        elif self.sasl_kwargs:
            p = self.protocol(self.thriftFactory(),
                              keyspace=self.keyspace,
                              **self.sasl_kwargs)
        else:
            p = self.protocol(self.thriftFactory(),
                              keyspace=self.keyspace)
        p.factory = self
        return p

    def clientGone(self, proto):
        try:
            self._protos.remove(proto)
        except ValueError:
            pass

    def set_keyspace(self, keyspace):
        """ switch all connections to another keyspace """
        self.keyspace = keyspace
        dfrds = []
        for p in self._protos:
            dfrds.append(p.submitRequest(ManagedThriftRequest(
                'set_keyspace', keyspace)))
        return defer.gatherResults(dfrds)

    def login(self, credentials):
        """ authenticate all connections """
        dfrds = []
        for p in self._protos:
            dfrds.append(p.submitRequest(ManagedThriftRequest('login',
                    ttypes.AuthenticationRequest(credentials=credentials))))
        return defer.gatherResults(dfrds)

    def submitRequest(self, proto):
        def reqError(err, req, d, r):
            if err.check(ttypes.InvalidRequestException, InvalidThriftRequest) \
                    or r < 1:
                if err.tb is None:
                    try:
                        raise err.value
                    except Exception:
                        # make new Failure object explicitly, so that the same
                        # (traceback-less) one made by Thrift won't be retained
                        # and useful tracebacks thrown away
                        t, v, tb = exc_info()
                        err = failure.Failure(v, t, tb)
                d.errback(err)
                self._pending.remove(d)
            else:
                self.queue.put((req, d, r))

        def reqSuccess(res, d):
            d.callback(res)
            self._pending.remove(d)

        def _process((request, deferred, retries)):
            if not proto in self._protos:
                # may have disconnected while we were waiting for a request
                self.queue.put((request, deferred, retries))
            else:
                try:
                    d = proto.submitRequest(request)
                except Exception:
                    proto.abort()
                    d = defer.fail()
                retries -= 1
                d.addCallbacks(reqSuccess,
                               reqError,
                               callbackArgs=[deferred],
                               errbackArgs=[request, deferred, retries])

        return self.queue.get().addCallback(_process)

    def pushRequest(self, request, retries=None):
        retries = retries or self.request_retries
        d = defer.Deferred()
        self._pending.append(d)
        self.queue.put((request, d, retries))
        return d

    def shutdown(self):
        self.stopTrying()
        for p in self._protos:
            if p.transport:
                p.transport.loseConnection()
        for d in self._pending:
            if not d.called:
                d.errback(UserError(string="Shutdown requested"))

########NEW FILE########
__FILENAME__ = _sasl
import struct

from thrift.transport.TTwisted import ThriftClientProtocol
from thrift.transport.TTransport import TTransportException

from twisted.internet import defer
from twisted.internet.protocol import connectionDone
from twisted.internet.threads import deferToThread

from puresasl.client import SASLClient

class ThriftSASLClientProtocol(ThriftClientProtocol):

    START = 1
    OK = 2
    BAD = 3
    ERROR = 4
    COMPLETE = 5

    MAX_LENGTH = 2 ** 31 - 1

    def __init__(self, client_class, iprot_factory, oprot_factory=None,
            host=None, service=None, mechanism='GSSAPI', **sasl_kwargs):
        ThriftClientProtocol.__init__(self, client_class, iprot_factory, oprot_factory)

        self._sasl_negotiation_deferred = None
        self._sasl_negotiation_status = None
        self.client = None

        if host is not None:
            self.createSASLClient(host, service, mechanism, **sasl_kwargs)

    def createSASLClient(self, host, service, mechanism, **kwargs):
        self.sasl = SASLClient(host, service, mechanism, **kwargs)

    def dispatch(self, msg):
        encoded = self.sasl.wrap(msg)
        len_and_encoded = ''.join((struct.pack('!i', len(encoded)), encoded))
        ThriftClientProtocol.dispatch(self, len_and_encoded)

    @defer.inlineCallbacks
    def connectionMade(self):
        self._sendSASLMessage(self.START, self.sasl.mechanism)
        initial_message = yield deferToThread(self.sasl.process)
        self._sendSASLMessage(self.OK, initial_message)

        while True:
            status, challenge = yield self._receiveSASLMessage()
            if status == self.OK:
                response = yield deferToThread(self.sasl.process, challenge)
                self._sendSASLMessage(self.OK, response)
            elif status == self.COMPLETE:
                if not self.sasl.complete:
                    msg = "The server erroneously indicated that SASL " \
                          "negotiation was complete"
                    raise TTransportException(msg, message=msg)
                else:
                    break
            else:
                msg = "Bad SASL negotiation status: %d (%s)" % (status, challenge)
                raise TTransportException(msg, message=msg)

        self._sasl_negotiation_deferred = None
        ThriftClientProtocol.connectionMade(self)

    def _sendSASLMessage(self, status, body):
        if body is None:
            body = ""
        header = struct.pack(">BI", status, len(body))
        self.transport.write(header + body)

    def _receiveSASLMessage(self):
        self._sasl_negotiation_deferred = defer.Deferred()
        self._sasl_negotiation_status = None
        return self._sasl_negotiation_deferred

    def connectionLost(self, reason=connectionDone):
        if self.client:
            ThriftClientProtocol.connectionLost(self, reason)

    def dataReceived(self, data):
        if self._sasl_negotiation_deferred:
            # we got a sasl challenge in the format (status, length, challenge)
            # save the status, let IntNStringReceiver piece the challenge data together
            self._sasl_negotiation_status, = struct.unpack("B", data[0])
            ThriftClientProtocol.dataReceived(self, data[1:])
        else:
            # normal frame, let IntNStringReceiver piece it together
            ThriftClientProtocol.dataReceived(self, data)

    def stringReceived(self, frame):
        if self._sasl_negotiation_deferred:
            # the frame is just a SASL challenge
            response = (self._sasl_negotiation_status, frame)
            self._sasl_negotiation_deferred.callback(response)
        else:
            # there's a second 4 byte length prefix inside the frame
            decoded_frame = self.sasl.unwrap(frame[4:])
            ThriftClientProtocol.stringReceived(self, decoded_frame)

########NEW FILE########
__FILENAME__ = test_cassandraclient
from twisted.trial import unittest
import os

from twisted.internet import defer, reactor, error
from telephus.protocol import ManagedCassandraClientFactory
from telephus.client import CassandraClient

from telephus.cassandra import ttypes

CONNS = 5

HOST = os.environ.get('CASSANDRA_HOST', 'localhost')
PORT = 9160
KEYSPACE = 'TelephusTests'
T_KEYSPACE = 'TelephusTests2'
CF = 'Standard1'
SCF = 'Super1'
COUNTER_CF = 'Counter1'
SUPERCOUNTER_CF = 'SuperCounter1'
IDX_CF = 'IdxTestCF'
T_CF = 'TransientCF'
T_SCF = 'TransientSCF'
COLUMN = 'foo'
COLUMN2 = 'foo2'
SCOLUMN = 'bar'

# RF for SimpleStrategy keyspaces should be set on the 'replication_factor'
# attribute of KsDefs below this version
KS_RF_ATTRIBUTE = (19, 4, 0)

COUNTERS_SUPPORTED_API = (19, 10, 0)

# until Cassandra supports these again..
DO_SYSTEM_RENAMING = False

class CassandraClientTest(unittest.TestCase):
    @defer.inlineCallbacks
    def setUp(self):
        self.cmanager = ManagedCassandraClientFactory(keyspace='system')
        self.client = CassandraClient(self.cmanager)
        for i in xrange(CONNS):
            reactor.connectTCP(HOST, PORT, self.cmanager)
        yield self.cmanager.deferred

        remote_ver = yield self.client.describe_version()
        self.version = tuple(map(int, remote_ver.split('.')))

        self.my_keyspace = ttypes.KsDef(
            name=KEYSPACE,
            strategy_class='org.apache.cassandra.locator.SimpleStrategy',
            strategy_options={},
            cf_defs=[
                ttypes.CfDef(
                    keyspace=KEYSPACE,
                    name=CF,
                    column_type='Standard'
                ),
                ttypes.CfDef(
                    keyspace=KEYSPACE,
                    name=SCF,
                    column_type='Super'
                ),
                ttypes.CfDef(
                    keyspace=KEYSPACE,
                    name=IDX_CF,
                    column_type='Standard',
                    comparator_type='org.apache.cassandra.db.marshal.UTF8Type',
                    column_metadata=[
                        ttypes.ColumnDef(
                            name='col1',
                            validation_class='org.apache.cassandra.db.marshal.UTF8Type',
                            index_type=ttypes.IndexType.KEYS,
                            index_name='idxCol1')
                    ],
                    default_validation_class='org.apache.cassandra.db.marshal.BytesType'
                ),
            ]
        )

        if self.version <= KS_RF_ATTRIBUTE:
            self.my_keyspace.replication_factor = 1
        else:
            self.my_keyspace.strategy_options['replication_factor'] = '1'

        if self.version >= COUNTERS_SUPPORTED_API:
            self.my_keyspace.cf_defs.extend([
                ttypes.CfDef(
                    keyspace=KEYSPACE,
                    name=COUNTER_CF,
                    column_type='Standard',
                    default_validation_class='org.apache.cassandra.db.marshal.CounterColumnType'
                ),
                ttypes.CfDef(
                    keyspace=KEYSPACE,
                    name=SUPERCOUNTER_CF,
                    column_type='Super',
                    default_validation_class='org.apache.cassandra.db.marshal.CounterColumnType'
                ),
            ])

        yield self.client.system_add_keyspace(self.my_keyspace)
        yield self.client.set_keyspace(KEYSPACE)

    @defer.inlineCallbacks
    def tearDown(self):
        yield self.client.system_drop_keyspace(self.my_keyspace.name)
        self.cmanager.shutdown()
        for c in reactor.getDelayedCalls():
            c.cancel()
        reactor.removeAll()

    @defer.inlineCallbacks
    def test_insert_get(self):
        yield self.client.insert('test', CF, 'testval', column=COLUMN)
        yield self.client.insert('test2', CF, 'testval2', column=COLUMN)
        yield self.client.insert('test', SCF, 'superval', column=COLUMN, super_column=SCOLUMN)
        yield self.client.insert('test2', SCF, 'superval2', column=COLUMN,
                                 super_column=SCOLUMN)
        res = yield self.client.get('test', CF, column=COLUMN)
        self.assertEqual(res.column.value, 'testval')
        res = yield self.client.get('test2', CF, column=COLUMN)
        self.assertEqual(res.column.value, 'testval2')
        res = yield self.client.get('test', SCF, column=COLUMN, super_column=SCOLUMN)
        self.assertEqual(res.column.value, 'superval')
        res = yield self.client.get('test2', SCF, column=COLUMN, super_column=SCOLUMN)
        self.assertEqual(res.column.value, 'superval2')

    @defer.inlineCallbacks
    def test_batch_insert_get_slice_and_count(self):
        yield self.client.batch_insert('test', CF,
                                       {COLUMN: 'test', COLUMN2: 'test2'})
        yield self.client.batch_insert('test', SCF,
                               {SCOLUMN: {COLUMN: 'test', COLUMN2: 'test2'}})
        res = yield self.client.get_slice('test', CF, names=(COLUMN, COLUMN2))
        self.assertEqual(res[0].column.value, 'test')
        self.assertEqual(res[1].column.value, 'test2')
        res = yield self.client.get_slice('test', SCF, names=(COLUMN, COLUMN2),
                                          super_column=SCOLUMN)
        self.assertEqual(res[0].column.value, 'test')
        self.assertEqual(res[1].column.value, 'test2')
        res = yield self.client.get_count('test', CF)
        self.assertEqual(res, 2)

    @defer.inlineCallbacks
    def test_batch_mutate_and_remove(self):
        yield self.client.batch_mutate({'test': {CF: {COLUMN: 'test', COLUMN2: 'test2'}, SCF: { SCOLUMN: { COLUMN: 'test', COLUMN2: 'test2'} } }, 'test2': {CF: {COLUMN: 'test', COLUMN2: 'test2'}, SCF: { SCOLUMN: { COLUMN: 'test', COLUMN2: 'test2'} } } })
        res = yield self.client.get_slice('test', CF, names=(COLUMN, COLUMN2))
        self.assertEqual(res[0].column.value, 'test')
        self.assertEqual(res[1].column.value, 'test2')
        res = yield self.client.get_slice('test2', CF, names=(COLUMN, COLUMN2))
        self.assertEqual(res[0].column.value, 'test')
        self.assertEqual(res[1].column.value, 'test2')
        res = yield self.client.get_slice('test', SCF, names=(COLUMN, COLUMN2),
                                          super_column=SCOLUMN)
        self.assertEqual(res[0].column.value, 'test')
        self.assertEqual(res[1].column.value, 'test2')
        res = yield self.client.get_slice('test2', SCF, names=(COLUMN, COLUMN2),
                                          super_column=SCOLUMN)
        self.assertEqual(res[0].column.value, 'test')
        self.assertEqual(res[1].column.value, 'test2')
        yield self.client.batch_remove({CF: ['test', 'test2']}, names=['test', 'test2'])
        yield self.client.batch_remove({SCF: ['test', 'test2']}, names=['test', 'test2'], supercolumn=SCOLUMN)

    @defer.inlineCallbacks
    def test_batch_mutate_with_deletion(self):
        yield self.client.batch_mutate({'test': {CF: {COLUMN: 'test', COLUMN2: 'test2'}}})
        res = yield self.client.get_slice('test', CF, names=(COLUMN, COLUMN2))
        self.assertEqual(res[0].column.value, 'test')
        self.assertEqual(res[1].column.value, 'test2')
        yield self.client.batch_mutate({'test': {CF: {COLUMN: None, COLUMN2: 'test3'}}})
        res = yield self.client.get_slice('test', CF, names=(COLUMN, COLUMN2))
        self.assertEqual(len(res), 1)
        self.assertEqual(res[0].column.value, 'test3')

    @defer.inlineCallbacks
    def test_multiget_slice_remove(self):
        yield self.client.insert('test', CF, 'testval', column=COLUMN)
        yield self.client.insert('test', CF, 'testval', column=COLUMN2)
        yield self.client.insert('test2', CF, 'testval2', column=COLUMN)
        res = yield self.client.multiget(['test', 'test2'], CF, column=COLUMN)
        self.assertEqual(res['test'][0].column.value, 'testval')
        self.assertEqual(res['test2'][0].column.value, 'testval2')
        res = yield self.client.multiget_slice(['test', 'test2'], CF)
        self.assertEqual(res['test'][0].column.value, 'testval')
        self.assertEqual(res['test'][1].column.value, 'testval')
        self.assertEqual(res['test2'][0].column.value, 'testval2')
        yield self.client.remove('test', CF, column=COLUMN)
        yield self.client.remove('test2', CF, column=COLUMN)
        res = yield self.client.multiget(['test', 'test2'], CF, column=COLUMN)
        self.assertEqual(len(res['test']), 0)
        self.assertEqual(len(res['test2']), 0)

    @defer.inlineCallbacks
    def test_range_slices(self):
        yield self.client.insert('test', CF, 'testval', column=COLUMN)
        yield self.client.insert('test', CF, 'testval', column=COLUMN2)
        yield self.client.insert('test2', CF, 'testval2', column=COLUMN)
        ks = yield self.client.get_range_slices(CF, start='', finish='')
        keys = [k.key for k in ks]
        for key in ['test', 'test2']:
            self.assertIn(key, keys)

    @defer.inlineCallbacks
    def test_indexed_slices(self):
        yield self.client.insert('test1', IDX_CF, 'one', column='col1')
        yield self.client.insert('test2', IDX_CF, 'two', column='col1')
        yield self.client.insert('test3', IDX_CF, 'three', column='col1')
        expressions = [ttypes.IndexExpression('col1', ttypes.IndexOperator.EQ, 'two')]
        res = yield self.client.get_indexed_slices(IDX_CF, expressions, start_key='')
        self.assertEquals(res[0].columns[0].column.value,'two')

    @defer.inlineCallbacks
    def test_counter_add(self):
        if self.version < COUNTERS_SUPPORTED_API:
            raise unittest.SkipTest('Counters are not supported before 0.8')

        # test standard column counter
        yield self.client.add('test', COUNTER_CF, 1, column='col')
        res = yield self.client.get('test', COUNTER_CF, column='col')
        self.assertEquals(res.counter_column.value, 1)

        yield self.client.add('test', COUNTER_CF, 1, column='col')
        res = yield self.client.get('test', COUNTER_CF, column='col')
        self.assertEquals(res.counter_column.value, 2)

        # test super column counters
        yield self.client.add('test', SUPERCOUNTER_CF, 1, column='col', super_column='scol')
        res = yield self.client.get('test', SUPERCOUNTER_CF, column='col', super_column='scol')
        self.assertEquals(res.counter_column.value, 1)

        yield self.client.add('test', SUPERCOUNTER_CF, 1, column='col', super_column='scol')
        res = yield self.client.get('test', SUPERCOUNTER_CF, column='col', super_column='scol')
        self.assertEquals(res.counter_column.value, 2)

    @defer.inlineCallbacks
    def test_counter_remove(self):
        if self.version < COUNTERS_SUPPORTED_API:
            raise unittest.SkipTest('Counters are not supported before 0.8')

        # test standard column counter
        yield self.client.add('test', COUNTER_CF, 1, column='col')
        res = yield self.client.get('test', COUNTER_CF, column='col')
        self.assertEquals(res.counter_column.value, 1)

        yield self.client.remove_counter('test', COUNTER_CF, column='col')
        yield self.assertFailure(self.client.get('test', COUNTER_CF, column='col'),
                                 ttypes.NotFoundException)

        # test super column counters
        yield self.client.add('test', SUPERCOUNTER_CF, 1, column='col', super_column='scol')
        res = yield self.client.get('test', SUPERCOUNTER_CF, column='col', super_column='scol')
        self.assertEquals(res.counter_column.value, 1)

        yield self.client.remove_counter('test', SUPERCOUNTER_CF,
                                         column='col', super_column='scol')
        yield self.assertFailure(self.client.get('test', SUPERCOUNTER_CF,
                                                 column='col', super_column='scol'),
                                 ttypes.NotFoundException)

    def sleep(self, secs):
        d = defer.Deferred()
        reactor.callLater(secs, d.callback, None)
        return d

    @defer.inlineCallbacks
    def test_ttls(self):
        yield self.client.insert('test_ttls', CF, 'testval', column=COLUMN, ttl=1)
        res = yield self.client.get('test_ttls', CF, column=COLUMN)
        self.assertEqual(res.column.value, 'testval')
        yield self.sleep(2)
        yield self.assertFailure(self.client.get('test_ttls', CF, column=COLUMN), ttypes.NotFoundException)

        yield self.client.batch_insert('test_ttls', CF, {COLUMN:'testval'}, ttl=1)
        res = yield self.client.get('test_ttls', CF, column=COLUMN)
        self.assertEqual(res.column.value, 'testval')
        yield self.sleep(2)
        yield self.assertFailure(self.client.get('test_ttls', CF, column=COLUMN), ttypes.NotFoundException)

        yield self.client.batch_mutate({'test_ttls': {CF: {COLUMN: 'testval'}}}, ttl=1)
        res = yield self.client.get('test_ttls', CF, column=COLUMN)
        self.assertEqual(res.column.value, 'testval')
        yield self.sleep(2)
        yield self.assertFailure(self.client.get('test_ttls', CF, column=COLUMN), ttypes.NotFoundException)

    def compare_keyspaces(self, ks1, ks2):
        self.assertEqual(ks1.name, ks2.name)
        self.assertEqual(ks1.strategy_class, ks2.strategy_class)
        self.assertEqual(ks1.cf_defs, ks2.cf_defs)

        def get_rf(ksdef):
            rf = ksdef.replication_factor
            if ksdef.strategy_options and \
               'replication_factor' in ksdef.strategy_options:
                rf = int(ksdef.strategy_options['replication_factor'])
            return rf

        def strat_opts_no_rf(ksdef):
            if not ksdef.strategy_options:
                return {}
            opts = ksdef.strategy_options.copy()
            if 'replication_factor' in ksdef.strategy_options:
                del opts['replication_factor']
            return opts

        self.assertEqual(get_rf(ks1), get_rf(ks2))
        self.assertEqual(strat_opts_no_rf(ks1), strat_opts_no_rf(ks2))

    @defer.inlineCallbacks
    def test_keyspace_manipulation(self):
        try:
            yield self.client.system_drop_keyspace(T_KEYSPACE)
        except ttypes.InvalidRequestException:
            pass

        ksdef = ttypes.KsDef(name=T_KEYSPACE, strategy_class='org.apache.cassandra.locator.SimpleStrategy', strategy_options={}, cf_defs=[])
        if self.version <= KS_RF_ATTRIBUTE:
            ksdef.replication_factor = 1
        else:
            ksdef.strategy_options['replication_factor'] = '1'

        yield self.client.system_add_keyspace(ksdef)
        ks2 = yield self.client.describe_keyspace(T_KEYSPACE)
        self.compare_keyspaces(ksdef, ks2)

        if DO_SYSTEM_RENAMING:
            newname = T_KEYSPACE + '2'
            yield self.client.system_rename_keyspace(T_KEYSPACE, newname)
            ks2 = yield self.client.describe_keyspace(newname)
            ksdef.name = newname
            self.compare_keyspaces(ksdef, ks2)
        yield self.client.system_drop_keyspace(ksdef.name)
        yield self.assertFailure(self.client.describe_keyspace(T_KEYSPACE), ttypes.NotFoundException)
        if DO_SYSTEM_RENAMING:
            yield self.assertFailure(self.client.describe_keyspace(ksdef.name), ttypes.NotFoundException)

    @defer.inlineCallbacks
    def test_column_family_manipulation(self):
        # CfDef attributes present in all supported c*/thrift-api versions
        common_attrs = (
            ('column_type', 'Standard'),
            ('comparator_type', 'org.apache.cassandra.db.marshal.BytesType'),
            ('comment', 'foo'),
            ('read_repair_chance', 1.0),
            ('column_metadata', []),
            ('gc_grace_seconds', 86400),
            ('default_validation_class', 'org.apache.cassandra.db.marshal.BytesType'),
            ('min_compaction_threshold', 5),
            ('max_compaction_threshold', 31),
        )
        cfdef = ttypes.CfDef(KEYSPACE, T_CF)
        for attr, val in common_attrs:
            setattr(cfdef, attr, val)

        yield self.client.system_add_column_family(cfdef)
        ksdef = yield self.client.describe_keyspace(KEYSPACE)
        cfdefs = [c for c in ksdef.cf_defs if c.name == T_CF]
        self.assertEqual(len(cfdefs), 1)
        cfdef2 = cfdefs[0]

        for attr, val in common_attrs:
            val1 = getattr(cfdef, attr)
            val2 = getattr(cfdef2, attr)
            self.assertEqual(val1, val2, 'attribute %s mismatch: %r != %r' % (attr, val1, val2))

        if DO_SYSTEM_RENAMING:
            newname = T_CF + '2'
            yield self.client.system_rename_column_family(T_CF, newname)
            ksdef = yield self.client.describe_keyspace(KEYSPACE)
            cfdef2 = [c for c in ksdef.cf_defs if c.name == newname][0]
            self.assertNotIn(T_CF, [c.name for c in ksdef.cf_defs])
            cfdef.name = newname
            self.assertEqual(cfdef, cfdef2)
        yield self.client.system_drop_column_family(cfdef.name)
        ksdef = yield self.client.describe_keyspace(KEYSPACE)
        self.assertNotIn(cfdef.name, [c.name for c in ksdef.cf_defs])

    @defer.inlineCallbacks
    def test_describes(self):
        name = yield self.client.describe_cluster_name()
        self.assertIsInstance(name, str)
        self.assertNotEqual(name, '')
        partitioner = yield self.client.describe_partitioner()
        self.assert_(partitioner.startswith('org.apache.cassandra.'),
                     msg='partitioner is %r' % partitioner)
        snitch = yield self.client.describe_snitch()
        self.assert_(snitch.startswith('org.apache.cassandra.'),
                     msg='snitch is %r' % snitch)
        version = yield self.client.describe_version()
        self.assertIsInstance(version, str)
        self.assertIn('.', version)
        schemavers = yield self.client.describe_schema_versions()
        self.assertIsInstance(schemavers, dict)
        self.assertNotEqual(schemavers, {})
        ring = yield self.client.describe_ring(KEYSPACE)
        self.assertIsInstance(ring, list)
        self.assertNotEqual(ring, [])
        for r in ring:
            self.assertIsInstance(r.start_token, str)
            self.assertIsInstance(r.end_token, str)
            self.assertIsInstance(r.endpoints, list)
            self.assertNotEqual(r.endpoints, [])
            for ep in r.endpoints:
                self.assertIsInstance(ep, str)

    @defer.inlineCallbacks
    def test_errback(self):
        yield self.client.remove('poiqwe', CF)
        try:
            yield self.client.get('poiqwe', CF, column='foo')
        except Exception, e:
            pass

    @defer.inlineCallbacks
    def test_bad_params(self):
        # This test seems to kill the thrift connection, so we're skipping it for now
        for x in xrange(CONNS+1):
            try:
                # pass an int where a string is required
                yield self.client.get(12345, CF, column='foo')
            except Exception, e:
                pass
    test_bad_params.skip = "Disabled pending further investigation..."

class ManagedCassandraClientFactoryTest(unittest.TestCase):
    @defer.inlineCallbacks
    def test_initial_connection_failure(self):
        cmanager = ManagedCassandraClientFactory()
        client = CassandraClient(cmanager)
        d = cmanager.deferred
        reactor.connectTCP('nonexistent.foobarexample.com', PORT, cmanager)
        yield self.failUnlessFailure(d, error.DNSLookupError, error.TimeoutError)
        cmanager.shutdown()

########NEW FILE########
__FILENAME__ = test_cassandraclusterpool
from __future__ import with_statement

import random
import contextlib
from time import time
from itertools import groupby
from twisted.trial import unittest
from twisted.internet import defer, reactor
from twisted.python import log
from telephus.pool import CassandraClusterPool, TTransport, get_endpoints_from_tokenrange

from telephus.cassandra import ttypes

try:
    from Cassanova import cassanova
except ImportError:
    cassanova = None

def deferwait(s, result=None):
    def canceller(my_d):
        dcall.cancel()
    d = defer.Deferred(canceller=canceller)
    dcall = reactor.callLater(s, d.callback, result)
    return d

def addtimeout(d, waittime):
    timeouter = reactor.callLater(waittime, d.cancel)
    def canceltimeout(x):
        if timeouter.active():
            timeouter.cancel()
        return x
    d.addBoth(canceltimeout)

class GeneralPoolTest(unittest.TestCase):
    def test_get_endpoints_from_tokenrange(self):
        # 07 token ranges have no rpc property
        range07 = ttypes.TokenRange(
                    start_token="1",
                    end_token="2",
                    endpoints=["127.0.0.1", "127.0.0.2"])
        self.assertEqual(["127.0.0.1", "127.0.0.2"], get_endpoints_from_tokenrange(range07))

        # the rpc endpoints field is optional, so test without it set
        range08 = ttypes.TokenRange(
                    start_token="1",
                    end_token="2",
                    endpoints=["127.0.0.1", "127.0.0.2"],
                    rpc_endpoints=None)
        self.assertEqual(["127.0.0.1", "127.0.0.2"], get_endpoints_from_tokenrange(range08))

        # test with some bad rpc_endpoints
        range08 = ttypes.TokenRange(
                    start_token="1",
                    end_token="2",
                    endpoints=["127.0.0.1", "127.0.0.2"],
                    rpc_endpoints=["127.0.0.5", "0.0.0.0"])
        self.assertEqual(["127.0.0.5", "127.0.0.2"], get_endpoints_from_tokenrange(range08))


class CassandraClusterPoolTest(unittest.TestCase):
    start_port = 44449
    ksname = 'TestKeyspace'

    def assertFired(self, d):
        self.assert_(d.called, msg='%s has not been fired' % (d,))

    def assertNotFired(self, d):
        self.assertNot(d.called, msg='Expected %s not to have been fired, but'
                                     ' it has been fired.' % (d,))

    def assertNumConnections(self, num):
        conns = self.cluster.get_connections()
        self.assertEqual(len(conns), num,
                         msg='Expected %d existing connections to cluster, but'
                             ' %d found.' % (num, len(conns)))
        return conns

    def assertNumUniqueConnections(self, num):
        conns = self.cluster.get_connections()
        conns = set(n for (n,p) in conns)
        self.assertEqual(len(conns), num,
                         msg='Expected %d unique nodes in cluster with existing'
                             ' connections, but %d found. Whole set: %r'
                             % (num, len(conns), sorted(conns)))
        return conns

    def assertNumWorkers(self, num):
        workers = self.cluster.get_working_connections()
        self.assertEqual(len(workers), num,
                         msg='Expected %d pending requests being worked on in '
                             'cluster, but %d found' % (num, len(workers)))
        return workers

    def killSomeConn(self):
        conns = self.cluster.get_connections()
        self.assertNotEqual(len(conns), 0)
        node, proto = conns[0]
        proto.transport.loseConnection()
        return proto

    def killSomeNode(self):
        conns = self.cluster.get_connections()
        self.assertNotEqual(len(conns), 0)
        node, proto = conns[0]
        node.stopService()
        return node

    def killWorkingConn(self):
        conns = self.cluster.get_working_connections()
        self.assertNotEqual(len(conns), 0)
        node, proto = conns[0]
        proto.transport.loseConnection()
        return proto

    def killWorkingNode(self):
        conns = self.cluster.get_working_connections()
        self.assertNotEqual(len(conns), 0)
        node, proto = conns[0]
        node.stopService()
        return node

    @contextlib.contextmanager
    def cluster_and_pool(self, num_nodes=10, pool_size=5, start=True,
                         cluster_class=None, node_discovery=True):
        if cluster_class is None:
            cluster_class = FakeCassandraCluster
        cluster = cluster_class(num_nodes, start_port=self.start_port)
        pool = CassandraClusterPool([cluster.iface], thrift_port=self.start_port,
                                    pool_size=pool_size, auto_node_discovery=node_discovery)
        if start:
            cluster.startService()
            pool.startService()
        self.cluster = cluster
        self.pool = pool
        try:
            yield cluster, pool
        finally:
            del self.pool
            del self.cluster
            if pool.running:
                pool.stopService()
            if cluster.running:
                cluster.stopService()

    @defer.inlineCallbacks
    def make_standard_cfs(self, ksname=None):
        if ksname is None:
            ksname = self.ksname
        yield self.pool.system_add_keyspace(
            ttypes.KsDef(
                name=ksname,
                replication_factor=1,
                strategy_class='org.apache.cassandra.locator.SimpleStrategy',
                cf_defs=(
                    ttypes.CfDef(
                        keyspace=ksname,
                        name='Standard1',
                        column_type='Standard'
                    ),
                    ttypes.CfDef(
                        keyspace=ksname,
                        name='Super1',
                        column_type='Super'
                    )
                )
            )
        )
        yield self.pool.set_keyspace(ksname)
        yield self.pool.insert('key', 'Standard1', column='col', value='value')

    @defer.inlineCallbacks
    def insert_dumb_rows(self, ksname=None, cf=None, numkeys=10, numcols=10,
                         timestamp=0):
        if ksname is None:
            ksname = self.ksname
        if cf is None:
            cf = 'Standard1'
        yield self.pool.set_keyspace(ksname)

        mutmap = {}
        for k in range(numkeys):
            key = 'key%03d' % k
            cols = [ttypes.Column(name='%s-%03d-%03d' % (ksname, k, n),
                                  value='val-%s-%03d-%03d' % (ksname, k, n),
                                  timestamp=timestamp)
                    for n in range(numcols)]
            mutmap[key] = {cf: cols}
        yield self.pool.batch_mutate(mutationmap=mutmap)

    @defer.inlineCallbacks
    def test_set_keyspace(self):
        pool_size=10
        num_nodes=4

        with self.cluster_and_pool(num_nodes=num_nodes, pool_size=pool_size):
            yield self.make_standard_cfs('KS1')
            yield self.make_standard_cfs('KS2')

            yield self.insert_dumb_rows('KS1', numcols=pool_size+2)
            yield self.insert_dumb_rows('KS2', numcols=pool_size+2)

            yield self.pool.set_keyspace('KS1')
            first = self.pool.get('key000', 'Standard1/wait=2.0', 'KS1-000-000')

            yield self.pool.set_keyspace('KS2')
            dfrds1 = []
            for x in range(pool_size + 1):
                d = self.pool.get('key001', 'Standard1/wait=0.1', 'KS2-001-%03d' % x)
                dfrds1.append(d)

            # all pool connections should have sent a real set_keyspace by
            # now; change it up again

            yield self.pool.set_keyspace('KS1')
            dfrds2 = []
            for x in range(pool_size + 1):
                d = self.pool.get('key002', 'Standard1/wait=0.1', 'KS1-002-%03d' % x)
                dfrds2.append(d)

            result = yield defer.DeferredList(dfrds1, consumeErrors=True)
            for n, (succ, res) in enumerate(result):
                self.assert_(succ, 'Failure on item %d was %s' % (n, res))
                res = res.column.value
                self.assertEqual(res, 'val-KS2-001-%03d' % n)

            result = yield defer.DeferredList(dfrds2)
            for n, (succ, res) in enumerate(result):
                self.assert_(succ, 'Failure was %s' % res)
                res = res.column.value
                self.assertEqual(res, 'val-KS1-002-%03d' % n)

            yield self.pool.set_keyspace('KS2')

            result = (yield first).column.value
            self.assertEqual(result, 'val-KS1-000-000')

            final = yield self.pool.get('key003', 'Standard1', 'KS2-003-005')
            self.assertEqual(final.column.value, 'val-KS2-003-005')

    @defer.inlineCallbacks
    def test_bad_set_keyspace(self):
        with self.cluster_and_pool():
            yield self.make_standard_cfs('KS1')
            yield self.insert_dumb_rows('KS1')

            yield self.assertFailure(self.pool.set_keyspace('i-dont-exist'),
                                     ttypes.InvalidRequestException)
            self.flushLoggedErrors()

            # should still be in KS1
            result = yield self.pool.get('key005', 'Standard1', 'KS1-005-000')
            self.assertEqual(result.column.value, 'val-KS1-005-000')

    @defer.inlineCallbacks
    def test_ring_inspection(self):
        with self.cluster_and_pool(start=False):
            self.assertEqual(len(self.pool.seed_list), 1)
            self.cluster.startService()
            self.pool.startService()
            yield self.pool.describe_cluster_name()
            self.assertEqual(len(self.pool.nodes), len(self.cluster.ring))

    @defer.inlineCallbacks
    def test_keyspace_connection(self):
        numkeys = 10
        numcols = 10
        tries = 500

        with self.cluster_and_pool():
            yield self.make_standard_cfs('KS1')
            yield self.make_standard_cfs('KS2')
            yield self.insert_dumb_rows('KS1', numkeys=numkeys, numcols=numcols)
            yield self.insert_dumb_rows('KS2', numkeys=numkeys, numcols=numcols)

            ksconns = dict((ksname, self.pool.keyspaceConnection(ksname))
                           for ksname in ('KS1', 'KS2'))

            dlist = []
            for i in xrange(tries):
                keyspace = 'KS%d' % random.randint(1, 2)
                keynum = '%03d' % random.randint(0, numkeys-1)
                key = 'key' + keynum
                col = '%s-%s-%03d' % (keyspace, keynum, random.randint(0, numcols-1))
                d = ksconns[keyspace].get(key, 'Standard1', col)
                d.addCallback(lambda c: c.column.value)
                d.addCallback(self.assertEqual, 'val-' + col)
                dlist.append(d)
            results = yield defer.DeferredList(dlist, consumeErrors=True)
            for succ, answer in results:
                if not succ:
                    answer.raiseException()

    @defer.inlineCallbacks
    def test_storm(self):
        numkeys = 10
        numcols = 10
        tries = 500

        with self.cluster_and_pool():
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows(numkeys=numkeys, numcols=numcols)

            dlist = []
            for i in xrange(tries):
                keynum = '%03d' % random.randint(0, numkeys-1)
                key = 'key' + keynum
                col = '%s-%s-%03d' % (self.ksname, keynum, random.randint(0, numcols-1))
                d = self.pool.get(key, 'Standard1', col)
                d.addCallback(lambda c: c.column.value)
                d.addCallback(self.assertEqual, 'val-' + col)
                dlist.append(d)
            results = yield defer.DeferredList(dlist, consumeErrors=True)
            for succ, answer in results:
                if not succ:
                    answer.raiseException()

    @defer.inlineCallbacks
    def test_retrying(self):
        with self.cluster_and_pool():
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            d = self.pool.get('key000', 'Standard1/wait=1.0', '%s-000-000' % self.ksname,
                              retries=3)

            # give the timed 'get' a chance to start
            yield deferwait(0.05)

            workers = self.assertNumWorkers(1)
            self.killWorkingConn()

            # allow reconnect
            yield deferwait(0.1)

            newworkers = self.assertNumWorkers(1)

            # we want the preference to be reconnecting the same node
            self.assertEqual(workers[0][0], newworkers[0][0])
            answer = (yield d).column.value
            self.assertEqual(answer, 'val-%s-000-000' % self.ksname)
        self.flushLoggedErrors()

    @defer.inlineCallbacks
    def test_resubmit_to_new_conn(self):
        pool_size = 8

        with self.cluster_and_pool(pool_size=1):
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            # turn up pool size once other nodes are known
            self.pool.adjustPoolSize(pool_size)
            yield deferwait(0.1)

            d = self.pool.get('key005', 'Standard1/wait=1.0', '%s-005-000' % self.ksname,
                              retries=3)

            # give the timed 'get' a chance to start
            yield deferwait(0.1)

            workers = self.assertNumWorkers(1)
            self.killWorkingNode()

            # allow reconnect
            yield deferwait(0.5)
            newworkers = self.assertNumWorkers(1)

            # reconnect should have been to a different node
            self.assertNotEqual(workers[0][0], newworkers[0][0])

            answer = (yield d).column.value
            self.assertEqual(answer, 'val-%s-005-000' % self.ksname)

        self.flushLoggedErrors()

    @defer.inlineCallbacks
    def test_adjust_pool_size(self):
        pool_size = 8
        diminish_by = 2

        with self.cluster_and_pool(pool_size=1):
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            # turn up pool size once other nodes are known
            self.pool.adjustPoolSize(pool_size)
            yield deferwait(0.1)

            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(pool_size)

            dlist = []
            for x in range(pool_size):
                d = self.pool.get('key001', 'Standard1/wait=1.0',
                                  '%s-001-002' % self.ksname, retries=0)
                d.addCallback(lambda c: c.column.value)
                d.addCallback(self.assertEqual, 'val-%s-001-002' % self.ksname)
                dlist.append(d)

            yield deferwait(0.1)

            for d in dlist:
                self.assertNotFired(d)
            self.assertNumConnections(pool_size)
            self.assertNumWorkers(pool_size)
            self.assertNumUniqueConnections(pool_size)

            # turn down pool size
            self.pool.adjustPoolSize(pool_size - diminish_by)
            yield deferwait(0.1)

            # still pool_size conns until the ongoing requests finish
            for d in dlist:
                self.assertNotFired(d)
            self.assertNumConnections(pool_size)
            self.assertEqual(len(self.pool.dying_conns), diminish_by)

            result = yield defer.DeferredList(dlist, consumeErrors=True)
            for succ, answer in result:
                if not succ:
                    answer.raiseException()
            yield deferwait(0.1)

            self.assertNumConnections(pool_size - diminish_by)
            self.assertNumWorkers(0)

    @defer.inlineCallbacks
    def test_zero_retries(self):
        with self.cluster_and_pool():
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()
            d = self.pool.get('key006', 'Standard1/wait=0.5',
                              '%s-006-002' % self.ksname, retries=0)

            yield deferwait(0.05)
            self.assertNumWorkers(1)

            # kill the connection handling the query- an immediate retry
            # should work, if a retry is attempted
            self.killWorkingConn()

            yield self.assertFailure(d, TTransport.TTransportException)

        self.flushLoggedErrors()

    @defer.inlineCallbacks
    def test_exhaust_retries(self):
        retries = 3
        num_nodes = pool_size = retries + 2

        with self.cluster_and_pool(num_nodes=num_nodes, pool_size=1):
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            # turn up pool size once other nodes are known
            self.pool.adjustPoolSize(pool_size)
            yield deferwait(0.2)

            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(pool_size)

            d = self.pool.get('key002', 'Standard1/wait=0.5',
                              '%s-002-003' % self.ksname, retries=retries)
            yield deferwait(0.05)

            for retry in range(retries + 1):
                self.assertNumConnections(pool_size)
                self.assertNumWorkers(1)
                self.assertNotFired(d)
                self.killWorkingNode()
                yield deferwait(0.1)

            yield self.assertFailure(d, TTransport.TTransportException)

        self.flushLoggedErrors()

    @defer.inlineCallbacks
    def test_kill_pending_conns(self):
        num_nodes = pool_size = 8
        fake_pending = 2

        with self.cluster_and_pool(num_nodes=num_nodes, pool_size=1):
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            # turn up pool size once other nodes are known
            self.pool.adjustPoolSize(pool_size)
            yield deferwait(0.1)

            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(pool_size)

            class fake_connector:
                def __init__(self, nodename):
                    self.node = nodename
                    self.stopped = False

                def stopFactory(self):
                    self.stopped = True

            fakes = [fake_connector('fake%02d' % n) for n in range(fake_pending)]
            # by putting them in connectors but not good_conns, these will
            # register as connection-pending
            self.pool.connectors.update(fakes)

            self.assertEqual(self.pool.num_pending_conns(), 2)
            self.pool.adjustPoolSize(pool_size)

            # the pending conns should have been killed first
            self.assertEqual(self.pool.num_pending_conns(), 0)
            self.assertEqual(self.pool.num_connectors(), pool_size)
            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(pool_size)

            for fk in fakes:
                self.assert_(fk.stopped, msg='Fake %s was not stopped!' % fk.node)

    @defer.inlineCallbacks
    def test_connection_leveling(self):
        num_nodes = 8
        conns_per_node = 10
        tolerance_factor = 0.20

        def assertConnsPerNode(numconns):
            tolerance = int(tolerance_factor * numconns)
            conns = self.cluster.get_connections()
            pernode = {}
            for node, nodeconns in groupby(sorted(conns), lambda (n,p): n):
                pernode[node] = len(list(nodeconns))
            for node, conns_here in pernode.items():
                self.assertApproximates(numconns, conns_here, tolerance,
                                        msg='Expected ~%r (+- %r) connections to %r,'
                                            ' but found %r. Whole map: %r'
                                            % (numconns, tolerance, node, conns_here,
                                               pernode))

        with self.cluster_and_pool(num_nodes=num_nodes, pool_size=1):
            pool_size = num_nodes * conns_per_node

            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            # turn up pool size once other nodes are known
            self.pool.adjustPoolSize(pool_size)
            yield deferwait(0.3)

            # make sure conns are (at least mostly) balanced
            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(num_nodes)

            assertConnsPerNode(conns_per_node)

            # kill a node and make sure connections are remade in a
            # balanced way
            node = self.killSomeNode()
            yield deferwait(0.6)

            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(num_nodes - 1)

            assertConnsPerNode(pool_size / (num_nodes - 1))

            # lower pool size, check that connections are killed in a
            # balanced way
            new_pool_size = pool_size - conns_per_node
            self.pool.adjustPoolSize(new_pool_size)
            yield deferwait(0.2)

            self.assertNumConnections(new_pool_size)
            self.assertNumUniqueConnections(num_nodes - 1)

            assertConnsPerNode(new_pool_size / (num_nodes - 1))

            # restart the killed node again and wait for the pool to notice
            # that it's up
            node.startService()
            yield deferwait(0.5)

            # raise pool size again, check balanced
            self.pool.adjustPoolSize(pool_size)
            yield deferwait(0.2)

            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(num_nodes)

            assertConnsPerNode(conns_per_node)

        self.flushLoggedErrors()

    def test_huge_pool(self):
        pass

    @defer.inlineCallbacks
    def test_manual_node_add(self):
        num_nodes = 3
        pool_size = 5

        class LyingCassanovaNode(cassanova.CassanovaNode):
            def endpoint_str(self):
                return '127.0.0.1:%d' % (self.addr.port + 1000)
        class LyingFakeCluster(FakeCassandraCluster):
            node_class = LyingCassanovaNode

        with self.cluster_and_pool(num_nodes=num_nodes, pool_size=1,
                                   cluster_class=LyingFakeCluster):
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            self.pool.conn_timeout = 0.5

            # turn up pool size once other nodes are known
            self.pool.adjustPoolSize(pool_size)
            yield deferwait(0.2)

            # shouldn't have been able to find any nodes besides the seed
            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(1)

            # add address for a second real node, raise pool size so new
            # connections are made
            self.pool.addNode((self.cluster.iface, self.cluster.port + 1))
            self.pool.adjustPoolSize(pool_size * 2)
            yield deferwait(0.4)

            self.assertNumConnections(pool_size * 2)
            self.assertNumUniqueConnections(2)

        self.flushLoggedErrors()

    @defer.inlineCallbacks
    def test_manual_node_remove(self):
        num_nodes = 5
        pool_size = 10

        with self.cluster_and_pool(num_nodes=num_nodes, pool_size=1):
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            # turn up pool size once other nodes are known
            self.pool.adjustPoolSize(pool_size)
            yield deferwait(0.2)

            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(num_nodes)

            n = iter(self.pool.nodes).next()
            self.pool.removeNode(n)
            yield deferwait(0.2)

            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(num_nodes - 1)

            # ask for one extra connection, to make sure the removed node
            # isn't re-added and connected to
            self.pool.adjustPoolSize(pool_size + 1)
            yield deferwait(0.1)

            self.assertNumConnections(pool_size + 1)
            self.assertNumUniqueConnections(num_nodes - 1)

    @defer.inlineCallbacks
    def test_conn_loss_during_idle(self):
        num_nodes = pool_size = 6

        with self.cluster_and_pool(num_nodes=num_nodes, pool_size=1):
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            # turn up pool size once other nodes are known
            self.pool.adjustPoolSize(pool_size)
            yield deferwait(0.2)

            self.assertNumConnections(pool_size)
            self.assertNumUniqueConnections(pool_size)
            self.assertNumWorkers(0)

            self.killSomeConn()
            yield deferwait(0.1)

            self.assertNumConnections(pool_size)
            self.assertNumWorkers(0)

            self.killSomeNode()
            yield deferwait(0.1)

            conns = self.assertNumConnections(pool_size)
            uniqnodes = set(n for (n,p) in conns)
            self.assert_(len(uniqnodes) >= (num_nodes - 1),
                         msg='Expected %d or more unique connected nodes, but found %d'
                             % (num_nodes - 1, len(uniqnodes)))
            self.assertNumWorkers(0)

        self.flushLoggedErrors()

    @defer.inlineCallbacks
    def test_last_conn_loss_during_idle(self):
        with self.cluster_and_pool(pool_size=1, num_nodes=1):
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            no_nodes_called = [False]
            def on_no_nodes(poolsize, targetsize, pendingreqs, expectedwait):
                self.assertEqual(poolsize, 0)
                self.assertEqual(targetsize, 1)
                self.assertEqual(pendingreqs, 0)
                no_nodes_called[0] = True
            self.pool.on_insufficient_nodes = on_no_nodes

            self.assertNumConnections(1)
            node = self.killSomeNode()
            yield deferwait(0.05)

            self.assert_(no_nodes_called[0], msg='on_no_nodes was not called')

            node.startService()
            d = self.pool.get('key004', 'Standard1', '%s-004-007' % self.ksname,
                              retries=2)
            addtimeout(d, 3.0)
            answer = yield d
            self.assertEqual(answer.column.value, 'val-%s-004-007' % self.ksname)

        self.flushLoggedErrors()

    @defer.inlineCallbacks
    def test_last_conn_loss_during_request(self):
        with self.cluster_and_pool(pool_size=1, num_nodes=1):
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows()

            self.assertNumConnections(1)

            d = self.pool.get('key004', 'Standard1/wait=1.0',
                              '%s-004-008' % self.ksname, retries=4)
            yield deferwait(0.1)

            def cancel_if_no_conns(numconns, pending):
                numworkers = self.pool.num_working_conns()
                if numworkers == 0 and not d.called:
                    d.cancel()
            self.pool.on_insufficient_conns = cancel_if_no_conns

            self.assertNumWorkers(1)
            self.killWorkingNode()
            yield deferwait(0.05)

            self.assertFired(d)
            yield self.assertFailure(d, defer.CancelledError)

        self.flushLoggedErrors()

    @defer.inlineCallbacks
    def test_main_seed_down(self):
        with self.cluster_and_pool(pool_size=1, num_nodes=2):
            yield self.make_standard_cfs()
            yield self.insert_dumb_rows(numkeys=20)

            self.pool.adjustPoolSize(5)
            yield deferwait(0.1)
            self.assertNumConnections(5)
            self.assertNumUniqueConnections(2)

            # kill the first seed node
            startnode = [node for (node, proto) in self.cluster.get_connections()
                              if node.addr.port == self.start_port]
            startnode[0].stopService()

            # submit a bunch of read requests
            dlist = []
            keys = yield self.pool.get_range_slices('Standard1', start='',
                                                    count=10, column_count=0)
            for k in keys:
                d = self.pool.get_range_slices('Standard1', start=k.key, finish=k.key,
                                               column_count=10)
                dlist.append(d)

            yield defer.DeferredList(dlist, fireOnOneErrback=True)

        self.flushLoggedErrors()

    @defer.inlineCallbacks
    def test_lots_of_up_and_down(self):
        pool_size = 20
        num_nodes = 10
        num_ops = 500
        num_twiddles = 100
        runtime = 4.0
        ksname = 'KS'
        num_keys = 20

        @defer.inlineCallbacks
        def node_twiddler(optime, numops):
            end_time = time() + optime
            wait_per_op = float(optime) / numops
            log.msg('twiddler starting')
            while True:
                if time() > end_time:
                    break
                yield deferwait(random.normalvariate(wait_per_op, wait_per_op * 0.2))
                nodes = self.cluster.get_nodes()
                running_nodes = [n for n in nodes if n.running]
                nonrunning = [n for n in nodes if not n.running]
                if len(running_nodes) <= 1:
                    op = 'up'
                elif len(nonrunning) == 0:
                    op = 'down'
                else:
                    op = random.choice(('down', 'up'))
                if op == 'down':
                    random.choice(running_nodes).stopService()
                else:
                    random.choice(nonrunning).startService()
            log.msg('twiddler done')

        @defer.inlineCallbacks
        def work_o_tron(optime, numops, n):
            log.msg('work_o_tron %d started' % n)
            end_time = time() + optime
            wait_per_op = float(optime) / numops
            opsdone = 0
            while True:
                if time() > end_time:
                    break
                thiswait = random.normalvariate(wait_per_op, wait_per_op * 0.2)
                keynum = random.randint(0, num_keys - 1)
                log.msg('work_o_tron %d getting key%03d, waiting %f' % (n, keynum, thiswait))
                d = self.pool.get('key%03d' % keynum, 'Standard1/wait=%f' % thiswait,
                                  '%s-%03d-001' % (ksname, keynum),
                                  retries=10)
                result = yield d
                log.msg('work_o_tron %d got %r' % (n, result))
                self.assertEqual(result.column.value, 'val-%s-%03d-001' % (ksname, keynum))
                opsdone += 1
            log.msg('work_o_tron %d done' % n)
            self.assertApproximates(opsdone, numops, 0.5 * numops)

        starttime = time()
        with self.cluster_and_pool(pool_size=1, num_nodes=num_nodes):
            yield self.make_standard_cfs(ksname)
            yield self.insert_dumb_rows(ksname, numkeys=num_keys)

            self.pool.adjustPoolSize(pool_size)
            yield deferwait(0.5)

            twiddler = node_twiddler(runtime, num_twiddles)
            workers = [work_o_tron(runtime, num_ops / pool_size, n)
                       for n in range(pool_size)]

            end = yield defer.DeferredList([twiddler] + workers, fireOnOneErrback=True)
            for num, (succ, result) in enumerate(end):
                self.assert_(succ, msg='worker %d failed: result: %s' % (num, result))
        endtime = time()

        self.assertApproximates(endtime - starttime, runtime, 0.5 * runtime)
        self.flushLoggedErrors()

    @defer.inlineCallbacks
    def test_auto_discovery_on(self):
        num_nodes = 5
        pool_size = 10

        with self.cluster_and_pool(num_nodes=num_nodes, pool_size=1):
            yield deferwait(0.5)
            self.assertEqual(len(self.pool.nodes), 5)

    @defer.inlineCallbacks
    def test_auto_discovery_off(self):
        num_nodes = 5
        pool_size = 10

        with self.cluster_and_pool(num_nodes=num_nodes, pool_size=1, node_discovery=False):
            yield deferwait(0.5)
            self.assertEqual(len(self.pool.nodes), 1)


if cassanova:
    class EnhancedCassanovaInterface(cassanova.CassanovaInterface):
        """
        Add a way to request operations which are guaranteed to take (at least) a
        given amount of time, for easier testing of things which might take a long
        time in the real world
        """

        def get(self, key, column_path, consistency_level):
            args = []
            if '/' in column_path.column_family:
                parts = column_path.column_family.split('/')
                column_path.column_family = parts[0]
                args = parts[1:]
            d = defer.maybeDeferred(cassanova.CassanovaInterface.get, self, key,
                                    column_path, consistency_level)
            waittime = 0
            for arg in args:
                if arg.startswith('wait='):
                    waittime += float(arg[5:])
            if waittime > 0:
                def doWait(x):
                    waiter = deferwait(waittime, x)
                    self.service.waiters.append(waiter)
                    return waiter
                d.addCallback(doWait)
            return d

    class EnhancedCassanovaFactory(cassanova.CassanovaFactory):
        handler_factory = EnhancedCassanovaInterface

    class EnhancedCassanovaNode(cassanova.CassanovaNode):
        factory = EnhancedCassanovaFactory

        def endpoint_str(self):
            return '%s:%d' % (self.addr.host, self.addr.port)

    class FakeCassandraCluster(cassanova.CassanovaService):
        """
        Tweak the standard Cassanova service to allow nodes to run on the same
        interface, but different ports. CassandraClusterPool already knows how
        to understand the 'host:port' type of endpoint description in
        describe_ring output.
        """

        node_class = EnhancedCassanovaNode

        def __init__(self, num_nodes, start_port=41356, interface='127.0.0.1'):
            cassanova.CassanovaService.__init__(self, start_port)
            self.waiters = []
            self.iface = interface
            for n in range(num_nodes):
                self.add_node_on_port(start_port + n)
            # make a non-system keyspace so that describe_ring can work
            self.keyspaces['dummy'] = cassanova.KsDef(
                'dummy',
                replication_factor=1,
                strategy_class='org.apache.cassandra.locator.SimpleStrategy',
                cf_defs=[]
            )

        def add_node_on_port(self, port, token=None):
            node = self.node_class(port, self.iface, token=token)
            node.setServiceParent(self)
            self.ring[node.mytoken] = node

        def stopService(self):
            cassanova.CassanovaService.stopService(self)
            for d in self.waiters:
                if not d.called:
                    d.cancel()
                    d.addErrback(lambda n: None)

if not cassanova:
    del CassandraClusterPoolTest

########NEW FILE########
