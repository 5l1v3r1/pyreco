# PlyPlus selectors tutorial.

In this section I'll explain how selectors work and give a few examples.

Tip: If you've ever done web development, plyplus' selector syntax and behavior are modeled after CSS selectors.

## Syntax

Selectors are basically a list of element selectors, separated by an (optional) operator.

So informally: element [op] element [op] element ...

Here are the element selectors:

  - _name_ - match a the name of a branch (in plyplus (and lisp), called a "head").
  - _/regexp/_ - match an element for the regular expression. Catches both terminals (tokens) and heads (branches).
  - _*_ - match any element. Use sparingly.
  - _(selector1,selector2,...)_ - match the selector(s) within the current context and use the resulting element. Useful for when more than one path is valid, and for lookaheads.

And here are the operators:

  - _a b_ - matches if a is a descendant of b (okay, it's the empty operator. Still counts)
  - _a > b_ - matches if b is a child of a
  - _a ~ b_ - matches a and b are siblings (have the same parent), and b comes after a.
  - _a + b_ - matches a and b are siblings, and b comes _immmediately_ after a.
  
Elements can also have modifiers (more to come!):

  - _element:is-parent_ - matches if the element ia a head (branch)
  - _element:is-leaf_ - matches if the element ia a terminal (token)

One last thing worth noting: Selectors always return the last element. If you want to return another element, prepend the yield operator (_=_) to it.

## Some examples

So how do we use them? Let's look at this Python expression from the [readme](/README.md)

    funccall(attrget(name('subprocess'), name('Popen')), arglist(arg(name('cmd')), arg(name('shell'), funccall(name('isinstance'), arglist(arg(name('cmd')), arg(name('basestring'))))), arg(name('bufsize'), name('bufsize')), arg(name('stdin'), name('PIPE')), arg(name('stdout'), name('PIPE')), arg(name('close_fds'), name('True'))))

It's a little messy, so you can use [this visualization](/docs/calling_popen.png) as reference.

Assuming it's stored in x, let's get all of the "name" heads:

    >>> x.select('name')
    [name('subprocess'), name('Popen'), name('cmd'), name('shell'), name('isinstance '), name('cmd'), ...

Simple enough. But suppose we just want the terminals? We can select them easily:

    >>> x.select('name *')
    ['subprocess', 'Popen', 'cmd', 'shell', 'isinstance', 'cmd', 'basestring', 'bufsize', 'bufsize', 'stdin', 'PIPE', 'stdout', 'PIPE', 'close_fds', 'True']

This is equivalent to x.select('name =\*'), but if we put the yield operator first, like '=name \*', the results would be similar to the previous code.

Now let's try to find all terminals containing the letter 'n'. We can use a regexp, but just using '/.\*n.\*' will give us 'name' heads etc., so let's use a modifier too:

    >>> x.select('/.*n.*/:is-leaf')
    ['Popen', 'isinstance', 'basestring', 'stdin']

Let's filter those terminals only for arguments:
    >>> x.select('arg /.*n.*/:is-leaf')
    ['isinstance', 'basestring', 'basestring', 'stdin']

Wait! Why did we get "basestring" twice? And why is "isinstance" there? It's not a bug! Using '=arg' reveals the source: arg is matched twice, once for the inner arg, and one for the outer. Let's filter only for the inner arg, based on the known structure:

    >>> x.select('arg > name > /.*n.*/:is-leaf') 
    ['basestring', 'stdin']
    
How about all of the keyword arguments used? (notice they are pairs of names inside an "arg" head)

    >>> x.select('arg =name ~ *')
    [name('isinstance'), name('shell'), name('bufsize'), name('stdin'), name('stdout'), name('close_fds')]

## Afterword

I hope this article was clear and helpful.

Selectors have many limitations, and you can't select everything that comes to mind, but hopefully they cover most of the useful cases.

If you have any questions or ideas, please email me at erez27+plyplus at gmail com


# PlyPlus tutorial.

In this section I'll show how to quickly write a list parser.

First we import the Grammar class:

    >>> from plyplus import Grammar

Now let's define the initial grammar:

    >>> list_parser = Grammar(r"start: name (',' name)* ; name: '\w+' ;")

A grammar is a collection of rules and tokens. In this example, we only use implicit tokens, by putting them in quotations. Let's dissect this grammar, which contains two rules:

Rule 1. --  start: name (',' name)\* ;

'start' is the rule's name. By default, parsing always starts with the 'start' rule.
The rule specifies that it must begin with a rule called 'name', follow by a sequence of (comma, name). The asterisk means that this sequence can have any length, including zero. The rule ends with a semicolon, as all rules must.

Rule 2. -- name: '\w+' ;

The rule 'name' (as referred to by start), contains just one token. The token is defined using a regular expression (all tokens are regexps), and matches words (any sequence of one or more letters). Note that we defined it in a new rule, instead of defining it anonymously in 'start', because plyplus filters the output for tokens that don't reside within their own rule. The rationale is that most tokens are useless punctuation, and in the cases that they aren't, the rule is useful to explain their significance.

Let's see the result of parsing with the grammar.

    >>> r=list_parser.parse('cat,milk,dog')
    >>> print r
    start(name(u'1:1|cat'), name(u'1:5|milk'), name(u'1:10|dog'))

The result is a STree instance, with a 'head' attribute of 'start' and a 'tail' attribute which is a list of nested STree instances. The tokens themselves are instances of str (or unicode) that contain extra information such as the line and column of the token in the text.

( Note: It's possible to keep the commas as well ("punctuation tokens"), by instanciating Grammar with auto\_filter\_tokens=False )

We can apply a simple list comprehension to get the list data:

    >>> [str(x.tail[0]) for x in r.tail]
    ['cat', 'milk', 'dog']

Or we can use selectors:

    >>> r.select('name>*')
    [u'1:1|cat', u'1:5|milk', u'1:10|dog']


That seems like a lot of overhead just to split a list, doesn't it? It is. But the beauty of using grammars is in how easy it is to add a lot of complexity. Now that we know the basics, let's write a grammar that takes a string of nested python-ish lists and returns a flat list of all the numbers in it.

    >>> list_parser = Grammar("""
            start: list ;                           // We only match a list
            @list : '\[' item (',' item)* '\]' ;   // Define a list
            @item : number | list ;                 // Define an item, provide nesting
            number: '\d+' ;
            SPACES: '[ ]+' (%ignore) ;              // Ignore spaces
            """)

    >>> res = list_parser.parse('[1, 2, [ [3,4], 5], [6,7   ] ]')
    >>> map(int, res.select('number>*'))
    [1, 2, 3, 4, 5, 6, 7]

This example contained some new elements, so here they are briefly:

1. Prepending '@' to a rule name tells plyplus to always expand it. This is why the rules '@list' and '@item' do not appear in the output.

2. Plyplus grammars support C++-like comments (// or /*..*/)

3. 'SPACES' is the first token we defined explicitly. It matches a sequence of spaces, and the special token flag '%ignore' tells plyplus not to include it when parsing (adding 'WHITESPACE+' everywhere would make the grammar very cumbersome, and slower).

Finally, if we have pydot and graphviz installed, we can visualize the tree by typing:

    >>> res.to_png_with_pydot('list_parser_tree.png')

![pydot visualization](https://raw.github.com/erezsh/plyplus/master/docs/list_parser_tree.png "pydot visualization")

The last example (for now) shows Plyplus' error handling. Let's say we forgot to open the brackets in the former sample input:

    >>> list_parser.parse('[1, 2,[], [ [3,4], 5], [6,7   ]]')
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
      File "plyplus\plyplus.py", line 505, in parse
        return self._grammar.parse(text)
      File "plyplus\plyplus.py", line 584, in parse
        raise ParseError('\n'.join(self.errors))
    plyplus.plyplus.ParseError: Syntax error in input at ']' (type _ANON_1) line 1 col 8
    Syntax error in input at ',' (type _ANON_3) line 1 col 22
    Syntax error in input at ']' (type _ANON_1) line 1 col 32
    Could not create parse tree!

Plyplus does not let the error pass quietly, and raises an exception. However, internally it keeps on going as far as it can, and raises the exception with a list of errors.



# PlyPlus - a friendly yet powerful LR-parser in Python.

Plyplus is a general-purpose parser built on top of [PLY](http://www.dabeaz.com/ply/), written in python, with a slightly different approach to parsing.

## Main Concepts

1. *Separation of code from grammar*: Grammar files are more readable and portable, and it makes the code cleaner too.

2. *Always build an AST (tree)*: Every application, not matter how small, can benefit from the power and simplicity of working with a tree, instead of a state-machine.

3. *Follow Python's Idioms*: Beauty, simplicity and readability are more important than speed. But Plyplus is fast enough!


## Features

 - EBNF grammar (supported: parentheses, '|', '\*', '?', and '+', inline tokens, token fragements, and more)
 - LR-parser
 - Builds an AST automagically based on the grammar
 - Selectors: run powerful css-like queries on the AST
 - Nested grammars (a grammar within a grammar. Useful for HTML/CSS, for example)
 - Unicode support
 - Python 2.7, Python 3.3 and PyPy 1.9 compatible
 - Fully-working Python 2.x grammar included

## Q & A

Q. How capable is Plyplus?

A. Plyplus is capable of parsing any LR-compatible grammar. It supports post-tokenizing code, so it's capable of parsing python (it comes with a ready-to-use python parser). Other features, such as sub-grammars, provide more flexibility to handle the trickier grammars.

Q. How fast is it?

A. Plyplus does not put speed as its first priority. However, right now it manages to parse the entire Python26/Libs directory (200 files, 4mb of text, including post-processing) in about 42 seconds on my humble dual-core 2ghz 2gb-ram machine (and 30 seconds with PyPy).

Q. So what is Plyplus' first priority?

A. Power and simplicity. See the examples and judge for yourself.

Q. I want to use Plyplus in a threaded application. Is it thread safe?

A. Yes, but you must pay attention. Plyplus relies on PLY, it can cause problems if you try to define multiple parsers at the same time using threads. Please make sure not to do that.


## Tutorials

Learn how to write a grammar for Plyplus at the [tutorial](/docs/tutorial.md)

Learn how to query the AST using [selectors](/docs/selectors.md)

## Examples

This section contains examples of plyplus usage. For a better explanation, check out [the tutorial](/docs/tutorial.md). If something is still not clear, feel free to email me and ask!

### Parsing Python

We'll use Plyplus' grammar for Python, and play with os.py for a bit (though it could be any Python file).

For starters, let's do something simple: Let's list all of the functions (or methods) in the os module. We'll query the AST using [selectors](/docs/selectors.md), so click the link if you want to be able to follow (or maybe an understanding of CSS/JQuery is enough?).

    >>> import plyplus, plyplus.grammars
    >>> g = plyplus.Grammar(plyplus.grammars.open('python.g'))   # load python grammar
    >>> t = g.parse(file(r'c:\python27\lib\os.py').read())                  # read os.py
    >>> t.select('funcdef > name > *:is-leaf')
    ['_get_exports_list', 'makedirs', 'removedirs', 'renames', 'walk', 'execl', 'execle', 'execlp', 'execlpe', ...

(Run it yourself for the full input)

Now let's count how many times os.py calls isinstance:

    >>> len(t.select('/isinstance/'))
    3

Interesting! But where in the file are they called? We can use the "line" attribute to find out (there's also a column attribute!):

    >>> [x.line for x in t.select('/isinstance/')]
    [669, 689, 709]

Let's look at one of those calls. We'll need to select more context for that.

    >>> t.select('=funccall > name > /isinstance/')[0]
    funccall(name('isinstance'), arglist(arg(name('cmd')), arg(name('basestring'))))

More context?

    >>> _.parent().parent().parent()
    funccall(attrget(name('subprocess'), name('Popen')), arglist(arg(name('cmd')), arg(name('shell'), funccall(...

Hard to read? Try looking at it visually! (requires pydot)

    >>> _.to_png_with_pydot(r'calling_popen.png')

[calling\_popen.png](/docs/calling_popen.png)

### Parsing INI files

INI files are too open-handed to be a good candidate for LR-parsing, but PlyPlus can handle them using nested grammars. By parsing different elements separately, a "]" symbol can be both a special token and just part of the text, all in the same file.

Let's parse an INI file that comes with NumPy.

    >>> g = plyplus.Grammar(plyplus.grammars.open('config.g'))   # load config grammar
    >>> t = g.parse(file(r"C:\Python26\Lib\site-packages\numpy\core\lib\npy-pkg-config\npymath.ini").read())

List the sections:

    >>> t.select('section > start > name *')
    ['meta', 'variables', 'default', 'msvc']

Let's look at the meta section

    >>> t.select('=section /meta/')
    [section(start(name('meta')), option(start(name('Name'), start(value('npymath')))), ...

(The start heads denote a sub-grammar)

Let's pretty-print it! We can use a transformer to do it. A transformer is a tree-visitor that returns a new value for each head (branch) it visits.

    >>> class PrettyINI(plyplus.STransformer):
        def option(self, tree):
            name = tree.select1('name *')   # select1 asserts only one result
            value = tree.select1('value *')
            return '%s = %s' % (name, value)
        def section(self, tree):
            name = tree.select1('name *')
            return '[%s]\n\t%s' % (name, '\n\t'.join(tree.tail[1:]))

Now that each rule has code to handle it, let's run it!

    >>> meta = t.select1('=section /meta/')
    >>> print PrettyINI().transform( meta )
    [meta]
            Name = npymath
            Description = Portable, core math library implementing C99 standard
            Version = 0.1

It works! Now that it's done, we can use it to output the rest of the file as well:

    >>> print '\n'.join( PrettyINI().transform(t).tail )
    ... (left as an excercise to the reader ;)


## License

Plyplus uses the [MIT license](https://github.com/jquery/jquery/blob/master/MIT-LICENSE.txt).

## Afterword

I hope this readme inspired you to play with Plyplus a bit, and maybe even use it for your project.

For more examples, check out the [test module](/plyplus/test/test_parser.py)

If you have any questions or ideas, please email me at erezshin+plyplus at gmail com

