__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Django Test Utils documentation build configuration file, created by
# sphinx-quickstart on Fri Apr  3 16:36:58 2009.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.append(os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.doctest', 'sphinx.ext.intersphinx']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Django Test Utils'
copyright = u'2009, Eric Holscher'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.3'
# The full version, including alpha/beta/rc tags.
release = '0.3'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
#unused_docs = []

# List of directories, relative to source directory, that shouldn't be searched
# for source files.
exclude_trees = []

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  Major themes that come with
# Sphinx are currently 'default' and 'sphinxdoc'.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_use_modindex = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = ''

# Output file base name for HTML help builder.
htmlhelp_basename = 'DjangoTestUtilsdoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'DjangoTestUtils.tex', ur'Django Test Utils Documentation',
   ur'Eric Holscher', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_use_modindex = True


# Example configuration for intersphinx: refer to the Python standard library.
intersphinx_mapping = {'http://docs.python.org/': None}

########NEW FILE########
__FILENAME__ = manage
#!/usr/bin/env python
from django.core.management import execute_manager
try:
    import settings # Assumed to be in the same directory.
except ImportError:
    import sys
    sys.stderr.write("Error: Can't find the file 'settings.py' in the directory containing %r. It appears you've customized things.\nYou'll have to run django-admin.py, passing it your settings module.\n" % __file__)
    sys.exit(1)

if __name__ == "__main__":
    execute_manager(settings)

########NEW FILE########
__FILENAME__ = admin
from polls.models import Poll, Choice
from django.contrib import admin

class ChoiceInline(admin.StackedInline):
    model = Choice
    extra = 3

class PollAdmin(admin.ModelAdmin):
    inlines = [ChoiceInline]

admin.site.register(Poll, PollAdmin)

########NEW FILE########
__FILENAME__ = models
from django.db import models

class Poll(models.Model):
    question = models.CharField(max_length=200)
    pub_date = models.DateTimeField('date published')
    slug = models.SlugField(null=True)

    def __unicode__(self):
        return self.question

class Choice(models.Model):
    poll = models.ForeignKey(Poll)
    choice = models.CharField(max_length=200)
    votes = models.IntegerField()

    def __unicode__(self):
        return self.choice

########NEW FILE########
__FILENAME__ = urls
from django.conf.urls.defaults import *
from models import Poll, Choice

info_dict = {
    'queryset': Poll.objects.all(),
}

urlpatterns = patterns('',
    (r'^$', 'django.views.generic.list_detail.object_list', info_dict),
    (r'^(?P<object_id>\d+)/$', 'django.views.generic.list_detail.object_detail', info_dict),
    url(r'^(?P<object_id>\d+)/results/$', 'django.views.generic.list_detail.object_detail', dict(info_dict, template_name='polls/results.html'), 'poll_results'),
    (r'^(?P<poll_id>\d+)/vote/$', 'polls.views.vote'),
)

########NEW FILE########
__FILENAME__ = views
# Create your views here.

from django.shortcuts import get_object_or_404, render_to_response
from django.http import HttpResponseRedirect
from django.core.urlresolvers import reverse
from polls.models import Poll, Choice

def vote(request, poll_id):
    p = get_object_or_404(Poll, pk=poll_id)
    try:
        selected_choice = p.choice_set.get(pk=request.POST['choice'])
    except (KeyError, Choice.DoesNotExist):
        # Redisplay the poll voting form.
        return render_to_response('polls/detail.html', {
            'poll': p,
            'error_message': "You didn't select a choice.",
        })
    else:
        selected_choice.votes += 1
        selected_choice.save()
        # Always return an HttpResponseRedirect after successfully dealing
        # with POST data. This prevents data from being posted twice if a
        # user hits the Back button.
        return HttpResponseRedirect("/polls/%s/results/" % p.id)

def results(request, poll_id):
    p = get_object_or_404(Poll, pk=poll_id)
    return render_to_response('polls/results.html', {'poll': p})

########NEW FILE########
__FILENAME__ = runtests
#This file mainly exists to allow python setup.py test to work.

import os, sys
os.environ['DJANGO_SETTINGS_MODULE'] = 'test_project.settings'

test_dir = os.path.dirname(__file__)
sys.path.insert(0, test_dir)

from django.test.utils import get_runner
from django.conf import settings

def runtests():
    test_runner = get_runner(settings)
    failures = test_runner([])
    sys.exit(failures)

if __name__ == '__main__':
    runtests()

########NEW FILE########
__FILENAME__ = settings
# Django settings for paradigm project.
import os
PROJECT_DIR = os.path.dirname(__file__)

#DEBUG = True
DEBUG = False
TEMPLATE_DEBUG = DEBUG

ADMINS = ()

MANAGERS = ADMINS

DATABASE_ENGINE = 'sqlite3'           # 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'.
DATABASE_NAME = PROJECT_DIR + '/test_settings.db'             # Or path to database file if using sqlite3.
#mckenzie

# Local time zone for this installation. Choices can be found here:
# http://en.wikipedia.org/wiki/List_of_tz_zones_by_name
# although not all choices may be available on all operating systems.
# If running in a Windows environment this must be set to the same as your
# system time zone.
TIME_ZONE = 'America/Chicago'

# Language code for this installation. All choices can be found here:
# http://www.i18nguy.com/unicode/language-identifiers.html
LANGUAGE_CODE = 'en-us'

SITE_ID = 1

# If you set this to False, Django will make some optimizations so as not
# to load the internationalization machinery.
USE_I18N = True

# Absolute path to the directory that holds media.
# Example: "/home/media/media.lawrence.com/"
MEDIA_ROOT = ''

# URL that handles the media served from MEDIA_ROOT. Make sure to use a
# trailing slash if there is a path component (optional in other cases).
# Examples: "http://media.lawrence.com", "http://example.com/media/"
MEDIA_URL = ''

# URL prefix for admin media -- CSS, JavaScript and images. Make sure to use a
# trailing slash.
# Examples: "http://foo.com/media/", "/media/".
ADMIN_MEDIA_PREFIX = '/media/'

# Make this unique, and don't share it with anybody.
SECRET_KEY = ''

# List of callables that know how to import templates from various sources.
TEMPLATE_LOADERS = (
    'django.template.loaders.filesystem.load_template_source',
    'django.template.loaders.app_directories.load_template_source',
)

MIDDLEWARE_CLASSES = (
    'django.middleware.common.CommonMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
)

ROOT_URLCONF = 'urls'

TEMPLATE_DIRS = (
    os.path.join(PROJECT_DIR, 'templates')
)

INSTALLED_APPS = (
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.comments',
    'django.contrib.sessions',
    'django.contrib.sites',
    'django.contrib.admin',
    'polls',
    'test_app',
)

########NEW FILE########
__FILENAME__ = models
from django.db import models

# Create your models here.

########NEW FILE########
__FILENAME__ = assertions_tests
from unittest import TestCase
from test_utils.assertions import DiffTestCaseMixin

class TestAssertions(TestCase, DiffTestCaseMixin):
    """
    Tests to test assertions in test utils.
    """

    def test_assert_no_diff_dict(self):
        dict1 = {'I love': 'you'}
        dict2 = {'I love': 'moo'}
        try:
            self.failIfDiff(dict1, dict2)
        except AssertionError, e:
            self.failIfDiff(e.message, """\n--- First \n\n+++ Second \n\n@@ -1,1 +1,1 @@\n\n-'I love':'you'\n+'I love':'moo'\n""")

    def test_assert_no_diff_list(self):
        list1 = ['I love', 'you']
        list2 = ['I love', 'to moo']
        try:
            self.failIfDiff(list1, list2)
        except AssertionError, e:
            self.failIfDiff(e.message, """\n--- First \n\n+++ Second \n\n@@ -1,2 +1,2 @@\n\n 'I love'\n-'you'\n+'to moo'\n""")

########NEW FILE########
__FILENAME__ = crawler_tests
"""
This file is to test testmaker. It will run over the polls app and with the crawler and with test maker outputting things. Hopefully this will provide a sane way to test testmaker.
"""
from django.test.testcases import TestCase
from test_utils.crawler.base import Crawler
import logging
import os

class CrawlerTests(TestCase):
    """
    Tests to test the Crawler API
    """
    urls = "test_project.polls.urls"
    fixtures = ['polls_testmaker.json']

    def setUp(self):
        self.log = logging.getLogger('crawler')
        [self.log.removeHandler(h) for h in self.log.handlers]
        self.log.setLevel(logging.DEBUG)
        handler = logging.FileHandler('crawler_log', 'a')
        handler.setFormatter(logging.Formatter('%(message)s'))
        self.log.addHandler(handler)

    def tearDown(self):
        os.remove('crawler_log')

    def test_basic_crawling(self):
        c = Crawler('/')
        c.run()
        self.assertEqual(c.crawled, {'/': True, u'/1': True, u'/2': True})

    def test_relative_crawling(self):
        c = Crawler('/1')
        c.run()
        self.assertEqual(c.crawled, {u'/1': True})

    def test_url_plugin(self):
        conf_urls = {'this_wont_be_crawled': True}
        c = Crawler('/', conf_urls=conf_urls)
        c.run()
        logs = open('crawler_log')
        output = logs.read()
        self.assertTrue(output.find('These patterns were not matched during the crawl: this_wont_be_crawled') != -1)

    def test_time_plugin(self):
        #This isn't testing much, but I can't know how long the time will take
        c = Crawler('/')
        c.run()
        logs = open('crawler_log')
        output = logs.read()
        self.assertTrue(output.find('Time taken:') != -1)

    def test_memory_plugin(self):
        from test_utils.crawler.plugins.memory_plugin import Memory
        Memory.active = True
        c = Crawler('/')
        c.run()
        logs = open('crawler_log')
        output = logs.read()
        self.assertTrue(output.find('Memory consumed:') != -1)


    #Guppy makes the tests take a lot longer, uncomment this if you want to
    #test it.
    """
    def test_guppy_plugin(self):
        #This isn't testing much, but I can't know how long the time will take
        from test_utils.crawler.plugins.guppy_plugin import ACTIVE, Heap
        if ACTIVE:
            Heap.active = True
            c = Crawler('/')
            c.run()
            logs = open('crawler_log')
            output = logs.read()
            import ipdb; ipdb.set_trace()
            self.assertTrue(output.find('heap') != -1)
        else:
            print "Skipping memory test, as guppy isn't installed"
    """

########NEW FILE########
__FILENAME__ = templatetags_tests
import os
from django.test.testcases import TestCase
from django.template import Context, Template
from django.contrib.auth.models import User
from test_utils.templatetags import TemplateParser
from test_utils.testmaker import Testmaker

from django.contrib.auth.models import User

class Parsing(TestCase):
   """
   Tests to test the parsing API
   """

   def setUp(self):
      self.tm = Testmaker()
      self.tm.setup_logging('test_file', 'serialize_file')

   def tearDown(self):
      #Teardown logging somehow?
      os.remove('test_file')
      os.remove('serialize_file')

   def test_basic_parsing(self):
      user = User.objects.create_user('john', 'lennon@thebeatles.com', 'johnpassword')
      user.save()
      c = Context({'object': user})
      t = TemplateParser('{% load comments %}{% get_comment_list for object as as_var %}{{ as_var }}', c)
      t.parse()
      self.assertEquals(t.template_calls[0], '{% get_comment_list for object as as_var %}')
      self.assertEquals(t.loaded_classes[0], '{% load comments %}')
      t.create_tests()
      logs = open('test_file')
      output = logs.read()
      self.assertTrue(output.find("{'object': get_model('auth', 'user')") != -1)

########NEW FILE########
__FILENAME__ = testmaker_tests
"""
This file is to test testmaker. It will run over the polls app and with the crawler and with test maker outputting things. Hopefully this will provide a sane way to test testmaker.
"""
from django.test.testcases import TestCase
from test_utils.testmaker import Testmaker
from django.conf import settings
import os

class TestMakerTests(TestCase):
    """
    Tests to test basic testmaker functionality.
    """
    urls = "test_project.polls.urls"
    fixtures = ['polls_testmaker.json']

    def setUp(self):
        self.tm = Testmaker()
        self.tm.setup_logging('test_file', 'serialize_file')
        Testmaker.enabled = True
        self.tm.insert_middleware()

    def tearDown(self):
        #Teardown logging somehow?
        os.remove('test_file')
        os.remove('serialize_file')

    def test_basic_testmaker(self):
        self.client.get('/')
        logs = open('test_file')
        output = logs.read()
        self.assertTrue(output.find('[<Poll: What\'s up?>, <Poll: Test poll>]') != -1)

    def test_twill_processor(self):
        settings.TESTMAKER_PROCESSOR = 'twill'
        self.client.get('/')
        self.client.get('/1/')
        logs = open('test_file')
        output = logs.read()
        self.assertTrue(output.find('code 200') != -1)

    def test_not_inserting_multiple_times(self):
        """
        Test that the middleware will only be inserted once.
        """
        self.tm.insert_middleware()
        self.tm.insert_middleware()
        middleware = settings.MIDDLEWARE_CLASSES
        #A set of the middleware should be the same, meaning the item isn't in twice.
        self.assertEqual(sorted(list(middleware)), sorted(list(set(middleware))))

########NEW FILE########
__FILENAME__ = twill_tests
__doc__ = """
### test setup() and teardown() logic

>>> from test_utils.utils.twill_runner import *
>>> from django.conf import settings
>>> setup()
<..._EasyTwillBrowser object at ...>
>>> setup()                                # no duplicate registrations
False
>>> len(INSTALLED)
1
>>> teardown()
True
>>> len(INSTALLED)
0

>>> setup(host='myhost', port=40)
<..._EasyTwillBrowser object at ...>
>>> setup(host='myhost', port=10)
<..._EasyTwillBrowser object at ...>
>>> teardown(port=10)                      # exact match OR no arguments to pop last required
False
>>> teardown()                             # this will remove the last
True
>>> len(INSTALLED)                         # one handler is still registered
1
>>> teardown(host='myhost', port=40)       # remove it by exact match
True
>>> len(INSTALLED)
0

>>> settings.DEBUG_PROPAGATE_EXCEPTIONS = False
>>> setup(propagate=True)
<..._EasyTwillBrowser object at ...>
>>> settings.DEBUG_PROPAGATE_EXCEPTIONS
True
>>> teardown()
True
>>> settings.DEBUG_PROPAGATE_EXCEPTIONS
False
>>> len(INSTALLED)
0


### test relative url handling ###
# Note that for simplicities sake we only
# check whether our custom code appended a
# host name; the twill browser base class
# never gets to see the urls, and we don't
# know what it makes of it.

# put browser into testing mode
>>> browser = get_browser()
>>> browser._testing_ = True

>>> setup(host='a', port=1)
<..._EasyTwillBrowser object at ...>

>>> browser.go('/')
'http://a:1/'
>>> browser.go('/index')
'http://a:1/index'

>>> browser.go('http://google.de')
'http://google.de'
>>> browser.go('/services')
'/services'
>>> browser.go('')
''
>>> browser.go('?foo=bar')
'?foo=bar'

>>> browser.go('/index', default=True)
'http://a:1/index'

# TODO: since we don't work with real urls, we don't get anything back. Improve.
>>> url()

>>> teardown()
True
>>> len(INSTALLED)
0

# leave testing mode again
>>> browser._testing_ = False

# TODO: test the login/logout methods
"""

########NEW FILE########
__FILENAME__ = urls
from django.conf.urls.defaults import *

from django.contrib import admin
admin.autodiscover()

urlpatterns = patterns('',
    # Example:
    (r'^polls/', include('polls.urls')),
    (r'^admin/doc/', include('django.contrib.admindocs.urls')),
    url(r'^admin/(.*)', admin.site.root, name='admin-root'),

)

########NEW FILE########
__FILENAME__ = assertions
"""
Code originally from: http://www.aminus.org/blogs/index.php/2009/01/09/assertnodiff
"""

import difflib
from pprint import pformat


class DiffTestCaseMixin(object):

    def get_diff_msg(self, first, second,
                     fromfile='First', tofile='Second'):
        """Return a unified diff between first and second."""
        # Force inputs to iterables for diffing.
        # use pformat instead of str or repr to output dicts and such
        # in a stable order for comparison.
        if isinstance(first, (tuple, list)):
            first = [pformat(d) for d in first]
        elif isinstance(first, dict):
            first = ["%s:%s" % (pformat(key), pformat(val)) for key,val in first.iteritems()]
        else:
            first = [pformat(first)]

        if isinstance(second, (tuple, list)):
            second = [pformat(d) for d in second]
        elif isinstance(second, dict):
            second = ["%s:%s" % (pformat(key), pformat(val)) for key,val in second.iteritems()]
        else:
            second = [pformat(second)]

        diff = difflib.unified_diff(
            first, second, fromfile=fromfile, tofile=tofile)
        # Add line endings.
        return '\n' + ''.join([d + '\n' for d in diff])

    def failIfDiff(self, first, second, fromfile='First', tofile='Second'):
        """If not first == second, fail with a unified diff."""
        if not first == second:
            msg = self.get_diff_msg(first, second, fromfile, tofile)
            raise self.failureException, msg

########NEW FILE########
__FILENAME__ = django_test_runner
#!/usr/bin/env python
"""
Many thanks to Brian Rosner <oebfare.com> for letting me include
this code in Test Utils.
"""

import os
import sys

from optparse import OptionParser

from django.conf import settings
from django.core.management import call_command

def main():
    """
The entry point for the script. This script is fairly basic. Here is a
quick example of how to use it::

    django_test_runner.py [path-to-app]

You must have Django on the PYTHONPATH prior to running this script. This
script basically will bootstrap a Django environment for you.

By default this script with use SQLite and an in-memory database. If you
are using Python 2.5 it will just work out of the box for you.
"""
    parser = OptionParser()
    parser.add_option("--DATABASE_ENGINE", dest="DATABASE_ENGINE", default="sqlite3")
    parser.add_option("--DATABASE_NAME", dest="DATABASE_NAME", default="")
    parser.add_option("--DATABASE_USER", dest="DATABASE_USER", default="")
    parser.add_option("--DATABASE_PASSWORD", dest="DATABASE_PASSWORD", default="")
    parser.add_option("--SITE_ID", dest="SITE_ID", type="int", default=1)

    options, args = parser.parse_args()

    # check for app in args
    try:
        app_path = args[0]
    except IndexError:
        print "You did not provide an app path."
        raise SystemExit
    else:
        if app_path.endswith("/"):
            app_path = app_path[:-1]
        parent_dir, app_name = os.path.split(app_path)
        sys.path.insert(0, parent_dir)

    settings.configure(**{
        "DATABASE_ENGINE": options.DATABASE_ENGINE,
        "DATABASE_NAME": options.DATABASE_NAME,
        "DATABASE_USER": options.DATABASE_USER,
        "DATABASE_PASSWORD": options.DATABASE_PASSWORD,
        "SITE_ID": options.SITE_ID,
        "ROOT_URLCONF": "",
        "TEMPLATE_LOADERS": (
            "django.template.loaders.filesystem.load_template_source",
            "django.template.loaders.app_directories.load_template_source",
        ),
        "TEMPLATE_DIRS": (
            os.path.join(os.path.dirname(__file__), "templates"),
        ),
        "INSTALLED_APPS": (
            # HACK: the admin app should *not* be required. Need to spend some
            # time looking into this. Django #8523 has a patch for this issue,
            # but was wrongly attached to that ticket. It should have its own
            # ticket.
            "django.contrib.admin",
            "django.contrib.auth",
            "django.contrib.contenttypes",
            "django.contrib.sessions",
            "django.contrib.sites",
            app_name,
        ),
    })
    call_command("test")

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = base
from HTMLParser import HTMLParseError
import logging
import os
import urlparse

from django.conf import settings
from django.db import transaction
from django.views.debug import cleanse_setting
from django.test.client import Client
from django.test.utils import setup_test_environment, teardown_test_environment

from test_utils.crawler import signals as test_signals
from test_utils.crawler.plugins.base import Plugin

LOG = logging.getLogger('crawler')

try:
    import lxml.html
    def link_extractor(html):
        try:
            tree = lxml.html.document_fromstring(html)
        except lxml.etree.ParseError, e:
            raise HTMLParseError(str(e), e.position)

        for element, attribute, link, pos in tree.iterlinks():
            yield link
except ImportError:
    LOG.info("Processing documents with HTMLParser; install lxml for greater performance")

    from HTMLParser import HTMLParser

    def link_extractor(html):
        class LinkExtractor(HTMLParser):
            links = set()

            def handle_starttag(self, tag, attrs):
                self.links.update(
                    v for k, v in attrs if k == "href" or k =="src"
                )

        parser = LinkExtractor()
        parser.feed(html)
        parser.close()

        return parser.links


class Crawler(object):
    """
    This is a class that represents a URL crawler in python
    """

    def __init__(self, base_url, conf_urls={}, verbosity=1, output_dir=None, ascend=True, **kwargs):
        self.base_url = base_url
        self.conf_urls = conf_urls
        self.verbosity = verbosity
        self.ascend = ascend

        auth = kwargs.get('auth')

        if output_dir:
            assert os.path.isdir(output_dir)
            self.output_dir = os.path.realpath(output_dir)
            LOG.info("Output will be saved to %s" % self.output_dir)
        else:
            self.output_dir = None

        #These two are what keep track of what to crawl and what has been.
        self.not_crawled = [(0, 'START',self.base_url)]
        self.crawled = {}

        self.c = Client(REMOTE_ADDR='127.0.0.1')

        if auth:
            printable_auth = ', '.join(
                '%s: %s' % (key, cleanse_setting(key.upper(), value))
                for key, value in auth.items())
            LOG.info('Log in with %s' % printable_auth)
            self.c.login(**auth)

        self.plugins = []
        for plug in Plugin.__subclasses__():
            active = getattr(plug, 'active', True)
            if active:
                #TODO: Check if plugin supports writing CSV (or to a file in general?)
                self.plugins.append(plug())

    def _parse_urls(self, url, resp):
        parsed = urlparse.urlparse(url)

        if resp['Content-Type'] == "text/html; charset=utf-8":
            html = resp.content.decode("utf-8")
        else:
            html = resp.content

        returned_urls = []

        for link in link_extractor(html):
            parsed_href = urlparse.urlparse(link)

            if not parsed_href.path:
                continue

            if parsed_href.scheme and not parsed_href.netloc.startswith("testserver"):
                LOG.debug("Skipping external link: %s", link)
                continue
                
            if parsed_href.path.startswith(settings.STATIC_URL) or \
                    parsed_href.path.startswith(settings.MEDIA_URL):
                LOG.debug("Skipping static/media link: %s", link)
                continue

            if parsed_href.path.startswith('/'):
                returned_urls.append(link)
            else:
                # We'll use urlparse's urljoin since that handles things like <a href="../foo">
                returned_urls.append(urlparse.urljoin(url, link))

        return returned_urls

    def get_url(self, from_url, to_url):
        """
        Takes a url, and returns it with a list of links
        This uses the Django test client.
        """
        parsed = urlparse.urlparse(to_url)
        request_dict = dict(urlparse.parse_qsl(parsed.query))
        url_path = parsed.path

        #url_path now contains the path, request_dict contains get params

        LOG.debug("%s: link to %s with parameters %s", from_url, to_url, request_dict)

        test_signals.pre_request.send(self, url=to_url, request_dict=request_dict)

        resp = self.c.get(url_path, request_dict, follow=False)

        test_signals.post_request.send(self, url=to_url, response=resp)

        if resp.status_code in (301, 302):
            location = resp["Location"]
            if location.startswith("http://testserver"):
                LOG.debug("%s: following redirect to %s", to_url, location)
                # Mmm, recursion TODO: add a max redirects limit?
                return self.get_url(from_url, location)
            else:
                LOG.info("%s: not following off-site redirect to %s", to_url, location)
                return (resp, ())
        elif 400 <= resp.status_code < 600:
            # We'll avoid logging a warning for HTTP statuses which aren't in the
            # official error ranges:
            LOG.warning("%s links to %s, which returned HTTP status %d", from_url, url_path, resp.status_code)
            return (resp, ())

        if resp['Content-Type'].startswith("text/html"):
            returned_urls = self._parse_urls(to_url, resp)
            test_signals.urls_parsed.send(self, fro=to_url, returned_urls=returned_urls)
        else:
            returned_urls = list()

        return (resp, returned_urls)

    def run(self, max_depth=3):
        for p in self.plugins:
            p.set_output_dir(self.output_dir)

        old_DEBUG = settings.DEBUG
        settings.DEBUG = False

        setup_test_environment()
        test_signals.start_run.send(self)

        # To avoid tainting our memory usage stats with startup overhead we'll
        # do one extra request for the first page now:
        self.c.get(*self.not_crawled[0][-1])

        while self.not_crawled:
            #Take top off not_crawled and evaluate it
            current_depth, from_url, to_url = self.not_crawled.pop(0)
            if current_depth > max_depth:
                continue

            transaction.enter_transaction_management()
            try:
                resp, returned_urls = self.get_url(from_url, to_url)
            except HTMLParseError, e:
                LOG.error("%s: unable to parse invalid HTML: %s", to_url, e)
            except Exception, e:
                LOG.exception("%s had unhandled exception: %s", to_url, e)
                continue
            finally:
                transaction.rollback()

            self.crawled[to_url] = True
            #Find its links that haven't been crawled
            for base_url in returned_urls:
                if not self.ascend and not base_url.startswith(self.base_url):
                    LOG.debug("Skipping %s - outside scope of %s", base_url, self.base_url)
                    continue

                if base_url not in [to for dep,fro,to in self.not_crawled] and not self.crawled.has_key(base_url):
                    self.not_crawled.append((current_depth+1, to_url, base_url))

        test_signals.finish_run.send(self)

        teardown_test_environment()

        settings.DEBUG = old_DEBUG

########NEW FILE########
__FILENAME__ = base
from test_utils.crawler import signals as test_signals

class Plugin(object):
    """
    This is a class to represent a plugin to the Crawler.
    Subclass it and define a start or stop function to be called on requests.
    Define a print_report function if your plugin outputs at the end of the run.
    """
    global_data = {}

    def __init__(self):
        #This should be refactored to call each of the subclasses.
        #Having them use the signal function signature is hacky..

        if hasattr(self, 'pre_request'):
            test_signals.pre_request.connect(self.pre_request)
        if hasattr(self, 'post_request'):
            test_signals.post_request.connect(self.post_request)
        if hasattr(self, 'start_run'):
            test_signals.start_run.connect(self.start_run)
        if hasattr(self, 'finish_run'):
            test_signals.finish_run.connect(self.finish_run)
        if hasattr(self, 'urls_parsed'):
            test_signals.urls_parsed.connect(self.urls_parsed)

        self.data = self.global_data[self.__class__.__name__] = {}

        # This will be updated when a run starts if the user wants output to
        # be saved:
        self.output_dir = None

    """
    #These functions enable instance['test'] to save to instance.data
    def __setitem__(self, key, val):
        self.global_data[self.__class__.__name__][key] = val

    def __getitem__(self, key):
        return self.global_data[self.__class__.__name__][key]
    """

    def set_output_dir(self, output_dir):
        """
        Extension point for subclasses to open files, create directories, etc.
        """

        self.output_dir = output_dir
########NEW FILE########
__FILENAME__ = graph
from base import Plugin

class Graph(Plugin):
    "Make pretty graphs of your requests"
    active = False

    def __init__(self):
        super(Graph, self).__init__()
        self.request_graph = self.data['request_graph'] = {}
        import pygraphviz
        self.graph = pygraphviz.AGraph(directed=True)

    def urls_parsed(self, sender, fro, returned_urls, **kwargs):
        from_node = self.graph.add_node(str(fro), shape='tripleoctagon')
        for url in returned_urls:
            if not self.graph.has_node(str(url)):
                node = self.graph.add_node(str(url))
                self.graph.add_edge(str(fro), str(url))

    def finish_run(self, sender, **kwargs):
        print "Making graph of your URLs, this may take a while"
        self.graph.layout(prog='fdp')
        self.graph.draw('my_urls.png')

PLUGIN = Graph

########NEW FILE########
__FILENAME__ = guppy_plugin
import csv
import logging
import os

from django.template.defaultfilters import filesizeformat

from guppy import hpy

from base import Plugin

LOG = logging.getLogger("crawler")


class Heap(Plugin):
    """
    Calculate heap consumed before and after request
    """

    def __init__(self):
        super(Heap, self).__init__()
        self.heap_urls = self.data['heap_urls'] = {}
        self.hp = hpy()
        self.csv_writer = None

    def set_output_dir(self, output_dir=None):
        super(Heap, self).set_output_dir(output_dir)

        if output_dir:
            self.csv_writer = csv.writer(open(os.path.join(output_dir, 'heap.csv'), 'w'))

    def pre_request(self, sender, **kwargs):
        url = kwargs['url']
        self.hp.setrelheap()

    def post_request(self, sender, **kwargs):
        url = kwargs['url']
        heap = self.hp.heap()
        self.heap_urls[url] = heap.size

        LOG.debug("%s: heap consumed: %s", url, filesizeformat(self.heap_urls[url]))

        if self.csv_writer:
            self.csv_writer.writerow([url, heap.size])

    def finish_run(self, sender, **kwargs):
        "Print the most heap consumed by a view"

        alist = sorted(self.heap_urls.iteritems(),
            key=lambda (k,v): (v,k),
            reverse=True
        )

        for url, mem in alist[:10]:
            LOG.info("%s: %s heap", url, filesizeformat(mem))


PLUGIN = Heap
########NEW FILE########
__FILENAME__ = memory_plugin
import csv
import logging
import os

from base import Plugin

LOG = logging.getLogger("crawler")

# from python mailing list http://mail.python.org/pipermail/python-list/2004-June/266257.html
_proc_status = '/proc/%d/status' % os.getpid()  # Linux only?
_scale = {'kB': 1024.0, 'mB': 1024.0*1024.0,
           'KB': 1024.0, 'MB': 1024.0*1024.0}

def _VmB(VmKey):
    global _scale
    try: # get the /proc/<pid>/status pseudo file
        t = open(_proc_status)
        v = [v for v in t.readlines() if v.startswith(VmKey)]
        t.close()
         # convert Vm value to bytes
        if len(v) == 1:
           t = v[0].split()  # e.g. 'VmRSS:  9999  kB'
           if len(t) == 3:  ## and t[0] == VmKey:
               return float(t[1]) * _scale.get(t[2], 0.0)
    except:
        pass
    return 0.0

def memory(since=0.0):
    '''Return process memory usage in bytes.
    '''
    return _VmB('VmSize:') - since

def stacksize(since=0.0):
    '''Return process stack size in bytes.
    '''
    return _VmB('VmStk:') - since


class Memory(Plugin):
    """
    Calculate proc memory consumed before and after request
    """
    active = False

    def __init__(self, write_csv=False):
        super(Memory, self).__init__()
        self.memory_urls = self.data['memory_urls'] = {}
        self.write_csv = write_csv
        if self.write_csv:
            self.csv_writer = csv.writer(open('memory.csv', 'w'))

    def pre_request(self, sender, **kwargs):
        url = kwargs['url']
        self.memory_urls[url] = memory()

    def post_request(self, sender, **kwargs):
        cur = memory()
        url = kwargs['url']
        old_memory = self.memory_urls[url]
        total_memory = cur - old_memory
        self.memory_urls[url] = total_memory
        LOG.info("Memory consumed: %s", self.memory_urls[url])
        if self.write_csv:
            self.csv_writer.writerow([url,cur, old_memory, total_memory])

    def finish_run(self, sender, **kwargs):
        "Print the most memory consumed by a view"
        alist = sorted(self.memory_urls.iteritems(), key=lambda (k,v): (v,k), reverse=True)
        for url, mem in alist[:10]:
            LOG.info("%s took %f of memory", url, mem)

PLUGIN = Memory
########NEW FILE########
__FILENAME__ = pdb
import logging

from base import Plugin

LOG = logging.getLogger("crawler")

class Pdb(Plugin):
    "Run pdb on fail"
    active = False

    def post_request(self, sender, **kwargs):
        url = kwargs['url']
        resp = kwargs['response']
        if hasattr(resp, 'status_code'):
            if not resp.status_code in (200, 302, 301):
                LOG.error("%s: Status Code: %s", url, resp.status_code)
                try:
                    import ipdb; ipdb.set_trace()
                except ImportError:
                    import pdb; pdb.set_trace()

PLUGIN = Pdb
########NEW FILE########
__FILENAME__ = query_count
import csv
import logging
import os

from django.conf import settings
from django.db import connections

from base import Plugin


LOG = logging.getLogger('crawler')


class QueryCount(Plugin):
    """
    Report the number of queries used to serve a page
    """

    def __init__(self):
        super(QueryCount, self).__init__()

        self.csv_writer = None

        self.query_counts = self.data['query_counts'] = {}

        # Horrible monkey-patch to log query counts when DEBUG = False:
        for conn in connections.all():
            conn.dtu_query_count = 0
            self._monkey_cursor_execute(conn)

    def _monkey_cursor_execute(self, conn):
            old_cursor = conn.cursor
            def new_cursor(*args, **kwargs):
                c = old_cursor(*args, **kwargs)

                old_execute = c.execute
                def new_execute(*args, **kwargs):
                    try:
                        return old_execute(*args, **kwargs)
                    finally:
                            conn.dtu_query_count += 1
                c.execute = new_execute

                old_executemany = c.executemany
                def new_executemany(s, sql, param_list, *args, **kwargs):
                    try:
                        return old_executemany(s, sql, param_list, *args, **kwargs)
                    finally:
                            conn.dtu_query_count += len(param_list)
                c.executemany = new_executemany

                return c

            conn.cursor = new_cursor

    def set_output_dir(self, output_dir=None):
        super(QueryCount, self).set_output_dir(output_dir)

        if output_dir:
            self.csv_writer = csv.writer(open(os.path.join(output_dir, 'query_counts.csv'), 'w'))

    def pre_request(self, sender, **kwargs):
        url = kwargs['url']
        self.query_counts[url] = dict((c.alias, c.dtu_query_count) for c in connections.all())

    def post_request(self, sender, **kwargs):
        url = kwargs['url']

        new_query_counts = [(c.alias, c.dtu_query_count) for c in connections.all()]

        deltas = {}
        for k, v in new_query_counts:
            # Skip inactive connections:
            delta = v - self.query_counts[url][k]
            if delta > 0:
                deltas[k] = delta

        for k, v in sorted(deltas.items(), reverse=True):
            if v > 50:
                log_f = LOG.critical
            elif v > 20:
                log_f = LOG.error
            elif v > 10:
                log_f = LOG.warning
            else:
                log_f = LOG.info
            log_f("%s: %s %d queries", url, k, v)

        if self.csv_writer:
            self.csv_writer.writerow((url, sum(deltas.values())))


PLUGIN = QueryCount
########NEW FILE########
__FILENAME__ = sanitize
import logging

from BeautifulSoup import BeautifulSoup

from base import Plugin

LOG = logging.getLogger("crawler")

class Sanitize(Plugin):
    "Make sure your response is good"

    def post_request(self, sender, response, **kwargs):
        if not response['Content-Type'].startswith("text/html"):
            return

        if response['Content-Type'] == "text/html; charset=utf-8":
            html = response.content.decode("utf-8")
        else:
            html = response.content

        try:
            soup = BeautifulSoup(html)
            if soup.find(text='&lt;') or soup.find(text='&gt;'):
                LOG.warning("%s has dirty html", kwargs['url'])
        except Exception, e:
            # TODO: Derive unique names so we can continue after errors without clobbering past error pages
            fo = open("temp.html", 'w')
            fo.write(kwargs['response'].content)
            fo.close()
            LOG.error('Saved bad html to file temp.html')
            raise e


PLUGIN = Sanitize
########NEW FILE########
__FILENAME__ = tidy
# encoding: utf-8
"""
HTML validation plugin which uses Jason Stitt's pytidylib wrapper for HTML Tidy

Prerequisites:
    tidylib: http://tidy.sourceforge.net/
    pytidylib: http://countergram.com/software/pytidylib/
"""

import logging
import re

import tidylib

from base import Plugin

# Based on http://stackoverflow.com/questions/92438/stripping-non-printable-characters-from-a-string-in-python
#
# We omit chars 9-13 (tab, newline, vertical tab, form feed, return) and 32
# (space) to avoid clogging our reports with warnings about common,
# non-problematic codes but still allow stripping things which will cause most
# XML parsers to choke

CONTROL_CHAR_RE = re.compile('[%s]' % "".join(
    re.escape(unichr(c)) for c in range(0, 8) + range(14, 31) + range(127, 160)
))

LOG = logging.getLogger("crawler")

class Tidy(Plugin):
    "Make sure your response is good"

    def post_request(self, sender, response, url=None, **kwargs):
        if not response['Content-Type'].startswith("text/html"):
            return

        # Check for redirects to avoid validation errors for empty responses:
        if response.status_code in (301, 302):
            return
        elif 400 <= response.status_code < 600:
            # We'll still validate error pages (they have user-written HTML, too)
            LOG.warning(
                "%s: Validating HTTP %d error page",
                url,
                response.status_code
            )
        elif response.status_code != 200:
            LOG.warning(
                "%s: Validating unusual HTTP %d response",
                url,
                response.status_code
            )

        # TODO: Decide how to handle character encodings more
        # intelligently - sniff? Scream bloody murder if charset isn't in
        # the HTTP headers?
        if response['Content-Type'] == "text/html; charset=utf-8":
            html = response.content.decode("utf-8")
        else:
            html = response.content

        if not html:
            LOG.error("%s: not processing empty response", url)
            return

        # First, deal with embedded control codes:
        html, sub_count = CONTROL_CHAR_RE.subn(" ", html)
        if sub_count:
            LOG.warning("%s: Stripped %d control characters from body: %s",
                url,
                sub_count,
                set(hex(ord(i)) for i in CONTROL_CHAR_RE.findall(html))
            )

        tidied_html, messages = tidylib.tidy_document(
            html.strip(),
            {
                "char-encoding":               "utf8",
                "clean":                        False,
                "drop-empty-paras":             False,
                "drop-font-tags":               False,
                "drop-proprietary-attributes":  False,
                "fix-backslash":                False,
                "indent":                       False,
                "output-xhtml":                 False,
            }
        )

        messages = filter(None, (l.strip() for l in messages.split("\n")))

        errors = []
        warnings = []

        for msg in messages:
            if "Error:" in msg:
                errors.append(msg)
            else:
                warnings.append(msg)

        if errors:
            LOG.error(
                "%s: HTML validation errors:\n\t%s",
                url,
                "\n\t".join(errors)
            )

        if warnings:
            LOG.warning(
                "%s: HTML validation warnings:\n\t%s",
                url,
                "\n\t".join(warnings)
            )


PLUGIN = Tidy
########NEW FILE########
__FILENAME__ = time_plugin
import time
import logging

from base import Plugin

LOG = logging.getLogger('crawler')

class Time(Plugin):
    """
    Follow the time it takes to run requests.
    """

    def __init__(self):
        super(Time, self).__init__()
        self.timed_urls = self.data['timed_urls'] = {}

    def pre_request(self, sender, **kwargs):
        url = kwargs['url']
        self.timed_urls[url] = time.time()

    def post_request(self, sender, **kwargs):
        cur = time.time()
        url = kwargs['url']
        old_time = self.timed_urls[url]
        total_time = cur - old_time
        self.timed_urls[url] = total_time
        LOG.debug("Time taken: %s", self.timed_urls[url])

    def finish_run(self, sender, **kwargs):
        "Print the longest time it took for pages to load"
        alist = sorted(self.timed_urls.iteritems(), key=lambda (k,v): (v,k), reverse=True)
        for url, ttime in alist[:10]:
            LOG.info("%s took %f", url, ttime)

PLUGIN = Time
########NEW FILE########
__FILENAME__ = urlconf
import logging
import re

from base import Plugin

LOG = logging.getLogger("crawler")

class URLConf(Plugin):
    """
    Plugin to check validity of URLConf.
    Run after the spider is done to show what URLConf entries got hit.
    """

    def finish_run(self, sender, **kwargs):
        normal_patterns = list()
        admin_patterns = list()

        for pattern in sender.conf_urls.keys():
            pattern = pattern.replace('^', '').replace('$', '').replace('//', '/')
            curr = re.compile(pattern)

            if any(curr.search(url) for url in sender.crawled):
                continue

            if pattern.startswith("admin"):
                admin_patterns.append(pattern)
            else:
                normal_patterns.append(pattern)

        if admin_patterns:
            LOG.debug("These admin pages were not crawled: %s", "\n\t".join(sorted(admin_patterns)))

        if normal_patterns:
            LOG.info("These patterns were not matched during the crawl: %s", "\n\t".join(sorted(normal_patterns)))

PLUGIN = URLConf
########NEW FILE########
__FILENAME__ = signals
import django.dispatch

pre_request =  django.dispatch.Signal(providing_args=['url', 'request'])
post_request =  django.dispatch.Signal(providing_args=['url', 'response'])
urls_parsed =  django.dispatch.Signal(providing_args=['fro', 'returned_urls'])
start_run =  django.dispatch.Signal()
finish_run =  django.dispatch.Signal()

########NEW FILE########
__FILENAME__ = crawlurls
from collections import defaultdict
from optparse import make_option
import logging
import sys

from django.conf import settings
from django.core.management.base import BaseCommand, CommandError
from django.contrib.admindocs.views import extract_views_from_urlpatterns

from test_utils.crawler.base import Crawler

class LogStatsHandler(logging.Handler):
    stats = defaultdict(int)

    def emit(self, record):
        self.stats[record.levelno] += 1

class Command(BaseCommand):
    option_list = BaseCommand.option_list + (
        make_option('-p', '--pdb', action='store_true', dest='pdb', default=False,
            help='Pass -p to drop into pdb on an error'),
        make_option('-d', '--depth', action='store', dest='depth', default=3,
            help='Specify the depth to crawl.'),
        make_option('-s', '--safe', action='store_true', dest='html', default=False,
            help='Pass -s to check for html fragments in your pages.'),
        make_option('-r', '--response', action='store_true', dest='response', default=False,
            help='Pass -r to store the response objects.'),
        make_option('-t', '--time', action='store_true', dest='time', default=False,
            help='Pass -t to time your requests.'),
        make_option('--enable-plugin', action='append', dest='plugins', default=[],
            help='Enable the specified plugin'),
        make_option("-o", '--output-dir', action='store', dest='output_dir', default=None,
            help='If specified, store plugin output in the provided directory'),
        make_option('--no-parent', action='store_true', dest="no_parent", default=False,
            help='Do not crawl URLs which do not start with your base URL'),
        make_option('-a', "--auth", action='store', dest='auth', default=None,
            help='Authenticate (login:user,password:secret) before crawl')
    )

    help = "Displays all of the url matching routes for the project."
    args = "[relative start url]"

    def handle(self, *args, **options):
        verbosity = int(options.get('verbosity', 1))
        depth = int(options.get('depth', 3))

        auth = _parse_auth(options.get('auth'))

        if verbosity > 1:
            log_level = logging.DEBUG
        elif verbosity:
            log_level = logging.INFO
        else:
            log_level = logging.WARN

        crawl_logger = logging.getLogger('crawler')
        crawl_logger.setLevel(logging.DEBUG)
        crawl_logger.propagate = 0

        log_stats = LogStatsHandler()

        crawl_logger.addHandler(log_stats)

        console = logging.StreamHandler()
        console.setLevel(log_level)
        console.setFormatter(logging.Formatter("%(name)s [%(levelname)s] %(module)s: %(message)s"))

        crawl_logger.addHandler(console)

        if len(args) > 1:
            raise CommandError('Only one start url is currently supported.')
        else:
            start_url = args[0] if args else '/'

        if settings.ADMIN_FOR:
            settings_modules = [__import__(m, {}, {}, ['']) for m in settings.ADMIN_FOR]
        else:
            settings_modules = [settings]

        conf_urls = {}

        # Build the list URLs to test from urlpatterns:
        for settings_mod in settings_modules:
            try:
                urlconf = __import__(settings_mod.ROOT_URLCONF, {}, {}, [''])
            except Exception, e:
                logging.exception("Error occurred while trying to load %s: %s", settings_mod.ROOT_URLCONF, str(e))
                continue

            view_functions = extract_views_from_urlpatterns(urlconf.urlpatterns)
            for (func, regex) in view_functions:
                #Get function name and add it to the hash of URLConf urls
                func_name = hasattr(func, '__name__') and func.__name__ or repr(func)
                conf_urls[regex] = ['func.__module__', func_name]

        c = Crawler(start_url,
            conf_urls=conf_urls,
            verbosity=verbosity,
            output_dir=options.get("output_dir"),
            ascend=not options.get("no_parent"),
            auth=auth,
        )

        # Load plugins:
        for p in options['plugins']:
            # This nested try is somewhat unsightly but allows easy Pythonic
            # usage ("--enable-plugin=tidy") instead of Java-esque
            # "--enable-plugin=test_utils.crawler.plugins.tidy"
            try:
                try:
                    plugin_module = __import__(p)
                except ImportError:
                    if not "." in p:
                        plugin_module = __import__(
                            "test_utils.crawler.plugins.%s" % p,
                            fromlist=["test_utils.crawler.plugins"]
                        )
                    else:
                        raise

                c.plugins.append(plugin_module.PLUGIN())
            except (ImportError, AttributeError), e:
                crawl_logger.critical("Unable to load plugin %s: %s", p, e)
                sys.exit(3)

        c.run(max_depth=depth)

        # We'll exit with a non-zero status if we had any errors
        max_log_level = max(log_stats.stats.keys())
        if max_log_level >= logging.ERROR:
            sys.exit(2)
        elif max_log_level >= logging.WARNING:
            sys.exit(1)
        else:
            sys.exit(0)


def _parse_auth(auth):
    """
    Parse auth string and return dict.

    >>> _parse_auth('login:user,password:secret')
    {'login': 'user', 'password': 'secret'}

    >>> _parse_auth('name:user, token:top:secret')
    {'name': 'user', 'token': 'top:secret'}
    """
    if not auth:
        return None
    items = auth.split(',')
    return dict(i.strip().split(':', 1) for i in items)

########NEW FILE########
__FILENAME__ = makefixture
"""
"Make fixture" command.

Highly useful for making test fixtures. Use it to pick only few items
from your data to serialize, restricted by primary keys. By default
command also serializes foreign keys and m2m relations. You can turn
off related items serialization with --skip-related option.

How to use:
    python manage.py makefixture

will display what models are installed

    python manage.py makefixture User[:3]
or
    python manage.py makefixture auth.User[:3]
or
    python manage.py makefixture django.contrib.auth.User[:3]

will serialize users with ids 1 and 2, with assigned groups, permissions
 and content types.

    python manage.py makefixture YourModel[3] YourModel[6:10]

will serialize YourModel with key 3 and keys 6 to 9 inclusively.

Of course, you can serialize whole tables, and also different tables at
once, and use options of dumpdata:

    python manage.py makefixture --format=xml --indent=4 YourModel[3] AnotherModel auth.User[:5] auth.Group
"""
# From http://www.djangosnippets.org/snippets/918/

#save into anyapp/management/commands/makefixture.py
#or back into django/core/management/commands/makefixture.py
#v0.1 -- current version
#known issues:
#no support for generic relations
#no support for one-to-one relations
from optparse import make_option
from django.core import serializers
from django.core.management.base import BaseCommand
from django.core.management.base import CommandError
from django.core.management.base import LabelCommand
from django.db.models.fields.related import ForeignKey
from django.db.models.fields.related import ManyToManyField
from django.db.models.loading import get_models

DEBUG = False

def model_name(m):
    module = m.__module__.split('.')[:-1] # remove .models
    return ".".join(module + [m._meta.object_name])

class Command(LabelCommand):
    help = 'Output the contents of the database as a fixture of the given format.'
    args = 'modelname[pk] or modelname[id1:id2] repeated one or more times'
    option_list = BaseCommand.option_list + (
        make_option('--skip-related', default=True, action='store_false', dest='propagate',
            help='Specifies if we shall not add related objects.'),
        make_option('--reverse', default=[], action='append', dest='reverse',
            help="Reverse relations to follow (e.g. 'Job.task_set')."),
        make_option('--format', default='json', dest='format',
            help='Specifies the output serialization format for fixtures.'),
        make_option('--indent', default=None, dest='indent', type='int',
            help='Specifies the indent level to use when pretty-printing output'),
    )
    def handle_reverse(self, **options):
        follow_reverse = options.get('reverse', [])
        to_reverse = {}
        for arg in follow_reverse:
            try:
                model_name, related_set_name = arg.rsplit(".", 1)
            except:
                raise CommandError("Bad fieldname on '--reverse %s'" % arg)
            model = self.get_model_from_name(model_name)
            try:
                getattr(model, related_set_name)
            except AttributeError:
                raise CommandError("Field '%s' does not exist on model '%s'" % (
                                   related_set_name, model_name))
            to_reverse.setdefault(model, []).append(related_set_name)
        return to_reverse

    def handle_models(self, models, **options):
        format = options.get('format','json')
        indent = options.get('indent',None)
        show_traceback = options.get('traceback', False)
        propagate = options.get('propagate', True)
        follow_reverse = self.handle_reverse(**options)

        # Check that the serialization format exists; this is a shortcut to
        # avoid collating all the objects and _then_ failing.
        if format not in serializers.get_public_serializer_formats():
            raise CommandError("Unknown serialization format: %s" % format)

        try:
            serializers.get_serializer(format)
        except KeyError:
            raise CommandError("Unknown serialization format: %s" % format)

        objects = []
        for model, slice in models:
            if isinstance(slice, basestring) and slice:
                objects.extend(model._default_manager.filter(pk__exact=slice))
            elif not slice or type(slice) is list:
                items = model._default_manager.all()
                if slice and slice[0]:
                    items = items.filter(pk__gte=slice[0])
                if slice and slice[1]:
                    items = items.filter(pk__lt=slice[1])
                items = items.order_by(model._meta.pk.attname)
                objects.extend(items)
            else:
                raise CommandError("Wrong slice: %s" % slice)

        all = objects
        if propagate:
            collected = set([(x.__class__, x.pk) for x in all])
            while objects:
                related = []
                for x in objects:
                    if DEBUG:
                        print "Adding %s[%s]" % (model_name(x), x.pk)
                    # follow forward relation fields
                    for f in x.__class__._meta.fields + x.__class__._meta.many_to_many:
                        if isinstance(f, ForeignKey):
                            new = getattr(x, f.name) # instantiate object
                            if new and not (new.__class__, new.pk) in collected:
                                collected.add((new.__class__, new.pk))
                                related.append(new)
                        if isinstance(f, ManyToManyField):
                            for new in getattr(x, f.name).all():
                                if new and not (new.__class__, new.pk) in collected:
                                    collected.add((new.__class__, new.pk))
                                    related.append(new)
                    # follow reverse relations as requested
                    for reverse_field in follow_reverse.get(x.__class__, []):
                        mgr = getattr(x, reverse_field)
                        for new in mgr.all():
                            if new and not (new.__class__, new.pk) in collected:
                                collected.add((new.__class__, new.pk))
                                related.append(new)
                objects = related
                all.extend(objects)

        try:
            return serializers.serialize(format, all, indent=indent)
        except Exception, e:
            if show_traceback:
                raise
            raise CommandError("Unable to serialize database: %s" % e)

    def get_models(self):
        return [(m, model_name(m)) for m in get_models()]

    def get_model_from_name(self, search):
        """Given a name of a model, return the model object associated with it

        The name can be either fully specified or uniquely matching the
        end of the model name. e.g.
            django.contrib.auth.User
        or
            auth.User
        raises CommandError if model can't be found or uniquely determined
        """
        models = [model for model, name in self.get_models()
                        if name.endswith('.'+name) or name == search]
        if not models:
            raise CommandError("Unknown model: %s" % search)
        if len(models)>1:
            raise CommandError("Ambiguous model name: %s" % search)
        return models[0]

    def handle_label(self, labels, **options):
        parsed = []
        for label in labels:
            search, pks = label, ''
            if '[' in label:
                search, pks = label.split('[', 1)
            slice = ''
            if ':' in pks:
                slice = pks.rstrip(']').split(':', 1)
            elif pks:
                slice = pks.rstrip(']')
            model = self.get_model_from_name(search)
            parsed.append((model, slice))
        return self.handle_models(parsed, **options)

    def list_models(self):
        names = [name for _model, name in self.get_models()]
        raise CommandError('Neither model name nor slice given. Installed model names: \n%s' % ",\n".join(names))

    def handle(self, *labels, **options):
        if not labels:
            self.list_models()

        output = []
        label_output = self.handle_label(labels, **options)
        if label_output:
            output.append(label_output)
        return '\n'.join(output)

########NEW FILE########
__FILENAME__ = quicktest
"""
Original code and ideas from http://www.djangosnippets.org/snippets/1318/
Thanks crucialfelix
"""
from django.core.management.base import BaseCommand
from optparse import make_option
import sys

class Command(BaseCommand):
    option_list = BaseCommand.option_list + (
        make_option('--noinput', action='store_false', dest='interactive', default=True,
            help='Tells Django to NOT prompt the user for input of any kind.'),
    )
    help = 'Runs the test suite, creating a test db IF NEEDED and NOT DESTROYING the test db afterwards.  Otherwise operates exactly as does test.'
    args = '[appname ...]'

    requires_model_validation = False

    def handle(self, *test_labels, **options):
        from django.conf import settings
        from django.test.utils import get_runner

        verbosity = int(options.get('verbosity', 1))
        interactive = options.get('interactive', True)

        settings.TEST_RUNNER = 'test_utils.test_runners.keep_database.run_tests'

        test_runner = get_runner(settings)

        failures = test_runner(test_labels, verbosity=verbosity, interactive=interactive)
        if failures:
            sys.exit(failures)

########NEW FILE########
__FILENAME__ = relational_dumpdata
from django.core.management.base import BaseCommand, CommandError
from django.core import serializers

from optparse import make_option
from django.db.models.fields.related import ForeignKey, ManyToManyField
from django.db.models import get_app, get_apps, get_models

def _relational_dumpdata(app, collected):
    objects = []
    for mod in get_models(app):
        objects.extend(mod._default_manager.all())
    #Got models, now get their relationships.
    #Thanks to http://www.djangosnippets.org/snippets/918/
    related = []
    collected = collected.union(set([(x.__class__, x.pk) for x in objects]))
    for obj in objects:
        for f in obj._meta.fields :
            if isinstance(f, ForeignKey):
                new = getattr(obj, f.name) # instantiate object
                if new and not (new.__class__, new.pk) in collected:
                    collected.add((new.__class__, new.pk))
                    related.append(new)
        for f in obj._meta.many_to_many:
            if isinstance(f, ManyToManyField):
                for new in getattr(obj, f.name).all():
                    if new and not (new.__class__, new.pk) in collected:
                        collected.add((new.__class__, new.pk))
                        related.append(new)
    if related != []:
        objects.extend(related)
    return (objects, collected)


class Command(BaseCommand):
    option_list = BaseCommand.option_list + (
        make_option('--format', default='json', dest='format',
            help='Specifies the output serialization format for fixtures.'),
        make_option('--indent', default=None, dest='indent', type='int',
            help='Specifies the indent level to use when pretty-printing output'),
        make_option('-e', '--exclude', dest='exclude',action='append', default=[],
            help='App to exclude (use multiple --exclude to exclude multiple apps).'),
    )
    help = 'Output the contents of the database as a fixture of the given format.'
    args = '[appname ...]'

    def handle(self, *app_labels, **options):

        format = options.get('format','json')
        indent = options.get('indent',None)
        exclude = options.get('exclude',[])
        show_traceback = options.get('traceback', False)

        excluded_apps = [get_app(app_label) for app_label in exclude]

        if len(app_labels) == 0:
            app_list = [app for app in get_apps() if app not in excluded_apps]
        else:
            app_list = [get_app(app_label) for app_label in app_labels]

        # Check that the serialization format exists; this is a shortcut to
        # avoid collating all the objects and _then_ failing.
        try:
            serializers.get_serializer(format)
        except KeyError:
            raise CommandError("Unknown serialization format: %s" % format)

        objects = []
        collected = set()
        for app in app_list: #Yey for ghetto recusion
            objects, collected = _relational_dumpdata(app, collected)
        #****End New stuff
        try:
            return serializers.serialize(format, objects, indent=indent)
        except Exception, e:
            if show_traceback:
                raise
            raise CommandError("Unable to serialize database: %s" % e)

########NEW FILE########
__FILENAME__ = testmaker
from optparse import make_option
import logging, os
from os import path

from django.core.management.base import BaseCommand, CommandError
from django.conf import settings
from django.core.management import call_command
from django.db import models

from test_utils.testmaker import Testmaker


class Command(BaseCommand):
    option_list = BaseCommand.option_list + (
        make_option('-a', '--app', action='store', dest='application',
            default=None, help='The name of the application (in the current \
                    directory) to output data to. (defaults to currect directory)'),
        make_option('-l', '--logdir', action='store', dest='logdirectory',
            default=os.getcwd(), help='Directory to send tests and fixtures to. \
            (defaults to currect directory)'),
        make_option('-x', '--loud', action='store', dest='verbosity', default='1',
            type='choice', choices=['0', '1', '2'],
            help='Verbosity level; 0=minimal output, 1=normal output, 2=all output'),
        make_option('-f', '--fixture', action='store_true', dest='fixture', default=False,
            help='Pass -f to not create a fixture for the data.'),
        make_option('--format', default='json', dest='format',
            help='Specifies the output serialization format for fixtures.'),
    )

    help = 'Runs the test server with the testmaker output enabled'
    args = '[server:port]'

    def handle(self, addrport='', *args, **options):

        app = options.get("application")
        verbosity = int(options.get('verbosity', 1))
        create_fixtures = options.get('fixture', False)
        logdir = options.get('logdirectory')
        fixture_format = options.get('format', 'xml')

        if app:
            app = models.get_app(app)

        if not app:
            #Don't serialize the whole DB :)
            create_fixtures = False

        testmaker = Testmaker(app, verbosity, create_fixtures, fixture_format, addrport)
        testmaker.prepare(insert_middleware=True)
        try:
            call_command('runserver', addrport=addrport, use_reloader=False)
        except SystemExit:
            if create_fixtures:
                testmaker.make_fixtures()
            else:
                raise

########NEW FILE########
__FILENAME__ = testshell
from django.core.management.base import BaseCommand

from optparse import make_option

class Command(BaseCommand):
    option_list = BaseCommand.option_list + (
        make_option('--addrport', action='store', dest='addrport',
            type='string', default='',
            help='port number or ipaddr:port to run the server on'),
    )
    help = 'Runs a development server with data from the given fixture(s).'
    args = '[fixture ...]'

    requires_model_validation = False

    def handle(self, *fixture_labels, **options):
        from django.core.management import call_command
        from django.db import connection
        from django.db.backends import creation
        from django.conf import settings

        verbosity = int(options.get('verbosity', 1))
        addrport = options.get('addrport')

        # Create a test database.
        connection.creation.create_test_db(verbosity, autoclobber=True)

        if settings.TEST_DATABASE_NAME:
            settings.DATABASE_NAME = settings.TEST_DATABASE_NAME
        else:
            settings.DATABASE_NAME = creation.TEST_DATABASE_PREFIX + settings.DATABASE_NAME

        # Import the fixture data into the test database.
        call_command('loaddata', *fixture_labels, **{'verbosity': verbosity})

        try:
            call_command('shell_plus')
        except:
            call_command('shell')

########NEW FILE########
__FILENAME__ = mocks
from django.test import Client
from django.core.handlers.wsgi import WSGIRequest

class RequestFactory(Client):
    """
    Class that lets you create mock Request objects for use in testing.

    Usage:

    rf = RequestFactory()
    get_request = rf.get('/hello/')
    post_request = rf.post('/submit/', {'foo': 'bar'})

    This class re-uses the django.test.client.Client interface, docs here:
    http://www.djangoproject.com/documentation/testing/#the-test-client

    Once you have a request object you can pass it to any view function,
    just as if that view had been hooked up using a URLconf.

    """
    def request(self, **request):
        """
        Similar to parent class, but returns the request object as soon as it
        has created it.
        """
        environ = {
            'HTTP_COOKIE': self.cookies,
            'PATH_INFO': '/',
            'QUERY_STRING': '',
            'REQUEST_METHOD': 'GET',
            'SCRIPT_NAME': '',
            'SERVER_NAME': 'testserver',
            'SERVER_PORT': 80,
            'SERVER_PROTOCOL': 'HTTP/1.1',
        }
        environ.update(self.defaults)
        environ.update(request)
        return WSGIRequest(environ)

########NEW FILE########
__FILENAME__ = models
#This is here so that Django thinks we are a model so we can test it.

########NEW FILE########
__FILENAME__ = testmaker
from django.conf import settings
from django.test import Client
from django.test.utils import setup_test_environment
from django.template import Template, Context

from test_utils.testmaker import processors
from test_utils.testmaker import serializers
from test_utils.testmaker import Testmaker

#Remove at your own peril.
#Thar be sharks in these waters.
debug = getattr(settings, 'DEBUG', False)
"""
if not debug:
    print "THIS CODE IS NOT MEANT FOR USE IN PRODUCTION"
else:
    print "Loaded Testmaker Middleware"
"""

if not Testmaker.enabled:
    testmaker = Testmaker(verbosity=0)
    testmaker.prepare()


SHOW_TESTMAKER_HEADER = getattr(settings, 'SHOW_TESTMAKER_HEADER', False)

RESPONSE_TEMPLATE = Template("""
<div class="wrapper" style="background-color: red; padding: 5px; color: #fff; width: 100%;">
Testmaker: Logging to: {{ file }}
<form action="/test_utils/set_logging/">
    <input type="text" name="filename">
    <input type="submit" value="New Test">
</form>
<a href="/test_utils/show_log/">Show Log</a>
</div>
""")


class TestMakerMiddleware(object):
    def __init__(self):
        """
        Assign a Serializer and Processer
        Serializers will be pluggable and allow for custom recording.
        Processers will process the serializations into test formats.
        """
        serializer_pref = getattr(settings, 'TESTMAKER_SERIALIZER', 'pickle')
        processor_pref = getattr(settings, 'TESTMAKER_PROCESSOR', 'django')
        self.serializer = serializers.get_serializer(serializer_pref)()
        self.processor = processors.get_processor(processor_pref)()

    def process_request(self, request):
        """
        Run the request through the testmaker middleware.
        This outputs the requests to the chosen Serializers.
        Possible running it through one or many Processors
        """
        #This is request.REQUEST to catch POST and GET
        if 'test_client_true' not in request.REQUEST:
            request.logfile = Testmaker.logfile()
            self.serializer.save_request(request)
            self.processor.save_request(request)
            #We only want to re-run the request on idempotent requests
            if request.method.lower() == "get":
                setup_test_environment()
                c = Client(REMOTE_ADDR='127.0.0.1')
                getdict = request.GET.copy()
                getdict['test_client_true'] = 'yes' #avoid recursion
                response = c.get(request.path, getdict)
                self.serializer.save_response(request, response)
                self.processor.save_response(request, response)
        return None

    def process_response(self, request, response):
        if 'test_client_true' not in request.REQUEST \
        and SHOW_TESTMAKER_HEADER:
            c = Context({'file': Testmaker.logfile()})
            s = RESPONSE_TEMPLATE.render(c)
            response.content = str(s) + str(response.content)
        return response

########NEW FILE########
__FILENAME__ = base
import logging
import re
import time

from django.template.defaultfilters import slugify as base_slugify
from django.template import Template, Context
from django.utils.encoding import force_unicode
from django.utils.safestring import mark_safe

from test_utils.templatetags import TemplateParser

TEST_TEMPLATE = 'Override in Subclass'
STATUS_TEMPLATE = 'Override in Subclass'
CONTEXT_TEMPLATE = 'Override in Subclass'
#DISCARD_CONTEXT_KEYS = ('LANGUAGES',)
DISCARD_CONTEXT_KEYS = []

def safe_dict(dict):
    new_dic = {}
    for key,val in dict.iteritems():
        new_dic[key] = mark_safe(val)
    return new_dic

def slugify(toslug):
    """
    Turn dashs into underscores to sanitize for filenames
    """
    return re.sub("-", "_", base_slugify(toslug))

class Processer(object):
    """Processes the serialized data. Generally to create some sort of test cases"""

    def __init__(self, name):
        self.name = name
        self.log = logging.getLogger('testprocessor')
        #self.log = logging.getLogger('testprocessor-%s' % self.name)
        self.data = {}

    def shall_we_proceed(self, request):
        if 'media' in request.path or 'test_utils' in request.path:
            return False
        return True

    def process_request(self, request):
        raise NotImplementedError

    def save_request(self, request):
        """ Actually write the request out to a file """
        if self.shall_we_proceed(request):
            self._log_request(request)

    def process_response(self, request, response):
        raise NotImplementedError

    def save_response(self, request, response):
        if self.shall_we_proceed(request):
            self._log_status(response)
            if response.context and response.status_code != 404:
                self._log_context(response.context)
                #This is where template tag outputting would go
                #Turned off until it gets betterer
                """
                parser = TemplateParser(response.template[0], context)
                parser.parse()
                parser.create_tests()
                """

    def _get_template(self, templatename):
        """Should be implemented in subclass"""
        raise NotImplementedError

    def _log_request(self, request):
        method = request.method.lower()
        request_str = "'%s', {" % request.path
        for dikt in request.REQUEST.dicts:
            for arg in dikt:
                request_str += "'%s': '%s', " % (arg, request.REQUEST[arg])
        request_str += "}"

        template = Template(self._get_template('test'))
        context = {
            'path': slugify(request.path),
            'time': slugify(time.time()),
            'method': method,
            'request_str': request_str,
        }
        context = Context(safe_dict(context))
        self.log.info(template.render(context))

    def _log_status(self, response):
        template = Template(self._get_template('status'))
        context = {
            'status_code': response.status_code,
        }
        if response.status_code in [301, 302]:
            context['location'] = response['Location']
        context = Context(safe_dict(context))
        self.log.info(template.render(context))

    def _get_context_keys(self, context):
        """Get the keys from the contexts(list) """
        keys = []
        for d in context.dicts:
            if isinstance(d, Context):
                keys += self._get_context_keys(d)
            keys += d.keys()
        return keys

    def _log_context(self, context):
        template = Template(self._get_template('context'))
        keys = []
        if isinstance(context, list):
            for c in context:
                keys += self._get_context_keys(c)
        else:
            keys += self._get_context_keys(context)
        keys = set(keys)

        # Skip some keys
        for discardkey in DISCARD_CONTEXT_KEYS:
            keys.discard(discardkey)

        for key in keys:
            val = force_unicode(context[key])
            con = {
                'key': key,
                'value': val,
            }
            con = Context(safe_dict(con))
            try:
                #Avoid memory addy's which will change.
                if not re.search("0x\w+", val):
                    self.log.info(template.render(con))
            except UnicodeDecodeError, e:
                pass

########NEW FILE########
__FILENAME__ = django_processor
import base

TEST_TEMPLATE = \
"""    def test_{{path}}_{{time}}(self):
        r = self.client.{{method}}({{request_str}})"""

STATUS_TEMPLATE  = \
"""        self.assertEqual(r.status_code, {{status_code}})"""

CONTEXT_TEMPLATE = \
'''        self.assertEqual(unicode(r.context["{{key}}"]), u"""{{value}}""")'''

class Processor(base.Processer):
    """Processes the serialized data. Generally to create some sort of test cases"""

    def __init__(self, name='django'):
        super(Processor, self).__init__(name)

    def _get_template(self, templatename):
        return {
            'test': TEST_TEMPLATE,
            'status': STATUS_TEMPLATE,
            'context': CONTEXT_TEMPLATE,
            }[templatename]

########NEW FILE########
__FILENAME__ = twill_processor
import base

TEST_TEMPLATE = """go {{ path }}"""

STATUS_TEMPLATE = """code {{ status_code }}"""

#CONTEXT_TEMPLATE = '''find {{value}}'''
CONTEXT_TEMPLATE = ''

class Processor(base.Processer):
    """Processes the serialized data. Generally to create some sort of test cases"""

    def __init__(self, name='twill'):
        super(Processor, self).__init__(name)

    def _get_template(self, templatename):
        return {
            'test': TEST_TEMPLATE,
            'status': STATUS_TEMPLATE,
            'context': CONTEXT_TEMPLATE,
            }[templatename]

########NEW FILE########
__FILENAME__ = replay
import sys
import re
import cPickle as pickle
from test_utils.testmaker import Testmaker
from test_utils.testmaker.processors.django_processor import Processor

class MockRequest(dict):
    'Mocking a dict to allow attribute access'
    def __getattr__(self, name):
        return self[name]

class Replay(object):

    def __init__(self, file_name, replay_file='replay_file'):
        self.file_name = file_name
        self.stream = open(self.file_name).readlines()
        self.tm = Testmaker()
        self.tm.setup_logging(replay_file, '/dev/null')
        self.processor = Processor('replay_processor')
        self.serial_obj = pickle

    def process(self):
        self.log = []

        buffer = []
        req_re = re.compile('---REQUEST_BREAK---')
        res_re = re.compile('---RESPONSE_BREAK---')

        for line in self.stream:
            if req_re.search(line):
                #process request
                to_pickle = ''.join(buffer)
                request = MockRequest(self.serial_obj.loads(to_pickle))
                self.processor.save_request(request)
                print request['path'], request['time']
                buffer = []
            elif res_re.search(line):
                #process response
                to_pickle = ''.join(buffer)
                response = MockRequest(self.serial_obj.loads(to_pickle))
                self.log.append(request, response)
                self.processer.save_response(request, response)
                print response['status_code'], response['time']
                buffer = []
            else:
                buffer.append(line)

if __name__ == '__main__':
    if len(sys.argv) == 2:
        in_file = sys.argv[1]
    else:
        raise Exception('Need file name')

    replay = Replay(in_file)
    replay.process()
########NEW FILE########
__FILENAME__ = base
import logging
import time

class Serializer(object):
    """A pluggable Serializer class"""

    name = "base"

    def __init__(self, name):
        """Constructor"""
        self.name = name
        self.ser = logging.getLogger('testserializer')
        #self.ser = logging.getLogger('testserializer-%s' % self.name)
        self.data = {}

    def process_request(self, request):
        request_dict = {
            'name': self.name,
            'time': time.time(),
            'path': request.path,

            'GET': request.GET,
            'POST': request.POST,
            'REQUEST': request.REQUEST,
            'method': request.method,
        }
        return request_dict

    def save_request(self, request):
        raise NotImplementedError

    def process_response(self, path, response):
        response_dict = {
            'name': self.name,
            'time': time.time(),
            'path': path,

            'context': response.context,
            'content': response.content,
            'status_code': response.status_code,
            'cookies': response.cookies,
            'headers': response._headers,
        }
        return response_dict

    def save_response(self, request, response):
        raise NotImplementedError

########NEW FILE########
__FILENAME__ = json_serializer
import base
from django.utils import simplejson as json
from test_utils.testmaker.serializers import REQUEST_UNIQUE_STRING, RESPONSE_UNIQUE_STRING

class Serializer(base.Serializer):

    def __init__(self, name='pickle'):
        super(Serializer, self).__init__(name)

    def save_request(self, request):
        """Saves the Request to the serialization stream"""
        request_dict = self.process_request(request)
        try:
            self.ser.info(json.dumps(request_dict))
            self.ser.info(REQUEST_UNIQUE_STRING)
        except TypeError, e:
            #Can't serialize wsgi.error objects
            pass

    def save_response(self, request, response):
        """Saves the Response-like objects information that might be tested"""
        response_dict = self.process_response(request.path, response)
        try:
            self.ser.info(json.dumps(response_dict))
            self.ser.info(RESPONSE_UNIQUE_STRING)
        except TypeError, e:
            #Can't serialize wsgi.error objects
            pass

########NEW FILE########
__FILENAME__ = pickle_serializer
import base
import cPickle as pickle
from test_utils.testmaker.serializers import REQUEST_UNIQUE_STRING, RESPONSE_UNIQUE_STRING

class Serializer(base.Serializer):

    def __init__(self, name='pickle'):
        super(Serializer, self).__init__(name)

    def save_request(self, request):
        """Saves the Request to the serialization stream"""
        request_dict = self.process_request(request)
        self.ser.info(pickle.dumps(request_dict))
        self.ser.info(REQUEST_UNIQUE_STRING)

    def save_response(self, request, response):
        """Saves the Response-like objects information that might be tested"""
        response_dict = self.process_response(request.path, response)
        try:
            self.ser.info(pickle.dumps(response_dict))
            self.ser.info(RESPONSE_UNIQUE_STRING)
        except (TypeError, pickle.PicklingError):
            #Can't pickle wsgi.error objects
            pass

########NEW FILE########
__FILENAME__ = keep_database
from django.test import TestCase
from django.test.simple import build_test, reorder_suite, build_suite
from django.test.utils import setup_test_environment, teardown_test_environment
from django.test.testcases import connections_support_transactions
from django.db.models import get_app, get_apps
from django.conf import settings
try:
    from django.utils import unittest # django's 1.3 copy of unittest2
except ImportError:
    import unittest # system fallback
import os

def run_tests(test_labels, verbosity=1, interactive=True, extra_tests=[]):
    """
    worsk exactly as per normal test
    but only creates the test_db if it doesn't yet exist
    and does not destroy it when done
    tables are flushed and fixtures loaded between tests as per usual
    but if your schema has not changed then this saves significant amounts of time
    and speeds up the test cycle

    Run the unit tests for all the test labels in the provided list.
    Labels must be of the form:
     - app.TestClass.test_method
        Run a single specific test method
     - app.TestClass
        Run all the test methods in a given class
     - app
        Search for doctests and unittests in the named application.

    When looking for tests, the test runner will look in the models and
    tests modules for the application.

    A list of 'extra' tests may also be provided; these tests
    will be added to the test suite.

    Returns the number of tests that failed.
    """
    setup_test_environment()

    settings.DEBUG = False
    suite = unittest.TestSuite()

    if test_labels:
        for label in test_labels:
            if '.' in label:
                suite.addTest(build_test(label))
            else:
                app = get_app(label)
                suite.addTest(build_suite(app))
    else:
        for app in get_apps():
            suite.addTest(build_suite(app))

    for test in extra_tests:
        suite.addTest(test)

    suite = reorder_suite(suite, (TestCase,))

    old_name = settings.DATABASES['default']['NAME']

    ###Everything up to here is from django.test.simple

    from django.db.backends import creation
    from django.db import connection, DatabaseError

    if settings.DATABASES['default']['TEST_NAME']:
        settings.DATABASES['default']['NAME'] = settings.DATABASES['default']['TEST_NAME']
    else:
        settings.DATABASES['default']['NAME'] = creation.TEST_DATABASE_PREFIX + settings.DATABASES['default']['NAME']
    connection.settings_dict["DATABASE_NAME"] = settings.DATABASES['default']['NAME']

    # does test db exist already ?
    try:
        if settings.DATABASES['default']['ENGINE'] == 'sqlite3':
            if not os.path.exists(settings.DATABASES['default']['NAME']):
                raise DatabaseError
        cursor = connection.cursor()
    except Exception:
        # db does not exist
        # juggling !  create_test_db switches the DATABASE_NAME to the TEST_DATABASE_NAME
        settings.DATABASES['default']['NAME'] = old_name
        connection.settings_dict["DATABASE_NAME"] = old_name
        connection.creation.create_test_db(verbosity, autoclobber=True)
    else:
        connection.close()

    settings.DATABASES['default']['SUPPORTS_TRANSACTIONS'] = connections_support_transactions()

    result = unittest.TextTestRunner(verbosity=verbosity).run(suite)

    #Since we don't call destory_test_db, we need to set the db name back.
    settings.DATABASES['default']['NAME'] = old_name
    connection.settings_dict["DATABASE_NAME"] = old_name
    teardown_test_environment()

    return len(result.failures) + len(result.errors)

########NEW FILE########
__FILENAME__ = profile
import cProfile
import pstats
from django.test.simple import run_tests as django_test_runner

def run_tests(test_labels, verbosity=1, interactive=True,
        extra_tests=[], nodatabase=False):
    """
    Test runner which displays basic profile data.
    Needs some improvement, mostly here for Continuous Integration purposes.
    """
    print "Using profiling test runner"
    cProfile.runctx("django_test_runner(test_labels, verbosity, interactive, extra_tests)", globals(), locals(), filename="django_tests.profile")
    stats = pstats.Stats('django_tests.profile')
    stats.strip_dirs().sort_stats('time').print_stats(30)
    return 0

########NEW FILE########
__FILENAME__ = urls
from django.conf.urls.defaults import *

import test_utils.views as test_views

urlpatterns = patterns('',
                       url(r'^set_logging/(?P<filename>.*?)/',
                           test_views.set_logging,
                           name='test_utils_set_logging'),
                       url(r'^set_logging/',
                           test_views.set_logging,
                           name='test_utils_set_logging'),
                       url(r'^show_log/',
                           test_views.show_log,
                           name='test_utils_show_log'),
                       )

########NEW FILE########
__FILENAME__ = twill_runner
"""

This code is originally by miracle2k:
http://bitbucket.org/miracle2k/djutils/src/97f92c32c621/djutils/test/twill.py


Integrates the twill web browsing scripting language with Django.

Provides two main functions, ``setup()`` and ``teardown``, that hook
(and unhook) a certain host name to the WSGI interface of your Django
app, making it possible to test your site using twill without actually
going through TCP/IP.

It also changes the twill browsing behaviour, so that relative urls
per default point to the intercept (e.g. your Django app), so long
as you don't browse away from that host. Further, you are allowed to
specify the target url as arguments to Django's ``reverse()``.

Usage:

    from test_utils.utils import twill_runner as twill
    twill.setup()
    try:
        twill.go('/')                     # --> Django WSGI
        twill.code(200)

        twill.go('http://google.com')
        twill.go('/services')             # --> http://google.com/services

        twill.go('/list', default=True)   # --> back to Django WSGI

        twill.go('proj.app.views.func',
                 args=[1,2,3])
    finally:
        twill.teardown()

For more information about twill, see:
    http://twill.idyll.org/
"""

# allows us to import global twill as opposed to this module
from __future__ import absolute_import

# TODO: import all names with a _-prefix to keep the namespace clean with the twill stuff?
import urlparse
import cookielib

import twill
import twill.commands
import twill.browser

from django.conf import settings
from django.core.servers.basehttp import AdminMediaHandler
from django.core.handlers.wsgi import WSGIHandler
from django.core.urlresolvers import reverse, NoReverseMatch
from django.http import HttpRequest
from django.utils.datastructures import SortedDict
from django.contrib import auth
from django.core import signals
from django.db import close_connection


# make available through this module
from twill.commands import *

__all__ = ('INSTALLED', 'setup', 'teardown', 'reverse',) + tuple(twill.commands.__all__)


DEFAULT_HOST = '127.0.0.1'
DEFAULT_PORT = 9090
INSTALLED = SortedDict()   # keep track of the installed hooks


class DjangoWsgiFix(object):
    """Django closes the database connection after every request;
    this breaks the use of transactions in your tests. This wraps
    around Django's WSGI interface and will disable the critical
    signal handler for every request served.

    Note that we really do need to do this individually a every
    request, not just once when our WSGI hook is installed, since
    Django's own test client does the same thing; it would reinstall
    the signal handler if used in combination with us.
    """
    def __init__(self, app):
        self.app = app

    def __call__(self, environ, start_response):
        signals.request_finished.disconnect(close_connection)
        try:
            return self.app(environ, start_response)
        finally:
            signals.request_finished.connect(close_connection)


def setup(host=None, port=None, allow_xhtml=True, propagate=True):
    """Install the WSGI hook for ``host`` and ``port``.

    The default values will be used if host or port are not specified.

    ``allow_xhtml`` enables a workaround for the "not viewer HTML"
    error when browsing sites that are determined to be XHTML, e.g.
    featuring xhtml-ish mimetypes.

    Unless ``propagate specifies otherwise``, the
    ``DEBUG_PROPAGATE_EXCEPTIONS`` will be enabled for better debugging:
    when using twill, we don't really want to see 500 error pages,
    but rather directly the exceptions that occured on the view side.

    Multiple calls to this function will only result in one handler
    for each host/port combination being installed.
    """

    host = host or DEFAULT_HOST
    port = port or DEFAULT_PORT
    key = (host, port)

    if not key in INSTALLED:
        # installer wsgi handler
        app = DjangoWsgiFix(AdminMediaHandler(WSGIHandler()))
        twill.add_wsgi_intercept(host, port, lambda: app)

        # start browser fresh
        browser = get_browser()
        browser.diverged = False

        # enable xhtml mode if requested
        _enable_xhtml(browser, allow_xhtml)

        # init debug propagate setting, and remember old value
        if propagate:
            old_propgate_setting = settings.DEBUG_PROPAGATE_EXCEPTIONS
            settings.DEBUG_PROPAGATE_EXCEPTIONS = True
        else:
            old_propgate_setting = None

        INSTALLED[key] = (app, old_propgate_setting)
        return browser
    return False


def teardown(host=None, port=None):
    """Remove an installed WSGI hook for ``host`` and ```port``.

    If no host or port is passed, the default values will be assumed.
    If no hook is installed for the defaults, and both the host and
    port are missing, the last hook installed will be removed.

    Returns True if a hook was removed, otherwise False.
    """

    both_missing = not host and not port
    host = host or DEFAULT_HOST
    port = port or DEFAULT_PORT
    key = (host, port)

    key_to_delete = None
    if key in INSTALLED:
        key_to_delete = key
    if not key in INSTALLED and both_missing and len(INSTALLED) > 0:
        host, port = key_to_delete = INSTALLED.keys()[-1]

    if key_to_delete:
        _, old_propagate = INSTALLED[key_to_delete]
        del INSTALLED[key_to_delete]
        result = True
        if old_propagate is not None:
            settings.DEBUG_PROPAGATE_EXCEPTIONS = old_propagate
    else:
        result = False

    # note that our return value is just a guess according to our
    # own records, we pass the request on to twill in any case
    twill.remove_wsgi_intercept(host, port)
    return result


def _enable_xhtml(browser, enable):
    """Twill (darcs from 19-09-2008) does not work with documents
    identifying themselves as XHTML.

    This is a workaround.
    """
    factory = browser._browser._factory
    factory.basic_factory._response_type_finder._allow_xhtml = \
        factory.soup_factory._response_type_finder._allow_xhtml = \
            enable


class _EasyTwillBrowser(twill.browser.TwillBrowser):
    """Custom version of twill's browser class that defaults relative
    URLs to the last installed hook, if available.

    It also supports reverse resolving, and some additional commands.
    """

    def __init__(self, *args, **kwargs):
        self.diverged = False
        self._testing_ = False
        super(_EasyTwillBrowser, self).__init__(*args, **kwargs)

    def go(self, url, args=None, kwargs=None, default=None):
        assert not ((args or kwargs) and default==False)

        try:
            url = reverse(url, args=args, kwargs=kwargs)
        except NoReverseMatch:
            pass
        else:
            default = True    # default is implied

        if INSTALLED:
            netloc = '%s:%s' % INSTALLED.keys()[-1]
            urlbits = urlparse.urlsplit(url)
            if not urlbits[0]:
                if default:
                    # force "undiverge"
                    self.diverged = False
                if not self.diverged:
                    url = urlparse.urlunsplit(('http', netloc)+urlbits[2:])
            else:
                self.diverged = True

        if self._testing_:   # hack that makes it simple for us to test this
            return url
        return super(_EasyTwillBrowser, self).go(url)

    def login(self, **credentials):
        """Log the user with the given credentials into your Django
        site.

        To further simplify things, rather than giving the credentials,
        you may pass a ``user`` parameter with the ``User`` instance you
        want to login. Note that in this case the user will not be
        further validated, i.e. it is possible to login an inactive user
        this way.

        This works regardless of the url currently browsed, but does
        require the WSGI intercept to be setup.

        Returns ``True`` if login was possible; ``False`` if the
        provided credentials are incorrect, or the user is inactive,
        or if the sessions framework is not available.

        Based on ``django.test.client.Client.logout``.

        Note: A ``twill.reload()`` will not refresh the cookies sent
        with the request, so your login will not have any effect there.
        This is different for ``logout``, since it actually invalidates
        the session server-side, thus making the current key invalid.
        """

        if not 'django.contrib.sessions' in settings.INSTALLED_APPS:
            return False

        host, port = INSTALLED.keys()[-1]

        # determine the user we want to login
        user = credentials.pop('user', None)
        if user:
            # Login expects the user object to reference it's backend.
            # Since we're not going through ``authenticate``, we'll
            # have to do this ourselves.
            backend = auth.get_backends()[0]
            user.backend = user.backend = "%s.%s" % (
                backend.__module__, backend.__class__.__name__)
        else:
            user = auth.authenticate(**credentials)
            if not user or not user.is_active:
                return False

        # create a fake request to use with ``auth.login``
        request = HttpRequest()
        request.session = __import__(settings.SESSION_ENGINE, {}, {}, ['']).SessionStore()
        auth.login(request, user)
        request.session.save()

        # set the cookie to represent the session
        self.cj.set_cookie(cookielib.Cookie(
            version=None,
            name=settings.SESSION_COOKIE_NAME,
            value=request.session.session_key,
            port=str(port),   # must be a string
            port_specified = False,
            domain=host, #settings.SESSION_COOKIE_DOMAIN,
            domain_specified=True,
            domain_initial_dot=False,
            path='/',
            path_specified=True,
            secure=settings.SESSION_COOKIE_SECURE or None,
            expires=None,
            discard=None,
            comment=None,
            comment_url=None,
            rest=None
        ))

        return True

    def logout(self):
        """Log the current user out of your Django site.

        This works regardless of the url currently browsed, but does
        require the WSGI intercept to be setup.

        Based on ``django.test.client.Client.logout``.
        """
        host, port = INSTALLED.keys()[-1]
        for cookie in self.cj:
            if cookie.name == settings.SESSION_COOKIE_NAME \
                    and cookie.domain==host \
                    and (not cookie.port or str(cookie.port)==str(port)):
                session = __import__(settings.SESSION_ENGINE, {}, {}, ['']).SessionStore()
                session.delete(session_key=cookie.value)
                self.cj.clear(cookie.domain, cookie.path, cookie.name)
                return True
        return False


def go(*args, **kwargs):
    # replace the default ``go`` to make the additional
    # arguments that our custom browser provides available.
    browser = get_browser()
    browser.go(*args, **kwargs)
    return browser.get_url()

def login(*args, **kwargs):
    return get_browser().login(*args, **kwargs)

def logout(*args, **kwargs):
    return get_browser().logout(*args, **kwargs)

def reset_browser(*args, **kwargs):
    # replace the default ``reset_browser`` to ensure
    # that our custom browser class is used
    result = twill.commands.reset_browser(*args, **kwargs)
    twill.commands.browser = _EasyTwillBrowser()
    return result

# Monkey-patch our custom browser into twill; this will be global, but
# will only have an actual effect when intercepts are installed through
# our module (via ``setup``).
# Unfortunately, twill pretty much forces us to use the same global
# state it does itself, lest us reimplement everything from
# ``twill.commands``. It's a bit of a shame, we could provide dedicated
# browser instances for each call to ``setup()``.
reset_browser()


def url(should_be=None):
    """Like the default ``url()``, but can be called without arguments,
    in which case it returns the current url.
    """

    if should_be is None:
        return get_browser().get_url()
    else:
        return twill.commands.url(should_be)

########NEW FILE########
__FILENAME__ = views
from django.http import HttpResponse

import logging

from test_utils.testmaker.processors.base import slugify
from test_utils.testmaker import Testmaker

def set_logging(request, filename=None):
    if not filename:
        filename = request.REQUEST['filename']
    filename = slugify(filename)
    log_file = '/tmp/testmaker/tests/%s_tests_custom.py' % filename
    serialize_file = '/tmp/testmaker/tests/%s_serial_custm.py' % filename
    tm = Testmaker()
    tm.setup_logging(test_file=log_file, serialize_file=serialize_file)
    #tm.app_name = 'tmp'
    #tm.prepare_test_file()
    return HttpResponse('Setup logging %s' % tm.test_file)

def show_log(request):
    file = Testmaker.logfile()
    contents = open(file)
    return HttpResponse(contents.read(), content_type='text/plain')
    HttpResponse()

########NEW FILE########
