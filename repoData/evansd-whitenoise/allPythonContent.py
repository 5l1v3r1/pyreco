__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# WhiteNoise documentation build configuration file, created by
# sphinx-quickstart on Sun Aug 11 15:22:49 2013.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = []

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'WhiteNoise'
copyright = u'2013, David Evans'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '1.0'
# The full version, including alpha/beta/rc tags.
release = '1.0.2'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.

if os.environ.get('READTHEDOCS', None) == 'True':
    html_theme = 'default'
else:
    import sphinx_rtd_theme
    html_theme = 'sphinx_rtd_theme'
    html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'WhiteNoisedoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'WhiteNoise.tex', u'WhiteNoise Documentation',
   u'David Evans', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'whitenoise', u'WhiteNoise Documentation',
     [u'David Evans'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'WhiteNoise', u'WhiteNoise Documentation',
   u'David Evans', 'WhiteNoise', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = django_settings
SECRET_KEY = '4'
STATIC_URL = '/static/'

ROOT_URLCONF = 'tests.django_urls'

INSTALLED_APPS = (
    'django.contrib.staticfiles',
    'whitenoise',
)

ALLOWED_HOSTS = ['*']

LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'filters': {
        'require_debug_false': {
            '()': 'django.utils.log.RequireDebugFalse'
        }
    },
    'handlers': {
        'log_to_stderr': {
            'level': 'ERROR',
            'class': 'logging.StreamHandler'
        }
    },
    'loggers': {
        'django.request': {
            'handlers': ['log_to_stderr'],
            'level': 'ERROR',
            'propagate': True,
        },
    }
}

########NEW FILE########
__FILENAME__ = django_urls
from django.conf.urls import patterns, url
from django.http import HttpResponse

def hello_world(reqeust):
    return HttpResponse(content='Hello Word', content_type='text/plain')

urlpatterns = patterns('',
    url(r'^hello$', hello_world),
)

########NEW FILE########
__FILENAME__ = test_django_gzip
from __future__ import absolute_import, unicode_literals

from django.test import SimpleTestCase
from django.test.utils import override_settings
from django.conf import settings
from django.core.management import call_command

from .test_gzip import GzipTest


@override_settings()
class DjangoGzipTest(GzipTest, SimpleTestCase):

    @classmethod
    def run_gzip(cls):
        settings.STATIC_ROOT = cls.tmp
        call_command('gzipstatic', verbosity=0)

########NEW FILE########
__FILENAME__ = test_django_whitenoise
from __future__ import absolute_import, unicode_literals

import errno
import os
import shutil
import tempfile

import django
from django.test import SimpleTestCase
from django.test.utils import override_settings
from django.conf import settings
from django.contrib.staticfiles import storage
from django.core.wsgi import get_wsgi_application
from django.core.management import call_command

from .utils import TestServer

from whitenoise.django import DjangoWhiteNoise

# For Django 1.7+ ensure app registry is ready
if hasattr(django, 'setup'):
    django.setup()

ROOT_FILE = '/robots.txt'
ASSET_FILE = '/some/test.some.file.js'
TEST_FILES = {
    'root' + ROOT_FILE: b'some text',
    'static' + ASSET_FILE: b'this is some javascript' * 10
}


@override_settings()
class DjangoWhiteNoiseTest(SimpleTestCase):

    @classmethod
    def setUpClass(cls):
        # Keep a record of the original lazy storage instance so we can
        # restore it afterwards. We overwrite this in the setUp method so
        # that any new settings get picked up.
        if not hasattr(cls, '_originals'):
            cls._originals = {'staticfiles_storage': storage.staticfiles_storage}
        # Make a temporary directory and copy in test files
        cls.tmp = tempfile.mkdtemp()
        settings.STATICFILES_STORAGE = 'whitenoise.django.GzipManifestStaticFilesStorage'
        settings.STATICFILES_DIRS = [os.path.join(cls.tmp, 'static')]
        settings.STATIC_ROOT = os.path.join(cls.tmp, 'static_root')
        settings.WHITENOISE_ROOT = os.path.join(cls.tmp, 'root')
        for path, contents in TEST_FILES.items():
            path = os.path.join(cls.tmp, path.lstrip('/'))
            try:
                os.makedirs(os.path.dirname(path))
            except OSError as e:
                if e.errno != errno.EEXIST:
                    raise
            with open(path, 'wb') as f:
                f.write(contents)
        # Collect static files into STATIC_ROOT
        call_command('collectstatic', verbosity=0, interactive=False)
        # Initialize test application
        django_app = get_wsgi_application()
        cls.application = DjangoWhiteNoise(django_app)
        cls.server = TestServer(cls.application)
        super(DjangoWhiteNoiseTest, cls).setUpClass()

    @classmethod
    def tearDownClass(cls):
        super(DjangoWhiteNoiseTest, cls).tearDownClass()
        # Restore monkey-patched values
        if hasattr(cls, '_originals'):
            storage.staticfiles_storage = cls._originals['staticfiles_storage']
            del cls._originals
        # Remove temporary directory
        shutil.rmtree(cls.tmp)

    def setUp(self):
        # Configure a new lazy storage instance so it will pick up
        # any new settings
        storage.staticfiles_storage = storage.ConfiguredStorage()

    def test_get_root_file(self):
        url = ROOT_FILE
        response = self.server.get(url)
        self.assertEqual(response.content, TEST_FILES['root' + ROOT_FILE])

    def test_versioned_file_cached_forever(self):
        url = storage.staticfiles_storage.url(ASSET_FILE.lstrip('/'))
        response = self.server.get(url)
        self.assertEqual(response.content, TEST_FILES['static' + ASSET_FILE])
        self.assertEqual(response.headers.get('Cache-Control'),
                'public, max-age={}'.format(DjangoWhiteNoise.FOREVER))

    def test_unversioned_file_not_cached_forever(self):
        url = settings.STATIC_URL + ASSET_FILE.lstrip('/')
        response = self.server.get(url)
        self.assertEqual(response.content, TEST_FILES['static' + ASSET_FILE])
        self.assertEqual(response.headers.get('Cache-Control'),
                'public, max-age={}'.format(DjangoWhiteNoise.max_age))

    def test_get_gzip(self):
        url = storage.staticfiles_storage.url(ASSET_FILE.lstrip('/'))
        response = self.server.get(url)
        self.assertEqual(response.content, TEST_FILES['static' + ASSET_FILE])
        self.assertEqual(response.headers['Content-Encoding'], 'gzip')
        self.assertEqual(response.headers['Vary'], 'Accept-Encoding')

########NEW FILE########
__FILENAME__ = test_gzip
from __future__ import absolute_import, unicode_literals

import errno
import gzip
import os
import shutil
import tempfile
from unittest import TestCase

from whitenoise.gzip import main as gzip_main


COMPRESSABLE_FILE = 'application.css'
TOO_SMALL_FILE = 'too-small.css'
WRONG_EXTENSION = 'image.jpg'
TEST_FILES = {
    COMPRESSABLE_FILE: b'a' * 1000,
    TOO_SMALL_FILE: b'hi',
}

class GzipTestBase(TestCase):

    @classmethod
    def setUpClass(cls):
        # Make a temporary directory and copy in test files
        cls.tmp = tempfile.mkdtemp()
        for path, contents in TEST_FILES.items():
            path = os.path.join(cls.tmp, path.lstrip('/'))
            try:
                os.makedirs(os.path.dirname(path))
            except OSError as e:
                if e.errno != errno.EEXIST:
                    raise
            with open(path, 'wb') as f:
                f.write(contents)
        cls.run_gzip()
        super(GzipTestBase, cls).setUpClass()

    @classmethod
    def tearDownClass(cls):
        super(GzipTestBase, cls).tearDownClass()
        # Remove temporary directory
        shutil.rmtree(cls.tmp)

class GzipTest(GzipTestBase):

    @classmethod
    def run_gzip(cls):
        gzip_main(cls.tmp, quiet=True)

    def test_compresses_file(self):
        with gzip.open(os.path.join(self.tmp, COMPRESSABLE_FILE + '.gz'), 'rb') as f:
            contents = f.read()
        self.assertEqual(TEST_FILES[COMPRESSABLE_FILE], contents)

    def test_doesnt_compress_if_no_saving(self):
        self.assertFalse(os.path.exists(os.path.join(self.tmp, TOO_SMALL_FILE + 'gz')))

    def test_ignores_other_extensions(self):
        self.assertFalse(os.path.exists(os.path.join(self.tmp, WRONG_EXTENSION + '.gz')))

########NEW FILE########
__FILENAME__ = test_whitenoise
from __future__ import absolute_import, unicode_literals

import errno
import os
import shutil
import tempfile
from unittest import TestCase
from wsgiref.simple_server import demo_app

from .utils import TestServer, gzip_bytes

from whitenoise import WhiteNoise


# Update Py2 TestCase to support Py3 method names
if not hasattr(TestCase, 'assertRegex'):
    class Py3TestCase(TestCase):
        def assertRegex(self, *args, **kwargs):
            return self.assertRegexpMatches(*args, **kwargs)
    TestCase = Py3TestCase


# Define files we're going to test against
JS_FILE = '/some/test.js'
GZIP_FILE = '/compress.css'
TEST_FILES = {
    JS_FILE: b'this is some javascript',
    GZIP_FILE: b'some css goes here'
}
# Gzipped version of GZIPFILE
TEST_FILES[GZIP_FILE + '.gz'] = gzip_bytes(TEST_FILES[GZIP_FILE])


class WhiteNoiseTest(TestCase):

    @classmethod
    def setUpClass(cls):
        # Make a temporary directory and copy in test files
        cls.tmp = tempfile.mkdtemp()
        for path, contents in TEST_FILES.items():
            path = os.path.join(cls.tmp, path.lstrip('/'))
            try:
                os.makedirs(os.path.dirname(path))
            except OSError as e:
                if e.errno != errno.EEXIST:
                    raise
            with open(path, 'wb') as f:
                f.write(contents)
        # Initialize test application
        cls.application = WhiteNoise(demo_app,
                root=cls.tmp, max_age = 1000)
        cls.server = TestServer(cls.application)
        super(WhiteNoiseTest, cls).setUpClass()

    @classmethod
    def tearDownClass(cls):
        super(WhiteNoiseTest, cls).tearDownClass()
        # Remove temporary directory
        shutil.rmtree(cls.tmp)

    def test_get_file(self):
        response = self.server.get(JS_FILE)
        self.assertEqual(response.content, TEST_FILES[JS_FILE])
        self.assertRegex(response.headers['Content-Type'], r'application/javascript\b')
        self.assertRegex(response.headers['Content-Type'], r'.*\bcharset="utf-8"')

    def test_get_not_accept_gzip(self):
        response = self.server.get(GZIP_FILE, headers={'Accept-Encoding': ''})
        self.assertEqual(response.content, TEST_FILES[GZIP_FILE])
        self.assertEqual(response.headers.get('Content-Encoding', ''), '')
        self.assertEqual(response.headers['Vary'], 'Accept-Encoding')

    def test_get_accept_gzip(self):
        response = self.server.get(GZIP_FILE)
        self.assertEqual(response.content, TEST_FILES[GZIP_FILE])
        self.assertEqual(response.headers['Content-Encoding'], 'gzip')
        self.assertEqual(response.headers['Vary'], 'Accept-Encoding')

    def test_not_modified(self):
        response = self.server.get(JS_FILE)
        last_mod = response.headers['Last-Modified']
        response = self.server.get(JS_FILE, headers={'If-Modified-Since': last_mod})
        self.assertEqual(response.status_code, 304)

    def test_max_age(self):
        response = self.server.get(JS_FILE)
        self.assertEqual(response.headers['Cache-Control'], 'public, max-age=1000')

    def test_other_requests_passed_through(self):
        response = self.server.get('/not/static')
        self.assertIn('Hello world!', response.text)

    def test_add_under_prefix(self):
        prefix = '/prefix'
        self.application.add_files(self.tmp, prefix=prefix)
        response = self.server.get(prefix + JS_FILE)
        self.assertEqual(response.content, TEST_FILES[JS_FILE])

    def test_response_has_allow_origin_header(self):
        for name in TEST_FILES:
            response = self.server.get(name)
            self.assertEqual(response.headers.get('Access-Control-Allow-Origin'), '*')

    def test_response_has_correct_content_length_header(self):
        response = self.server.get(JS_FILE)
        length = int(response.headers['Content-Length'])
        self.assertEqual(length, len(TEST_FILES[JS_FILE]))

    def test_gzip_response_has_correct_content_length_header(self):
        response = self.server.get(GZIP_FILE)
        length = int(response.headers['Content-Length'])
        self.assertEqual(length, len(TEST_FILES[GZIP_FILE + '.gz']))

    def test_post_request_returns_405(self):
        response = self.server.request('post', JS_FILE)
        self.assertEqual(response.status_code, 405)

    def test_head_request_has_no_body(self):
        response = self.server.request('head', JS_FILE)
        self.assertEqual(response.status_code, 200)
        self.assertFalse(response.content)

########NEW FILE########
__FILENAME__ = utils
from __future__ import absolute_import, unicode_literals

import gzip
import io
import threading
import warnings
from wsgiref.simple_server import make_server, WSGIRequestHandler

import requests

warnings.filterwarnings(action='ignore', category=DeprecationWarning,
        module='requests')


class SilentWSGIHandler(WSGIRequestHandler):
    def log_message(*args):
        pass

class TestServer(object):
    """
    Wraps a WSGI application and allows you to make real HTTP
    requests against it
    """

    def __init__(self, application):
        self.application = application
        self.server = make_server('127.0.0.1', 0, application,
                handler_class=SilentWSGIHandler)

    def get(self, *args, **kwargs):
        return self.request('get', *args, **kwargs)

    def request(self, method, path, *args, **kwargs):
        url = 'http://{0[0]}:{0[1]}{1}'.format(self.server.server_address, path)
        thread = threading.Thread(target=self.server.handle_request)
        thread.start()
        response = requests.request(method, url, *args, **kwargs)
        thread.join()
        return response


def gzip_bytes(b):
    f = io.BytesIO()
    gz = gzip.GzipFile(fileobj=f, mode='wb')
    gz.write(b)
    gz.close()
    return f.getvalue()

########NEW FILE########
__FILENAME__ = base
from __future__ import absolute_import

from email.utils import parsedate, formatdate
import mimetypes
import os
import os.path
import re
from wsgiref.headers import Headers


class StaticFile(object):

    gzip_path = None

    def __init__(self, path):
        self.path = path
        self.headers = Headers([])


class WhiteNoise(object):

    BLOCK_SIZE = 16 * 4096
    GZIP_SUFFIX = '.gz'
    ACCEPT_GZIP_RE = re.compile(r'\bgzip\b')
    # All mimetypes starting 'text/' take a charset parameter, plus the
    # additions in this set
    MIMETYPES_WITH_CHARSET = frozenset((
        'application/javascript', 'application/xml'))
    # Ten years is what nginx sets a max age if you use 'expires max;'
    # so we'll follow its lead
    FOREVER = 10*365*24*60*60

    # Attributes that can be set by keyword args in the constructor
    config_attrs = ('max_age', 'allow_all_origins', 'charset')
    max_age = 60
    # Set 'Access-Control-Allow-Orign: *' header on all files.
    # As these are all public static files this is safe (See
    # http://www.w3.org/TR/cors/#security) and ensures that things (e.g
    # webfonts in Firefox) still work as expected when your static files are
    # served from a CDN, rather than your primary domain.
    allow_all_origins = True
    charset = 'utf-8'

    def __init__(self, application, root=None, prefix=None, **kwargs):
        for attr in self.config_attrs:
            try:
                setattr(self, attr, kwargs.pop(attr))
            except KeyError:
                pass
        if kwargs:
            raise TypeError("Unexpected keyword argument '{}'".format(
                list(kwargs.keys())[0]))
        self.application = application
        self.files = {}
        if root is not None:
            self.add_files(root, prefix)

    def __call__(self, environ, start_response):
        static_file = self.files.get(environ['PATH_INFO'])
        if static_file is None:
            return self.application(environ, start_response)
        else:
            return self.serve(static_file, environ, start_response)

    def serve(self, static_file, environ, start_response):
        method = environ['REQUEST_METHOD']
        if method != 'GET' and method != 'HEAD':
            start_response('405 Method Not Allowed', [('Allow', 'GET, HEAD')])
            return []
        if self.file_not_modified(static_file, environ):
            start_response('304 Not Modified', [])
            return []
        path, headers = self.get_path_and_headers(static_file, environ)
        start_response('200 OK', headers.items())
        if method == 'HEAD':
            return []
        file_wrapper = environ.get('wsgi.file_wrapper', self.yield_file)
        fileobj = open(path, 'rb')
        return file_wrapper(fileobj)

    def get_path_and_headers(self, static_file, environ):
        if static_file.gzip_path:
            if self.ACCEPT_GZIP_RE.search(environ.get('HTTP_ACCEPT_ENCODING', '')):
                return static_file.gzip_path, static_file.gzip_headers
        return static_file.path, static_file.headers

    def file_not_modified(self, static_file, environ):
        try:
            last_requested = environ['HTTP_IF_MODIFIED_SINCE']
        except KeyError:
            return False
        # Exact match, no need to parse
        if last_requested == static_file.headers['Last-Modified']:
            return True
        return parsedate(last_requested) >= static_file.mtime

    def yield_file(self, fileobj):
        # Only used as a fallback in case environ doesn't supply a
        # wsgi.file_wrapper
        try:
            while True:
                block = fileobj.read(self.BLOCK_SIZE)
                if block:
                    yield block
                else:
                    break
        finally:
            fileobj.close()

    def add_files(self, root, prefix=None, followlinks=False):
        prefix = (prefix or '').strip('/')
        prefix = '/{}/'.format(prefix) if prefix else '/'
        files = {}
        for dir_path, _, filenames in os.walk(root, followlinks=followlinks):
            for filename in filenames:
                file_path = os.path.join(dir_path, filename)
                url = prefix + os.path.relpath(file_path, root).replace('\\', '/')
                files[url] = self.get_static_file(file_path, url)
        self.find_gzipped_alternatives(files)
        self.files.update(files)

    def get_static_file(self, file_path, url):
        static_file = StaticFile(file_path)
        self.add_stat_headers(static_file, url)
        self.add_mime_headers(static_file, url)
        self.add_cache_headers(static_file, url)
        self.add_cors_headers(static_file, url)
        self.add_extra_headers(static_file, url)
        return static_file

    def add_stat_headers(self, static_file, url):
        stat = os.stat(static_file.path)
        static_file.mtime = int(stat.st_mtime)
        static_file.headers['Last-Modified'] = formatdate(
                static_file.mtime, usegmt=True)
        static_file.headers['Content-Length'] = str(stat.st_size)

    def add_mime_headers(self, static_file, url):
        mimetype, encoding = mimetypes.guess_type(static_file.path)
        mimetype = mimetype or 'application/octet-stream'
        charset = self.get_charset(mimetype, static_file, url)
        params = {'charset': charset} if charset else {}
        static_file.headers.add_header('Content-Type', mimetype, **params)
        if encoding:
            static_file.headers['Content-Encoding'] = encoding

    def get_charset(self, mimetype, static_file, url):
        if (mimetype.startswith('text/')
                or mimetype in self.MIMETYPES_WITH_CHARSET):
            return self.charset

    def add_cache_headers(self, static_file, url):
        if self.is_immutable_file(static_file, url):
            max_age = self.FOREVER
        else:
            max_age = self.max_age
        if max_age is not None:
            cache_control = 'public, max-age={}'.format(max_age)
            static_file.headers['Cache-Control'] = cache_control

    def is_immutable_file(self, static_file, url):
        """
        This should be implemented by sub-classes (see e.g. DjangoWhiteNoise)
        """
        return False

    def add_cors_headers(self, static_file, url):
        if self.allow_all_origins:
            static_file.headers['Access-Control-Allow-Origin'] = '*'

    def add_extra_headers(self, static_file, url):
        """
        This is provided as a hook for sub-classes, by default a no-op
        """
        pass

    def find_gzipped_alternatives(self, files):
        for url, static_file in files.items():
            gzip_url = url + self.GZIP_SUFFIX
            try:
                gzip_file = files[gzip_url]
            except KeyError:
                continue
            static_file.gzip_path = gzip_file.path
            static_file.headers['Vary'] = 'Accept-Encoding'
            # Copy the headers and add the appropriate encoding and length
            gzip_headers = Headers(static_file.headers.items())
            gzip_headers['Content-Encoding'] = 'gzip'
            gzip_headers['Content-Length'] = gzip_file.headers['Content-Length']
            static_file.gzip_headers = gzip_headers

########NEW FILE########
__FILENAME__ = django
from __future__ import absolute_import

import os.path

try:
    import urlparse
except ImportError:
    import urllib.parse as urlparse

from django.conf import settings
from django.core.exceptions import ImproperlyConfigured
from django.contrib.staticfiles.storage import staticfiles_storage
try:
    from django.contrib.staticfiles.storage import ManifestStaticFilesStorage
except ImportError:
    # For Django versions < 1.7
    from .storage_backport import ManifestStaticFilesStorage

from .base import WhiteNoise
from .gzip import compress, extension_regex, GZIP_EXCLUDE_EXTENSIONS


class DjangoWhiteNoise(WhiteNoise):

    def __init__(self, application):
        self.charset = settings.FILE_CHARSET
        # Allow settings to override default attributes
        for attr in self.config_attrs:
            settings_key = 'WHITENOISE_{}'.format(attr.upper())
            try:
                setattr(self, attr, getattr(settings, settings_key))
            except AttributeError:
                pass
        static_root, static_prefix = self.get_static_root_and_prefix()
        self.static_prefix = static_prefix
        root = getattr(settings, 'WHITENOISE_ROOT', None)
        super(DjangoWhiteNoise, self).__init__(application, root=root)
        self.add_files(static_root, prefix=static_prefix)

    def get_static_root_and_prefix(self):
        static_url = getattr(settings, 'STATIC_URL', None)
        static_root = getattr(settings, 'STATIC_ROOT', None)
        if not static_url or not static_root:
            raise ImproperlyConfigured('Both STATIC_URL and STATIC_ROOT '
                    'settings must be configured to use DjangoWhiteNoise')
        static_prefix = urlparse.urlparse(static_url).path
        static_prefix = '/{}/'.format(static_prefix.strip('/'))
        return static_root, static_prefix

    def is_immutable_file(self, static_file, url):
        """
        Determine whether given URL represents an immutable file (i.e. a
        file with a hash of its contents as part of its name) which can
        therefore be cached forever
        """
        if not url.startswith(self.static_prefix):
            return False
        name = url[len(self.static_prefix):]
        name_without_hash = self.get_name_without_hash(name)
        if name == name_without_hash:
            return False
        static_url = self.get_static_url(name_without_hash)
        # If the static URL function maps the name without hash
        # back to the original URL, then we know we've got a
        # versioned filename
        if static_url and static_url.endswith(url):
            return True
        return False

    def get_name_without_hash(self, filename):
        """
        Removes the version hash from a filename e.g, transforms
        'css/application.f3ea4bcc2.css' into 'css/application.css'

        Note: this is specific to the naming scheme used by Django's
        CachedStaticFilesStorage. You may have to override this if
        you are using a different static files versioning system
        """
        name_with_hash, ext = os.path.splitext(filename)
        name = os.path.splitext(name_with_hash)[0]
        return name + ext

    def get_static_url(self, name):
        try:
            return staticfiles_storage.url(name)
        except ValueError:
            return None


class GzipStaticFilesMixin(object):

    def post_process(self, *args, **kwargs):
        files = super(GzipStaticFilesMixin, self).post_process(*args, **kwargs)
        dry_run = kwargs.get('dry_run', False)
        extensions = getattr(settings, 'WHITENOISE_GZIP_EXCLUDE_EXTENSIONS',
                GZIP_EXCLUDE_EXTENSIONS)
        excluded_re = extension_regex(extensions)
        for name, hashed_name, processed in files:
            if not dry_run and not excluded_re.search(name):
                compress(self.path(name))
                if hashed_name is not None:
                    compress(self.path(hashed_name))
            yield name, hashed_name, processed


class GzipManifestStaticFilesStorage(GzipStaticFilesMixin, ManifestStaticFilesStorage):
    pass

########NEW FILE########
__FILENAME__ = gzip
#!/usr/bin/env python
from __future__ import absolute_import, print_function, division, unicode_literals

import argparse
import gzip
import os
import os.path
import re


# Makes the default extension list look a bit nicer
class PrettyTuple(tuple):
    def __repr__(self):
        return ', '.join(self)


CHUNK_SIZE = 64 * 1024

# Extensions that it's not worth trying to gzip
GZIP_EXCLUDE_EXTENSIONS = PrettyTuple((
    # Images
    'jpg', 'jpeg', 'png', 'gif', 'webp',
    # Compressed files
    'zip', 'gz', 'tgz', 'bz2', 'tbz',
    # Flash
    'swf', 'flv',
))

null_log = lambda x: x


def main(root, extensions=None, quiet=False, log=print):
    excluded_re = extension_regex(extensions)
    if quiet:
        log = null_log
    for dirpath, dirs, files in os.walk(root):
        for filename in files:
            if not excluded_re.search(filename):
                path = os.path.join(dirpath, filename)
                compress(path, log)


def extension_regex(extensions):
    if not extensions:
        return re.compile('^$')
    else:
        return re.compile(
            r'\.({})$'.format('|'.join(map(re.escape, extensions))),
            re.IGNORECASE)


def compress(path, log=null_log):
    gzip_path = path + '.gz'
    with open(path, 'rb') as in_file:
        # Explicitly set mtime to 0 so gzip content is fully determined
        # by file content (0 = "no timestamp" according to gzip spec)
        with gzip.GzipFile(gzip_path, 'wb', compresslevel=9, mtime=0) as out_file:
            for chunk in iter(lambda: in_file.read(CHUNK_SIZE), b''):
                out_file.write(chunk)
    # If gzipped file isn't actually any smaller then get rid of it
    orig_size = os.path.getsize(path)
    gzip_size = os.path.getsize(gzip_path)
    if gzip_size >= orig_size:
        log('Skipping {} (Gzip file is larger)'.format(path))
        os.unlink(gzip_path)
    else:
        log('Gzipping {} ({}K -> {}K)'.format(
            path, orig_size // 1024, gzip_size // 1024))


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
            description="Search for all files inside <root> *not* matching <extensions> "
                        "and produce gzipped versions with a '.gz' suffix (as long "
                        "this results in a smaller file)",
            formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('-q', '--quiet', help="Don't produce log output", action='store_true')
    parser.add_argument('root', help='Path root from which to search for files')
    parser.add_argument('extensions', nargs='*', help='File extensions to exclude from gzipping',
            default=GZIP_EXCLUDE_EXTENSIONS)
    args = parser.parse_args()
    main(**vars(args))

########NEW FILE########
__FILENAME__ = gzipstatic
from __future__ import absolute_import

import django
from django.core.management.base import NoArgsCommand
from django.conf import settings

from ...gzip import main, GZIP_EXCLUDE_EXTENSIONS


class Command(NoArgsCommand):
    help = "Search for files in STATIC_ROOT and produced gzipped version with a '.gz' suffix.\n" \
            "Skips files with extensions specified in WHITENOISE_GZIP_EXCLUDE_EXTENSIONS\n" \
            "By default: {}".format(GZIP_EXCLUDE_EXTENSIONS)

    if django.VERSION < (1, 7):
        requires_model_validation = False
    else:
        requires_system_checks = False

    def handle_noargs(self, quiet=None, **options):
        quiet = '0' == '{}'.format(options.get('verbosity'))
        root = settings.STATIC_ROOT
        extensions = getattr(settings, 'WHITENOISE_GZIP_EXCLUDE_EXTENSIONS',
                GZIP_EXCLUDE_EXTENSIONS)
        main(root, extensions, log=self.stdout.write, quiet=quiet)

########NEW FILE########
__FILENAME__ = storage_backport
from __future__ import absolute_import, unicode_literals

import json

from django.contrib.staticfiles.storage import CachedStaticFilesStorage


class ManifestStaticFilesStorage(CachedStaticFilesStorage):
    """
    Basic emulation of ManifestStaticFilesStorage from Django 1.7
    """
    manifest_name = 'staticfiles.json'

    def __init__(self, *args, **kwargs):
        super(ManifestStaticFilesStorage, self).__init__(*args, **kwargs)
        self.cache = ManifestCache(self.path(self.manifest_name))

    def cache_key(self, name):
        return name


class ManifestCache(object):
    """
    Acts enough like a cache backend to be used with CachedStaticFilesStorage
    from Django < 1.7, but stores data in a manifest file like Django 1.7+
    """
    def __init__(self, manifest_file):
        self.manifest_file = manifest_file
        try:
            with open(self.manifest_file) as f:
                self.manifest = json.load(f)['paths']
        except IOError:
            self.manifest = {}
        # Wire up the get method directly to the dict getter
        self.get = self.manifest.get

    def set(self, key, value, **kwargs):
        self.manifest[key] = value

    def set_many(self, values, **kwargs):
        self.manifest.update(values)
        payload = {'paths': self.manifest, 'version': '1.0'}
        with open(self.manifest_file, 'w') as f:
            json.dump(payload, f)

########NEW FILE########
