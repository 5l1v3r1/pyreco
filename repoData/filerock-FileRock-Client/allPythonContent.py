__FILENAME__ = filerock
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
FileRock Client main script


This is the main script of FileRock Client.
FileRock is a backup and synchronization service that provides confidentiality
and checks the integrity of your data.

In order to use FileRock Client, you will need a FileRock account.
You can get one at https://www.filerock.com/register

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.main import main


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = application
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
The layer controlling the relationship between user interfaces
and the rest of the application.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import sys
import socket
import httplib
import urllib
import urllib2
import os
import logging
import Queue
import signal
import threading
import datetime
import traceback
from ConfigParser import NoOptionError
import portalocker

from filerockclient.core import Core
from filerockclient.logging_helper import LoggerManager
from filerockclient.config import ConfigManager
from filerockclient.bugreporter import Collector, HTTPSSender, DevelopCollector
from filerockclient.bugreporter.logger_sender import LoggerSender
from filerockclient.exceptions import FileRockException
from filerockclient.exceptions import UpdateRequestedException
from filerockclient.exceptions import UpdateProcedureException
from filerockclient.exceptions import LogOutRequiredException
from filerockclient.exceptions import MandatoryUpdateDeniedException
from filerockclient import config
from filerockclient.util import https_downloader
from filerockclient.updater.UpdaterBase import PlatformUpdater
from filerockclient.util.utilities import increase_exponentially, \
                                          open_folder_in_system_shell


MIN_RESET_INTERVAL = datetime.timedelta(seconds=10)
MAX_NUMBER_OF_RESTART = 4
MIN_MINUTES_TO_WAIT_AFTER_PAUSE = 1
MAX_MINUTES_TO_WAIT_AFTER_PAUSE = 10


class UnknownCommandError(FileRockException):
    pass


class Application(object):
    """
    The layer controlling the relationship between user interfaces
    and the rest of the application.

    The main reason for this component to exist is to decouple the
    "core" code from the user interfaces (UI), such that these can run
    independently from the rest of the client.
    After a UI is created, she's registered to "the client" (an instance
    of the filerockclient.core.Core class), which is treated as an
    external producer of events (see the "Observer" design pattern).
    This enables the client to restart without involving the UIs, which
    indeed keep running; as soon as a new client instance is ready to
    run, the UIs are registered again and forget the old client instance.
    Any application run is a new instance of the filerock.core.Core
    class, so restarting implies creating a new instance.
    "Application" handles all kinds of "application termination" events:
    stop, restart, quit, restart after a while, etc. Other components
    asks these services when needed.
    Note: the main thread lives in this component, listening for
    requests.
    """

    def __init__(self, develop, bugreport, configdir, startupslides,
                 restartcount,  hardreset_allowed, showpanel, interface, cmdline_args,
                 main_script):
        """
        @param develop:
                    Boolean flag telling whether the application is
                    running in "development" mode.
        @param bugreport:
                    Boolean flag telling whether unhandled
                    exceptions (that is, those that reaches the top
                    of the call stack) should automatically send a
                    bug report to the FileRock development team.
        @param configdir:
                    The directory in the filesystem that keeps the
                    user's configuration files.
        @param startupslides:
                    Boolean flag telling whether to show the
                    introductive slides at application startup.
        @param restartcount:
                    How many times the application has been
                    recently restarted by hardreset (usually due to errors).
        @param hardreset_allowed:
                    This says if the resatrt can be performed (exit otherwise)
        @param showpanel:
                    Boolean flag telling whether the GUI panels
                    should automatically appear at application startup.
        @param interface:
                    The type of user interface to use:
                    'c': console only
                    'g': graphical interface
                    'n': no interface (actually a do-nothing interface)
                    Note that 'g' implies the console user interface if
                    the application is run in develop mode.
        @param cmdline_args:
                    List of command line arguments to start client.
                    First parameter is always an executable
        @param main_script:
                    Filename of the main Python script (usually
                    "FileRock.py").
        """
        self.develop = develop
        self.bugreport = bugreport if not develop else False
        self.configdir = configdir
        self.startupslides = startupslides
        self.restartcount = restartcount
        self.hardreset_allowed = hardreset_allowed
        self.showpanel = showpanel
        self.interface = interface
        self.cmdline_args = cmdline_args
        self.main_script = main_script
        self._ui_cache = {}
        self.auto_start = True
        self.restart_after_minute = 0
        self._lockfile = None

    def main_loop(self):
        """
        The never-ending loop where the main thread runs, listening for
        termination events.

        Calling this method means actually starting FileRock.
        Each iteration of the loop implies a re-initialization of some
        part of the application: just the core, the UI as well, the
        whole OS process, etc. Most of the time the thread sleeps,
        waiting for a command in the input queue, in a blocking fashion.
        """
        logging_helper = LoggerManager()
        logger = self._get_logger(logging_helper)
        self.logger = logger

        cfg = ConfigManager(self.configdir)
        cfg.load()

        self._lockfile = self._check_unique_instance_running(cfg, logger)
        if not self._lockfile:
            self._open_warebox_folder(cfg)
            return

        self._save_process_pid()
        running = True
        skip_ui_creation = False
        command_queue = Queue.Queue()
        file_handler = None
        oldhook = None
        last_reset_time = datetime.datetime.now() - datetime.timedelta(days=1)

        if self.restartcount > 0:
            self.startupslides = False
            self.showpanel = False

        if self.restartcount >= MAX_NUMBER_OF_RESTART:
            self.restartcount = 0
            self._pause_client(True)

        def sigterm_handler(sig, sframe):
            command_queue.put('TERMINATE')

        def sigabrt_handler(sig, sframe):
            command_queue.put('HARD_RESET')

        signal.signal(signal.SIGTERM, sigterm_handler)
        signal.signal(signal.SIGABRT, sigabrt_handler)

        while running:

            cfg.load()

            self._reload_connection_proxy_settings(cfg, logger)

            file_handler = self._configure_file_logging(logger,
                                                        logging_helper,
                                                        file_handler,
                                                        cfg.get_config_dir())

            logger.debug("Current configuration:\n%s" % cfg)

            core = Core(cfg,
                        self.startupslides,
                        self.showpanel,
                        command_queue,
                        self.cmdline_args,
                        self._lockfile.fileno(),
                        self.auto_start,
                        self.restart_after_minute)

            # In case of SOFT_RESET startupslides and panel
            # should not be shown
            self.startupslides = False
            self.showpanel = False

            logger.debug("Command line arguments: %r"
                         % self.cmdline_args)

            bug_reporter, oldhook = self._setup_bug_reporting(
                core, cfg, logging_helper, command_queue)

            try:
                self._setup_user_interfaces(core,
                                            logger,
                                            logging_helper,
                                            cfg,
                                            skip_ui_creation)

                skip_ui_creation = False
                self.auto_start = True

                # Let the magic begin
                core.start_service()

                # Listen for termination commands from other threads
                while True:
                    try:
                        # Note: the actual blocking get cannot be interrupted
                        # by signals, e.g. by pressing Ctrl-C, so we use the
                        # timeout version with a very large timeout value.
                        command = command_queue.get(True, 999999)
                    except Queue.Empty:
                        continue

                    if command == 'TERMINATE':
                        logger.debug('Executing command TERMINATE...')
                        self._terminate(core, logger)
                        running = False
                        logger.debug('Command TERMINATE executed.')
                        break

                    elif command == 'START':
                        logger.debug('Executing command START...')
                        self.restart_after_minute = -1
                        core.connect()
                        logger.debug('Command START executed.')

                    elif command == 'PAUSE':
                        logger.debug('Executing command PAUSE...')
                        self._terminate(core, logger, terminate_ui=False)
                        core.unschedule_start()
                        skip_ui_creation = True
                        self._pause_client()
                        logger.debug('Command PAUSE executed.')
                        break

                    elif command == 'PAUSE_AND_RESTART':
                        logger.debug('Executing command PAUSE AND RESTART...')
                        self._terminate(core, logger, terminate_ui=False)
                        skip_ui_creation = True
                        self._pause_client(schedule_a_start=True)
                        logger.debug('Command PAUSE AND RESTART executed.')
                        break

                    elif command == 'RESET_PAUSE_TIMER':
                        logger.debug('Resetting waiting after reset')
                        self.restart_after_minute = -1

                    elif command == 'SOFT_RESET':
                        logger.debug('Executing command SOFT_RESET...')
                        self._terminate(core, logger, terminate_ui=False)
                        skip_ui_creation = True
                        logger.debug('Command SOFT_RESET executed.')
                        break

                    elif command == 'FULL_RESET':
                        running = self._full_reset(
                                core, logger, last_reset_time)
                        last_reset_time = datetime.datetime.now()
                        break

                    elif command == 'HARD_RESET':
                        logger.debug('Executing command HARD_RESET...')
                        self._terminate(core, logger)
                        exc = None
                        try:
                            # Note: this call doesn't return
                            self._hard_reset(logger)
                        except Exception as e:
                            exc = e
                        logger.critical('Error while hard resetting: %r' % exc)
                        os._exit(1)
                    else:
                        logger.error(
                            'Application is unable to handle '
                            'command %s. Forcing termination...' % command)
                        raise UnknownCommandError(command)

            except KeyboardInterrupt:
                # Ctrl-C is equivalent to the TERMINATE command
                self._terminate(core, logger)
                running = False
            except LogOutRequiredException:
                logger.info(u"Logout is required to continue, shutting down..")
                self._terminate(core, logger)
                running = False
            except MandatoryUpdateDeniedException:
                logger.info(u"User denied a mandatory update, shutting down...")
                self._terminate(core, logger)
                running = False
            except UpdateRequestedException:
                # TODO: this will be replaced by an UPDATE command
                logger.info(u"Client is going to be updated, shutting down")
                self._terminate(core, logger)
                self._close_lockfile()
                logger.info(u"Starting update procedure...")
                try:
                    updater = PlatformUpdater(
                                    cfg.get_config_dir(),
                                    cfg.get('Application Paths', 'webserver_ca_chain'))
                    updater.execute_update()
                except UpdateProcedureException as e:
                    logger.error(u"Update procedure error: %s" % e)
            except Exception:
                # The main thread shouldn't rely on automatic bug reporting,
                # she must handle her own exceptions or nobody will be there to
                # terminate the application at the end!
                bug_reporter.on_exception(*sys.exc_info())
                running = self._full_reset(core, logger, last_reset_time)
                last_reset_time = datetime.datetime.now()

        if oldhook:
            sys.excepthook = oldhook
        logger.info(u"Shut down. Goodbye.")

    def _check_unique_instance_running(self, cfg, logger):
        """Check whether this is the only instance of FileRock running.

        If so, returns a file object held open with an exclusive lock,
        which ensures that no other instances will run concurrently.
        If not, returns False.
        """
        config_dir = cfg.get_config_dir()
        lockfile_path = os.path.join(config_dir, 'lockfile')
        lockfile = open(lockfile_path, 'w')
        try:
            portalocker.lock(lockfile, portalocker.LOCK_EX | portalocker.LOCK_NB)
        except portalocker.LockException:
            logger.info(u"Can't start the application since there is"
                        " another instance running.")
            return False
        return lockfile

    def _close_lockfile(self):
        """Try to close lockfile (see _check_unique_instance_running)
        """
        try:
            self._lockfile.close()
        except Exception as e:
            self.logger.debug(u"Can't close lockfile (maybe someone already "
                              "closed it): %s" % e)

    def _open_warebox_folder(self, cfg):
        """Open the warebox in the system shell.
        """
        warebox_path = cfg.get('Application Paths', 'warebox_path')
        open_folder_in_system_shell(warebox_path)

    def _save_process_pid(self):
        """
        Changes the progress title adding a -PID_%PID parameter
        """
        if sys.platform.startswith('linux2'):
            import setproctitle
            title = setproctitle.getproctitle()
            setproctitle.setproctitle("%s -PID_%s" % (title, os.getpid()))
            new_title = setproctitle.getproctitle()
            self.logger.info("Current proc title is %s" % new_title)

    def _pause_client(self, schedule_a_start=False):
        """
        Put the application to pause.

        "Pause" is a no-op state where the application is not connected
        to the network and doesn't perform any disk operation.
        The user has the chance to put the client to pause through the
        user interface. Moreover, the application puts herself to pause
        as a first reaction to critical errors, then scheduling a
        command to restart again after a given interval of time.

        @param schedule_a_start:
                    Boolean flag telling whether a restart should be
                    scheduled in order to restart the application after
                    a while. The waiting interval increases exponentially
                    up to a maximum value.
        """
        self.auto_start = False
        if schedule_a_start:
            self.restart_after_minute = increase_exponentially(
                                            self.restart_after_minute,
                                            MAX_MINUTES_TO_WAIT_AFTER_PAUSE,
                                            MIN_MINUTES_TO_WAIT_AFTER_PAUSE)
        else:
            self.restart_after_minute = -1

    def _get_logger(self, logging_helper):
        """
        Setup the application root logger.

        @param logging_helper:
                    Instance of filerockclient.logging_helper.LoggerManager
        @return
                    A configured logger object.
        """
        # Mute the root logger.
        # This will disable all loggers except ours, i.e. the "FR.*" ones.
        root_logger = logging.getLogger()
        root_logger.addHandler(logging.NullHandler())

        # Configure our main logger
        logger = logging.getLogger("FR")
        logger.setLevel(logging.INFO)
        if self.develop:
            handler = logging_helper._get_StreamHandler(logging.INFO)
            logger.addHandler(handler)
        else:
            logger.addHandler(logging.NullHandler())
            # On Windows, GUI applications by default don't open the stdout and
            # stderr streams. Py2exe redirects both to a log file but we don't
            # like it, so we monkey patch the two streams in order to produce
            # no output. Damn py2exe.
            dev_null = open(os.devnull, 'w')
            sys.stderr = dev_null
            sys.stdout = dev_null
        return logger

    def _configure_file_logging(
            self, logger, logging_helper, file_handler, config_dir):
        """
        Setup a given logger object to make it write log messages
        to a file.

        This kind of setup must be redone at each application restart,
        since the location of the log file may have been changed in the
        meanwhile. This is the only reason why this method exists outside
        of self._get_logger().

        @param logger:
                    The logger object to setup.
        @param logging_helper:
                    Instance of filerockclient.logging_helper.LoggerManager
        @param file_handler:
                    The handler instance returned by the previous call
                    of this method, if any. This parameter is needed to
                    remove such handler from the logger before creating
                    the new one.
        @param config_dir:
                    Absolute filesystem pathname of the directory where
                    the log file will be created.
        @return
                    The instance of logging handler just added to the
                    logger.
        """
        # TODO: check if this method actually refreshes the logger when
        # the config_dir has changed, I don't think so.
        if file_handler is not None:
            logger.removeHandler(file_handler)
        file_handler = logging_helper._get_RotatingFileHandler(config_dir)
        logger.addHandler(file_handler)
        logger.setLevel(logging.DEBUG)
        return file_handler

    def _setup_bug_reporting(self, core, cfg, logging_helper, command_queue):
        """
        Configure the automatic bug reporting for the application.

        An instance of filerockclient.bug_reporter.Collector.Collector
        is created and registered as the exception hook (see Python's
        sys.excepthook). It automatically sends a bug report to the
        FileRock development team each time an exception is let
        unhandled.

        @param core:
                    Instance of filerockclient.core.Core.
        @param cfg:
                    Instance of filerockclient.config.ConfigManager.
        @param logging_helper:
                    Instance of filerockclient.logging_helper.LoggerManager.
        @param command_queue:
                    Instance of Queue.Queue. The command queue of
                    Application will be given to the bug reporter so
                    that it could restart the application on errors.
        @return
                A pair with the created bug reporter object and the
                previous exception hook that was installed (possibly
                None).
        """
        if self.bugreport:
            collector = Collector.Collector(core._internal_facade,
                                            cfg,
                                            logging_helper,
                                            self.restartcount,
                                            command_queue,
                                            self.cmdline_args,
                                            self.main_script)
            collector.add_sender(HTTPSSender.HTTPSSender(
                'www.filerock.com', '443', 'client_report'))
        else:
            collector = DevelopCollector.DevelopCollector(
                core._internal_facade, cfg, logging_helper,
                self.restartcount, command_queue, self.cmdline_args,
                self.main_script)
            collector.add_sender(LoggerSender())
        oldhook = sys.excepthook
        sys.excepthook = collector.on_exception
        return collector, oldhook

    def _reload_connection_proxy_settings(self, cfg, logger):
        """
        Setup the network layer to use the proxy settings.

        This method monkey-patches the standard network modules to make
        them transparently use a proxy. It's just a dirt hack that will
        be removed as soon as our application will have its own
        "network" layer, instead of directly accessing the standard
        libraries everywhere.

        @param cfg:
                    Instance of filerockclient.config.ConfigManager.
        @param logger:
                    The main logger.
        """
        # TODO: move this to the network layer

        # Reload standard modules in any case. This refreshes such modules,
        # thus canceling any previous patch.
        reload(socket)
        reload(httplib)
        reload(urllib)
        reload(urllib2)
        reload(https_downloader)
        proxy_usage = cfg.get(config.USER_DEFINED_OPTIONS, 'proxy_usage')

        # Override properly according to proxy settings
        if proxy_usage == u'True':
            logger.info('Loading proxy settings from configuration...')
            if not 'sockes' in sys.modules: import socks
            proxy_host = cfg.get(config.USER_DEFINED_OPTIONS, 'proxy_host')
            proxy_type = getattr(socks, 'PROXY_TYPE_%s' % cfg.get(config.USER_DEFINED_OPTIONS, 'proxy_type'))
            proxy_port = cfg.getint(config.USER_DEFINED_OPTIONS, 'proxy_port')
            proxy_resolve_dns_on_proxy_server = (cfg.get(config.USER_DEFINED_OPTIONS, 'proxy_rdns') == u'True')
            proxy_username = cfg.get(config.USER_DEFINED_OPTIONS, 'proxy_username')
            if proxy_username == u'': proxy_username = None
            proxy_password = cfg.get(config.USER_DEFINED_OPTIONS, 'proxy_password')
            if proxy_password == u'': proxy_password = None
            proxy_settings_log = '''
                          - proxy type: %s
                          - proxy host: %s
                          - proxy port: %s
                          - proxy rdns: %s
                          - proxy user: %s
                          - proxy pass: %s ''' % ( proxy_type,
                                                   proxy_host,
                                                   proxy_port,
                                                   proxy_resolve_dns_on_proxy_server,
                                                   proxy_username,
                                                   proxy_password )
            logger.info('Using the following settings as proxy configuration: %s' % proxy_settings_log)
            socks.setdefaultproxy(  proxy_type,
                                    proxy_host,
                                    proxy_port,
                                    proxy_resolve_dns_on_proxy_server,
                                    proxy_username,
                                    proxy_password )
            socket.socket         = socks.socksocket
            httplib.socket.socket = socks.socksocket
            urllib.socket.socket  = socks.socksocket
            urllib2.socket.socket = socks.socksocket

    def _setup_user_interfaces(
                self, core, logger, logging_helper, cfg, skip_creation=False):
        """
        Setup and run the user interfaces (UIs).

        The user interfaces to setup are those indicated by self.interface.
        Each of them is created and registered to the core.

        @param core:
                    Instance of filerockclient.core.Core.
        @param logger:
                    The main logger.
        @param logging_helper:
                    Instance of filerockclient.logging_helper.LoggerManager.
                    Used to setup some UI logging facilities.
        @param cfg:
                    Instance of filerockclient.config.ConfigManager.
        @param skip_creation:
                    Boolean flag telling whether the creation step for
                    the user interfaces must be skipped. When True, it
                    means we have just done a soft reset of the
                    application; the old UI instances have been cached
                    and only need to be registered to the new core
                    instance.
        """

        # Note: the first registered UI is preferred by the application
        # for interacting with the user.

        if self.interface == u'c':

            from filerockclient.ui.console import SimpleConsoleUI
            if not skip_creation:
                self._ui_cache['console'] = core.setup_ui(SimpleConsoleUI)
            core.register_ui(self._ui_cache['console'])

        elif self.interface == u'g':

            # Initialize the wxGui.constants module before of loading any
            # other GUI code, since such code makes a lot of static
            # accesses to it at loading time.
            from filerockclient.ui.wxGui import constants as wxGuiConstants
            images_dir = cfg.get('Application Paths', 'images_dir')
            icons_dir = cfg.get('Application Paths', 'icons_dir')
            locale_dir = cfg.get('Application Paths', 'locale_dir')
            wxGuiConstants.init(images_dir, icons_dir, locale_dir)

            from filerockclient.ui.wxGui import gui

            if not skip_creation:
                self._ui_cache['gui'] = core.setup_ui(gui.GUI)
                gui_log_handler = logging_helper._get_GuiHandler()
                gui_log_handler.registerGuiLogHandler(
                    self._ui_cache['gui'].newLogLine)
                logger.addHandler(gui_log_handler)
            core.register_ui(self._ui_cache['gui'])

            from filerockclient.ui import shellextension
            try:
                if shellextension.ui_class is not None:
                    if not skip_creation:
                        ui_cls = shellextension.ui_class
                        self._ui_cache['shellext'] = core.setup_ui(ui_cls)
                    core.register_ui(self._ui_cache['shellext'])
            except Exception:
                logger.warning(u"Error while initializing the shell extension,"
                               " it will be skipped for this run.")

            # TODO: move this into the shellextension package - we want to be
            # as little platform-aware as possible here!
            if sys.platform == 'darwin':
                try: enable_osx_label_shellext = cfg.get(config.USER_DEFINED_OPTIONS, 'osx_label_shellext') == u'True'
                except NoOptionError: enable_osx_label_shellext = False
                if enable_osx_label_shellext:
                    from filerockclient.ui.shellextension.osx.label_based_ui import OSXLabelBasedUI
                    self._ui_cache['osx_label_based_shellext'] = core.setup_ui(OSXLabelBasedUI)
                    core.register_ui(self._ui_cache['osx_label_based_shellext'])

            if self.develop:
                from filerockclient.ui.console import SimpleConsoleUI
                if not skip_creation:
                    self._ui_cache['console'] = core.setup_ui(SimpleConsoleUI)
                core.register_ui(self._ui_cache['console'])

        elif self.interface == u'n':

            from filerockclient.ui.dummy import DummyUI
            if not skip_creation:
                self._ui_cache['dummy'] = core.setup_ui(DummyUI)
            core.register_ui(self._ui_cache['dummy'])

        # else:
        #     # TODO: move this to main
        #     logger.info(
        #         "Invalid UI specification in option -i or --interface.")
        #     parser.print_help()
        #     sys.exit(1)

    def _terminate(self, core, logger, terminate_ui=True):
        """
        Cleanly terminate the application. A preliminary step for both
        closing and restarting.

        In case of any error during the termination, a hard reset is
        tried. This is usually the sympthom of an exception thrown by
        the termination procedure of some component.

        @param core:
                    The instance of filerockclient.core.Core to terminate.
        @param logger:
                    The logger.
        @param terminate_ui:
                    Boolean flag telling whether the UIs should be
                    terminated, besides the core. False means that we
                    are doing a "soft reset" of the application.
        """
        try:
            old_handler = signal.signal(signal.SIGINT, signal.SIG_IGN)
            logger.info(u"Terminating the application...")
            core.terminate()
            if terminate_ui:
                logger.debug(u"Terminating the user interfaces...")
                for ui in self._ui_cache.itervalues():
                    ui.quitUI()
                logger.debug(u"User interfaces terminated.")
            logger.info(u"Application terminated.")
            threads = '\n'.join([repr(t) for t in threading.enumerate()])
            logger.debug(
                'Still active threads (it should be only main):\n%s' % threads)
            signal.signal(signal.SIGINT, old_handler)
        except Exception as e:
            logger.critical(
                "Error while terminating the application: %r. Can't recover "
                "from this, trying to hard reset..." % e)
            logger.debug(
                u"Last error stacktrace:\n%r" % traceback.format_exc())
            self._hard_reset(logger)


    def _full_reset(self, core, logger, last_reset_time):
        """
        Perform a "full reset" of the application.

        The full reset basically terminates both the core and the UIs,
        leaving to the main loop to actually restart everything.

        @return Boolean flag telling whether to restart the application
                or not, due to the detection of too many failures in a
                short time.
        """
        logger.debug('Executing command FULL_RESET...')
        self._terminate(core, logger)
        logger.debug('Command FULL_RESET executed.')
        reset_interval = datetime.datetime.now() - last_reset_time
        if reset_interval.total_seconds() < MIN_RESET_INTERVAL.total_seconds():
            logger.warning(
                "Detected two application failures in too short a time. "
                "Giving up, the application won't restart.")
            return False
        return True

    def _hard_reset(self, logger):
        """
        Perform an "hard reset" of the application.

        The OS process where FileRock is restarted by the mean of a
        method in the os.exec* family. Any running thread is abruptly
        stopped and the process memory is overwritten.
        It's a "hard" way to restart and should not replace other forms
        of restart/termination. However is very useful to recover from
        critical errors, where nothing else could be done.
        When successful, this call doesn't return.

        If hard reset is not allowed (by constructor parameter 
        of this application object), it exits abrubptly.
        """
        
        if not self.hardreset_allowed:
            sys.exit(666)
        
        logger.info(u'\n\n-----------\n' +
            'Restarting FileRock, please wait...\n-----------\n')

        # On Unix any open file descriptor is retained after calling
        # os.exec*. This would prevent the client from restarting
        # (self-deadlock), so we explicitly close the lockfile
        # handle just before to reset.
        self._close_lockfile()

        cmdline_args = self.cmdline_args[:]

        def clean_cmdline_arg(parameter):
            """Strips the given parameter name from sys.argv"""
            filtered_args = filter(lambda x: x.startswith(parameter), cmdline_args)
            for arg in filtered_args:
                cmdline_args.remove(arg)

        # Increment the restart counter
        clean_cmdline_arg('--restart-count')
        cmdline_args.append('--restart-count=%s' % (self.restartcount + 1))

        # Force not to show the presentation slides at startup
        clean_cmdline_arg('--no-startup-slides')
        cmdline_args.append('--no-startup-slides')

        def escape_cmdline_args(args):
            """Perform any escaping needed by the OS shell.

            Windows requires the command line arguments to be double-
            quoted. Linux and OSX require to be NOT double-quoted.
            """
            if not sys.platform.startswith('win'):
                return args
            else:
                return [u'"%s"' % arg for arg in args]

        executable = cmdline_args[0]
        cmdline_args = escape_cmdline_args(cmdline_args)

        logger.debug('Command HARD_RESET executed. Restarting process...'
                     ' (executable: %s, args: %s)'
                     % (executable, cmdline_args))

        # TODO: we should flush every open file descriptor before execv*
        # (see http://docs.python.org/2/library/os.html#os.execvpe)
        os.execvp(executable, tuple(cmdline_args))


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = blacklist
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the blacklist module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import re, logging, json, hashlib
import cPickle as pickle
from filerockclient.util.utilities import format_to_log


class Blacklist(object):
    def __init__(self, dirs=[], files=[], contains=[], extentions=[]):
        super(Blacklist, self).__init__()
#        self.log = logging.getLogger("FR."+self.__class__.__name__)
#        self.log.debug('Hi')

        escaped = [self._unify_dirs(dirs),
                   self._unify_files(files),
                   self._unify_extentions(extentions),
                   self._unify_contains(contains)
                   ]

        expr = self._unify_escaped(escaped)
        compiled = re.compile(expr)
        self._blacklist = set([compiled])
        self.blacklisted_path = set()
        self.allowed_paths=set()
        #self.log.debug('Blacklist initialized with the following patterns %s', format_to_log(escaped))


    def _unify_escaped(self, escaped):
        """
        Generate one big regex usign given expressions

        Generate one regex, unifying all given expressions,
        in the following format ^( reg1 | reg2 | .... | regN)$

        @param escaped: a list of escaped regular expressions
        """
        escaped = filter(lambda e: e is not None, escaped)
        if len(escaped) == 0: return None

        expr ='^(%s)$' % '|'.join(escaped)
        return expr

    def _unify_files(self, files):
        if len(files) == 0: return None

        escaped = map(self._escape_expression, files)
        expr = '(.*/)?(%s)' % '|'.join(escaped)
        return expr

    def _unify_contains(self, contains):
        if len(contains) == 0: return None

        escaped = map(self._escape_expression, contains)
        expr = '.*(%s).*' % '|'.join(escaped)
        return expr

    def _unify_dirs(self, dirs):
        if len(dirs) == 0: return None
        escaped = map(self._escape_expression, dirs)

        expr = '(%s)' % '|'.join(escaped)
        return expr

    def _unify_extentions(self, extentions):
        if len(extentions) == 0: return None

        escaped = map(self._escape_expression, extentions)
        expr = '(.*/)?[^/]+\.(%s)' % '|'.join(escaped)
        return expr

    def get_hash(self):
        '''
        Returns hex hash representing the blacklist pattern set
        '''
        return hashlib.md5(pickle.dumps(self._blacklist)).hexdigest()

    def _check_match(self, pattern, pathname):
        return pattern.match(pathname) is not None

    def is_blacklisted(self, pathname):
        '''
        Returns true if pathname is blacklisted, false otherwise

        @param pathname string or unicode pathname
        '''
#        self.log.debug('Checking if pathname %s is in blacklist %s',
#                        format_to_log(pathname),
#                        format_to_log(self._blacklist)
#                        )



        if pathname in self.blacklisted_path:
            return True
        if pathname in self.allowed_paths:
            return False
        
        matches = map(lambda p: self._check_match(p, pathname),self._blacklist)

        if reduce(lambda x, y: x or y, matches, False):
            self.blacklisted_path.add(pathname)
            return True
        else:
            self.allowed_paths.add(pathname)
            return False

    def _add_expressions(self, expressions=[]):
        '''
        Gets a list of expression and add them to the blacklist
        escaping all character except the *

        @param expressions: a list of string expressions
        '''
        escaped = map(lambda expr: self._escape_expression(expr), expressions)
#        self.log.debug('Adding following pattern to blacklist %s',
#                    format_to_log(escaped)
#                        )
        self._blacklist.update(set(escaped))

    def _escape_expression(self, expression):
        '''
        Gets the expressions and return the unicode escaped version of it
        '''
        return re.escape(unicode(expression)).replace('\\*','.*')

if __name__ == '__main__':
    mainlogger = logging.getLogger('FR')
    mainlogger.setLevel(logging.DEBUG)
    logging.basicConfig()
    bl = Blacklist(['p*'])
    print bl.is_blacklisted(u'asdfpdfasdf')
    bl._add_expressions(['*p?*'])
    print bl.is_blacklisted('asdfp?dfasdf')
    print bl.is_blacklisted('asdfp?dfasdf')

########NEW FILE########
__FILENAME__ = blacklisted_expressions
# -*- coding: utf-8 -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the blacklisted_expressions module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

BLACKLISTED_DIRS = [
    '.FileRock/*',
    '.filerock/*',
]


BLACKLISTED_FILES = [
".DS_Store",
".directory",
".fuse_hidden*",
"~$*.docx",
"~$*.dotx",
"~$*.potx",
"~$*.ppsx",
"~$*.pptx",
"~$*.sldx",
"~$*.thmx",
"~$*.vdx",
"~$*.vsx",
"~$*.vtx",
"~$*.xlsx",
"~$*.xltx"
]

CONTAINS_PATTERN = [
"\n",
"\n\r",
"\r",
"\r\n"
]

EXTENTIONS = [
u"###",
u"#$#",
u"#&7",
u"$$$",
u"$db",
u"$ed",
u"$vm",
u"(d)",
u")2(",
u"---",
u"000",
u"001",
u"002",
u"00a",
u"4sh",
u"4sw",
u"@@1",
u"@@2",
u"BridgeCacheT",
u"InstallState",
u"TemporaryItems",
u"_501",
u"a$v",
u"abc",
u"adblock",
u"adm",
u"als",
u"alt",
u"aso",
u"asx",
u"bak",
u"bde",
u"bdi",
u"bdm",
u"blk",
u"bmb",
u"bmc",
u"bom",
u"box",
u"bsd",
u"bsi",
u"bu",
u"buf",
u"bv1",
u"bv2",
u"bv3",
u"bv4",
u"bv5",
u"bv6",
u"bv7",
u"bv8",
u"bv9",
u"cache",
u"cache-2",
u"cah",
u"cdt",
u"chk",
u"chkn",
u"ci",
u"clp",
u"cnv",
u"compo",
u"crdownload",
u"csac",
u"csstore",
u"dap",
u"db$",
u"dca",
u"ddat",
u"dem",
u"dinfo",
u"dir",
u"dmsk",
u"dov",
u"download",
u"dtapart",
u"dtf",
u"dw3",
u"ers",
u"etl",
u"exd",
u"fb!",
u"fchc",
u"fes",
u"filepart",
u"fts",
u"ger",
u"hax",
u"heu",
u"hmap",
u"hmap.Dir",
u"hrd",
u"identcache",
u"idlk",
u"iff",
u"indexArrays",
u"indexCompactDirectory",
u"indexPositions",
u"init",
u"inprogress",
u"ipe_tempfile",
u"ipl",
u"ipl22",
u"ird",
u"isl",
u"jnk",
u"laccdb",
u"lck",
u"little",
u"lock",
u"lockfile",
u"lrd",
u"lst",
u"m_p",
u"md0",
u"meb",
u"memb",
u"met",
u"mex",
u"moz",
u"mpgindex",
u"mpx",
u"msj",
u"mtx",
u"muf",
u"mx1",
u"mxdl",
u"ncch",
u"nmu",
u"npk",
u"objectcache",
u"onecache",
u"onetmp",
u"part",
u"partial",
u"pat",
u"peb",
u"pet",
u"pfc",
u"pft",
u"phc",
u"pls",
u"pm$",
u"pnf",
u"preview7",
u"pzx",
u"qbi",
u"qbt",
u"qdat",
u"qtindex",
u"r1m",
u"rad",
u"rcv",
u"rdn",
u"reapeaks",
u"ref",
u"rld",
u"rmg",
u"rra",
u"rsc_tmp",
u"rsx",
u"rvs",
u"s",
u"s$$",
u"s2mi",
u"save",
u"sdx",
u"sfk",
u"spc",
u"sqlite3-journal",
u"sss~",
u"stf",
u"svn-work",
u"swd",
u"swp",
u"t44",
u"tb0",
u"temp",
u"thumbdata3--*",
u"tic",
u"tmd",
u"tmp",
u"tmt",
u"tof",
u"tst",
u"tv1",
u"tv2",
u"tv3",
u"tv4",
u"tv5",
u"tv6",
u"tv7",
u"tv8",
u"tv9",
u"u96",
u"vaf",
u"vmc",
u"vmem",
u"vsscc",
u"w44",
u"waf",
u"wa~",
u"wfm",
u"wid",
u"wlx",
u"wsb",
u"wtmp",
u"xp",
u"xps",
u"xps~",
u"xp~",
u"zl",
u"zn~",
u"zoner-index-cache",
u"zoner-rawdata-cache",
u"zsr",
u"~$~",
u"~cr",
u"~nt",
u"¬ß¬ß¬ß",
]
########NEW FILE########
__FILENAME__ = Collector
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Collects all necessary data for the bugreporting.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import platform
import sys
import json
import traceback
import logging
import codecs
import locale
import threading
from filerockclient.updater.UpdaterBase import CURRENT_CLIENT_VERSION
from datetime import datetime


class Collector(object):
    """
    Collects all necessary data for the bugreporting.
    """
# Data to be collected:                                                       #
#                                                                             #
# Username                                                                    #
# Client ID                                                                   #
# Timestamp                                                                   #
# Client Machine OS                                                           #
# Client Machine hardware details (i.e., CPU & RAM, tot & used)               #
# Client Version (and build number)                                           #
# Client Stacktrace (on crash)                                                #
# Client State (from state machine)                                           #
# Client obtained proofs (if any)                                             #
# Client last basis                                                           #
# Client configuration                                                        #
# Used Server IP                                                              #

    def __init__(self,
                 application,
                 cfg,
                 loggerManager,
                 restart_count,
                 command_queue,
                 command_line_args,
                 main_script):

        """
        @param application:
            Instance of filerockclient.internal_facade.InternalFacade
        @param cfg:
            Instance of filerockclient.config.ConfigManager.
        @param loggerManager:
            Instance of filerockclient.logging_helper.LoggerManager.
        @param restart_count:
            How many times the application has been
            recently restarted (usually due to errors).
        @param command_queue:
            Instance of Queue.Queue. The command queue of
            Application will be given to the bug reporter so
            that it could restart the application on errors.
        @param command_line_args:
            List of arguments which the client has been invoked with
        @param main_script:
            Filename of the main Python script (usually
            "FileRock.py").
        """

        self.data = dict()
        self.details = dict()
        self.data['details'] = self.details
        self.app = application
        self.cfg = cfg
        self.restart_count = restart_count
        self._command_queue = command_queue
        self.command_line_args = command_line_args
        self.main_script = main_script
        self.loggerManager = loggerManager
        self.senders = []
        self.exception_info = None
        self.logger = logging.getLogger("FR." + self.__class__.__name__)
        self.access = threading.Lock()

    def on_exception(self, exc_type, value, tb):
        """
        Method to use as sys.excepthook

        @param exc_type: exception type
        @param value: exception value
        @param tb: exception traceback
        """
        if self.access.acquire(False) is False:
            self.logger.debug(
                u'Bug reporting is already in act, ignoring exception: %s'
                % traceback.format_exception(exc_type, value, tb))
            return
        self._collect_info_and_send_report(exc_type, value, tb)
        self._command_queue.put('HARD_RESET')

    def _collect_info_and_send_report(self, exc_type, value, tb):
        """
        Fetches all useful informations from client
        and sends them to the server

        @param exc_type: exception type
        @param value: exception value
        @param tb: exception traceback

        """
        self.logger.critical(u'A critical error has been detected and will' +
            ' be automatically reported to the FileRock development team.' +
            ' Please wait...')

        self.data['local_time'] = datetime.now().ctime()
        self.data['utc_time'] = datetime.utcnow().ctime()
        self.data['version'] = CURRENT_CLIENT_VERSION

        # EnvironmentError exceptions come from outside Python, i.e. from the
        # operating system. Sadly, the embedded error message is in the
        # system language and it's encoded with the system encoding. For example,
        # on the Italian version of Windows we get messages in Italian
        # and encoded in cp1252. We want all exceptions to be unicode instead.
        if isinstance(value, EnvironmentError) and isinstance(value.strerror, str):
            msg = value.strerror
            try:
                msg = unicode(msg, locale.getdefaultlocale()[1])
            except UnicodeDecodeError:
                msg = unicode(msg, 'ASCII', 'replace')
            value.strerror = msg

        self.exception_info = [exc_type, value, tb]
        self._add_exc_info(traceback.format_exception(exc_type, value, tb))
        self._collect_information()
        self.logger.debug(
            u'Reporting uncaught exception: %s' % self.details['exc_info'])
        self.send()
        self.logger.critical(u'Error reporting done. Thank you.')

    def _add_platform(self):
        """
        Collects all platform's data
        """

        self.details["platform"]={
            "system": platform.system(),
            "node": platform.node(),
            "release": platform.release(),
            "version": platform.version(),
            "machine": platform.machine(),
            "processor": platform.processor()
        }

    def _add_python(self):
        """
        Collects all python interpreter's data
        """
        self.details["python"]={
            "branch": platform.python_branch(),
            "build": platform.python_build(),
            "compiler": platform.python_compiler(),
            "implementation": platform.python_implementation(),
            "revision": platform.python_revision(),
            "version": platform.python_version()
        }

    def _add_platform_dependent(self):
        """
        Collects all platform dependent data
        """
        if sys.platform.startswith('win'):
#            platform.win32_ver(release='', version='', csd='', ptype='')
            pass
        elif sys.platform.startswith('darwin'):
#            platform.mac_ver(release='', versioninfo=('', '', ''), machine='')
            pass
        elif sys.platform.startswith('linux'):
#            platform.linux_distribution(distname='', version='', id='', supported_dists=('SuSE', 'debian', 'redhat', 'mandrake', ...), full_distribution_name=1)
            pass

    def _add_exc_info(self, rawreport):
        self.details['exc_info'] = "".join(rawreport)

    def _add_configuration(self):
        """
        Adds dictionary representation of configuration
        """
        self.details['configuration'] = {}
        try:
            config = self.cfg.to_dict()
            self.details['configuration'] = config
        except Exception:
            self.details['configuration']['Error_On_Collect'] = traceback.format_exc()

    def _add_server_session_info(self):
        """
        Collects session's data
        """
        data = {}
        self.details['session'] = data
        try:
            server_session = self.app.server_session
            data['client_id'] = server_session.client_id
            data['server_hostname'] = server_session.host
            data['server_port'] = server_session.port
            data['basis'] = server_session.get_current_basis()
            data['session_id'] = server_session.session_id
        except Exception:
            data['Error_On_Collect'] = traceback.format_exc()

    def _add_application_info(self):
        """
        Collects application's data
        """
        data = {}
        self.details['application'] = data
        try:
            data['cmdline_args'] = self.command_line_args
            data['status'] = self.app.status
        except Exception:
            data['Error_On_Collect'] = traceback.format_exc()

    def _add_logs(self):
        """
        Collects log data
        """
        data = {}
        self.data['logs'] = data
        try:
            filename = self.loggerManager._get_log_filename()
            with codecs.open(filename) as fp:
                data['0'] = fp.read()
        except Exception:
            data['Error_On_Collect'] = traceback.format_exc()

    def _collect_information(self):
        """
        Collects all useful informations
        """
        self._add_platform()
        if self.cfg:
            self._add_configuration()
        if self.app:
            self._add_application_info()
            self._add_server_session_info()
        if self.loggerManager:
            self._add_logs()

    def add_sender(self, sender):
        """
        Adds a Sender to the collector

        Senders should implement a send method who accept a data object
        """
        self.senders.append(sender)

    def to_json(self):
        """
        Returns collected data in json format
        """
        return json.dumps(self.data, encoding='utf8')

    def send(self):
        """
        Tries to call all the send method from associated senders,
        passing them the collected data.
        """
#        json = self.to_json()
        for sender in self.senders:
            try:
                sender.send(self.data)
            except Exception as e:
                self.logger.exception(u'Exception on sending: %s' % e)


if __name__ == "__main__":
    pass

########NEW FILE########
__FILENAME__ = DevelopCollector
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the DevelopCollector module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.bugreporter.Collector import Collector


class DevelopCollector(Collector):
    """
    Extends filerock client.bug report.Collector.Collector class,
    overrides send method to not send anything
    """

    def send(self):
        self.logger.info(self.details['exc_info'])
        self.logger.info(
            u'Error reporting in developer mode,' +
            ' no data will be actually sent...')

if __name__ == "__main__":
    pass
########NEW FILE########
__FILENAME__ = HTTPSSender
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the HTTPSSender module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import httplib
import json
import contextlib
import zlib


class HTTPSSender(object):
    '''
    Sends the bug report via POST request
    '''

    def __init__(self, host="127.0.0.1", port="443", url="client_report"):
        """
        Initialize the sender

        @param host: the host
        @param port: the port
        @param url: the resource
        """
        self.host = host
        self.port = port
        self.url = '/' + url

    def to_json(self, data):
        """
        Returns data in json format

        @param data: data to dumps
        """
        return json.dumps(data, encoding='utf8')

    def send(self, data):
        """
        Compress the data with zlib and
        sends them with a post to self.host host on self.port port
        """
        report = self.to_json(data)
        compressed_report = zlib.compress(report)
        headers = {'Content-Type': 'application/x-gzip'}
        with contextlib.closing(httplib.HTTPSConnection(self.host, self.port, timeout=20)) as connection:
            connection.request('POST', self.url, compressed_report, headers)
            response = connection.getresponse()

if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = logger_sender
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the logger_sender module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging

class LoggerSender(object):
    def __init__(self):
        self.logger = logging.getLogger("FR."+self.__class__.__name__)

    def send(self, report):
        self.logger.info(report['details']['exc_info'])
########NEW FILE########
__FILENAME__ = config
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Container for the application settings.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import ConfigParser
import codecs
import os
import logging
import sys

from filerockclient import APPLICATION_NAME
from filerockclient.exceptions import FileRockException


SYSTEM_SECTION = u"System"
USER_SECTION = u"User"
CLIENT_SECTION = u"Client"
USER_DEFINED_OPTIONS = u"User Defined Options"
APPLICATION_PATHS = u"Application Paths"

APPNAME = u"filerock"
CONFIG_FILE_NAME = u"config.ini"
CURRENT_CONFIG_VERSION = 13
BLACKLISTED_DIR = ".FileRockTemp"

PROXY_PORT = '443'

# You can use %(field_name)s in the config values, where field_name
# is the name of any field in the configuration file. It will be
# automatically interpolated. Please note that it exists "config_dir"
# as a default field.
DEFAULT_CONFIG = {
    u"System": {
        u'config_version': u'%s' % CURRENT_CONFIG_VERSION,
        u'server_hostname': u'serv1.filerock.com',
        u'server_port': u'23425',
        u'linking_hostname': u'registration.filerock.com',
        u'linking_port': u'23000',
        u'storage_endpoint': u'seewebstorage.it',
        u'refused_declare_max': u'5',
        u'refused_declare_waiting_time': u'5'
    },
    u"User": {
        u'username': u'',
        u'client_id': u'',
        u'encryption_key': u''
    },
    u"Client": {
        u'commit_threshold_seconds': u'10',
        u'commit_threshold_operations': u'10',
        u'commit_threshold_bytes': u'52428800'  # 50 MB
    },
    u"User Defined Options": {
        u'on_tray_click': u'panel',
        u'osx_label_shellext': u'False',
        u'auto_update': u'False',
        u'launch_on_startup': u'True',
        u'show_slideshow': u'False',
        u'proxy_usage': u'False',
        u'proxy_type': u'SOCKS5',
        u'proxy_host': u'',
        u'proxy_port': u'1080',
        u'proxy_rdns': u'True',
        u'proxy_username': u'',
        u'proxy_password': u'',
        u'bandwidth_limit_upload': u'0',
        u'bandwidth_limit_download': u'0'
    },
    u"Application Paths": {
        u'data_dir': u'<AUTO-DISCOVERY>',
        u'icons_dir': u'%(data_dir)s/icons',
        u'images_dir': u'%(data_dir)s/images',
        u'ssl_cert_dir': u'%(data_dir)s/ssl_certs',
        u'locale_dir': u'<AUTO-DISCOVERY>',
        u'server_certificate': u'%(ssl_cert_dir)s/server2ca_chain.pem',
        u'linking_certificate': u'%(ssl_cert_dir)s/server2ca_chain.pem',
        u'webserver_ca_chain': u'%(ssl_cert_dir)s/update_server_ca_certs.pem',
        u'warebox_path': u'<AUTO-DISCOVERY>',
        u'client_priv_key_file': u'%(config_dir)s/private_key.pem',
        u'temp_dir': os.path.join(u'%(warebox_path)s', BLACKLISTED_DIR),
        u'caches_dir': u'%(config_dir)s/caches',
        u'storage_cache_db': u'%(caches_dir)s/storage_cache.db',
        u'transaction_cache_db': u'%(caches_dir)s/transaction_cache.db',
        u'warebox_cache_db': u'%(caches_dir)s/warebox_cache.db',
        u'metadatadb': u'%(config_dir)s/metadata.db',
        u'hashesdb': u'%(config_dir)s/hasheshistory.db'
    }
}


DONT_OVERWRITE_ON_MERGE = [
    ('User', 'username'),
    ('User', 'client_id'),
    ('User', 'encryption_key'),
    ('User Defined Options', '*'),
    ('Application Paths', '*')
    #('System', 'server_hostname'),
    #('System', 'linking_hostname')
]


DONT_DELETE_ON_MERGE = [
    ('*', 'config_dir')
]


def _find_config_dir(appname=APPNAME):
    """
    Returns different config path depending on OS.

    On Windows 7/2008 configuration dir will be %LOCALAPPDATA%/appname/
    On Windows XP configuration dir will be %APPDATA%/appname/
    On Linux and other UnixLike systems configdir will be ~/.appname
    """
    if sys.platform.startswith('win'):
        # %APPDATA%
        #   WinXP => C:\Documents and Settings\{username}\Application Data
        #   Win7/2008 => C:\Users\{username}\AppData\Roaming
        # %LOCALAPPDATA%
        #   WinXP => N/A (but can be manually added:
        #       LOCALAPPDATA=%USERPROFILE%\Local Settings\Application Data)
        #   Win7/2008 => C:\Users\{username}\AppData\Local
        try:
            appdata = os.path.join(os.environ['LOCALAPPDATA'], appname)
        except KeyError:
            appdata = os.path.join(os.environ['APPDATA'], appname)
    elif sys.platform.startswith('linux') or sys.platform.startswith('darwin'):
        appdata = os.path.expanduser(os.path.join("~", "." + appname))
    else:
        appdata = os.path.expanduser(os.path.join("~", "." + appname))

    return appdata


def _find_warebox_dir():
    warebox_path = os.path.join(u"~", u"FileRock")
    return os.path.normpath(os.path.expanduser(warebox_path))


def _find_data_dir():

    try:
        # Try to detect the directory that contains our code
        code_path = os.path.dirname(__file__)
        package_code_path = os.path.dirname(code_path)
    except NameError:
        # __file__ may be undefined in frozen applications
        code_path = u''
        package_code_path = u''

    candidate_paths = [

        # Look for a data dir that is local to the running script.
        # sys.path[0] is the directory containing the script
        # that was used to invoke the Python interpreter, when the
        # application is run from sources.
        # This matches when FileRock is directly run from a cloned GIT
        # repository.
        # Note: for a frozen application sys.path[0] is:
        #   py2exe: the bundled library.zip archive (yes, really!)
        #   py2app: (TO BE DONE)
        #   cx_Freeze: (TO BE DONE)
        os.path.join(sys.path[0], u'data'),

        # Look for a data dir inside the directory that contains the
        # "filerockclient" package.
        os.path.join(package_code_path, u'data'),

        # Look just inside the "filerockclient" package directory. Some
        # installation may put the application data along with the code.
        os.path.join(code_path, u'data'),

        # Look in the standard path used by distutils to install stuff.
        # This is the case when the application has been installed through
        # our setup.py script by the user. "sys.prefix" is "a string giving the
        # site-specific directory prefix where the platform independent Python
        # files are installed".
        # When the application is run from sources, it is something like:
        #   Linux: /usr/local (not on Debian/Ubuntu)
        #   Windows: C:\Python27
        #   OSX: /Library/Frameworks/Python.framework/Versions/2.7
        # For a frozen application, sys.prefix is:
        #   py2exe: the directory containing the packaged executable
        #   py2app: (TO BE DONE)
        #   cx_Freeze: (TO BE DONE)
        os.path.join(sys.prefix, u'share', APPLICATION_NAME, u'data'),

        # On Debian/Ubuntu using sys.prefix for searching the data is not
        # reliable. In fact, they have modified Python so to have a "/usr"
        # prefix, although the data of applications installed by the user still
        # goes into "/usr/local".
        os.path.join(u'/usr/local/share', APPLICATION_NAME, 'data'),

        # The official Debian/Ubuntu package installs data into /usr/share
        os.path.join(u'/usr/share', APPLICATION_NAME, 'data'),

        # Special case for the Windows binaries frozen with py2exe: look into
        # the directory containing the executable.
        os.path.join(sys.prefix, u'data')
    ]

    for path in candidate_paths:
        if os.path.isdir(path):
            return path
    raise ConfigException(
            u'Could not find an existing data dir among: %s' % candidate_paths)


def _find_locale_dir():
    data_dir = _find_data_dir()
    locale_dir = os.path.join(data_dir, 'locale')
    if os.path.isdir(locale_dir):
        # Detected a locale dir into the data dir.
        # Remember that gettext will look for a pathname like:
        #   <data_dir>/locale/en_US/LC_MESSAGES/filerock-client.mo
        # See gettext's documentation for details.
        return locale_dir
    else:
        # An empty string makes gettext look for language files into some
        # standard location. E.g.:
        #   /usr/share/locale/en_US/LC_MESSAGES/filerock-client.mo
        # See gettext's documentation for details.
        return ''


AUTO_DISCOVERY = {
    ('Application Paths', 'warebox_path'): _find_warebox_dir,
    ('Application Paths', 'data_dir'): _find_data_dir,
    ('Application Paths', 'locale_dir'): _find_locale_dir
}


class ConfigFileNotFoundException(FileRockException):
    pass


class ConfigException(FileRockException):
    pass


class ConfigManager(ConfigParser.SafeConfigParser):
    """Container for the application settings.

    If a custom configdir path is passed the module tries to load the
    file, it raises an Exception if the file don't exists. Otherwise, if
    no file_path is provided, an "OS dependent" config path is defined
    and the module tries to load the content of this path, if no file is
    found the module loads a default config.
    """

    def __init__(self, custom_conf_dir=None):
        if custom_conf_dir is not None:
            config_dir = custom_conf_dir
            config_dir = os.path.expanduser(config_dir)
            if os.path.exists(config_dir) and not os.path.isdir(config_dir):
                raise ConfigException('Argument must be a directory')
            self.custom = True
        else:
            config_dir = _find_config_dir(APPNAME)
            self.custom = False

        config_dir = os.path.normpath(os.path.abspath(config_dir))

        DEFAULTS = {'config_dir': config_dir}
        ConfigParser.SafeConfigParser.__init__(self, DEFAULTS)

        self.config_dir = config_dir
        self.file_path = os.path.join(self.config_dir, CONFIG_FILE_NAME)
        self.logger = logging.getLogger("FR.%s" % self.__class__.__name__)
        self._was_auto_discovered = {}

    def _port_for_proxy(self, section, option):
        return (section == SYSTEM_SECTION
                    and (option == u'server_port' or option == u'linking_port')
                    and self.getboolean(USER_DEFINED_OPTIONS, u'proxy_usage'))

    def get(self, section, option, raw=False, vars=None):
        """
        Overrides the class get method, returns PROXY_PORT if server_port
        or linking_port are asked and proxy support is enabled.

        Note: all getX() methods are affected by this override.
        """
        if self._port_for_proxy(section, option):
            return PROXY_PORT
        return ConfigParser.SafeConfigParser.get(
                                    self, section, option, raw=raw, vars=vars)

    def get_config_dir(self):
        """
        Returns client config dir, recreates it if not exists
        """
        if not os.path.exists(self.config_dir):
            os.makedirs(self.config_dir)
            self.logger.debug(u'Created config directory %r' % self.config_dir)
        return self.config_dir

    def load(self):
        """
        if self.file_path exists
            Loads the configuration from file
        else if a custom file_path was passed
            raise and exception
        else loads the default config and write it to file
        """
        self.logger.debug(u'Loading configuration from %r' % self.file_path)
        try:
            self._read_from_file()
        except IOError:
            self.logger.warning(u'No configuration file found')
            if self.custom:
                raise ConfigFileNotFoundException
            self._load_defaults()
            self.write_to_file()

        try:
            version = self.getint('System', 'config_version')
        except ConfigParser.NoOptionError:
            self.logger.warning(u"The config file doesn't have a version"
                                " number, assuming version 0.")
            version = 0

        if version != CURRENT_CONFIG_VERSION:
            self.logger.warning(u"The config file is obsolete, will be updated")
            # TODO: remove this at the next transition update
            self._patch_transition_from_release_0_4_0()
            self._merge_with_default_configuration()
            self.write_to_file()

        self._parse_auto_discovery_options()
        self._try_create_dirs()
        return self

    def _read_from_file(self):
        """
        Reads the configuration from the file.
        """
        self.logger.debug(u'Reading configuration from %s' % self.file_path)
        with codecs.open(self.file_path, encoding='utf-8_sig') as fp:
            self.readfp(fp)
        if self.config_dir != self.get('DEFAULT', 'config_dir'):
            self.logger.error('Wrong config_dir param in config file, should '
                'be:\n   [DEFAULT]\n   config_dir = %s' % (self.config_dir))
            raise ConfigException('Wrong config dir in config file')

    def _parse_auto_discovery_options(self):
        self._was_auto_discovered.clear()
        for section in self.sections():
            for option, value in self.items(section):
                if value == '<AUTO-DISCOVERY>' \
                and (section, option) in AUTO_DISCOVERY:
                    function = AUTO_DISCOVERY[(section, option)]
                    discovered_value = function()
                    self.set(section, option, discovered_value)
                    self._was_auto_discovered[(section, option)] = True

    def set(self, section, option, value=None):
        ConfigParser.SafeConfigParser.set(self, section, option, value)
        try:
            del self._was_auto_discovered[(section, option)]
        except KeyError:
            pass

    def _merge_with_default_configuration(self):
        """
        Merges the existing configuration file with the new DEFAULT_CONFIG.

        Add a tuple as (section, options) to the DONT_DELETE_ON_MERGE array,
        if you want deny the deletion of a option

        Add a tuple as (section, options) to the DONT_OVERWRITE_ON_MERGE array,
        if you want deny the overwriting of a option
        """
        # Remove obsolete options
        for section in self.sections():
            # Obsolete sections are deleted,
            # unless sect.* is in DONT_DELETE_ON_MERGE
            if (section, '*') in DONT_DELETE_ON_MERGE:
                continue
            if section not in DEFAULT_CONFIG:
                self.remove_section(section)
                continue
            for option, value in self.items(section):
                # Option is kept if (sect, opt) or (*, opt)
                # is in DONT_DELETE_ON_MERGE
                if (section, option) in DONT_DELETE_ON_MERGE:
                    continue
                if ('*', option) in DONT_DELETE_ON_MERGE:
                    continue
                # All filters are passed. Delete the option if it's obsolete
                if option not in DEFAULT_CONFIG[section]:
                    self.remove_option(section, option)

        # Update current options
        for section in DEFAULT_CONFIG.keys():

            if not self.has_section(section):
                self.add_section(section)
            for option, value in DEFAULT_CONFIG[section].iteritems():
                if self.has_option(section, option):
                    # Option is not updated if it or its containing section
                    # are in DONT_OVERWRITE_ON_MERGE
                    if (section, option) in DONT_OVERWRITE_ON_MERGE:
                        continue
                    if ('*', option) in DONT_OVERWRITE_ON_MERGE:
                        continue
                    if (section, '*') in DONT_OVERWRITE_ON_MERGE:
                        continue

                # All filters are passed. Update the option value.
                self.set(section, option, value)

    def _try_create_dirs(self):
        """
        Creates all the necessary dirs into the config dir
        """
        # TODO: I don't think this should be done here
        dirs = [
            self.get('Application Paths', 'caches_dir')
        ]
        for directory in dirs:
            if not os.path.exists(directory):
                os.makedirs(directory)

    def _try_create_backup(self):
        """
        Creates a backup of existent configuration, appending a ~
        character to it
        """
        if os.path.exists(self.file_path):
            backup_filename = self.file_path + '~'
            if os.path.exists(backup_filename):
                try:
                    os.unlink(backup_filename)
                except Exception as e:
                    self.logger.error(u'Error on removing an older '
                        'configuration backup: %r. ' % e +
                        'File %r will be overwritten' % self.file_path)
            try:
                os.rename(self.file_path, backup_filename)
            except Exception as e:
                self.logger.debug(u'Error on creating a configuration backup: '
                    '%r. File %r will be overwritten.' % (e, self.file_path))

    def write_to_file(self):
        """
        Writes the configuration setting to disk.
        """
        self.logger.debug(u'Writing configuration\n%s\nto %s'
                          % (self, self.file_path))
        self._try_create_dirs()
        self._try_create_backup()
        with codecs.open(self.file_path, "w", encoding='utf-8_sig') as fp:
            self.write(fp)

    def write(self, fp):
        """Write an .ini-format representation of the configuration state.

        This overwrites ConfigParser's original write() method, which
        doesn't handle languages different from English and platforms
        different from Unix. Damn ConfigParser.
        """
        if self._defaults:
            DEFAULTSECT = ConfigParser.DEFAULTSECT
            fp.write("[%s]\n" % DEFAULTSECT)
            for (key, value) in self._defaults.items():
                if (DEFAULTSECT, key) in self._was_auto_discovered:
                    value = '<AUTO-DISCOVERY>'
                value = value.replace(os.linesep, '%s\t' % os.linesep)
                fp.write("%s = %s%s" % (key, value, os.linesep))
            fp.write(os.linesep)
        for section in self._sections:
            fp.write("[%s]%s" % (section, os.linesep))
            for (key, value) in self._sections[section].items():
                if key == "__name__":
                    continue
                if (section, key) in self._was_auto_discovered:
                    value = '<AUTO-DISCOVERY>'
                if (value is not None) or (self._optcre == self.OPTCRE):
                    value = value.replace(os.linesep, '%s\t' % os.linesep)
                    key = " = ".join((key, value))
                fp.write("%s%s" % (key, os.linesep))
            fp.write(os.linesep)

    def _load_defaults(self):
        """
        Loads the default configuration.
        """
        self.logger.debug(u'Loading default configuration')
        for section in DEFAULT_CONFIG:
            self.add_section(section)
            for option, value in DEFAULT_CONFIG[section].iteritems():
                self.set(section, option, value)

    def __getstate__(self):
        """Called on pickling. Removes the non-picklable attributes."""
        state = self.__dict__.copy()
        state['logger'] = None
        return state

    def __setstate__(self, state):
        """Called on unpickling. Restores the non-picklable attributes"""
        self.__dict__ = state
        self.logger = logging.getLogger("FR." + self.__class__.__name__)

    def __str__(self):
        """Create a string representation of the config"""
        result = u""
        for section in self.sections():
            result += u"[%s]\n" % section
            for key, value in self.items(section):
                if key != u'encryption_key':
                    result += u"  %s: %s\n" % (key, value)
        return unicode(result)

    def to_dict(self):
        """
        returns a dictionary representation of config in the form
        {
            section: {
                option: value
                option1: value1
            }
            section1: {
                option2: value2
                option3: value3
            }
        }
        """
        result = {}
        for section in self.sections():
            result[section] = {}
            for option, value in self.items(section):
                if option != u'encryption_key':
                    result[section][option] = value
        return result

    def from_dict(self, cfg):
        """
        Gets a dictionary as parameter in the form
        {
            section: {
                option: value
                option1: value1
            }
            section1: {
                option2: value2
                option3: value3
            }
        }

        No existing sections/options will be created,
        On the existing one the value will be overwrited

        Note: The configuration will be NOT persisted on file,
        you should use write_to_file method to do that
        """
        for section in cfg:
            if section not in self.sections():
                self.add_section(section)
            for option in cfg[section]:
                value = cfg[section][option]
                self.set(section, option, value)

    def _patch_transition_from_release_0_4_0(self):
        """Patch that handles a critical change in the configuration
        file format.

        After release 0.4.0 we moved all pathnames to the new
        "Application Paths" section of the configuration file. This
        patch keeps any previous modification done to warebox_path,
        which is very likely to have been changed by the user).

        To be removed as soon as all clients are updated.
        """
        if not self.has_section('Application Paths'):
            self.add_section('Application Paths')

        if self.has_option('User', 'warebox_path'):
            value = self.get('User', 'warebox_path', raw=True)
            self.set('Application Paths', 'warebox_path', value)


if __name__ == "__main__":
    pass

########NEW FILE########
__FILENAME__ = constants
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Definition of global static constants used by the application.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

# Remember not to put here anything that needs to be set from outside
# or that needs to be overridable by configuration - use the config module
# for that.

import sys
import os
import platform

try:
    # The "build_specs" module is automatically generated (and deleted)
    # by the build/deploy scripts; its existence tells us we are running
    # an installed instance of the client (that is, not directly from
    # sources).
    # Known ways to get an installed application:
    #   - You have downloaded a frozen bundle from our website
    #   - You have installed through the setup.py script
    #   - You have installed through your OS package manager
    #     (@Maintainers: yes, it's you).
    import filerockclient.build_specs
    RUNNING_INSTALLED = True
except ImportError:
    RUNNING_INSTALLED = False

try:
    # The build_specs module, if present, must specify the current version
    from filerockclient.build_specs import VERSION
except ImportError:
    VERSION = 'trunk'

# @Maintainers: remember that FileRock Client is able to restart itself.
# It usually auto-detects all needed values, however you can force
# in the filerockclient.build_specs module the following (optional) values:
#   EXECUTABLE_PATH, COMMAND_LINE_ARGUMENTS.
try:
    # This should be a string, representing the executable to launch the client
    from filerockclient.build_specs import EXECUTABLE_PATH
except ImportError:
    EXECUTABLE_PATH = None

try:
    # This should be a list of string, representing command line arguments
    from filerockclient.build_specs import COMMAND_LINE_ARGUMENTS
except ImportError:
    COMMAND_LINE_ARGUMENTS = None


# Please set both EXECUTABLE_PATH and COMMAND_LINE_ARGUMENTS or none of them
assert (EXECUTABLE_PATH is None and COMMAND_LINE_ARGUMENTS is None) or \
       (EXECUTABLE_PATH is not None and COMMAND_LINE_ARGUMENTS is not None)

RUNNING_FROM_SOURCE = not hasattr(sys, 'frozen')
IS_WINDOWS = sys.platform.startswith('win')
IS_LINUX = sys.platform.startswith('linux')
IS_DARWIN = sys.platform.startswith('darwin')
IS_64BITS = sys.maxsize > 2 ** 32
IS_PYTHON_27 = (platform.python_version_tuple()[0:2] == ('2', '7'))


def get_command_line():
    """Return the command line which the application has been invoked
    with, as a list of strings.

    The result can be used with the os.exec* functions.
    """

    def get_commandline_args():
        """Nested function. Returns the list of command line arguments
        which the client has been invoked with.

        The first argument is the main script name, if the application is
        run from sources (that is, through the Python interpreter).

        This function returns only the params used to start the client, thus
        the executable name is stripped away if present. It's automatically
        removed by the Python interpreter when the application is run from
        sources, but usually it is still present (as sys.argv[0]) when the
        application is run as a frozen executable; the only exception to
        this rule is py2app (OSX), which keeps the script name as the first
        argument (just like the interpreter does). We remove it for the sake
        of uniformity.
        """

        if COMMAND_LINE_ARGUMENTS is not None:
            return COMMAND_LINE_ARGUMENTS

        if RUNNING_FROM_SOURCE:
            # let everything pass
            return sys.argv[:]
        else:
            # strip the first argument (python script)
            return sys.argv[1:]

    def get_executable_path():
        """Nested function. Returns the absolute filesystem path of the
        executable launched to run the client.

        It's the Python interpreter when the application is run from
        sources, while it's the binary executable for a frozen application.
        """

        if EXECUTABLE_PATH is not None:
            return EXECUTABLE_PATH

        if IS_WINDOWS or IS_LINUX:
            # sys.executable is correctly set in both source and frozen modes
            return sys.executable

        elif IS_DARWIN:
            if RUNNING_FROM_SOURCE:
                # It's /path/to/python/interpreter
                return sys.executable
            else:
                # Return "/path/to/.app/Contents/MacOS/FileRock".
                # Actually py2app sets sys.executable to
                # the bundled python interpreter; the real frozen
                # binary is contained within the same directory.
                return os.path.join(
                    os.path.dirname(sys.executable),
                    "FileRock"
                )

    # Produce the final command line
    if IS_DARWIN and RUNNING_FROM_SOURCE:
        # On OSX most distributions of Python are universal binaries,containing
        # both the 32bit and 64bit executables. The default is 64bit and thus
        # we need to force the 32bit version of the interpreter, due to the
        # lack of a 64bit distribution of wxPython for OSX.
        cmdline = ['/usr/bin/env', 'arch', '-i386', get_executable_path()]
        cmdline += get_commandline_args()
    else:
        cmdline = [get_executable_path()] + get_commandline_args()

    return cmdline


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = core
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
The main class of FileRock client.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
import sys
import platform

from filerockclient.databases.metadata import MetadataDB
from filerockclient.databases.hashes import HashesDB
from filerockclient.events_queue import EventsQueue
from filerockclient.storage_connector import StorageConnector
from filerockclient.warebox import Warebox
from filerockclient.constants import RUNNING_FROM_SOURCE, RUNNING_INSTALLED
from filerockclient.serversession.server_session import ServerSession
from filerockclient.databases.storage_cache import StorageCache
from filerockclient.serversession.startup_synchronization import \
    StartupSynchronization
from filerockclient.linker import Linker
from filerockclient.updater.UpdaterBase import PlatformUpdater
from filerockclient.exceptions import UpdateRequestedException
from filerockclient.exceptions import UnsupportedPlatformException
from filerockclient.exceptions import ClientUpdateInfoRetrievingException
from filerockclient.exceptions import LogOutRequiredException
from filerockclient.exceptions import MandatoryUpdateDeniedException
from filerockclient.exceptions import UpdateRequestedFromTrunkClient
import filerockclient.filesystemwatcher as filesystemwatcher
from filerockclient.internal_facade import InternalFacade
from filerockclient.ui.client_facade import ClientFacade
from filerockclient.ui.ui_controller import UIController
from filerockclient.workers.filters.encryption import utils as CryptoUtils
from filerockclient.util.multi_queue import MultiQueue
from filerockclient.util.scheduler import Scheduler
from filerockclient.databases import metadata
from filerockclient import config
from filerockclient.osconfig import OsConfig
from filerockclient.constants import VERSION as CURRENT_CLIENT_VERSION



class Core(object):
    """The main class of FileRock client.

    This is the place where things begin and end. The application
    services are started and terminated through this interface.
    This class creates and registers all other domain components, except
    for user interfaces which are handled elsewhere.
    Performs initial checks at startup and offers a public interface
    for registering UI objects.
    """

    def __init__(self, configManager, startupSlide, show_panel, command_queue,
                 cmdline_args, lockfile_fd, auto_start=True,
                 restart_after_minute=-1):

        """FileRock client initialization.

        Loads and configures all application components.

        @param configManager:
                    Instance of filerockclient.config.configManager
        @param startupSlide:
                    Boolean telling whether the startup slides should
                    be shown.
        @param show_panel:
                    Boolean telling whether the UI should appear to the
                    user after the startup.
        @param command_queue:
                    Instance of Queue.Queue where to put commands for
                    filerockclient.application.Application.
        @param cmdline_args:
                    List of arguments which the client has been invoked with.
        @param lockfile_fd:
                    File descriptor of the lock file which ensures there
                    is only one instance of FileRock Client running.
                    Child processes have to close it to avoid stale locks.
        @param auto_start:
                    Boolean telling whether the client should automatically
                    connect to the server after initialization.
        @param restart_after_minute:
                    Number of minutes after which the application must
                    be restarted. There is no restart to do if it is
                    less than 0.
        """
        self.logger = logging.getLogger("FR")
        self.cfg = configManager
        self.startupSlide = startupSlide
        self.show_panel = show_panel
        self.auto_start = auto_start
        self.cmdline_args = cmdline_args
        self.lockfile_fd = lockfile_fd
        self.restart_after_time = restart_after_minute
        self.sys_config_path = self.cfg.get_config_dir()
        self.temp_dir = self.cfg.get('Application Paths', 'temp_dir')

        self.logger.info(
            u"Hello, this is FileRock client (version %s)"
            % CURRENT_CLIENT_VERSION)
        self.logger.debug(u"python variable __debug__==%r" % __debug__)

        self.logger.debug(u"Initializing Metadata DB...")
        database_file = self.cfg.get('Application Paths', 'metadatadb')
        self._metadata_db = MetadataDB(database_file)
        self._metadata_db_exists_at_start = not self._metadata_db.recreated

        self.logger.debug(u"Initializing InternalFacade...")
        self._internal_facade = InternalFacade(
            self, command_queue, logging.getLogger('FR.InternalFacade'))

        self.logger.debug(u"Initializing UIController...")
        self._ui_controller = UIController(
            self._metadata_db, logging.getLogger('FR.UIController'))

        self.logger.debug(u"Initializing ClientFacade...")
        self._client_facade = ClientFacade(
            self, command_queue, logging.getLogger('FR.ClientFacade'))

        self.logger.debug(u"Initializing zombie ClientFacade...")
        import copy
        self._zombie_client_facade = copy.copy(self._client_facade)
        self._zombie_client_facade._set_zombie()

        self._scheduler = Scheduler()

        self.logger.debug(u"Initializing Hashes DB...")
        hashesdb_file = self.cfg.get('Application Paths', 'hashesdb')
        self.hashesDB = HashesDB(hashesdb_file)

        self.logger.debug(u"Initializing Storage Cache...")
        self.storage_cache = StorageCache(
                    self.cfg.get('Application Paths', 'storage_cache_db'))

        self.logger.debug(u"Initializing Linker...")
        self.linker = Linker(self.cfg, self._ui_controller)

        self.logger.debug(u"Initializing OS settings manager...")
        self.os_settings_manager = OsConfig(
                                        cmdline_args=self.cmdline_args
                                    )

        self._warebox = None
        self.queue = None
        self.connector = None
        self.FSWatcher = None
        self.startup_synchronization = None
        self._server_session = None

    def _get_ready_for_service(self):
        """Perform further initialization.

        Here are initialized those components that need any information
        available at runtime and thus couldn't be initialized by the
        constructor.
        """
        # TODO: do we need this at all?

        self.logger.debug(u"Initializing Warebox...")
        self._warebox = Warebox(self.cfg)

        self.logger.debug(u"Initializing Warebox Cache...")

        session_queue = MultiQueue([
            'servermessage',   # Messages sent by the server
            'operation',       # PathnameOperation objects to handle
            'usercommand',     # Commands sent by the user
            'sessioncommand',  # ServerSession internal use commands
            'systemcommand'    # Commands sent by other client components
        ])

        self.logger.debug(u"Initializing Event Queue...")
        self.queue = EventsQueue(self._internal_facade, session_queue)

        self.logger.debug(u"Initializing Storage Connector...")
        self.connector = StorageConnector(self._warebox, self.cfg)

        self.logger.debug(u"Initializing FileSystem Watcher...")
        self.FSWatcher = filesystemwatcher.watcher_class(self._warebox,
                                                         self.queue,
                                                         start_suspended=True)

        self.logger.debug(u"Initializing Startup Synchronization...")
        self.startup_synchronization = StartupSynchronization(
            self._warebox, self.storage_cache, self.queue)

        self.logger.debug(u"Initializing Server Session...")
        self._server_session = ServerSession(
            self.cfg, self._warebox,
            self.storage_cache, self.startup_synchronization,
            self.FSWatcher, self.linker,
            self._metadata_db, self.hashesDB, self._internal_facade,
            self._ui_controller, self.lockfile_fd, auto_start=self.auto_start,
            input_queue=session_queue, scheduler=self._scheduler)

        self.logger.debug(u"Initialization completed successfully")

    def _clean_env(self):
        """Delete all user meta-data on integrity checks.

        This reproduces the situation where the application has been
        just installed, so it won't bother with integrity checks on the
        user files at next connection. Moreover, local modifications
        will not be detected and every file in the warebox will result
        as "new", getting merged with the content of the storage.
        It's necessary when something has changed in such a way that
        checking integrity or real synchronization are not
        possible (e.g. the user has choosen a different directory to be
        the warebox, some data on integrity have been lost, etc).
        """
        self.logger.debug(u"Cleaning User environment")
        self.storage_cache.clear()
        self._metadata_db.delete_key('trusted_basis')
        self._metadata_db.delete_key('candidate_basis')
        self._metadata_db.delete_key(metadata.LASTACCEPTEDSTATEKEY)

    def _apply_os_config(self):
        """Apply OS-specific configurations.

        Any setup aimed at integrating FileRock with the OS should be
        done here.
        """
        
        # Start client on system startup (only for installed clients)
        if RUNNING_INSTALLED:
            value = self.cfg.get('User Defined Options', 'launch_on_startup')
            launch_on_startup = (value == u'True')
            self.os_settings_manager.set_autostart(enable=launch_on_startup)

        # Add FileRock to whitelisted tray icons if necessary
        if not self.os_settings_manager.is_systray_icon_whitelisted():
            self.os_settings_manager.whitelist_tray_icon()
            self._ui_controller.ask_for_user_input('logout_required')
            raise LogOutRequiredException()

    def _change_warebox_path(self, new_warebox):
        """Set a new folder as the warebox.

        @param new_warebox:
                    Absolute filesystem pathname of the directory that
                    will be the new warebox.
        """
        self.cfg.set('Application Paths', 'warebox_path', new_warebox)
        self.cfg.write_to_file()
        self._metadata_db.set('last_warebox_path',
                              self.cfg.get('Application Paths', 'warebox_path'))
        warebox = Warebox(self.cfg)
        CryptoUtils.recreate_encrypted_dir(warebox, self.logger)
        self._clean_env()

    def _ask_warebox_path(self, cfg):
        """Ask the user to select a directory on his filesystem to use
        as the warebox.

        @param cfg:
                    Instance of filerockclient.config.configManager.
        @return
                    Boolean telling whether the user has inserted the
                    requested input or has canceled the request.
        """
        last_warebox = self._metadata_db.try_get('last_warebox_path')

        if last_warebox is None and not self._metadata_db_exists_at_start:
            result = self._ui_controller.ask_for_user_input(
                                        'warebox_path',
                                        self.cfg.get('Application Paths',
                                                     'warebox_path')
                    )
            if result['result']:
                old_warebox = cfg.get('Application Paths', 'warebox_path')
                new_warebox = result['warebox_path']
                if self._warebox_need_merge(result['warebox_path']):
                    ret = self._ui_controller.ask_for_user_input(
                        'warebox_not_empty', old_warebox, new_warebox)
                    if ret != 'ok':
                        self._metadata_db.destroy()
                        return False
                self._change_warebox_path(new_warebox)
            else:
                self._metadata_db.destroy()
                return False

        return True

    def _warebox_need_merge(self, warebox_path):
        """Check whether a given directory would need to be merged with
        the content of the storage if used as the warebox.

        @param warebox_path:
                    Absolute filesystem pathname of the directory that
                    will be the new warebox.
        @return
                    True if the passed warebox will need a merge, False
                    otherwise.
        """
        old = self.cfg.get('Application Paths', 'warebox_path')
        self.cfg.set('Application Paths', 'warebox_path', warebox_path)
        tmp_warebox = Warebox(self.cfg)
        self.cfg.set('Application Paths', 'warebox_path', old)
        content = tmp_warebox.get_content(recursive=False)
        if CryptoUtils.ENCRYPTED_FOLDER_NAME in content:
            content.remove(CryptoUtils.ENCRYPTED_FOLDER_NAME)
        if content != []:
            return True
        return False

    def _check_warebox_or_username_changes(self):
        """Check whether the username or the warebox path have changed
        from the last time FileRock was running.

        If anything is changed than the user meta-data get deleted to
        restore a first-start condition.
        If the warebox has changed and it will be merged at next startup
        the user is asked to accept it.

        @return
                    False if the user refused to merge, True otherwise.
        """
        last_user = self._metadata_db.try_get('last_username')
        curr_user = self.cfg.get('User', 'username')
        last_warebox = self._metadata_db.try_get('last_warebox_path')
        curr_warebox = self.cfg.get('Application Paths', 'warebox_path')

        warebox_changed = last_warebox != curr_warebox
        user_changed = last_user is None or last_user != curr_user

        if user_changed:
            self.logger.debug('User changed from %s to %s',
                              last_user,
                              curr_user)

        if warebox_changed:
            self.logger.debug('Warebox path changed from %s to %s',
                              last_warebox,
                              curr_warebox)
            self.logger.debug('Maybe User has changed warebox path by hand')
            if self._warebox_need_merge(curr_warebox) \
            and not self._metadata_db_exists_at_start:
                ret = self._ui_controller.ask_for_user_input(
                    'warebox_not_empty', last_warebox, curr_warebox, True)
                if ret != 'ok':
                    return False
                self.logger.debug(
                    'User accepted the new warebox and content merge')

        if warebox_changed or user_changed:
            self._clean_env()

        self._metadata_db.set('last_warebox_path', curr_warebox)
        self._metadata_db.set('last_username', curr_user)
        return True

    def start_service(self):
        """Main entry point to run the application.

        Startup routine that makes initial checks and starts threads.
        All threads except those that run UIs are started from here.
        """
        self._check_for_updates()
        self._apply_os_config()
        self._show_welcome(self.cfg)

        self._patch_transition_from_release_0_4_0_no_null_basis()

        if self.storage_cache.recreated or not self.linker.is_linked():
            self.logger.debug('Storage cache was recreated or not linked')
            self._clean_env()

        if not self._ask_warebox_path(self.cfg):
            self._internal_facade.terminate()
            return

        self._get_ready_for_service()
        self._scheduler.start()
        link_result = self.linker.link()

        if not link_result:
            if link_result == False:
                self._internal_facade.terminate()
            return

        if not self._check_warebox_or_username_changes():
            self._internal_facade.terminate()
            return

        self._ui_controller.update_client_info({
            "username": self.cfg.get('User', 'username'),
            "client_id": self.cfg.get('User', 'client_id'),
            "client_hostname": platform.node(),
            "client_platform": platform.system(),
            "client_version": CURRENT_CLIENT_VERSION,
            "basis": self._metadata_db.try_get('trusted_basis')})

        self._ui_controller.update_config_info(self.cfg)

        if self.show_panel:
            self._ui_controller.show_panel()

        # Clear the storage cache if the blacklist has changed
        blacklist_currhash = self._warebox.get_blacklist_hash()
        blacklist_hash = self._metadata_db.try_get('blacklist_hash')
        if blacklist_hash is None or blacklist_hash != blacklist_currhash:
            self.logger.debug('Blacklist changed, cleaning cache')
            for pathname in map(lambda x: x[0], self.storage_cache.get_all_records()):
                if self._warebox.is_blacklisted(pathname):
                    self.storage_cache.delete_record(pathname)
            self._metadata_db.set('blacklist_hash', blacklist_currhash)

        self.FSWatcher.start()
        self._server_session.reload_config_info()
        self._server_session.start()
        if not self.auto_start:
            self._schedule_a_start()
        self._ui_controller.notify_core_ready()
        self._clean_os_label()

    def _patch_transition_from_release_0_4_0_no_null_basis(self):
        """Patch that handles an erroneous existence of an empty
        trusted basis in the metadata.

        The old FileRock releases used to automatically persist a None
        trusted basis if the 'trusted_basis' record didn't exist.
        However, now the metadata database has changed and would give an
        error on getting a None basis.

        To be removed as soon as all clients are updated.
        """
        trusted_basis = self._metadata_db.try_get('trusted_basis')
        exists = self._metadata_db.exist_record('trusted_basis')
        if exists and not trusted_basis:
            self.logger.info("Deleting a null trusted basis")
            self._metadata_db.delete_key('trusted_basis')

    def _clean_os_label(self):
        """Reset all labels of the OSX shell extension UI.
        """
        # TODO: move this method to the UI layer!!
        if sys.platform == 'darwin':
            try: enable_osx_label_shellext = self.cfg.get(config.USER_DEFINED_OPTIONS, 'osx_label_shellext') == u'True'
            except Exception: enable_osx_label_shellext = False
            if not enable_osx_label_shellext:
                if self._metadata_db.try_get('osx_label_shellext') != None:
                    from filerockclient.ui.shellextension.osx import label_based_ui
                    pathnames_list = map(self._warebox.absolute_pathname, self._warebox.get_content())
                    label_based_ui.clean_all_osx_labels(pathnames_list)
                    self._metadata_db.delete_key('osx_label_shellext')

    def _show_welcome(self, cfg):
        """Displays the presentation slides to the user, if needed.
        """
#        no_welcome = self._metadata_db.try_get('No welcome on startup')
#        no_welcome = no_welcome is not None and no_welcome != u'0'
        show = self.cfg.getboolean(config.USER_DEFINED_OPTIONS,'show_slideshow')

        if self.startupSlide and show:
            result = self._ui_controller.show_welcome(cfg, True)
            show = str(result['show welcome on startup'])
            self.cfg.set(config.USER_DEFINED_OPTIONS,'show_slideshow', show)
            self.cfg.write_to_file()

    def _check_for_updates(self):
        """Check if an update for FileRock is available.

        If a new a client version is found, user is prompted to download
        and install the upgrade.
        """

        # Never check for updates when running from source
        if RUNNING_FROM_SOURCE:
            self.logger.debug(u"Skipping update procedures (client is running from sources)")
            return
        
        # Get updater class for current platform (win32/darwin/linux2)
        try:
            updater = PlatformUpdater(
                                self.cfg.get('Application Paths', 'temp_dir'),
                                self.cfg.get('Application Paths', 'webserver_ca_chain'))
        # Note: this should never happen
        except UpdateRequestedFromTrunkClient as e:
            self.logger.debug(u"Skipping update procedures (running from trunk)")
            return
        except UnsupportedPlatformException as e:
            self.logger.warning(u"%s" % e)
            return
        # Updater failed to fetch latest version info (just log a warning)
        except ClientUpdateInfoRetrievingException as e:
            self.logger.warning(u"Error reading client update info: %s" % e)
            return

        # If client version is obsolete, prompt user to install updates
        if updater.is_client_version_obsolete():
            last_version = updater.get_latest_version_available()
            self.logger.info(
                u"Current client version (%s) is obsolete, latest is %s"
                % (CURRENT_CLIENT_VERSION, last_version))

            if self.cfg.get(u"User Defined Options", "auto_update") == u'True':
                user_choice = True
            else:
                # If cfg param 'auto_update' is off, prompt user to perform update
                user_choice = updater.prompt_user_for_update(self._ui_controller)

            if user_choice:
                raise UpdateRequestedException()
            elif updater.is_update_mandatory():
                raise MandatoryUpdateDeniedException()

        else:
            # Remove update data
            updater.flush_update_file()

    def _schedule_a_start(self):
        """Schedule a restart of the application.
        """
        # TODO: move this to the Application layer
        if self.restart_after_time > 0:
            self._scheduler.schedule_action(self.connect,
                                            name='START',
                                            minutes=self.restart_after_time)
            self.logger.info('Client schedules a connect in %d minutes' %
                             self.restart_after_time)

    def unschedule_start(self):
        """Unschedule a restart of the application, if there is any.
        """
        # TODO: move this to the Application layer
        self._scheduler.unschedule_action(self.connect)
        self.logger.debug('Removing scheduled connect')

    def terminate(self, terminate_ui=True):
        """Main termination routine.

        Makes all threads stop and releases all acquired resources.
        """
        self.logger.debug(u'Terminating Core...')
        self._client_facade._set_zombie()
        self._scheduler.terminate()
        if self.queue is not None:
            self.logger.debug(u"Aborting current operations...")
            self.queue.terminate()
            self.logger.debug(u"Current operations aborted.")
        if self._server_session is not None:
            self._server_session.terminate()
        if self.FSWatcher is not None:
            self.FSWatcher.terminate()
        self.logger.debug(u'Core terminated.')

    def connect(self):
        """Connect to the server.
        """
        self.unschedule_start()
        self._server_session.connect()

    def setup_ui(self, ui_class):
        """Factory method for creating user interface instances.

        Given a UI class, returns an instance of such class. Some basic
        setup is performed on the created object.
        It's needed only once.

        @param ui_class:
                    Any UI class in the filerockclient.ui package.
        """
        return ui_class.initUI(self._zombie_client_facade)

    def register_ui(self, ui):
        """Register a user interface object for interacting with the
        client.

        After a UI instance has been created by setup_ui(), it can be
        registered with this method. The UI gets linked to the client
        and can both receive messages and send queries/operations.

        @param ui:
                    Instance of any UI class in the filerockclient.ui
                    package.
        """
        ui.setClient(self._client_facade)
        self._ui_controller.register_ui(ui)


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = abstract_cache
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
A generic SQL-based store.

"Caches" are databases used by FileRock to persistently store
several kinds of data. Such a database (which is implemented with
SQLite) contains a set of "records", identified by a column called
"key". A cache can be configured with the following parameters:

    table: name of the cache (and of the underlying SQL table)
    schema: list of string, each defining a field of the records
    key: the field that identifies the records.

Usually AbstractCache isn't used as is, but instead it's subclassed
into "concrete" caches, which may expose higher-level functionalities.
A common pattern in defining caches is to define the module-level
constants TABLE, SCHEMA, KEY, making the constructor use them.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os
import logging
import copy

from contextlib import contextmanager
from filerockclient.databases.sqlite_driver import SQLiteDB

TABLENAME = 'Override me!'
KEY = u'pathname'
SCHEMA = [u'pathname Text', u'field2 Text', u'filed3 Text']


class WrongNumberOfParameters(Exception):
    pass


class NonexistentKey(Exception):
    pass


class MissingSchema(Exception):
    pass


class MissingKey(Exception):
    pass


class NoSuchTable(Exception):
    pass


class UnknownColumn(Exception):
    pass


class WrongSchema(Exception):
    pass


class AbstractCache(object):
    """A generic SQL-based store.

    "Caches" are databases used by FileRock to persistently store
    several kinds of data. Each database (which is implemented with
    SQLite) contains a set of "records", identified by a column called
    "key". A cache can be configured with the following parameters:

    TABLE: name of the cache (and of the underlying SQL table)
    SCHEMA: list of string, each defining a field of the records
    KEY: the field that identifies the records.

    Usually AbstractCache isn't used as is, but instead it's subclassed
    into "concrete" caches, which may expose higher-level functionalities.
    A common pattern in defining caches is defining the module-level
    constants TABLE, SCHEMA, KEY, making the constructor use them.

    @param database_file:
                absolute filesystem pathname to a file which
                will contain the database.
    @param table_name:
                name of the cache.
    @param table_schema:
                List of strings ['col_name col_type', 'col2_name col2_type']
                defining the fields of the records.
    @param key:
                Name of the field that identifies the records.
     """

    def __init__(self,
                 database_file, table_name, table_schema, key, logger=None):

        if logger is None:
            self.logger = logging.getLogger()
            self.logger.addHandler(logging.NullHandler())
        else:
            self.logger = logger
        self._table_name = table_name
        self._autocommit = True
        self._key = None
        self._columns = None
        self._schema = None
        self._db = SQLiteDB(database_file)
        self._filename = database_file
        self.recreated = False
        # Note: self.schema is a property object
        self.schema = table_schema
        self._check_schema() # possibly creating the table if it does not exist
        # Note: self.key is a property object
        self.key = key
        self._create_index_if_needed()
        
        # Remember not to vacuum from any other method than the constructor,
        # since it makes any open transaction commit!
        self._execute("VACUUM")

    def _check_schema(self):
        """
        Check the given table schema with the one present on db.

        Raises exception if declared table is not there or the schema is
        wrong.
        """
        data = self._query(u"SELECT sql FROM sqlite_master WHERE "
                           "type='table' and name=?", [self._table_name])
        if len(data) < 1:
            raise NoSuchTable()
        sql = data[0][0]
        sql = sql.split('(')[1]
        sql = sql.split(')')[0]
        sql = sql.split(',')
        found_schema = [' '.join(column_def.split()) for column_def in sql]
        if self._schema != found_schema:
            raise WrongSchema("expected: %s, found: %s"
                              % (self._schema, found_schema))

    @property
    def table_name(self):
        return self._table_name

    @property
    def schema(self):
        return self._schema

    @schema.setter
    def schema(self, schema):
        schema = [' '.join(column_def.split()) for column_def in schema]
        self._schema = schema
        self._schema_tostr = ', '.join(self._schema)
        self._columns = [string.split()[0] for string in self._schema]
        self._recreate_db_if_not_exists()

    @property
    def key(self):
        return self._key

    @key.setter
    def key(self, key):
        if self._columns is None:
            raise MissingSchema(u'Please define a schema')
        msg = u'key %s is not part of %s table' % (key, self.table_name)
        if key not in self._columns:
            raise NonexistentKey(msg)
        self._key = key
        self._key_index = self._columns.index(key)

    def _recreate_db_if_not_exists(self):
        must_recreate = False

        if not os.path.exists(self._filename):
            must_recreate = True
        else:
            try:
                self._db.query("SELECT * FROM %s LIMIT 1" % self.table_name)
                must_recreate = False
            except Exception:
                must_recreate = True

        if must_recreate:
            self.logger.debug(
                u"Initializing a new database "
                u"because no valid database could be found.")
            self._initialize_new()
            self.recreated = True

    def _create_index_if_needed(self):
        """Assuming the database is there and the schema is ok, 
        it add a key index if it is not present."""

        data=self._query(u"SELECT sql FROM sqlite_master "
                         u"WHERE type='index' and name=?", 
                         [self._key+"_index"])
        
        if len(data)==0:
            self.logger.debug("adding index to %s" % self._table_name)
            self._execute(u'CREATE INDEX "%s_index" on %s (%s ASC)' %
                      (self._key, self._table_name, self._key))


    def _initialize_new(self):
        """Initialize a new database table.
        """
        self.logger.debug(u'Creating database table...')
        args = (self.table_name, self._schema_tostr)
        self._execute(u'CREATE TABLE %s (%s)' % args)
        self.logger.debug(u'Database table successfully created.')

    def update_record(self, *record):
        """
        Write a record into the cache.

        If a record with the same key values already exists, it is
        overwritten.
        Raises WrongNumberOfParameters exception if a wrong number of
        fields is passed.

        @param record: a tuple of values (column1_value, column2_value, ...)
        """
        number_of_field = len(record)
        if number_of_field != len(self.schema):
            raise WrongNumberOfParameters(
                            u'Passed %s parameters, %s were required in the'
                            ' following schema: %s'
                            % (len(record), len(self.schema), self.schema))

        if not self.exist_record(record[self._key_index]):
            self._insert_record(record)
        else:
            self._update_record(record)

    def _insert_record(self, record):
        fields = ', '.join(['?'] * len(record))
        statement = ''.join([u'INSERT INTO %s VALUES (', fields, ')'])
        self._execute(statement % self.table_name, record)

    def _update_record(self, record):
        columns = u', '.join(["%s = ?" % column for column in self._columns])
        statement = u"UPDATE %s SET %s WHERE %s = ?"
        statement = statement % (self.table_name, columns, self.key)
        values = record + (record[self._key_index],)
        self._execute(statement, values)

    def update_record_fields(self, key_value, **fields):
        """
        Updates the fields specified by the "keyword args" for the row
        with the given key_value.

        @param key_value: the value of the key column
        @param **fields: parameters with format: field_name=value
        """
        if len(fields) == 0:
            raise WrongNumberOfParameters(
                            u'You should pass at least 1 column to update')
        if len(fields) >= len(self._schema):
            raise WrongNumberOfParameters(
                            u'You pass %s parameters, %s was required in the'
                            ' following schema %s'
                            % (len(fields), len(self.schema), self.schema))
        for key in fields.keys():
            if key not in self._columns:
                raise UnknownColumn(u'Column %s not in %s table'
                                    % (key, self._table_name))

        columns = u', '.join(["%s = ?" % column for column in fields])
        statement = u'UPDATE %s SET %s WHERE %s = ?' \
                                    % (self.table_name, columns, self.key)
        values = fields.values()
        values.append(key_value)
        self._execute(statement, tuple(values))

    def delete_record(self, key_value):
        """
        Delete a record from db with the given key value.

        @param key_value: the value of the key of the row to delete.
        """
        statement = u'DELETE FROM %s WHERE %s=?' % (self.table_name, self.key)
        self._execute(statement, (key_value,))

    def delete_records(self, key_values):
        """
        Delete all records with the given key values.

        @param key_values: an array of key values of the rows to delete
        """
        if len(key_values) == 0:
            return
        statement = u"DELETE FROM %s where %s=?" % (self.table_name, self.key)
        eargs = [(unicode(x),) for x in key_values]
        self._execute(statement, eargs)

    def exist_record(self, key_value):
        """
        Returns true if a there is a row with the given key value.

        @param key_value: the value of the key you are looking for
        @return: boolean
        """
        statement = "SELECT COUNT(*) FROM %s ""WHERE %s = ?" \
                                % (self.table_name, self.key)
        result = self._query(statement, (key_value,))
        count = result[0][0]
        return count > 0

    def get_record(self, key_value):
        """
        Return the record with the given key value.

        @param key_value: the value of the key column
        @return: a tuple representing the first row found with the given key
                or None if no row was found
        """
        stm = u'SELECT * FROM %s WHERE %s=?' % (self.table_name, self.key)
        result = self._query(stm, [key_value])
        if len(result) == 0:
            return None
        if len(result) > 1:
            self.logger.warning(
                u'More than one record found for %s="%s", returning the first.'
                % (self.key, key_value))
        return result[0]

    def get_all_records(self):
        return self._query(u"SELECT * FROM %s" % self.table_name)

    def get_all_keys(self):
        res = self._query(u"SELECT %s FROM %s" % (self.key, self.table_name))
        res = [record[0] for record in res]
        return res

    def clear(self):
        """ Delete all records from the database """
        self._execute(u"DELETE FROM %s" % self.table_name)

    def destroy(self):
        """ Delete DB File """
        if os.path.exists(self._filename):
            os.remove(self._filename)

    def _execute(self, statement, parameters=[]):
        if not self._autocommit:
            self._db.execute(statement, parameters)
        else:
            with self.transaction() as transactional_self:
                transactional_self._db.execute(statement, parameters)

    def _query(self, statement, parameters=[]):
        try:
            return self._db.query(statement, parameters)
        finally:
            if self._autocommit:
                self._db.close()

    @contextmanager
    def transaction(self, *caches_to_attach):
        """Open a transaction on this cache.

        Modifications to a cache usually are immediate, that is, they
        get persisted just after being made. However sometimes there is
        need for making several modifications in a transactional fashion,
        so to rollback if any error happens during the process.
        Any modification to the cache made inside this context manager
        is automatically committed when the context is finished and is
        automatically rollbacked if an exception is raised.

        Calling the context manager returns a clone of this cache, which
        must be used in place of the original one in order for the
        transaction to be effective.
        E.g.:  with mycache.transaction() as transactional_mycache: ...
        If other caches are passed to the context manager call, they
        are "attached" to this and become part of the same transaction
        (that is, either all caches are modified or none of them).
        E.g: with cache1.transaction(cache2) as (trans_c1, trans_c2): ...
        """

        transactional_self = copy.copy(self)
        transactional_self._autocommit = False
        transactional_self._db.begin_transaction()

        attached_caches = [transactional_self]

        for cache in caches_to_attach:
            statement = "ATTACH DATABASE '%s' as %s" \
                                  % (cache._filename, cache.__class__.__name__)
            transactional_self._execute(statement)
            transactional_cache = copy.copy(cache)
            transactional_cache._autocommit = False
            transactional_cache._db = self._db
            transactional_cache._table_name = "%s.%s" \
                                % (cache.__class__.__name__, cache._table_name)
            attached_caches.append(transactional_cache)

        try:
            if not caches_to_attach:
                yield transactional_self
            else:
                yield tuple(attached_caches)
        except:
            transactional_self._db.rollback_transaction()
            raise
        else:
            transactional_self._db.commit_transaction()
        finally:
            transactional_self._db.close()


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = hashes
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the hashes module.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging

from filerockclient.util.utilities import get_unix_and_local_timestamp
from filerockclient.databases.abstract_cache import AbstractCache


TABLE_NAME = u'hashes'

SCHEMA = [u'gmtime       INTEGER',
          u'localtime    TEXT',
          u'type         TEXT',
          u'prev_hash    TEXT',
          u'next_hash    TEXT']

KEY = u'gmtime'


class HashesDB(AbstractCache):

    def __init__(self, database_file):
        logger = logging.getLogger('FR.').getChild(self.__class__.__name__)
        super(HashesDB, self).__init__(database_file,
                                       TABLE_NAME,
                                       SCHEMA,
                                       KEY,
                                       logger=logger)
        self._logger = self.logger

    def add(self, prev_hash, next_hash, user_accepted=False):
        """
        Adds an hash couple into the db.

        @param prev_hash: the current hash
        @param next_hash: the next hash
        @param user_accepted:
                    if true set the column type to "useraccept"
                    instead of "commit"
        """

        self._logger.debug(u'Saving following hashes %s %s'
                           % (prev_hash, next_hash))
        if user_accepted:
            record_type = 'useraccept'
        else:
            record_type = 'commit'

        if prev_hash is None:
            prev_hash = 'Unknown'

        unix_gmtime, string_localtime = get_unix_and_local_timestamp()

        self._recreate_db_if_not_exists()

        self.update_record(unix_gmtime,
                           string_localtime,
                           record_type,
                           prev_hash,
                           next_hash)

        self._logger.debug(u'New hash couple saved (%s, %s, %s)'
                           % (record_type, prev_hash, next_hash))

    def list(self):
        return self.get_all_records()


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = metadata
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the metadata module.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging

from filerockclient.databases.abstract_cache import AbstractCache
from filerockclient.exceptions import FileRockException


LASTACCEPTEDSTATEKEY = 'LastAcceptedState'

TABLE_NAME = "metadata"

SCHEMA = ["key text",
          "value text"]

KEY = "key"


class MetadataDB(AbstractCache):
    """
    A key-value store
    It manage a locally persistent that keep whatever data
    that should be available among different run of the client.
    """

    def __init__(self, database_file):
        logger = logging.getLogger("FR.%s" % self.__class__.__name__)
        AbstractCache.__init__(
                self, database_file, TABLE_NAME, SCHEMA, KEY, logger)

    def get(self, key):
        """
        Looks for the record with the given key.

        @param key: the key value
        @return: the value associated with the given key
        """
        value = self.try_get(key)
        if value is None:
            raise FileRockException("Unknown key: %s" % key)
        return value

    def try_get(self, key):
        """
        Tries to get the value associated with the given key

        @return: the value or None
        """
        record = self.get_record(key)
        return record[1] if not record is None else None

    def set(self, key, value):
        """
        Adds a key or updates the value of a key

        @param key: the key name
        @param value: the key value
        """
        self.update_record(key, value)

    def delete_key(self, key):
        """
        Deletes a key

        @param key: the key to delete
        """
        self.delete_record(key)


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = sqlite_driver
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
A wrapper around the standard sqlite3 module with a nice interface.


-Guidelines for using this module-

We are using the sqlite3 module with default settings for transaction
handling. This means that auto-commit is turned off and that a
transaction is implicitly started before a Data Modification Language
(DML) statement (i.e. INSERT/UPDATE/DELETE/REPLACE) if there isn't one
already, and implicitly committed before a non-DML, non-query statement
(i.e. anything other than SELECT or the aforementioned). Please pay
attention to this: executing any maintenance command (e.g. VACUUM) makes
any open transaction commit, no matter what.

We prefer to use the implicit transaction handling as little as
possible. Although there is no way to explicitly start a transaction
(the BEGIN statement seems to be disabled by the sqlite3 module), it is
still possible to commit explicitly. This should be always done, to
avoid confusion and misleading code.

Remember that using SQLite in a multithreaded environment can be
tricky: a connection to a database file can't be shared by two or more
threads. While connection pooling would have been an option, we have
found simpler to make each thread use its own connection. The connection
is automagically created and handled by the SQLiteDB class, but you
should never forget about it. For example, each thread has to close its
own connection (that is, no global "closing procedure" is possible).

SQLite acquires an EXCLUSIVE lock while it writes to a database, meaning
that concurrent threads must wait for it to finish. For example, if a
thread T1 tries to begin a transaction while another thread T2 has an
uncommitted transaction (i.e. not committed yet), T1 will wait for an
amount of time given by the "timeout" parameter of sqlite3.connect()
(it is 5 seconds by default). If the lock is not released, then T1
raises an sqlite3.OperationalError exception with the message "database
is locked".

We prefer to use concurrency as little as possible. If you find yourself
facing locking issues (expecially with concurrent writing), then you
should probably consider to serialize the threads in your code.
Concurrent writing is acceptable only for very small operations, that
is, for writing single records that are immediately committed.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
import sqlite3
import threading


class SQLiteDB(object):
    """A wrapper around the standard sqlite3 module with a nice interface."""

    def __init__(self, database_file):
        """
        @param database_file:
                    The absolute filesystem pathname of the database
                    file. It will be created if it doesn't exist.
        """
        self._logger = logging.getLogger("FR.%s" % self.__class__.__name__)
        self._filename = database_file
        self._thread_local = threading.local()

    def _get_connection(self):
        """
        Return the sqlite3.Connection object for the current thread.

        One is created if the current thread doesn't already have a
        connection. The created object will be cached and returned on
        every call to this method.
        """
        try:
            connection = self._thread_local.connection
        except AttributeError:
            connection = sqlite3.connect(self._filename)
            try:
                connection.execute('PRAGMA case_sensitive_like = True')
            except Exception as e:
                self._logger.error(
                    u'Error setting PRAGMA case_sensitive_like: %s' % e)
                connection.close()
                raise
            self._thread_local.connection = connection
        return connection

    def begin_transaction(self):
        """
        Begin a transaction.

        Actually the sqlite3 module doesn't support the SQL "BEGIN"
        statement, so there isn't a way to explicitly start a new
        transaction. This is implicitly done by any DML statement.
        Nonetheless, calling "begin_transaction" in one's own code is,
        oh, so warm and cosy, making clearer the intention to begin a
        transaction. So this class supports a no-op begin method.
        """
        pass

    def commit_transaction(self):
        """Commit the current transaction."""
        connection = self._get_connection()
        connection.commit()

    def rollback_transaction(self):
        """Rollback the current transaction."""
        connection = self._get_connection()
        connection.rollback()

    def close(self):
        """
        Close the connection to the database for the current thread.

        Each thread must close its own connection, that is, each thread
        that made use of this class should call close() at shutdown.
        Closing a connection having an uncommitted transaction implies
        to rollback.
        """
        try:
            self._thread_local.connection.close()
            del self._thread_local.connection
        except AttributeError:
            pass

    def execute(self, statement, eargs=[]):
        """
        Execute any SQL statement that modify the database: INSERT,
        DELETE, CREATE, ALTER, etc.

        @param statement:
                    String containing an SQL statement. Placeholders for
                    parameters can be used in the forms "?" or ":name".
        @param eargs:
                    Values to be used as parameters in the given SQL
                    statement. When placeholders in the "?" format are
                    used, it can be either a tuple or an iterable
                    (e.g. a list) of tuples, each referring to an
                    execution of the statement. When the placeholders
                    are in the ":name" format, it can be either a
                    dictionary or an iterable of dictionaries.
        """
        connection = self._get_connection()
        try:
            if type(eargs) is tuple or eargs == []:
                connection.execute(statement, eargs)
            else:
                connection.executemany(statement, eargs)
        except Exception as e:
            self._logger.exception(
                u'Error executing statement "%s" with args %r: %r '
                % (statement, eargs, e.args[0]))
            raise

    def query(self, statement, eargs=[]):
        """
        Execute a SELECT SQL statement.

        @param statement:
                    String containing an SQL statement. Placeholders for
                    parameters can be used in the forms "?" or ":name".
        @param eargs:
                    Values to be used as parameters in the given SQL
                    statement. When placeholders in the "?" format are
                    used, it can be either a tuple or an iterable
                    (e.g. a list) of tuples, each relative to an
                    execution of the statement. When the placeholders
                    are in the ":name" format, it can be either a
                    dictionary or an iterable of dictionaries.
        @return
                    List of tuples, each being a row in the result set.
        """
        connection = self._get_connection()
        try:
            return connection.execute(statement, eargs).fetchall()
        except Exception as e:
            self._logger.error(
                u'Error performing query "%s" with values %r: %r '
                % (statement, eargs, e.args[0]))
            raise


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = storage_cache
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the storage_cache module.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
import datetime

from filerockclient.databases.abstract_cache import AbstractCache


TABLE_NAME = "storage_cache"

SCHEMA = ["pathname text",
          "warebox_size int",
          "storage_size int",
          "lmtime text",
          "warebox_etag text",
          "storage_etag text"]

KEY = "pathname"


class StorageCache(AbstractCache):
    '''
    The last known state of the storage.
    The lmtime (last modification time) field has the following meaning:
        - it's the local filesystem time for locally updated files
        - it's the local filesystem time for downloaded files
        - it's the local filesystem time for restored records which got lost
    In any case it is NOT the time of the commit, which isn't saved yet. It
    will be the "record time", that is, the time when the record was updated.
    '''

    def __init__(self, database_file):
        logger = logging.getLogger("FR.%s" % self.__class__.__name__)
        AbstractCache.__init__(
                self, database_file, TABLE_NAME, SCHEMA, KEY, logger)

    def get_all_records(self):
        """
        Returns either the list of tuples or False on error.

        The row is represented as a tuple containing the values of columns

        @return: a list of tuples each tuple contains
                (pathname, warebox_size, storage_size,
                lmtime, warebox_etag, storage_etag)
        """
        records = AbstractCache.get_all_records(self)
        result = []
        for record in records:
            pathname, warebox_size, storage_size, _, _, _ = record
            _, _, _, lmtime, warebox_etag, storage_etag = record
            lmtime = datetime.datetime.strptime(lmtime, '%Y-%m-%d %H:%M:%S')
            result.append((pathname, warebox_size, storage_size, lmtime,
                           warebox_etag, storage_etag))
        return result

    def exist_record_proper_prefix(self, prefix):
        """
        Checks the presence of pathnames with the given prefix

        @param prefix: a string prefix
        """
        query = "SELECT COUNT(*) FROM storage_cache " \
                "WHERE pathname LIKE (? || '%') AND NOT pathname = ?"
        result = self._query(query, (prefix, prefix))
        count = result[0][0]
        return count > 0

    def update_record(self,
                pathname, warebox_size, storage_size, lmtime,
                warebox_etag, storage_etag):

        lmtime_str = lmtime.strftime('%Y-%m-%d %H:%M:%S')
        AbstractCache.update_record(self,
                               pathname, warebox_size, storage_size,
                               lmtime_str, warebox_etag, storage_etag)


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = transaction_cache
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the transaction_cache module.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
import pickle
from datetime import datetime

from filerockclient.databases.abstract_cache import AbstractCache


TABLE_NAME = "transaction_cache"

SCHEMA = ["id int",
          "file_operation blob",
          "transaction_timestamp text"]

KEY = "id"


class TransactionCache(AbstractCache):

    def __init__(self, database_file):
        logger = logging.getLogger("FR.%s" % self.__class__.__name__)
        AbstractCache.__init__(
                self, database_file, TABLE_NAME, SCHEMA, KEY, logger)

    def update_record(self, op_id, operation, transaction_timestamp):
        # Pickled data are stored as binary data into a BLOB field
        operation_str = buffer(pickle.dumps(operation))
        timestamp_str = transaction_timestamp.strftime('%Y-%m-%d %H:%M:%S')
        AbstractCache.update_record(self, op_id, operation_str, timestamp_str)

    def get_all_records(self):
        records = AbstractCache.get_all_records(self)
        result = []
        for record in records:
            op_id, operation_str, timestamp_str = record
            # Pickled data are stored as binary data into a BLOB field
            operation = pickle.loads(str(operation_str))
            timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
            result.append((op_id, operation, timestamp))
        return result


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = warebox_cache
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the warebox_cache module.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
from filerockclient.databases.abstract_cache import AbstractCache

TABLE_NAME = u'warebox_cache'

SCHEMA = [u'pathname text',
          u'size int',
          u'lmtime text',
          u'etag text']

KEY = u'pathname'


class WareboxCache(AbstractCache):

    def __init__(self, database_file):
#         logger = logging.getLogger('FR.').getChild(self.__class__.__name__)
        super(WareboxCache, self).__init__(database_file,
                                           TABLE_NAME,
                                           SCHEMA,
                                           KEY,
                                           logger=None)

if __name__ == '__main__':
    wc = WareboxCache('./warebox_cache_temp')
    wc.insert_record('pippo', 12, 'blabla', '1234')
    wc.insert_record('pipo', 12, 'blabla', '1234')
    print wc.get_all_records()
    print wc.get_all_keys()
    wc.destroy()

########NEW FILE########
__FILENAME__ = events_queue
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Central database that tracks the status of all pathnames in the warebox.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from collections import deque
from threading import RLock
import logging

from filerockclient.events_todo_structure import EventsTodoStructure
from filerockclient.pathname_operation import PathnameOperation
from filerockclient.interfaces import PStatuses


class PathnameEvent(object):
    """An event happened to a pathname in the warebox"""

    def __init__(self, action, pathname, size=None, lmtime=None, etag=None,
                 paired_pathname=None, conflicted=False):
        """
        @param action:
                    One in: 'CREATE', 'DELETE', 'MODIFY', 'COPY',
                    'UPDATE_FROM_REMOTE'.
                    (Actually a REMOTELY_DELETED action is supported
                    too, but it isn't used yet).
        @param pathname:
                    String of a pathname in the warebox.
        @param paired_pathname:
                    Secondary pathname for those events that support it
                    (e.g. it is the source pathname for COPY events).
        @param size:
                    Size of pathname's content
        @param lmtime:
                    Last modification time of pathname
        @param etag:
                    Etag of pathname's content. None for DELETE events.
        """
        self.action = action
        self.pathname = pathname
        self.paired_pathname = paired_pathname
        self.size = size
        self.lmtime = lmtime
        self.etag = etag
        self.conflicted = conflicted

    def __str__(self):
        tpl = (self.action, self.pathname, self.size, self.lmtime, self.etag)
        res = u'PathnameEvent: %s [pathname: %r, size: %s, lmtime: %s, etag: %s' % tpl
        if not self.paired_pathname is None:
            res += u", paired_pathname: %r" % self.paired_pathname
        res += u"]"
        return res


class EventsQueue(object):
    """
    Central database that tracks the status of all pathnames in the warebox.

    This component holds a record for every known pathname in the warebox,
    remembering its status, if it's currently under synchronization, etc.
    Other threads can update it by the mean of PathnameEvent objects.
    After an update, a pathname needs to be synchronized. Other threads
    can query EventsQueue for pathnames to synchronize, which are
    returned as PathnameOperation objects. The operation type tells what
    to do for synchronizing the pathname.
    """

    def __init__(self, application, output_queue):
        self.logger = logging.getLogger("FR.%s" % self.__class__.__name__)
        self.events = deque([])
        # The data structure that actually holds the status of the pathnames
        self.map = EventsTodoStructure()
        self._last_event_for_pathname = {}
        self.access = RLock()
        self.application = application
        self._output_queue = output_queue

    def length(self):
        """
        @return
                    Length of the queue of the pathnames that need
                    synchronization.
        """
        with self.access:
            return len(self.events)

    def isEmpty(self):
        """
        @return
                    Boolean telling whether there are pathnames that
                    need synchronization.
        """
        return self.length() < 1

    def clear(self):
        """
        Clear all internal data structures, thus forgetting about any
        pathname.
        """
        with self.access:
            self.events.clear()
            self.map.clear()
            self._last_event_for_pathname.clear()

    def terminate(self):
        """
        Terminate this component, release any acquired resource.
        """
        with self.access:
            self.map.terminate()
            self.clear()

    def put(self, event):
        """
        Update a pathname status with a pathname event.

        Any ongoing synchronization activity on the pathname gets
        interrupted. A PathnameOperation is produced and sent to the
        output queue.

        @param event:
                    Instance of PathnameEvent
        """
        with self.access:
            self._digest(event)
            self._send_pathname_operation()

    def _digest(self, event):
        """
        Update a pathname status with a pathname event.

        Any ongoing synchronization activity on the pathname gets
        interrupted.

        @param event:
                    Instance of PathnameEvent
        """
        #self.logger.debug(u'Digesting event %s' % event)
        self._last_event_for_pathname[event.pathname] = event

        # Force copies to be creations. We aren't ready to handle copies yet.
        if event.action == 'COPY':
            event.action = 'CREATE'
            event.paired_pathname = None

        if event.action in ['CREATE', 'MODIFY', 'DELETE', 'UPDATE_FROM_REMOTE',
                            'REMOTELY_DELETED']:
            self._digest_single_pathname_event(event)

        else:
            # TODO: we don't support COPY yet
            raise Exception('EventsQueue, unsupported event: %s' % event)

    def _digest_single_pathname_event(self, event):
        """
        Handle status transitions for those events which involve just
        one pathname (e.g. UPDATE, DELETE, etc).
        """
        #self.logger.debug(u'Digesting single pathname event "%s"' % repr(event))
        action, pathname = event.action, event.pathname

        if self.map.isLocked(pathname):
            self.logger.debug(
                        u'Pathname "%s" seems worker-locked. Sending'
                        ' termination request to current worker.' % pathname)
            # Note: self.on_file_operation_abort is called on abort
            file_operation = self.map.getLockingWorker(pathname)
            file_operation.abort()

        if action == 'CREATE' or action == 'MODIFY':
            self.map.update(pathname)
            self.application.notify_pathname_status_change(
                                                pathname, PStatuses.TOBEUPLOADED)
        elif action == 'DELETE':
            self.map.delete(pathname)
            self.application.notify_pathname_status_change(
                                              pathname, PStatuses.DELETETOBESENT)
        elif action == 'UPDATE_FROM_REMOTE':
            self.map.update_from_remote(pathname)
            self.application.notify_pathname_status_change(pathname, PStatuses.TOBEDOWNLOADED)
        elif action == 'REMOTELY_DELETED':
            self.map.remotely_deleted(pathname)
        else:
            self.logger.warning(u'Unknown action requested: "%s" for'
                                ' pathname "%s"' % (action, pathname))

        self.events.append(pathname)

    def on_file_operation_complete(self, file_operation):
        """
        Handler called by PathnameOperation objects when they have been
        completed.

        Update the pathname status and release any constraint.

        @param file_operation:
                    The PathnameOperation that has been completed.
        """
        with self.access:
            if self.map.has_constraints_from(file_operation.pathname):
                self.map.dropConstraintFrom(file_operation.pathname)
            self.map.setStatus('OK', file_operation.pathname)
            self.map.unlock(file_operation.pathname)

    def on_file_operation_abort(self, file_operation):
        """
        Handler called by PathnameOperation objects when they have been
        aborted.

        Update the pathname status and release any constraint.
        Note: actually only EventsQueue can abort operations, so this is
        a self-call event handler.

        @param file_operation:
                    The PathnameOperation that has been aborted.
        """
        with self.access:
            # Note: constraints release here is reduntant, since it's performed
            # also on the next status change. I haven't decided yet which place
            # between here and there is better for this task.
            # The same goes for on_file_operation_complete.
            if self.map.has_constraints_from(file_operation.pathname):
                self.map.dropConstraintFrom(file_operation.pathname)
            self.map.setStatus('OK', file_operation.pathname)
            self.map.unlock(file_operation.pathname)
            self.application.notify_pathname_status_change(
                file_operation.pathname, PStatuses.ALIGNED)

    def _create_pathname_operation(self, status, pathname, oldpath=None):
        """
        Factory method for PathnameOperation objects
        """
        status_to_verb = {
            'LN': 'UPLOAD',
            'LD': 'DELETE',
            'LRto': 'REMOTE_COPY',
            'RN': 'DOWNLOAD',
            'RD': 'DELETE_LOCAL'
        }
        event = self._last_event_for_pathname[pathname]
        operation = PathnameOperation(
            self.application, self.access, status_to_verb[status],
            pathname, oldpath, event.etag, event.size, event.lmtime,
            event.conflicted)
        operation.register_abort_handler(self.on_file_operation_abort)
        operation.register_complete_handler(self.on_file_operation_complete)
        return operation

    def _send_pathname_operation(self):
        """
        Produce a PathnameOperation object corresponding to the last
        received PathnameEvent and send it to the output queue.
        """
        pathname = self.events.popleft()
        status = self.map.getStatus(pathname)
        oldpath = None
        operation = self._create_pathname_operation(status, pathname, oldpath)
        self.map.lock(pathname, operation)
        self._output_queue.put(operation, 'operation')


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = events_todo_structure
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the events_todo_structure module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging

# TODO: this module contains mostly legacy code and should be cleansed
# sooner or later.

class EventsTodoStructure(object):
    '''
    EventsToDoStructure class represents the map in EventsQueue and holds all the methods implementing status transitions for one-way on-line delayed synchronization.

    entries in self.status_map should look like:
    pathname: { 'status': <status>,
                'OLDPATH': <OLDPATH>,                            # Only if status == 'LRto'
                'LOCKED_BY': <worker-reference>                  # Only if sync operation is in progress
                'WAITING_FOR': <pathname_P'>                     # If there is a constraint in the form "... <-- P' ", here it is
                'MAKING_WAIT': <pathname_P'>                     # If there is a constraint in the form "P' <-- ... ", here it is
    }
    '''

    def __init__(self, status_map = {}):
        self.logger = logging.getLogger('JustShutUpLogger')
        self.logger.addHandler(logging.NullHandler())
        self.status_map = status_map

    def clear(self):
        self.status_map.clear()

    def terminate(self):
        m = self.status_map
        operations = [m[p]['LOCKED_BY'] for p in m if 'LOCKED_BY' in m[p]]
        for operation in operations:
            operation.abort()
        self.clear()

    def riseFalse(self, msg, acceptable=False):
        ''' This just logs a message and returns False.
        By default, the message is logged as a warning.
        In case this is called in an acceptable situation, the message is logged as a debug message '''
        if not acceptable: self.logger.warning(u'%s' % (msg))
        else: self.logger.debug(u'%s' % (msg))
        return False

    def getStatus(self, pathname):
        ''' Returns pathname status or False if pathname record is there but no status is set (which should not happend). '''
        if pathname in self.status_map and 'status' in self.status_map[pathname]: return self.status_map[pathname]['status']
        elif pathname in self.status_map and 'status' not in self.status_map[pathname]: return self.riseFalse('Missing status in record for pathname %s.' % pathname)
        else: return 'OK'

    def lock(self, pathname, worker):
        ''' "Locks" a pathname in self.status_map.
            Basically, by setting self.status_map[pathname]['LOCKED_BY'], we say "This worker is taking care of this pathname". '''
        self.status_map[pathname]['LOCKED_BY'] = worker

    def unlock(self, pathname):
        ''' "Unlock" a pathname in self.status_map. To be called only when workers are interrupted. Otherwise, see self.setStatus('OK', pathname). '''
        try: del(self.status_map[pathname]['LOCKED_BY'])
        except: self.logger.warning(u'Tried to unlock pathname not in self.status_map' )

    def isLocked(self, pathname):
        ''' Returns if pathname is being handled by another worker. Logs a warning and also returns False if pathname not in self.status_map. '''
        try: return 'LOCKED_BY' in self.status_map[pathname]
        except: return self.riseFalse('isLock? requested for pathname "%s" not in self.status_map' % pathname)

    def getLockingWorker(self, pathname):
        ''' Returns the reference to the current worker handling pathname.
            Returns False if there's no record for pathname in self.status_map or pathname is unlocked. '''
        if not self.isLocked(pathname) or not 'LOCKED_BY' in self.status_map[pathname]: return False
        else: return self.status_map[pathname]['LOCKED_BY']

    def has_constraints_from(self, pathname):
        ''' Returns if there is a constraint in the form "... <-- P " '''
        try: return 'MAKING_WAIT' in self.status_map[pathname]
        except KeyError: return self.riseFalse('"has_constraints_from" requested for pathname "%s" not in self.status_map' % (pathname), True)
        except: return self.riseFalse('.has_constraints_from("%s"): Something went wrong checking for constraints.' % (pathname))

    def has_constraints_to(self, pathname):
        ''' Returns if there is a constraint in the form "P <-- ... " '''
        try: return 'WAITING_FOR' in self.status_map[pathname]
        except KeyError: return self.riseFalse('"has_constraints_to" requested for pathname "%s" not in self.status_map' % (pathname), True)
        except: return self.riseFalse('.has_constraints_to("%s"): Something went wrong checking for constraints.' % (pathname))

    def get_paired_by_constraint_from(self, pathname):
        ''' Returns pathname target of constraint in the form "... <-- P " '''
        try: return self.status_map[pathname]['MAKING_WAIT']
        except: return self.riseFalse('Unable to get constraint target for pathname "%s" or pathname not in self.status_map' % (pathname))

    def get_paired_by_constraint_to(self, pathname):
        ''' Returns pathname source of constraint in the form "P <-- ... " '''
        try: return self.status_map[pathname]['WAITING_FOR']
        except: return self.riseFalse('Unable to get constraint source for pathname "%s" or pathname not in self.status_map' % (pathname))

    def set_constraint_from(self, pathname, oldpath):
        ''' Set MAKING_WAIT field. Checks are assumed as already performed. '''
        self.status_map[pathname]['MAKING_WAIT'] = oldpath
        return

    def set_constraint_to(self, oldpath, pathname):
        ''' Set WAITING_FOR field. Checks are assumed as already performed. '''
        self.status_map[oldpath]['WAITING_FOR'] = pathname
        return

    def delete_constraint(self, constraint_points_to, constraint_points_from):
        ''' This actually deletes " P' <-- P " by ereasing respective fields. Checks are supposed to be already performed.
            also constraints_points_from['OLDPATH'] is removed. '''
        try:
            del(self.status_map[constraint_points_to]['WAITING_FOR'])
            del(self.status_map[constraint_points_from]['MAKING_WAIT'])
            del(self.status_map[constraint_points_from]['OLDPATH'])
            return True
        except: return self.riseFalse('Something went wrong deleting constraint "%s" <-- "%s" ' % (constraint_points_to, constraint_points_from))

    def dropConstraintFrom(self, pathname):
        ''' Removes the constraint in the form "... <-- pathname ". '''
        if not self.has_constraints_from(pathname): return True
        try: paired_pathname = self.get_paired_by_constraint_from(pathname)
        except: return self.riseFalse('Unable to get paired pathname on "dropAnyConstraintFrom" pathname "%s"' % pathname)
        try: paired_pathname_constraint_comes_from = self.get_paired_by_constraint_to(paired_pathname)
        except: return self.riseFalse('Unable to get paired pathname from paired pathname (%s) on "dropAnyConstraintFrom" pathname "%s"' % (paired_pathname, pathname))
        if paired_pathname_constraint_comes_from == pathname: return self.delete_constraint(paired_pathname, pathname)
        else: self.riseFalse('Mismatching pairing! "%s" is MAKING_WAIT "%s" but it is instead WAITING_FOR "%s"' % (pathname, paired_pathname, paired_pathname_constraint_comes_from))

    def dropAnyConstraintTo(self, pathname):
        ''' Removes the constraint in the form " pathname <-- ...". '''
        if not self.has_constraints_to(pathname): return True
        try: paired_pathname = self.get_paired_by_constraint_to(pathname)
        except: return self.riseFalse('Unable to get paired pathname on "dropAnyConstraintTo" pathname "%s"' % pathname)
        try: paired_pathname_constraint_points_to = self.get_paired_by_constraint_from(paired_pathname)
        except: return self.riseFalse('Unable to get paired pathname from paired pathname (%s) on "dropAnyConstraintTo" pathname "%s"' % (paired_pathname, pathname))
        if paired_pathname_constraint_points_to == pathname: return self.delete_constraint(pathname, paired_pathname)
        else: self.riseFalse('Mismatching pairing! "%s" is WAITING_FOR "%s" but it is instead MAKING_WAIT "%s"' % (pathname, paired_pathname, paired_pathname_constraint_points_to))

    def imposeConstraint(self, oldpath, pathname):
        ''' Sets up the constraint "oldpath <-- pathname" and returns True. Returns False on missing records. '''
        if oldpath not in self.status_map or pathname not in self.status_map: self.riseFalse('Imposing "%s <-- %s " without pathnames records in self.status_map!' % (oldpath, pathname))
        self.set_constraint_from(pathname, oldpath)
        self.set_constraint_to(oldpath, pathname)
        return True

    def checkForCycles(self, oldpath, pathname):
        ''' Check for cycles created by the insertion of "oldpath <-- pathname", i.e., for path " oldpath -> ... -> ... -> pathname." '''
        current_pathname = oldpath
        cycle_found = False
        while not cycle_found:
            if not self.has_constraints_from(current_pathname): return False
            else: current_pathname = self.get_paired_by_constraint_from(current_pathname)
            if current_pathname == pathname: cycle_found = True
        return True

    def removeRecord(self, pathname):
        ''' Remove pathname record from self.status_map, i.e., set its status to 'OK'. '''
        if pathname in self.status_map: del(self.status_map[pathname])
        else: self.logger.warning(u'"OK" status set for pathname (%s) when pathname not in todo.' % (pathname))

    def setStatus(self, status, pathname):
        ''' Set pathname status. Setting pathname status to OK removes pathname entry from self.status_map, implicitly unlocking it. '''
        if status == 'OK': self.removeRecord(pathname)                                      # Record has to be removed to set status to 'OK'
        elif pathname in self.status_map: self.status_map[pathname]['status'] = status      # Status is updated if record is present
        else: self.status_map[pathname] = { 'status': status }                              # New record is created otherwise.
        self.logger.debug(u'Status %s set for pathname %s' % (status, pathname))

    def set_oldpath(self, pathname, oldpath):
        ''' Set OLDPATH field. This should be set when rename-like status transitions are handled.
            Note: set_oldpath() should always and only be called after self.setStatus('LRto', pathname). '''
        self.status_map[pathname]['OLDPATH'] = oldpath
        return

    def get_oldpath(self, pathname):
        ''' Returns pathname's oldpath, if any is set. Otherwise, get_oldpath() returns False.
            Note: get_oldpath(pathname) should always and only be called for pathnames in LRto status. '''
        try: return self.status_map[pathname]['OLDPATH']
        except: return False

    def update(self, pathname):
        ''' Handle status transitions for create/update operations. '''
        status = self.getStatus(pathname)
        if status in ['OK','LN','LD','LRto']: self.setStatus('LN', pathname)
        else:   self.logger.warning(u'Detected unknown status for pathname %s on setStatus(LN) request O_o' % (pathname))
        if status == 'LRto': self.dropAnyConstraintFrom(pathname)               # constraints "... <-- P " are dropped if status was LRto

    def delete(self, pathname):
        ''' Handle status transitions for delete operations. '''
        status = self.getStatus(pathname)
        if status in ['OK','LN','LRto']: self.setStatus('LD', pathname)
        elif status == 'LD': self.logger.debug(u'Requested delete for pathname already in LD (%s). This might happend with folder deletion propagation, when a content is already scheduled for deletion.' % (pathname))
        else:   self.logger.warning(u'Detected unknown status for pathname %s on setStatus(LD) request O_o' % (pathname))
        if status == 'LRto': self.dropAnyConstraintFrom(pathname)               # constraints "... <-- P " are dropped if status was LRto

    #######################################################################################################################
    # THIS SECTION IS A TEMP IMPLEMENTATION (used only in initial sync. to be completed when client will be "two-ways"    #
    #######################################################################################################################
    #
    #

    def update_from_remote(self, pathname):
        ''' Handle status transitions for remote update (i.e., remote pathname content updated). '''
        # this is a temp implementation, should be enough for offline sync
        if self.getStatus(pathname) != 'OK':    # What happend when a RN is notified "on-line" ? what if pathname status is !OK ?
            self.logger.warning(u'''(%s) RN STATUS NOTIFIED for !OK pathname "%s".
This is a two-way function and is not yet implemented.
Current status for pathname is: "%s" ''' % (pathname, ))
            return
            # self.dropAnyConstraintTo(pathname)
            # self.dropConstraintFrom(pathname)
        self.setStatus('RN', pathname)  # For offline sync, put pathname in RN is enough

    def remotely_deleted(self, pathname):
        ''' Handle status transitions for remotely deleted files. '''
        # this is a temp implementation, should be enough for offline sync
        if self.getStatus(pathname) != 'OK':    # What happend when a RD is notified "on-line" ? what if pathname status is !OK ?
            self.logger.warning(u'''(%s) RD STATUS NOTIFIED for !OK pathname "%s".
This is a two-way function and is not yet implemented.
Current status for pathname is: "%s" ''' % (pathname, ))
            return
        self.setStatus('RD', pathname)  # For offline sync, put pathname in RN is enough

    #
    #
    #######################################################################################################################
    # END OF THE TEMP IMPLEMENTATION                                                                                      #
    #######################################################################################################################

    def rename(self, oldpath, pathname):
        ''' Handle status transitions for rename-like operations. '''
        oldpath_status = self.getStatus(oldpath)
        if oldpath_status == 'OK': self.rename_with_oldpath_in_OK(oldpath, pathname)
        elif oldpath_status == 'LN': self.rename_with_oldpath_in_LN(oldpath, pathname)
        elif oldpath_status == 'LD': self.logger.warning(u'Unexpected sequence, rename-like ("%s" to "%s") requested with source status LD.' % (oldpath, pathname))
        elif oldpath_status == 'LRto': self.rename_with_oldpath_in_LRto(oldpath, pathname)
        else: self.logger.warning(u'Unexpected source status "%s" for rename-like operation ("%s" to "%s").' % (oldpath_status, oldpath, pathname))
        return

    def rename_with_oldpath_in_OK(self, oldpath, pathname):
        ''' Handle rename-like status transitions with oldpath in OK.
            Sets statuses, oldpath and constraint "oldpath <-- P " '''
        pathname_status = self.getStatus(pathname)
        self.setStatus('LD', oldpath)
        self.setStatus('LRto', pathname)
        self.set_oldpath(pathname, oldpath)
        if pathname_status == 'LRto': self.dropAnyConstraintFrom(pathname)
        self.imposeConstraint(oldpath, pathname)
        return

    def rename_with_oldpath_in_LN(self, oldpath, pathname):
        ''' Handle rename-like status transitions with oldpath in LN.
            Basically a shortcut is applied, oldpath is pur in LD and P in LN.
            Constraints "... <-- P " are dropped '''
        pathname_status = self.getStatus(pathname)
        self.setStatus('LD', oldpath)
        self.setStatus('LN', pathname)
        if pathname_status == 'LRto': self.dropAnyConstraintFrom(pathname)
        return

    def rename_with_oldpath_in_LRto(self, oldpath, pathname):
        ''' Handle rename-like status transitions with oldpath in LRto. '''
        Y = self.get_oldpath(oldpath)                       # Get oldpath_oldpath
        self.setStatus('LD', oldpath)                       # Set status LD, still preserving "oldpath <-- ... " if any
        self.dropAnyConstraintFrom(oldpath)                 # This includes Y <-- oldpath
        if self.has_constraints_from(pathname): self.dropAnyConstraintFrom(pathname) # drop any " ... <-- P ", since content of P is going to updated
        if not self.checkForCycles(oldpath, pathname):      # either from Y (i.e., by means of shortcut application)...
            self.setStatus('LRto', pathname)                #
            self.set_oldpath(pathname, Y)                   # set P(oldpath) = Y
            self.imposeConstraint(Y, pathname)              # impose Y <-- P
        else: self.setStatus('LN', pathname)                # ... or with direct upload to avoid cycles


if __name__ == '__main__':
    print "\n This file does nothing on its own, it's just the %s module. \n" % __file__

########NEW FILE########
__FILENAME__ = exceptions
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the exceptions module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""


class FileRockException(Exception):
    '''The root of all FileRock evil'''
    pass


class HashMismatchException(FileRockException):
    pass


class FailedLinkingException(FileRockException):
    pass


class BrokenPipeException(FileRockException):
    pass


class CachePersistenceException(FileRockException):
    pass


class EncryptedDirDelException(FileRockException):
    pass


class UpdateRequestedException(FileRockException):
    pass


class UpdateRequestedFromTrunkClient(FileRockException):
    pass


class MandatoryUpdateDeniedException(FileRockException):
    pass


class UpdateProcedureException(FileRockException):
    pass


class LogOutRequiredException(FileRockException):
    pass


class ClientUpdateInfoRetrievingException(FileRockException):
    pass


class UnsupportedPlatformException(FileRockException):
    pass


class ConnectionException(FileRockException):
    pass


class ProtocolException(FileRockException):
    pass


class ExecutionInterrupted(FileRockException):
    pass


class UnexpectedMessageException(ProtocolException):

    def __init__(self, message):
        self.message = message

    def __str__(self):
        name = self.message.name
        reason = self.message.getParameter('reason')
        return "%s, reason: %s" % (name, reason)


class ForceStateChange(FileRockException):
    """Not really an exception. Raise it when the current state must be
    interrupted to pass to the next state
    """
    pass

########NEW FILE########
__FILENAME__ = FileSystemWatcherCrossPlatform
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
The component that detect changes on the user files.

A "filesystem watcher" continuously monitors the data that the user wants
to be synchronized, so to detect changes as soon as they happen.
The current version of our filesystem watcher applies a simple scan-based
policy, that is, it periodically does a full scan of the user directory.
This is very inefficient but was the easiest solution that could
correctly work on every platform. The next step will be to make use of
the notification systems implemented by most OS, e.g. "inotify" on
Linux and "ReadDirectoryChanges" on Windows. This will bring us from
having only one cross-platform filesystem watcher to have several
implementations, one for each platform (at least Windows, Linux, OSX).


Notes on the diff algorithm.

The cross-platform filesystem watcher periodically produces a "snapshot"
of the warebox (the directory containing the user data), at each
iteration the new snapshot is compared with the last one to detect what
is changed.

All differences but deletions can be computed in chunks.
Assume we have a complete last_snapshot:
forall P in chunk:
 - P existed in last_snapshot and it hasn't changed: ok
 - P existed in last_snapshot and it has changed: modified
 - P didn't exist in last_snapshot but another had the same hash: rename
 - P didn't exist in last_snapshot and no other one had the same hash:
   created.
Since chunks are disjoined we are free to tell properties about
pathnames in each chunk (what is in a chunk cannot be in another one).
However deletions need full-list comparing, since what isn't in a chunk
COULD be in another one.
Note: rename detection is not really supported. We instead detect
copies, either from the last snapshot or from the current snapshot
itself. We also detect deletions, so a rename is actually by a COPY and
a DELETE opetions.
Note: we are furthemore able to detect copies into the current snapshot
that didn't have a correspondence in the last snapshot.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import time
import collections
import threading
import bisect
import Queue
import logging
from filerockclient.events_queue import PathnameEvent
from filerockclient.util.suspendable_thread import SuspendableThread


class WareboxSnapshot(object):
    '''
    Contains the list of pathnames in the Warebox in a given moment,
    together with their metadata (e.g. file size, date of last
    modifications, md5 hash of the content).
    '''

    def __init__(self, pathnames, metadata, warebox):
        self.logger = logging.getLogger("FR." + self.__class__.__name__)
        self.pathnames = pathnames
        self.metadata = metadata
        self._warebox = warebox
        self._dont_copy_below_size = 131072
        self._split_on_sizes = [0, 65536, 524288, 4194304, 10485760, 52428800]

    def split_by_size(self):
        '''
        Splits this snapshot in several disjoined snapshots
        corresponding to the size classes defined by the "sizes"
        argument.

        The elements in the "sizes" list must be in increasing order and
        the first one must be 0; each two consecutive elements define a
        size class, the last element is the lower bound of an unbounded
        class.
        Returns a list with the created snapshots following the same
        ordering as "sizes". Snapshots corresponding to classes with no
        pathnames aren't returned.
        '''
        sizes = self._split_on_sizes
        chunks = dict([(size, []) for size in sizes])

        def assign_to_chunk(pathname):
            ''' Classify a pathname by its size '''
            p_size = self.metadata[pathname]['size']
            if p_size < sizes[-1]:
                # Pathname isn't in the unbounded size class
                for i in xrange(1, len(sizes)):
                    if p_size < sizes[i]:
                        chunks[sizes[i - 1]].append(pathname)
                        break
            else:
                # Pathname is in the unbounded size class
                chunks[sizes[-1]].append(pathname)

        map(assign_to_chunk, self.pathnames)
        snapshots = []
        for size in sizes:
            chunk_pathnames = chunks[size]
            if len(chunk_pathnames) == 0:
                continue
            chunk_metadata = {}
            for pathname in chunk_pathnames:
                chunk_metadata[pathname] = self.metadata[pathname]
            snapshot = WareboxSnapshot(
                chunk_pathnames, chunk_metadata, self._warebox)
            snapshots.append(snapshot)
        return snapshots

    def update_content(self):
        '''
        Updates the list of pathnames this snapshot contains by
        accessing the Warebox. Any previous content is discarded.
        '''
        pathnames = self._warebox.get_content(blacklisted=True)
        metadata = {}
        for pathname in pathnames:
            metadata[pathname] = {'size': None, 'lmtime': None, 'etag': None}
        self.pathnames = pathnames
        self.metadata = metadata

    def update_etag(self, last_snapshot):
        '''
        Updates the "etag" metadata (an MD5 hash of its content) for all
        pathnames in the snapshot.
        If accessing the filesystem fails on a pathname for any reason,
        then that pathname is removed from the snapshot.
        '''
        def compute_etag_if_necessary(pathname):
            '''Gets the etag from last_snapshot if it's up to date,
            otherwise recompute it with fresh data from the disk.'''
            lmtime = self.metadata[pathname]['lmtime']
            try:
                last_lmtime = last_snapshot.metadata[pathname]['lmtime']
            except KeyError:
                last_lmtime = None
            if last_lmtime is None or lmtime != last_lmtime:
                return self._warebox.compute_md5_hex(pathname)
            else:
                return last_snapshot.metadata[pathname]['etag']

        self._update_metadata('etag', compute_etag_if_necessary)

    def update_lmtime(self):
        '''
        Updates the "last modification time" metadata for all pathnames
        in thesnapshot.
        If accessing the filesystem fails on a pathname for any
        reason, then that pathname is removed from the snapshot.
        '''
        self._update_metadata(
            'lmtime', self._warebox.get_last_modification_time)

    def update_size(self):
        '''
        Updates the "size" metadata for all pathnames in the snapshot.
        If accessing the filesystem fails on a pathname for any
        reason, then that pathname is removed from the snapshot.
        '''
        self._update_metadata('size', self._warebox.get_size)

    def _update_metadata(self, what, callback):
        '''
        Updates the metadata identified by "what" for all pathnames in
        the snapshot. "callback" must be a callable that returns the
        metadata value for a given pathname.
        If the callback fails on a pathname with an exception for any
        reason, then that pathname is removed from the snapshot.
        '''
        failed = []
        for pathname in self.pathnames:
            try:
                value = callback(pathname)
                self.metadata[pathname][what] = value
            except:
                failed.append(pathname)
        for pathname in failed:
            # TODO: lists are inefficient at deleting
            self.pathnames.remove(pathname)
            del self.metadata[pathname]

    def _create_inverted_index(self):
        '''
        Returns a dictionary that maps file contents to pathnames,
        i.e. tells the pathnames that have a given (etag, size) pair.
        '''
        index = collections.defaultdict(list)
        for pathname in self.pathnames:
            etag = self.metadata[pathname]['etag']
            size = self.metadata[pathname]['size']
            index[(etag, size)].append(pathname)
        return index

    def detect_modifications_from(self, last_snapshot):
        '''
        Detects part of the operations necessary to transform
        last_snapshot in self. Detected operations are: pathname
        creations, modifications, copies.
        Precondition: self.pathnames is sorted in lexicographic ordering.
        The ordering is significant for finding copies too: when a
        pathname could be copied from more than one source than the
        first one found by scanning the list will be chosen.
        Returns: a tuple with three lists of pathnames: created,
        modified, copied. Such lists are sorted in such a way that no
        hiearachy inconsistences are induced (e.g.: a file is created
        before its parent folder).
        '''
        created_pathnames = []
        modified_pathnames = []
        copied_pathnames = []
        is_done = collections.defaultdict(bool)  # defaults to False
        self_inverted_index = self._create_inverted_index()
        last_inverted_index = last_snapshot._create_inverted_index()

        def has_changed(pathname):
            ''' Tells if a pathname has changed from last_snapshot '''
            self_metadata = self.metadata[pathname]
            last_metadata = last_snapshot.metadata[pathname]
            return \
                self_metadata['etag'] != last_metadata['etag'] or \
                self_metadata['size'] != last_metadata['size']

        def find_twin(pathname):
            ''' Finds a pathname we can copy from, that is, that has
                the same content as "pathname" '''
            etag = self.metadata[pathname]['etag']
            size = self.metadata[pathname]['size']
            possible_twins = []
            cond = lambda p: False

            if size < self._dont_copy_below_size:
                pass
            elif (etag, size) in last_inverted_index:
                possible_twins = last_inverted_index[(etag, size)]
                cond = lambda p: p != pathname
            elif (etag, size) in self_inverted_index:
                possible_twins = self_inverted_index[(etag, size)]
                cond = lambda p: p != pathname and is_done[p]
            try:
                twin = (p for p in possible_twins if cond(p)).next()
            except StopIteration:
                twin = None

            return twin

        for pathname in self.pathnames:
            if pathname in last_snapshot.metadata:
                # Pathname existed in last snapshot
                if has_changed(pathname):
                    twin_pathname = find_twin(pathname)
                    if twin_pathname is None:
                        modified_pathnames.append(pathname)
                    else:
                        copied_pathnames.append((pathname, twin_pathname))
            else:
                # Pathname didn't exist in last snapshot
                twin_pathname = find_twin(pathname)
                if twin_pathname is None:
                    created_pathnames.append(pathname)
                else:
                    copied_pathnames.append((pathname, twin_pathname))
            is_done[pathname] = True
        created_pathnames.sort(key=len)
        return (created_pathnames, modified_pathnames, copied_pathnames)

    def detect_deletions_from(self, last_snapshot):
        '''
        Detects part of the operations necessary to transform
        last_snapshot in self. Detected operations are: deletions.
        Precondition: last_snapshot.pathnames is sorted in reverse
        lexicographic ordering.
        Returns: a list with the deleted pathnames. Such list is sorted
        in such a way that no hiearachy inconsistences are induced
        (e.g.: a file is created before its parent folder).
        '''
        deleted_pathnames = [
            pathname for pathname in last_snapshot.pathnames
            if not pathname in self.metadata]
        deleted_pathnames.sort(key=lambda x: -len(x))
        return deleted_pathnames

    def learn_pathname(self, pathname, size, lmtime, etag):
        if not pathname in self.metadata:
            bisect.insort_left(self.pathnames, pathname)
        else:
            raise Exception(
                u'Trying to learn an already known pathname: %s' % pathname)
        self.metadata[pathname] = {}
        self.metadata[pathname]['size'] = size
        self.metadata[pathname]['lmtime'] = lmtime
        self.metadata[pathname]['etag'] = etag

    def forget_pathname(self, pathname):
        error = False
        try:
            self.pathnames.remove(pathname)
            del self.metadata[pathname]
        except ValueError:
            error = True
        except KeyError:
            error = True
        if error:
            raise Exception(
                u'Trying to forget an unknown pathname: %s' % pathname)

    def __str__(self):
        res = ''
        for pathname in self.pathnames:
            metadata = self.metadata[pathname]
            res = res + repr(pathname) + ", "
            res = res + str(metadata['size']) + ", "
            date_ = metadata['lmtime']
            res = res + date_.isoformat() + ", "
            res = res + str(metadata['etag']) + "\n"
        return res


class FileSystemWatcherCrossPlatform(SuspendableThread):
    '''
    Thread that detects modifications done on the Warebox by the user
    and produces corresponding WareboxEvent objects.

    Detection is done with a scan-based approach: the watcher
    periodically does a full disk scan of the Warebox and creates a
    "snapshot", that is, a list of the pathnames in the Warebox together
    with their metadata. After each scan it compares the snapshot with
    the last one and produces a sequence of WareboxEvent necessary to
    make the last snapshot equal to the current one. Such list of events
    is put in self._output_event_queue.
    Production of WareboxEvents is done in chunks, with each chunk
    containing pathnames with a given maximum file size; chunks are
    computed in increasing file size ordering. This makes small files
    being notified first. Moreover, deletions are detected and notified
    last.
    '''

    def __init__(
            self, warebox, output_event_queue,
            start_suspended=True):
        SuspendableThread.__init__(
            self, start_suspended, name=self.__class__.__name__)
        self._logger = logging.getLogger("FR." + self.__class__.__name__)
        self._warebox = warebox
        self._output_event_queue = output_event_queue
        self._ready_to_scan = threading.Event()
        self._scan_interval = 5
        self._must_die = threading.Event()
        self.reset()

    def _make_snapshot(self):
        '''
        Creates a new snapshot of the Warebox by performing a full disk
        scan.
        '''
        snapshot = self._make_empty_snapshot()
        snapshot.update_content()
        snapshot.update_size()
        snapshot.update_lmtime()
        return snapshot

    def _make_empty_snapshot(self):
        '''
        Creates an empty snapshot of the Warebox.
        '''
        snapshot = WareboxSnapshot([], {}, self._warebox)
        return snapshot

    def learn_pathname(self, pathname, size, lmtime, etag):
        record = (pathname, size, lmtime, etag)
        #self._logger.debug(
        #    u'Learning pathname %r (size: %s, lmtime: %s, etag: %s)'
        #    % record)
        self._pathnames_to_learn.put(record)

    def forget_pathname(self, pathname):
        self._logger.debug(u'Forgetting pathname %r' % pathname)
        self._pathnames_to_forget.put(pathname)

    def _receive_external_snapshot_modifications(self):
        while True:
            try:
                pathname, size, lmtime, etag = \
                    self._pathnames_to_learn.get_nowait()
            except Queue.Empty:
                break
            self._last_snapshot.learn_pathname(pathname, size, lmtime, etag)
        while True:
            try:
                pathname = self._pathnames_to_forget.get_nowait()
            except Queue.Empty:
                break
            self._last_snapshot.forget_pathname(pathname)

    def _handle_snapshot(self, snapshot):
        '''
        Compares "snapshot" with the last one and produces the
        WareboxEvent objects corresponding to their differences. Such
        events are put in self._output_event_queue.
        '''
        snapshot_chunks = snapshot.split_by_size()
        for chunk in snapshot_chunks:
            chunk.update_etag(self._last_snapshot)
            created, modified, copied = \
                chunk.detect_modifications_from(self._last_snapshot)
            for pathname in created:
                size = snapshot.metadata[pathname]['size']
                lmtime = snapshot.metadata[pathname]['lmtime']
                etag = snapshot.metadata[pathname]['etag']
                self._output_event_queue.put(
                    PathnameEvent(
                        'CREATE', pathname, size, lmtime, etag))
            for pathname in modified:
                size = snapshot.metadata[pathname]['size']
                lmtime = snapshot.metadata[pathname]['lmtime']
                etag = snapshot.metadata[pathname]['etag']
                self._output_event_queue.put(
                    PathnameEvent(
                        'MODIFY', pathname, size, lmtime, etag))
            for dst_pathname, src_pathname in copied:
                size = snapshot.metadata[dst_pathname]['size']
                lmtime = snapshot.metadata[dst_pathname]['lmtime']
                etag = snapshot.metadata[dst_pathname]['etag']
                self._output_event_queue.put(
                    PathnameEvent(
                        'COPY', dst_pathname, size, lmtime, etag, src_pathname))
        deleted = snapshot.detect_deletions_from(self._last_snapshot)
        for pathname in deleted:
            self._output_event_queue.put(PathnameEvent('DELETE', pathname))

    def _wait_for_next_scan(self):
        '''
        Makes the watcher sleep until there is need for a new scan (e.g.
        timeout occurs).
         '''
        self._ready_to_scan.wait(self._scan_interval)

    def _interrupt_execution(self):
        '''
        Part of the SuspendableThread protocol.
        Creates the conditions for ensuring that this thread will get to
        the "check suspension" point; namely, interrupt any waiting
        between two scans.
        Called automatically.
        See also: SuspendableThread class.
        '''
        self._ready_to_scan.set()

    def _clear_interruption(self):
        '''
        Part of the SuspendableThread protocol.
        Clear any state set by the _interrupt_execution method in order
        to restore a consistent state.
        Automatically called.
        See also: SuspendableThread class.
        '''
        self._ready_to_scan.clear()

    def reset(self):
        '''
        Resets the watcher status.
        '''
        self._pathnames_to_learn = Queue.Queue()
        self._pathnames_to_forget = Queue.Queue()
        self._last_snapshot = self._make_empty_snapshot()

    def _main(self):
        '''
        Part of the SuspendableThread protocol.
        Main logic of the FileSystemWatcher.
        '''

        # --- uncomment the following to enable profiling ---
        #import cProfile
        #self.prof=cProfile.Profile()
        #self.prof.enable()

        while not self._must_die.is_set():
            #self._logger.debug(u'Starting a scan')
            # Suspend execution if so requested, until explicitly resumed
            self._check_suspension()
            self._receive_external_snapshot_modifications()
            snapshot = self._make_snapshot()
            self._handle_snapshot(snapshot)
            self._last_snapshot = snapshot
            #self._logger.debug(u'Scan ended')
            self._wait_for_next_scan()

        # --- uncomment the following to enable profiling ---
        #self.prof.disable()
        #self.prof.dump_stats('fswatcher.profile')

    def terminate(self):
        '''
        Shut down the FileSystemWatcher.
        '''

        # --- uncomment the following to enable profiling ---
        #try:
            #self.prof.disable()
            #self.prof.dump_stats('fswatcher.profile')
        #except:
            #pass

        self._must_die.set()
        # Part of the SuspendableThread protocol
        self._terminate_suspension_handling()
        self._ready_to_scan.set()


if __name__ == '__main__':
    from filerockclient.warebox import Warebox

    class OutputQueueMock(object):

        def put(self, event):
            print event

    def single_scan_test():
        ''' Simple test '''
        output_queue_mock = OutputQueueMock()
        watcher = FileSystemWatcherCrossPlatform(
            Warebox(), None, output_queue_mock)
        begin = time.time()
        snapshot = watcher._make_snapshot()
        last_snapshot = watcher._make_empty_snapshot()
        snapshot.update_etag(last_snapshot)
        print snapshot
        end = time.time()
        print "> %s seconds elapsed" % (end - begin)

    def periodic_scan_test():
        ''' Complex test '''
        output_queue_mock = OutputQueueMock()
        watcher = FileSystemWatcherCrossPlatform(
            Warebox(), None, output_queue_mock)
        watcher.start()
        watcher.join(120)

    single_scan_test()
    #periodic_scan_test()

########NEW FILE########
__FILENAME__ = ClientSkipList
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the ClientSkipList module.


----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from FileRockSharedLibraries.IntegrityCheck.SkipList import AbstractSkipList
import logging


POSITIVE_INFINITE = u'+INF'
NEGATIVE_INFINITE = u'-INF'

VERIFY = 'VERIFY'
DELETE = 'DELETE'
INSERT = 'INSERT'
UPDATE = 'UPDATE'


class ClientSkipList(AbstractSkipList):
    '''This class implements a SkipList client-side; it has to be
    attached to a dataset and it can be built starting by a proof root
    node.
    '''

    def __init__(self, root_node, condemned_pathnames=[]):
        '''
        @root_node: a SkipListNode root of one or more proof paths.
        @dataset: a dictionary { 'pathname': 'content_hash' }
        BE CAREFUL: content_hash IS THE HASH OF THE PATHNAME CONTENT
        '''
        super(ClientSkipList, self).__init__()
        self.logger = logging.getLogger("FR."+self.__class__.__name__)
        self.root = root_node
        self._normalize(root_node)
        self.logger.debug(u'SkipList successfully initialized and normalized.')

    def _normalize(self, root):
        '''This method recursively navigate a SkipListNode tree and
        adjusts the SkipList accordingly.

        This method guarantees not only the presence of the node in its
        correct position in SkipList data structures, but also that it
        has correct label directly from dataset.
        '''
        if root is None:
            return
        if not root.pathname in self.pathnames:
            self.pathnames.append(root.pathname)
        #self._resetNodeData(root)
        if root.height == 0:
            self.leaves[root.pathname] = root
        if root.isPlateau():
            self.plateaus[root.pathname] = root
        self._normalize(root.lower_child)
        self._normalize(root.right_child)

########NEW FILE########
__FILENAME__ = IntegrityManager
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the IntegrityManager module.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""


from filerockclient.integritycheck.ProofManager import ProofManager
import logging


class PathnameTypeException(Exception):
    def __init__(self, message, type):
        Exception.__init__(self, message)
        self.type = type


class UnexpectedBasisComputationException(Exception):
    pass


class WrongBasisFromProofException(Exception):
    def __init__(self, message, proof, pathname, operation_basis):
        Exception.__init__(self, message)
        self.proof = proof
        self.pathname = pathname
        self.operation_basis = operation_basis


class WrongBasisAfterUpdatingException(Exception):
    def __init__(self, message, computed_basis):
        Exception.__init__(self, message)
        self.computed_basis = computed_basis


class IntegrityManager(object):
    '''IntegrityManager handles integrity checks for the client.

    It must be initialized with a trusted beginning basis; after then it
    can check proofs and store operations.
    It can 'check commit results', checking a given server basis.
    '''

    def __init__(self, trusted_basis):
        '''Initializes the IntegrityManager with a trusted basis.
        '''
        self.trusted_basis = trusted_basis
        self.proofmanager = ProofManager(False)
        self.logger = logging.getLogger("FR."+self.__class__.__name__)

    def addOperation(self, verb, pathname, proof, filehash=None):
        '''Adds the described operation to the operation register,
        checking its correctness and the integrity of the related
        information.

        @verb: describes the operation
        @pathname: the target pathname of the operation
        @filehash: None by default, it's used in insertions and updatings.
        @proof: the Proof recieved by the server.

        raise: MalformedProofException if proof is somehow broken.
        raise: UnrelatedProofException if proof is fraudolent or not
               related to specified pathname.
        raise: WrongBasisFromProofException if basis doesn't match.
        raise: PathnameTypeException if given pathname is not a unicode
               object
        '''

        self._checkUnicodePathname(pathname)
        # This must be done before checking correctness.
        proof.operation = verb
        proof.pathname = pathname
        operation_basis = self.proofmanager.addOperation(proof, filehash)
        if operation_basis != self.trusted_basis:
            raise WrongBasisFromProofException(
                "Basis mismatch between trusted-basis and proof-basis!",
                proof, pathname, operation_basis)

    def clear(self):
        self.proofmanager.flushOperationList()
        self.trusted_basis = None

    def getCurrentBasis(self):
        '''Returns currently stored trusted basis.
        '''
        return self.trusted_basis

    def setCurrentBasis(self, basis):
        '''Sets currently stored trusted basis.
        '''
        self.trusted_basis = basis

    def isCurrent(self, basis):
        return basis == self.trusted_basis

    def checkCommitResult(self, server_basis):
        '''Verifies that server ADS matches with the client ADS after
        committing previously added operations.

        If no operations have been scheduled, previous trusted basis is
        used for comparison.

        raise: UnexpectedBasisComputationException if anything goes
               wrong while computing basis.
        raise: WrongBasisAfterUpdatingException if after basis
               computation, it is different by given server basis.
        '''
        # It's important to flush operations in any case and reassign basis
        # only if everything it's ok.
        try:
            self._checkBasis(server_basis)
        finally:
            self.proofmanager.flushOperationList()

    def _checkBasis(self, server_basis):
        '''Actually do the dirty job: computes basis, compares it to
        given one, update the current trusted basis.

        raise: UnexpectedBasisComputationException
        raise: WrongBasisAfterUpdatingException
        '''
        candidate_basis = self.getCandidateBasis()
        # The time of truth!
        if not candidate_basis == server_basis:
            raise WrongBasisAfterUpdatingException(
                "Basis mismatch between computed-basis and server-basis!",
                candidate_basis)
        self.trusted_basis = candidate_basis

    def getCandidateBasis(self):
        '''
        Returns the client-basis that must be compared to the server basis.
        raise: UnexpectedBasisComputationException
        '''
        if len(self.proofmanager.getPendingOperations()) == 0:
            return self.trusted_basis
        try:
            computed_basis = self.proofmanager.getBasis()
        except Exception as e:
            raise UnexpectedBasisComputationException(
                "Unexpected error during basis computation: %s" % e.message)
        return computed_basis

    def _checkUnicodePathname(self, pathname):
        '''Checks if a pathname is an unicode object.

        It does not return anything, but raise PathnameTypeException.
        '''
        try:
            assert pathname.__class__.__name__ == "unicode"
        except:
            raise PathnameTypeException(
                "Pathname %s is not a unicode object!" %
                (repr(pathname)), pathname.__class__.__name__)

########NEW FILE########
__FILENAME__ = ProofManager
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the ProofManager module.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
from copy import deepcopy

from filerockclient.integritycheck.ClientSkipList import ClientSkipList
from FileRockSharedLibraries.IntegrityCheck.SkipListNode import (SkipListNode,
                                                                 ProxyNode)

VERIFY = 'VERIFY'
DELETE = 'DELETE'
INSERT = 'INSERT'
UPDATE = 'UPDATE'
POSITIVE_INFINITE = u'+INF'
NEGATIVE_INFINITE = u'-INF'


class MalformedProofException(Exception):
    pass


class ProofManager():
    '''ProofManager manages proofs and can provide basis for integrity
    check and current status basis.

    It need to be provided with the operations to be checked and then
    executed and, most of all, a dataset.
    Dataset is a map <pathname,filecontenthash>.
    '''

    def __init__(self, verbose=False):
        '''ProofManager must be initialized with a dataset, a map
        <pathname, filecontenthash>.
        '''
        self.operations = []
        self.verbose = verbose
        self.logger = logging.getLogger("FR." + self.__class__.__name__)
        self.logger.debug(u"ProofManager initialized.")

    def addOperation(self, proof, filehash=None):
        '''Adds a proof declared to the server with related filehash, if
        needed; computes and returns the basis for such operation proof.

        @proof: a Proof object for the operation.
        @filehash: hash of the file, needed for deletion, insertions and
        updates. It may be None.
        raise: MalformedProofException.
        '''
        client_operation = proof.operation

        if client_operation == 'UPLOAD' and filehash is None:
            raise MalformedProofException(
                "No hashfile attached to UPDATE/INSERT operation!")

        # Map client operation names to integrity check operation names
        translation_table = {}
        translation_table['UPLOAD'] = 'INSERT'  # potentially an insert
        translation_table['REMOTE_COPY'] = 'INSERT'
        translation_table['RENAME'] = 'VERIFY'
        translation_table['MOVE'] = 'VERIFY'
        translation_table['DELETE'] = 'DELETE'
        translation_table['DOWNLOAD'] = 'VERIFY'
        translation_table['DELETE_LOCAL'] = 'VERIFY2'

        proof.operation = translation_table[client_operation]

        proof.consolidateOperation()

        # TODO: consolidateOperation mainly distinguish between INSERT and
        # UPDATE operations. However, it doesn't take into account operations
        # different from DELETE, INSERT and UPDATE, so we need to manually
        # fix the VERIFY case. It needs to be corrected.
        if client_operation == 'DOWNLOAD':
            proof.operation = 'VERIFY'

        if client_operation == 'DELETE_LOCAL':
            proof.operation = 'VERIFY2'

        proof.checkCorrectness()

        # TODO: move this check to Proof.checkCorrectness()
        if proof.operation == 'VERIFY':
            leaf_node = proof.getStartingNodes()[0]

            if leaf_node.height != 0:
                raise MalformedProofException(
                    "VERIFY proof whose leaf has height different from 0")

            if leaf_node.filehash != filehash:
                raise MalformedProofException(
                    "Proof filehash is different from the actual file MD5")

        # TODO: move this check to Proof.checkCorrectness()
        if proof.operation == 'VERIFY2':

            if len(proof.proofpaths) > 2:
                raise MalformedProofException(
                    "VERIFY2 proof has more than two proofpaths.")

            elif len(proof.proofpaths) == 2:
                pathnames = sorted(proof.proofpaths.keys())
                if not pathnames[0] < proof.pathname < pathnames[1]:
                    raise MalformedProofException(
                        "VERIFY2 proof whose pathname is not between "
                        "the two proofpaths.")
                if not proof._checkProofPathsAdjacency(proof.proofpaths[pathnames[0]],
                                                       proof.proofpaths[pathnames[1]]):
                    raise MalformedProofException(
                        "VERIFY2 proof with two non adjacent proofpaths")

            else:
                node = proof.proofpaths.values()[0]
                if not (node.pathname < proof.pathname or node.pathname == "-INF"):
                    raise MalformedProofException(
                        "VERIFY2 proof with only one proofpath non minor of the pathname.")
                if not proof._checkHighestProofPath(node):
                    raise MalformedProofException(
                        "VERIFY2 proof whose single path has right contributes.")

        self.logger.debug(u"Appending operation %s on %s, filehash=%s"
                          % (proof.operation, proof.pathname, filehash))
        self.operations.append((proof, filehash))
        return self._getProofBasis(proof)

    def abortOperation(self, proof, filehash):
        '''Removes a couple <proof, filehash> from the operation register.
        '''
        self.operations.remove((proof, filehash))

    def getPendingOperations(self):
        '''Returns a list of the non-verify operations appended to the
        Proof Manager.
        '''
        return [o for o in self.operations if not o[0].operation == VERIFY]

    def getBasis(self):
        '''Computes and returns basis for the whole current structure
        made of added Operations.

        If no operations were added, None is returned.
        raise: UnexpectedBasisException if anything goes wrong while
        computing basis.
        '''
        ops = self.getPendingOperations()
        if len(ops) <= 0:
            return None
        self.logger.debug(u"Recomputing basis.")
        skiplist = ProofManager._buildCommitSkipList(deepcopy(ops))
        return skiplist.getBasis()

    def flushOperationList(self):
        '''Empties the operations list.
        '''
        self.operations = []

    def _getProofBasis(self, proof):
        '''Computes and returns basis for a single operation proof, that
        semantically is an integrity proof for the operation.
        '''
        skipList = ProofManager._buildSkipList([deepcopy(proof)])
        return skipList.getBasis(forced=True)

    @staticmethod
    def _applyOperations(skipList, operations):
        '''Given a list of operations and a SkipList, executes the
        operations.
        '''
        #self.logger.debug(u"Applying operations on local skiplist.")
        for op in operations:
            if op[0].operation == INSERT:
                skipList.updateSkipListOnInsert(op[0].pathname, op[1])
            if op[0].operation == DELETE:
                skipList.updateSkipListOnDelete(op[0].pathname)
            if op[0].operation == UPDATE:
                skipList.updateSkipListOnUpdate(op[0].pathname, op[1])

    @staticmethod
    def _buildCommitSkipList(operations):
        '''Given a list of operations, builds & returns a skiplist with
        operations applied.
        '''
        proofs = [op[0] for op in operations]
        skipList = ProofManager._buildSkipList(proofs)
        ProofManager._applyOperations(skipList, operations)
        return skipList

    @staticmethod
    def _buildSkipList(proofs):
        '''Given a list of operations, this method builds and returns a
        SkipList with the proofs attached to given operations.
        '''
        starting_leaves = ProofManager._getStartingLeaves(proofs)
        merged_tree_root = ProofManager._mergePaths(starting_leaves)
        skipList = ClientSkipList(merged_tree_root)
        return skipList

    @staticmethod
    def _getStartingLeaves(proofs):
        '''Given a list of operations, returns the map of the
        pathname->leaves from which the several proofpaths begin.

        If more than one proofpath begin from a specific leave, only one
        is returned.
        '''
        starting_leaves = {}
        for proof in proofs:
            for node in [n for n in proof.getStartingNodes() if n is not None]:
                starting_leaves[node.pathname] = node
        return starting_leaves

    @staticmethod
    def _mergePaths(starting_leaves):
        '''Given a list of leaves, leading paths to root, returns the
        root of the tree built as merge of the paths.

        This is the main step of the merging algorithm: it merges paths
        into a tree.
        '''

        # Step 0: for now starting leaves must be ordered.
        starting_ordered_leaves = ProofManager._getStartingOrderedLeaves(starting_leaves)
        first_leave = starting_ordered_leaves[0]

        # Step 1: building the first proxies set. This set will be used
        # during the algorithm.
        # First path is chosen for proxy set initialization
        proxies = ProofManager._getProxiesInPath(first_leave)
        root = ProofManager._getPathRoot(first_leave)
        unproxieds = []

        # Step 2: merging the other paths to the tree.
        for starting_node in starting_ordered_leaves:
            ProofManager._mergePathInTree(starting_node, proxies, unproxieds)
        return root

    @staticmethod
    def _getStartingOrderedLeaves(starting_leaves):
        '''Given a list of nodes, return them sorted by pathname.
        '''
        starting_pathnames = list(starting_leaves.keys())
        starting_pathnames.sort()
        starting_ordered_leaves = []
        for pn in starting_pathnames:
            starting_ordered_leaves.append(starting_leaves[pn])
        return starting_ordered_leaves

    @staticmethod
    def _getPathRoot(node):
        '''Returns the root node of a computation path starting from the
        given node.
        '''
        #PRENDE IL NODO ROOT DI UN CAMMINO
        while isinstance(node, SkipListNode):
            root = node
            node = node.father
        return root

    @staticmethod
    def _getProxiesInPath(node):
        '''Given a path starting from 'node', returns a map of proxies
        in that path.

        Such map has the following structure: (proxy_child.pathname,
            proxy_child.height) -> father_node
        '''
        #PRENDE I PROXY LUNGO IL CAMMINO
        proxies = {}
        while isinstance(node, SkipListNode):
            lower = node.lower_child
            right = node.right_child
            candidate = None
            if isinstance(lower, ProxyNode):
                candidate = lower
            if isinstance(right, ProxyNode):
                candidate = right
            if isinstance(candidate, ProxyNode):
                proxies[(candidate.pathname, candidate.height)] = node
            node = node.father
        return proxies

    @staticmethod
    def _mergePathInTree(starting_node, proxies, unproxieds):
        '''Given a starting node of a computation path, this method
        merges the path in the tree.

        Merging points to the tree are found in the "proxies" data
        structure.

        @starting_node:
                    the leaf node of the path to be joined.
        @proxies:
                    the proxy map in the form (proxy_child.pathname,
                    proxy_child.height) -> father_node
        @unproxieds:
                    list of coordinates (pathname, height) of nodes that
                    must NOT be replaced by proxies.
        '''
        node = starting_node
        while isinstance(node, SkipListNode):
            break_order = ProofManager._attachNodeToTree(node, proxies, unproxieds)
            node = node.father
            if break_order:
                break

    @staticmethod
    def _attachNodeToTree(node, proxies, unproxieds):
        '''Given a node, this methods verifies if the node must replace
        a proxy node and in case, executes replacement.

        @node:
                    the node that must be checked as a replacement.
        @proxies:
                    the proxy map in the form (proxy_child.pathname,
                    proxy_child.height) -> father_node
        @unproxieds:
                    list of coordinates (pathname, height) of nodes that
                    must NOT be replaced by proxies.
        @return
                    True if any attaching happened.
        '''

        break_needed = False

        # Current node proxy children must be put in proxies.
        if isinstance(node.right_child, ProxyNode):
            r_child = (node.right_child.pathname, node.right_child.height)
            if not r_child in unproxieds:
                proxies[r_child] = node

        if isinstance(node.lower_child, ProxyNode):
            l_child = (node.lower_child.pathname, node.lower_child.height)
            if not l_child in unproxieds:
                proxies[l_child] = node

        # Verifying if current node must replace a proxy; in this case,
        # replace the proxy with current node.
        if (node.pathname, node.height) in proxies:
            newfather = proxies[(node.pathname, node.height)]
            if node.pathname == newfather.pathname:
                newfather.lower_child = node
            else:
                newfather.right_child = node
            node.father = newfather
            del proxies[(node.pathname, node.height)]
            unproxieds.append((node.pathname, node.height))
            break_needed = True

        return break_needed

    def _navigateTree(self, root):
        '''Debug method that simply navigates the tree from given root.
        '''
        if root is None:
            return
        nodes = (root, root.father, root.lower_child, root.right_child)
        self.logger.debug(u"-> %s  RELATIVES[%s][%s][%s]" % nodes)
        self._navigateTree(root.lower_child)
        self._navigateTree(root.right_child)

########NEW FILE########
__FILENAME__ = GStatus
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the GStatus module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.interfaces import GStatuses

def isConnected(status):
    return status >= GStatuses._MIN_CONNECTED

def _idToStrings():
    '''
    return a mapping from id's to corresponding strings for all states
    '''
    r={}
    for s in GStatuses.__dict__.keys():
        if s[0:3]=='NC_' or s[0:2]=='C_':
            code=GStatuses.__dict__[s]
            r[code]=s
    return dict(r)


def _getAll():
    '''
    get a set of all status codes
    '''
    r=set()
    for s in GStatuses.__dict__.keys():
        if s[0:3]=='NC_' or s[0:2]=='C_':
            code=GStatuses.__dict__[s]
            r.add(code)
    return frozenset(r)


def _getConnected():
    '''
    get a set of all status which represent a connected state
    '''
    allStates=_getAll()
    r=set()
    for i in allStates:
        if isConnected(i):
            r.add(i)

    return frozenset(r)


def _getNotConnected():
    '''
    get a set of all status which represent a connected state
    '''
    allStates=_getAll()
    r=set()
    for i in allStates:
        if not isConnected(i):
            r.add(i)

    return frozenset(r)


allStates=_getAll()
connectedStates=_getConnected()
notConnectedStates=frozenset(allStates-connectedStates)
name=_idToStrings()
########NEW FILE########
__FILENAME__ = GStatuses
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Contains the constants that are allowed for the global status
of the client, utilities for converting codes to meaningful names
(computing using a 'reflective' approach), and notable sets of states.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

NC_STOPPED=1
NC_CONNECTING=2
NC_NOSERVER=3
NC_ANOTHERCLIENT=4
NC_NOTAUTHORIZED=5

# the minimum value for codes representing a connected status
_MIN_CONNECTED=100
C_ALIGNED=100
C_NOTALIGNED=101
C_SERVICEBUSY=102

C_HASHMISMATCHONCONNECT=150
C_BROKENPROOF=151
C_HASHMISMATCHONCOMMIT=152
########NEW FILE########
__FILENAME__ = LinkingStatuses
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Contains the constants that indicate the linking phase status.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

UNLINKED = -1
SUCCESS = 0
GENERATING_RSA_KEY=1
SENDING = 2
SERVER_UNREACHABLE = 3
SERVER_ERROR = 4
WRONG_CREDENTIALS = 5
MALFORMED_USERNAME = 6
LINKING_FAILED = 7
UNKNOW_ERROR=8

########NEW FILE########
__FILENAME__ = PStatus
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the PStatus module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.interfaces import PStatuses

def _idToStrings():
    '''
    return a mapping from id's to corresponding strings for all states
    '''
    r = {}
    for s in PStatuses.__dict__.keys():
        if s[0] == '_':
            continue
        code = PStatuses.__dict__[s]
        r[code] = s
    return dict(r)


name = _idToStrings()
########NEW FILE########
__FILENAME__ = PStatuses
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Contains the constants that are allowed for the status of each pathname
utilities for converting codes to meaningful names
(computing using a 'reflective' approach).
The specified states are used for both files and directories.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

UNKNOWN = 0

ALIGNED = 1

TOBEUPLOADED = 12
UPLOADING = 13
UPLOADED = 14
UPLOADNEEDED = 15

TOBEDOWNLOADED = 21
DOWNLOADING = 22
DOWNLOADNEEDED = 23

RENAMETOBESENT = 31
RENAMESENT = 32

DELETETOBESENT = 41
DELETESENT = 42
DELETENEEDED = 43

LOCALDELETE = 51
LOCALRENAME = 52
LOCALCOPY = 53
LOCALDELETENEEDED = 54
LOCALRENAMENEEDED = 55
LOCALCOPYNEEDED = 56

BROKENPROOF = 101

########NEW FILE########
__FILENAME__ = internal_facade
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This object offers global application-level services to other
components. They see it as "the application".

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""


class InternalFacade(object):
    """This object offers global application-level services to other
    components. They see it as "the application".

    Very few responsibilities should be assigned here or we'll go
    toward the land of Low Cohesion. Always try to assign to some domain
    object first.
    """

    def __init__(self, core, command_queue, logger):
        """
        @param core:
                    Instance of filerockclient.core.Core.
        @param command_queue:
                    Instance of Queue.Queue where to put commands to
                    send to filerockclient.application.Application for
                    execution.
        @param logger:
                    Instance of logging.Logger.
        """
        self._logger = logger
        self._core = core
        self._command_queue = command_queue
        self._metadata_db = core._metadata_db
        self._first_startup = None

    def set_global_status(self, status):
        """Signal what is the current global status for the application.

        The UIs are signaled by this as well.

        @param status:
                    Instance of filerockclient.interfaces.GStatuses
        """
        facade = self._core._client_facade
        facade._set_global_status(status)
        ui_controller = self._core._ui_controller
        ui_controller.set_global_status(status)

    def notify_pathname_status_change(self, pathname, new_status, extras={}):
        """Signal what is the current status for the given pathname.

        User interfaces are signaled by this as well.

        @param pathname:
                    String referring to a pathname in the warebox.
        @param new_status:
                    Instance of filerockclient.interfaces.PStatuses
        @param extras:
                    Dictionary with any additional parameter to be
                    passed along with "new_status".
        """
        facade = self._core._client_facade
        facade._notify_pathname_status_change(pathname, new_status)
        ui_controller = self._core._ui_controller
        ui_controller.notify_pathname_status_change(pathname, new_status, extras)

    def learn_initial_status(self, known_pathnames):
        """Stores the initial known pathnames.

        The status for all known pathnames is set to ALIGNED.

        @param known_pathnames:
                    List of pathnames.
        """
        facade = self._core._client_facade
        facade._learn_initial_status(known_pathnames)

    def is_first_startup(self):
        """ Tell whether it's the first time this installation of
        FileRock runs.
        """
        if self._first_startup is None:
            self._first_startup = \
                self._metadata_db.try_get('firts_start') is None

        return self._first_startup

    def first_startup_end(self):
        """Mark the end of the first time this installation of FileRock
        runs.
        """
        self._metadata_db.set('firts_start', 'Done')

    def terminate(self):
        """Request the application to terminate

        This is an asynchronous request, so the caller must expect that
        the command will be eventually executed.
        """
        self._command_queue.put('TERMINATE')

    def pause(self):
        """Request the application to go to pause

        This is an asynchronous request, so the caller must expect that
        the command will be eventually executed.
        """
        self._command_queue.put('PAUSE')

    def reset_pause_timer(self):
        """Reset any active restart timer when the application is in pause

        This is an asynchronous request, so the caller must expect that
        the command will be eventually executed.
        """
        self._command_queue.put('RESET_PAUSE_TIMER')

    def pause_and_restart(self):
        """Put the application to pause and restart it after a while

        This is an asynchronous request, so the caller must expect that
        the command will be eventually executed.
        """
        self._command_queue.put('PAUSE_AND_RESTART')

    def soft_reset(self):
        """Terminate and restart the application (but user interfaces)

        This is an asynchronous request, so the caller must expect that
        the command will be eventually executed.
        """
        self._command_queue.put('SOFT_RESET')

########NEW FILE########
__FILENAME__ = linker
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the linker module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
import os
import hashlib
import platform
import urllib
import httplib
#import requests
import json
import pbkdf2
import codecs
import ConfigParser
from binascii import hexlify, unhexlify
from Crypto.PublicKey.RSA import RSAImplementation

from filerockclient.exceptions import *
from filerockclient.config import ConfigManager
from filerockclient.workers.filters.encryption import utils as CryptoUtils
import filerockclient.interfaces.LinkingStatuses as LinkingStatus
from FileRockSharedLibraries.Misc.LinkingServiceCodes import \
    LinkingServiceCodes


class Linker(object):

    def __init__(self, cfg, ui_controller):
        self._ui_controller = ui_controller
        self.host = cfg.get('System', 'linking_hostname')
        self.port = cfg.getint('System', 'linking_port')
        self.certificate = cfg.get('Application Paths', 'linking_certificate')
        self.cfg = cfg
        self.protocol_version = 1
        self.client_id = None
        self.username = None

        if cfg.has_option('User', 'client_id'):
            self.client_id = cfg.get('User', 'client_id')

        if cfg.has_option('User', 'username'):
            self.username = cfg.get('User', 'username')

        self.logger = logging.getLogger("FR." + self.__class__.__name__)

    def _pad(self, blob, length):
        """Returns a padded version of the passed blob which has the
        indicated length.

        @blob: the data to be padded. It's considered as a string.
        @length: the length to be reached (in bytes)
        """
        if len(blob) > length:
            raise Exception('invalid length')
        elif len(blob) == length:
            return blob
        else:
            return '%s%s' % (' ' * (length - len(blob)), blob)

    def _generate_authDigest(self, username,  password):
        """
        Generates Authentication Digests from username and password.

        Returns the result of sha1(username:pbkdf2(password, username)
        """
        #hp = hexlify(pbkdf2.pbkdf2(password,  username,  64))
        hp = hexlify(pbkdf2.PBKDF2(password,  username).read(64))
        authentication_digest = hashlib.sha1(
            u'%s:%s' % (username, hp)).hexdigest()
        return authentication_digest

    def _generate_keys(self):
        """Generates RSA 2048 public and private key and returns them."""
        RSAfactory = RSAImplementation()
        self.logger.debug(u'Generating new RSA keypair...')
        keypair = RSAfactory.generate(2048)
        pub_key = keypair.publickey().exportKey()
        pvt_key = keypair.exportKey()
        self.logger.debug(u'RSA keypair generated.')
        self.logger.debug(u'Public key generated:\n %s' % pub_key)
        return pub_key, pvt_key

    def _ask_for_credentials(self, retry, initialization):
        credentials = self._ui_controller.ask_for_user_input(
            "linking_credentials", retry, initialization)
        return credentials

    def reset_info(self):
        self.client_id = None
        self.username = None
        self.cfg.set('User', 'client_id', "")
        self.cfg.write_to_file()

    def is_linked(self):
        return self._check_linking()

    def _check_linking(self):
        try:
            p = self.cfg.get(u'Application Paths', u'client_priv_key_file')
        except ConfigParser.NoSectionError:
            return False

        if self.client_id and self.username and os.path.exists(p):
            return True

        return False

    def link(self, credentials=None):
        """Executes the linking of the client.

        You can pass a credentials dictionary with username and password.
        Without credentials Linker will ask the credentials using the
        available UI.
        """
        if self._check_linking():
            self.logger.debug(
                u"Client already linked with id %s" % self.client_id)
            return True

        self.logger.info(
            u"This client must be linked to the server. "
            u"Starting the linking procedure...")

        linked = False
        pub_key = None
        pvt_key = None

        if credentials is None:
            credentials = {
                u'username': self.cfg.get(u'User', u'username'),
                u'password': u''
            }
            self.logger.debug(u"credentials from config are %r", credentials)
            credentials = self._ask_for_credentials(True, credentials)
            self.logger.debug(u"user specified credentials ")
        else:
            self.logger.debug(u"caller passed credentials ")


        while credentials['provided'] and not linked \
        and credentials['provided'] is not None:
            username = credentials['username']
            password = credentials['password']

            system = platform.system()
            hostname = platform.node()

            if pub_key is None:
                self._ui_controller.update_linking_status(LinkingStatus.SENDING)
                self.logger.info(u'Generating your public/private keys...')
                pub_key, pvt_key = self._generate_keys()
                self.logger.info(u'Public key generated...\n %s' % pub_key)

            authentication_digest = \
                self._generate_authDigest(username,  password)

            enc_key = CryptoUtils.generate_encryption_key()
            enc_mk = CryptoUtils.enckey_to_encmk(enc_key, username, password)

            try:
                self._ui_controller.update_linking_status(LinkingStatus.SENDING)

                data = json.dumps(dict(
                    authentication_digest=authentication_digest,
                    pub_key=pub_key,
                    platform=system,
                    hostname=hostname,
                    proposed_encryption_key=hexlify(enc_mk)
                ))

                # Note: We can't use requests yet because of the proxy patch
                # on httplib. Keep using httplib for now.
                # url = "https://%s/user/%s/client/link" % (self.host, username)
                # response = requests.post(url=url, data=data)

                conn = httplib.HTTPSConnection(self.host)
                #conn.set_debuglevel(1)
                target = urllib.quote("/user/%s/client/link" % username)
                conn.request("POST", target, data)
                response = conn.getresponse()

                if response.status == 200:
                    response_obj = json.loads(response.read())
                    self._on_success(response_obj, username, password, pvt_key)
                    linkstatus = LinkingStatus.SUCCESS
                    linked = True
                else:
                    self.logger.error(u"Linking error, status: %s, body: %s"
                                      % (response.status, response.read()))

                    error_table = {
                        # Unauthorized.
                        # It means: invalid authentication_digest
                        401: LinkingStatus.WRONG_CREDENTIALS,

                        # Not found.
                        # It means: unknown username
                        404: LinkingStatus.MALFORMED_USERNAME,

                        # Precondition failed.
                        # It means: there are already too many linked clients
                        412: LinkingStatus.LINKING_FAILED,

                        # Temporary unavailable.
                        503: LinkingStatus.SERVER_ERROR,

                        # Internal server error.
                        500: LinkingStatus.SERVER_ERROR
                    }

                    try:
                        linkstatus = error_table[response.status]
                    except KeyError:
                        linkstatus = LinkingStatus.UNKNOW_ERROR

                self._ui_controller.update_linking_status(linkstatus)
                credentials = self._ask_for_credentials(True, credentials)
                if credentials['provided'] is None:
                    break

            except (ConnectionException, BrokenPipeException, ProtocolException):
                self._ui_controller.update_linking_status(LinkingStatus.SERVER_UNREACHABLE)
                credentials = self._ask_for_credentials(True, credentials)

        if credentials['provided'] is None:
            return None

        if linked:
            self.logger.debug("Link done!!!")
        else:
            self.logger.debug("Link not done!!!")

        return linked

    def _on_success(self, response, username, password, pvt_key):
        """@ptype response:  the response returned by requests.post()
        """
        client_id = response['assigned_client_id']

        self.logger.info(u"Linking done successfully, assigned client id = %s"
                         % client_id)

        enc_mk = response['assigned_encryption_key']
        strId = unicode(str(client_id), 'utf-8_sig')
        #Adds cliend id to the configuration
        enc_key = CryptoUtils.encmk_to_enckey(
            unhexlify(enc_mk), username, password)

        self.logger.debug(u'Setting new configuration username:%s client_id:%s'
                          % (username, strId))

        self.cfg.set('User', 'client_id', strId)
        self.cfg.set('User', 'username', username)
        #TODO: check the presence of encryption dir in config
        self.cfg.set('User', 'encryption_key', hexlify(enc_key))

        priv_key_file = self.cfg.get('Application Paths', 'client_priv_key_file')

        #Write private Key
        self.logger.debug(u'Writing private key to %s' % priv_key_file)
        try:
            with codecs.open(priv_key_file, 'w', encoding='utf-8') as f:
                f.write(pvt_key)

            #Rewrite new configuration
            self.cfg.write_to_file()
        except:
            self.logger.error(u'Failed writing linking information')
            raise FailedLinkingException(
                "Linking failed on write configuration")


if __name__ == "__main__":
    file_name = u'./config.ini'
    config = ConfigManager()
    config.load()
    linker = Linker(config)
    linker.link()

########NEW FILE########
__FILENAME__ = logging_helper
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the logging_helper module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os, logging, logging.handlers

LOG_FILENAME = 'client.log'
LOGGING_CONFIGURATION = {
    'version': 1,
    'loggers': {
        'ExampleLogger': {
            'handlers': ['developer_console']
        },
    },
    'handlers': {
        'developer_console': {
            'class': 'logging.StreamHandler',
            'level': 'DEBUG',
            'formatter': 'verbose',
            'stream': 'ext://sys.stdout',
        },
        'user_console': {
            'class': 'logging.StreamHandler',
            'level': 'INFO',
            'formatter': 'user_friendly',
            'stream': 'ext://sys.stdout',
        },
        'user_log_file': {
            'class' : 'logging.handlers.RotatingFileHandler',
            'level': 'DEBUG',
            'formatter': 'verbose',
            'filename': LOG_FILENAME,
            'encoding': 'UTF-8',
            'maxBytes': 10485760, # 10 MB
            'backupCount': 0,
        },
    },
    'formatters': {
        'verbose': {
            #'format': '[CLIENT][%(levelname)-8s][%(asctime)s][%(threadName)-10s] (%(name)s) %(message)s',
            'format': '[%(levelname)-8s][%(asctime)s][%(threadName)-10s] (%(name)s) %(message)s',
            'datefmt': '%m/%d/%Y %H:%M:%S'
        },
        'console_debug': {
            'format': '[%(levelname)-8s][%(threadName)-10s] (%(name)s) %(message)s',
            'datefmt': '%H:%M:%S'
        },
        'user_friendly': {
            'format': '[%(levelname)s][%(asctime)s] %(message)s',
            'datefmt': '%m/%d/%Y %H:%M:%S',
        },
    },
}

class GuiHandler(logging.NullHandler):
    def __init__(self, *args, **kwds):
        logging.NullHandler.__init__(self, *args, **kwds)
        self.guihandler = None

    def handle(self, record):
        if self.guihandler is not None:
            try:
                self.guihandler(self.format(record)+'\n')
            except:
                pass

    def registerGuiLogHandler(self, function):
        self.guihandler = function


class LoggerManager(object):
    """configure the logger"""
    def __init__(self, verbosity = 'user_friendly'):
        self.configuration = LOGGING_CONFIGURATION
        self.verbosity = verbosity
        self.log_filename=None
        self.stream_handler=None
        self.file_handler=None
        self.gui_handler = None

    def _get_GuiHandler(self):
        if self.gui_handler:
            return self.gui_handler

        format = self.configuration['formatters'][self.verbosity]['format']
        datefmt = self.configuration['formatters'][self.verbosity]['datefmt']

        handler = GuiHandler()
        handler.setFormatter(logging.Formatter(format, datefmt))
        handler.setLevel(logging.INFO)

        self.gui_handler=handler
        return handler

    def _get_StreamHandler(self, level=logging.INFO):
        if self.stream_handler:
            return self.stream_handler

        verbosity = self.verbosity
        if level == logging.DEBUG:
            verbosity = 'console_debug'
        format = self.configuration['formatters'][verbosity]['format']
        datefmt = self.configuration['formatters'][verbosity]['datefmt']

        handler = logging.StreamHandler()
        handler.setFormatter(logging.Formatter(format, datefmt))
        handler.setLevel(level)

        self.stream_handler=handler
        return handler

    def _get_log_filename(self):
        return self.log_filename

    def _get_RotatingFileHandler(self, log_dir='.'):
        """
        This method return a new file handler the first time 
        it is called and then the same handler the next times.
        This means that it is meant to be called the first time 
        to get a new handler to be added and the second time 
        to get the same handler, for example to remove it.
        """
        if self.file_handler:
            return self.file_handler
        self.log_dir = log_dir
        filename = self.configuration['handlers']['user_log_file']['filename']
        mode = 'a'
        maxBytes = self.configuration['handlers']['user_log_file']['maxBytes']
        backupCount = self.configuration['handlers']['user_log_file']['backupCount']
        filepath = os.path.join(self.log_dir, filename)

        format = self.configuration['formatters']['verbose']['format']
        datefmt = self.configuration['formatters']['verbose']['datefmt']

        handler = logging.handlers.RotatingFileHandler(filepath, mode, maxBytes, backupCount)
        handler.setLevel(logging.DEBUG)
        handler.setFormatter(logging.Formatter(format, datefmt))

        self.log_filename = filepath

        self.file_handler=handler
        return handler



########NEW FILE########
__FILENAME__ = main
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the main module.


----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.constants import \
    get_command_line, IS_DARWIN, IS_PYTHON_27, IS_64BITS

assert IS_PYTHON_27, "Python 2.7 required"
assert not (IS_DARWIN and IS_64BITS), "Python 2.7 32bit required on OSX"

import os
import argparse
from multiprocessing import freeze_support
from filerockclient.application import Application


def main():
    freeze_support()
    from filerockclient.util.utilities import install_excepthook_for_threads
    install_excepthook_for_threads()

    # Command line argument parsing
    parser = argparse.ArgumentParser(
        description='The tool for accessing '
        'your cloud storage files securely.')

    parser.add_argument(
        '-c', '--configdir',
        help='Set the configuration directory', type=unicode, default=None,
        metavar="<configuration directory>")

    parser.add_argument(
        '-i', '--interface',
        help='User interface mode: g=gui (default), c=console, n=none',
        type=unicode, default=u"g", metavar="<user interface mode>")

    parser.add_argument(
        '--no-bug-report',
        dest='bugreport', action='store_false',
        help="In case of unhandled exceptions do not trigger the bug-report "
        "subsystem but shows exceptions on terminal. This options is intended "
        "to be used by developers.")

    parser.add_argument(
        '--show-panel',
        dest='showpanel', action='store_true',
        help="If this param is specified the software will open the Gui "
             "panel on startup")

    parser.add_argument(
        '--no-startup-slides',
        dest='startupslides', action='store_false',
        help="Whether to show the presentation slides at startup.")

    parser.add_argument(
        '-d', '--develop',
        help='Enable develop mode', action='store_true')

    parser.add_argument(
        '--restart-count',
        dest='restartcount', help='Internal use', type=int, default=0,
        metavar="<restart count>")

    parser.add_argument(
        '--no-hard-reset',
        dest='hardreset_allowed', help='disable automatic restart of the '
                                       'application upon internal faults',
        action='store_false', default=True)

    # Just parse known options
    args, _ = parser.parse_known_args()

    application = Application(
        args.develop, args.bugreport, args.configdir, args.startupslides,
        args.restartcount, args.hardreset_allowed, args.showpanel,
        args.interface, get_command_line(), 'filerock.py')

    application.main_loop()

    # Despite our efforts, it still happens to have hanging threads.
    # We use _exit() as a temporary fix to make the application close.
    os._exit(0)


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = PlatformSettingsBase
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the PlatformSettingsBase module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging, os

class PlatformSpecificSettingsBase(object):

     # List of arguments that shall never go into autostart command string
    BLACKLISTED_ARGUMENTS = [
        u"--restart-count",
        u"-d"
    ]

    def __init__(self, *args, **kdws):
        self.cmdline_args = kdws['cmdline_args']
        self.logger = logging.getLogger("FR.%s" % self.__class__.__name__)

    def set_autostart(self, enable):
        """ Enable/disable client start on system startup """
        assert False, u"Unimplemented method set_autostart() called"

    def is_systray_icon_whitelisted(self):
        """ Check if tray icon will be visible (Ubuntu with Unity only) """
        assert False, u"Unimplemented method is_systray_icon_whitelisted() called"


    def whitelist_tray_icon(self):
        """ Sets client tray icon visible (Ubuntu with Unity only) """
        assert False, u"Unimplemented method whitelist_tray_icon() called"

    def _get_command_string(self):
        """
        Returns a string representing command line to start
        FileRock client, possibly stripping some unwanted args

        Might be overridden by PlatformSettings* classes
        """

        # Get filtered cmd line args
        arguments = self._filter_cmd_line_args(self.cmdline_args)

        # Ugly trick to patch relative path related issues
        # Abs-pathize everything that looks like a valid path
        arguments = map(
            lambda arg : os.path.abspath(arg) if not arg.startswith("-") and os.path.exists(arg) else arg,
            arguments
        )

        return " ".join(arguments).strip()


    def _filter_cmd_line_args(self, arguments):
        """
        Return a filtered list of cmd line args, which will
        be added to the launch agent plist file

        Might be overridden by PlatformSettings* classes
        """

        # Just strips everything that starts with a "-"
        # TODO: implement a smarter cmdline argument filtering strategy
        return filter(lambda arg: not arg.startswith("-"), arguments)


########NEW FILE########
__FILENAME__ = PlatformSettingsLinux
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the PlatformSettingsLinux module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.osconfig.PlatformSettingsBase import PlatformSpecificSettingsBase

import os



class PlatformSettingsLinux(PlatformSpecificSettingsBase):


    # Autostart handling is defined according to FreeDesktop Standard
    # http://standards.freedesktop.org/autostart-spec/autostart-spec-latest.html

    # Desktop entry location
    DESKTOP_ENTRY_FILENAME = u'filerock-client.desktop'
    DESKTOP_ENTRY_DIR = u'data'
    # XDG_CONFIG_HOME environment variable
    XDG_CONFIG_HOME_ENV = u'XDG_CONFIG_HOME'
    # Fallback value if XDG_CONFIG_HOME env var is not set
    XDG_CONFIG_HOME_FALLBACK = os.path.expanduser('~/.config')
    # Unity panel GSettings schema
    UNITY_PANEL_SCHEMA = u'com.canonical.Unity.Panel'
    # Unity panel whitelist key
    UNITY_PANEL_SYSTRAY_WHITELIST = u'systray-whitelist'

    # List of entries to be written into desktop file
    DESKTOP_FILE_ENTRIES = [
        u"[Desktop Entry]",
        u"Exec=%(executable_path)s",
        u"Name=FileRock",
        u"StartupNotify=true",
        u"Terminal=false",
        u"Type=Application",
        u"Categories=Network;",
        u"Icon=filerock-client",
        u"Comment=FileRock client",
        u"Hidden=%(disabled)s"
    ]

   

    def set_autostart(self, enable):
        """ Sets/Unsets Linux autostart entry """
        xdg_autostart_dir = os.path.join(
            os.getenv(self.XDG_CONFIG_HOME_ENV, self.XDG_CONFIG_HOME_FALLBACK),
            'autostart')

        if not os.path.exists(xdg_autostart_dir):
            try: os.makedirs(xdg_autostart_dir)
            except Exception as e:
                self.logger.warning(u"Could not create dir %s: %s" % (xdg_autostart_dir, e))
                return

        
        desktop_entry_pathname = os.path.join(xdg_autostart_dir, self.DESKTOP_ENTRY_FILENAME)

        try:
            self._write_desktop_entry_file(desktop_entry_pathname, enable)
        except Exception as e:
            self.logger.warning("Could not update desktop entry file: %s" % e)


    def is_systray_icon_whitelisted(self):
        """
        Check if FileRock client is listed in tray whitelisted application,
        looking in GSettings entry com.canonical.Unity.Panel systray-whitelist
        """

        try:
            from gi.repository import Gio, GLib
        except ImportError:
            return True

        # If current DE isn't "Unity", just return True
        if not os.getenv('XDG_CURRENT_DESKTOP','') == 'Unity': return True

        # Check if UNITY_PANEL_SCHEMA is whitin GSettings schema
        # (not doing so may cause a crash when calling Gio.Settings.new() )
        
        if not self.UNITY_PANEL_SCHEMA in Gio.Settings.list_schemas():
            self.logger.warning(u'%s schema is not listed between valid schemas, skipping whitelist procedure...' % self.UNITY_PANEL_SCHEMA)
            return True

        # Create GSettings instance
        gsettings = Gio.Settings.new(self.UNITY_PANEL_SCHEMA)

        # Check if UNITY_PANEL_SYSTRAY_WHITELIST key is within current schema keys
        # (not doing so may cause a crash when calling get/set value methods)
        # Note: if whitelist contains "all" keyword, then any application is allowed
        # in the systray
        if  not self.UNITY_PANEL_SYSTRAY_WHITELIST in gsettings.list_keys():
            self.logger.warning(u'%s key not found in %s, skipping whitelist procedure...' % (self.UNITY_PANEL_SYSTRAY_WHITELIST, self.UNITY_PANEL_SCHEMA))
            return True

        whitelisted_applications = gsettings.get_value(self.UNITY_PANEL_SYSTRAY_WHITELIST).dup_strv()[0]

        return 'FileRock' in whitelisted_applications or \
                'all' in whitelisted_applications


    def whitelist_tray_icon(self):
        """
        Adds FileRock client to Ubuntu Unity whitelisted tray applications,
        editing GSettings entry com.canonical.Unity.Panel systray-whitelist
        """

        try:
            from gi.repository import Gio, GLib
        except ImportError:
            return True

        # Create GSettings instance
        gsettings = Gio.Settings.new(self.UNITY_PANEL_SCHEMA)

        # TODO: check if key is writable

        # Get systray whitelisted applications (as a list)
        # see also http://developer.gnome.org/glib/stable/glib-GVariant.html
        whitelisted_applications = gsettings.get_value(self.UNITY_PANEL_SYSTRAY_WHITELIST).dup_strv()[0]
        whitelisted_applications.append('FileRock')
        gsettings.set_value(self.UNITY_PANEL_SYSTRAY_WHITELIST, GLib.Variant.new_strv(whitelisted_applications))
        gsettings.sync()

    def _write_desktop_entry_file(self, desktop_entry_pathname, enabled):
        """
        Writes desktop entry file content, with the help of a SafeConfigParser
        object (which is capable of writing ini-style files)
        """
        config = "\n".join(self.DESKTOP_FILE_ENTRIES) % {
                                'executable_path': self._get_command_string(),
                                'disabled': str(not enabled).lower()
                            }
        with open(desktop_entry_pathname,'w') as desktop_file_fp:
            desktop_file_fp.write(config)



        



########NEW FILE########
__FILENAME__ = PlatformSettingsOSX
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the PlatformSettingsOSX module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os
from filerockclient.osconfig.PlatformSettingsBase import PlatformSpecificSettingsBase
from xml.dom.minidom import Document, getDOMImplementation

class PlatformSettingsOSX(PlatformSpecificSettingsBase):

    # Client identifier
    LAUNCH_AGENT_BUNDLE_ID = u"com.filerock.client"
    # User's launch agents path
    LAUNCH_AGENTS_DIR = os.path.expanduser(u"~/Library/LaunchAgents")

    
    def __init__(self, *args, **kdws):
        super(PlatformSettingsOSX, self).__init__(*args, **kdws)
        # Set launch agent plist filename
        self.LAUNCH_AGENT_PLIST_FILENAME = u"%(bundle_id)s.plist" % {
                                            'bundle_id' : self.LAUNCH_AGENT_BUNDLE_ID
                                            }

    def set_autostart(self, enable):
        """
        A LaunchAgent is created to start the client when user logs in;
        agent is create writing a plist file into ~/Library/LaunchAgents
        directory
        """
        self.logger.debug(u"set_autostart() called, enable: %s" % enable)

        agent_path = os.path.join(self.LAUNCH_AGENTS_DIR, self.LAUNCH_AGENT_PLIST_FILENAME)


        # Try to create launch agents directory if it doesn't exists
        if not os.path.exists(self.LAUNCH_AGENTS_DIR):
            try:
                os.makedirs(self.LAUNCH_AGENTS_DIR, 0755)
            except Exception as e:
                self.logger.warning(u"Could not create launch agent directory: %s" % e)
                return


        # Actually write launch agent plist file
        try:
            with open(agent_path, "w") as plist:
                plist.write(self._get_launch_agent_content(enable))
        except Exception as e:
            self.logger.warning(u"Error applying autostart settings (enable=%s): %s"
                                    % (enable, e))


    def _get_launch_agent_content(self, enable):
        """
        Returns XML content of launch agent plist file
        """

        imp = getDOMImplementation()
        doctype = imp.createDocumentType("plist", "-//Apple//DTD PLIST 1.0//EN", "http://www.apple.com/DTDs/PropertyList-1.0.dtd")

        doc = imp.createDocument(None,"plist",doctype)
        doc.documentElement.setAttribute("version","1.0")

        dict_elem = doc.createElement("dict")


        label_key_elem = doc.createElement("key")
        label_key_elem.appendChild(doc.createTextNode("Label"))

        label_string_elem = doc.createElement("string")
        label_string_elem.appendChild(doc.createTextNode(self.LAUNCH_AGENT_BUNDLE_ID))

        prog_args_key_elem = doc.createElement("key")
        prog_args_key_elem.appendChild(doc.createTextNode("ProgramArguments"))

        args_array_elem = doc.createElement("array")


        for argument in self._filter_cmd_line_args(self.cmdline_args):
            arg_string_elem = doc.createElement("string")
            arg_string_elem.appendChild(doc.createTextNode(argument))
            args_array_elem.appendChild(arg_string_elem)


        run_at_load_key = doc.createElement("key")
        run_at_load_key.appendChild(doc.createTextNode("RunAtLoad"))
        run_at_load_true = doc.createElement(str(enable).lower())

        dict_elem.appendChild(label_key_elem)
        dict_elem.appendChild(label_string_elem)
        dict_elem.appendChild(prog_args_key_elem)
        dict_elem.appendChild(args_array_elem)
        dict_elem.appendChild(run_at_load_key)
        dict_elem.appendChild(run_at_load_true)

        doc.documentElement.appendChild(dict_elem)

        return doc.toxml(encoding='utf-8')



    def _filter_cmd_line_args(self, arguments):
        """
        Overrides PlatformSettingsBase._filter_cmd_line_args
        Do not filter pass -i386 argument
        """

        return filter(lambda arg: not arg.startswith("-") or arg == '-i386', arguments)

        

    def is_systray_icon_whitelisted(self):
        self.logger.debug(u"is_systray_icon_whitelisted() method not implemented")
        return True

    def whitelist_tray_icon(self):
        self.logger.debug(u"whitelist_tray_icon() method not implemented")
########NEW FILE########
__FILENAME__ = PlatformSettingsWindows
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the PlatformSettingsWindows module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import _winreg, os

from filerockclient.osconfig.PlatformSettingsBase import PlatformSpecificSettingsBase

class PlatformSettingsWindows(PlatformSpecificSettingsBase):


    AUTORUN_KEY = r"Software\Microsoft\Windows\CurrentVersion\Run"
    AUTORUN_APPLICATION_NAME = r"FileRock Client"


    def _get_command_string(self):
        """
        Overrides  PlatformSettingsBase._get_command_string()

        Double quote every command line argument
        """

        # Get filtered cmd line args
        arguments = self._filter_cmd_line_args(self.cmdline_args)

        # Ugly trick to patch relative path related issues
        # Abs-pathize everything that looks like a valid path
        arguments = map(
            lambda arg : os.path.abspath(arg) if not arg.startswith("-") and os.path.exists(arg) else arg,
            arguments
        )

        # Double quote every param
        arguments = map(
            lambda arg : '"%s"' % arg,
            arguments
        )

        return " ".join(arguments).strip()

    def set_autostart(self, enable):
        
        self.logger.debug(u"set_autostart() called, enable: %s" % enable)

        try:
            if enable: self._create_autostart_entry()
            else: self._delete_autostart_entry()
        except Exception as e:
            self.logger.warning(u"Error applying autostart settings (enable=%s): %s"
                                    % (enable, e))

    def _autostart_entry_exists(self):
        """
        Check if autostart entry exists within Windows registry.
        @return True/False
        """
        
        with self._open_key_handle(self.AUTORUN_KEY) as key_handle:
            try:
                _winreg.QueryValueEx(   key_handle, 
                                        self.AUTORUN_APPLICATION_NAME
                                    )
            except WindowsError as e:
                self.logger.debug(u"Key in %s doesn't exists" % self.AUTORUN_KEY)
                return False
            else:
                self.logger.debug(u"Key in %s already exists" % self.AUTORUN_KEY)
                return True


    def _create_autostart_entry(self):
        """
        Creates autostart entry for current user within Windows registry
        """
        self.logger.debug(u"Creating registry key in %s: (%s : %s)" %
                                                (self.AUTORUN_KEY,
                                                self.AUTORUN_APPLICATION_NAME,
                                                self._get_command_string())
                        )

    
        with self._create_key_handle(self.AUTORUN_KEY) as key_handle:
            try:
                _winreg.SetValueEx( key_handle, 
                                    self.AUTORUN_APPLICATION_NAME,
                                    0,
                                    _winreg.REG_SZ,
                                    self._get_command_string()
                                    )
            except Exception as e:
                self.logger.warning(u"Error creating autostart registry key: %s" % e)

    def _delete_autostart_entry(self):
        """
        Deletes autostart entry for current user within Windows registry
        """

        self.logger.debug(u"Removing registry key %s" % self.AUTORUN_KEY)

        if not self._autostart_entry_exists() : return

        with self._open_key_handle(self.AUTORUN_KEY) as key_handle:
            try:
                _winreg.DeleteValue(key_handle, 
                                    self.AUTORUN_APPLICATION_NAME
                                    )
            except Exception as e:
                self.logger.warning(u"Error removing autostart registry key: %s" % e)

    def _open_key_handle(self, key):
        """
        Open an handle for given registry HKCU\@key
        """

        return _winreg.OpenKey(_winreg.HKEY_CURRENT_USER,
                                key, 
                                0,
                                _winreg.KEY_ALL_ACCESS
                                )

    def _create_key_handle(self, key):
        """
        Open an handle for given registry HKCU\@key (possibly creating if it
        doesn't exists)
        """
        return _winreg.CreateKey(_winreg.HKEY_CURRENT_USER,
                                key
                                )

    def is_systray_icon_whitelisted(self):
        self.logger.debug(u"is_systray_icon_whitelisted() method not implemented")
        return True

    def whitelist_tray_icon(self):
        self.logger.debug(u"whitelist_tray_icon() method not implemented")
########NEW FILE########
__FILENAME__ = pathname_operation
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the pathname_operation module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import pickle

# Note: keep this class picklable


class PathnameOperation(object):

    def __init__(self, application, lock, verb, pathname, oldpath=None, 
                 etag=None, size=None, lmtime=None, conflicted=False):
        '''
        @param application: the main application class, it is needed to call notify_pathname_status_change() on it
        @type application: HeyDriveClient

        @param verb: it can be one in 'UPLOAD', 'DELETE', 'REMOTE_COPY', 'DOWNLOAD', 'DELETE_LOCAL'
        @type verb: str

        @param pathname: the pathname for this operation
        @type pathname: unicode

        @param oldpath: the pathname from which the content is taken, meaningful only for REMOTE_COPY
        @type oldpath: unicode

        '''

        assert verb in set({'UPLOAD',
                            'DELETE',
                            'REMOTE_COPY',
                            'DOWNLOAD',
                            'DELETE_LOCAL'})
        assert pathname.__class__.__name__ == "unicode"
        
        assert (not verb == 'REMOTE_COPY') \
        or (oldpath and oldpath.__class__.__name__ == "unicode")

        self.application = application
        self.state = 'working'
        ''' 
        The state of this pathname, it can be only 'working',
        'aborted', 'completed', 'rejected'
        '''

        self.to_encrypt = False
        self.to_decrypt = False
        self.encrypted_pathname = None
        self.encrypted_fd = None
        self.temp_pathname = None
        self.temp_fd = None
        self.extras = {}
        self.conflicted = conflicted

        self.verb = verb
        self.pathname = pathname

        if oldpath is not None:
            self.oldpath = oldpath
        if etag is not None:
            self.storage_etag = etag
            self.warebox_etag = etag
        if size is not None:
            self.storage_size = size
            self.warebox_size = size
        if lmtime is not None:
            self.lmtime = lmtime
        self.lock = lock
        self.abort_handlers = []
        self.complete_handlers = []
        self.reject_handlers = []

    def is_directory(self):
        return self.pathname.endswith('/')

    def is_working(self): return self.state == 'working'
    def is_aborted(self): return self.state == 'aborted'
    def is_completed(self): return self.state == 'completed'
    def is_rejected(self): return self.state == 'rejected'

    def register_abort_handler(self, handler):
        self.abort_handlers.append(handler)
        
    def register_complete_handler(self, handler):
        self.complete_handlers.append(handler)

    def register_reject_handler(self, handler):
        self.reject_handlers.append(handler)

    def unregister_abort_handler(self, handler):
        self.abort_handlers.remove(handler)

    def unregister_complete_handler(self, handler):
        self.complete_handlers.remove(handler)

    def unregister_reject_handler(self, handler):
        self.reject_handlers.remove(handler)

    def _raise_event(self, event):
        with self.lock:
#             logger = logging.getLogger("FR."+self.__class__.__name__)
            if self.state == 'working':
                self.state = event + 'ed' if not event.endswith('e') else event + 'd'
                for handler in getattr(self, '%s_handlers' % event):
                    handler(self)
                return True
            else:
                return False

    def complete(self):
        self._raise_event('complete')
    
    def abort(self):
        self._raise_event('abort')
    
    def reject(self):
        self._raise_event('reject')

    def notify_pathname_status_change(self, newStatus, extras={}):
        self.extras.update(extras)
        self.application.notify_pathname_status_change(self.pathname,
                                                       newStatus,
                                                       self.extras)

    def __repr__(self):
        tokens = []
        tokens.append(u"verb: %s" % self.verb)
        tokens.append(u'pathname: "%s"' % self.pathname)

        if self.verb == 'REMOTE_COPY':
            tokens.append(u'oldpath: "%s"' % self.oldpath)

        tokens.append(u"state: %s" % self.state)

        v = self.warebox_etag if hasattr(self, 'warebox_etag') else None
        tokens.append(u"warebox_etag: %s" % v)

        v = self.warebox_size if hasattr(self, 'warebox_size') else None
        tokens.append(u"warebox_size: %s" % v)

        v = self.lmtime if hasattr(self, 'lmtime') else None
        tokens.append(u"lmtime: %s" % v)

        v = self.storage_size if hasattr(self, 'storage_size') else None
        tokens.append(u"storage_size: %s" % v)

        v = self.storage_etag if hasattr(self, 'storage_etag') else None
        tokens.append(u"storage_etag: %s" % v)

        v = self.temp_pathname if hasattr(self, 'temp_pathname') else None
        tokens.append(u'temp_pathname: "%s"' % v)

        v = self.encrypted_pathname if hasattr(self, 'encrypted_pathname') else None
        tokens.append(u'encrypted_pathname: "%s"' % v)

        v = self.iv if hasattr(self, 'iv') else None
        tokens.append(u"iv: %s" % v)

        result = u"PathnameOperation(%s)" % u", ".join(tokens)
        return result

    def __getstate__(self):
        '''Called on pickling'''
        state = self.__dict__.copy()
        # Handle standard nonpicklable attributes
        state['lock'] = None
        state['abort_handlers'] = []
        state['complete_handlers'] = []
        state['reject_handlers'] = []
        state['application'] = None
        # Remove nonstandard nonpicklable attributes
        to_delete = []
        for k, v in state.iteritems():
            try: pickle.dumps(v)
            except: to_delete.append(k)
        for k in to_delete:
            del state[k]
        return state

    def __setstate__(self, state):
        '''Called on unpickling'''
        self.__dict__ = state


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = commands
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Commands to be sent to ServerSession.

Just put one in its input queue.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.exceptions import FileRockException


class UnknownCommandError(FileRockException):

    def __init__(self, name):
        FileRockException.__init__(self)
        self.name = name

    def __str__(self):
        return "%s(%s)" % (self.__class__.__name__, self.name)


KNOWN_COMMANDS = [
    'BROKENCONNECTION',
    'KEEPALIVETIMEDOUT',
    'CONNECT',
    'USERCOMMIT',
    'DISCONNECT',
    'WORKERFREE',
    'TERMINATE',
    'CHANGESTATE',
    'HANDSHAKE',
    'COMMIT',
    'REDECLAREOPERATION',
    'USERCOMMIT',
    'OPERATIONSFINISHED',
    'GOTOONCOMPLETION',
    'UPDATEBEFOREREPLICATION',
    'STARTSYNCPHASE',
    'INTEGRITYERRORONDOWNLOAD',
    'INTEGRITYERRORONDELETELOCAL'
]


class Command(object):

    def __init__(self, name):
        if name not in KNOWN_COMMANDS:
            raise UnknownCommandError(name)
        self.name = name


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = connection_handling
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the connection_handling module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
import threading
from select import select

from FileRockSharedLibraries.Communication.Messages import POISON_PILL, unpack
from filerockclient.exceptions import ConnectionException

from filerockclient.serversession.commands import Command


class ServerConnectionWriter(threading.Thread):
    MESSAGE_LENGTH_DESCRIPTOR_LENGTH = 32

    def __init__(self, session_queue, output_message_queue, sock):
        threading.Thread.__init__(self, name=self.__class__.__name__)
        self._session_queue = session_queue
        self.output_message_queue = output_message_queue
        self.sock = sock
        self.must_die = threading.Event()
        self.started = False
        self.logger = logging.getLogger("FR.%s" % self.__class__.__name__)

    def run(self):
        self.started = True
        try:
            msg = None
            while not self._termination_requested():
                if msg == None:
                    msg = self.output_message_queue.get()
                if msg == POISON_PILL:
                    continue
                _, ready, _ = select([], [self.sock], [], 1)
                if ready:
                    self._send_message(msg)
                    msg = None
        except Exception as exception:
            self.logger.warning(
                u"Detected a connection problem, aborting: %s", exception)
            self._session_queue.put(
                Command('BROKENCONNECTION'), 'sessioncommand')

    def _send_message(self, msg):
        if msg.name != 'KEEP_ALIVE':
            self.logger.debug(u"Sending message %r", msg)
        # Pack & pad message
        msg_length, message = msg.pack()
        msg_length_padded = self._pad(
            str(msg_length), self.MESSAGE_LENGTH_DESCRIPTOR_LENGTH)
        # First send message length
        totalsent = 0
        while totalsent < len(msg_length_padded):
            sent = self.sock.send(msg_length_padded[totalsent:])
            if sent == 0:
                raise ConnectionException(
                    'Unable to write all the bytes to the socket.')
            totalsent += sent
        # Then send packed message
        totalsent = 0
        while totalsent < len(message):
            sent = self.sock.send(message[totalsent:])
            if sent == 0:
                raise ConnectionException(
                    'Unable to write all the bytes to the socket.')
            totalsent += sent

    def _pad(self, blob, length):
        """
        Returns a padded version of the passed blob which has the
        indicated length.
        @blob: the data to be padded
        @length: the length to be reached
        """
        if len(blob) > length:
            raise Exception('invalid length')
        elif len(blob) == length:
            return blob
        else:
            return '%s%s' % (blob, ' ' * (length - len(blob)))

    def terminate(self):
        '''
        Shutdown procedure.
        '''
        self.logger.debug(u"Terminating Server Connection Writer...")
        if self.started:
            self.must_die.set()
            self.output_message_queue.put(POISON_PILL)
            self.join() if self is not threading.current_thread() else None
        self.logger.debug(u"Server Connection Writer terminated.")

    def _termination_requested(self):
        return self.must_die.wait(0.01)


class ServerConnectionReader(threading.Thread):
    MESSAGE_LENGTH_DESCRIPTOR_LENGTH = 32

    def __init__(self, input_message_queue, input_keepalive_queue, sock):
        threading.Thread.__init__(self, name=self.__class__.__name__)
        self.input_message_queue = input_message_queue
        self.input_keepalive_queue = input_keepalive_queue
        self.sock = sock
        self.must_die = threading.Event()
        self.started = False
        self.logger = logging.getLogger("FR.%s" % self.__class__.__name__)

    def run(self):
        self.started = True
        try:
            while not self._termination_requested():
                ready, _, _ = select([self.sock], [], [], 1)
                if ready:
                    msg = self._receive_message()
                    if msg.name == 'KEEP_ALIVE':
                        self.input_keepalive_queue.put(msg)
                    else:
                        self.input_message_queue.put(msg, 'servermessage')
        except ConnectionException:
            self.logger.info(u"Server has closed the connection, aborting")
            self.input_message_queue.put(
                Command('BROKENCONNECTION'), 'sessioncommand')
        except Exception as e:
            self.logger.warning(
                u"Detected a connection problem, aborting: %s", e)
            self.input_message_queue.put(
                Command('BROKENCONNECTION'), 'sessioncommand')

    def _receive_message(self):

        # Reads expected message length, reading
        # MESSAGE_LENGTH_DESCRIPTOR_LENGTH bytes
        msg_length = ''
        while len(msg_length) < self.MESSAGE_LENGTH_DESCRIPTOR_LENGTH:
            chunk = self.sock.recv(
                self.MESSAGE_LENGTH_DESCRIPTOR_LENGTH - len(msg_length))
            if len(chunk) == 0:
                raise ConnectionException("Server has closed the connection.")
            msg_length += chunk
        msg_length = msg_length.strip()
        msg_length = int(msg_length)

        # Reads msg_length bytes
        msg = ''
        while len(msg) < msg_length:
            chunk = self.sock.recv(msg_length - len(msg))
            if len(chunk) == 0:
                raise ConnectionException("Server has closed the connection.")
            msg += chunk
        msg = unpack(msg)
        if msg.name != 'KEEP_ALIVE':
#            self.logger.debug(u"Received message %r", msg)
            pass
        return msg

    def terminate(self):
        '''
        Shutdown procedure.
        '''
        self.logger.debug(u"Terminating Server Connection Reader...")
        if self.started:
            self.must_die.set()
            self.join() if self is not threading.current_thread() else None
        self.logger.debug(u"Server Connection Reader terminated.")

    def _termination_requested(self):
        return self.must_die.wait(0.01)


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = connection_lifekeeper
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the connection_lifekeeper module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
import threading
import Queue

from FileRockSharedLibraries.Communication.Messages import \
    POISON_PILL, KEEP_ALIVE
from filerockclient.serversession.commands import Command
from filerockclient.util.suspendable_thread import SuspendableThread


class ConnectionLifeKeeper(SuspendableThread):

    def __init__(
            self, session_queue, input_message_queue, output_message_queue,
            start_suspended=False):

        SuspendableThread.__init__(
            self, start_suspended, name=self.__class__.__name__)
        self.logger = logging.getLogger("FR." + self.__class__.__name__)
        self._session_queue = session_queue
        self.input_message_queue = input_message_queue
        self.output_message_queue = output_message_queue
        self.interval = threading.Event()
        self.must_die = threading.Event()
        self.keepalive_id = 0
        self.timeout_time = 60

    def _main(self):
        while not self.must_die.is_set():
            self._exchange_keepalive_message()
            self.interval.wait(self.timeout_time)

    def _exchange_keepalive_message(self):
        #self.logger.debug(
        #    u"Sending KEEP_ALIVE id=%s to server" % self.keepalive_id)
        self.output_message_queue.put(
            KEEP_ALIVE('KEEP_ALIVE', {'id': self.keepalive_id}))
        self.keepalive_id += 1
        if self.keepalive_id > 99999:
            self.keepalive_id = 1
        try:
            while True:
                message = self.input_message_queue.get(
                    block=True, timeout=self.timeout_time)
                if message is POISON_PILL:
                    break
                if message.getParameter('id') == self.keepalive_id - 1:
                    break
        except Queue.Empty:
            self.logger.warning(
                u"Server hasn't replied to KEEP_ALIVE in %s seconds,"
                " assuming crash." % self.timeout_time)
            self._session_queue.put(
                Command('KEEPALIVETIMEDOUT'), 'sessioncommand')
            return
        # Have we been woken up due to suspension?
        if not self._check_suspension():
            # No, it was a normal KEEP_ALIVE reply from the server
            ##self.logger.debug(
            ##    u"Received KEEP_ALIVE reply id=%s from server"
            ##    % (message.getParameter('id')))
            pass

    def _interrupt_execution(self):
        self.input_message_queue.put(POISON_PILL)
        self.interval.set()

    def _clear_interruption(self):
        self.interval.clear()

    def terminate(self):
        self.logger.debug(u"Terminating ConnectionLifeKeeper...")
        self.must_die.set()
        self._terminate_suspension_handling()
        self.input_message_queue.put(POISON_PILL)
        self.interval.set()
        self.join()
        self.logger.debug(u"ConnectionLifeKeeper terminated")


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = server_session
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
The thread that controls the communication with the server and the
internal execution of the client.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
import threading
import socket
import os
import ssl
import Queue
import traceback

from filerockclient.util.utilities import stoppable_exponential_backoff_waiting
from filerockclient.workers.worker_pool import WorkerPool
from filerockclient.databases.transaction_cache import TransactionCache
from filerockclient.serversession.transaction import Transaction
from filerockclient.serversession.transaction_manager import TransactionManager
from filerockclient.integritycheck.IntegrityManager import IntegrityManager
from filerockclient.workers.filters.encryption.adapter import Adapter
from filerockclient.exceptions import UnexpectedMessageException
from filerockclient.exceptions import ProtocolException
from filerockclient.serversession.connection_lifekeeper import \
    ConnectionLifeKeeper
from filerockclient.serversession.connection_handling import \
    ServerConnectionWriter, ServerConnectionReader
from filerockclient.serversession.states.register import StateRegister
from filerockclient.interfaces import GStatuses
from filerockclient.serversession.commands import Command
from filerockclient.util.match_hostname import match_hostname, CertificateError


MAX_CONNECTION_ATTEMPTS = 5


class ServerSession(threading.Thread):
    """
    The thread that controls the communication with the server and the
    internal execution of the client.

    ServerSession is the intelligent part of the client application. It
    is implemented as an event-loop machine, receiving events from many
    sources: the user, ServerSession itself, other application
    components and the server, each with a different priority level. It
    decides, for example, when to handle operations for synchronizing
    data and when to answer to messages from the server, thus
    implementing the communication protocol.
    The logic is implemented as an object-oriented state machine, which
    decides which events to handle in each state and how to do it.
    ServerSession is both a container (formally a "context") for "state"
    objects and the only public interface of this component. The context
    gives the states a shared memory space and access to other
    components.
    All the logic is actually implemented in the state objects, limiting
    ServerSession to execute the "current state". State objects also
    decide when to switch to another state, as a reaction to an input
    event. The states are implemented using object-oriented inheritance
    in order to common factor the logic of several states, making
    ServerSession precisely a "Hierarchical State Machine".
    See the "State" design pattern from the book: Gamma et al, "Design
    Patterns: Elements of Reusable Object-Oriented Software" for a
    reference to the design.
    """

    def __init__(self,
            cfg, warebox, storage_cache,
            startup_synchronization, filesystem_watcher, linker,
            metadata_db, hashes_db, internal_facade, ui_controller,
            lockfile_fd, auto_start, input_queue, scheduler):
        """
        @param cfg:
                    Instance of filerockclient.config.ConfigManager.
        @param warebox:
                    Instance of filerockclient.warebox.Warebox.
        @param storage_cache:
                    Instance of filerockclient.databases.storage_cache.
                    StorageCache.
        @param startup_synchronization:
                    Instance of filerockclient.serversession.
                    startup_synchronization.
        @param filesystem_watcher:
                    Instance of any class in the filerockclient.
                    filesystem_watcher package.
        @param linker:
                    Instance of filerockclient.linker.Linker.
        @param metadata_db:
                    Instance of filerockclient.databases.metadata.
                    MetadataDB.
        @param hashes_db:
                    Instance of filerockclient.databases.hashes.HashesDB.
        @param internal_facade:
                    Instance of filerockclient.internal_facade.
                    InternalFacade.
        @param ui_controller:
                    Instance of filerockclient.ui.ui_controller.
                    UIController.
        @param lockfile_fd:
                    File descriptor of the lock file which ensures there
                    is only one instance of FileRock Client running.
                    Child processes have to close it to avoid stale locks.
        @param auto_start:
                    Boolean flag telling whether ServerSession should
                    connect to the server when started.
        @param input_queue:
                    Instance of filerockclient.util.multi_queue.
                    MultiQueue. It is expected to have the following
                    queues:
                    usercommand: Commands sent by the user
                    sessioncommand: ServerSession internal use commands
                    systemcommand: Commands sent by other client components
                    servermessage: Messages sent by the server.
                    operation: PathnameOperation objects to handle
        @param scheduler:
                    Instance of filerockclient.util.scheduler.Scheduler.
        """

        threading.Thread.__init__(self, name=self.__class__.__name__)
        self.logger = logging.getLogger("FR.%s" % self.__class__.__name__)
        self._input_queue = input_queue
        self.warebox = warebox
        self.startup_synchronization = startup_synchronization
        self.filesystem_watcher = filesystem_watcher
        self._internal_facade = internal_facade
        self._ui_controller = ui_controller
        self.metadataDB = metadata_db
        self.hashesDB = hashes_db
        self.auto_start = auto_start
        self._scheduler = scheduler
        self.storage_cache = storage_cache
        self.linker = linker
        self.warebox = warebox
        self.cfg = cfg
        self._lockfile_fd = lockfile_fd

        self._started = False
        self.must_die = threading.Event()
        # TODO: this flag exists due to auto-disconnection. It will be removed
        # and replaced by a CONNECTFORCE command as soon as ServerSession will
        # stop going automatically to DisconnectedState.
        self.disconnect_other_client = False
        self.operation_responses = {}
        self._pathname2id = {}
        self.output_message_queue = Queue.Queue()
        self.input_keepalive_queue = Queue.Queue()
        self.current_state = None
        self.reconnection_time = 1
        self.num_connection_attempts = 0
        self.max_connection_attempts = MAX_CONNECTION_ATTEMPTS
        self._basis_lock = threading.Lock()
        self.server_basis = None
        self.session_id = None
        self.storage_ip_address = None
        self.refused_declare_count = 0
        self._current_basis = None
        self.id = 0
        self._sync_operations = []

        self.keepalive_timer = ConnectionLifeKeeper(
                                self._input_queue, self.input_keepalive_queue,
                                self.output_message_queue, True)
        self.transaction = Transaction()
        self.transaction_manager = TransactionManager(
                                          self.transaction, self.storage_cache)

        StateRegister.setup(self)

        self.client_id = None
        self.username = None
        self.priv_key = None
        self.host = None
        self.port = None
        self.server_certificate = None
        self.storage_hostname = None
        self.refused_declare_max = None
        self.refused_declare_waiting_time = None
        self.commit_threshold_seconds = None
        self.commit_threshold_operations = None
        self.commit_threshold_bytes = None
        self.transaction_cache = None
        self.integrity_manager = None
        self.cryptoAdapter = None
        self.temp_dir = None
        self.connection_reader = None
        self.connection_writer = None
        self.sock = None
        self.listening_operations = False

        self.reload_config_info()

    def reload_config_info(self):
        """
        Refresh the configuration values.

        Reload the configuration, get configuration values from self.cfg
        and set them as attributes of self.
        To be called at least once.
        """
        # TODO: merge this method into the constructor, there is no reason to
        # keep it separated anymore.

        self.cfg.load()

        self.client_id = self.cfg.get('User', 'client_id')
        self.username = self.cfg.get('User', 'username')
        self.priv_key = self.cfg.get('Application Paths', 'client_priv_key_file')
        self.host = self.cfg.get('System', 'server_hostname')
        self.port = self.cfg.getint('System', 'server_port')
        self.server_certificate = self.cfg.get('Application Paths', 'server_certificate')
        self.storage_hostname = self.cfg.get('System', 'storage_endpoint')

        self.refused_declare_max = self.cfg.getint(
            'System', 'refused_declare_max')
        self.refused_declare_waiting_time = self.cfg.getint(
            'System', 'refused_declare_waiting_time')
        self.commit_threshold_seconds = self.cfg.getint(
            'Client', 'commit_threshold_seconds')
        self.commit_threshold_operations = self.cfg.getint(
            'Client', 'commit_threshold_operations')
        self.commit_threshold_bytes = self.cfg.getint(
            'Client', 'commit_threshold_bytes')

        temp = self.cfg.get('Application Paths', 'transaction_cache_db')
        self.transaction_cache = TransactionCache(temp)
        self.integrity_manager = IntegrityManager(None)

        is_firt_startup = self._internal_facade.is_first_startup()

        self.cryptoAdapter = Adapter(self.cfg,
                                     self.warebox,
                                     self._input_queue,
                                     self._lockfile_fd,
                                     enc_dir='enc',
                                     first_startup=is_firt_startup)

        self.worker_pool = WorkerPool(self.warebox,
                                      self,
                                      self.cfg,
                                      self.cryptoAdapter)

        self.temp_dir = self.cryptoAdapter.get_enc_dir()
        self._ui_controller.update_config_info(self.cfg)

    def run(self):
        """Implementation of the threading.Thread.run() method."""
        self._started = True
        try:
            self.worker_pool.start_workers()
            self.keepalive_timer.start()
            self.current_state = StateRegister.get('DisconnectedState')
            curr_basis = self.current_state._load_trusted_basis()
            self.integrity_manager.setCurrentBasis(curr_basis)
            self.logger.info(u'Current basis is: %s' % curr_basis)
            self.current_state._on_entering()
            self._internal_facade.set_global_status(GStatuses.NC_STOPPED)
            if self.auto_start:
                self._input_queue.put(Command('CONNECT'), 'sessioncommand')
            self.cryptoAdapter.start()
            self._scheduler.schedule_action(
                self.check_encrypted_folder, name='check_encrypted_folder',
                seconds=5, repeating=True)

            # The event loop
            self._main_loop()

        except UnexpectedMessageException as e:
            self.logger.critical(
                u"Received an unexpected message from the Server while in "
                u"state '%s': %s. Forcing termination."
                % (self.current_state.__class__, str(e)))
            raise

        except ProtocolException as e:
            self.logger.critical(
                u"Detected an unrecoverable error, forcing termination: %s"
                % str(e))
            # Pre-emptive release, just stop before messing up the server
            self.release_network_resources()
            raise

        except Exception as e:
            self.logger.critical(
                u"Forcing termination due to uncaught exception '%s': %s"
                % (e.__class__, e))
            self.logger.debug(
                u"Last error stacktrace:\n%s" % traceback.format_exc())
            # Pre-emptive release, just stop before messing up the server
            self.release_network_resources()
            raise

    def _main_loop(self):
        """
        The event loop.

        A loop that contiuosly calls the current state of the state
        machine, executing its logic.
        It exits when self.terminate() is called.
        """
        while not self.must_die.is_set():
            next_state = self.current_state.do_execute()
            if next_state != self.current_state:
                self.current_state._on_leaving()
                next_state._on_entering()
                self.current_state = next_state

    def check_encrypted_folder(self):
        """
        Check if encryption preconditions are satisfied, try to
        satisfy them otherwise.

        This method is meant to be asynchronously called by a timer,
        precisely to be registered into self._scheduler.
        """
        if not self.cryptoAdapter.check_precondition(self._ui_controller):
            self._internal_facade.terminate()

    def acquire_network_resources(self):
        """
        Configure a network connection to the server.

        The resulting socket is handled by two instances of
        ServerConnectionReader and ServerConnectionWriter, which are
        created and run as well. It is possibile to send/receive
        message to/from them through the queues self.output_message_queue
        and self._input_queue (servermessage).

        Note: this private method should be actually "protected" for
        the ServerSession states, but Python doesn't have such a
        protection level.
        """
        try:
            self.logger.debug(u"Creating a socket on %s:%s", self.host, self.port)
            sock = socket.create_connection((self.host, self.port), timeout=10)
            ca_chain = os.path.abspath(self.server_certificate)
            self.sock = ssl.wrap_socket(
                sock, cert_reqs=ssl.CERT_REQUIRED, ca_certs=ca_chain,
                ssl_version=ssl.PROTOCOL_TLSv1)
            self.sock.setblocking(True)
            match_hostname(self.sock.getpeercert(), self.host)
        except CertificateError as e:
            self.logger.critical(u"SSL certificate validation failed: %s" % e)
            raise ssl.SSLError(e)
        except socket.error as exception:
            self.logger.debug(u"Error opening SSL socket: %s" % exception)
            self.logger.warning(
                u"Unable to connect, re-trying in %s seconds."
                % self.reconnection_time)
            self.reconnection_time = stoppable_exponential_backoff_waiting(
                self.reconnection_time, self.must_die, 10)
            self.num_connection_attempts += 1
            return False
        except socket.timeout as exception:
            self.logger.debug(u"Socket timeout: %s" % exception)
            self.logger.warning(u"Unable to connect, re-trying in %s seconds."
                                % self.reconnection_time)
            self.reconnection_time = stoppable_exponential_backoff_waiting(
                self.reconnection_time, self.must_die, 10)
            self.num_connection_attempts += 1
            return False
        self.connection_reader = ServerConnectionReader(
            self._input_queue, self.input_keepalive_queue, self.sock)
        self.connection_writer = ServerConnectionWriter(
            self._input_queue, self.output_message_queue, self.sock)
        self.connection_reader.start()
        self.connection_writer.start()
        self.reconnection_time = 1
        return True

    def release_network_resources(self):
        """
        Close the active connection to the server, if any.

        Note: this private method should be actually "protected" for
        the ServerSession states, but Python doesn't have such a
        protection level.
        """
        try:
            self.connection_reader.terminate()
        except AttributeError:
            pass
        try:
            self.connection_writer.terminate()
        except AttributeError:
            pass
        try:
            self.sock.shutdown(socket.SHUT_RDWR)
            self.sock.close()
        except socket.error:
            # Shutdown yelds an error on already closed sockets
            pass
        except AttributeError:
            pass

    def commit(self):
        """Make the client commit the current transaction."""
        self._input_queue.put(Command('USERCOMMIT'), 'usercommand')

    def connect(self):
        """Make the client connect to the server."""
        self._input_queue.put(Command('CONNECT'), 'usercommand')

    def disconnect(self):
        """Make the client disconnect from the client, if connected."""
        # TODO: this method has been temporarly replaced by PAUSE
        self._input_queue.put(Command('DISCONNECT'), 'usercommand')

    def signal_free_worker(self):
        """
        Tell ServerSession that a worker is free to receive new tasks.

        This method is meant to be called by WorkerPool.
        """
        self._input_queue.put(Command('WORKERFREE'), 'systemcommand')

    def signal_download_integrity_error(
            self, operation, reason,
            expected_etag, expected_basis,
            actual_etag, computed_basis):
        """Tell ServerSession that the integrity check of a downloaded
        file has failed.

        This method is meant to be called by Workers.

        @param operation:
                    Instance of PathnameOperation. Remember that it
                    contains also its Proof object.
        @param reason:
                    String shortly describing the error.
        @param expected_etag:
                    The etag the file was expected to have. It's the one
                    communicated by the server in its file list.
        @param expected_basis:
                    The trusted basis. It's the one the user had
                    accepted when the sync started.
        @param actual_etag:
                    The etag the file has turned to have after being
                    downloaded.
        @param computed_basis:
                    The basis returned by the IntegrityManager when
                    computing the given proof object. Possibly None.
        """
        cmd = Command('INTEGRITYERRORONDOWNLOAD')
        cmd.operation = operation
        cmd.proof = operation.download_info['proof']
        cmd.reason = reason
        cmd.expected_etag = expected_etag
        cmd.expected_basis = expected_basis
        cmd.actual_etag = actual_etag
        cmd.computed_basis = computed_basis
        self._input_queue.put(cmd, 'systemcommand')

    def signal_deletelocal_integrity_error(
            self, pathname, proof, reason, expected_basis, computed_basis):
        """Tell ServerSession that the integrity check of a
        pathname to delete locally has failed.

        This method is meant to be called by Workers.

        @param pathname:
                    String representing the pathname.
        @param reason:
                    String shortly describing the error.
        @param expected_basis:
                    The trusted basis. It's the one the user had
                    accepted when the sync started.
        @param computed_basis:
                    The basis returned by the IntegrityManager when
                    computing the given proof object. Possibly None.
        """
        cmd = Command('INTEGRITYERRORONDELETELOCAL')
        cmd.pathname = pathname
        cmd.proof = proof
        cmd.reason = reason
        cmd.expected_basis = expected_basis
        cmd.computed_basis = computed_basis
        self._input_queue.put(cmd, 'systemcommand')

    def get_current_basis(self):
        """
        Return the current trusted basis.

        @return The current trusted basis.
        """
        with self._basis_lock:
            return self._current_basis

    def print_transaction(self):
        """
        Print the list of operations in the current transaction.

        Debug method, it prints to stdout and thus works only when the
        application is attached to a console.
        """
        self.transaction.print_all()

    def terminate(self):
        """
        Termination routine for this component.

        Stops the running thread and releases any acquired resource.
        """
        self.logger.debug(u"Terminating Server Session...")
        if self._started:
            self.must_die.set()
            self.worker_pool.terminate()
            self._input_queue.put(Command('TERMINATE'), 'usercommand')
            self.transaction.can_be_committed.set()
            self.join() if self is not threading.current_thread() else None
            self.keepalive_timer.terminate()
            self.release_network_resources()
            self.cryptoAdapter.terminate()
        self.logger.debug(u"Server Session terminanted.")


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = startup_synchronization
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
The algorithm that decides the operations necessary to synchronize the
warebox with the remote modifications to data.

After connecting to the server, it can result that the data on the
remote storage have been altered by another client while this was not
connected. Moreover, the warebox could have been altered offline. This
algorithm finds a merge strategy for all these changes.

This module performs a 3-way diff between:
    * the content of the warebox
    * the storage cache
    * the content of the storage
where the storage cache is the "base status" from which both the warebox
and the storage derive.

In relation to its status in the storage cache, a pathname can be:
    * the same (-)
    * modified (M)
    * deleted (D)

Diff rules for each pathname (Storage/Warebox):
    - / -: Nothing to do
    M / -: download
    D / -: delete_local
    - / M: upload
    M / M: edit conflict. Rename local, download
    D / M: deletion conflict. Rename local
    - / D: delete
    M / D: Conflict implicitly solved. Download
    D / D: Conflict implicitly solved. Nothing to do

Rule of thumb: the storage wins.

--
The missing storage cache problem.

The system behaves correctly while there is a consistent storage cache.
However it can happen for it to get lost (e.g. file corruption,
accidental deletion, deletion by the application due to a warebox change,
etc). Even if nothing is really changed, the missing cache could cause a
wrong detection of changes:
    * deletions aren't detected
    * existing unchanged pathnames are detected as changed
Missing deletions make a previously deleted pathname re-appear, since it
is detected as "new" and gets synchronized again ("Hey, what the... I'm
sure I had deleted that!"). There is no real solutions to this problem,
which anyway isn't considered harmful, since it doesn't lose any data.
The second kind of problem is much worse: even if nobody has changed a
file, everything conflict and get renamed, since it results changed both
in the Warebox and on the Storage. To avoid this, the diff algorithm
checks if the two versions have the same etag; in such case they are not
detected as changed and the cache record is simply restored to the
current value.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
from datetime import datetime

from filerockclient.events_queue import PathnameEvent
from filerockclient.exceptions import ExecutionInterrupted


class StartupSynchronization(object):
    """The algorithm that decides the operations necessary to
    synchronize the warebox with the remote modifications to data.

    After connecting to the server, it can result that the data on the
    remote storage have been altered by another client while this was
    not connected. Moreover, the warebox could have been altered offline.
    This algorithm finds a merge strategy for all these changes.
    """
    def __init__(self, warebox, storage_cache, events_queue):
        self.logger = logging.getLogger("FR.%s" % self.__class__.__name__)
        self.warebox = warebox
        self.storage_cache = storage_cache
        self.events_queue = events_queue
        self.last_session_warebox_etag = {}
        self.last_session_storage_etag = {}
        self.local_size = {}
        self.local_lmtime = {}
        self.local_etag = {}
        self.remote_size = {}
        self.remote_lmtime = {}
        self.remote_etag = {}

        # TODO: these two are not used outside of this module,
        # maybe they can be removed.
        self.content_to_upload = set()
        self.content_to_delete = set()

        self.content_to_download = set()
        self.content_to_delete_locally = set()
        self.remote_deletions = set()
        self.edit_conflicts = set()
        self.ignored_conflicts = set()
        self.deletion_conflicts = set()

    def prepare(self, storage_content, interruption):
        """
        Step 0: detect offline changes made to both the warebox and
        the remote storage by performing a 3-way diff between the
        warebox, the storage cache and the storage.
        """
        # Collect data
        last_session_content = self._get_last_session_content(interruption)
        remote_content = self._get_remote_content(storage_content)
        local_content = self._get_local_content(interruption)

        # print "Last session content:\n%s" % last_session_content
        # print "Local content:\n%s" % local_content
        # print "Remote content:\n%s" % remote_content

        # 1) Detect offline changes.

        # Compute: storage - storage_cache
        self.content_to_download, self.content_to_delete_locally = \
            self._detect_remote_changes(last_session_content, remote_content)

        # Compute: warebox - storage_cache
        self.content_to_upload, self.content_to_delete = \
            self._detect_local_changes(last_session_content, local_content)

        # Save a backup copy of the list of deletions, we'll need it later
        self.remote_deletions = self.content_to_delete_locally.copy()

        # 2) Merge the detected changes.

        # Edit conflicts: pathnames that have changed both on the storage and
        # in the warebox. Ignored conflicts: pathnames that have the same
        # etag in the warebox and on the storage and thus just need to restore
        # the cache records.
        # TODO: this call does side effect on content_to_download and
        # content_to_upload to remove any ignored conflicts. Maybe it is
        # better to do it here!
        self.edit_conflicts, self.ignored_conflicts = \
            self._detect_edit_conflicts(self.content_to_upload,
                                        self.content_to_download)

        # Common deletions: they just need to remove the cache records.
        common_deletions = self.content_to_delete.intersection(
            self.content_to_delete_locally)

        # Deletion conflicts: the storage has deleted a pathname that's been
        # modified in the warebox. Alternatively, it has deleted an ancestor
        # of the modified pathname.
        self.deletion_conflicts = self._detect_deletion_conflicts(
            self.content_to_upload, self.content_to_delete_locally)

        # Don't upload conflicted pathnames, since they need to be renamed
        # in order to resolve the conflict.
        self.content_to_upload.difference_update(self.edit_conflicts,
                                                 self.deletion_conflicts)

        # Don't send deletions for pathnames that have been either modified or
        # deleted remotely - remember, the storage wins.
        self.content_to_delete.difference_update(self.content_to_download,
                                                 common_deletions)

        # Don't locally delete pathnames that have been already deleted
        # from the warebox (nothing to delete) or that are conflicted
        # (renaming, which solves the conflict, performs an implicit delete).
        self.content_to_delete_locally.difference_update(common_deletions,
                                                         self.deletion_conflicts)

    def update_conflicts_of_encrypted_pathnames(self, encrypted_etags):
        """
        Step 1: correct any error that has been made on encrypted
        pathnames by the conflict detection.

        The diff algorithm may have wrongly detected an encrypted
        pathname as conflicted even if it is not due to a cache loss,
        since its warebox etag (which is cleartext) and the storage one
        are different by definition. Giving this method the etag for the
        encrypted version of the warebox pathname makes it possible to
        re-do the diff and correct the error.

        Note: side effect on content_to_upload and content_to_download
        to remove redundant transfers.

        @param encrypted_etags:
                    Dictionary that maps every encrypted pathname to
                    its etag for the encrypted version. It is trusted,
                    that is, it's been locally computed.
        """
        select_unchanged = lambda p: encrypted_etags[p] == self.remote_etag[p]
        redundant_transfers = set(filter(select_unchanged, encrypted_etags))
        self.edit_conflicts.difference_update(redundant_transfers)
        self.content_to_upload.difference_update(redundant_transfers)
        self.content_to_download.difference_update(redundant_transfers)
        self.ignored_conflicts.update(redundant_transfers)

    def execute(self):
        """
        Step 2: solve any detected conflict by local renaming and
        perform any local deletion.

        Note: this method only exists because there is no easy way to
        communicate with workers yet. This kind of modifications to the
        warebox should (and shall) will be assigned to workers sooner
        or later.
        """
        # self.logger.debug(u"Edit conflicts:\n%s\n\n"
        #                   % '\n'.join(sorted(self.edit_conflicts)))
        # self.logger.debug(u'Deletion conflicts:\n%s\n\n'
        #                   % '\n'.join(sorted(self.deletion_conflicts)))
        # self.logger.debug(u'Content to delete:\n%s\n\n'
        #                   % '\n'.join(sorted(self.content_to_delete)))
        # self.logger.debug(u'Content to upload:\n%s\n\n'
        #                   % '\n'.join(sorted(self.content_to_upload)))
        # self.logger.debug(u'Content to delete locally:\n%s\n\n'
        #                   % '\n'.join(sorted(self.content_to_delete_locally)))
        # self.logger.debug(u'Content deleted from storage:\n%s\n\n'
        #                   % '\n'.join(sorted(self.remote_deletions)))
        # self.logger.debug(u'Content to download:\n%s\n\n'
        #                   % '\n'.join(sorted(self.content_to_download)))

        # Sort pathnames so to perform operations in the correct order
        self.content_to_download = sorted(self.content_to_download)
        self.content_to_delete_locally = sorted(self.content_to_delete_locally)
        self.content_to_delete_locally.reverse()

        if len(self.content_to_download) > 0 or len(self.content_to_delete_locally) > 0:
            self.logger.info(u'The following pathnames have been remotely '
                             'updated while offline and will be synchronized:')
            MAXDOWNLOAD_IN_LOG = 100
            MAXDELETE_IN_LOG = 100
            self.logger.info(
                u'    DOWNLOADING %d files, no more than %d visualized'
                % (len(self.content_to_download), MAXDOWNLOAD_IN_LOG))
            self.logger.info(
                u'    DELETING %d files, no more than %d visualized'
                % (len(self.content_to_delete_locally), MAXDELETE_IN_LOG))
            for pathname in self.content_to_download[:MAXDOWNLOAD_IN_LOG]:
                self.logger.info(u'    DOWNLOAD %s' % pathname)
            for pathname in self.content_to_delete_locally[:MAXDELETE_IN_LOG]:
                self.logger.info(u'    DELETE LOCAL %s' % pathname)

    def generate_downlink_events(self):
        """
        Step 4: produce DOWNLOAD operations for those pathnames that
        have been changed on the storage.
        """
        for pathname in self.content_to_download:

            assert pathname.__class__.__name__ == "unicode", \
                u"pathname %s is not unicode" % repr(pathname)

            event = PathnameEvent(
                'UPDATE_FROM_REMOTE', pathname,
                self.remote_size[pathname],
                self.remote_lmtime[pathname],
                self.remote_etag[pathname],
                conflicted=(pathname in self.edit_conflicts))
            self.events_queue.put(event)

    def _get_last_session_content(self, interruption):
        """
        @return the storage cache content.
        """
        content_ = self.storage_cache.get_all_records()
        content = set()

        for (pathname, _, _, _, warebox_etag, storage_etag) in content_:
            if interruption.is_set():
                raise ExecutionInterrupted()
            content.add(pathname)
            self.last_session_warebox_etag[pathname] = warebox_etag
            self.last_session_storage_etag[pathname] = storage_etag
        return content

    def _get_local_content(self, interruption):
        """
        @param interruption:
                    An event object telling if someone in the
                    application has requested this method to interrupt.
        @return
                    The warebox content.
        """
        self.logger.debug('Starting get local content')
        content = set()
        pathnames = self.warebox.get_content(blacklisted=True,
                                             interruption=interruption)

        for pathname in pathnames:
            if interruption.is_set():
                raise ExecutionInterrupted()
            try:
                lmtime = self.warebox.get_last_modification_time(pathname)
                size = self.warebox.get_size(pathname)
                etag = self.warebox.compute_md5_hex(pathname)
            except Exception as exception:
                self.logger.warning(
                    u'Failed reading disk metadata for pathname %r.'
                    ' Skipped. Reason: %s' % (pathname, exception))
                continue
            content.add(pathname)
            self.local_size[pathname] = size
            self.local_lmtime[pathname] = lmtime
            self.local_etag[pathname] = etag
        self.logger.debug('Local content acquired')
        return content

    def _get_remote_content(self, storage_content):
        """
        @param storage_content:
                list of dictionaries with the following format:
                [
                    {
                        u'lmtime': u'2012-05-08T21:26:42.000Z',
                        u'etag': u'"d41d8cd98f00b204e9800998ecf8427e"',
                        u'key': u'File.txt',
                        u'size': u'25054'
                    },
                    ...
                ]
        @return the content of the storage as in "storage_content".
        """
        content = set()
        for record in storage_content:
            pathname = record['key']
            etag = record['etag']
            lmtime = datetime.strptime(record['lmtime'],
                                       '%Y-%m-%dT%H:%M:%S.000Z')
            size = int(record['size'])
            self.remote_lmtime[pathname] = lmtime
            self.remote_size[pathname] = size
            self.remote_etag[pathname] = etag
            content.add(pathname)
        return content

    def _detect_local_changes(self, last_session_content, local_content):
        """Detect the offline changes made to the warebox.
        """
        return self._detect_changes(last_session_content,
                                    local_content,
                                    self.local_etag,
                                    self.last_session_warebox_etag)

    def _detect_remote_changes(self, last_session_content, remote_content):
        """Detect the offline changes made to the storage.
        """
        return self._detect_changes(last_session_content,
                                    remote_content,
                                    self.remote_etag,
                                    self.last_session_storage_etag)

    def _detect_changes(self, content_from, content_to,
                        etag_map, last_session_etag_map):
        """Detect the update and delete operations necessary to change
        content_from into content_to.

        @param content_from:
                    Set of strings representing pathnames.
        @param content_to:
                    Set of strings representing pathnames.
        @params etag_map
                    Dictionary with an etag for each pathname in content_to
        @params last_session_etag_map
                    Dictionary with an etag for each pathname in content_from
        @return
                    tuple(updated_content, deleted_content), they are
                    both sets of pathnames.
        """
        updated_content = set()
        deleted_content = set()
        for pathname in content_to:
            if pathname not in content_from or etag_map[pathname] != last_session_etag_map[pathname]:
                updated_content.add(pathname)
        for pathname in content_from:
            if pathname not in content_to:
                deleted_content.add(pathname)
        return (updated_content, deleted_content)

    def _detect_edit_conflicts(self, content_to_upload, content_to_download):
        """Detect edit conflicts between uploads and download.

        A pathname is an "edit conflict" if it's been modified both in
        the warebox and on the storage.

        Note: side effect on content_to_upload and content_to_download
        in order to remove redundant transfers.

        @param content_to_upload:
                    Set of pathnames to uplaod.
        @param content_to_download:
                    Set of pathnames to download.
        @return
                    tuple(conflicts, redundant_transfers). Conflicts are
                    pathnames that are really in conflict. Redundant
                    transfers are pathname that are equal in the warebox
                    and on the storage, so there is no need to actual
                    transfer them and restoring the storage cache record
                    would be enough.
        """
        conflicts = content_to_upload.intersection(content_to_download)
        redundant_transfers = set(filter(lambda p: self.local_etag[p] == self.remote_etag[p], conflicts))
        conflicts.difference_update(redundant_transfers)
        content_to_upload.difference_update(redundant_transfers)
        content_to_download.difference_update(redundant_transfers)
        return conflicts, redundant_transfers

    def _detect_deletion_conflicts(self,
                                   content_to_upload,
                                   content_to_delete_locally):
        """Detect deletion conflicts between uploads and remote deletions.

        A pathname is a "delete conflict" if it's been both modified in
        the warebox and deleted from the storage. A modified pathname
        could be a delete conflict also because an ancestor of him
        (and thus the whole subtree) have been deleted from the storage.

        @param content_to_upload:
                    Set of pathnames to uplaod.
        @param content_to_download:
                    Set of pathnames to delete from the warebox.
        @return
                    Set of pathnames that are deletion conflicts.
        """
        # Deletion conflicts are more complex than others, because they must
        # be extended to folders' content
        conflicts = set()
        for pathname in content_to_delete_locally:
            confl = [p for p in content_to_upload if p.startswith(pathname)]
            conflicts.update(set(confl))
        return conflicts


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = abstract
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Abstraction for the states of ServerSession.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging

from filerockclient.exceptions import \
    ForceStateChange, ProtocolException, UnexpectedMessageException
from filerockclient.interfaces import GStatuses
from filerockclient.serversession.states.register import StateRegister
from filerockclient.serversession.commands import Command


START_BASIS = None


class ServerSessionState(object):
    """Abstraction for the states of ServerSession.

    This class contains any common logic among the states. For example
    the main entry point, which implements high-level reception and
    handling of events, is located here. There are also support methods
    for changing state.

    A state must implement a _handle_X_Y method for each event that it
    should handle, where X is in ['command', 'message'] and Y is the
    particular event to handle. A command is an instance of
    filerockclient.serversession.commands.Command, while a message is
    a message from the server, instance of any subclass of
    FileRockSharedLibraries.Communication.Messages.Message. An handler
    is given the event object as a argument.
    The abstract state implements a few common handlers. States must
    also declare which server messages are expected, through the class
    attribute "accepted_messages". Receiving any unexpected message
    raises an error.

    States can access ServerSession's attributes by the mean of the
    self._context attribute; in fact, ServerSession acts as a common
    context (memory space) for its states.
    """
    accepted_messages = ['QUIT', 'ERROR']

    def __init__(self, context):
        """
        @param context:
                    Instance of filerockclient.serversession.
                    server_session.ServerSession.
        """
        self._context = context
        self.logger = logging.getLogger("FR.%s" % self.__class__.__name__)

    def do_execute(self):
        """The entry point for executing this state's logic.

        ServerSession calls this method at each iteration of its event
        loop. An event is fetched from the input queue if available
        (otherwise it blocks waiting for an event), which is then
        dispatched to the corresponding handler.
        Several types of event are fetched by self._input_queue, which
        is an instance of filerockclient.util.multi_queue.MultiQueue.
        Each state can choose the fetching priority from this queue by
        overriding the _receive_next_message method.
        """
        message, from_queue = self._receive_next_message()

        try:
            if from_queue == 'usercommand':
                subject = 'command_%s' % message.name

            if from_queue == 'sessioncommand':
                if message.name == 'CHANGESTATE':
                    return message.next_state
                subject = 'command_%s' % message.name

            if from_queue == 'systemcommand':
                subject = 'command_%s' % message.name

            elif from_queue == 'servermessage':
                subject = 'message'

            elif from_queue == 'operation':
                subject = 'operation'

            callback = '_handle_%s' % subject
            method = getattr(self, callback)
            method(message)

        except ForceStateChange:
            pass

        return self._context.current_state

    def _receive_next_message(self):
        """Fetch the next event from the input queue.

        Blocks until an event is available. Suclasses can override this
        method to re-define which events to receive and in which order.

        The available queues are:
        * usercommand: command from the user. This queue mustn't be
                ignored, since termination command come from here.
        * sessioncommand: command produced by ServerSession itself as a
                reaction to some other condition. Different states can
                communicate in this way.
        * systemcommand: command sent by some client component different
                from ServerSession.
        * servermessage: message sent by the server.
        """
        return self._context._input_queue.get([
            'usercommand', 'sessioncommand', 'systemcommand', 'servermessage'])

    def _handle_command_DISCONNECT(self, command):
        """Disconnect from the server.
        """
        self._set_next_state(StateRegister.get("DisconnectedState"))

    def _handle_command_TERMINATE(self, command):
        """Terminate ServerSession and release all acquired resources.
        """
        pass

    def _handle_command_WORKERFREE(self, command):
        """A worker is free to execute some work.
        """
        self.logger.debug(u"Received unexpected WORKERFREE command")

    def _handle_command_BROKENCONNECTION(self, command):
        """The connection to the server is broken.
        """
        self.logger.info(u"Detected disconnection from the server")
        self._set_next_state(StateRegister.get('DisconnectedState'))
        self._context._input_queue.put(Command('CONNECT'), 'sessioncommand')

    def _handle_command_KEEPALIVETIMEDOUT(self, command):
        """The server hasn't replied to the keep-alive message for too
        long.
        """
        self._handle_command_BROKENCONNECTION(command)

    def _set_next_state(self, next_state):
        """Change ServerSession's state.

        @param next_state:
                    Instance of a subclass of ServerSessionState.
        """
        command = Command('CHANGESTATE')
        command.next_state = next_state
        self._context._input_queue.put(command, 'sessioncommand')

    def _on_entering(self):
        """Called each time ServerSession enters a state.

        Subclasses can override this to define some behavior.
        """
        self.logger.debug('State changed')
        pass

    def _on_leaving(self):
        """Called each time ServerSession leaves a state.

        Subclasses can override this to define some behavior.
        """
        pass

    def _handle_message(self, message):
        """Dispatch a server message to the corresponding handler.
        """
        if message.name not in self.accepted_messages:
            raise UnexpectedMessageException(message)
        callback = '_handle_message_%s' % message.name
        method = getattr(self, callback)
        method(message)

    def _handle_command_CONNECT(self, message):
        """Connect to the server.
        """
        pass

    def _handle_command_USERCOMMIT(self, message):
        """Commit the current transaction for the will of the user.
        """
        self.logger.info(u"Cannot commit now, sorry.")

    def _handle_command_COMMIT(self, command):
        """Commit the current transaction.
        """
        self.logger.info(u"Cannot commit now, sorry.")

    def _handle_message_QUIT(self, message):
        """The server has dumped us!
        """
        self.logger.info(u"Received quit from server with reason: %s"
            % message.getParameter('reason'))
        self._context._internal_facade.set_global_status(GStatuses.NC_STOPPED)
        if message.getParameter('issued_by') \
        and message.getParameter('issued_by') == 'client':
            details = message.getParameter('details')
            self._context._ui_controller.ask_for_user_input(
                'quit', message.getParameter('issued_by'), details)
            self._context._internal_facade.pause()
        else:
            #self._context._ui_controller.ask_for_user_input('quit')
            self._context._internal_facade.pause_and_restart()

    def _handle_message_ERROR(self, message):
        """Error answer from the server to last interaction.
        """
        self.logger.error("Received ERROR message from server. Aborting...")
        self.logger.debug("Error message: %r" % message)
        raise ProtocolException("Received ERROR message")

    def _handle_command_REDECLAREOPERATION(self, command):
        """An operation declared in the past must be declared again,
        since it didn't go well.

        States that need to handle this command should override this
        method.
        """
        # TODO: do we really need this to be abstract?
        pass

    def _try_set_global_status_aligned(self):
        """Set "aligned" as the global status, if there is nothing else
        to synchronize.

        Aligned means that there is nothing to be synchronized with the
        storage. ServerSession calls this every time it's reasonable
        to suppose that we are aligned, e.g. after a successfully
        committed transaction. However it still possible that some
        operation is waiting for synchronization, so we can't really
        go into the aligned state yet.
        """
        # Note: operations sent to the encrypter and still not returned back
        # aren't tracked here. This can give false positives, which will be
        # fixed as soon as the encryption step completes. For this reason, the
        # user may see the global status flickering for a moment.
        if self._context._input_queue.empty(['operation']) \
        and self._context.transaction.size() == 0:
            self._context._ui_controller.set_global_status(GStatuses.C_ALIGNED)

    def _load_candidate_basis(self):
        """Load the candidate basis from the persistence store.

        Raises FileRockException if none is found.

        @return The candidate basis
        """
        return self._context.metadataDB.get('candidate_basis')

    def _try_load_candidate_basis(self):
        """Load the candidate basis from the persistent store.

        @return The candidate basis if it exists, otherwise None
        """
        return self._context.metadataDB.try_get('candidate_basis')

    def _save_basis_in_history(
            self, prev_basis, next_basis, user_accepted=False, hashes_db=None):
        """Save the given basis in the basis history, into the
        persistent store.

        @param prev_basis:
                    The last persisted basis
        @param next_basis:
                    The most recent basis, i.e. the current one
        @param user_accepted:
                    Boolean flag telling whether the basis
                    has been explicitly accepted by the user, during the
                    synch phase.
        @param hashes_db:
                    Instance of filerockclient.databases.hashes.HashesDB.
                    If None is passed, ServerSession's own instance will
                    be used instead. Passing an instance is useful when
                    this call is part of an open transaction on the
                    database.
        """
        if hashes_db is None:
            hashes_db = self._context.hashesDB
        hashes_db.add(prev_basis, next_basis, user_accepted)

    def _persist_candidate_basis(self, basis, metadata_db=None):
        """Save the given basis as the "candidate basis" in the
        persistent store.

        The candidate basis is the one computed by the client just
        before of committing the current transaction. It's used to
        counter-check the result of the commit, sent from the server.
        The candidate basis must be persisted in order to make the
        client resistent to crashes of both itself and the server.

        @param basis:
                    The basis to be persisted as the candidate.
        @param metadata_db:
                    Instance of filerockclient.databases.metadata.MetadataDB.
                    If None is passed, ServerSession's own instance will
                    be used instead. Passing an instance is useful when
                    this call is part of an open transaction on the
                    database.
        """
        if metadata_db is None:
            metadata_db = self._context.metadataDB
        metadata_db.set('candidate_basis', basis)

    def _clear_candidate_basis(self, metadata_db=None):
        """Delete the current "candidate basis" from the persistent store.

        @param metadata_db:
                    Instance of filerockclient.databases.metadata.MetadataDB.
                    If None is passed, ServerSession's own instance will
                    be used instead. Passing an instance is useful when
                    this call is part of an open transaction on the
                    database.
        """
        if metadata_db is None:
            metadata_db = self._context.metadataDB
        metadata_db.delete_key('candidate_basis')

    def _load_trusted_basis(self):
        """Load the trusted basis from the persistence store.

        @return The trusted basis if it exists, otherwise None
        """
        if self._context.metadataDB.exist_record('trusted_basis'):
            basis = self._context.metadataDB.get('trusted_basis')
        else:
            basis = START_BASIS
        with self._context._basis_lock:
            self._context._current_basis = basis
        return basis

    def _persist_trusted_basis(self, basis, metadata_db=None):
        """Save the given basis as the "trusted basis" in the
        persistent store.

        The trusted basis represents the "last known good situation" of
        the user data. It is obtained by doing local computation (which
        are trusted indeed) on a trusted basis. It must be persisted to
        make it available on the next application startup.

        @param basis:
                    The basis to be persisted as the candidate.
        @param metadata_db:
                    Instance of filerockclient.databases.metadata.MetadataDB.
                    If None is passed, ServerSession's own instance will
                    be used instead. Passing an instance is useful when
                    this call is part of an open transaction on the
                    database.
        """
        if metadata_db is None:
            metadata_db = self._context.metadataDB
        metadata_db.set('trusted_basis', basis)
        with self._context._basis_lock:
            self._context._current_basis = basis


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = commit
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Collection of the "commit" ServerSession's states.

We call "commit" the set of session states that belong
to the time when the operations done in Replication and Transfer (i.e.
the current transaction) must be finalized and made persistent.

ServerSession keeps track of the current "transaction", a container for
replication actions, which is committed when it gets too large or when
the server (or the user) asks so.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import datetime

from FileRockSharedLibraries.Communication.Messages import COMMIT_START
from FileRockSharedLibraries.IntegrityCheck.Proof import Proof
from filerockclient.integritycheck.IntegrityManager import \
    WrongBasisAfterUpdatingException, WrongBasisFromProofException

from filerockclient.interfaces import GStatuses, PStatuses
from filerockclient.exceptions import *
from filerockclient.serversession.states.abstract import ServerSessionState
from filerockclient.serversession.states.register import StateRegister
from filerockclient.serversession.commands import Command


class CommitState(ServerSessionState):
    """Preparing for committing the current transaction.
    """
    accepted_messages = ServerSessionState.accepted_messages + \
        []

    def _on_entering(self):
        """ServerSession waits for all operations currently handled by
        workers to be completed, afterwards it begins the commit.

        Integrity of the transaction is checked and the "candidate basis"
        (the expected basis after our modifications to the storage) is
        computed.
        """
        self.logger.debug(u"Committing the current transaction...")

        # Block until all pending uploads are finished
        self.logger.debug(u"Waiting for the transaction to be finished...")
        self._context.transaction_manager.wait_until_finished()
        self.logger.debug(u"Transaction is finished!")

        self.logger.info(u"Committing the following pathnames:")
        operations = self._context.transaction_manager.get_completed_operations()
        for (op_id, op) in operations:
            self.logger.info(u'    %s "%s"' % (op.verb, op.pathname))
            self.logger.debug(u"    id=%s %s" % (op_id, op))

        # Use the received proofs to compute the next expected basis
        self._check_transaction_integrity(operations)
        candidate_basis = self._context.integrity_manager.getCandidateBasis()
        self.logger.info("Candidate basis: %s" % candidate_basis)

        # Persist the expected state
        metadata = self._context.metadataDB
        transaction_cache = self._context.transaction_cache
        with metadata.transaction(transaction_cache) as (meta, trans):
            self._persist_candidate_basis(candidate_basis, metadata_db=meta)
            self._update_transaction_cache(trans, operations)

        # Ready to go, tell the server to start the commit!
        completed_operations_id = [op_id for (op_id, _) in operations]
        self._context.output_message_queue.put(COMMIT_START(
            "COMMIT_START", {'achieved_operations': completed_operations_id}))
        self._set_next_state(StateRegister.get('CommitStartState'))

    def _update_transaction_cache(self, transaction_cache, operations):
        """Persist the current transaction.

        This cache is useful to recover the commit in the future,
        should the commit go wrong.
        """
        transaction_cache.clear()
        transaction_timestamp = datetime.datetime.now()
        for op_id, operation in operations:
            transaction_cache.update_record(
                op_id, operation, transaction_timestamp)

    def _handle_command_COMMIT(self, message):
        """Any further commit command is redundant here.
        """
        pass

    def _handle_command_USERCOMMIT(self, message):
        """Any further commit command is redundant here.
        """
        self.logger.info(u"I'm already committing, don't be in a hurry")

    def _handle_message_COMMIT_FORCE(self, message):
        """Any further commit command is redundant here.

        Note that this message can actually be received. The server
        could have received a request from us after he sent commit_force
        because of network timing, and it has replied with another
        commit_force. It's OK, just ignore it.
        """
        pass

    def _check_transaction_integrity(self, operations):
        """Check that all proofs which came from the server along with
        authorizations for the operations in transaction are valid.

        If so, the proofs can be used to securely compute the candidate
        basis (the next expected basis).
        """
        for (op_id, operation) in operations:
            response = self._context.operation_responses[op_id]
            details = response.getParameter('response_details')
            proof = Proof(details.proof)
            etag = operation.storage_etag if hasattr(operation, 'storage_etag') else None
            try:
                self._context.integrity_manager.addOperation(
                    operation.verb, operation.pathname, proof, etag)
            except WrongBasisFromProofException as e:
                self._context._internal_facade.set_global_status(GStatuses.C_BROKENPROOF)
                self.logger.critical(
                    u'Detected an integrity problem with data on the storage:'
                    ' server has returned for pathname %s "%s" the basis %s'
                    ' which is different from our trusted basis %s'
                    % (operation.verb, operation.pathname, e.operation_basis,
                        self._context.integrity_manager.getCurrentBasis()))
                raise ProtocolException('WrongBasisFromProofException')


class CommitStartState(ServerSessionState):
    """The commit has been started, waiting for a reply from the server.
    """
    accepted_messages = ServerSessionState.accepted_messages + \
        ['REPLICATION_DECLARE_RESPONSE', 'COMMIT_FORCE', 'COMMIT_DONE',
            'COMMIT_ERROR', 'ERROR']

    def _handle_message_COMMIT_DONE(self, message):
        """Everything went well, the server has completed the commit.

        Check the resulting basis declared by the server and, if it is
        valid, then finalize the commit by updating all internal data
        structures. Finally go back to the Replication & Transfer state,
        we start again.
        """
        server_basis = message.getParameter('new_basis')
        self.logger.info(u'Commit done')
        self.logger.debug(u"Server basis: %s" % (server_basis))
        previous_basis = self._context.integrity_manager.getCurrentBasis()
        self.logger.debug(u"Previous basis: %s" % previous_basis)

        # Check the server basis against the one we have computed
        self._check_integrity(server_basis)

        # Everything OK, persist the new trusted basis and related metadata
        new_basis = self._context.integrity_manager.getCurrentBasis()
        completed_ops = self._context.transaction_manager.get_completed_operations()
        self._persist_integrity_metadata(previous_basis,
                                         new_basis,
                                         completed_ops)

        self.logger.info(u"Updated basis: %s" % new_basis)
        self._context.transaction_manager.clear()
        self._context.operation_responses.clear()
        self._context.refused_declare_count = 0
        self.logger.debug(
            u"Current transaction has been committed successfully.")
        for (_, operation) in completed_ops:
            operation.notify_pathname_status_change(PStatuses.ALIGNED)
        self._update_user_interfaces(message)
        self._try_set_global_status_aligned()
        self._set_next_state(StateRegister.get('ReplicationAndTransferState'))

    def _check_integrity(self, server_basis):
        """Check the server basis against the one we have computed.

        Precondition: self._context.integrity_manager contains the
        expected basis.
        """
        try:
            self._context.integrity_manager.checkCommitResult(server_basis)
        except WrongBasisAfterUpdatingException as e:
            state = GStatuses.C_HASHMISMATCHONCOMMIT
            self._context._internal_facade.set_global_status(state)
            self.logger.critical(
                u"Detected an integrity problem with data on the storage:"
                " server basis %s doesn't match our computed basis %s"
                % (server_basis, e.computed_basis))
            raise ProtocolException('WrongBasisAfterUpdatingException')

    def _persist_integrity_metadata(
                        self, previous_basis, new_basis, completed_operations):
        """Transactionally persist all metadata related to integrity:
        basis and storage_cache.
        """
        metadata = self._context.metadataDB
        hashes = self._context.hashesDB
        storage_cache = self._context.storage_cache
        transaction_cache = self._context.transaction_cache

        with metadata.transaction(hashes, storage_cache, transaction_cache) \
                as (metadata_, hashes_, storage_cache_, transaction_cache_):
            self._persist_trusted_basis(new_basis, metadata_db=metadata_)
            self._clear_candidate_basis(metadata_db=metadata_)
            self._save_basis_in_history(previous_basis, new_basis, hashes_db=hashes_)
            self._update_storage_cache(storage_cache_, completed_operations)
            transaction_cache_.clear()

    def _update_storage_cache(self, storage_cache, operations):
        """Update the storage cache by inserting the content of the
        committed transaction.

        This update is very important and it's done transactionally: we
        need a consistent storage cache to correctly check integrity
        and compute the operations to do in the sync phase.
        """
        operations = [op for (_, op) in operations]
        lmtime = datetime.datetime.now()

        for operation in operations:
            if operation.verb in ['UPLOAD', 'REMOTE_COPY']:
                pathname = operation.pathname
                warebox_size = operation.warebox_size
                storage_size = operation.storage_size
                lmtime = operation.lmtime
                warebox_etag = operation.warebox_etag
                storage_etag = operation.storage_etag
                storage_cache.update_record(
                    pathname, warebox_size, storage_size, lmtime,
                    warebox_etag, storage_etag)
            elif operation.verb == 'DELETE':
                storage_cache.delete_record(operation.pathname)
            else:
                raise Exception("Unexpected operation verb while in state "
                    "%s: %s" % (self.__class__.__name__, operation))

    def _update_user_interfaces(self, message):
        """Send the user interfaces information on the successful commit.
        """
        self._context._ui_controller.update_session_info({
            'last_commit_client_id':
                message.getParameter('last_commit_client_id'),
            'last_commit_client_hostname':
                message.getParameter('last_commit_client_hostname'),
            'last_commit_client_platform':
                message.getParameter('last_commit_client_platform'),
            'last_commit_timestamp':
                message.getParameter('last_commit_timestamp'),
            'used_space':
                message.getParameter('used_space'),
            'user_quota':
                message.getParameter('user_quota'),
            'basis':
                message.getParameter('new_basis')
        })

    def _handle_message_COMMIT_ERROR(self, message):
        """The server couldn't complete the commit for some reason.
        Give up, we'll try to recover it as a "pending commit".
        """
        self.logger.error(
            u"Server failed while committing the current transaction: %s."
            " Shutting down, we'll try again at next startup."
            % (message.getParameter('reason')))
        raise ProtocolException('Error while committing')

    def _handle_message_ERROR(self, message):
        # TODO: The server is sending ERROR instead of COMMIT_ERROR
        self._handle_message_COMMIT_ERROR(message)

    def _handle_command_USERCOMMIT(self, message):
        """Any further commit command is redundant here.
        """
        self.logger.info(u"I'm already committing, don't be in a hurry")

    def _handle_command_COMMIT(self, message):
        """Any further commit command is redundant here.
        """
        pass

    def _handle_message_COMMIT_FORCE(self, message):
        """Any further commit command is redundant here.

        The server may send a COMMIT_FORCE here for two reasons:
        1) she has received a request from us after a commit_force because of
           network timing, so it has replied with another commit_force.
        2) she has decided that it's a nice time for a commit, but we had
           already decided so due to choice from user.
        It's OK in both cases, just ignore it.
        """
        pass

    def _handle_message_REPLICATION_DECLARE_RESPONSE(self, message):
        """The server has replied to a request that we have sent just a moment
        before that the user decided to commit.
        The authorized operation has been already postponed and will be
        requested again later, in the next transaction.
        It's OK, just ignore it.
        """
        pass


class PendingCommitState(ServerSessionState):
    """Recovering a commit that was interrupted in the last session.
    """
    accepted_messages = ServerSessionState.accepted_messages

    def _on_entering(self):
        """Tell the server that we are ready.
        """
        self._context.output_message_queue.put(COMMIT_START(
            "COMMIT_START", {'achieved_operations': 'RECOVER_FROM_CRASH'}))
        self._set_next_state(StateRegister.get('PendingCommitStartState'))

    def _handle_command_USERCOMMIT(self, message):
        """Any further commit command is redundant here.
        """
        self.logger.info(u"I'm already committing, don't be in a hurry")


class PendingCommitStartState(CommitStartState):
    """Recovering the pending commit, waiting for a reply from the
    server.

    Note: this is a subclass of CommitStartState
    """
    accepted_messages = ServerSessionState.accepted_messages + \
        ['COMMIT_DONE', 'COMMIT_ERROR', 'ERROR']

    def _handle_message_COMMIT_DONE(self, message):
        """Everything went well, the server has completed the commit.

        Check the resulting basis sent by the server against our
        candidate basis, if it's valid then finalize the commit by
        updating all internal data structures.
        Finally go into the sync phase, the session can begin at last.
        """
        self.logger.info(u'Commit done')
        server_basis = message.getParameter('new_basis')
        candidate_basis = self._load_candidate_basis()
        previous_basis = self._load_trusted_basis()
        self.logger.debug(u"Server basis: %s" % server_basis)
        self.logger.debug(u"Candidate basis: %s" % candidate_basis)
        self.logger.debug(u"Last trusted basis: %s" % previous_basis)

        # Check the server basis against the candidate basis
        self._context.integrity_manager.setCurrentBasis(candidate_basis)
        self._check_integrity(server_basis)

        # Everything OK, persist the new trusted basis and related metadata
        operations = self._context.transaction_cache.get_all_records()
        operations = [(op_id, op) for (op_id, op, _) in operations]
        self._persist_integrity_metadata(previous_basis,
                                         server_basis,
                                         operations)
        self._context.integrity_manager.setCurrentBasis(server_basis)

        self.logger.info(u"Pending commit successfully recovered.")
        self.logger.info(u"Updated basis: %s" % server_basis)
        self._update_user_interfaces(message)
        self._set_next_state(StateRegister.get('ReadyForServiceState'))
        self._context._input_queue.put(
                                Command('STARTSYNCPHASE'), 'sessioncommand')


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = integrity_error
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the integrity_error module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.serversession.states.abstract import ServerSessionState
from filerockclient.interfaces import GStatuses


class IntegrityErrorState(ServerSessionState):

    accepted_messages = ServerSessionState.accepted_messages

    def _receive_next_message(self):
        return self._context._input_queue.get(['usercommand'])

    def _on_entering(self):
        self.logger.debug('State changed')
        self._context._internal_facade.set_global_status(
            GStatuses.C_HASHMISMATCHONCONNECT)
        self._context._ui_controller.notify_user('hash_mismatch')
        self._context.release_network_resources()
        if not self._context.keepalive_timer.is_suspended():
            self._context.keepalive_timer.suspend_execution()
        if not self._context.filesystem_watcher.is_suspended():
            self._context.filesystem_watcher.suspend_execution()

########NEW FILE########
__FILENAME__ = pre_authentication
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Collection of the "pre-authentication" ServerSession's states.

We call "pre-authentication" the set of session states that belong to
the time before that mutual authentication between server and client has
happened.
The client starts in pre-authentication.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import Queue

from FileRockSharedLibraries.Communication.Messages import \
    CHALLENGE_REQUEST, CHALLENGE_RESPONSE, READY_FOR_SERVICE, \
    SYNC_START, PROTOCOL_VERSION, UNEXPECTED_DATA
from FileRockSharedLibraries.Cryptography.CryptoLib import CryptoUtil
from filerockclient.interfaces import GStatuses
from filerockclient.exceptions import *
from filerockclient.serversession.states.abstract import ServerSessionState
from filerockclient.serversession.states.register import StateRegister
from filerockclient.serversession.commands import Command
from filerockclient.util import multi_queue


class DisconnectedState(ServerSessionState):
    """The client is not connected to the server.

        This is also the state in which ServerSession is just after
        initialization.
    """
    accepted_messages_on_entering = [
        'UNKNOWN_CLIENT_ID_ERROR', 'CHALLENGE_VERIFY_RESPONSE', 'QUIT',
        'PROTOCOL_VERSION_AGREEMENT']
    accepted_messages = ServerSessionState.accepted_messages + \
        accepted_messages_on_entering

    def __init__(self, session):
        ServerSessionState.__init__(self, session)
        self.messages_to_handle_before_start = []

    def _flush_queue(self, queue):
        """Clear the given queue.

        @param queue:
                    An instance of Queue.Queue.
        """
        while True:
            try:
                queue.get_nowait()
            except Queue.Empty:
                break

    def _on_entering(self):
        """Release any network resource acquired in the past and restore
        an initial situation.

        Any queue is cleared, handling all remaining messages if possible.
        """
        self.logger.debug('State changed')
        self.logger.info(u"Disconnected from the server.")
        self.messages_to_handle_before_start = []
        if not self._context.keepalive_timer.is_suspended():
            self._context.keepalive_timer.suspend_execution()
#        self.worker_pool.on_disconnect()
        self._context.release_network_resources()
        self._flush_queue(self._context.output_message_queue)
        while True:
            try:
                message, _ = self._context._input_queue.get(['servermessage'], False)
                if message.name in self.accepted_messages_on_entering:
                    self.messages_to_handle_before_start.append(message)
                    self.logger.debug(
                        'Message to handle before reconnect %r'
                        % self.messages_to_handle_before_start)
            except multi_queue.Empty:
                break
        if not self._context.filesystem_watcher.is_suspended():
            self._context.filesystem_watcher.suspend_execution()
        self._context._input_queue.clear(['operation'])
        self._context.transaction.clear()
        for message in self.messages_to_handle_before_start:
            self._handle_message(message)
        self._context._internal_facade.set_global_status(GStatuses.NC_STOPPED)
        
        self._context.worker_pool.clean_download_dir()

    def _handle_command_CONNECT(self, message):
        """Connect to the server.
        """
        self._set_next_state(StateRegister.get('ConnectingState'))

    def _handle_message_UNKNOWN_CLIENT_ID_ERROR(self, message):
        """The server didn't recognize our client and then close the
        connection, go relinking.

        Note: this is just post-disconnection handling, the natural
        handler would be ChallengeRequestState.
        """
        self.logger.info(u'Declared client id seems not linked!')
        relink_user(self)

    def _handle_message_CHALLENGE_VERIFY_RESPONSE(self, message):
        """The server replied to our request to authenticate and then
        closed the connection. Is there another client connected?

        Note: this is just post-disconnection handling, the natural
        handler would be ChallengeResponseState.
        """
        if message.is_other_client_connected():
            client = message.get_other_connected_client()
            if client["client_id"]==0:
                other_client_message = u"Your web client is already connected"
            else:
                other_client_message = \
                    u"Client number %s from computer %s already connected" \
                    % (client["client_id"], client["hostname"])
            self.logger.warning(other_client_message)
            self._context.disconnect_other_client = True
            force_disconnection = self._context._ui_controller.ask_for_user_input(
                "other_client_connected", client["client_id"],
                client["hostname"])

            if not force_disconnection == 'ok':
                self._context._internal_facade.pause()
                return

    def _handle_message_PROTOCOL_VERSION_AGREEMENT(self, message):
        """The server replied to our greeting message and then closed
        the connection. Is our client version obsolete?

        Note: this is just post-disconnection handling, the natural
        handler would be ProtocolVersionState.
        """
        state = StateRegister.get('ProtocolVersionState')
        state._check_protocol_mismatch(message)


class ConnectingState(ServerSessionState):
    """Connecting to the server.
    """
    accepted_messages = ServerSessionState.accepted_messages

    def _on_entering(self):
        """Acquire network resources and try to connect.

        The connection is authenticated by the mean of the server
        certificate, so it is trusted.
        """
        self.logger.info(u"Connecting to server...")
        self._context._internal_facade.set_global_status(GStatuses.NC_CONNECTING)
        if self._context.acquire_network_resources():
            self.logger.info(u"Server has successfully authenticated itself")
            self._context.num_connection_attempts = 0
            self._context._internal_facade.reset_pause_timer()
            self._set_next_state(StateRegister.get('ConnectedState'))
            self._context._input_queue.put(Command('HANDSHAKE'), 'sessioncommand')
        else:
            self._context._internal_facade.set_global_status(GStatuses.NC_NOSERVER)
            if self._context.num_connection_attempts > self._context.max_connection_attempts:
                self.logger.error(u'Server has been unreachable for too long, giving up.')
                return self._context._internal_facade.pause_and_restart()
            self._set_next_state(StateRegister.get('DisconnectedState'))
            self._context._input_queue.put(Command('CONNECT'), 'sessioncommand')

    def _receive_next_message(self):
        """It's too early to handle something different from commands.
        """
        return self._context._input_queue.get(['usercommand', 'sessioncommand'])


class ConnectedState(ServerSessionState):
    """Sent a connection request, waiting for a reply from the server.
    """
    accepted_messages = ServerSessionState.accepted_messages

    def _handle_command_HANDSHAKE(self, message):
        """Positive reply from the server, tell him the protocol version
        that we can support.
        """
        self._context.output_message_queue.put(
            PROTOCOL_VERSION('PROTOCOL_VERSION', {'version': 1}))
        self._set_next_state(StateRegister.get('ProtocolVersionState'))


class ProtocolVersionState(ServerSessionState):
    """Sent the supported protocol version, waiting for a reply.
    """
    accepted_messages = ServerSessionState.accepted_messages + \
        ['PROTOCOL_VERSION_AGREEMENT']

    def _handle_message_PROTOCOL_VERSION_AGREEMENT(self, message):
        """Received the reply from the server, check if he agreed our
        protocol version. If so, ask the server to authenticate.
        """
        self._check_protocol_mismatch(message)

        # Protocol agreed, starting authentication
        challenge_request_msg = CHALLENGE_REQUEST(
            "CHALLENGE_REQUEST",
            {'client_id': self._context.client_id, 'username': self._context.username})
        self._context.output_message_queue.put(challenge_request_msg)
        self._set_next_state(StateRegister.get('ChallengeRequestState'))

    def _check_protocol_mismatch(self, message):
        """Check whether the server has agreed our protocol version. If
        not, the user has an obsolete version of FileRock.
        """
        protocol_version_obsolete = message.getParameter('response') != 'OK'
        if protocol_version_obsolete:
            self._context._ui_controller.ask_for_user_input('protocol_obsolete')
            self._context._internal_facade.terminate()
            raise ForceStateChange()


def relink_user(state):
    """
    Abandon this session and link this client to the server, since it
    seems to be unlinked.
    """
    state._context.linker.reset_info()
    state._context._internal_facade.soft_reset()
    # TODO: we should better go into a no-op state here,
    # waiting for termination.

#    if not state._context.linker.link():
#        state.logger.info('User has canceled the linking procedure')
#        state._context._internal_facade.terminate()
#        raise ForceStateChange()
#    state._context.reload_config_info()
#    state._set_next_state(StateRegister.get('DisconnectedState'))
#    state._context._input_queue.put(Command('CONNECT'), 'sessioncommand')


class ChallengeRequestState(ServerSessionState):
    """Authenticating ourselves with the server.
    """
    accepted_messages = ServerSessionState.accepted_messages + \
        ['CHALLENGE_REQUEST_RESPONSE', 'ERROR', 'UNKNOWN_CLIENT_ID_ERROR']

    def __init__(self, session):
        ServerSessionState.__init__(self, session)
        self.crypto = CryptoUtil()

    def _handle_message_CHALLENGE_REQUEST_RESPONSE(self, message):
        """The server has agreed to start the authentication and has
        sent us a challange to sign.
        """
        challenge = str(message.getParameter('challenge'))
        # Sign challenge with private key
        signed = self.crypto.challenge_sign(
            challenge, open(self._context.priv_key, 'r').read())
        # Create CHALLENGE_RESPONSE with signed challenge
        challenge_response_msg = CHALLENGE_RESPONSE(
            'CHALLENGE_RESPONSE',
            {'client_id': self._context.client_id, 'response': signed})
        if self._context.disconnect_other_client:
            key = "force_other_client_disconnection"
            challenge_response_msg.parameters[key] = True
#            challenge_response_msg.set_force_other_client_disconnection()
        self._context.disconnect_other_client = False
        self._context.output_message_queue.put(challenge_response_msg)
        self._set_next_state(StateRegister.get('ChallengeResponseState'))

    def _handle_message_UNKNOWN_CLIENT_ID_ERROR(self, message):
        """The server didn't recognize our client, go relinking.
        """
        self.logger.error(u'Server refused the client id: %s' % self._context.client_id)
        relink_user(self)

    def _handle_message_ERROR(self, message):
        """Received an error from the server. Was it because of an
        invalid username?
        """
        error_code = message.getParameter('error_code')
        reason = message.getParameter('reason')

        if error_code != UNEXPECTED_DATA \
        or not reason.startswith("Invalid username provided"):
            ServerSessionState._handle_message_ERROR(self, message)
            return

        self.logger.error('Server refused the username: %s' % self._context.username)
        relink_user(self)


class ChallengeResponseState(ServerSessionState):
    """Sent server the signed challenge to authenticate ourselves,
    waiting for a reply.
    """
    accepted_messages = ServerSessionState.accepted_messages + \
        ['CHALLENGE_VERIFY_RESPONSE']

    def _handle_message_CHALLENGE_VERIFY_RESPONSE(self, message):
        """Received a reply to our challenge. Did the server authenticate
        us? If not, maybe another client is already connected to this
        account.
        """
        auth_result = message.getParameter('result')
        if auth_result:
            self.logger.info(u"Client has successfully authenticated itself.")
            self._context.output_message_queue.put(READY_FOR_SERVICE('READY_FOR_SERVICE'))
            self._context.session_id = message.get_session_id()
            self.logger.debug(
                u"Received Session id %s from server" % self._context.session_id)
            self._context.keepalive_timer.resume_execution()
            self._set_next_state(StateRegister.get('ReadyForServiceState'))
        else:
            self.logger.error(u"Server rejected client authentication.")
            self._context._internal_facade.set_global_status(GStatuses.NC_NOTAUTHORIZED)
            if message.is_other_client_connected():
                client = message.get_other_connected_client()
                if client["client_id"]==0:
                    other_client_message = u"Your web client is already connected"
                else:
                    other_client_message = \
                        u"Client number %s from computer %s already connected" \
                        % (client["client_id"], client["hostname"])
                self.logger.warning(other_client_message)
                self._context.disconnect_other_client = True
                force_disconnection = self._context._ui_controller.ask_for_user_input(
                    "other_client_connected", client["client_id"],
                    client["hostname"])
                if not force_disconnection == 'ok':
                    self._context._internal_facade.pause()
                    return
                else:
                    self._context.current_state._set_next_state(
                        StateRegister.get('DisconnectedState'))
                    self._context._input_queue.put(Command('CONNECT'), 'sessioncommand')
                    return
            else:
                relink_user(self)


class ReadyForServiceState(ServerSessionState):
    """Authentication went well, now we are ready for the serious stuff.
    """
    accepted_messages = ServerSessionState.accepted_messages + \
        ['COMMIT_FORCE', 'SYNC_READY']

    def _on_entering(self):
        self.logger.debug('State changed')
        self._context._internal_facade.set_global_status(GStatuses.C_NOTALIGNED)

    def _handle_message_COMMIT_FORCE(self, message):
        """As the first thing, the server wants to resume a commit
        pending from the last session, which was interrupted.
        """
        self.logger.info(u"Resuming a commit pending from the last session...")
        self._set_next_state(StateRegister.get('PendingCommitState'))

    def _handle_message_SYNC_READY(self, message):
        """The server is ready to start syncing. So we are.
        """
        self.logger.info(u"Starting Startup Synchronization phase.")
        self._context.output_message_queue.put(SYNC_START('SYNC_START'))
        self._set_next_state(StateRegister.get('SyncStartState'))

    def _handle_command_STARTSYNCPHASE(self, command):
        """Finished to resume a pending commit, starting the synchronization
        phase.
        """
        self._handle_message_SYNC_READY(None)


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = register
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Global register which gives access to ServerSession's states.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""


class StateRegister(object):
    """Global register which gives access to ServerSession's states.

    States (instances of any subclass of filerockclient.serversession.
    states.abstract.Abstract) are singleton objects, stored here.
    StateRegister also creates them the first time they are accessed,
    so being also a Factory.

    The StateRegister class has only static methods and is usually
    statically accessed - that is, without creating any instance of it.
    """

    # TODO: probably a python module would be more pythonic than a
    # static class. Moreover, we really should remove any static access
    # from ServerSession. The register (class or module) may be passed
    # as an argument.

    instances = {}
    session = None
    phases = []

    @classmethod
    def setup(cls, session):
        """Initialization method.

        Call this just once at application startup.

        @param session:
                    Instance of filerockclient.serversession.
                    server_session.ServerSession.
        """
        cls.instances = {}
        cls.session = session
        import filerockclient.serversession.states.pre_authentication
        import filerockclient.serversession.states.sync_diff
        import filerockclient.serversession.states.sync_download
        import filerockclient.serversession.states.replication_and_transfer
        import filerockclient.serversession.states.commit
        import filerockclient.serversession.states.integrity_error
        cls.phases = [
            filerockclient.serversession.states.pre_authentication,
            filerockclient.serversession.states.sync_diff,
            filerockclient.serversession.states.sync_download,
            filerockclient.serversession.states.replication_and_transfer,
            filerockclient.serversession.states.commit,
            filerockclient.serversession.states.integrity_error
        ]

    @classmethod
    def get(cls, state_name):
        """Get the state instance whose class has the given name.

        The singleton instance of a state is created the first time this
        method is called.

        @param state_name:
                    String, name of the class of the state instance we
                    want to get.
        """
        if state_name not in cls.instances:
            state_class = None
            for phase in cls.phases:
                try:
                    state_class = getattr(phase, state_name)
                except AttributeError:
                    pass
            assert state_class is not None
            cls.instances[state_name] = state_class(cls.session)
        return cls.instances[state_name]


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = replication_and_transfer
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Collection of the "replication & transfer" ServerSession's states.

We call "replication & transfer" the set of session states that belong
to the time when the updates on the local data are replicated on the
remote storage. For example, uploads are performed in this phase.

ServerSession keeps track of the current "transaction", a container for
replication actions, which is committed when it gets too large or when
the server (or the user) asks so.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import base64
import binascii
import datetime
import socket

from FileRockSharedLibraries.Communication.Messages import \
    REPLICATION_DECLARE_REQUEST
from FileRockSharedLibraries.Communication.RequestDetails import \
    ENCRYPTED_FILES_IV_HEADER_FIELD_NAME

from filerockclient.interfaces import GStatuses, PStatuses
from filerockclient.exceptions import *
from filerockclient.workers.filters.encryption import utils as CryptoUtils
from filerockclient.serversession.states.abstract import ServerSessionState
from filerockclient.serversession.states.register import StateRegister
from filerockclient.serversession.commands import Command


class EnteringReplicationAndTransferState(ServerSessionState):
    """Preparing for entering the actual R&T state.

    ServerSession pass through this state only once per session, at the
    beginning, thus not after a successful commit.
    """

    def _handle_command_UPDATEBEFOREREPLICATION(self, command):
        """Initialize all data structures and components.
        """
        storage_content = self._context.storage_cache.get_all_records()
        self._update_client_status(storage_content)
        self._update_filesystem_watcher(storage_content)
        self._context.filesystem_watcher.resume_execution()
        self.logger.info(u'Started filesystem monitoring.')
        self._context.refused_declare_count = 0
        self._context.id = 0
        self._try_set_global_status_aligned()
        self._set_next_state(StateRegister.get('ReplicationAndTransferState'))

    def _update_client_status(self, storage_content):
        """Initialize the central data structure that holds the status
        for all known pathnames of the warebox.

        The initial status of a pathname is the one in the storage
        cache, that is, the last known synchronized status.
        """
        known_pathnames = (content[0] for content in storage_content)
        self._context._internal_facade.learn_initial_status(known_pathnames)

    def _update_filesystem_watcher(self, storage_content):
        """
        Initialize the filesystem watcher component.

        Creates an initial state of the FilesystemWatcher equal to the
        current state of the storage. Any modification done by the user
        in the meanwhile (and any modification done by
        StartupSynchronization) will be eventually detected.
        """
        # TODO: merge this into self._update_client_status().
        self._context.filesystem_watcher.reset()
        for path, warebox_size, _, lmtime, warebox_etag, _ in storage_content:
            self._context.filesystem_watcher.learn_pathname(
                path, warebox_size, lmtime, warebox_etag)


class ReplicationAndTransferState(ServerSessionState):
    """Replicating local data to the remote storage.

    This state receives PathnameOperation objects from its input queue,
    which must be given to some worker for execution. When all workers
    are busy it stop listening for operations, until a worker become
    available again.
    """

    accepted_messages = ServerSessionState.accepted_messages + \
        ['REPLICATION_DECLARE_RESPONSE', 'COMMIT_FORCE',
        'USER_QUOTA_EXCEEDED']

    def __init__(self, session):
        ServerSessionState.__init__(self, session)
        self.last_operation_time = datetime.datetime.now()
        self._context.listening_operations = True

    def _receive_next_message(self):
        queues = [
            'usercommand', 'sessioncommand',
            'systemcommand', 'servermessage'
        ]
        if self._context.listening_operations:
            queues.append('operation')
        return self._context._input_queue.get(queues)

    def _on_entering(self):
        self.logger.debug(u"Started replication & transfer phase.")
        if self._context.worker_pool.exist_free_workers():
            self._context.listening_operations = True
        self._context._scheduler.schedule_action(
            func=self._check_time_to_commit, name='check_time_to_commit',
            seconds=self._context.commit_threshold_seconds, repeating=True)
        self.logger.info(u'Ready. Listening for events...')

    def _on_leaving(self):
        self._context._scheduler.unschedule_action(self._check_time_to_commit)

    def _handle_command_WORKERFREE(self, command):
        """A worker is available, start to serve operations again.
        """
        if self._context.worker_pool.exist_free_workers():
            self._context.listening_operations = True

    def _handle_operation(self, file_operation):
        """Here is an operation to do for replicating a local pathname.
        Do everything needed to synchronize it.

        If it's OK to serve it (e.g. it hasn't been aborted) then it's
        first declared to the server and then given to some worker.
        """
        assert file_operation.verb in ['UPLOAD', 'DELETE', 'REMOTE_COPY'], \
            "Unexpected operation verb while in state %s: %s" \
            % (self.__class__.__name__, file_operation)

        self.logger.debug(u"Received file operation: %s" % file_operation)
        if file_operation.is_aborted():
            return

        file_operation.register_reject_handler(on_operation_rejected)
        self._context._internal_facade.set_global_status(GStatuses.C_NOTALIGNED)

        # The "encrypted" folder is invariantly part of the warebox and gets
        # automatically re-created when deleted by the user.
        # The server won't accept to delete it.
        if file_operation.verb == 'DELETE' \
        and file_operation.pathname == u'encrypted/':
            file_operation.complete()
            self._try_set_global_status_aligned()
            return

        CryptoUtils.prepare_operation(file_operation)
        if CryptoUtils.to_encrypt(file_operation):
            self.logger.debug(u"Sending operation to encryption: %s" % file_operation)
            self._context.cryptoAdapter.put(file_operation)
            return

        op_id = self._next_id()
        must_declare = self._context.transaction_manager.handle_operation(
            op_id, file_operation, self)
        if not must_declare:
            self._try_set_global_status_aligned()
            return

        # The operation is not aborted nor ignored, process it
        if file_operation.verb == 'UPLOAD':
            # Note: operations different from uploads don't need workers
            if not self._context.worker_pool.acquire_worker():
                raise FileRockException(
                    u"Concurrency trouble in %s: could not acquire a worker"
                    " although some should have been available"
                    % (self.__class__.__name__ + "._handle_file_operation"))

            if __debug__:
                self._context.worker_pool.track_acquire_anonymous_worker(
                    file_operation.pathname)

            if not self._context.worker_pool.exist_free_workers():
                self._context.listening_operations = False

        self._declare_operation(file_operation, op_id)
        self._check_time_to_commit()

    def _declare_operation(self, operation, op_id):
        """Declare to the server our intention to synchronize a pathname.
        The reply will contain, among other thing, an authorization
        token for accessing the storage.
        """
        self.logger.info(
            u'Synchronizing pathname: %s "%s"'
            % (operation.verb, operation.pathname))
        request = self._create_declare_message(op_id, operation)
        #self.logger.debug(u"Produced Declare message: %s", request)
        self._context.output_message_queue.put(request)

    def _create_declare_message(self, op_id, file_operation):
        """Produce an instance of message for declaring an operation
        to the server.
        """
        params = {}
        params['request_id'] = op_id
        params['pathname'] = file_operation.pathname
        params['operation'] = file_operation.verb
        if file_operation.verb == 'REMOTE_COPY':
            params['paired_pathname'] = file_operation.oldpath
        else:
            params['paired_pathname'] = ''
        if file_operation.verb == 'UPLOAD':
            params['Content_MD5'] = base64.b64encode(
                binascii.unhexlify(file_operation.storage_etag))
            params['Content_Type'] = 'application/octet-stream'
            params['Content_Length'] = file_operation.storage_size
            if file_operation.to_encrypt:
                field_name = ENCRYPTED_FILES_IV_HEADER_FIELD_NAME
                params[field_name] = file_operation.iv
        else:
            params['Content_MD5'] = ''
            params['Content_Type'] = ''
            params['Content_Length'] = ''

        return REPLICATION_DECLARE_REQUEST(
            "REPLICATION_DECLARE_REQUEST", {'request_details': params})

    def _next_id(self):
        """Get the next operation ID.

        Each operation is assigned a numeric identifier.
        """
        self._context.id += 1
        if self._context.id > 999999:
            self._context.id = 1
        return self._context.id

    def _handle_message_REPLICATION_DECLARE_RESPONSE(self, message):
        """The server has replied to our request to synchronize a
        pathname. If everything went OK, send the operation to some
        worker.

        If the answer is positive than the message contains the
        authentication token for accessing the storage. Otherwise
        we'll retry to declare the operation for a few times before
        giving up.
        """
        #self.logger.debug(u"Received declare response: %s", message)
        op_id = message.getParameter('response_details').request_id
        operation = self._context.transaction_manager.get_operation(op_id)

        if message.getParameter('response_details').result is False:
            self.logger.debug(
                u"Negative Declare Response for operation: %s" % operation)
            if self._context.refused_declare_count > self._context.refused_declare_max:
                raise ProtocolException("Too many negative Declare Responses")
            self.logger.debug(
                u"Trying again in %s seconds the refused declaration of %s"
                % (self._context.refused_declare_waiting_time, operation))
            self._context.refused_declare_count += 1
            operation.unregister_reject_handler(on_operation_rejected)
            self._context.transaction.remove_operation(op_id)
            if operation.verb == 'UPLOAD':
                self._context.worker_pool.release_worker()
                if __debug__:
                    self._context.track_release_unassigned_worker(operation.pathname)
            self._context._input_queue.append(operation, 'operation')
            self._set_next_state(StateRegister.get('WaitingOnDeclarationFailure'))
            return

        self._context.operation_responses[op_id] = message
        must_be_processed = self._context.transaction_manager.authorize_operation(op_id)
        if not must_be_processed:
            return

        # The operation is not aborted nor collapsed, process it
        if operation.verb == 'UPLOAD':
            response = message.getParameter('response_details')
            operation.upload_info = {}
            operation.upload_info['remote_pathname'] = response.journal_pathname
            operation.upload_info['bucket'] = response.bucket
            operation.upload_info['auth_token'] = response.auth_token
            operation.upload_info['auth_date'] = response.auth_date
            new_ip = response.storage_connector_ip

            if new_ip != self._context.storage_ip_address:
                try:
                    _, _, ipaddrlist = socket.gethostbyname_ex(self._context.storage_hostname)
                except socket.error as e:
                    raise Exception("Error while resolving storage ip %s: %s"
                        % (new_ip, e))
                if not new_ip in ipaddrlist:
                    #raise ProtocolException('Detected a malicious IP' +
                    #    ' address for the storage coming from the server:' +
                    #    ' %s not in %s' % (new_ip, ipaddrlist))
                    self.logger.warning(
                        u"Server sent an IP addresss for the storage service"
                        " that couldn't be verified by a DNS query: %s not in"
                        " %s. It will be accepted nevertheless."
                        % (new_ip, ipaddrlist))
                self._context.storage_ip_address = new_ip
                self.logger.debug("New IP address for storage: %s" % new_ip)
            operation.upload_info['remote_ip_address'] = self._context.storage_ip_address
            self._context.worker_pool.send_operation(operation)
        elif operation.verb == 'DELETE' or operation.verb == 'REMOTE_COPY':
            self.logger.info(
                u'Synchronized pathname: %s "%s", which will be persisted '
                'after a commit' % (operation.verb, operation.pathname))
            operation.complete()
            if operation.verb == 'DELETE':
                operation.notify_pathname_status_change(PStatuses.DELETESENT)
            else:
                operation.notify_pathname_status_change(PStatuses.RENAMESENT)

    def postpone_operation(self, operation):
        """Push an operation back to the input queue, so that it will
        be received again the next time.
        """
        self.logger.debug(u"Postponing file operation: %s" % (operation))
        self._context._input_queue.append(operation, 'operation')

    def on_commit_necessary_to_proceed(self):
        """Session can decide to commit the current transaction. It
        happens if the transaction has got too large, if it's passed too
        much time from the last commit or if a commit is needed to honor
        some session constraint.
        """
        self.logger.info(
            u"The application has decided that a commit is necessary")
        self._set_next_state(
            StateRegister.get('WaitingForUnauthorizedOperationsState'))

    def _update_last_operation_time(self):
        """Remember the last time we synchronized something.
        """
        if not self._context._input_queue.empty(['operation']):
            self.last_operation_time = datetime.datetime.now()

    def _check_time_to_commit(self):
        """If it's time to commit, so be it.
        """
        if self._is_time_to_commit():
            self._context._input_queue.put(Command('COMMIT'), 'sessioncommand')

    def _handle_command_COMMIT(self, command):
        """Go to the commit state to start a commit.
        """
        self.logger.info(u"Committing the current transaction")
        self._set_next_state(
            StateRegister.get('WaitingForUnauthorizedOperationsState'))

    def _is_time_to_commit(self):
        """
        Tell whether it's time to commit the current transaction.

        The values considered to make a decision are:
         * now: current time
         * t.size: number of operations in transaction
         * op: time of the last seen operation.
        It is time to commit when:
        t.size > 0 and (
            either (t.size > max_size_allowed)
            or (op > max_time_allowed)
            or (size > max_size_allowed)
        )
        """
        self._update_last_operation_time()
        need = self._context.transaction.size() > 0
        op_count = self._context.transaction.size() >= self._context.commit_threshold_operations
        timeout = datetime.datetime.now() - self.last_operation_time > \
            datetime.timedelta(seconds=self._context.commit_threshold_seconds)
        size = self._context.transaction.data_size() > self._context.commit_threshold_bytes
        return (need and (timeout or op_count or size))

    def _immediate_commit(self):
        """Pre-emptive style commit.

        Usually ServerSession wait for authorization from the server
        for those operations that were already declared, before actually
        start a commit. But sometimes you just can't wait, so all
        still unauthorized operations are postponed. For example this
        happens when the user asked to commit - hey, it's better not to
        contradict the boss.
        """
        unauthorized = self._context.transaction_manager.flush_unauthorized_operations()
        for operation in unauthorized:
            self.postpone_operation(operation)
            self._context.worker_pool.release_worker()
            if __debug__: 
                self._context.worker_pool.track_release_unassigned_worker(operation)
        self._set_next_state(StateRegister.get('CommitState'))

    def _handle_command_USERCOMMIT(self, message):
        """Start a commit due to the will of the user.
        """
        self.logger.info(u"User has requested commit")
        self._immediate_commit()

    def _handle_message_COMMIT_FORCE(self, message):
        """Start a commit due to the will of the server.
        """
        self.logger.info(u"Server has forced commit")
        self._immediate_commit()

    def _handle_message_USER_QUOTA_EXCEEDED(self, message):
        """Oh dear, we declared an operation to the server and he
        has answered that we haven't enough space for the upload on the
        remote storage. The operation will be ignored until some space
        is freed.
        """
        # TODO: we don't actually handle the available space, so the
        # ignored operation will keep being ignored until the next
        # session. We can do better.
        operation_id = message.getParameter('request_id')
        operation = self._context.transaction_manager.get_operation(operation_id)
        self._context.transaction_manager.remove_operation(operation_id)
        operation.complete()
        operation.notify_pathname_status_change(PStatuses.UNKNOWN)

        user_used_space = message.getParameter('user_used_space')
        pathname = message.getParameter('pathname')
        user_quota = message.getParameter('user_quota')
        size = message.getParameter('size')

        self._context._internal_facade.pause()
        self._context._ui_controller.notify_user('disk_quota_exceeded',
                                                 user_used_space,
                                                 user_quota,
                                                 pathname,
                                                 size)


def on_operation_rejected(operation):
    """Called by a worker that couldn't complete an operation.

    Note: the calling thread is the worker's one, not ServerSession's.
    """
    # TODO: try to reset just the session instead of the whole client.
    raise FileRockException("Operation rejected: %s" % operation)


class WaitingOnDeclarationFailure(ServerSessionState):
    """ServerSession gets to this state when a declaration for an
    operation has been refused by the server. It waits for a while
    and then retries.
    """

    def _receive_next_message(self):
        """Stop serving operations.
        """
        return self._context._input_queue.get(['usercommand', 'sessioncommand'])

    def _on_entering(self):
        """Schedule another attempt to declare the operation.
        """
        self._context._internal_facade.set_global_status(GStatuses.C_SERVICEBUSY)
        self._context._scheduler.schedule_action(
            self._wake_me_up, seconds=self._context.refused_declare_waiting_time)

    def _wake_me_up(self):
        """Callback for the scheduler.
        """
        self._context._input_queue.put(Command('REDECLAREOPERATION'), 'sessioncommand')

    def _handle_command_REDECLAREOPERATION(self, command):
        """It's time, go back to R&T and let's declare the operation one
        more time.
        """
        self._set_next_state(StateRegister.get('ReplicationAndTransferState'))

    def _handle_command_USERCOMMIT(self, message):
        """The user has asked to commit, the operation will be recovered on
        next R&T loop.
        """
        self._set_next_state(StateRegister.get('ReplicationAndTransferState'))
        self._context._input_queue.put(Command('USERCOMMIT'), 'sessioncommand')

    def _on_leaving(self):
        """Cancel the scheduled callback.
        """
        self._context._scheduler.unschedule_action(self._wake_me_up)


class WaitingForUnauthorizedOperationsState(ReplicationAndTransferState):
    """We get to this state because the client has decided that a commit
    is necessary. It acts like the ReplicationAndTransferState but
    doesn't send new requests to the server, just listening for responses.

    We stay here until either:
        - all operations in transaction have been authorized or aborted;
        - someone (the user, the server) forces a commit.
    In the latter case case we give up and all unauthorized operations
    get postponed, as usual.

    Note: this is a subclass of ReplicationAndTransferState.
    """

    def _receive_next_message(self):
        """Differently from ReplicationAndTransferState, here new
        operations aren't served.
        """
        return self._context._input_queue.get([
            'usercommand', 'sessioncommand', 'systemcommand', 'servermessage'])

    def _on_entering(self):
        """Prepare for waiting all the requested authorizations.
        """
        self.logger.debug(u"Waiting for all operations in transaction"
                          " to be authorized...")
        self.logger.info(u"Preparing to commit...")

        if self._context.transaction_manager.all_operations_are_authorized():
            self._pass_to_next_state()

    def _handle_message_REPLICATION_DECLARE_RESPONSE(self, message):
        """Received a reply from the server for one of the declared
        operations.

        If the answer is positive then act as usual (send it to some
        worker), otherwise postpone it, it will be served in the next
        transaction.
        """
        if message.getParameter('response_details').result is True:
            cls = ReplicationAndTransferState
            cls._handle_message_REPLICATION_DECLARE_RESPONSE(self, message)
        else:
            id_ = message.getParameter('response_details').request_id
            operation = self._context.transaction_manager.get_operation(id_)
            self._context.transaction.remove_operation(id_)
            if operation.verb == 'UPLOAD':
                self._context.worker_pool.release_worker()
            self._context._input_queue.append(operation, 'operation')
        if self._context.transaction_manager.all_operations_are_authorized():
            self._pass_to_next_state()

    def _pass_to_next_state(self):
        """Go to the commit state.
        """
        self.logger.debug(
            u"All operations have been authorized, let's commit.")
        self._set_next_state(StateRegister.get('CommitState'))


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = sync_diff
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Collection of the "synchronization" ServerSession's states.

We call "synchronization" (or just "sync") the set of session states
that belong to the time when the client has just connected to the server
and must download any modification made on the remote storage by other
clients of the same account. For example, downloads are performed in
this phase. The sync phase must resolve any conflict due to local and
remote modification on the same data, both done while this client was
not connected.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import socket
import os
import re

from FileRockSharedLibraries.Communication.Messages import \
    SYNC_GET_ENCRYPTED_FILES_IVS
from filerockclient.interfaces import GStatuses, PStatuses
from filerockclient.util.utilities import format_to_log, get_hash
from filerockclient.exceptions import *
from filerockclient.workers.filters.encryption import \
    utils as CryptoUtils, helpers as CryptoHelpers
from filerockclient.serversession.states.abstract import ServerSessionState
from filerockclient.serversession.states.register import StateRegister
from filerockclient.databases import metadata


def remove_lmtime_from_filelist(filelist):
    obj = [{u'etag': entry['etag'],
            u'key': entry['key'],
            u'size': entry['size']}
           for entry in filelist]
    return obj


class SyncStartState(ServerSessionState):
    """The sync phase has begun. Waiting for a reply of the server
    with the remote filelist.

    The remote filelist is the current content of the remote storage.
    We must detect what's changed from the last time this client was
    connected, both in the local warebox and on the remote storage,
    merge the remote modifications into the warebox and resolve any
    conflict.
    """
    accepted_messages = ServerSessionState.accepted_messages + \
        ['SYNC_FILES_LIST', 'SYNC_ENCRYPTED_FILES_IVS']

    def _on_entering(self):
        """Resolve the storage hostname (which came from the configuration
        into an IP address).
        """
        self.logger.debug('State changed')
        try:
            self._context.storage_ip_address = \
                socket.gethostbyname(self._context.storage_hostname)
        except socket.error as e:
            raise Exception("Error while resolving storage hostname %s: %s"
                            % (self._context.storage_hostname, e))
        ip = self._context.storage_ip_address
        self.logger.debug("Starting storage IP address: %s" % ip)

    def _validate_storage_content(self, remote_dataset):
        """Validate the format of the remote filelist received from the
        server.

        Note: the filelist gets sorted by pathname.
        """
        remote_dataset.sort(key=lambda record: record['key'])
        valid_md5 = re.compile('[0-9a-z]{32}')

        #self.logger.debug(u'Content received from the server:')
        for record in remote_dataset:

            # Force unicode on text data since on some platforms the
            # "json.loads" method of the json library generates unicode objects
            # only "if necessary", that is, only if the string contains non
            # ASCII characters, while we always need unicode objects.
            # Damn json library.
            record['key'] = unicode(record['key'])
            record['etag'] = unicode(record['etag'])

            # Remove the evil double quotes sent by the storage.
            record['etag'] = record['etag'].replace('"', '')
            r = (record['key'], record['etag'], record['size'], record['lmtime'])
            #self.logger.debug('\t%r, %r, %r, %r' % r)

            # Validate the format of the etag
            if not valid_md5.match(record['etag']):
                raise ProtocolException("Invalid etag for pathname '%r': %r"
                                        % (record['key'], record['etag']))

        #self.logger.debug(u'End of content received from the server.')

    def _handle_message_SYNC_FILES_LIST(self, message):
        """Received the remote filelist from the server. Compute
        differences, perform integrity checks on it and ask the user
        confirmation to proceed with the synchronization.

        Message: SYNC_FILES_LIST
        Parameters:
            last_commit_client_id: String or None
            last_commit_client_hostname: String or None
            last_commit_client_platform: String or None
            last_commit_timestamp: Number
            used_space: Number
            basis: String
            user_quota: Number

            optional parameters:

            plan: a dictionary as follows (mandatory)
                      { id: <plan_id>,    # a number
                        space: <plan_space_in_GB>,   # a number (within a plan this is mandatory and 'not None')
                        price: <price_in_$>,      # a number    (if absent or ==None it means "free")
                        payment_type: <(SINGLE|SUBSCRIPTION)>,   # unicode  (present if price is not None)
                        payment_recurrence: <(MONTHLY|YEARLY)>   # unicode  (present if price is not None)
                        }
            expires_on: <GMT-Date-or-None>    # a number representing a unix timestamp UTC (mandatory)
                        (it might None if plan is "forever", this is the expiration date of the subscription,
                         it does not change when in grace time).
            status: <(TRIAL|ACTIVE|GRACE|SUSPENDED|MAINTAINANCE)>  # unicode (mandatory)


        """
        storage_content = message.getParameter('dataset')
        self.storage_content = storage_content
        self._validate_storage_content(storage_content)

        self.server_basis = message.getParameter('basis')
        self.candidate_basis = self._try_load_candidate_basis()
        self.client_basis = self._load_trusted_basis()

        fields = [
            'last_commit_client_id',
            'last_commit_client_hostname',
            'last_commit_client_platform',
            'last_commit_timestamp',
            'used_space',
            'user_quota',
            'plan',
            'status',
            'expires_on'
        ]
        info = dict(map(lambda f: (f, message.getParameter(f)), fields))

        # trial
        # info.update(status='ACTIVE_TRIAL',
        #             expires_on=1366814411,
        #             plan=dict(
        #                 space=1
        #                 )
        #             )

        # beta
        # info.update(status='ACTIVE_BETA',
        #             expires_on=None,
        #             plan=dict(
        #                 space=3
        #                 )
        #             )

        # expired
        # info.update(status='ACTIVE_GRACE',
        #             expires_on=1366810000,
        #             plan=dict(
        #                 space=1,
        #                 payment_type='SUBSCRIPTION',
        #                 payment_recurrence='MONTHLY'
        #                 )
        #             )

        # good yearly
        # info.update(status='ACTIVE_PAID',
        #             expires_on=1366810000,
        #             plan=dict(
        #                 space=1,
        #                 payment_type='SUBSCRIPTION',
        #                 payment_recurrence='YEARLY'
        #                 )
        #             )

        self._context._ui_controller.update_session_info(info)

        # No blacklisted pathname should be found on the storage. If any, tell
        # the user and then shut down the application.
        remote_pathnames = [entry['key'] for entry in storage_content]
        blacklisted = filter(
            lambda x: self._context.warebox.is_blacklisted(x),
            remote_pathnames)
        if len(blacklisted) > 0:
            self.logger.critical(
                'The following blacklisted pathnames have been found on the '
                'storage %s' % format_to_log(blacklisted))
            self._context._ui_controller.ask_for_user_input(
                'blacklisted_pathname_on_storage', blacklisted)
#            self._internal_facade.terminate()
            self._context._internal_facade.pause()
            return

        # Detect actions to be taken for synchronization as well as conflicts
        self.logger.debug(u"Starting computing the three-way diff...")
        try:
            self._context.startup_synchronization.prepare(
                                                    storage_content,
                                                    self._context.must_die)
        except ExecutionInterrupted:
            self.logger.debug(u'ExecutionInterrupted, terminating...')
            self._set_next_state(StateRegister.get('DisconnectedState'))
            return
        self.logger.debug(u"Finished computing the three-way diff.")

        # Conflicts on encrypted files need extra data from the server to be
        # solved. If there are any, handle them.
        encrypted_pathnames = CryptoUtils.filter_encrypted_pathname(
            self._context.startup_synchronization.edit_conflicts)
        if len(encrypted_pathnames) > 0:
            self.logger.debug(
                u'Encrypted file in conflict: %r' % encrypted_pathnames)
            message = SYNC_GET_ENCRYPTED_FILES_IVS(
                'SYNC_GET_ENCRYPTED_FILES_IVS',
                {'requested_files_list': encrypted_pathnames})
            self._context.output_message_queue.put(message)
            return

        # If there are no conflicts on encrypted files, just proceed normally.
        try:
            if self._check_hash_mismatch():
                self._start_syncing()
            else:
#                self._internal_facade.terminate()
                self._context._internal_facade.pause()
        except HashMismatchException as excp:
            self.logger.critical('Integrity error %s' % excp)
            self._set_next_state(StateRegister.get('IntegrityErrorState'))

    def _check_hash_mismatch(self):
        """Handles the hash mismatch, if any.

        An "hash mismatch" means that the content on the storage is
        different from what we remember from our last connection. We
        have to ask the user to tell if such modifications are acceptable
        (meaning that the user himself did them with another client)
        or if it's the result of malicious data tampering. The user
        will match both the hash (together with its visual representation,
        the "robohash") and the list of remote modification to replicate
        on the local data to make a decision.

        @return
                    Boolean telling whether it's OK to proceed with the
                    synchronization or not.
        """
        # Collect the data resulting from the diff algorithm
        diff = self._context.startup_synchronization
        content_to_download = sorted(diff.content_to_download)
        content_to_delete_locally = sorted(diff.content_to_delete_locally)
        content_to_delete_locally.reverse()
        edit_conflicts = diff.edit_conflicts
        deletion_conflicts = diff.deletion_conflicts

        # Any pathname to synchronize?
        something_to_sync = len(content_to_download) > 0
        something_to_sync |= len(content_to_delete_locally) > 0
        something_to_sync |= len(deletion_conflicts) > 0

        # Any modification to the storage cache to do?
        storage_cache_needs_update = len(diff.remote_deletions) > 0
        storage_cache_needs_update |= len(diff.ignored_conflicts) > 0

        # Anything the user should be notified of by opening the dialog?
        out_of_sync = something_to_sync or storage_cache_needs_update

        remote_sizes = self._context.startup_synchronization.remote_size
        local_sizes = self._context.startup_synchronization.local_size

        accepted_state = self._context.metadataDB.try_get(
                                                metadata.LASTACCEPTEDSTATEKEY)

#        if there is an accepted basis but it is the same of the current basis
#        and there is nothing to sync, maybe the client was crashed before
#        removing it from storage_cache
        if accepted_state is not None:
            accepted_basis, _ = accepted_state.split()
            if not out_of_sync and self.client_basis == accepted_basis:
                self._context.metadataDB.delete_key(metadata.LASTACCEPTEDSTATEKEY)
                accepted_state = None

        if self.client_basis is not None: # First Start, I cannot check anything
            current_state = self._catch_wrong_states(self.storage_content,
                                                     accepted_state,
                                                     out_of_sync)

        if self.client_basis is None:
            client_server_differ = True
        else:
            client_server_differ = (self.server_basis != self.client_basis)

        if self.candidate_basis is None:
            candidate_server_differ = True
        else:
            candidate_server_differ = (self.server_basis != self.candidate_basis)

        # Ask the user if he's OK with proceeding with the synchronization
        if self.client_basis is None or accepted_state is None \
        or accepted_state != current_state:
            if client_server_differ and candidate_server_differ:
                if out_of_sync \
                and not self._user_accepts_synchronization(
                            content_to_download, content_to_delete_locally,
                            edit_conflicts, deletion_conflicts,
                            self.client_basis, self.server_basis,
                            remote_sizes, local_sizes):
                    self.logger.warning(
                        u'User has refused the synchronization, shutting down')
                    return False

                storage_list_hash = get_hash(remove_lmtime_from_filelist(self.storage_content))
                to_save = "%s %s" % (self.server_basis, storage_list_hash)
                self._context.metadataDB.set(metadata.LASTACCEPTEDSTATEKEY, to_save)
                self._save_basis_in_history(self.client_basis,
                                                     self.server_basis,
                                                     True)

        if self._context._internal_facade.is_first_startup():
            self._save_basis_in_history(self.client_basis,
                                                 self.server_basis,
                                                 True)

        return True

    def _catch_wrong_states(self,
                            storage_content,
                            accepted_state,
                            out_of_sync):
        """Perform basic integrity checks on the basis/filelist sent
        by the server.

        The (basis, filelist) pair can be one of those that we already
        know: the trusted, the candidate, the accepted. In such case
        there is nothing new to synchronize. If both the elements of the
        pair have changed then we have to ask the user for confirmation.
        If only one has changed then we can tell for sure that something
        is wrong about the integrity of this synchronization.

        @param storage_content:
                    Filelist of the remote storage.
        @param accepted_state:
                    A (basis, filelist_hash) pair that we accepted on
                    last synchronization, if any.
        @param out_of_sync:
                    Boolean flag telling whether there are remote
                    modification to replicate on the local data.
        """

        declared_content = get_hash(remove_lmtime_from_filelist(storage_content))
        current_state = "%s %s" % (self.server_basis, declared_content)

        self.logger.debug('storage_content = %s', storage_content)
        self.logger.debug('server_state = %s', current_state)
        self.logger.debug('accepted_state = %s', accepted_state)
        self.logger.debug('out_of_sync = %s', out_of_sync)

        if out_of_sync:
            if self.server_basis == self.client_basis:
                raise HashMismatchException('ERROR! Something to sync with same basis')
            else:
                self._check_accepted_state(accepted_state, storage_content)
        else:
            if self.server_basis == self.client_basis:
                accepted_state = None

            self._check_accepted_state(accepted_state, storage_content)

            if accepted_state is not None:
                accepted_basis, _ = accepted_state.split()

            if self.candidate_basis is None:
                check_candidate_basis = True
            else:
                check_candidate_basis = (self.server_basis != self.candidate_basis)

            if (accepted_state is None or self.server_basis != accepted_basis) \
            and self.server_basis != self.client_basis \
            and check_candidate_basis:
                raise HashMismatchException('ERROR! Basis mismatch but nothing to sync')

        return current_state

    def _check_accepted_state(self, accepted_state, storage_content):
        """
        If there was an accepted_state, checks if the declared state is
        coherent with the accepted one.

        The server cannot declare same basis with different content or
        viceversa.

        @param accepted_state:
                an accepted state, None if not state was accepted or a
                string as "server_basis<space>get_hash(declared_content)"
        @param storage_content:
                list of files declared from server
        """
        declared_content = get_hash(remove_lmtime_from_filelist(storage_content))
        if accepted_state is not None:
            accepted_basis, accepted_content = accepted_state.split()
            same_basis = (accepted_basis == self.server_basis)
            same_content = (accepted_content == declared_content)

            if (same_basis and not same_content)\
            or (same_content and not same_basis):
                raise HashMismatchException('ERROR! Basis mismatch Server declare inconsistent ServerBasis and StorageContent')

    def _start_syncing(self):
        """The list of modification to perform has been accepted, make
        the synchronization phase start.
        """
        self._context.integrity_manager.setCurrentBasis(self.server_basis.encode())
        self._context._internal_facade.set_global_status(GStatuses.C_NOTALIGNED)
        self._context.startup_synchronization.execute()
        self._context.startup_synchronization.generate_downlink_events()
        self._set_next_state(StateRegister.get('ResolvingDeletionConflictsState'))

    def _conflicted_pathname(self, pathname):
        # TODO: try harder in finding a name that is available
#        curr_time = datetime.now().strftime('%Y-%m-%d %H_%M_%S')
        suffix = u' (Conflicted on YYYY-MM-dd HH_mm_ss)'  # % curr_time
        if pathname.endswith('/'):
            new_pathname = pathname[:-1] + suffix + '/'
        else:
            basename, ext = os.path.splitext(pathname)
            new_pathname = basename + suffix + ext
        return new_pathname

    def _user_accepts_synchronization(self,
            content_to_download, content_to_delete_locally,
            edit_conflicts, deletion_conflicts, client_basis, server_basis,
            remote_sizes, local_sizes):
        """Use the user interface to ask the user to accept the
        current synchronization.

        @param content_to_download:
                    List of pathnames that must be downloaded.
        @param content_to_delete_locally:
                    List of warebox pathnames that must be deleted.
        @param edit_conflicts:
                    List of pathnames that have changed both locally
                    and remotely.
        @param deletion_conflicts:
                    List of pathnames that have been modified locally
                    but deleted remotely.
        @param client_basis:
                    Our last trusted basis.
        @param server_basis:
                    The new basis sent by the server.
        @param remote_size:
                    Dictionary with the sizes of the pathnames to
                    download.
        @param local_sizes:
                    Dictionary with the sizes of the pathnames in the
                    warebox that need to be modified.
        @return
                    Boolean telling whether the user accepts the
                    synchronization.
        """

        # Prepare the detected changes as a list of "operations" (dictionaries)
        # to be reported to the user.
        operations = []

        # Prepare the content to download
        for pathname in content_to_download:
            op2 = {
                'pathname': pathname,
                'status': PStatuses.DOWNLOADNEEDED,
                'size': remote_sizes[pathname]
            }
            conflict = pathname in edit_conflicts
            if conflict:
                op1 = {
                    'pathname': pathname,
                    'status': PStatuses.LOCALRENAMENEEDED,
                    'size': local_sizes[pathname],
                    'newpathname': self._conflicted_pathname(pathname)
                }
                operations.append(op1)
            operations.append(op2)

        # Prepare the deletion conflicts.
        # Note: differently from edit conflicts, pathnames in deletion
        # conflicts
        # are removed from content_to_delete_locally. This is because conflict
        # resolving implies local renaming, which implicitly deletes the
        # pathnames. However for correct reporting both deletion_conflicts and
        # content_to_delete_locally must be presented to the user.
        for pathname in deletion_conflicts:
            op1 = {
                'pathname': pathname,
                'status': PStatuses.LOCALCOPYNEEDED,
                'size': local_sizes[pathname],
                'newpathname': self._conflicted_pathname(pathname)
            }
            op2 = {
                'pathname': pathname,
                'status': PStatuses.LOCALDELETENEEDED,
                'size': local_sizes[pathname]
            }
            operations.append(op1)
            operations.append(op2)

        # Prepare the content to delete locally.
        for pathname in content_to_delete_locally:
            op = {
                'pathname': pathname,
                'status': PStatuses.LOCALDELETENEEDED,
                'size': local_sizes[pathname]
            }
            operations.append(op)

        if self._context._internal_facade.is_first_startup():
            client_basis = None

        res = self._context._ui_controller.ask_for_user_input(
            'accept_sync', operations, client_basis, server_basis)

        return res == 'ok'

    def _handle_message_SYNC_ENCRYPTED_FILES_IVS(self, message):
        """We have asked the server to send the IVs for some of the
        encrypted files, here they are. Now it's possible to proceed
        with the synchronization as usual.

        ServerSession needs the etag for both the cleartext and the
        encrypted versions of an encrypted file to correctly detect
        changes. If the storage cache is not available then we need
        to encrypt the files again in order to read their etag. The
        same IVs used the encrypt the first time must be used.

        Basically ServerSession receives this message only if there
        are some encrypted files but there is no storage cache available
        for them.
        """
        self.logger.debug(u"Recomputing the etag for encrypted conflicted pathnames...")
        server_ivs = message.getParameter('ivs')
        server_ivs_notNone = {
            key: server_ivs[key]
            for key in filter(
                lambda key: server_ivs[key] is not None, server_ivs
            )
        }

        try:
            self.logger.debug("I'm going to recalculate all encrypted etags")
            enc_etags = CryptoHelpers.recalc_encrypted_etag(
                                                    server_ivs_notNone,
                                                    self._context.warebox,
                                                    self._context.cfg,
                                                    self._context.must_die)
            self.logger.debug("Encrypted etags recalculated")
        except ExecutionInterrupted:
            self.logger.debug(u'ExecutionInterrupted, terminating...')
            self._set_next_state(StateRegister.get('DisconnectedState'))
            return
        #self.logger.debug(u"Finished recomputing the etag for encrypted conflicted pathnames.")
        #self.logger.debug('IVs received from server\n %r' % server_ivs)
        #self.logger.debug('IVs NotNone\n %r' % server_ivs_notNone)
        #self.logger.debug('encrypted Etag\n %r' % enc_etags)
        #self.logger.debug('Remote Etag\n %r' % self._context.startup_synchronization.remote_etag)
        self._context.startup_synchronization.update_conflicts_of_encrypted_pathnames(enc_etags)

        try:
            if self._check_hash_mismatch():
                self._start_syncing()
            else:
#                self._internal_facade.terminate()
                self._context._internal_facade.pause()
        except HashMismatchException as excp:
            self.logger.critical('Integrity Error %s' % excp)
            self._set_next_state(StateRegister.get('IntegrityErrorState'))


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = sync_download
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Collection of the "synchronization" ServerSession's states.

We call "synchronization" (or just "sync") the set of session states
that belong to the time when the client has just connected to the server
and must download any modification made on the remote storage by other
clients of the same account. For example, downloads are performed in
this phase. The sync phase must resolve any conflict due to local and
remote modification on the same data, both done while this client was
not connected.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import threading

from FileRockSharedLibraries.Communication.Messages import \
    SYNC_DONE, SYNC_GET_REQUEST, PATHNAME_ERROR
from filerockclient.exceptions import *
from filerockclient.workers.filters.encryption import utils as CryptoUtils
from filerockclient.serversession.commands import Command
from filerockclient.serversession.states.abstract import ServerSessionState
from filerockclient.serversession.states.register import StateRegister
from filerockclient.util import multi_queue
from filerockclient.databases import metadata
from FileRockSharedLibraries.IntegrityCheck.Proof import Proof


class ResolveDeletionConflictsTask(object):

    def __init__(self, deletion_conflicts, content_to_delete_locally,
                 trusted_basis, pathname2proof,
                 on_complete, on_abort, on_reject):
        self.verb = 'RESOLVE_DELETION_CONFLICTS'
        self.state = 'working'
        self.deletion_conflicts = list(deletion_conflicts)
        self.content_to_delete_locally = list(content_to_delete_locally)
        self.trusted_basis = trusted_basis
        self.pathname2proof = dict(pathname2proof)
        self._on_complete = on_complete
        self._on_abort = on_abort
        self._on_reject = on_reject

        # this is needed for task tracking facility
        if __debug__:
            self.pathname = "RESOLVE_DELETION_CONFLICTS"

    def complete(self):
        self.state = 'completed'
        self._on_complete(self)

    def reject(self):
        self.state = 'rejected'
        self._on_reject(self)

    def abort(self):
        self.state = 'aborted'
        self._on_abort(self)

    def is_working(self):
        return self.state == 'working'

    def is_aborted(self):
        return self.state == 'aborted'

    def is_completed(self):
        return self.state == 'completed'

    def is_rejected(self):
        return self.state == 'rejected'

    def register_complete_handler(self, handler):
        pass

    def register_reject_handler(self, handler):
        pass

    def register_abort_handler(self, handler):
        pass


class ResolvingDeletionConflictsState(ServerSessionState):
    accepted_messages = ServerSessionState.accepted_messages

    def __init__(self, session):
        ServerSessionState.__init__(self, session)
        self._pathname_to_do = {}
        self._pathname2proof = {}
        self._queues_to_listen = [
            'usercommand', 'sessioncommand', 'systemcommand',
            'servermessage'
        ]

    def _receive_next_message(self):
        return self._context._input_queue.get(self._queues_to_listen)

    def _on_entering(self):
        self._queues_to_listen = [
            'usercommand', 'sessioncommand', 'systemcommand', 'servermessage'
        ]
        self._pathname_to_do = {}
        self._pathname2proof = {}

        diff_result = self._context.startup_synchronization
        diff_result.deletion_conflicts

        if len(diff_result.deletion_conflicts) > 0:
            for pathname in diff_result.deletion_conflicts:
                self._pathname_to_do[pathname] = True
                request = SYNC_GET_REQUEST("SYNC_GET_REQUEST",
                                           {'pathname': pathname})
                #self.logger.debug(u"Produced Request message: %s", request)
                self._context.output_message_queue.put(request)
        else:
            self._on_task_complete(None)

    def _handle_message_ERROR(self, message):
        #self.logger.debug(u"Received declare response: %s", message)

        if message.getParameter('error_code') != PATHNAME_ERROR:
            super(ResolvingDeletionConflictsState, self)._handle_message_ERROR(message)
            return

        # I really hate this
        reason = message.getParameter('reason')
        pathname = reason.replace('Given pathname (', '', 1)
        pathname = pathname.replace(') does no exist.', '', 1)
        assert pathname in self._pathname_to_do

        proof = Proof(message.getParameter('proof'))
        proof.raw = message.getParameter('proof')
        self._pathname2proof[pathname] = proof
        del self._pathname_to_do[pathname]
        self.logger.info(u'Received info on deletion of pathname "%s" '
                         '(still %s to do)' %
                         (pathname, len(self._pathname_to_do)))
        if len(self._pathname_to_do) == 0:
            self._send_task()

    def _send_task(self):
        self._queues_to_listen = ['usercommand',
                                  'sessioncommand',
                                  'systemcommand']

        diff_result = self._context.startup_synchronization
        trusted_basis = self._context.integrity_manager.getCurrentBasis()

        task = ResolveDeletionConflictsTask(
            diff_result.deletion_conflicts,
            diff_result.content_to_delete_locally,
            trusted_basis,
            self._pathname2proof,
            self._on_task_complete,
            self._on_task_abort,
            self._on_task_reject)

        got_it = self._context.worker_pool.acquire_worker()
        assert got_it
        if __debug__:
            self._context.worker_pool.track_acquire_anonymous_worker(task.pathname)
        self._context.worker_pool.send_operation(task)

    def _on_task_complete(self, task):
        self._set_next_state(StateRegister.get('LocalDeletionState'))

    def _on_task_abort(self, task):
        raise Exception('task aborted')

    def _on_task_reject(self, task):
        raise Exception('task rejected')

    def _handle_command_INTEGRITYERRORONDELETELOCAL(self, command):
        """
        Attributes available in the command object:
            - pathname
            - proof
            - reason
            - expected_basis
            - computed_basis
        """
        self.logger.critical(u"Detected an integrity error while deleting "
                             "locally pathname %s. Reason: %s" %
                             (command.pathname, command.reason))
        self._set_next_state(StateRegister.get('IntegrityErrorState'))


class DeleteLocalTask(object):

    def __init__(self, trusted_basis, pathname2proof,
                 on_complete, on_abort, on_reject):
        self.verb = 'DELETE_LOCAL'
        self.state = 'working'
        self.trusted_basis = trusted_basis
        self.pathname2proof = dict(pathname2proof)
        self._on_complete = on_complete
        self._on_abort = on_abort
        self._on_reject = on_reject

        # this is needed for task tracking facility
        if __debug__:
            self.pathname = "DELETE_LOCAL"

    def complete(self):
        self.state = 'completed'
        self._on_complete(self)

    def reject(self):
        self.state = 'rejected'
        self._on_reject(self)

    def abort(self):
        self.state = 'aborted'
        self._on_abort(self)

    def is_working(self):
        return self.state == 'working'

    def is_aborted(self):
        return self.state == 'aborted'

    def is_completed(self):
        return self.state == 'completed'

    def is_rejected(self):
        return self.state == 'rejected'

    def register_complete_handler(self, handler):
        pass

    def register_reject_handler(self, handler):
        pass

    def register_abort_handler(self, handler):
        pass


class LocalDeletionState(ServerSessionState):
    accepted_messages = ServerSessionState.accepted_messages + \
        ['SYNC_GET_RESPONSE']

    def __init__(self, session):
        ServerSessionState.__init__(self, session)
        self._pathname_to_do = {}
        self._pathname2proof = {}
        self._queues_to_listen = [
            'usercommand', 'sessioncommand', 'systemcommand',
            'servermessage'
        ]

    def _receive_next_message(self):
        return self._context._input_queue.get(self._queues_to_listen)

    def _on_entering(self):
        self._queues_to_listen = [
            'usercommand', 'sessioncommand', 'systemcommand',
            'servermessage'
        ]
        self._pathname_to_do = {}
        self._pathname2proof = {}

        diff_result = self._context.startup_synchronization
        pathnames = diff_result.content_to_delete_locally

        if len(pathnames) > 0:
            for pathname in pathnames:
                self._pathname_to_do[pathname] = True
                request = SYNC_GET_REQUEST("SYNC_GET_REQUEST",
                                           {'pathname': pathname})
                #self.logger.debug(u"Produced Request message: %s", request)
                self._context.output_message_queue.put(request)
        else:
            self._on_task_complete(None)

    def _handle_message_ERROR(self, message):
        #self.logger.debug(u"Received declare response: %s", message)

        if message.getParameter('error_code') != PATHNAME_ERROR:
            super(LocalDeletionState, self)._handle_message_ERROR(message)
            return

        # I really hate this
        reason = message.getParameter('reason')
        pathname = reason.replace('Given pathname (', '', 1)
        pathname = pathname.replace(') does no exist.', '', 1)
        assert pathname in self._pathname_to_do

        proof = Proof(message.getParameter('proof'))
        proof.raw = message.getParameter('proof')
        self._pathname2proof[pathname] = proof
        del self._pathname_to_do[pathname]
        self.logger.info(u'Received info on deletion of pathname "%s" '
                         '(still %s to do)' %
                         (pathname, len(self._pathname_to_do)))
        if len(self._pathname_to_do) == 0:                                            
            self._send_task()

    def _send_task(self):
        self._queues_to_listen = ['usercommand',
                                  'sessioncommand',
                                  'systemcommand']
        trusted_basis = self._context.integrity_manager.getCurrentBasis()
        task = DeleteLocalTask(trusted_basis,
                               self._pathname2proof,
                               self._on_task_complete,
                               self._on_task_abort,
                               self._on_task_reject)

        self._context.worker_pool.acquire_worker()
        if __debug__:
            self._context.worker_pool.track_acquire_anonymous_worker("DELETE_LOCAL")
        self._context.worker_pool.send_operation(task)

    def _on_task_complete(self, task):
        self._set_next_state(
            StateRegister.get('DownloadingDirectoriesState'))

    def _on_task_abort(self, task):
        raise Exception('task aborted')

    def _on_task_reject(self, task):
        raise Exception('task rejected')

    def _handle_command_INTEGRITYERRORONDELETELOCAL(self, command):
        """
        Attributes available in the command object:
            - pathname
            - proof
            - reason
            - expected_basis
            - computed_basis
        """
        self.logger.critical(u"Detected an integrity error while deleting "
                             "locally pathname %s. Reason: %s" %
                             (command.pathname, command.reason))
        self._set_next_state(StateRegister.get('IntegrityErrorState'))


def sync_on_operation_rejected(operation):
    """Called by a worker that couldn't complete an operation.

    Note: the calling thread is the worker's one, not ServerSession's.
    """
    # TODO: try to reset just the session instead of the whole client.
    raise Exception("operation rejected")


def on_download_integrity_error(state, command):
    """
    Attributes available in the command object:
        - operation
        - proof
        - reason
        - expected_etag
        - expected_basis
        - actual_etag
        - computed_basis
    """
    operation = command.operation
    state.logger.critical(u"Detected an integrity error while downloading "
                          "pathname %s. Reason: %s" %
                          (operation.pathname, command.reason))
    state._set_next_state(StateRegister.get('IntegrityErrorState'))


class CreateDirectoriesTask(object):

    def __init__(self, operations, on_complete, on_abort, on_reject):
        self.verb = 'CREATE_DIRECTORIES'
        self.state = 'working'
        self.operations = list(operations)
        self._on_complete = on_complete
        self._on_abort = on_abort
        self._on_reject = on_reject

        # this is needed for task tracking facility
        if __debug__:
            self.pathname = "CREATE_DIRECTORIES"

    def complete(self):
        self.state = 'completed'
        self._on_complete(self)

    def reject(self):
        self.state = 'rejected'
        self._on_reject(self)

    def abort(self):
        self.state = 'aborted'
        self._on_abort(self)

    def is_working(self):
        return self.state == 'working'

    def is_aborted(self):
        return self.state == 'aborted'

    def is_completed(self):
        return self.state == 'completed'

    def is_rejected(self):
        return self.state == 'rejected'

    def register_complete_handler(self, handler):
        pass

    def register_reject_handler(self, handler):
        pass

    def register_abort_handler(self, handler):
        pass


class DownloadingDirectoriesState(ServerSessionState):
    accepted_messages = ServerSessionState.accepted_messages + \
        ['SYNC_GET_RESPONSE']

    def __init__(self, session):
        ServerSessionState.__init__(self, session)
        self._pathname2operation = {}
        self._directories = []
        self._queues_to_listen = [
            'usercommand', 'sessioncommand', 'systemcommand',
            'servermessage', 'operation'
        ]

    def _receive_next_message(self):
        return self._context._input_queue.get(self._queues_to_listen)

    def _on_entering(self):
        self._queues_to_listen = [
            'usercommand', 'sessioncommand', 'systemcommand',
            'servermessage', 'operation'
        ]
        self._context._sync_operations = []
        self._pathname2operation = {}
        self._directories = []

        # Collect all the operations to do.
        # No matter what, we have to successfully complete all these
        # operations for the sync to pass the integrity checks.
        while True:
            try:
                op, _ = self._context._input_queue.get(['operation'],
                                                       blocking=False)
            except multi_queue.Empty:
                break
            #self.logger.debug(u"Received file operation: %s", op)
            self._context._sync_operations.append(op)

        # Stop listening operations
        self._queues_to_listen = ['usercommand',
                                  'sessioncommand',
                                  'systemcommand',
                                  'servermessage']

        files = []

        # Tell apart directories from files
        for operation in self._context._sync_operations:
            if operation.is_directory():
                self._directories.append(operation)
            else:
                files.append(operation)

        # Put back the files to the input queue, they'll be handled later
        self._context._input_queue.append('NO_MORE_OPERATIONS', 'operation')
        for operation in reversed(files):
            self._context._input_queue.append(operation, 'operation')

        if len(self._directories) > 0:
            for operation in self._directories:
                self._pathname2operation[operation.pathname] = operation
                request = SYNC_GET_REQUEST("SYNC_GET_REQUEST",
                                           {'pathname': operation.pathname})
                #self.logger.debug(u"Produced Request message: %s", request)
                self._context.output_message_queue.put(request)
        else:
            self._on_task_complete(None)

    def _handle_message_SYNC_GET_RESPONSE(self, message):
        #self.logger.debug(u"Received declare response: %s", message)

        # Note: SYNC_GET_RESPONSE messages don't contain the request id,
        # so we have to use the pathname.
        operation = self._pathname2operation[message.getParameter('pathname')]
        msg = message
        trusted_basis = self._context.integrity_manager.getCurrentBasis()
        operation.download_info = {}
        operation.download_info['proof'] = Proof(msg.getParameter('proof'))
        operation.download_info['proof'].raw = msg.getParameter('proof')
        operation.download_info['trusted_basis'] = trusted_basis
        del self._pathname2operation[operation.pathname]
        self.logger.info(u'Received info on directory "%s" '
                         '(still %s to do)' %
                         (operation.pathname, len(self._pathname2operation)))
        if len(self._pathname2operation) == 0:
            self._send_task()

    def _send_task(self):
        self._queues_to_listen = ['usercommand',
                                  'sessioncommand',
                                  'systemcommand']
        task = CreateDirectoriesTask(self._directories,
                                     self._on_task_complete,
                                     self._on_task_abort,
                                     self._on_task_reject)
        got_it = self._context.worker_pool.acquire_worker()
        assert got_it
        if __debug__:
            self._context.worker_pool.track_acquire_anonymous_worker(task.pathname)
        self._context.worker_pool.send_operation(task)

    def _on_task_complete(self, task):
        self._set_next_state(StateRegister.get('DownloadingFilesState'))

    def _on_task_abort(self, task):
        raise Exception('task aborted')

    def _on_task_reject(self, task):
        raise Exception('task rejected')

    def _handle_command_INTEGRITYERRORONDOWNLOAD(self, command):
        on_download_integrity_error(self, command)


class DownloadingFilesState(ServerSessionState):
    accepted_messages = ServerSessionState.accepted_messages + \
        ['SYNC_GET_RESPONSE']

    def __init__(self, session):
        ServerSessionState.__init__(self, session)
        self._listening_operations = True
        self._pathname2operation = {}
        self._num_received_operations = 0
        self._num_finished_operations = 0
        self._received_all_operations = False
        self._lock = threading.Lock()

    def _on_entering(self):
        self._context.id = 0
        if self._context.worker_pool.exist_free_workers():
            self._listening_operations = True
        self._pathname2operation = {}
        self._num_received_operations = 0
        self._num_finished_operations = 0
        self._received_all_operations = False

    def _receive_next_message(self):
        queues = [
            'usercommand', 'sessioncommand',
            'systemcommand', 'servermessage'
        ]
        if self._listening_operations:
            queues.append('operation')
        return self._context._input_queue.get(queues)

    def _handle_operation(self, operation):
        if operation == 'NO_MORE_OPERATIONS':
            self._received_all_operations = True
            with self._lock:
                num_finished = self._num_finished_operations
                num_received = self._num_received_operations
                if num_received == num_finished:
                    self._set_next_state(StateRegister.get('SyncDoneState'))
            return

        self._num_received_operations += 1

        if not self._context.worker_pool.acquire_worker():
            raise FileRockException(
                u"Concurrency trouble in %s: could not acquire a worker"
                " although some should have been available"
                % (self.__class__.__name__ + "._handle_file_operation"))

        if __debug__:
            self._context.worker_pool.track_acquire_anonymous_worker(
                operation.pathname)

        if not self._context.worker_pool.exist_free_workers():
            self._listening_operations = False

        self.logger.info(u'Synchronizing pathname: %s "%s"'
                         % (operation.verb, operation.pathname))

        with operation.lock:
            if operation.is_working():
                operation.register_complete_handler(self._on_complete_operation)
                operation.register_abort_handler(self._on_complete_operation)
                operation.register_reject_handler(sync_on_operation_rejected)
            else:
                self.logger.debug(u"Ignoring aborted operation:%s" % operation)
                self._num_received_operations -= 1
                self._context.worker_pool.release_worker()
                return

        CryptoUtils.prepare_operation(operation, self._context.temp_dir)
        self._pathname2operation[operation.pathname] = operation
        request = SYNC_GET_REQUEST("SYNC_GET_REQUEST",
                                   {'pathname': operation.pathname})
        #self.logger.debug(u"Produced Request message: %s", request)
        self._context.output_message_queue.put(request)

    def _on_complete_operation(self, operation):
        with self._lock:
            self._num_finished_operations += 1
            num_finished = self._num_finished_operations
            num_received = self._num_received_operations
            if self._received_all_operations and num_received == num_finished:
                self._set_next_state(StateRegister.get('SyncDoneState'))

    def _handle_command_WORKERFREE(self, command):
        """A worker is available to serve more operations.
        """
        if self._context.worker_pool.exist_free_workers():
            self._listening_operations = True

    def _handle_message_SYNC_GET_RESPONSE(self, message):
        """An operation has been authorized by the server, let's send it
        to the workers.
        """
        #self.logger.debug(u"Received declare response: %s", message)

        # Note: SYNC_GET_RESPONSE messages don't contain the request id,
        # so we have to use the pathname.
        operation = self._pathname2operation[message.getParameter('pathname')]
        msg = message
        operation.download_info = {}
        operation.download_info['bucket'] = msg.getParameter('bucket')
        operation.download_info['auth_token'] = msg.getParameter('auth_token')
        operation.download_info['auth_date'] = msg.getParameter('auth_date')
        operation.download_info['proof'] = Proof(msg.getParameter('proof'))
        operation.download_info['proof'].raw = msg.getParameter('proof')
        operation.download_info['trusted_basis'] = self._context.integrity_manager.getCurrentBasis()
        operation.download_info['remote_ip_address'] = self._context.storage_ip_address
        self._context.worker_pool.send_operation(operation)

    def _handle_command_INTEGRITYERRORONDOWNLOAD(self, command):
        on_download_integrity_error(self, command)


class SyncDoneState(ServerSessionState):
    """Synchronization went well. Finalize it by updating the internal
    data structures.
    """
    accepted_messages = (
        ServerSessionState.accepted_messages + ['REPLICATION_START'])

    def _on_entering(self):
        """Persist the new basis, the storage cache and tell the UI
        about the completion of the sync phase.
        """
        temp = [op.is_completed() for op in self._context._sync_operations]
        all_done = reduce(lambda x, y: x and y, temp, True)

        if all_done:
            # All expected operations have been completed.
            self.logger.info(
                u"Startup Synchronization phase has completed successfully")
            self._context.output_message_queue.put(SYNC_DONE('SYNC_DONE'))

            completed_operations = self._context._sync_operations
            self._update_storage_cache(completed_operations)
            self._context.transaction.clear()
            # In case the server had sent a fresher basis
            # TODO: save into the basis history as well, if the basis has
            # changed (it happens, for example, if the client had crashed
            # on the last COMMIT_DONE message)
            self._persist_trusted_basis(self._context.integrity_manager.getCurrentBasis())

            self._context.metadataDB.delete_key(metadata.LASTACCEPTEDSTATEKEY)
            self._clear_candidate_basis()
            self._context.transaction_cache.clear()

            self._context._internal_facade.first_startup_end()
            self._context._ui_controller.update_session_info(
                {'basis': self._context.integrity_manager.getCurrentBasis()})
        else:
            # Some operations have been aborted. The basis can't be persisted,
            # because it doesn't match what is on disk. We must stop here and
            # repeat the synchronization.
            self.logger.info(u"Startup Synchronization interrupted due to"
                             " the abort of some operations.")
            self._context._internal_facade.pause()
            state = StateRegister.get('WaitingForTerminationState')
            self._set_next_state(state)

        self._context.worker_pool.clean_download_dir()
        self._context._sync_operations = []

    def _update_storage_cache(self, operations):
        """Update the storage cache with the operation we have just done.
        """
        self.logger.debug("Starting updating the storage cache...")
        with self._context.storage_cache.transaction() as storage_cache:

            # Update the records of the downloaded pathnames
            for operation in operations:
                pathname = operation.pathname
                lmtime = operation.lmtime
                warebox_size = operation.warebox_size
                storage_size = operation.storage_size
                warebox_etag = operation.warebox_etag
                storage_etag = operation.storage_etag
                record = (pathname, warebox_size, storage_size,
                        lmtime, warebox_etag, storage_etag)
                storage_cache.update_record(*record)

            diff = self._context.startup_synchronization

            # Delete the records of the remotely deleted pathnames
            for pathname in diff.remote_deletions:
                storage_cache.delete_record(pathname)

            # Restore the records of the ignored conflicts (that is, pathnames
            # whose content is the same in the warebox and on the storage but
            # whose cache record is missing)
            for pathname in diff.ignored_conflicts:
                warebox_size = diff.local_size[pathname]
                storage_size = diff.remote_size[pathname]
                lmtime = diff.local_lmtime[pathname]
                warebox_etag = diff.local_etag[pathname]
                storage_etag = diff.remote_etag[pathname]
                storage_cache.update_record(pathname, warebox_size,
                                            storage_size, lmtime,
                                            warebox_etag, storage_etag)

        self.logger.debug("Finished updating the storage cache.")

    def _handle_message_REPLICATION_START(self, message):
        """The server is ready to leave the sync phase, too. Let's
        start the Replication & Transfer phase.
        """
        self._set_next_state(
            StateRegister.get('EnteringReplicationAndTransferState'))
        self._context._input_queue.put(
            Command('UPDATEBEFOREREPLICATION'), 'sessioncommand')


class WaitingForTerminationState(ServerSessionState):

    accepted_messages = ServerSessionState.accepted_messages

    def _receive_next_message(self):
        return self._context._input_queue.get(['usercommand'])


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = transaction
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the transaction module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import threading, operator, logging


class Transaction(object):
    """
    How Transaction deals with aborted operations.

    There can be two kinds of operations into Transaction:

    1) operations that were registered while in status "working" (see method
       self.authorize_operation);
    2) operations that were registered already aborted.

    The former clear the self.can_be_committed flag, which, however, will be
    correctly set when the operations are either completed or aborted.
    The latter don't clear the flag, so basically they don't do any mess:
    it is safe to wait on self.can_be_committed.

    Although aborted operations are kept into Transaction, most query methods
    skip them. Notably:
        - self.all_operations_are_authorized
        - self.get_operations_to_authorize
        - self.get_completed_operations
    """


    def __init__(self):
        self.logger = logging.getLogger("FR."+self.__class__.__name__)

        # A id=>operation map. Operations waiting for a DECLARE_RESPONSE from the server, they'll get moved to self.operations.
        self.operations_to_authorize = {}

        # A id=>operation map. Authorized operations, they have received a DECLARE_RESPONSE from the server.
        # Remember to use self.lock when modifying this map, since it's accessed concurrently.
        self.operations = {}

        self.lock = threading.Lock()
        self.can_be_committed = threading.Event()
        self.can_be_committed.set()
        self.pathname2operation = {}

    def on_operation_finished(self, file_operation):
        self.logger.debug(u"An operation has been finished: %s", file_operation)
        with self.lock:
            unfinished_operations = filter(lambda x: x.is_working(), self.operations.values())
            if len(unfinished_operations) == 0:
                self.logger.debug(u"For now all operations in transaction are finished.")
                self.can_be_committed.set()

    def add_operation(self, index, operation):
        if operation.pathname in self.pathname2operation:
            raise Exception("Only one operation per pathname can be in Transaction")
        self.operations_to_authorize[index] = operation
        self.pathname2operation[operation.pathname] = operation

    def get_operation(self, index):
        try:
            return self.operations[index]
        except KeyError:
            return self.operations_to_authorize[index]

    def get_by_pathname(self, pathname):
        return self.pathname2operation[pathname]

    def get_id(self, operation):
        list1 = [index for (index,op) in self.operations.iteritems() if op is operation]
        list2 = [index for (index,op) in self.operations_to_authorize.iteritems() if op is operation]
        if len(list1) > 0: return list1[0]
        elif len(list2) > 0: return list2[0]
        else: raise Exception("Asking for the index of an unknown operation: %s" % operation)

    def remove_operation(self, index):
        if index in self.operations:
            operation = self.operations[index]
            del self.operations[index]
        elif index in self.operations_to_authorize:
            operation = self.operations_to_authorize[index]
            del self.operations_to_authorize[index]
        else:
            raise Exception("Removing an operation with unknown index: %s" % index)
        del self.pathname2operation[operation.pathname]

    def authorize_operation(self, index):
        operation = self.operations_to_authorize[index]
        del self.operations_to_authorize[index]
        with operation.lock:
            if operation.is_working():
                operation.register_complete_handler(self.on_operation_finished)
                operation.register_abort_handler(self.on_operation_finished)
                with self.lock:
                    self.operations[index] = operation
                    self.can_be_committed.clear()
                return True
            else:
                with self.lock:
                    self.operations[index] = operation
                return False

    def all_operations_are_authorized(self):
        left_operations = self.get_operations_to_authorize()
        return len(left_operations) == 0

    def get_operations_to_authorize(self):
        return [(index,op) for (index,op) in self.operations_to_authorize.iteritems() if not op.is_aborted()]

    def flush_unauthorized_operations(self):
        # Ids, which are incremental, are used to enforce the order of operations
        operations = [op for (_, op) in sorted(self.operations_to_authorize.iteritems(), key=operator.itemgetter(0))]
        self.operations_to_authorize.clear()
        return operations

    def wait_until_finished(self):
        if len(self.operations) == 0:
            self.logger.debug(u"There is nothing to commit.")
        else:
            self.can_be_committed.wait()

    def cancel_waiting(self):
        self.can_be_committed.set()

    def get_completed_operations(self):
        # Ids, which are incremental, are used to enforce the order of operations
        return sorted([(index,op) for (index,op) in self.operations.iteritems() if op.is_completed()], key=operator.itemgetter(0))

    def get_completed_operations_id(self):
        return [index for (index, _) in self.get_completed_operations()]

    def size(self):
        with self.lock:
            return len(self.operations) + len(self.operations_to_authorize)

    def data_size(self):
        with self.lock:
            op1 = self.operations.values()
            op2 = self.operations_to_authorize.values()
            size = sum([op.storage_size for op in op1 + op2 if op.verb == 'UPLOAD'])
            return size

    def clear(self):
        self.operations.clear()
        self.pathname2operation.clear()
        self.operations_to_authorize.clear() # This should already be empty, but whatever

    def print_all(self):
        print "Current transaction:"
        print "  Authorized operations:"
        with self.lock:
            for (index,op) in self.operations.iteritems():
                print "    index=", index, ": ", op
        print "  Nonauthorized operations:"
        for (index,op) in self.operations_to_authorize.iteritems():
            print "    index=", index, ": ", op



if __name__ == '__main__':
    print "\n This file does nothing on its own, it's just the %s module. \n" % __file__

########NEW FILE########
__FILENAME__ = transaction_manager
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the transaction_manager module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
from filerockclient.exceptions import ForceStateChange
from filerockclient.interfaces import PStatuses


class TransactionManager(object):

    def __init__(self, transaction, storage_cache):
        self.logger = logging.getLogger("FR."+self.__class__.__name__)
        self.transaction = transaction
        self.storage_cache = storage_cache
        # A id=>operation map. Operations that were in transaction but have been replaced by others on the same pathnames
        self.canceled_operations = {}

    def handle_operation(self, index, operation, session):
        '''Returns True if operation must be declared to the server, False otherwise'''
        return getattr(self, '_handle_%s_operation' % operation.verb.lower())(index, operation, session)

    def _handle_upload_operation(self, index, operation, session_state):
        if not operation.is_aborted() and self._any_missing_folder(operation.pathname):
            session_state.postpone_operation(operation)
            session_state.on_commit_necessary_to_proceed()
            raise ForceStateChange()
        # Note: we are putting aborted operations into the transaction, just to trace them
        try: conflicting_operation = self.transaction.get_by_pathname(operation.pathname)
        except KeyError: conflicting_operation = None
        if not conflicting_operation is None:
            self._cancel_operation(conflicting_operation)
        self.transaction.add_operation(index, operation)
        return not operation.is_aborted()

    def _any_missing_folder(self, pathname):
        folder = self._find_first_missing_folder(pathname)
        if folder is None:
            return False
        try: folder_operation = self.transaction.get_by_pathname(folder)
        except KeyError: folder_operation = None
        if folder_operation is None or not folder_operation.verb in ['UPLOAD', 'REMOTE_COPY']:
            raise Exception("Uploading to nonexistent destination: %s" % pathname)
        return True

    def _find_first_missing_folder(self, pathname):
        tokens = pathname.split('/')
        tokens = [token for token in tokens if token != '']
        del tokens[-1]
        folders = []
        folder = ''
        for token in tokens:
            folder = u"%s%s/" % (folder, token)
            folders.append(folder)
        for folder in folders:
            if not self.storage_cache.exist_record(folder):
                return folder
        return None

    def _cancel_operation(self, operation):
        index = self.transaction.get_id(operation)
        self.transaction.remove_operation(index)
        self.canceled_operations[index] = operation
        operation.notify_pathname_status_change(PStatuses.ALIGNED)

    def _handle_delete_operation(self, index, operation, session_state):
        # handling situations in which there is a different operation for the same pathname in the transaction
        try: conflicting_operation = self.transaction.get_by_pathname(operation.pathname)
        except KeyError: conflicting_operation = None
        if conflicting_operation:
            # TODO either treat all cases, or put an assert here, is it true that no other verb is allowed? why?
            if conflicting_operation.verb != 'UPLOAD' and conflicting_operation.verb != 'REMOTE_COPY':
                raise Exception("TransactionManager collapsing a DELETE operation with another unexpected verb: %s" % conflicting_operation)
            self._cancel_operation(conflicting_operation)

        if self.storage_cache.exist_record(operation.pathname):
            #if folder check if it is empty on the raw storage
            if operation.is_directory():
                if self.storage_cache.exist_record_proper_prefix(operation.pathname):
                    #we know that directory is not empty
                    session_state.postpone_operation(operation)  #no worker has been acquired yet -> no release
                    session_state.on_commit_necessary_to_proceed()
                    raise ForceStateChange()

            # Note: we are putting aborted operations into the transaction, just to trace them
            self.transaction.add_operation(index, operation)
            return not operation.is_aborted()
        else:
            #we assume that the following storage invariant. if there is a /X/Y entry there there is also a /X/ entry.
            # so we do not bore about deletion of non existent folder key which have some content!

            self.logger.debug(u"Ignoring a DELETE operation for a nonexistent pathname: %s" % (operation))
            # This can really happen due to timing of events. E.g.: renaming an uncommitted pathname produces both a deletion
            # and a remote_copy operations. The original update operation gets aborted, but if it was a creation then the pathname
            # hasn't been created on the storage, so a deletion shouldn't have been produced at all. However, it isn't so at this moment.
            # The deletion may meet the aborted update into the transaction, and then be silently collapsed; but if the transaction
            # is committed in the meanwhile for any reason (by the user, for example) then the aborted creation is flushed and the
            # deletion matches the "deleting a nonexistent pathname" case.
            # I think that EventsQueue should be modified to not emit a deletion at all in this case.
            operation.complete()
            operation.notify_pathname_status_change(PStatuses.ALIGNED)
            return False


    def _handle_remote_copy_operation(self, index, operation, session_state):
        if not self.storage_cache.exist_record(operation.oldpath):
            try:
                source_upload_operation = self.transaction.get_by_pathname(operation.oldpath)
                if not source_upload_operation.verb in ['UPLOAD', 'REMOTE_COPY']:
                    raise Exception(
                        u'Detected an inconsistent operation: trying to remote_copy-ing '
                        u'a pathname whose source has on operation different from '
                        u' creation. Operation: %s. Found this one on the source pathname: %s'
                        % (operation, source_upload_operation))
            except KeyError:
                source_upload_operation = None
            if not source_upload_operation is None and source_upload_operation.is_completed():
                # If the source doesn't exist on the storage but it will be
                # created by the current transaction, force a commit.
                session_state.postpone_operation(operation)
                session_state.on_commit_necessary_to_proceed()
                raise ForceStateChange()
            else:
                # Note: we give up at copying if the source doesn't exist and
                # it won't be created in the current transaction (e.g. due to a
                # reject). We give up even if the source will be created but is
                # still uploading. If it's a rename then the source doesn't exist anymore
                # and the upload is going to fail soon. If it's a copy, it could
                # be fine but the upload may still fail for network reasons and
                # we have currently no way to check it.
                # Basically we only trust declared copies and completed uploads.
                operation.verb = 'UPLOAD'
        return self._handle_upload_operation(index, operation, session_state)

    def authorize_operation(self, index):
        '''Returns whether the operation must be processed or not (e.g. collapsed, aborted)'''
        if index in self.canceled_operations:
            del self.canceled_operations[index]
            return False
        else:
            return self.transaction.authorize_operation(index)

    def get_operation(self, index):
        if index in self.canceled_operations:
            return self.canceled_operations[index]
        else:
            return self.transaction.get_operation(index)

    def clear(self):
        self.canceled_operations.clear()
        self.transaction.clear()

    def __getattr__(self, name):
        '''TransactionManager completely wraps Transaction'''
        return getattr(self.transaction, name)


if __name__ == '__main__':
    print "\n This file does nothing on its own, it's just the %s module. \n" % __file__

########NEW FILE########
__FILENAME__ = storage_connector
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the storage_connector module.


----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""
from __future__ import division
import httplib
import urllib
import urllib2
import contextlib
import base64
import binascii
import hashlib

from FileRockSharedLibraries.Communication.RequestDetails import \
    ENCRYPTED_FILES_IV_HEADER


CHUNK_SIZE = 4096
DOWNLOAD_CHUNK_SIZE = CHUNK_SIZE * 10


class TerminationException(Exception):
    pass


class StorageConnector(object):

    def __init__(self, warebox, cfg):
        self.warebox = warebox
        self.endpoint = cfg.get('System', 'storage_endpoint')
        ##_fix_get_http_request()

    def get_percentage(self, point, total):
        if total > 0:
            return int(round((point / total) * 100))
        else:
            return 100

    def byte_to_send(self, bandwidth, max):
        if bandwidth is not None:
            return bandwidth.byte_to_send()
        else:
            return max

    def upload_file(self,
            local_pathname, remote_pathname, remote_ip_address, bucket, token,
            auth_date, open_function, file_md5=None, file_size=None, iv=None,
            terminationEvent=None, percentageQueue=None, logger=None, bandwidth=None):
        headers = {}
        headers['Host'] = '%s.%s' % (bucket, self.endpoint)
        headers['Date'] = auth_date
        headers['Authorization'] = token
        headers['Content-MD5'] = base64.b64encode(binascii.unhexlify(file_md5))
        headers['Content-Type'] = 'application/octet-stream'
        headers['Content-Length'] = file_size
        if not iv is None:
            headers[ENCRYPTED_FILES_IV_HEADER] = iv
        #address = self.endpoint
        address = remote_ip_address
        target = urllib.quote('/%s' % remote_pathname.encode('utf-8'))
        uploaded = 0
        percentage = self.get_percentage(uploaded, file_size)
        if percentageQueue is not None:
            percentageQueue(percentage)
        try:
            with open_function(local_pathname, 'rb') as body:
                with contextlib.closing(httplib.HTTPSConnection(address, timeout=10)) as connection:
#                    connection.set_debuglevel(1)
#                    connection.request('PUT', target, body, headers)
                    connection.putrequest('PUT', target, True, True)
                    for k, v in headers.iteritems():
                        connection.putheader(k, v)
                    connection.endheaders()

                    chunk = body.read(self.byte_to_send(bandwidth, CHUNK_SIZE))
                    while len(chunk) > 0:
                        if terminationEvent is not None:
                            if terminationEvent.is_set():
                                raise TerminationException()
                            else:
                                connection.send(chunk)
                        else:
                            connection.send(chunk)
                        if percentageQueue is not None:
                            uploaded += len(chunk)
                            percentage = self.get_percentage(uploaded, file_size)
                            if (percentage % 3 == 0):
                                percentageQueue(percentage)
                        chunk = body.read(self.byte_to_send(bandwidth, CHUNK_SIZE))

                    response = connection.getresponse()
                    result = {'success': None, 'details': {}}
                    result['success'] = (response.status == 200)
                    result['details']['status'] = response.status
                    result['details']['reason'] = response.reason
                    result['details']['headers'] = '%s' % response.getheaders()
                    result['details']['body'] = response.read()
                    return result
        except TerminationException as e:
            # Note: connection timeouts raise socket.error
            result = {'success': False, 'details': {}}
            result['details']['status'] = None
            result['details']['reason'] = u'%r' % e
            result['details']['headers'] = None
            result['details']['body'] = None
            result['details']['termination'] = True
            return result
        except Exception as e:
            # Note: connection timeouts raise socket.error
            result = {'success': False, 'details': {}}
            result['details']['status'] = None
            result['details']['reason'] = u'%r' % e
            result['details']['headers'] = None
            result['details']['body'] = None
            return result

    def download_file(self, local_pathname, remote_pathname, remote_ip_address,
            bucket, token, auth_date, open_function, terminationEvent=None,
            byte_range=None, percentageQueue=None, logger=None, bandwidth=None):
        """
        byte_range specifies byte range to download. Format must be like:
            1) xxx-yyy
            2) -yyy
            3) xxx-
        where xxx is starting offset and yyy is ending offset
        """
        target = urllib.quote(remote_pathname.encode('utf-8'))  # Damn urllib2
        #url = 'http://%s.%s/%s' % (bucket, self.endpoint, target)
        url = 'https://%s/%s' % (remote_ip_address, target)
        headers = {}
        headers['Host'] = '%s.%s' % (bucket, self.endpoint)
        headers['Date'] = auth_date
        headers['Authorization'] = token
        if byte_range is not None: headers['Range'] = "bytes=%s" % byte_range
        request = urllib2.Request(url, None, headers)
        downloaded = 0

        try:
            with contextlib.closing(urllib2.urlopen(request)) as remote_file:
                with open_function(local_pathname, 'wb') as local_file:
                    file_size = int(remote_file.info()['Content-Length'])
                    percentage = self.get_percentage(downloaded, file_size)
                    etag = hashlib.md5()

                    chunk = remote_file.read(self.byte_to_send(bandwidth, DOWNLOAD_CHUNK_SIZE))

                    while len(chunk) > 0:
                        if terminationEvent is not None:
                            if terminationEvent.is_set():
                                raise TerminationException()
                            else:
                                local_file.write(chunk)
                        else:
                            local_file.write(chunk)

                        etag.update(chunk)

                        if percentageQueue is not None:
                            downloaded += len(chunk)
                            percentage = self.get_percentage(downloaded, file_size)
                            if (percentage % 2 == 0):
                                percentageQueue(percentage)
                        chunk = remote_file.read(self.byte_to_send(bandwidth, DOWNLOAD_CHUNK_SIZE))

#                    local_file.write(remote_file.read())
                    result = {'success': True, 'details': {}}
                    result['details']['status'] = 200
                    result['details']['reason'] = None
                    result['details']['headers'] = '%s' % remote_file.info()
                    result['details']['body'] = None
                    result['etag'] = binascii.hexlify(etag.digest())
                    return result

        except TerminationException as e:
            # Note: connection timeouts raise socket.error
            result = {'success': False, 'details': {}}
            result['details']['status'] = None
            result['details']['reason'] = u'%r' % e
            result['details']['headers'] = None
            result['details']['body'] = None
            result['details']['termination'] = True
            return result

        except urllib2.URLError as e:
            result = {'success': False, 'details': {}}
            result['details']['status'] = None
            result['details']['reason'] = None
            result['details']['headers'] = None
            result['details']['body'] = None

            if hasattr(e, 'code'):
                # Only for HTTPError
                result['details']['status'] = e.code

            if hasattr(e, 'reason'):
                # Only for URLError (Damn urllib2)
                result['details']['reason'] = e.reason

            if hasattr(e, 'info'):
                # Only for HTTPError
                result['details']['headers'] = '%s' % e.info()

            return result

        except Exception as e:
            result = {'success': False, 'details': {}}
            result['details']['status'] = None
            result['details']['reason'] = u'%r' % e
            result['details']['headers'] = None
            result['details']['body'] = None
            return result

    def check_connection(self):
        with contextlib.closing(httplib.HTTPConnection(self.endpoint)) as connection:
            #connection.set_debuglevel(1)
            connection.request('GET', '/', '', {'Host': self.endpoint})
            response = connection.getresponse()
            if response.status != 403 or response.reason != 'Forbidden':
                raise Exception('StorageConnector.check_connection')


# This served to clean GET requests from the "Connection: close" and
# "User-agent" HTTP headers, forced by urllib2 and httplib. However they have
# turned out to be not harmful, so this code is kept here commented as a backup.
##def _fix_get_http_request():
##    opener = urllib2.build_opener(HeaderFixingHTTPHandler())
##    opener.addheaders = []
##    urllib2.install_opener(opener)
##
##class HeaderFixingHTTPHandler(urllib2.HTTPHandler):
##    def http_open(self, req):
##        return self.do_open(HeaderFixingHTTPConnection, req)
##
##
##class HeaderFixingHTTPConnection(httplib.HTTPConnection):
##
##    def request(self, method, url, body=None, headers={}):
##        del headers['Connection']
##        self._send_request(method, url, body, headers)
##
##    def putrequest(self, method, url, skip_host=0, skip_accept_encoding=0):
##        httplib.HTTPConnection.putrequest(self, method, url, 1, 1)


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = client_facade
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Thread-safe interface to Client's functionalities meant to be
used by user interfaces (UIs).

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import threading
from itertools import izip, repeat


from filerockclient.interfaces import GStatuses, GStatus, PStatuses


class ClientFacade(object):
    """Thread-safe interface to Client's functionalities meant to be
    used by user interfaces (UIs).

    Through this facade, UIs can send commands or queries to the Client
    core e.g. polling for pathname status, requesting connection, etc.
    """

    def __init__(self, core, command_queue, logger):
        """
        @param core:
                    Instance of filerockclient.core.Core.
        @param command_queue:
                    Instance of Queue.Queue where to put commands to
                    send to filerockclient.application.Application for
                    execution.
        @param logger:
                    Instance of logging.Logger.
        """
        self._core = core
        self._command_queue = command_queue
        self._logger = logger
        self._global_status = GStatuses.NC_STOPPED
        self._pathname_status = {}
        self._pending_delete = set()
        self._lock = threading.Lock()
        self._zombie = False

    def hard_reset(self):
        """Terminate and restart the whole application.

        This is an asynchronous request, so the caller must expect that
        the command will be eventually executed.
        """
        self._command_queue.put("HARD_RESET")

    def warebox_need_merge(self, warebox_path):
        """Tell whether the warebox would be merged with the storage
        in case of synchronization.

        This is equivalent to ask: is there any content in the warebox?

        @param warebox_path:
                    Absolute filesystem pathname of the warebox to check
        """
        return self._core._warebox_need_merge(warebox_path)

    def apply_config(self, cfg):
        self._core.cfg.from_dict(cfg)
        self._core.cfg.write_to_file()
        if 'warebox_path' in cfg['Application Paths']:
            self._core._change_warebox_path(cfg['Application Paths']['warebox_path'])
        if 'osx_label_shellext' in cfg['User Defined Options'] \
        and cfg['User Defined Options']['osx_label_shellext'] == 'False':
            self._core._metadata_db.set('osx_label_shellext', 'disabled')
        self._command_queue.put('SOFT_RESET')

    def getAbsolutePathname(self, internal_pathname):
        """Returns an absolute pathname following the OS conventions.

        @param internal_pathname:
                    A pathname in internal format (i.e. relative to the
                    warebox root, with forward slashes and with a
                    trailing '/' to denote a directory)
        """
        return self._core._warebox.absolute_pathname(internal_pathname)

    def get_warebox_content(self):
        """Get the warebox content.

        @return a list of warebox-relative pathnames
        """
        return self._core._warebox.get_content()

    def getInternalPathname(self, absolute_pathname):
        """Converts to an internal-use pathname.

        An internal pathname has the following properties:
        * it is relative to the warebox root
        * it uses forward slashes as separators
        * it has a trailing forward slash IFF it represents a directory

        This method raises :class:`ValueError` if `absolute_pathname` is
        not contained in the warebox.

        @param absolute_pathname:
                    A pathname in absolute, OS-dependent format.
        @return
                    The warebox-relative version of the given pathname.
        """
        return self._core._warebox.internal_pathname(absolute_pathname)

    def getConfigAsDictionary(self):
        """Get the current configuration.

        @return
                    A dictionary representation of the current
                    configuration. See filerockclient.config for
                    details.
        """
        return self._core.cfg.to_dict()

    def getCurrentGlobalStatus(self):
        """Get the current global status.

        @return
                    Instance of filerockclient.interfaces.GStatuses
        """
        with self._lock:
            if self._zombie:
                return GStatuses.NC_STOPPED
            return self._global_status

    def isConnected(self):
        """Tell whether the client is connected to the server."""
        return GStatus.isConnected(self.getCurrentGlobalStatus())

    def getPathnameStatus(self, pathname):
        """Get the current status of the pathname.

        A pathnames that represent a folder is denoted by a unicode
        string ending with a "/".

        @return
                    Instance of filerockclient.interfaces.PStatuses
        """
        with self._lock:
            if self._zombie:
                return PStatuses.UNKNOWN
            return self._getPathnameStatus(pathname)

    def _getPathnameStatus(self, pathname):
        """Internal use-only version of getPathnameStatus()"""
        return self._pathname_status.get(pathname, PStatuses.UNKNOWN)

    def getFolderStatus(self, folder):
        """Return the current status of all pathnames in the specified
        subfolder of the warebox.

        A pathname that represents a folder is denoted by a unicode
        string ending with a "/".
        Not recursive, but folders are included. It returns also the
        status of the requested folder itself.
        WARNING: this does not scale for the number of files, possible
        variation: returns all pathnames lexicographically grather than
        a specified string, limited to a certain number.

        @param folder:
                    Pathname of a subfolder of the warebox.
        @return
                A list [(unicode, PStatus), (unicode, PStatus), ...]
        """
        with self._lock:
            if self._zombie:
                return [(folder, PStatuses.UNKNOWN)]
            result = []
            result.append((folder, self._getPathnameStatus(folder)))
            folder_content = self._core._warebox.get_content(folder, recursive=False)
            for pathname in folder_content:
                result.append((pathname, self._getPathnameStatus(pathname)))
            return result

    def getLastHash(self):
        '''
        Returns the last hash that has been returned by server, that
        represents the current state of the remotely stored files.
        '''
        with self._lock:
            if self._zombie:
                return 'None'
            return self._core._server_session.get_current_basis()

    def connect(self):
        """Asks the client to connect to the server.

        This method can be called only if global status is one among
        those that begin with NC_* (Not Connected).
        It cause the client to transition into NC_CONNECTING.
        """
        self._command_queue.put('START')

    def connectForceDisconnection(self):
        """Ask the client to connect to server by forcing disconnection
        of another client that is possibly connected to the client.

        This method can be called only if global status is NC_ANOTHERCLIENT.
        It cause the client to transition into NC_CONNECTING.
        """
        assert False, "Not implemented"

    def commit(self):
        """Ask the client to commit the current transaction."""
        self._core._server_session.commit()

    def disconnect(self):
        """Asks the client to disconnect from the server.

        This method can be called only if global status is one among
        those that begin with C_* (Connected).
        It causes the client to transition into NC_STOPPED.
        """
        self._command_queue.put('PAUSE')

    def quit(self):
        """Terminate the whole application.

        This is an asynchronous request, so the caller must expect that
        the command will be eventually executed.
        """
        self._command_queue.put('TERMINATE')

    def get_warebox_path(self):
        """Get the absolute filesystem pathname of the warebox.

        @return
                    A string with the warebox pathname.
        """
        with self._lock:
            if self._zombie:
                return None
            return self._core._warebox.get_warebox_path()

    # What follow are "protected" methods

    def _set_global_status(self, status):
        """Internal use only, set the current global state.

        This method is meant to be inaccessible to user interfaces. It
        is called by other components of the client to update the
        current data in this interface. Although Python doesn't have
        such a concept, you can think of it as a "protected" method.

        @param status:
                    Instance of filerockclient.interfaces.GStatuses
        """
        with self._lock:
            if status != self._global_status:
                s1 = GStatus._idToStrings()[self._global_status]
                s2 = GStatus._idToStrings()[status]
                self._logger.debug(
                    u"Changing application status from %s to %s" % (s1, s2))
                self._global_status = status

    def _notify_pathname_status_change(self, pathname, new_status):
        """Internal use only, set the state for the given pathname.

        This method is meant to be inaccessible to user interfaces. It
        is called by other components of the client to update the
        current data in this interface. Although Python doesn't have
        such a concept, you can think of it as a "protected" method.

        @param pathname:
                    A pathname in the warebox.
        @param new_status:
                    Instance of filerockclient.interfaces.PStatuses
        """
        with self._lock:
            if new_status == PStatuses.DELETESENT:
                self._pending_delete.add(pathname)
            if new_status == PStatuses.ALIGNED and pathname in self._pending_delete:
                del self._pathname_status[pathname]
                self._pending_delete.remove(pathname)
            else:
                self._pathname_status[pathname] = new_status

    def _learn_initial_status(self, known_pathnames):
        """Stores the initial known pathnames.

        The status for all known pathnames is set to ALIGNED.
        This method is meant to be inaccessible to user interfaces. It
        is called by other components of the client to update the
        current data in this interface. Although Python doesn't have
        such a concept, you can think of it as a "protected" method.

        @param known_pathnames:
                    List of pathnames.
        """
        with self._lock:
            self._pathname_status = dict(
                izip(known_pathnames, repeat(PStatuses.ALIGNED)))
            self._pending_delete = set()

    def _set_zombie(self):
        """Set this facade to be a zombie.

        The client can become permanently inactive for any reason (e.g
        shutdown, reset). In such case this facade is set as "zombie".
        When in zombie mode, the facade stops accessing Core
        functionalities and returns only static default values.

        This method is meant to be inaccessible to user interfaces. It
        is called by other components of the client to update the
        current data in this interface. Although Python doesn't have
        such a concept, you can think of it as a "protected" method.
        """
        with self._lock:
            self._zombie = True

########NEW FILE########
__FILENAME__ = console
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the console module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import sys
import logging
import threading
from time import sleep
from threading import Event

from filerockclient.util.utilities import nbgetch
from filerockclient.interfaces import PStatus


class SimpleConsoleUI(threading.Thread):

    def __init__(self, client):
        threading.Thread.__init__(self, name=self.__class__.__name__)
        self.logger = logging.getLogger("FR.SimpleConsoleUI")
        self.client = client
        self.must_die = Event()

    def run(self):
        while not self.must_die.is_set():
            c = nbgetch()
            if c != False:
                print "> Pressed key: ", c
                if c == "\x03":  # Ctrl-C
                    raise KeyboardInterrupt()
                if c == "c":
                    self.client.commit()
                if c == "k":
                    self.client.connect()
                if c == "d":
                    self.client.disconnect()
                if c == "q":
                    self.client.quit()
                if c == "r":
                    self.client.hard_reset()
                if c == "f":
                    print "status of the warebox:"
                    folder_status = self.client.getFolderStatus(u'')
                    for f in folder_status:
                        print '    ', f[0].encode(sys.stdout.encoding, 'replace'), ': ', PStatus.name[f[1]]
                if c == "t":
                    self.client.server_session.print_transaction()
                if c == "h":
                    print "Still alive threads:"
                    for thr in threading.enumerate():
                        print "\t", thr
                if c == "H":
                    print
                    print "==== SimpleConsoleUI Help ==== "
                    print
                    print " H - Print this help"
                    print " c - Ask for commit"
                    print " k - Connect"
                    print " d - Disconnect"
                    print " q - Quit"
                    print " f - Print warebox status"
                    print " t - Print transaction status"
                    print " h - List (still) alive threads"
                    print
                    print "============================== "
                    print
            sleep(1)

    @staticmethod
    def initUI(client):
        SimpleConsoleUI.instance = SimpleConsoleUI(client)
        SimpleConsoleUI.instance.start()
        return SimpleConsoleUI.instance

    def setClient(self, client):
        self.client = client

    def notifyGlobalStatusChange(self, newStatus):
        pass

    def notifyPathnameStatusChange(self, pathname, newStatus, extras=None):
        pass

    def notifyUser(self, what, *args):
        method_name = '_notifyUser_%s' % what
        try:
            method = getattr(self, method_name)
        except AttributeError:
            self.notifyUser_default(what, args)
        method(*args)

    def notifyCoreReady(self):
        pass

    def askForUserInput(self, what, *args):
        method_name = '_askForUserInput_%s' % what
        try:
            ask_method = getattr(self, method_name)
        except AttributeError:
            return self.askForUserInput_default(what, args)
        return ask_method(*args)

    def askForUserInput_default(self, what, args):
        print (
            u"Application is asking user input for: %s. However it's still"
            u" unimplemented for user interface %s, a default affermative"
            u" answer will be given." % (what, 'SimpleConsoleUI'))
        return "ok"

    def notifyUser_default(self, what, args):
        print u"Application is notifying user about: %s." % what

    def updateLinkingStatus(self, status):
        pass

    def updateConfigInformation(self, cfg):
        pass

    def updateClientInformation(self, infos):
        pass

    def updateSessionInformation(self, infos):
        pass

    def showWelcome(self, cfg, onEveryStartup=True):
        return {
            'result': True,
            'show welcome on startup': False
        }

    def quitUI(self):
        self.logger.debug(u'Terminating...')
        self.must_die.set()
        self.join() if self is not threading.current_thread() else None
        self.logger.debug(u'Terminated.')

    def waitReady(self):
        pass

    def isReady(self):
        return True


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = dummy
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the dummy module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging

from filerockclient.ui import interfaces
from filerockclient.interfaces import GStatuses


class DummyUI(interfaces.HeyDriveUserInterfaceNotification):

    @staticmethod
    def initUI(client):
        DummyUI.instance = DummyUI(client)
        return DummyUI.instance

    def __init__(self, client):
        self.logger = logging.getLogger("FR."+self.__class__.__name__)
        self.client = client

    def waitReady(self):
        pass

    def isReady(self):
        return True

    def quitUI(self):
        pass

    def showWelcome(self, cfg, onEveryStartup): pass

    def notifyGlobalStatusChange(self, newStatus):
        if newStatus == GStatuses.C_HASHMISMATCHONCONNECT:
            self.client.acceptProposedHash()

    def notifyPathnameStatusChange(self, pathname, newStatus, extra=None):
        pass

    def notifyCoreReady(self):
        pass

    def askForUserInput(self, what, *args):

        method_name = '_askForUserInput_' + what

        try:
            ask_method = getattr(self, method_name)
        except AttributeError:
            assert False, "Method %s doesn't exists in %s" % (method_name, self.__class__.__name__)

        return ask_method(*args)

    def _askForUserInput_accept_server_hash(self,  h):
        assert False, 'GUI._askForUserInput_accept_server_hash() not implemented'

    def _askForUserInput_linking_credentials(self,  retry, initialization):
        """Alsways behave as user clicked 'later'"""
        return {'later': True}

    def _askForUserInput_message(self, m, c, cancel=False):
        """Alsways behave as user clicked ok"""
        return "ok"


if __name__ == '__main__':
    print "\n This file does nothing on its own, it's just the %s module. \n" % __file__
########NEW FILE########
__FILENAME__ = interfaces
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the interfaces module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""


class HeyDriveUserInterfaceNotification(object):
    '''
    Specifies the operations that a Gui componet must implement to cooperate with
    the client main component. The set of primitives are designed to support both
    both tryicon clients and file browser extension (like windows shell extension).
    The way the gui related threads are started is implementation dependant.
    '''

    @staticmethod
    def initUI(client):
        '''
        Creates a UI object and initialize it with the given "client" object.
        Creates and starts any UI-related thread.
        Returns the UI object.
        '''
        assert False, "Not implemented"

    def notifyGlobalStatusChange(self, newStatus):
        '''
        Notifies the UI that the global status of the client is changed.
        This method is supposed to be called in the client thread (not in the GUI thread)
        This method MUST always be called by client when its status is changed.
        This method can be potentially called by more threads at the same time.
        This method does not necessarily enqueue any event, events notified in a non ready state are lost.
        '''
        assert False, "method notifyGlobalStatusChange not implemented for %s" \
            % self.__class__.__name__

    def notifyPathnameStatusChange(self, pathname, newStatus, extras=None):
        '''
        Notifies the UI that the status of a specific pathname is changed.
        This method MUST alwasy be called by client when a pathname change its status.
        The pathname not necessarily exists on disk.
        newStatus is one of the const values defined in PStatus.
        extras is a dict with extra parameters to send to interface
        This method can be potentially called by more threads at the same time.
        This method does not necessarily enqueue any event, events notified in a non ready state are lost.
        '''
        assert False, "method notifyPathnameStatusChange not implemented for %s" \
            % self.__class__.__name__

    def notifyCoreReady(self):
        '''
        Notifies when core thread is started
        '''
        assert False, "method notifyCoreReady not implemented for %s" \
            % self.__class__.__name__

    def notifyUser(self, what, *args):
        '''
        Generic entry point for notify to user.
        what ---  is a string that specifies the kind of information needed
        args --- are generic arguments that depend on the kind of information needed
        '''
        assert False, "method notifyUser not implemented for %s" \
            % self.__class__.__name__

    def askForUserInput(self, what, *args):
        '''
        Generic entry point for asking for user input from any UI.
        what ---  is a string that specifies the kind of information needed
        args --- are generic arguments that depend on the kind of information needed
        '''
        assert False, "method askForUserInput not implemented for %s" \
            % self.__class__.__name__

    def updateLinkingStatus(self, status):
        '''
        Update the linking procedure status using one of the Linking Status specified above
        '''
        assert False, "method updateLinkingStatus not implemented for %s" \
            % self.__class__.__name__

    def updateClientInformation(self, infos):
        '''
        Set client information as:
        username: string
        client_id: number
        client_hostname: string
        client_platform: string
        client_version: string
        client_basis: string
        '''
        assert False, "method updateClientInformation not implemented for %s" \
            % self.__class__.__name__

    def updateSessionInformation(self, infos):
        '''
        Update sesssion information in the user interface
        Ex:
            last_commit_client_id: string or None
            last_commit_client_hostname: string or None
            last_commit_client_platform: string or None
            last_commit_timestamp: unix time
            user_quota: number (space in bytes)
            user_space: number (space in bytes)
            basis
        '''
        assert False, "method updateSessionInformation not implemented for %s" \
            % self.__class__.__name__

    def updateConfigInformation(self, infos):
        '''
        Update the config information in the user interface
        infos is a dict
        '''
        assert False, "method updateConfigInformation not implemented for %s" \
            % self.__class__.__name__

    def showWelcome(self, cfg, onEveryStartup):
        '''
        show a presentation of client on first start
        '''
        assert False, "method showWelcome not implemented for %s" \
            % self.__class__.__name__

    # ======================== the following methods are not events strictly speaking

    def quitUI(self):
        '''
        Asks the UI component to gracefully exit. This must be called by the client
        before quitting.
        '''
        assert False, "method quitUI not implemented for %s" \
            % self.__class__.__name__

    def waitReady(self):
        '''
        Blocks until the UI to became ready to get any notification.

        '''
        assert False, "method waitReady not implemented for %s" \
            % self.__class__.__name__

    def isReady(self):
        '''
        Checks if the UI is ready to get any notification.
        '''
        return self.ready




########NEW FILE########
__FILENAME__ = label_based_ui
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the label_based_ui module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
from xattr import xattr
from struct import pack, unpack

from filerockclient.ui.interfaces import HeyDriveUserInterfaceNotification
from filerockclient.interfaces import  PStatuses

OSX_LABEL_NONE    = 0
OSX_LABEL_ORANGE  = 1
OSX_LABEL_RED     = 2
OSX_LABEL_YELLOW  = 3
OSX_LABEL_BLUE    = 4
OSX_LABEL_PURPLE  = 5
OSX_LABEL_GREEN   = 6
OSX_LABEL_GREY    = 7
OSX_FINDER_XATTR_NAME   = u'com.apple.FinderInfo'
OSX_FINDER_XATTR_FORMAT = 32*'B'


def set_osx_finder_file_label(pathname, osx_label_code):
    '''
    Set @pathname label color to @osx_label_code.
    NB: @pathname must be an absolute pathname.
    Do nothing if system.platform is not darwin (Mac Os X).
    '''
    xattrs = xattr(pathname)
    try:             finder_xattr = list(unpack(OSX_FINDER_XATTR_FORMAT, xattrs[OSX_FINDER_XATTR_NAME]))
    except KeyError: finder_xattr = [0] * 32
    finder_xattr[9] = (8 - osx_label_code) * 2
    finder_xattr = tuple(finder_xattr)
    xattrs.set(OSX_FINDER_XATTR_NAME, pack(OSX_FINDER_XATTR_FORMAT, *finder_xattr))


def get_osx_finder_file_label(pathname):
    '''
    Return osx_label_code for @pathname.
    Return None if system.platform is not darwin (Mac Os X).
    '''
    try:
        finder_attrs = xattr(pathname)[OSX_FINDER_XATTR_NAME]
        return (8-(unpack(OSX_FINDER_XATTR_FORMAT, finder_attrs)[9]/2))
    except KeyError: return 0


def clean_all_osx_labels(pathnames_list):
    '''
    Remove labels from all pathnames in @pathnames_list
    @pathnames_list must contain only absolute pathnames
    '''
    for p in pathnames_list:
        if get_osx_finder_file_label(p) != OSX_LABEL_NONE:
            set_osx_finder_file_label(p, OSX_LABEL_NONE)


class OSXLabelBasedUI(HeyDriveUserInterfaceNotification):

    def __init__(self, client):
        self.logger = logging.getLogger("FR.OSXLabelBasedUI")
        self.client = client
        self._get_absolute_pathname = client.getAbsolutePathname

    @staticmethod
    def initUI(client):
        OSXLabelBasedUI.instance = OSXLabelBasedUI(client)
        return OSXLabelBasedUI.instance

    def setClient(self, client):
        self.client = client

    def notifyGlobalStatusChange(self, newStatus):
        pass

    def notifyCoreReady(self):
        for i in self.client.get_warebox_content():
            self.notifyPathnameStatusChange(i, PStatuses.ALIGNED)

    def notifyPathnameStatusChange(self, pathname, newStatus, extras=None):

        absolute_pathname      = self._get_absolute_pathname(pathname)
        pathname_current_color = get_osx_finder_file_label(absolute_pathname)

        if   newStatus == PStatuses.ALIGNED:           color = OSX_LABEL_GREEN
        elif newStatus == PStatuses.UNKNOWN:           color = OSX_LABEL_NONE
        elif newStatus == PStatuses.TOBEUPLOADED:      color = OSX_LABEL_YELLOW
        elif newStatus == PStatuses.UPLOADING :        color = OSX_LABEL_BLUE
        elif newStatus == PStatuses.UPLOADED :         color = OSX_LABEL_BLUE
        elif newStatus == PStatuses.UPLOADNEEDED :     color = OSX_LABEL_ORANGE
        elif newStatus == PStatuses.TOBEDOWNLOADED :   color = OSX_LABEL_YELLOW
        elif newStatus == PStatuses.DOWNLOADING :      color = OSX_LABEL_BLUE
        elif newStatus == PStatuses.DOWNLOADNEEDED :   color = OSX_LABEL_ORANGE
        elif newStatus == PStatuses.BROKENPROOF :      color = OSX_LABEL_RED

        #=======================================================================
        # We do not really need labels for deleted files, do we? :-)
        #=======================================================================
        # elif newStatus == Pstatus.DELETETOBESENT :    pass
        # elif newStatus == Pstatus.DELETESENT :        pass
        # elif newStatus == Pstatus.DELETENEEDED :      pass
        #=======================================================================
        # These are currently not used by the client at this time
        #=======================================================================
        # elif newStatus == Pstatus.RENAMETOBESENT :    color = pass
        # elif newStatus == Pstatus.RENAMESENT :        color = pass
        # elif newStatus == Pstatus.LOCALDELETE :       color = pass
        # elif newStatus == Pstatus.LOCALRENAME :       color = pass
        # elif newStatus == Pstatus.LOCALCOPY :         color = pass
        # elif newStatus == Pstatus.LOCALDELETENEEDED : color = pass
        # elif newStatus == Pstatus.LOCALRENAMENEEDED : color = pass
        # elif newStatus == Pstatus.LOCALCOPYNEEDED :   color = pass
        #=======================================================================

        try:
            if not pathname_current_color == color:
                set_osx_finder_file_label(absolute_pathname, color)
        except: pass

    def notifyUser(self, what, *args):
        pass

    def askForUserInput(self, what, *args):
        pass

    def askForUserInput_default(self, what, args):
        pass

    def notifyUser_default(self, what, args):
        pass

    def updateLinkingStatus(self, status):
        pass

    def updateConfigInformation(self, cfg):
        pass

    def updateClientInformation(self, infos):
        pass

    def updateSessionInformation(self, infos):
        pass

    def showWelcome(self, cfg, onEveryStartup=True):
        pass

    def quitUI(self):
        pass

    def waitReady(self):
        pass

    def isReady(self):
        return True


if __name__ == '__main__': pass

########NEW FILE########
__FILENAME__ = handlers
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the handlers module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""


from filerockclient.interfaces import PStatuses
from filerockclient.ui.shellextension.win32.driver.shellext_pb2 import \
            Request, Status, Menu

_handlers = {}


def get_handler(request_id, action_id):
    """Returns the registered handler for the given parameters.

    If no handler is registered for the given (request_id, action_id)
    pair, `NotImplemented` is returned.
    """
    return _handlers.get((request_id, action_id), NotImplemented)


def handler(request_id, action_id=0):
    """Decorator to register a request handler.

    A handler will be always called with two parameters: the
    :class:`Core` instance and the
    :class:`shellextension.win32.shellext_pb2.Request` to be handled.

    :param request_id: Id of the request handled
    :param action_id: (optional) Id of the action handled
    """
    def define_handler(function):
        _handlers[request_id, action_id] = function
        return function
    return define_handler


ALL_STATUSES = (Status.OK_CLEARTEXT, Status.OK_ENCRYPTED,
                Status.SYNCRONIZING, Status.INTEGRITY_KO)

SHOW_INFO = 0
ENCRYPT = 1
DECRYPT = 2
VERIFY_INTEGRITY = 3

_menu = (
    (SHOW_INFO, u'Show information', u'Show file information',
        u'Filerock.Info', ALL_STATUSES),
    (ENCRYPT, u'Encrypt', u'Store in encrypted format', u'Filerock.Encrypt',
        (Status.OK_CLEARTEXT,)),
    (DECRYPT, u'Decrypt', u'Store in cleartext', u'Filerock.Decrypt',
        (Status.OK_ENCRYPTED,)),
    (VERIFY_INTEGRITY, u'Verify integrity',
        u'Verify the integrity of the remote copy', u'Filerock.Verify',
        ALL_STATUSES)
)


@handler(Request.QUERY_FULL_CONTEXT_MENU)
def query_full_context_menu(hnd, client, request):
    response = Menu()

    if not client.isConnected():
        return response

    for cid, label, help_text, verb, _ in _menu:
        item = response.items.add()
        item.id = cid
        item.label = label
        item.help_text = help_text
        item.verb = verb
    return response


@handler(Request.QUERY_PATH_CONTEXT_MENU)
def query_path_context_menu(hnd, client, request):
    response = Menu()

    if not client.isConnected():
        return response

    try:
        status = get_status(client, request)
    except ValueError:
        return response

    for cid, label, help_text, verb, status_list in _menu:
        if status not in status_list:
            continue
        item = response.items.add()
        item.id = cid
        item.label = label
        item.help_text = help_text
        item.verb = verb
    return response


@handler(Request.QUERY_PATH_STATUS)
def query_path_status(hnd, client, request):
    response = Status()

    if not client.isConnected():
        return response

    try:
        response.status = get_status(client, request)
    except ValueError:
        pass

    return response


def format_pathnames(pathnames):
    output = u''
    for pathname in pathnames:
        output += '\n\t' + repr(pathname)
    return output


@handler(Request.EXECUTE_MENU_ACTION, SHOW_INFO)
def execute_show_info(hnd, client, request):
    hnd.log.info(
        u'Ignoring unimplemented SHOW_INFO request for pathnames:\n\t{}'
        .format(u'\n\t'.join(request.pathname)))


@handler(Request.EXECUTE_MENU_ACTION, ENCRYPT)
def execute_encrypt(hnd, client, request):
    hnd.log.info('Ignoring unimplemented ENCRYPT shell extension request' +
        ' for pathnames: %s' % format_pathnames(request.pathname))


@handler(Request.EXECUTE_MENU_ACTION, DECRYPT)
def execute_decrypt(hnd, client, request):
    hnd.log.info('Ignoring unimplemented DECRYPT shell extension request' +
        ' for pathnames: %s' % format_pathnames(request.pathname))


@handler(Request.EXECUTE_MENU_ACTION, VERIFY_INTEGRITY)
def execute_verify_integrity(hnd, client, request):
    hnd.log.info(
        'Ignoring unimplemented VERIFY_INTEGRITY shell extension request' +
        ' for pathnames: %s' % format_pathnames(request.pathname))


def get_status(client, request):
    pathname = client.getInternalPathname(request.pathname[0])
    return transcode_status(
        client.getPathnameStatus(pathname),
        is_encrypted(pathname))


def is_encrypted(pathname):
    return pathname.startswith(u'encrypted/')


def transcode_status(pstatus, encrypted):
    if pstatus == PStatuses.ALIGNED:
        return Status.OK_ENCRYPTED if encrypted else Status.OK_CLEARTEXT

    if pstatus == PStatuses.UNKNOWN:
        return Status.STILL_UNSEEN

    if pstatus == PStatuses.BROKENPROOF:
        return Status.INTEGRITY_KO

    return Status.SYNCRONIZING

########NEW FILE########
__FILENAME__ = shellext_pb2
# Generated by the protocol buffer compiler.  DO NOT EDIT!

from google.protobuf import descriptor
from google.protobuf import message
from google.protobuf import reflection
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)



DESCRIPTOR = descriptor.FileDescriptor(
  name='shellext.proto',
  package='filerock.shellext',
  serialized_pb='\n\x0eshellext.proto\x12\x11\x66ilerock.shellext\"\xd1\x01\n\x07Request\x12.\n\x07\x63ommand\x18\x01 \x02(\x0e\x32\x1d.filerock.shellext.Request.Id\x12\x14\n\taction_id\x18\x02 \x01(\r:\x01\x30\x12\x10\n\x08pathname\x18\x03 \x03(\t\"n\n\x02Id\x12\x15\n\x11QUERY_PATH_STATUS\x10\x00\x12\x1b\n\x17QUERY_PATH_CONTEXT_MENU\x10\x01\x12\x1b\n\x17QUERY_FULL_CONTEXT_MENU\x10\x02\x12\x17\n\x13\x45XECUTE_MENU_ACTION\x10\x03\"\xc6\x01\n\x06Status\x12\x42\n\x06status\x18\x01 \x01(\x0e\x32$.filerock.shellext.Status.FileStatus:\x0cGOT_NO_REPLY\"x\n\nFileStatus\x12\x10\n\x0cGOT_NO_REPLY\x10\x00\x12\x10\n\x0cOK_CLEARTEXT\x10\x01\x12\x10\n\x0cOK_ENCRYPTED\x10\x02\x12\x10\n\x0cSYNCRONIZING\x10\x03\x12\x10\n\x0cINTEGRITY_KO\x10\x04\x12\x10\n\x0cSTILL_UNSEEN\x10\x05\"w\n\x04Menu\x12+\n\x05items\x18\x01 \x03(\x0b\x32\x1c.filerock.shellext.Menu.Item\x1a\x42\n\x04Item\x12\n\n\x02id\x18\x01 \x02(\r\x12\r\n\x05label\x18\x02 \x02(\t\x12\x11\n\thelp_text\x18\x03 \x02(\t\x12\x0c\n\x04verb\x18\x04 \x02(\t')



_REQUEST_ID = descriptor.EnumDescriptor(
  name='Id',
  full_name='filerock.shellext.Request.Id',
  filename=None,
  file=DESCRIPTOR,
  values=[
    descriptor.EnumValueDescriptor(
      name='QUERY_PATH_STATUS', index=0, number=0,
      options=None,
      type=None),
    descriptor.EnumValueDescriptor(
      name='QUERY_PATH_CONTEXT_MENU', index=1, number=1,
      options=None,
      type=None),
    descriptor.EnumValueDescriptor(
      name='QUERY_FULL_CONTEXT_MENU', index=2, number=2,
      options=None,
      type=None),
    descriptor.EnumValueDescriptor(
      name='EXECUTE_MENU_ACTION', index=3, number=3,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=137,
  serialized_end=247,
)

_STATUS_FILESTATUS = descriptor.EnumDescriptor(
  name='FileStatus',
  full_name='filerock.shellext.Status.FileStatus',
  filename=None,
  file=DESCRIPTOR,
  values=[
    descriptor.EnumValueDescriptor(
      name='GOT_NO_REPLY', index=0, number=0,
      options=None,
      type=None),
    descriptor.EnumValueDescriptor(
      name='OK_CLEARTEXT', index=1, number=1,
      options=None,
      type=None),
    descriptor.EnumValueDescriptor(
      name='OK_ENCRYPTED', index=2, number=2,
      options=None,
      type=None),
    descriptor.EnumValueDescriptor(
      name='SYNCRONIZING', index=3, number=3,
      options=None,
      type=None),
    descriptor.EnumValueDescriptor(
      name='INTEGRITY_KO', index=4, number=4,
      options=None,
      type=None),
    descriptor.EnumValueDescriptor(
      name='STILL_UNSEEN', index=5, number=5,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=328,
  serialized_end=448,
)


_REQUEST = descriptor.Descriptor(
  name='Request',
  full_name='filerock.shellext.Request',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    descriptor.FieldDescriptor(
      name='command', full_name='filerock.shellext.Request.command', index=0,
      number=1, type=14, cpp_type=8, label=2,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    descriptor.FieldDescriptor(
      name='action_id', full_name='filerock.shellext.Request.action_id', index=1,
      number=2, type=13, cpp_type=3, label=1,
      has_default_value=True, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    descriptor.FieldDescriptor(
      name='pathname', full_name='filerock.shellext.Request.pathname', index=2,
      number=3, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _REQUEST_ID,
  ],
  options=None,
  is_extendable=False,
  extension_ranges=[],
  serialized_start=38,
  serialized_end=247,
)


_STATUS = descriptor.Descriptor(
  name='Status',
  full_name='filerock.shellext.Status',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    descriptor.FieldDescriptor(
      name='status', full_name='filerock.shellext.Status.status', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=True, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _STATUS_FILESTATUS,
  ],
  options=None,
  is_extendable=False,
  extension_ranges=[],
  serialized_start=250,
  serialized_end=448,
)


_MENU_ITEM = descriptor.Descriptor(
  name='Item',
  full_name='filerock.shellext.Menu.Item',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    descriptor.FieldDescriptor(
      name='id', full_name='filerock.shellext.Menu.Item.id', index=0,
      number=1, type=13, cpp_type=3, label=2,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    descriptor.FieldDescriptor(
      name='label', full_name='filerock.shellext.Menu.Item.label', index=1,
      number=2, type=9, cpp_type=9, label=2,
      has_default_value=False, default_value=unicode("", "utf-8"),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    descriptor.FieldDescriptor(
      name='help_text', full_name='filerock.shellext.Menu.Item.help_text', index=2,
      number=3, type=9, cpp_type=9, label=2,
      has_default_value=False, default_value=unicode("", "utf-8"),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    descriptor.FieldDescriptor(
      name='verb', full_name='filerock.shellext.Menu.Item.verb', index=3,
      number=4, type=9, cpp_type=9, label=2,
      has_default_value=False, default_value=unicode("", "utf-8"),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  extension_ranges=[],
  serialized_start=503,
  serialized_end=569,
)

_MENU = descriptor.Descriptor(
  name='Menu',
  full_name='filerock.shellext.Menu',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    descriptor.FieldDescriptor(
      name='items', full_name='filerock.shellext.Menu.items', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[_MENU_ITEM, ],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  extension_ranges=[],
  serialized_start=450,
  serialized_end=569,
)

_REQUEST.fields_by_name['command'].enum_type = _REQUEST_ID
_REQUEST_ID.containing_type = _REQUEST;
_STATUS.fields_by_name['status'].enum_type = _STATUS_FILESTATUS
_STATUS_FILESTATUS.containing_type = _STATUS;
_MENU_ITEM.containing_type = _MENU;
_MENU.fields_by_name['items'].message_type = _MENU_ITEM
DESCRIPTOR.message_types_by_name['Request'] = _REQUEST
DESCRIPTOR.message_types_by_name['Status'] = _STATUS
DESCRIPTOR.message_types_by_name['Menu'] = _MENU

class Request(message.Message):
  __metaclass__ = reflection.GeneratedProtocolMessageType
  DESCRIPTOR = _REQUEST
  
  # @@protoc_insertion_point(class_scope:filerock.shellext.Request)

class Status(message.Message):
  __metaclass__ = reflection.GeneratedProtocolMessageType
  DESCRIPTOR = _STATUS
  
  # @@protoc_insertion_point(class_scope:filerock.shellext.Status)

class Menu(message.Message):
  __metaclass__ = reflection.GeneratedProtocolMessageType
  
  class Item(message.Message):
    __metaclass__ = reflection.GeneratedProtocolMessageType
    DESCRIPTOR = _MENU_ITEM
    
    # @@protoc_insertion_point(class_scope:filerock.shellext.Menu.Item)
  DESCRIPTOR = _MENU
  
  # @@protoc_insertion_point(class_scope:filerock.shellext.Menu)

# @@protoc_insertion_point(module_scope)

########NEW FILE########
__FILENAME__ = ui
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the ui module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""


from logging import getLogger
from SocketServer import TCPServer, BaseRequestHandler
from threading import Thread
from win32com.shell import shell, shellcon

from filerockclient.ui.shellextension.win32.driver.handlers import get_handler
from filerockclient.ui.shellextension.win32.driver.shellext_pb2 import Request


HOST, PORT = 'localhost', 9999


class UiListener(object):
    def __init__(self, client, tcp_listener):
        self._get_absolute_pathname = client.getAbsolutePathname
        self._tcp_listener = tcp_listener

    def setClient(self, client):
        self._get_absolute_pathname = client.getAbsolutePathname
        self._tcp_listener.set_client(client)

    def notifyGlobalStatusChange(self, new_status):
        pass

    def notifyPathnameStatusChange(self, pathname, new_status, extras=None):
        shell.SHChangeNotify(shellcon.SHCNE_UPDATEITEM, shellcon.SHCNF_PATHW,
            self._get_absolute_pathname(pathname), None)

    def notifyUser(self, what, *args):
        pass

    def notifyCoreReady(self):
        pass

    def askForUserInput(self, what, *args):
        pass

    def updateLinkingStatus(self, status):
        pass

    def updateClientInformation(self, infos):
        pass

    def updateSessionInformation(self, infos):
        pass

    def updateConfigInformation(self, infos):
        pass

    def showWelcome(self, cfg, onEveryStartup):
        pass

    def quitUI(self):
        self._tcp_listener.shutdown()

    def waitReady(self):
        pass

    def isReady(self):
        return True


class TcpListener(Thread):
    def __init__(self, server):
        Thread.__init__(self, name='ShellExtTCPListener')
        self._server = server
        self._log = getLogger('FR.' + self.__class__.__name__)

    def run(self):
        self._log.debug('Starting TCP listener for shell extension')
        try:
            self._server.serve_forever()
        except StandardError:
            raise Error('Could not start TCP listener for shell extension')

    def set_client(self, client):
        # Setting client to server, woww.
        self._server.filerock_client = client

    def shutdown(self):
        self._log.debug('Terminating TCP listener for shell extension...')
        self._server.shutdown()
        self._server.server_close()
        self._log.debug('TCP listener for shell extension terminated.')


class ProtobufHandler(BaseRequestHandler):
    def handle(self):
        request = Request()
        try:
            request.ParseFromString(self.request.recv(1024))
        except Exception as e:
            self.log.error(
                u'Received incomplete request from shellext: %r' % e)
            return

        handler = get_handler(request.command, request.action_id)
        if handler is NotImplemented:
            self.log.warning(
                u'Received unknown request ({0}, {1}) from shellext'
                .format(request.command, request.action_id))
            return
        response = handler(self, self.server.filerock_client, request)

        if response is not None:
            try:
                self.request.sendall(response.SerializeToString())
            except Exception:
                self.log.error(u'Could not send response to shellext')

    @property
    def log(self):
        return getLogger('FR.' + self.__class__.__name__)


def initUI(client):
    server = TCPServer((HOST, PORT), ProtobufHandler)

    # ProtobufHandler needs access to an instance of "client" that can be
    # updated at any time (due to soft-reset of the application). We have no
    # control on it since the ProtobufHandler instance is automatically created
    # by TCPserver, that is, we can't set any handler field. However
    # TCPServer passes itself to the handler at construction time, so basically
    # we access the client through the handler's self.server attribute. Sounds
    # tortuous but it works, believe me.
    server.filerock_client = client

    listener = TcpListener(server)
    listener.start()

    return UiListener(client, listener)


class Error(Exception):
    pass

########NEW FILE########
__FILENAME__ = ui_controller
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Central interface for controlling the user interfaces (UIs).

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.util.utilities import format_to_log


class UIController(object):
    """Central interface for controlling the user interfaces (UIs).

    This controller let other application components send messages
    to the UIs and update them with data.
    User interface instances must be registered to this components (see
    the "Observer" design pattern). This first registered user
    interface is the one used for communicating with the user and it's
    called the "privileged UI".
    """

    def __init__(self, metadata_db, logger):
        """
        @param metadata_db:
                    Instance of filerockclient.databases.metadata.MetadataDB
        @param logger:
                    Instance of logging.Logger.
        """
        self._metadata_db = metadata_db
        self._logger = logger
        self._user_interfaces = []

    def register_ui(self, ui):
        """Register a user interface object to receive updates from
        the client.

        @param ui:
                Instance of any concrete implementation of
                filerockclient.ui.interfaces.HeyDriveUserInterfaceNotification
        """
        self._user_interfaces.append(ui)

    def set_global_status(self, status):
        """Send the current global status to all registered UIs.

        @param status:
                    Instance of filerockclient.interfaces.GStatuses
        """
        for ui in self._user_interfaces:
            ui.notifyGlobalStatusChange(status)

    def notify_pathname_status_change(self, pathname, new_status, extras={}):
        """Send the current status for the given pathname
        to all registered UIs.

        @param pathname:
                    String referring to a pathname in the warebox.
        @param new_status:
                    Instance of filerockclient.interfaces.PStatuses
        @param extras:
                    Dictionary with any additional parameter to be
                    passed along with "new_status".
        """
        for ui in self._user_interfaces:
            ui.notifyPathnameStatusChange(pathname,
                                          new_status,
                                          extras)

    def notify_core_ready(self):
        """Communicate that the client is ready to send and receive data
        to all registered UIs.
        """
        for ui in self._user_interfaces:
            ui.notifyCoreReady()

    def notify_user(self, what, *args):
        """Notify the user about a message.

        The only registered UI to receive the message will be the
        privileged UI.

        @param what:
                    A string that identifies what is the message to
                    communicate.
        @param args:
                    Any additional argument to send along with the
                    message.
        """
        main_ui = self._user_interfaces[0]
        main_ui.notifyUser(what, *args)

    def ask_for_user_input(self, what, *args):
        """Ask the user to insert some input data.

        The calling thread will block until this call returns, that is,
        until the user has answered.
        The only registered UI to receive the message will be the
        privileged UI.

        @param what:
                    A string that identifies what is the input to
                    insert.
        @param args:
                    Any additional argument to send along with the
                    request.
        """
        main_ui = self._user_interfaces[0]
        return main_ui.askForUserInput(what, *args)

    def update_client_info(self, infos):
        """Send client meta-data to all registered UIs.

        @param infos:
                    Dictionary with the following keys: username,
                    client_id, client_hostname, client_platform,
                    client_version, basis.
        """
        keys = ['username', 'client_id', 'client_hostname']
        keys.extend(['client_platform', 'client_version'])
        for key in keys:
            if not key in infos:
                infos[key] = None

        for key in ['last_commit_timestamp', 'used_space', 'user_quota']:
            infos[key] = self._metadata_db.try_get(key)

        self._logger.debug("Updating Client info on Gui: %s" % infos)
        for ui in self._user_interfaces:
            ui.updateClientInformation(infos)

    def update_session_info(self, infos):
        """Send session meta-data to all registered UIs.

        @param infos:
                Dictionary with the following keys: last_commit_client_id,
                last_commit_client_hostname, last_commit_client_platform',
                last_commit_timestamp, used_space, user_quota, basis,
                plan, status, expires_on.
        """
        self._logger.debug(
            'Info received from server %s', format_to_log(infos))
        keys = [
            'last_commit_client_id',
            'last_commit_client_hostname',
            'last_commit_client_platform',
            'last_commit_timestamp',
            'used_space',
            'user_quota',
            'plan',
            'status',
            'expires_on'
        ]

        for key in keys:
            if not key in infos:
                infos[key] = None

        for key in ['last_commit_timestamp', 'used_space', 'user_quota']:
            if infos[key] is not None:
                self._metadata_db.set(key, infos[key])

        for ui in self._user_interfaces:
            ui.updateSessionInformation(infos)

    def update_config_info(self, cfg):
        """Send the current configuration to all registered UIs.

        @param cfg:
                Instance of filerockclient.config.ConfigManager.
        """
        for ui in self._user_interfaces:
            ui.updateConfigInformation(cfg.to_dict())

    def update_linking_status(self, status):
        """Send the current status of the client linking phase to all
        registered UIs.

        @param status:
                Instance of filerockclient.interfaces.LinkingStatuses.
        """
        for ui in self._user_interfaces:
            ui.updateLinkingStatus(status)

    def show_welcome(self, cfg, onEveryStartup=True):
        """Tell the privileged UI to welcome the user with introductive
        information.

        Usually used at the startup of the application.

        @param cfg:
                    Instance of filerockclient.config.ConfigManager.
        @param onEveryStartup:
                    Boolean flag telling whether the welcome will be
                    shown to every startup of the application.
        """
        main_ui = self._user_interfaces[0]
        # TODO: we should pass a dictionary version of cfg
        return main_ui.showWelcome(cfg, onEveryStartup)

    def show_panel(self):
        """Tell the privileged UI to show itself to the user.

        For graphical user interfaces this usually means that the
        FileRock windows shall open.
        """
        main_ui = self._user_interfaces[0]
        return main_ui.showPanel()

########NEW FILE########
__FILENAME__ = ask_for_user_input
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the ask_for_user_input module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx
import threading
import sys
import wx.lib.newevent

from filerockclient.ui.wxGui import Messages
from filerockclient.ui.wxGui.dialogs.listdialog import ListDialog
from filerockclient.ui.wxGui.dialogs.dialog.MyMessageDialog import MyMessageDialog

LinkDialogWxEvent,          EVT_LINK_DIALOG       = wx.lib.newevent.NewEvent()
OnWareboxPathWxEvent,       EVT_WAREBOXPATH       = wx.lib.newevent.NewEvent()
OnSyncBasisMismatchWxEvent, EVT_SYNCBASISMISMATCH = wx.lib.newevent.NewEvent()


class Ask_for_user_input(object):

    def __init__(self, app):
        '''
        Constructor
        '''
        app.Bind(EVT_LINK_DIALOG, app.OnLinkDialog)
        app.Bind(EVT_WAREBOXPATH, app.OnWareboxDialog)
        app.Bind(EVT_SYNCBASISMISMATCH, app.onSyncBasisMismatch)
        self.app = app

    def askForUserInput(self, what, *args, **kwds):
        '''
        This method is supposed to be called by a non-gui thread to request user
        interaction. It is a facade to other methods selected by parameter what.
        '''
        self.app.waitReady()
        method_name = '_askForUserInput_' + what

        try:
            ask_method = getattr(self, method_name)
        except AttributeError:
            assert False, "Method %s doesn't exists in %s" % (method_name,
                                                    self.__class__.__name__)

        return ask_method(*args, **kwds)

    def _askForUserInput_rename_encrypted_file(self):
        '''
        Asks user to rename encrypted file if present
        '''
        title = Messages.RENAME_ENCRYPTED_FILE_DIALOG_TITLE
        message = Messages.RENAME_ENCRYPTED_FILE_DIALOG_BODY
        return self.askForUserInput('message', message, title, True)

    def _askForUserInput_other_client_connected(self,
                                                client_id,
                                                client_hostname):
        '''
        Asks user if want disconnect other connected client

        @param client_id: the client id number
        @param client_hostname: the hostname of the machine
        '''
        if client_id==0:
            message = Messages.WEBCLIENT_CONNECTED_DIALOG_BODY
        else:
            message = Messages.OTHER_CLIENT_CONNECTED_DIALOG_BODY % {
                                'client_id': client_id,
                                'client_hostname': client_hostname
                            }

        title = Messages.OTHER_CLIENT_CONNECTED_DIALOG_TITLE
        return self.askForUserInput('message', message, title, True)

    def _askForUserInput_warebox_not_empty(self,
                                        old_warebox_path,
                                        new_warebox_path,
                                        cancel=True,
                                        from_ui=False):
        """
        Asks user if want to select a non empty warebox

        @param old_warebox_path: the path of current warebox
        @param new_warebox_path: the path selected for the warebox
        @param cancel: if True the cancel button will shown
        @param from_ui:
        """

        if old_warebox_path==new_warebox_path:
            message = Messages.WAREBOX_NOT_EMPTY
        else:
            message = Messages.WAREBOX_CHANGED % {
                    'old_warebox_path': old_warebox_path,
                    'new_warebox_path': new_warebox_path
                    }

        title = Messages.WAREBOX_CHANGED_TITLE
        return self.askForUserInput('message', message, title, cancel, from_ui)

    def _askForUserInput_linking_credentials(self,  retry, initialization):
        '''
        Ask for user and password, blocks until the user has provided them.
        '''
        somethingToWaitOn = threading.Event()
        if initialization is None:
            user_provided_input = dict()
        else:
            user_provided_input = initialization

        evt = LinkDialogWxEvent(
                synchronization=somethingToWaitOn,  # this thread (the client) will wait on this a few lines below
#               prompt=prompt,    # something to be shown
                first_time=not retry,
                user_provided_input=user_provided_input  # a map to be modified by the dialog box to return user input
            )
        wx.PostEvent(self.app, evt)
        somethingToWaitOn.wait()  #the method blocks if requested by proper parameter

        return user_provided_input

    def _askForUserInput_logout_required(self):
        caption = Messages.LOGOUT_REQUIRED_DIALOG_TITLE
        msg = Messages.LOGOUT_REQUIRED_DIALOG_BODY
        return self._askForUserInput_message(msg, caption)

    def _askForUserInput_update_client(self, latest_version, update_is_mandatory):
        '''
        Ask for user to perform update client now
        '''
        if update_is_mandatory:
            message = Messages.UPDATE_MANDATORY_CLIENT_DIALOG_BODY % {
                                        'latest_version': latest_version
                                    }
            title = Messages.UPDATE_MANDATORY_CLIENT_DIALOG_TITLE
        else:
            message = Messages.UPDATE_CLIENT_DIALOG_BODY % {
                'latest_version': latest_version
            }
            title = Messages.UPDATE_CLIENT_DIALOG_TITLE
        return self.askForUserInput('message', message, title, True)


    def _askForUserInput_notify_update_client(self, latest_version,update_is_mandatory, download_url):
        '''
        Notify user that a new version is available
        '''
        if update_is_mandatory:
            message = Messages.UPDATE_CLIENT_MANDATORY_LINUX_DIALOG_BODY % {
                'latest_version': latest_version,
                'download_url' : download_url
            }
            title = Messages.UPDATE_CLIENT_MANDATORY_LINUX_DIALOG_TITLE
        else:
            message = Messages.UPDATE_CLIENT_LINUX_DIALOG_BODY % {
                'latest_version': latest_version,
                'download_url' : download_url
            }
            title = Messages.UPDATE_CLIENT_LINUX_DIALOG_TITLE

        return self.askForUserInput('message',message, title)

    def _askForUserInput_blacklisted_pathname_on_storage(self, list):
        '''
            Asks the user to contact us reporting the list
        '''
        message = Messages.BLACKLISTED_ON_STORAGE_BODY
        title = Messages.BLACKLISTED_ON_STORAGE_TITLE
        return self.askForUserInput('list_dialog', message, title, list)

    def _askForUserInput_message(self,
                                 msg,
                                 caption,
                                 cancel=False,
                                 from_ui=False):
        '''
        Show a simple message dialog box,
        blocks until the user has provided them.

        @param msg: the message to show
        @param caption: the dialog title
        @param cancel: true if cancel button will shown
        @param from_ui:
                    false if you want to wait on Event until a
                    reply will be received
        '''

        def show_message_dialog(synchronization, message, title, style, result # this later one will be modified adding the result of the dialog
                                ):
            with self.app.tbiconlocked():
                if sys.platform.startswith('darwin'):
                    dlg = wx.MessageDialog(None, message, title, style)
                else:
                    dlg = MyMessageDialog(None, -1, '')
                    dlg.putInfos(message, title, style)

                self.visible_dialog = dlg

                r = dlg.ShowModal()
                result.append(r)  # modify result
                dlg.Destroy()
                self.visible_dialog = None

                if synchronization is not None:
                    synchronization.set()

        style = wx.OK | wx.ICON_EXCLAMATION
        if cancel:
            style |= wx.CANCEL
        result = []

        if not from_ui:
            somethingToWaitOn = threading.Event()
            wx.CallAfter(show_message_dialog,
                         somethingToWaitOn,
                         msg,
                         caption,
                         style,
                         result)  # schedule for GUI thread the dialog to pop up asap
            somethingToWaitOn.wait()  # wait for the gui thread to do it's job
        else:
            show_message_dialog(None, msg, caption, style, result)

        if result[0] == wx.ID_OK:
            r = "ok"
        elif result[0] == wx.ID_CANCEL:
            r = "cancel"
        return r

    def _askForUserInput_list_dialog(self, msg, caption, oplist):
        '''
        Show a message dialog with a list of things.

        @param msg: the message
        @param caption: the dialog title
        @param oplist: list strings to append
        '''

        # this later one will be modified adding the result of the dialog
        def show_list_dialog(synchronization, message, title, lines, result
                                ):
            with self.app.tbiconlocked():
                ldlg = ListDialog.ListDialog(None, self, message, title, lines)
                self.visible_dialog = ldlg
                r = ldlg.ShowModal()
                result.append(r)  # modify result
                ldlg.Destroy()
                self.visible_dialog = None
                synchronization.set()

        somethingToWaitOn = threading.Event()
        result = []
        wx.CallAfter(show_list_dialog,
                     somethingToWaitOn,
                     msg,
                     caption,
                     oplist,
                     result)  # schedule for GUI thread to pop up asap
        somethingToWaitOn.wait()  # wait for the gui thread to do it's job
        if result[0] == wx.ID_OK:
            res = "ok"
        elif result[0] == wx.ID_CANCEL:
            res = "cancel"
        return res

    def _askForUserInput_warebox_path(self, warebox_path):
        """
        Shows a dialog with a path selector

        @param warebox_path: the current warebox path
        """
        return_struct = {
                         'result': False,
                         'warebox_path': warebox_path
                         }
        somethingToWaitOn = threading.Event()
        self.app.waitReady()
        evt = OnWareboxPathWxEvent(result=return_struct,
                                   syncOn=somethingToWaitOn)
        wx.PostEvent(self.app, evt)
        somethingToWaitOn.wait()
        return return_struct

    def _askForUserInput_accept_sync(self,
                                     content,
                                     client_basis,
                                     server_basis):
        """
        Shows a dialog with the client and the server basis and the list of
        operation to accept.

        @param content: the operation list
        @param client_basis: the basis known by the client
        @param server_basis: the basis declared from server
        """
        return_struct = {'result': ''}
        somethingToWaitOn = threading.Event()
        if self.app.isReady():
            evt = OnSyncBasisMismatchWxEvent(
                    result=return_struct,
                    syncOn=somethingToWaitOn,
                    content=content,
                    client_basis=client_basis,
                    server_basis=server_basis
                )
            wx.PostEvent(self.app, evt)
        somethingToWaitOn.wait()
        return return_struct['result']

    def _askForUserInput_encryption_dir_deleted(self, firststart=False):
        """
        Notifies the user about the deletion of the encryption directory
        """
        caption = Messages.ENCRYPTED_DIR_DELETED_DIALOG_TITLE
        msg = Messages.ENCRYPTED_DIR_DELETED_DIALOG_BODY
        return self._askForUserInput_message(msg, caption)

    def _askForUserInput_protocol_obsolete(self):
        """Notifies the user about the obsolescence of protocol version"""
        caption = Messages.PROTOCOL_OBSOLETE_DIALOG_TITLE
        msg = Messages.PROTOCOL_OBSOLETE_DIALOG_BODY
        return self._askForUserInput_message(msg, caption)

    def _askForUserInput_quit(self, issued_by=None, details=None):
        """Notifies the user about a quit request"""
        caption = Messages.QUIT_DIALOG_TITLE
        if details is not None and 'client_ip' in details:
            client_ip = details['client_ip']
        else:
            client_ip = Messages.UNKNOWN

        if issued_by is not None and issued_by == 'client':
            msg = Messages.QUIT_DIALOG_ISSUED_FROM_CLIENT_BODY % {
                                    'client_id': details['client_id'],
                                    'client_hostname': details['hostname'],
                                    'client_platform': details['platform'],
                                    'client_ip': client_ip
                                }
        else:
            msg = Messages.QUIT_DIALOG_BODY
        return self._askForUserInput_message(msg, caption)
########NEW FILE########
__FILENAME__ = constants
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Global values that need to be statically accessed by the GUI code.

The available values are the absolute filesystem pathnames for:
    - ICON_PATH: directory that contains the application icons.
    - IMAGE_PATH: directory that contains the application images.
    - LOCALE_PATH: directory that contains the application translations.

Please try not to abuse of this module, of you course you know that
static global visibility is pure evil. It only exists because the GUI
code already had so many static/hardwired accesses to the values it
contains.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

ICON_PATH = u""
IMAGE_PATH = u""
LOCALE_PATH = u""


def init(images_path, icons_path, locale_path):
    """Set the global variables IMAGE_PATH, ICON_PATH, LOCALE_PATH.

    These variables contains the filesystem paths where there are stored
    the icons, the images and the translation files.

    Only GUI modules use these variabile. Their initialization is done
    only once, at application startup, by some external module.
    """
    global ICON_PATH
    global IMAGE_PATH
    global LOCALE_PATH

    ICON_PATH = icons_path
    IMAGE_PATH = images_path
    LOCALE_PATH = locale_path

########NEW FILE########
__FILENAME__ = MyFrame
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the MyFrame module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

# generated by wxGlade 0.6.3 on Wed Jun 27 12:27:39 2012

import wx

# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade

class MyFrame(wx.Frame):
    def __init__(self, *args, **kwds):
        # begin wxGlade: MyFrame.__init__
        kwds["style"] = wx.DEFAULT_FRAME_STYLE
        wx.Frame.__init__(self, *args, **kwds)
        self.panel_2 = wx.Panel(self, -1)
        self.sizer_4_staticbox = wx.StaticBox(self.panel_2, -1, "Activity")
        self.list_ctrl_1 = wx.ListCtrl(self.panel_2, -1, style=wx.LC_REPORT|wx.LC_ICON|wx.LC_SORT_ASCENDING|wx.SUNKEN_BORDER)

        self.__set_properties()
        self.__do_layout()
        # end wxGlade




    def __set_properties(self):
        # begin wxGlade: MyFrame.__set_properties
        self.SetTitle("frame_1")
        # end wxGlade


    def __do_layout(self):
        # begin wxGlade: MyFrame.__do_layout
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_4 = wx.StaticBoxSizer(self.sizer_4_staticbox, wx.VERTICAL)
        sizer_4.Add(self.list_ctrl_1, 1, wx.EXPAND, 0)
        self.panel_2.SetSizer(sizer_4)
        sizer_1.Add(self.panel_2, 1, wx.LEFT|wx.RIGHT|wx.EXPAND, 10)
        self.SetSizer(sizer_1)
        sizer_1.Fit(self)
        self.Layout()
        # end wxGlade

# end of class MyFrame



########NEW FILE########
__FILENAME__ = SettingsWidgets
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the SettingsWidgets module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx
from wx import FilePickerCtrl
from wx.combo import BitmapComboBox

from filerockclient.ui.wxGui.Utils import TASKBARLEFTCLICKACTIONS
from filerockclient.ui.wxGui.Utils import _img
from filerockclient.ui.wxGui import Messages

ENABLED = True
DISABLED = False


TASKBARLEFTCLICKACTIONS_LABELS = [
                                  Messages.CONFIG_LEFTCLICK_PANEL,
                                  Messages.CONFIG_LEFTCLICK_FOLDER
                                  ]

UPDATECOMBOBOX_LABELS = [
                         Messages.CONFIG_AUTOUPDATE,
                         Messages.CONFIG_ASKFORUPDATE
                         ]

CLOUD_COMBOBOX = [
                  Messages.CONFIG_CLOUD_SEEWEB,
                  Messages.CONFIG_CLOUD_AMAZON,
                  Messages.CONFIG_CLOUD_AZURE
                  ]

class SpinCtrl(wx.SpinCtrl):
    def __init__(self, *args, **kwds):
        super(SpinCtrl, self).__init__(*args, **kwds)
        self.default_value = 0
    
    def SetValue(self, value):
        int_value = 0
        try:
            int_value=int(value)
        except:
            pass
        return super(SpinCtrl, self).SetValue(int_value)
    
    def GetValue(self):
        str_value = '0'
        try:
            str_value = str(super(SpinCtrl, self).GetValue())
        except:
            pass
        return str_value

class CtrlText(wx.TextCtrl):

    def __init__(self, *args, **kwds):
        super(CtrlText, self).__init__(*args, **kwds)
        self.default_value = ""
        self.Bind(wx.EVT_KEY_UP, self.onKeyUp)

    def onKeyUp(self, evt):
        if evt.GetKeyCode() == wx.WXK_ESCAPE:
            self.SetValue(self.default_value)

class DirPickerCtrl(wx.DirPickerCtrl):
    def __init__(self, *args, **kwds):
        super(DirPickerCtrl, self).__init__(*args, **kwds)
        self.default_value = ""
        self.Bind(wx.EVT_KEY_UP, self.onKeyUp)

    def GetValue(self):
        return self.GetPath()

    def SetValue(self, value):
        return self.SetPath(value)

    def onKeyUp(self, evt):
        if evt.GetKeyCode() == wx.WXK_ESCAPE:
            self.SetValue(self.default_value)


class CheckBox(wx.CheckBox):
    def __init__(self, value, *args, **kwds):
        super(CheckBox, self).__init__(*args, **kwds)
        self.default_value = ""
        self.SetValue(value)

    def GetValue(self):
        if super(CheckBox, self).GetValue():
            return u"True"
        else:
            return u"False"

    def SetValue(self, value):
        if value == u"True":
            super(CheckBox, self).SetValue(True)
        else:
            super(CheckBox, self).SetValue(False)


class Proxy_options(wx.BoxSizer):
    def __init__(self, value, parent, panel, *args, **kwargs):
        wx.BoxSizer.__init__(self, *args, **kwargs)
        self.checkbox = CheckBox(value, parent)
        self.config_button = Button(parent, -1, 'Proxy Settings')
        panel.Bind(wx.EVT_BUTTON, panel.show_proxy_dialog, self.config_button)
        self.Add(self.checkbox, 0 , wx.ALIGN_CENTER_VERTICAL |wx.LEFT, 5)
        self.Add(self.config_button, 1, wx.LEFT, 5)

    def GetValue(self):
        return self.checkbox.GetValue()

    def SetValue(self, value):
        return self.checkbox.SetValue(value)

class Bandwidth_limit(wx.BoxSizer):
    def __init__(self, value, parent, panel, *args, **kwargs):
        wx.BoxSizer.__init__(self, *args, **kwargs)

        self.up = SpinCtrl(parent, -1, value["UP"], style=wx.SP_HORIZONTAL,
                           min=0, max = 9999)
        self.down = SpinCtrl(parent, -1, value["DOWN"], style=wx.SP_HORIZONTAL,
                             min=0, max = 9999)
        up_text = wx.StaticText(parent,
                                     -1,
                                     Messages.CONFIG_BANDWIDTH_UPLOAD_LABEL)
        down_text = wx.StaticText(parent,
                                       -1,
                                       Messages.CONFIG_BANDWIDTH_DOWNLOAD_LABEL)
        self.up.SetToolTipString(Messages.CONFIG_BANDWIDTH_LIMIT_UPLOAD_TOOLTIP)
        self.down.SetToolTipString(Messages.CONFIG_BANDWIDTH_LIMIT_DOWNLOAD_TOOLTIP)
        self.Add(up_text,0,wx.ALIGN_CENTER_VERTICAL|wx.RIGHT, 2)
        self.Add(self.up,1,wx.ALIGN_CENTER_VERTICAL)
        self.Add((10, 5), 0, 0, 0)
        self.Add(down_text,0,wx.ALIGN_CENTER_VERTICAL|wx.RIGHT, 2)
        self.Add(self.down,1,wx.ALIGN_CENTER_VERTICAL)

    def GetValue(self):
        values = {"UP": self.up.GetValue(),
                  "DOWN": self.down.GetValue()}
        return values

    def SetValue(self, values):
        self.up.SetValue(values["UP"])
        self.down.SetValue(values["DOWN"])

class CloudComboBox(BitmapComboBox):

    def __init__(self, *args, **kwds):
        self.status = {
            Messages.CONFIG_CLOUD_SEEWEB: (ENABLED, _img('cloud/ESeeweb.png')),
            Messages.CONFIG_CLOUD_AMAZON: (DISABLED,_img('cloud/DAmazonS3.png')),
            Messages.CONFIG_CLOUD_AZURE:  (DISABLED,_img('cloud/DAzure.png'))
        }

        super(CloudComboBox, self).__init__(*args, **kwds)
        self.Bind(wx.EVT_COMBOBOX, self.OnChange)
        for cloud in CLOUD_COMBOBOX:
            status = ''
            if not self.status[cloud][0]:
                status = '%s' % Messages.CONFIG_CLOUD_DISABLED_LABEL
            label = Messages.CONFIG_CLOUD_LABEL % {'status': status,
                                                   'cloud': cloud}

            self.Append(label, self.status[cloud][1])
        self.SetValue(CLOUD_COMBOBOX[0])

    def SetValue(self, value):
        if value is not None:
            self.Select(CLOUD_COMBOBOX.index(value))
        else:
            self.SetSelection(0)

    def OnChange(self, evt):
        if not self.status[CLOUD_COMBOBOX[self.GetSelection()]][0]:
            self.SetSelection(0)

class ReplicaComboBox(wx.ComboBox):
    def __init__(self, *args, **kwds):
        super(ReplicaComboBox, self).__init__(*args, **kwds)
        self.Insert(Messages.CONFIG_NOT_AVAILABLE ,0)
        self.Disable()

    def SetValue(self, value):
        if value is not None:
            return wx.ComboBox.SetValue(self, value)
        self.SetSelection(0)
        return None

class ComboBox(wx.ComboBox):
    def __init__(self, *args, **kwds):
        super(ComboBox, self).__init__(*args, **kwds)
        self.default_value = ""
        self.str_to_value = None
        self.value_to_str = None
        
    def GetValue(self, *args, **kwargs):
        return self.str_to_value[super(ComboBox, self).GetValue(*args, **kwargs)]

    def SetValue(self, value):
        return super(ComboBox, self).SetValue(self.value_to_str[value])

class LeftClickComboBox(ComboBox):
        
    def __init__(self, parent, val):
        super(LeftClickComboBox, self).__init__(parent,
                                                -1,
                                                val,
                                                choices=TASKBARLEFTCLICKACTIONS_LABELS,
                                                style=wx.CB_READONLY),
        self.value_to_str = {
            TASKBARLEFTCLICKACTIONS[0]: TASKBARLEFTCLICKACTIONS_LABELS[0],
            TASKBARLEFTCLICKACTIONS[1]: TASKBARLEFTCLICKACTIONS_LABELS[1]
        }

        self.str_to_value = {
            TASKBARLEFTCLICKACTIONS_LABELS[0]: TASKBARLEFTCLICKACTIONS[0],
            TASKBARLEFTCLICKACTIONS_LABELS[1]: TASKBARLEFTCLICKACTIONS[1]
        }


class AutoUpdateComboBox(ComboBox):
    
    def __init__(self, parent, val):
        super(AutoUpdateComboBox, self).__init__(parent,
                                             -1,
                                             val,
                                             choices=UPDATECOMBOBOX_LABELS,
                                             style=wx.CB_READONLY),
        self.value_to_str = {
            str(ENABLED)  : UPDATECOMBOBOX_LABELS[0],
            str(DISABLED) : UPDATECOMBOBOX_LABELS[1]
        }
        
        self.str_to_value = {
            UPDATECOMBOBOX_LABELS[0] : str(ENABLED),
            UPDATECOMBOBOX_LABELS[1] : str(DISABLED)
        }



class Button(wx.Button):
    def __init__(self, *args, **kwargs):
        wx.Button.__init__(self, *args, **kwargs)

    def SetValue(self, value):
        pass

    def GetValue(self, *args, **kwargs):
        pass


class LogsButton(wx.Button):
    """This button shows the logs window, but it is supposed to be used
    only as option widget within panel3. This is because the way it 
    bind its event to the method of the mainwindow."""
    
    def __init__(self, parent, *args, **kwargs):
        wx.Button.__init__(self, parent, *args, **kwargs)

        # this is a quick and dirty approach to find the right method do call on button click
        panel3=parent.Parent  
        mainwindow=panel3.Parent
        self.Bind(wx.EVT_BUTTON, mainwindow.OnLogsClick, self)

        #improperly using the MAINWINDOW symbols for labels and tooltips
        self.SetLabel(Messages.MAINWINDOW_LOGS_BUTTON_LABEL) 
        self.SetToolTipString(Messages.MAINWINDOW_LOGS_BUTTON_TOOTIP)
        
    def SetValue(self, unused_value):
        pass

    def GetValue(self):
        return None

########NEW FILE########
__FILENAME__ = widgets_dict
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the widgets_dict module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.ui.wxGui.default.panel_3.widgets.SettingsWidgets import *

WIDGETS = {
    u'Application Paths': {
        u'warebox_path': lambda parent, val, _: DirPickerCtrl(parent, -1, val)
    },
    u"NOCFG": {
        u'cloud_storage': lambda parent,
                                val,
                                _: CloudComboBox(parent,
                                                 -1,
                                                 style=wx.CB_READONLY),
        u'replica_cloud': lambda parent,
                                val,
                                _: ReplicaComboBox(parent,
                                                   -1,
                                                   style=wx.CB_READONLY),
        u'bandwidth_limit': lambda parent,
                                  val,
                                  panel: Bandwidth_limit(val, parent, panel),
                                  
        u'show_logs_window': lambda parent,
                                  val,
                                  panel: LogsButton(parent)
                                  
    },
    u"User Defined Options": {
        u'launch_on_startup': lambda parent, val, _: CheckBox(val, parent),
        u'on_tray_click': lambda parent,
                                val,
                                _: LeftClickComboBox(parent,
                                                     val),
        u'auto_update': lambda parent,
                                val,
                                _: AutoUpdateComboBox(parent,
                                                      val),
        u'osx_label_shellext': lambda parent, val, _: CheckBox(val, parent),
        u'proxy_usage': lambda parent,
                              val,
                              panel: Proxy_options(val,
                                                   parent,
                                                   panel,
                                                   wx.HORIZONTAL),
        'show_slideshow': lambda parent,
                                     val,
                                     _: CheckBox(val, parent)


    }
}
########NEW FILE########
__FILENAME__ = MainWindow
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the MainWindow module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""
# generated by wxGlade 0.6.3 on Tue Jun 26 22:31:17 2012

import wx
import os

# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode
from filerockclient.ui.wxGui.Utils import MywxStaticText
# end wxGlade


class MainWindow(wx.Frame):
    def __init__(self, images_dir, icons_dir, *args, **kwds):
        # begin wxGlade: MainWindow.__init__
        kwds["style"] = wx.CAPTION|wx.CLOSE_BOX|wx.MINIMIZE_BOX|wx.SYSTEM_MENU|wx.CLIP_CHILDREN
        wx.Frame.__init__(self, *args, **kwds)
        self.images_dir = images_dir
        self.icons_dir = icons_dir
        self.sizer_3_staticbox = wx.StaticBox(self, -1, "Used Space")
        self.folder_bitmap_button = wx.BitmapButton(self, -1, wx.Bitmap(self._image_path("other/folder-48.png"), wx.BITMAP_TYPE_ANY))
        self.folder_label = wx.StaticText(self, -1, "Open Folder")
        self.status_bitmap_button = wx.BitmapButton(self, -1, wx.Bitmap(self._image_path("GUI-icons/dialog-information-48.png"), wx.BITMAP_TYPE_ANY))
        self.status_label = wx.StaticText(self, -1, "Status")
        self.activity_bitmap_button = wx.BitmapButton(self, -1, wx.Bitmap(self._image_path("GUI-icons/activity-48.png"), wx.BITMAP_TYPE_ANY))
        self.activity_label = wx.StaticText(self, -1, "Activity")
        self.preferences_bitmap_button = wx.BitmapButton(self, -1, wx.Bitmap(self._image_path("GUI-icons/preferences-system-48.png"), wx.BITMAP_TYPE_ANY), style=wx.BU_AUTODRAW)
        self.preferences_label = wx.StaticText(self, -1, "Options")
        self.start_stop_bitmap_button = wx.BitmapButton(self, -1, wx.Bitmap(self._image_path("GUI-icons/pause-48-tango.png"), wx.BITMAP_TYPE_ANY))
        self.start_stop_label = wx.StaticText(self, -1, "Pause")
        #self.logs_bitmap_button = wx.BitmapButton(self, -1, wx.Bitmap(self._image_path("GUI-icons/logs-48.png"), wx.BITMAP_TYPE_ANY), style=wx.BU_AUTODRAW)
        #self.logs_label = wx.StaticText(self, -1, "Logs")
        self.space_ctrl = MywxStaticText(self, -1, "--- Mb of -- Gb")
        self.used_space_bar = wx.Gauge(self, -1, 1000)
        self.get_more_space_button = wx.Button(self, -1, "Upgrade", style=wx.BU_EXACTFIT)

        self.__set_properties()
        self.__do_layout()

        self.Bind(wx.EVT_BUTTON, self.OnFileRockFolder, self.folder_bitmap_button)
        self.Bind(wx.EVT_BUTTON, self.OnStatusClick, self.status_bitmap_button)
        self.Bind(wx.EVT_BUTTON, self.OnActivityClick, self.activity_bitmap_button)
        self.Bind(wx.EVT_BUTTON, self.OnPreferencesClick, self.preferences_bitmap_button)
        self.Bind(wx.EVT_BUTTON, self.OnStartStop, self.start_stop_bitmap_button)
        #self.Bind(wx.EVT_BUTTON, self.OnLogsClick, self.logs_bitmap_button)
        self.Bind(wx.EVT_BUTTON, self.OnGetMoreSpace, self.get_more_space_button)
        # end wxGlade

        self.buttons = {
                        'status': self.status_bitmap_button,
                        'activity': self.activity_bitmap_button,
                        'preferences': self.preferences_bitmap_button
                        }

    def _image_path(self, name):
        return os.path.join(self.images_dir, name)

    def _icon_path(self, name):
        return os.path.join(self.icons_dir, name)

    def __set_properties(self):
        # begin wxGlade: MainWindow.__set_properties
        self.SetTitle("FileRock")
        self.SetBackgroundColour(wx.SystemSettings_GetColour(wx.SYS_COLOUR_WINDOW))
        self.folder_bitmap_button.SetSize(self.folder_bitmap_button.GetBestSize())
        self.status_bitmap_button.SetSize(self.status_bitmap_button.GetBestSize())
        self.activity_bitmap_button.SetSize(self.activity_bitmap_button.GetBestSize())
        self.preferences_bitmap_button.SetSize(self.preferences_bitmap_button.GetBestSize())
        self.start_stop_bitmap_button.SetSize(self.start_stop_bitmap_button.GetBestSize())
        #self.logs_bitmap_button.SetSize(self.logs_bitmap_button.GetBestSize())
        # end wxGlade

    def __do_layout(self):
        # begin wxGlade: MainWindow.__do_layout
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_3 = wx.StaticBoxSizer(self.sizer_3_staticbox, wx.VERTICAL)
        sizer_3_copy = wx.FlexGridSizer(1, 3, 0, 7)
        sizer_4 = wx.BoxSizer(wx.HORIZONTAL)
        sizer_2 = wx.BoxSizer(wx.VERTICAL)

        #grid_sizer_4 = wx.GridSizer(1, 6, 0, 10)
        grid_sizer_4 = wx.GridSizer(1, 5, 0, 10)

        #sizer_10 = wx.BoxSizer(wx.VERTICAL)  # this is the "Logs" button to be removed
        sizer_11 = wx.BoxSizer(wx.VERTICAL)
        sizer_9 = wx.BoxSizer(wx.VERTICAL)
        sizer_7 = wx.BoxSizer(wx.VERTICAL)
        sizer_6 = wx.BoxSizer(wx.VERTICAL)
        sizer_12 = wx.BoxSizer(wx.VERTICAL)
        sizer_12.Add(self.folder_bitmap_button, 0, wx.ALIGN_CENTER_HORIZONTAL, 0)
        sizer_12.Add(self.folder_label, 0, wx.TOP|wx.BOTTOM|wx.ALIGN_CENTER_HORIZONTAL, 5)
        grid_sizer_4.Add(sizer_12, 0, wx.EXPAND, 5)
        sizer_6.Add(self.status_bitmap_button, 0, wx.ALIGN_CENTER_HORIZONTAL, 0)
        sizer_6.Add(self.status_label, 0, wx.TOP|wx.BOTTOM|wx.ALIGN_CENTER_HORIZONTAL, 5)
        grid_sizer_4.Add(sizer_6, 0, wx.EXPAND, 5)
        sizer_7.Add(self.activity_bitmap_button, 0, wx.ALIGN_CENTER_HORIZONTAL, 0)
        sizer_7.Add(self.activity_label, 0, wx.TOP|wx.BOTTOM|wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 5)
        grid_sizer_4.Add(sizer_7, 0, wx.EXPAND, 0)
        sizer_9.Add(self.preferences_bitmap_button, 0, wx.ALIGN_CENTER_HORIZONTAL, 0)
        sizer_9.Add(self.preferences_label, 0, wx.TOP|wx.BOTTOM|wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 5)
        grid_sizer_4.Add(sizer_9, 0, wx.EXPAND, 0)
        sizer_11.Add(self.start_stop_bitmap_button, 0, wx.ALIGN_CENTER_HORIZONTAL, 0)
        sizer_11.Add(self.start_stop_label, 0, wx.TOP|wx.BOTTOM|wx.ALIGN_CENTER_HORIZONTAL, 5)
        grid_sizer_4.Add(sizer_11, 0, wx.EXPAND, 5)
        
        #sizer_10.Add(self.logs_bitmap_button, 0, wx.ALIGN_CENTER_HORIZONTAL, 0)
        #sizer_10.Add(self.logs_label, 0, wx.TOP|wx.BOTTOM|wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 5)
        #grid_sizer_4.Add(sizer_10, 0, wx.EXPAND, 0)

        sizer_2.Add(grid_sizer_4, 0, wx.LEFT|wx.RIGHT|wx.TOP|wx.ALIGN_CENTER_HORIZONTAL, 15)
        sizer_1.Add(sizer_2, 1, wx.LEFT|wx.RIGHT|wx.EXPAND, 10)
        sizer_3_copy.Add(self.space_ctrl, 0, wx.ALIGN_CENTER_VERTICAL, 0)
        sizer_4.Add(self.used_space_bar, 1, wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 3)
        sizer_3_copy.Add(sizer_4, 1, wx.EXPAND, 0)
        sizer_3_copy.Add(self.get_more_space_button, 0, 0, 5)
        sizer_3_copy.AddGrowableCol(1)
        sizer_3.Add(sizer_3_copy, 0, wx.LEFT|wx.RIGHT|wx.EXPAND, 5)
        sizer_1.Add(sizer_3, 0, wx.ALL|wx.EXPAND, 10)
        self.SetSizer(sizer_1)
        sizer_1.Fit(self)
        self.Layout()
        self.Centre()
        # end wxGlade
        self.sizer_2 = sizer_2

    def OnStatusClick(self, event): # wxGlade: MainWindow.<event_handler>
        print "Event handler `OnStatusClick' not implemented"
        event.Skip()

    def OnActivityClick(self, event): # wxGlade: MainWindow.<event_handler>
        print "Event handler `OnActivityClick' not implemented"
        event.Skip()

    def OnPreferencesClick(self, event): # wxGlade: MainWindow.<event_handler>
        print "Event handler `OnPreferencesClick' not implemented"
        event.Skip()

    def OnLogsClick(self, event): # wxGlade: MainWindow.<event_handler>
        print "Event handler `OnLogsClick' not implemented"
        event.Skip()

    def OnGetMoreSpace(self, event): # wxGlade: MainWindow.<event_handler>
        print "Event handler `OnGetMoreSpace' not implemented"
        event.Skip()

    def OnStartStop(self, event): # wxGlade: MainWindow.<event_handler>
        print "Event handler `OnStartStop' not implemented"
        event.Skip()

    def OnFileRockFolder(self, event): # wxGlade: MainWindow.<event_handler>
        print "Event handler `OnFileRockFolder' not implemented"
        event.Skip()

# end of class MainWindow



########NEW FILE########
__FILENAME__ = MyMessageDialog
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the MyMessageDialog module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

# generated by wxGlade 0.6.3 on Tue Jul 10 17:07:14 2012

import wx
import os

from filerockclient.ui.wxGui.Utils import _img
from filerockclient.ui.wxGui.constants import IMAGE_PATH

# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade

class MyMessageDialog(wx.Dialog):
    def __init__(self, *args, **kwds):
        # begin wxGlade: MyMessageDialog.__init__
        kwds["style"] = wx.DEFAULT_DIALOG_STYLE
        wx.Dialog.__init__(self, *args, **kwds)
#        self.bitmap_1 = wx.EmptyBitmap(1,1)
        self.message_label = wx.StaticText(self,
                                           -1,
                                           "Standard Message Dialog Message")

        # end wxGlade
        self.bitmap_1 = wx.StaticBitmap(self,
                                        -1,
                                        _img("Warning.png"))

        self.__set_properties()
        self.__do_layout()
        self.buttonSizer=None

    def putInfos(self, message, title, style, bold=False, warning=False):
        self.SetTitle(title)
        self.message_label.SetLabel(message)
        if bold:
            staticText = self.message_label
            font = staticText.GetFont()
            font.SetWeight(wx.FONTWEIGHT_BOLD)
            staticText.SetFont(font)
        if not warning:
            self.bitmap_1.Hide()

        self.sizer_1.Add(
            self.CreateStdDialogButtonSizer(style),
            0,
            wx.ALL | wx.ALIGN_CENTER_HORIZONTAL | wx.ALIGN_CENTER_VERTICAL,
            10
        )

        self.sizer_1.Fit(self)
        self.Layout()

    def __set_properties(self):
        # begin wxGlade: MyMessageDialog.__set_properties
#        self.SetTitle("dialog_1")
        # end wxGlade
        _icon = wx.Icon(os.path.join(IMAGE_PATH, "other/FileRock.ico"), wx.BITMAP_TYPE_ICO)
        self.SetIcon(_icon)

    def __do_layout(self):
        # begin wxGlade: MyMessageDialog.__do_layout
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_2 = wx.BoxSizer(wx.HORIZONTAL)
        sizer_2.Add(self.bitmap_1, 0, wx.ALL|wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 5)
        sizer_2.Add(self.message_label, 0, wx.ALL|wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 5)
        sizer_1.Add(sizer_2, 1, wx.ALL|wx.EXPAND, 10)
        self.SetSizer(sizer_1)
        sizer_1.Fit(self)
        self.Layout()
        self.Centre()
        # end wxGlade
        self.sizer_1 = sizer_1
        self.sizer_2 = sizer_2

# end of class MyMessageDialog



########NEW FILE########
__FILENAME__ = LinkDialog
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the LinkDialog module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""
# generated by wxGlade 0.6.3 on Sun Jul  1 16:35:09 2012

import wx
import os
from filerockclient.interfaces import LinkingStatuses as LS
from filerockclient.ui.wxGui import Messages
from filerockclient.ui.wxGui.constants import IMAGE_PATH

# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade

ERROR_COLOR = wx.Colour(255, 0, 0)
SUCCESS_COLOR = wx.Colour(0, 170, 70)
MESSAGE_COLOR = wx.Colour(0, 0, 0)
LOGOTYPE = os.path.join(IMAGE_PATH, "other/FileRockLogotype.png")
HEADLINE_PLACEHOLDER = u"Please insert your FileRock credentials"


class LinkDialog(wx.Dialog):
    def __init__(self, app, *args, **kwds):
        # begin wxGlade: LinkDialog.__init__
        kwds["style"] = wx.DEFAULT_DIALOG_STYLE|wx.DIALOG_NO_PARENT
        wx.Dialog.__init__(self, *args, **kwds)
        self.bitmap_1 = wx.StaticBitmap(self,
                                        -1,
                                        wx.Bitmap(LOGOTYPE, wx.BITMAP_TYPE_PNG))
        self.headline_label = wx.StaticText(self,
                                            -1,
                                            HEADLINE_PLACEHOLDER,
                                            style=wx.ALIGN_CENTRE)
        self.username_label = wx.StaticText(self, -1, "Username:")
        self.username_ctrl = wx.TextCtrl(self, -1, "")
        self.password_label = wx.StaticText(self, -1, "Password:")
        self.password_ctrl = wx.TextCtrl(self, -1, "", style=wx.TE_PASSWORD)
        self.message_label = wx.StaticText(self, -1, "")
        self.ok_button = wx.Button(self, wx.ID_OK, "")
        self.cancel_button = wx.Button(self, wx.ID_CANCEL, "")
        self.button_1 = wx.Button(self, -1, Messages.LINK_PROXY_BUTTON_LABEL)
        self.footer_label = wx.StaticText(self,
                                          -1,
                                          "Get your free account at",
                                          style=wx.ALIGN_CENTRE)
        self.footer_link = wx.HyperlinkCtrl(self,
                                            -1,
                                            "www.filerock.com",
                                            app.links["register"])

        self.__set_properties()
        self.__do_layout()

        self.Bind(wx.EVT_BUTTON, self.on_ok, self.ok_button)
        self.Bind(wx.EVT_BUTTON, self.on_cancel, self.cancel_button)
        self.Bind(wx.EVT_BUTTON, self.goto_proxySettings, self.button_1)
        # end wxGlade

        message = 'self.footer link should be wx.HyperlinkCtrl(self, \
                    -1, "www.filerock.com", app.links["register"])'
        assert self.footer_link.__class__.__name__ == 'HyperlinkCtrl', message

        self.username_label.SetLabel(Messages.LINK_USERNAME_LABEL)
        self.password_label.SetLabel(Messages.LINK_PASSWORD_LABEL)
        self.headline_label.SetLabel(Messages.LINK_HEADLINE_LABEL)
        self.footer_label.SetLabel(Messages.LINK_FOOTER_LABEL)
        self.Bind(wx.EVT_CLOSE, self.on_close)

        self.timer = wx.Timer(None)
        self.timer.Bind(wx.EVT_TIMER, self.on_close)

        font = self.message_label.GetFont()
        font.SetWeight(wx.FONTWEIGHT_BOLD)
        self.message_label.SetFont(font)

        self.messages = {
                     LS.SUCCESS: Messages.LINK_SUCCESS,
                     LS.GENERATING_RSA_KEY: Messages.LINK_GENERATING_RSA_KEY,
                     LS.SERVER_UNREACHABLE: Messages.LINK_SERVER_UNREACHABLE,
                     LS.SENDING: Messages.LINK_SENDING,
                     LS.SERVER_ERROR: Messages.LINK_SERVER_ERROR,
                     LS.WRONG_CREDENTIALS: Messages.LINK_WRONG_CREDENTIALS,
                     LS.MALFORMED_USERNAME: Messages.LINK_MALFORMED_USERNAME,
                     LS.LINKING_FAILED: Messages.LINK_LINKING_FAILED,
                     LS.UNKNOW_ERROR: Messages.LINK_UNKNOW_ERROR
                }
        self.message_color = {
                     LS.SUCCESS: SUCCESS_COLOR,
                     LS.SERVER_UNREACHABLE: ERROR_COLOR,
                     LS.GENERATING_RSA_KEY: MESSAGE_COLOR,
                     LS.SENDING: MESSAGE_COLOR,
                     LS.SERVER_ERROR: ERROR_COLOR,
                     LS.WRONG_CREDENTIALS: ERROR_COLOR,
                     LS.MALFORMED_USERNAME: ERROR_COLOR,
                     LS.LINKING_FAILED: ERROR_COLOR,
                     LS.UNKNOW_ERROR: ERROR_COLOR
                }

        self.user_provided_input = {}
        self.user_provided_input['provided'] = False
        self.synchronization = None
        self.status = -1
        self.app = app

    def __set_properties(self):
        # begin wxGlade: LinkDialog.__set_properties
        self.SetTitle(Messages.LINK_TITLE)
        _icon = wx.EmptyIcon()
        pathname = os.path.join(IMAGE_PATH, "other/FileRock.ico")
        _icon.CopyFromBitmap(wx.Bitmap(pathname, wx.BITMAP_TYPE_ANY))
        self.SetIcon(_icon)
        self.username_ctrl.SetMinSize((200, 23))
        self.username_ctrl.SetFocus()
        self.password_ctrl.SetMinSize((200, 23))
        self.ok_button.SetDefault()
        # end wxGlade
        _icon = wx.Icon(pathname, wx.BITMAP_TYPE_ICO)
        self.SetIcon(_icon)

    def __do_layout(self):
        # begin wxGlade: LinkDialog.__do_layout
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_2 = wx.BoxSizer(wx.VERTICAL)
        sizer_3 = wx.GridSizer(2, 2, 0, 50)
        grid_sizer_1 = wx.FlexGridSizer(3, 1, 6, 0)
        sizer_5 = wx.BoxSizer(wx.VERTICAL)
        sizer_4 = wx.BoxSizer(wx.VERTICAL)
        sizer_1.Add(self.bitmap_1, 0, wx.LEFT|wx.RIGHT|wx.TOP|wx.ALIGN_CENTER_HORIZONTAL, 15)
        sizer_1.Add(self.headline_label, 0, wx.ALL|wx.ALIGN_CENTER_HORIZONTAL, 10)
        sizer_4.Add(self.username_label, 0, wx.BOTTOM, 2)
        sizer_4.Add(self.username_ctrl, 0, 0, 0)
        grid_sizer_1.Add(sizer_4, 0, wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 0)
        sizer_5.Add(self.password_label, 0, wx.BOTTOM, 2)
        sizer_5.Add(self.password_ctrl, 0, 0, 0)
        grid_sizer_1.Add(sizer_5, 1, wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 0)
        grid_sizer_1.Add(self.message_label, 0, wx.ALIGN_CENTER_HORIZONTAL, 0)
        sizer_1.Add(grid_sizer_1, 0, wx.LEFT|wx.RIGHT|wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 19)
        sizer_3.Add(self.ok_button, 0, 0, 0)
        sizer_3.Add(self.cancel_button, 0, 0, 0)
        sizer_2.Add(sizer_3, 0, wx.BOTTOM|wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 10)
        sizer_2.Add(self.button_1, 0, wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 6)
        sizer_1.Add(sizer_2, 1, wx.ALL|wx.ALIGN_CENTER_HORIZONTAL, 10)
        sizer_1.Add(self.footer_label, 0, wx.ALIGN_CENTER_HORIZONTAL, 10)
        sizer_1.Add(self.footer_link, 0, wx.BOTTOM|wx.ALIGN_CENTER_HORIZONTAL, 10)
        self.SetSizer(sizer_1)
        sizer_1.Fit(self)
        self.Layout()
        self.Centre()
        # end wxGlade


    def on_ok(self, event):  # wxGlade: LinkDialog.<event_handler>
        if self.status == LS.SUCCESS:
            self.Close()
        else:
            username = self.username_ctrl.GetValue()
            password = self.password_ctrl.GetValue()
            if username is not None and password is not None:
                self.user_provided_input['provided'] = True
                self.user_provided_input['username'] = username
                # notify the caller that user input is ready to be read
                self.user_provided_input['password'] = password
            else:
                self.user_provided_input['provided'] = False
            self.try_syncronize()
        self.ok_button.Disable()
        self.cancel_button.Disable()

    def on_cancel(self, event):  # wxGlade: LinkDialog.<event_handler>
        self.user_provided_input['provided'] = False
        self.Close()

    def goto_proxySettings(self, event): # wxGlade: LinkDialog.<event_handler>
        self.app.OnOptions(event)

# end of class LinkDialog

    def setUserProvidedInputMap(self, upi):
        # a map, keys 'username' and 'password' should
        # be properly when user says ok.
        self.user_provided_input = upi
        self.user_provided_input['provided'] = False
        if 'username' in upi and len(upi['username'].strip()) > 0:
            self.username_ctrl.SetValue(upi['username'])
            self.password_ctrl.SetFocus()

    def setSync(self, threadingEvent):
        # this is an threading.Event object used to notify the caller
        # that credentials are ready to be read
        self.synchronization = threadingEvent

    def initialize(self):
        self.username_ctrl.SetValue('')
        self.password_ctrl.SetValue('')
        self.message_label.SetLabel('')
        self.status = -1

    def try_syncronize(self):
        if self.synchronization:
            self.synchronization.set()
            self.synchronization = None

    def on_close(self, event):
        self.timer.Stop()
        self.try_syncronize()
        self.Hide()

    def change_status(self, event):
        if event.code >= len(self.messages):
            self.message_label.SetForegroundColour(wx.Color(255, 0, 0))
            self.message_label.SetLabel(self.messages[len(self.messages) - 1])
        else:
            self.message_label.SetForegroundColour(self.message_color[
                                                                event.code]
                                                   )
            self.message_label.SetLabel(self.messages[event.code])

        self.Layout()
        self.status = event.code
        if self.status != LS.SENDING and self.status != LS.SUCCESS:
            self.ok_button.Enable()
            self.cancel_button.Enable()
        if self.status == LS.SUCCESS:
            self.timer.Start(2000)
########NEW FILE########
__FILENAME__ = ListDialog
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the ListDialog module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

# generated by wxGlade 0.6.3 on Fri Jul 27 16:05:41 2012

import wx
import os
import logging

from filerockclient.ui.wxGui.constants import IMAGE_PATH

# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade

class ListDialog(wx.Dialog):
    def __init__(self, parent, app, msg, title, list, *args, **kwds):
        # begin wxGlade: ListDialog.__init__
        kwds["style"] = wx.DEFAULT_DIALOG_STYLE|wx.RESIZE_BORDER|wx.MAXIMIZE_BOX|wx.THICK_FRAME
        wx.Dialog.__init__(self, parent, *args, **kwds)
        pathname = os.path.join(IMAGE_PATH, "GUI-icons/stop-64.png")
        self.bitmap_1 = wx.StaticBitmap(self, -1, wx.Bitmap(pathname, wx.BITMAP_TYPE_PNG))
        self.message_label = wx.StaticText(self, -1, "Basis Mismatch")
        self.list_ctrl = wx.TextCtrl(self, -1, "", style=wx.TE_MULTILINE|wx.TE_READONLY)

        self.__set_properties()
        self.__do_layout()
        # end wxGlade
        self.app = app
        self.logger = logging.getLogger("FR.Gui"+self.__class__.__name__)
        self.message_label.SetLabel(msg)
        font = self.message_label.GetFont()
        font.SetWeight(wx.FONTWEIGHT_BOLD)
        self.message_label.SetFont(font)

        self.sizer_2.Add(self.CreateStdDialogButtonSizer(wx.OK), 0, wx.ALL | wx.ALIGN_CENTER_HORIZONTAL | wx.ALIGN_CENTER_VERTICAL, 15)
        self.SetTitle(title)
        for item in list:
            self.list_ctrl.AppendText(item+'\n')
        self.Layout()

    def __set_properties(self):
        # begin wxGlade: ListDialog.__set_properties
        self.SetTitle("Sync Report")
        self.SetSize((700, 560))
        # end wxGlade

    def __do_layout(self):
        # begin wxGlade: ListDialog.__do_layout
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_2 = wx.BoxSizer(wx.VERTICAL)
        sizer_3 = wx.BoxSizer(wx.HORIZONTAL)
        grid_sizer_2 = wx.FlexGridSizer(1, 3, 0, 20)
        grid_sizer_2.Add(self.bitmap_1, 0, wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 0)
        grid_sizer_2.Add(self.message_label, 0, wx.EXPAND|wx.ALIGN_CENTER_VERTICAL, 0)
        grid_sizer_2.AddGrowableCol(1)
        sizer_1.Add(grid_sizer_2, 0, wx.ALL|wx.EXPAND, 15)
        sizer_3.Add(self.list_ctrl, 1, wx.ALL|wx.EXPAND, 10)
        sizer_2.Add(sizer_3, 1, wx.EXPAND, 0)
        sizer_1.Add(sizer_2, 1, wx.EXPAND, 0)
        self.SetSizer(sizer_1)
        self.Layout()
        self.Centre()
        # end wxGlade
        self.sizer_2 = sizer_2

# end of class ListDialog



########NEW FILE########
__FILENAME__ = MyFrame
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the MyFrame module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

# generated by wxGlade 0.6.3 on Wed Jun 27 12:27:39 2012

import wx

from wx.lib.mixins.listctrl import ListCtrlAutoWidthMixin
# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade

class MyFrame(wx.Frame):
    def __init__(self, *args, **kwds):
        # begin wxGlade: MyFrame.__init__
        kwds["style"] = wx.DEFAULT_FRAME_STYLE
        wx.Frame.__init__(self, *args, **kwds)
        self.panel_2 = wx.Panel(self, -1)
        self.sizer_4_staticbox = wx.StaticBox(self.panel_2, -1, "Activity")
        self.list_ctrl_1 = wx.ListCtrl(self.panel_2, -1, style=wx.LC_REPORT|wx.LC_ICON|wx.LC_SORT_ASCENDING|wx.SUNKEN_BORDER)

        self.__set_properties()
        self.__do_layout()
        # end wxGlade




    def __set_properties(self):
        # begin wxGlade: MyFrame.__set_properties
        self.SetTitle("frame_1")
        # end wxGlade


    def __do_layout(self):
        # begin wxGlade: MyFrame.__do_layout
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_4 = wx.StaticBoxSizer(self.sizer_4_staticbox, wx.VERTICAL)
        sizer_4.Add(self.list_ctrl_1, 1, wx.EXPAND, 0)
        self.panel_2.SetSizer(sizer_4)
        sizer_1.Add(self.panel_2, 1, wx.LEFT|wx.RIGHT|wx.EXPAND, 10)
        self.SetSizer(sizer_1)
        sizer_1.Fit(self)
        self.Layout()
        # end wxGlade

# end of class MyFrame



########NEW FILE########
__FILENAME__ = LogFrame
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the LogFrame module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

# generated by wxGlade 0.6.3 on Tue Jul 10 08:32:45 2012

import os
import wx

from filerockclient.ui.wxGui import Messages
from filerockclient.ui.wxGui.constants import IMAGE_PATH

# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade

class LogFrame(wx.Frame):
    def __init__(self, *args, **kwds):
        # begin wxGlade: LogFrame.__init__
        kwds["style"] = wx.DEFAULT_FRAME_STYLE
        wx.Frame.__init__(self, *args, **kwds)
        self.log_ctrl = wx.TextCtrl(self, -1, "", style=wx.TE_MULTILINE|wx.TE_READONLY|wx.HSCROLL)

        self.__set_properties()
        self.__do_layout()
        # end wxGlade
        self.Bind(wx.EVT_CLOSE, self.on_close)

    def on_close(self, event):
        self.Hide()

    def __set_properties(self):
        # begin wxGlade: LogFrame.__set_properties
        self.SetTitle(Messages.LOG_DIALOG_TITLE)
        _icon = wx.EmptyIcon()
        pathname = os.path.join(IMAGE_PATH, "other/FileRock.ico")
        _icon.CopyFromBitmap(wx.Bitmap(pathname, wx.BITMAP_TYPE_ICO))
        self.SetIcon(_icon)
        self.SetSize((750, 550))
        # end wxGlade
        _icon = wx.Icon(pathname, wx.BITMAP_TYPE_ICO)
        self.SetIcon(_icon)

    def __do_layout(self):
        # begin wxGlade: LogFrame.__do_layout
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_1.Add(self.log_ctrl, 1, wx.ALL|wx.EXPAND, 5)
        self.SetSizer(sizer_1)
        self.Layout()
        self.Centre()
        # end wxGlade

    def OnLogLine(self, event):
        self.log_ctrl.AppendText(event.line)


# end of class LogFrame



########NEW FILE########
__FILENAME__ = ProgressDialog
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the ProgressDialog module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx
import wx.lib.newevent

(RunEvent, EVT_RUN) = wx.lib.newevent.NewEvent()
(CancelEvent, EVT_CANCEL) = wx.lib.newevent.NewEvent()
(DoneEvent, EVT_DONE) = wx.lib.newevent.NewEvent()
(ProgressStartEvent, EVT_PROGRESS_START) = wx.lib.newevent.NewEvent()
(ProgressEvent, EVT_PROGRESS) = wx.lib.newevent.NewEvent()


class ProgressDialog(wx.Dialog):
    """ This dialog shows the progress of any ThreadedJob.

    It can be shown Modally if the main application needs to suspend
    operation, or it can be shown Modelessly for background progress
    reporting.

    app = wx.PySimpleApp()
    job = EggTimerJob(duration = 10)
    dlg = JobProgress(None, job)
    job.SetProgressMessageWindow(dlg)
    job.Start()
    dlg.ShowModal()


    """
    def __init__(self, parent, job):
        self.job = job

        wx.Dialog.__init__(self, parent, -1, "Progress", size=(350,200))

        # vertical box sizer
        sizeAll = wx.BoxSizer(wx.VERTICAL)

        # Job status text
        self.JobStatusText = wx.StaticText(self, -1, "Starting...")
        sizeAll.Add(self.JobStatusText, 0, wx.EXPAND|wx.ALL, 8)

        # wxGague
        self.ProgressBar = wx.Gauge(self, -1, 10, wx.DefaultPosition, (250, 15))
        sizeAll.Add(self.ProgressBar, 0, wx.EXPAND|wx.ALL, 8)

        # horiz box sizer, and spacer to right-justify
        sizeRemaining = wx.BoxSizer(wx.HORIZONTAL)
        sizeRemaining.Add((2,2), 1, wx.EXPAND)

        # time remaining read-only edit
        # putting wide default text gets a reasonable initial layout.
        self.remainingText = wx.StaticText(self, -1, "???:??")
        sizeRemaining.Add(self.remainingText, 0, wx.LEFT|wx.RIGHT|wx.ALIGN_CENTER_VERTICAL, 8)

        # static text: remaining
        self.remainingLabel = wx.StaticText(self, -1, "remaining")
        sizeRemaining.Add(self.remainingLabel, 0, wx.ALL|wx.ALIGN_CENTER_VERTICAL, 8)

        # add that row to the mix
        sizeAll.Add(sizeRemaining, 1, wx.EXPAND)

        # horiz box sizer & spacer
        sizeButtons = wx.BoxSizer(wx.HORIZONTAL)
        sizeButtons.Add((2,2), 1, wx.EXPAND|wx.ADJUST_MINSIZE)

        # Pause Button
        #self.PauseButton = wx.Button(self, -1, "Pause")
        #sizeButtons.Add(self.PauseButton, 0, wx.ALL, 4)
        #self.Bind(wx.EVT_BUTTON, self.OnPauseButton, self.PauseButton)

        # Cancel button
        self.CancelButton = wx.Button(self, wx.ID_CANCEL, "Cancel")
        sizeButtons.Add(self.CancelButton, 0, wx.ALL, 4)
        self.Bind(wx.EVT_BUTTON, self.OnCancel, self.CancelButton)

        # Add all the buttons on the bottom row to the dialog
        sizeAll.Add(sizeButtons, 0, wx.EXPAND|wx.ALL, 4)

        self.SetSizer(sizeAll)
        #sizeAll.Fit(self)
        sizeAll.SetSizeHints(self)

        # jobs tell us how they are doing
        self.Bind(EVT_PROGRESS_START, self.OnProgressStart)
        self.Bind(EVT_PROGRESS, self.OnProgress)
        self.Bind(EVT_DONE, self.OnDone)

        self.Layout()
    #

    def OnPauseButton(self, event):
        if self.job.isPaused:
            self.job.Continue()
            self.PauseButton.SetLabel("Pause")
            self.Layout()
        else:
            self.job.Pause()
            self.PauseButton.SetLabel("Resume")
            self.Layout()
        #
    #

    def OnCancel(self, event):
        #self.job.Stop()
        self.Hide()
    #

    def OnProgressStart(self, event):
        self.ProgressBar.SetRange(event.total)
        self.statusUpdateTime = time.clock()
    #

    def OnProgress(self, event):
        # update the progress bar
        self.ProgressBar.SetValue(event.count)

        self.remainingText.SetLabel(self.job.TimeRemaining())

        # update the text a max of 20 times a second
        if time.clock() - self.statusUpdateTime > 0.05:
            self.JobStatusText.SetLabel(str(self.job))
            self.statusUpdateTime = time.clock()
            self.Layout()
        #
    #

    # when a job is done
    def OnDone(self, event):
        self.ProgressBar.SetValue(0)
        self.JobStatusText.SetLabel("Finished")
        self.Destroy()
    #
#

########NEW FILE########
__FILENAME__ = ProxyDialog
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Proxy Dialog module

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx


# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

import os

from filerockclient.ui.wxGui import Messages
from filerockclient.ui.wxGui.constants import IMAGE_PATH


ENABLED = True
DISABLED = False

PROXY_LABELS = [
                'SOCKS4',
                'SOCKS5',
                'HTTP/HTTPS'
               ]

PROXY_LABEL_TO_VALUES = {
                         PROXY_LABELS[0]: 'SOCKS4',
                         PROXY_LABELS[1]: 'SOCKS5',
                         PROXY_LABELS[2]: 'HTTP'
                        }

PROXY_VALUE_TO_LABEL = {
                         'SOCKS4': PROXY_LABELS[0],
                         'SOCKS5': PROXY_LABELS[1],
                         'HTTP': PROXY_LABELS[2]
                        }



class SpinCtrl(wx.SpinCtrl):
    def __init__(self, *args, **kwds):
        super(SpinCtrl, self).__init__(*args, **kwds)
        self.default_value = 0
        self.Bind(wx.EVT_KILL_FOCUS, self.updateValue)
    
    def SetValue(self, value):
        int_value = 0
        try:
            int_value=int(value)
        except:
            pass
        return super(SpinCtrl, self).SetValue(int_value)
    
    def GetValue(self):
        str_value = '0'
        try:
            str_value = str(super(SpinCtrl, self).GetValue())
        except:
            pass
        return str_value
    
    def updateValue(self, env):
        try:
            value_to_set = int(self.GetValue())
        except:
            value_to_set = 1
        self.SetValue(value_to_set)
            

class CtrlText(wx.TextCtrl):

    def __init__(self, *args, **kwds):
        super(CtrlText, self).__init__(*args, **kwds)
        self.default_value = ""
        self.Bind(wx.EVT_KEY_UP, self.onKeyUp)

    def onKeyUp(self, evt):
        if evt.GetKeyCode() == wx.WXK_ESCAPE:
            self.SetValue(self.default_value)


class DirPickerCtrl(wx.DirPickerCtrl):
    def __init__(self, *args, **kwds):
        super(DirPickerCtrl, self).__init__(*args, **kwds)
        self.default_value = ""
        self.Bind(wx.EVT_KEY_UP, self.onKeyUp)

    def GetValue(self):
        return self.GetPath()

    def SetValue(self, value):
        return self.SetPath(value)

    def onKeyUp(self, evt):
        if evt.GetKeyCode() == wx.WXK_ESCAPE:
            self.SetValue(self.default_value)


class CheckBox(wx.CheckBox):
    def __init__(self, value, *args, **kwds):
        super(CheckBox, self).__init__(*args, **kwds)
        self.default_value = ""
        self.SetValue(value)

    def GetValue(self):
        if super(CheckBox, self).GetValue():
            return u"True"
        else:
            return u"False"

    def SetValue(self, value):
        if value == u"True":
            super(CheckBox, self).SetValue(True)
        else:
            super(CheckBox, self).SetValue(False)

class ReplicaComboBox(wx.ComboBox):
    def __init__(self, *args, **kwds):
        super(ReplicaComboBox, self).__init__(*args, **kwds)
        self.Insert(Messages.CONFIG_NOT_AVAILABLE ,0)
        self.Disable()

    def SetValue(self, value):
        if value is not None:
            return wx.ComboBox.SetValue(self, value)
        self.SetSelection(0)
        return None

class ComboBox(wx.ComboBox):
    def __init__(self, *args, **kwds):
        super(ComboBox, self).__init__(*args, **kwds)
        self.default_value = ""

    def GetValue(self, *args, **kwargs):
        return PROXY_LABEL_TO_VALUES[super(ComboBox, self).GetValue(*args, **kwargs)]

    def SetValue(self, value):
        if value in PROXY_VALUE_TO_LABEL.keys():
            return super(ComboBox, self).SetValue(PROXY_VALUE_TO_LABEL[value])

UserDefinedOptions = "User Defined Options"

WIDGETS = {
    UserDefinedOptions: {
        'proxy_type': lambda parent, val: ComboBox(parent,
                                                   -1,
                                                   val,
                                                   choices=PROXY_LABELS,
                                                   style=wx.CB_READONLY
                                                   ),
        'proxy_host': lambda parent, val: CtrlText(parent, -1, val),
        'proxy_port': lambda parent, val: SpinCtrl(parent,
                                                   -1,
                                                   val,
                                                   style=wx.SP_HORIZONTAL,
                                                   min=0,
                                                   max=655360),
        'proxy_rdns': lambda parent, val: CheckBox(val, parent),
        'proxy_username': lambda parent, val: CtrlText(parent, -1, val),
        'proxy_password': lambda parent, val: CtrlText(parent, -1, val)
    }
}
# end wxGlade

class ProxyDialog(wx.Dialog):
    def __init__(self, *args, **kwds):
        # begin wxGlade: ProxyDialog.__init__
        kwds["style"] = wx.DEFAULT_DIALOG_STYLE|wx.MINIMIZE_BOX
        wx.Dialog.__init__(self, *args, **kwds)
        self.button_ok = wx.Button(self, wx.ID_OK, "")

        self.__set_properties()
        self.__do_layout()
        # end wxGlade

    def __set_properties(self):
        # begin wxGlade: ProxyDialog.__set_properties
        self.SetTitle("Proxy Settings")
        # end wxGlade
        pathname = os.path.join(IMAGE_PATH, 'other/FileRock.ico')
        _icon = wx.Icon(pathname, wx.BITMAP_TYPE_ICO)
        self.SetIcon(_icon)

    def __do_layout(self):
        # begin wxGlade: ProxyDialog.__do_layout
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_2 = wx.BoxSizer(wx.VERTICAL)
        sizer_2.Add(self.button_ok, 0, wx.TOP|wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 5)
        sizer_1.Add(sizer_2, 1, wx.ALL|wx.EXPAND, 5)
        self.SetSizer(sizer_1)
        sizer_1.Fit(self)
        self.Layout()
        self.Centre()
        # end wxGlade
        self.container = sizer_2
        self.init_config()
# end of class ProxyDialog

    def init_config(self):
        self.sections_grid = {}
        self.sections_panel = {}
        self.options = {}
        self.labels = {
                       'proxy_type': u'Proxy type',
                       'proxy_host': u'Host',
                       'proxy_port': u'Port',
                       'proxy_rdns': u'Resolve DNS',
                       'proxy_username': u'Username',
                       'proxy_password': u'Password'
        }

        self.tooltips = {
                        'proxy_type': u'Proxy type',
                        'proxy_host': u'Host',
                        'proxy_port': u'Port',
                        'proxy_rdns': u'Resolve DNS',
                        'proxy_username': u'Username',
                        'proxy_password': u'Password'
        }


        self.visible_keys = {UserDefinedOptions: ['proxy_type',
                                                  'proxy_host',
                                                  'proxy_port',
                                                  'proxy_rdns',
                                                  'proxy_username',
                                                  'proxy_password'
                                                 ]}


        self.key_order = [(UserDefinedOptions, 'proxy_type'),
                          (UserDefinedOptions, 'proxy_host'),
                          (UserDefinedOptions, 'proxy_port'),
                          (UserDefinedOptions, 'proxy_rdns'),
                          (UserDefinedOptions, 'proxy_username'),
                          (UserDefinedOptions, 'proxy_password')
                         ]

        self.add_section('Configuration')

    def add_section(self, label):
        self.container.Insert(0,self.create_panel(label), 1, wx.ALL | wx.EXPAND, 0)

    def create_panel(self, label):
        panel = wx.Panel(self, -1, style=wx.TAB_TRAVERSAL)
        sizer_21 = wx.BoxSizer(wx.HORIZONTAL)
        grid_sizer = wx.FlexGridSizer(6, 2, 5, 20)
        grid_sizer.AddGrowableCol(1)
        sizer_21.Add(grid_sizer, 1, wx.ALL | wx.VERTICAL, 4)
        panel.SetSizer(sizer_21)
        self.sections_grid[label] = grid_sizer
        self.sections_panel[label] = panel
        return panel

    def updateConfig(self, cfg):
        self.cfg = cfg
        for section, option in self.key_order:
            if section in self.visible_keys.keys() \
            and option in self.visible_keys[section]\
            and section in self.cfg\
            and option in self.cfg[section]:
                if section not in self.options:
                    self.options[section] = {}
#                    self.add_section(Messages.PANEL3_USER_SECTION_TITLE)
                if section != 'NOCFG':
                    value = self.cfg[section][option]
                else:
                    value = None
                self.insertupdate_setting(section, option, value)
        self.Fit()
        size = self.GetMinSize()
        size[1]=-1
        self.SetMaxSize(size)

    def collectValues(self, onlyifnew=False):
        cfg = {}
        somethingsnew = False
        for section in self.options:
            cfg[section] = {}
            for option in self.options[section]:
                value = self.options[section][option].GetValue()
                default_value = self.options[section][option].default_value
                cfg[section][option] = value
                if value != default_value:
                    somethingsnew = True
        if onlyifnew and not somethingsnew:
            return {}
        else:
            return cfg

    def getConfig(self):
        cfg = self.collectValues(True)
        if 'NOCFG' in cfg:
            cfg.pop('NOCFG')
        return cfg

    def insertupdate_setting(self, section, key, value):
        if key not in self.visible_keys[section]:
            return
        if key not in self.options[section]:
            self.add_option(section, key, value)
        self.options[section][key].SetValue(value)
        self.options[section][key].default_value = value

    def insertupdate_System_setting(self, section, key, value):
#        self.system_list_ctrl.insertupdate_key_value(section, key, value)
        pass

    def insertupdate_Client_setting(self, section, key, value):
        pass

    def create_static_text(self, parent, key):
        staticText = wx.StaticText(parent, -1, self.labels[key])
        font = staticText.GetFont()
        font.SetWeight(wx.FONTWEIGHT_BOLD)
        staticText.SetFont(font)
        return staticText

    def create_ctrl_text(self, parent, label, value, path=False):
        if path:
            ctrlText = DirPickerCtrl(parent, -1, value)
        else:
            ctrlText = CtrlText(parent, -1, value)
        if label in self.tooltips:
            ctrlText.SetToolTipString(self.tooltips[label])
        return ctrlText

    def add_option(self, section, key, value, path=False, checkbox=False):
        parent = self.sections_panel['Configuration']
        grid = self.sections_grid['Configuration']
        staticText = self.create_static_text(parent, key)
        self.options[section][key] = WIDGETS[section][key](parent, value)
        if key in self.tooltips:
            self.options[section][key].SetToolTipString(self.tooltips[key])
        self.add_options_to_grid(grid, staticText, self.options[section][key])

    def add_options_to_grid(self, grid, staticText, ctrlText):
        grid.Add(staticText, 0, wx.ALIGN_LEFT | wx.ALIGN_CENTER_VERTICAL, 2)
        grid.Add(ctrlText, 0, wx.EXPAND | wx.ALIGN_CENTER_VERTICAL, 2)


########NEW FILE########
__FILENAME__ = MyFrame
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the MyFrame module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

# generated by wxGlade 0.6.3 on Fri Jun 29 16:15:13 2012

import wx

# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade

class MyFrame(wx.Frame):
    def __init__(self, *args, **kwds):
        # begin wxGlade: MyFrame.__init__
        kwds["style"] = wx.DEFAULT_FRAME_STYLE
        wx.Frame.__init__(self, *args, **kwds)
        self.panel_1 = wx.Panel(self, -1)
        self.bitmap_1 = wx.StaticBitmap(self.panel_1, -1, wx.Bitmap("./images/black.png", wx.BITMAP_TYPE_PNG))

        self.__set_properties()
        self.__do_layout()
        # end wxGlade

    def __set_properties(self):
        # begin wxGlade: MyFrame.__set_properties
        self.SetTitle("frame_1")
        # end wxGlade

    def __do_layout(self):
        # begin wxGlade: MyFrame.__do_layout
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_2 = wx.BoxSizer(wx.VERTICAL)
        sizer_2.Add(self.bitmap_1, 0, 0, 0)
        self.panel_1.SetSizer(sizer_2)
        sizer_1.Add(self.panel_1, 1, wx.EXPAND, 0)
        self.SetSizer(sizer_1)
        sizer_1.Fit(self)
        self.Layout()
        # end wxGlade

# end of class MyFrame



########NEW FILE########
__FILENAME__ = panels
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the panels module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx

class Slider(wx.Panel):
    def __init__(self, parent, *args, **kwds):
        self.parent = parent
        wx.Panel.__init__(self, parent, *args, **kwds)
#        self.SetMinSize((600, 367))
        self.isTimeToStopFunction = None
        self.changeSizeFunction=None
        self.slideTimer = wx.Timer(None)
        self.slideTimer.Bind(wx.EVT_TIMER, self.slide)

    def OnSlideInStopTimer(self):
        if self.GetSize().GetWidth()>=600:
            self.slideTimer.Stop()
            self.Refresh()
            return True
        return False

    def OnSlideOutStopTimer(self):
        if self.GetSize().GetWidth()<=0:
            self.slideTimer.Stop()
            self.Refresh()
            return True
        return False

    def OnSlideOut(self):
        size = self.GetSize()
        if size.GetWidth()>0:
            size.DecBy(30,0)
            self.SetSize(size)
            for child in self.GetChildren():
                child.SetSize(size)

    def OnSlideIn(self):
        size = self.GetSize()
        if size.GetWidth()<=600:
            size.IncBy(30,0)
            self.SetSize(size)
            for child in self.GetChildren():
                child.SetSize(size)

    def slide(self, evt):
        if not self.isTimeToStopFunction():
            self.changeSizeFunction()
        self.parent.Layout()
#        self.Update()

    def slideOut(self):
        self.slideTimer.Stop()
        self.isTimeToStopFunction=self.OnSlideOutStopTimer
        self.changeSizeFunction=self.OnSlideOut
        self.slideTimer.Start(2)

    def slideIn(self):
        self.slideTimer.Stop()
        self.isTimeToStopFunction=self.OnSlideInStopTimer
        self.changeSizeFunction=self.OnSlideIn
        self.slideTimer.Start(2)

class PanelTemplate(Slider):
    def __init__(self, parent, imageFile,*args, **kwds):
        Slider.__init__(self, parent, *args, **kwds)
        self.bitmap_1 = wx.StaticBitmap(self, -1, wx.Bitmap(imageFile, wx.BITMAP_TYPE_PNG))

        self.__set_properties()
        self.__do_layout()

    def __set_properties(self):
        pass

    def __do_layout(self):
        sizer_2 = wx.BoxSizer(wx.VERTICAL)
        sizer_2.Add(self.bitmap_1, 0, 0, 0)
        self.Layout()



class PanelMaker(object):
    def __init__(self, parent, images):
        self.parent=parent
        self.images=images

    def create_panels(self):
        panels=[]
        for image in self.images:
            panels.append(PanelTemplate(self.parent, image))
        return panels


########NEW FILE########
__FILENAME__ = SliderDialog
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the SliderDialog module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

# generated by wxGlade 0.6.3 on Wed Jul 11 19:13:21 2012

import os
import wx
import sys
from Panels import panels

from filerockclient.ui.wxGui import Messages
from filerockclient.ui.wxGui.constants import IMAGE_PATH

# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade

class SliderDialog(wx.Dialog):
    def __init__(self, *args, **kwds):
        # begin wxGlade: SliderDialog.__init__
        kwds["style"] = wx.DEFAULT_DIALOG_STYLE
        wx.Dialog.__init__(self, *args, **kwds)
        self.panel_1 = wx.Panel(self, -1)
        self.panel_2 = wx.Panel(self.panel_1, -1)
        self.checkbox_1 = wx.CheckBox(self.panel_1, -1, "Show welcome at startup")
        self.checkbox_3 = wx.CheckBox(self.panel_1, -1, "")
        self.back_button = wx.Button(self.panel_1, wx.ID_BACKWARD, "")
        self.skip_button = wx.Button(self.panel_1, wx.ID_OK, "")
        self.forward_button = wx.Button(self.panel_1, wx.ID_FORWARD, "")
        self.go_button = wx.Button(self.panel_1, wx.ID_OK, "")

        self.__set_properties()
        self.__do_layout()

        self.Bind(wx.EVT_BUTTON, self.OnBack, self.back_button)
#        self.Bind(wx.EVT_BUTTON, self.OnSkip, self.skip_button)
        self.Bind(wx.EVT_BUTTON, self.OnForward, self.forward_button)
        # end wxGlade

        self.checkbox_1.SetLabel(Messages.SLIDER_SHOW_ON_EVERY_STARTUP)
        self.active_panel = 0
        self.skip_button.SetLabel(Messages.SLIDER_DIALOG_SKIP)
        self.forward_button.SetLabel(Messages.SLIDER_DIALOG_NEXT)
        self.back_button.SetLabel(Messages.SLIDER_DIALOG_PREV)
        self.back_button.Disable()

    def __set_properties(self):
        # begin wxGlade: SliderDialog.__set_properties
        self.SetTitle(Messages.SLIDER_DIALOG_TITLE)
        _icon = wx.EmptyIcon()
        pathname = os.path.join(IMAGE_PATH, "other/FileRock.ico")
        _icon.CopyFromBitmap(wx.Bitmap(pathname, wx.BITMAP_TYPE_ICO))
        self.SetIcon(_icon)
        self.panel_2.SetMinSize((600, 400))
        self.checkbox_3.Hide()
        self.forward_button.SetDefault()
        self.go_button.Hide()
        # end wxGlade
        _icon = wx.Icon(pathname, wx.BITMAP_TYPE_ICO)
        self.SetIcon(_icon)

    def __do_layout(self):
        FORCE_WIN = False
        FORCE_OSX = False
        if sys.platform.startswith('win') or FORCE_WIN:
            folder = os.path.join(IMAGE_PATH, "slides")
        elif sys.platform.startswith('darwin') or FORCE_OSX:
            folder = os.path.join(IMAGE_PATH, "slides_osx")
        else:
            folder = os.path.join(IMAGE_PATH, "slides")
        images = map(lambda filename: os.path.join(folder, filename), [
                                                    "FileRock - Intro.001.png",
                                                    "FileRock - Intro.002.png",
                                                    "FileRock - Intro.003.png",
                                                    "FileRock - Intro.004.png",
                                                    "FileRock - Intro.005.png",
                                                    "FileRock - Intro.006.png",
                                                    "FileRock - Intro.007.png",
                                                    "FileRock - Intro.008.png",
                                                    "FileRock - Intro.009.png",
                                                    "FileRock - Intro.010.png",
                                                    "FileRock - Intro.011.png",
                                                    "FileRock - Intro.012.png"])
        maker = panels.PanelMaker(self.panel_2, images)
        self.panels = maker.create_panels()
        sizer_13 = wx.BoxSizer(wx.HORIZONTAL)
        for panel in self.panels:
            sizer_13.Add(panel, 0, wx.EXPAND)
        # begin wxGlade: SliderDialog.__do_layout
        sizer_10 = wx.BoxSizer(wx.VERTICAL)
        sizer_11 = wx.BoxSizer(wx.VERTICAL)
        sizer_1 = wx.BoxSizer(wx.HORIZONTAL)
        sizer_12 = wx.FlexGridSizer(1, 4, 0, 5)
        grid_sizer_1 = wx.FlexGridSizer(1, 3, 0, 5)
#        sizer_13 = wx.BoxSizer(wx.HORIZONTAL)
        self.panel_2.SetSizer(sizer_13)
        sizer_11.Add(self.panel_2, 0, wx.EXPAND, 0)
        grid_sizer_1.Add(self.checkbox_1, 0, 0, 0)
        grid_sizer_1.Add(self.checkbox_3, 0, wx.ALIGN_CENTER_VERTICAL, 0)
        grid_sizer_1.Add((20, 20), 0, 0, 0)
        sizer_1.Add(grid_sizer_1, 1, wx.ALIGN_CENTER_VERTICAL, 0)
        sizer_12.Add(self.back_button, 0, wx.ALIGN_CENTER_VERTICAL, 0)
        sizer_12.Add(self.skip_button, 0, wx.ALIGN_CENTER_VERTICAL, 0)
        sizer_12.Add(self.forward_button, 0, wx.ALIGN_CENTER_VERTICAL, 0)
        sizer_12.Add(self.go_button, 0, 0, 0)
        sizer_1.Add(sizer_12, 0, wx.ALIGN_RIGHT, 0)
        sizer_11.Add(sizer_1, 0, wx.ALL|wx.EXPAND, 10)
        self.panel_1.SetSizer(sizer_11)
        sizer_10.Add(self.panel_1, 0, wx.EXPAND, 0)
        self.SetSizer(sizer_10)
        sizer_10.Fit(self)
        self.Layout()
        self.Centre()
        # end wxGlade
        self.sizer_12 = sizer_12


    def Reconfigure(self):
        if self.active_panel==0:
            self.back_button.Disable()
            self.forward_button.Enable()
            self.skip_button.Enable()
        elif self.active_panel==len(self.panels)-1:
            self.forward_button.Hide()
            self.go_button.Show()
            self.skip_button.Disable()
            self.back_button.Enable()
        elif self.active_panel>0 and self.active_panel<len(self.panels)-1:
            self.back_button.Enable()
            self.go_button.Hide()
            self.forward_button.Show()
            self.skip_button.Enable()
#        self.Layout()
        self.sizer_12.Layout()

    def OnBack(self, event): # wxGlade: SliderDialog.<event_handler>
        if self.active_panel > 0:
            self.active_panel-=1
            self.panels[self.active_panel].slideIn()
        self.Reconfigure()

    def OnSkip(self, event): # wxGlade: SliderDialog.<event_handler>
        while self.active_panel < len(self.panels)-1:
            self.panels[self.active_panel].slideOut()
            self.active_panel+=1
        self.Reconfigure()

    def OnForward(self, event): # wxGlade: SliderDialog.<event_handler>
        if self.active_panel < len(self.panels)-1:
            self.panels[self.active_panel].slideOut()
            self.active_panel+=1
        self.Reconfigure()


# end of class SliderDialog



########NEW FILE########
__FILENAME__ = SyncDialog
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the SyncDialog module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""
# generated by wxGlade 0.6.3 on Thu Jul  5 19:53:37 2012

import wx
import logging
import os
from threading import Thread

from filerockclient.ui.wxGui.dialogs.syncdialog.panel_2 import Panel2
from filerockclient.ui.wxGui import Utils, Messages
from filerockclient.ui.wxGui.constants import IMAGE_PATH

# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade


class SyncDialog(wx.Dialog):

    def __init__(self, app, *args, **kwds):
        # begin wxGlade: SyncDialog.__init__
        kwds["style"] = wx.DEFAULT_DIALOG_STYLE|wx.RESIZE_BORDER|wx.MAXIMIZE_BOX|wx.THICK_FRAME
        wx.Dialog.__init__(self, *args, **kwds)
        self.bitmap_1 = wx.StaticBitmap(self, -1, wx.Bitmap(os.path.join(IMAGE_PATH, "GUI-icons/stop-64.png"), wx.BITMAP_TYPE_PNG))
        self.message_label = wx.StaticText(self, -1, "Basis Mismatch")
        self.bitmap_button_1 = wx.BitmapButton(self, -1, wx.Bitmap(os.path.join(IMAGE_PATH, "GUI-icons/question.png"), wx.BITMAP_TYPE_PNG), style=wx.NO_BORDER)
        self.robohash_from_bitmap = wx.StaticBitmap(self, -1, wx.Bitmap(os.path.join(IMAGE_PATH, "other/noconnection_robot_100x100.png"), wx.BITMAP_TYPE_PNG))
        self.bitmap_4 = wx.StaticBitmap(self, -1, wx.Bitmap(os.path.join(IMAGE_PATH, "GUI-icons/change-to.png"), wx.BITMAP_TYPE_PNG))
        self.robohash_to_bitmap = wx.StaticBitmap(self, -1, wx.Bitmap(os.path.join(IMAGE_PATH, "other/noconnection_robot_100x100.png"), wx.BITMAP_TYPE_PNG))

        self.__set_properties()
        self.__do_layout()

        self.Bind(wx.EVT_BUTTON, self.OnHelp, self.bitmap_button_1)
        # end wxGlade
        self.app = app
        self.logger = logging.getLogger("FR.Gui" + self.__class__.__name__)
        self.UNKNOWN_BASIS_STRING = Messages.SYNC_UNKNOWN_BASIS_STRING
        self.mismatch_message = Messages.SYNC_BASIS_MISMATCH_MESSAGE
        self.message_label.SetLabel(self.mismatch_message % {
                                     "client_hash": self.UNKNOWN_BASIS_STRING,
                                     "server_hash": self.UNKNOWN_BASIS_STRING
                                     })
        font = self.message_label.GetFont()
        font.SetWeight(wx.FONTWEIGHT_BOLD)
        self.message_label.SetFont(font)

        self.panel_2 = Panel2(self)
        self.sizer_2.Add(self.panel_2, 1, wx.LEFT|wx.RIGHT|wx.EXPAND, 10)

        self.sizer_2.Add(self.CreateStdDialogButtonSizer(wx.OK|wx.CANCEL), 0, wx.ALL | wx.ALIGN_CENTER_HORIZONTAL | wx.ALIGN_CENTER_VERTICAL, 15)
        self.Layout()

    def __set_properties(self):
        # begin wxGlade: SyncDialog.__set_properties
        self.SetTitle(Messages.SYNC_DIALOG_TITLE)
        _icon = wx.EmptyIcon()
        pathname = os.path.join(IMAGE_PATH, "other/FileRock.ico")
        _icon.CopyFromBitmap(wx.Bitmap(pathname, wx.BITMAP_TYPE_ICO))
        self.SetIcon(_icon)
        self.SetSize((700, 560))
        self.bitmap_button_1.SetToolTipString(Messages.SYNC_BASIS_MISMATCH_HELP_TOOLTIP)
        self.bitmap_button_1.SetSize(self.bitmap_button_1.GetBestSize())
        # end wxGlade
        _icon = wx.Icon(pathname, wx.BITMAP_TYPE_ICO)
        self.SetIcon(_icon)

    def __do_layout(self):
        # begin wxGlade: SyncDialog.__do_layout
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_2 = wx.BoxSizer(wx.VERTICAL)
        grid_sizer_2 = wx.FlexGridSizer(1, 3, 0, 20)
        sizer_3 = wx.BoxSizer(wx.VERTICAL)
        sizer_3_copy = wx.BoxSizer(wx.HORIZONTAL)
        grid_sizer_2.Add(self.bitmap_1, 0, wx.ALIGN_CENTER_HORIZONTAL|wx.ALIGN_CENTER_VERTICAL, 0)
        grid_sizer_2.Add(self.message_label, 0, wx.EXPAND|wx.ALIGN_CENTER_VERTICAL, 0)
        sizer_3.Add(self.bitmap_button_1, 0, wx.ALIGN_RIGHT, 0)
        sizer_3_copy.Add(self.robohash_from_bitmap, 0, 0, 0)
        sizer_3_copy.Add(self.bitmap_4, 0, wx.ALIGN_CENTER_VERTICAL, 0)
        sizer_3_copy.Add(self.robohash_to_bitmap, 0, 0, 0)
        sizer_3.Add(sizer_3_copy, 1, 0, 0)
        grid_sizer_2.Add(sizer_3, 1, wx.EXPAND, 0)
        grid_sizer_2.AddGrowableCol(1)
        sizer_1.Add(grid_sizer_2, 0, wx.ALL|wx.EXPAND, 15)
        sizer_1.Add(sizer_2, 1, wx.EXPAND, 0)
        self.SetSizer(sizer_1)
        self.Layout()
        self.Centre()
        # end wxGlade
        self.sizer_2 = sizer_2

    def OnHelp(self, event): # wxGlade: SyncDialog.<event_handler>
        self.app.OnHashMismatchHelp(event)


    def updateRobotHash(self):
        self.robohash_from_bitmap.SetBitmap(Utils.GetVHash(self.local_basis, 100, self.logger))
        self.robohash_to_bitmap.SetBitmap(Utils.GetVHash(self.server_basis, 100, self.logger))
    
    def update_information(self, client_basis, server_basis, content):
        
        local_basis = client_basis
        self.local_basis = client_basis
        self.server_basis = server_basis

        if client_basis == Utils.UNKNOWN_HASH:
            local_basis = self.UNKNOWN_BASIS_STRING

        self.message_label.SetLabel(self.mismatch_message % {
                                            'client_hash': local_basis,
                                            'server_hash': server_basis
                                   })

        updateRobots = Thread(target=self.updateRobotHash)
        updateRobots.daemon = True
        updateRobots.run()
        if len(content) == 0:
            self.panel_2.give_message(Messages.BASIS_MISMATCH_NOTHING_TO_SYNC)
            
        self.panel_2.update_content(content)

# end of class SyncDialog


########NEW FILE########
__FILENAME__ = WareboxDialog
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Warebox dialog module

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx
import os

from filerockclient.ui.wxGui import Messages
from filerockclient.ui.wxGui.constants import IMAGE_PATH


# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade


class DirPickerCtrl(wx.DirPickerCtrl):

    def __init__(self, *args, **kwds):
        super(DirPickerCtrl, self).__init__(*args, **kwds)

    def GetValue(self):
        return self.GetPath()

    def SetValue(self, value):
        return self.SetPath(value)


class WareboxDialog(wx.Dialog):

    def __init__(self, warebox_path, *args, **kwds):
        # begin wxGlade: WareboxDialog.__init__
        # end wxGlade
        kwds["style"] = wx.DEFAULT_DIALOG_STYLE | wx.RESIZE_BORDER
#        kwds["size"] = (400, 90)
        wx.Dialog.__init__(self, *args, **kwds)

        self.message_label = wx.StaticText(self,
                                           -1,
                                           Messages.WAREBOX_DIALOG_MESSAGE)
#        self.label_1 = wx.StaticText(self,
#                                     -1,
#                                     Messages.WAREBOX_DIALOG_LABEL)

        self.setFontBold(self.message_label)
#        self.setFontBold(self.label_1)

        self.warebox_ctrl = DirPickerCtrl(self,
                                          -1,
                                          "",
                                          style=wx.DIRP_USE_TEXTCTRL)
        self.buttons = self.CreateStdDialogButtonSizer(wx.OK)
        self.__set_properties()
        self.__do_layout()

    def __set_properties(self):
        # begin wxGlade: WareboxDialog.__set_properties
        self.SetTitle(Messages.WAREBOX_DIALOG_TITLE)
        _icon = wx.EmptyIcon()
        pathname = os.path.join(IMAGE_PATH, "other/FileRock.ico")
        _icon.CopyFromBitmap(wx.Bitmap(pathname, wx.BITMAP_TYPE_ANY))
        self.SetIcon(_icon)
        # end wxGlade
        _icon = wx.Icon(pathname, wx.BITMAP_TYPE_ICO)
        self.SetIcon(_icon)
        self.SetMinSize((400, -1))
        self.SetMaxSize((600, -1))

    def __do_layout(self):

        # begin wxGlade: WareboxDialog.__do_layout
        # end wxGlade
        sizer_1 = wx.BoxSizer(wx.VERTICAL)
        sizer_2 = wx.FlexGridSizer(1, 1, 0, 5)
        sizer_1.Add(self.message_label, 0, wx.ALL |
                                           wx.EXPAND |
                                           wx.ALIGN_CENTER_HORIZONTAL |
                                           wx.ALIGN_CENTER_VERTICAL, 10)
#        sizer_2.Add(self.label_1, 0, wx.ALIGN_CENTER_HORIZONTAL |
#                                     wx.ALIGN_CENTER_VERTICAL, 0)
        sizer_2.Add(self.warebox_ctrl, 1, wx.EXPAND, 0)
        sizer_2.AddGrowableCol(0)
        sizer_1.Add(sizer_2, 1, wx.RIGHT |
                                wx.LEFT |
                                wx.EXPAND, 10)
        sizer_1.Add(self.buttons, 0,
                    wx.ALL |
                    wx.ALIGN_CENTER_HORIZONTAL |
                    wx.ALIGN_CENTER_VERTICAL, 10)
        self.SetSizer(sizer_1)
        sizer_1.Fit(self)
        self.Layout()
        self.Centre()

    def setFontBold(self, label):
        font = label.GetFont()
        font.SetWeight(wx.FONTWEIGHT_BOLD)
        label.SetFont(font)

# end of class WareboxDialog



########NEW FILE########
__FILENAME__ = gui
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the gui module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx
import threading
import sys
import os
import logging
import webbrowser
from contextlib import contextmanager

from filerockclient.constants import IS_DARWIN
from filerockclient.ui.wxGui.ask_for_user_input import Ask_for_user_input
from filerockclient.ui.wxGui.notify_user import Notify_user
from filerockclient.interfaces import GStatuses
from filerockclient.ui.interfaces import HeyDriveUserInterfaceNotification
from filerockclient.interfaces import LinkingStatuses as LS
from filerockclient.ui.wxGui.dialogs.linkdialog import LinkDialog
from filerockclient.ui.wxGui.dialogs.syncdialog import SyncDialog
from filerockclient.ui.wxGui.dialogs.logviewer import LogFrame
from filerockclient.ui.wxGui.dialogs.wareboxdialog import WareboxDialog
from filerockclient.ui.wxGui.dialogs.sliderdialog.SliderDialog import SliderDialog
from filerockclient.ui.wxGui import TBIcon, Utils, constants
from filerockclient.ui.wxGui.leaky_bucket import LeakyBucket
from filerockclient.ui.wxGui.MainWindow import MainWindow
from filerockclient.util.utilities import open_folder_in_system_shell

# #### custom events declarations
from wx.lib.newevent import NewEvent

# this custom event is raised when an GUI should be updated,
# that is global status or hash changes
GuiUpdateWxEvent,               EVT_GUIUPDATE               = NewEvent()
#this custom event is raise when a GUI information should be updated
GuiUpdateClientInfoWxEvent,     EVT_GUIUPDATECLIENTINFO     = NewEvent()
GuiUpdateSessionInfoWxEvent,    EVT_GUIUPDATESESSIONINFO    = NewEvent()
GuiUpdatePathnameStatusWxEvent, EVT_GUIUPDATEPATHNAMESTATUS = NewEvent()
GuiUpdateConfigWxEvent,         EVT_GUIUPDATECONFIG         = NewEvent()
OnPanelWxEvent,                 EVT_ONPANEL                 = NewEvent()
#this custom event is raised when an input dialog is needed
#to start a link procedure (username and password)
LinkStatusUpdateEvent,          EVT_LINK_STATUS_CHANGE      = NewEvent()

GuiGetNewLogLineWxEvent,        EVT_ONNEWLOGLINE            = NewEvent()
OnWelcomeWxEvent,               EVT_ONWELCOME               = NewEvent()

HASHMISHMATCH_ANCHOR = '#FAQ_566700de7b9a4b08328a2b32111c8749'

LINKS = {
    'register': "https://www.filerock.com/register",
    'help': "https://www.filerock.com/help",
    'home': "https://www.filerock.com/home",
    'manual-report': "https://www.filerock.com/manual-report",
    'morespace': "https://www.filerock.com/morespace",
    'download': "https://www.filerock.com/download",
    'robohash': "https://www.filerock.com/visualhash",
    'hashmismatch': 'https://www.filerock.com/faq%s' % HASHMISHMATCH_ANCHOR
}

class GUI(wx.App, HeyDriveUserInterfaceNotification):

    class GuiThread(threading.Thread):
        def __init__(self, client):
            threading.Thread.__init__(self, name=self.__class__.__name__)
            self.daemon = True
            self.client = client
            self.waitGuiLock = threading.Lock()
            self.waitGuiLock.acquire()  # self.gui is not available yet

            self.ready = False
            self.readyLock = threading.Lock()
            # in any case GUI will start in non-ready state
            self.readyLock.acquire()
            self.logger = logging.getLogger("FR.Gui")

        def getGUI(self):
            self.waitGuiLock.acquire()  # possibly blocking
            assert "gui" in self.__dict__
            self.waitGuiLock.release()
            return self.gui

        def run(self):
            self.gui = GUI(self.client, self)
            self.waitGuiLock.release()

            self.logger.debug(u"GUI mainloop started")

            # not sure if this should be placed here or in
            # the handler of an hypothetical first event dispatched
            self.gui._makeReady()
            self.gui.MainLoop()

            self.readyLock.acquire()  # GUI is not ready
            self.ready = False

            self.logger.debug(u"GUI mainloop exited normally")

    @staticmethod
    def initUI(client):
        '''
        Creates a new thread in which the main loop of the gui is running.
        The thread in which the main loop will runs is the same
        that initializes the wx.App object as required by wx 2.5

        Returns a reference to the GUI object.
        '''
        gui_thread = GUI.GuiThread(client)
        gui_thread.start()
        gui = gui_thread.getGUI()  # possibly blocking until GUI is created
        return gui

    def __init__(self, client, thread):
        '''
        Never call this method directly,
        initialize by calling static method GUI.initGUI(client)
        '''
        wx.App.__init__(self, 0)
        self.thread = thread
        self.client = client
        self.clientStatus = client.getCurrentGlobalStatus()
        self.logger = logging.getLogger("FR." + self.__class__.__name__)

        # the dialog for asking for the credential will be created on demand
        self.credentialDialog = None
        # the frame for security status and logs will be created on demand
        self.securityFrame = None
        self.wareboxDialog = None

    def setClient(self, client):
        self.client = client

    ##################### model

    def getClientStatus(self):
        return self.clientStatus

    def getLastHash(self):
        return self.client.getLastHash()

    def getProposedHash(self):
        return self.client.getProposedHash()

    ################### Interact with client

    def refreshConfig(self):
        """
        Returns the client configurations as a dictionary
        """
        return self.client.getConfigAsDictionary()

    def applyConfig(self, cfg):
        """
        Applies the new configuration, delegating the task to the client
        """
        self.linkDialog.user_provided_input['provided'] = None
        self.linkDialog.Close()
        self.client.apply_config(cfg)

    ##################### Readyness.

    def waitReady(self):
        '''
        This is supposed to be called by a thread different for
        that of the GUI main loop to wait for the
        GUI to became ready to get any notification. This happens when
        self._makeReady() is called internally by the GUI.
        '''
        self.thread.readyLock.acquire()
        self.thread.readyLock.release()

    def isReady(self):
        return self.thread.ready

    def _makeReady(self):
        '''
        call this to make the gui ready to handle events.
        Ideally is when the main loop is about to start,
        however, since I do not know now if a "first" event is fired
        when MainLoop is started, I call this in OnInit.
        However, OnInit is called before MainLoop is started, which is started
        when self.start() is called, see self.run()
        '''
        self.thread.readyLock.release()
        self.thread.ready = True

    ###################### threading aspects

    # run this GUI using ordinary start() method

    def quitUI(self):
        '''
        This method gracefully finish the gui main loop
        (use this instead of corresponding thread methods).
        '''
        self.logger.debug(u"Terminating Systray UI...")
        self.tbicon.RemoveIcon()
        self.ExitMainLoop()
        self.logger.debug(u"Systray UI terminated.")

    ################### handling of events from client

    def notifyUser(self, what, *args, **kwds):
        '''
        This method is supposed to be called by a non-gui thread
        to request user notification.
        It is a facade to other methods selected by parameter what.
        '''
        return self.notify_user_methods.notifyUser(what, *args, **kwds)


    def notifyCoreReady(self):
        pass

    def askForUserInput(self, what, *args, **kwds):
        '''
        This method is supposed to be called by
        a non-gui thread to request user interaction.
        It is a facade to other methods selected by parameter what.
        '''
        return self.ask_user_methods.askForUserInput(what, *args, **kwds)

    def notifyGlobalStatusChange(self, newStatus):
        '''
        when the status change the GUI should
        execute proper actions e.g. changing the icon.
        If the GUI is not ready to be notified,
        this method has no graphic effect but to updated
        the local 'clientStatus' attribute.
        '''
        self.clientStatus = newStatus

        if self.isReady():
            evt = GuiUpdateWxEvent(ns=newStatus)
            wx.PostEvent(self, evt)

    def updateLinkingStatus(self, status):
        '''
        Update the linking procedure status
        using one of the Linking Status specified above
        '''
        if self.isReady():
            evt = LinkStatusUpdateEvent(code=status)
            wx.PostEvent(self, evt)

    def updateClientInformation(self, infos):
        '''
        Set client information as:
            username: string
            client_id: number
            client_hostname: string
            client_platform: string
            client_version: string
            client_basis: string
        '''
        evt = GuiUpdateClientInfoWxEvent(infos=infos)
        wx.PostEvent(self, evt)

    def updateSessionInformation(self, infos):
        '''
        Sets the initial sesssion information in the user interface
        Ex:
            last_commit_client_id: string or None
            last_commit_client_hostname: string or None
            last_commit_client_platform: string or None
            last_commit_timestamp: unix time
            user_quota: number (space in bytes)
            used_space: number (space in bytes)
            basis
            plan
            status 
            expries_on
        '''
        evt = GuiUpdateSessionInfoWxEvent(infos=infos)
        wx.PostEvent(self, evt)

    def updateConfigInformation(self, infos):
        """
        Posts a EVT_GUIUPDATECONFIG event

        @param info: a dictionary representation of the configuration
        """
        evt = GuiUpdateConfigWxEvent(cfg=infos)
        wx.PostEvent(self, evt)

    def notifyPathnameStatusChange(self, pathname, newStatus, extras=None):
        """
        Posts a EVT_GUIUPDATEPATHNAMESTATUS event

        @param pathname: the pathname
        @param newStatus: the new status
        @param extras: a dictionary containing useful informations
        """
        if self.isReady():
            self.leaky_bucket.new_pathname_event(pathname, newStatus, extras)
#             evt = GuiUpdatePathnameStatusWxEvent(pathname=pathname,
#                                                  status=newStatus,
#                                                  extras=extras
#                                                  )
#             wx.PostEvent(self, evt)

    def newLogLine(self, line):
        """
        Posts a EVT_ONNEWLOGLINE event

        @param line: the logged line
        """
        if self.isReady():
            evt = GuiGetNewLogLineWxEvent(line=line)
            wx.PostEvent(self, evt)

    def showWelcome(self, cfg, onEveryStartup=True):
        """
        Posts a EVT_ONWELCOME event

        @param cfg: an instance of filerockclient.config.ConfigManager
        """
        return_struct = {
                       'result': False,
                       'show welcome on startup': onEveryStartup
                       }
        somethingToWaitOn = threading.Event()
        self.waitReady()
        evt = OnWelcomeWxEvent(cfg=cfg,
                               result=return_struct,
                               syncOn=somethingToWaitOn)
        wx.PostEvent(self, evt)
        somethingToWaitOn.wait()
        return return_struct

    def showPanel(self):
        """
        Posts a EVT_ONPANEL event
        """
        evt = OnPanelWxEvent()
        wx.PostEvent(self, evt)

    ################### handling of events related to the GUI

    def OnInit(self):
        self.ready = False
        self.visible_dialog = None

        wx.InitAllImageHandlers()

        self._readyLock = threading.Lock()

        self.links = LINKS

        self.tbicon = TBIcon.TBIcon(self)

        self.tbicon.lock()

        self.ask_user_methods = Ask_for_user_input(self)
        self.notify_user_methods = Notify_user(self)

        images_dir = constants.IMAGE_PATH
        icons_dir = constants.ICON_PATH
        self.mainWindow = MainWindow(self, images_dir, icons_dir, None, -1, "")
        self.SetTopWindow(self.mainWindow)

        self.sliderDialog = None
        self.sync_dialog = None

        self.leaky_bucket = LeakyBucket(self, GuiUpdatePathnameStatusWxEvent)

        self.linkDialog = LinkDialog.LinkDialog(self, None, -1, "")
        self.logViewer = LogFrame.LogFrame(None, -1, "")

        self.trayBarLeftClickActions = {
            Utils.TASKBARLEFTCLICKACTIONS[0]: self.OnPanel,
            Utils.TASKBARLEFTCLICKACTIONS[1]: self.OnOpenWareboxRequest
        }
        # bind custom events
        self.Bind(EVT_LINK_STATUS_CHANGE, self.OnLinkStatusChange)
        self.Bind(EVT_GUIUPDATE, self.OnGuiUpdate)
        self.Bind(EVT_GUIUPDATECLIENTINFO, self.mainWindow.OnUpdateClientInfo)
        self.Bind(EVT_GUIUPDATESESSIONINFO,
                  self.mainWindow.OnUpdateSessionInfo)
        self.Bind(EVT_GUIUPDATEPATHNAMESTATUS,
                  self.mainWindow.OnUpdatePathnameStatus)
        self.Bind(EVT_ONPANEL, self.OnPanel)
        self.Bind(EVT_GUIUPDATECONFIG, self.mainWindow.OnUpdateConfig)
        self.Bind(EVT_ONNEWLOGLINE, self.logViewer.OnLogLine)
        self.Bind(EVT_ONWELCOME, self.OnWelcome)
        #Binding the quit action on OSX
        self.Bind(wx.EVT_MENU, self.OnQuit, id=wx.ID_EXIT)
        return True

    def OnQuit(self, event):
        '''
        Asks the client to quit all the application
        '''
        self.client.quit()

    def OnOpenWareboxRequest(self, event):
        """
        Opens the FileRock folder using the system file browser
        """
        full_warebox_path = self.client.get_warebox_path()
        if full_warebox_path is None:
            return
        open_folder_in_system_shell(full_warebox_path)

    def OnTrayBarLeftClick(self, event):
        """
        Executes the default action associated with the TrayBarIcon left click
        """
        config = self.refreshConfig()
        section = u'User Defined Options'
        option = u'on_tray_click'
        if section in config.keys() and option in config[section].keys():
            self.trayBarLeftClickActions[config[section][option]](event)
        else:
            self.trayBarLeftClickActions[Utils.TASKBARLEFTCLICKACTIONS[0]](event)

    def OnGuiUpdate(self, event):
        '''
        This is called when the the wx event to update the status,
        that is the taskbar and the hash is handled,
        this is posted by notifyGlobalStatusChange()
        '''
        self.tbicon.update(event.ns)
        self.mainWindow.updateStatus(event.ns)

    @contextmanager
    def tbiconlocked(self):
        """
        A context manager method,
        call it with the with statement to do actions with the tray icon locked
        """
        self.tbicon.lock()
        try:
            yield
        finally:
            self.tbicon.unlock()

    def OnLinkDialog(self, event):
        """
        Creates, updates and raises the Link dialog
        """
        self.linkDialog.setSync(event.synchronization)
        if event.first_time:
            self.linkDialog.initialize()
            self.tbicon.unlock()
        self.linkDialog.setUserProvidedInputMap(event.user_provided_input)
        if not self.linkDialog.IsShown():
            self.linkDialog.Show()
        self.linkDialog.Raise()

    def OnWareboxDialog(self, event):
        """
        Shows the warebox dialog in case the user
        want change the FileRock folder path
        """
        if self.wareboxDialog is None:
            self.wareboxDialog = WareboxDialog.WareboxDialog(
                                                event.result['warebox_path'],
                                                None, -1, "")
        with self.tbiconlocked():
            if not IS_DARWIN:
                self.wareboxDialog.Show()
            self.wareboxDialog.warebox_ctrl.SetPath(event.result['warebox_path'].strip())
            result = self.wareboxDialog.ShowModal()
            if result == wx.ID_OK:
                event.result['result'] = True
                warebox_path = self.wareboxDialog.warebox_ctrl.GetValue()
                event.result['warebox_path'] = warebox_path
            elif result == wx.ID_CANCEL:
                event.result['result'] = False
            event.syncOn.set()

    def OnLinkStatusChange(self, event):
        """
        Updates the link status on Linking dialog,
        unlock the tbicon if login ended successfully
        """
        if event.code == LS.SUCCESS:
            self.tbicon.unlock()
        self.linkDialog.change_status(event)

    def OnWelcome(self, event):
        """
        Shows the welcome slide show
        """
        if self.sliderDialog is None:
            self.sliderDialog = SliderDialog(None, -1, "")
        with self.tbiconlocked():
            checked = event.result['show welcome on startup']
            self.sliderDialog.checkbox_1.SetValue(checked)
            result = self.sliderDialog.ShowModal()
            if result == wx.ID_OK:
                event.result['result'] = True
            elif result == wx.ID_CANCEL:
                event.result['result'] = False
            checked = self.sliderDialog.checkbox_1.IsChecked()
            event.result['show welcome on startup'] = checked
            event.syncOn.set()

    def onSyncBasisMismatch(self, event):
        """
        Shows the sync dialog asking the user to accept the changes
        """
        with self.tbiconlocked():
            self.sync_dialog = SyncDialog.SyncDialog(self, None, -1, "")
            self.sync_dialog.update_information(event.client_basis,
                                                event.server_basis,
                                                event.content)
            result = self.sync_dialog.ShowModal()
            if result == wx.ID_OK:
                event.result['result'] = "ok"
            elif result == wx.ID_CANCEL:
                event.result['result'] = "cancel"
            event.syncOn.set()

    def OnLogViewer(self, event):
        """
        Opens the log viewer dialog
        """
        if self.logViewer.IsShown():
            self.logViewer.Hide()
        else:
            self.logViewer.Show()
            self.logViewer.Raise()

    def OnTBiconLocked(self, event):
        """
        Raises every visible dialog
        """
        if self.visible_dialog is not None:
            if self.visible_dialog.IsShown():
                self.visible_dialog.Raise()

        if self.sync_dialog is not None:
            if self.sync_dialog.IsShown():
                self.sync_dialog.Raise()

        if self.sliderDialog is not None:
            if self.sliderDialog.IsShown():
                self.sliderDialog.Raise()

        if self.linkDialog.IsShown():
            self.linkDialog.Raise()

    def OnForceConnect(self, event):
        if self.client.getCurrentGlobalStatus() == GStatuses.NC_ANOTHERCLIENT:
            self.client.connectForceDisconnection()
        else:
            self.client.connect()

    def OnHelp(self, event):
        """
        Opens the browser on help url
        """
        webbrowser.open(self.links["help"])

    def OnLaunchBrowser(self, event):
        """
        Opens the browser on home url
        """
        webbrowser.open(self.links["home"])

    def OnSendUsFeedback(self, event):
        """
        Opens the browser on manual-report url
        """
        webbrowser.open(self.links["manual-report"])

    def OnGetMoreSpace(self, event):
        """
        Opens the browser on morespace url
        """
        webbrowser.open(self.links["morespace"])

    def OnRoboHashHelp(self, event):
        """
        Opens the browser on robohash url
        """
        webbrowser.open(self.links["robohash"])

    def OnHashMismatchHelp(self, event):
        """
        Opens the browser on hashmismatch url
        """
        webbrowser.open(self.links["hashmismatch"])

    def OnCommitForce(self, event):
        """
        Asks the client to commit
        """
        self.client.commit()

    def OnPause(self, event):
        """
        Asks the client to disconnect itself
        """
        self.client.disconnect()

    def OnStart(self, event):
        """
        Asks the client to connect itself
        """
        self.client.connect()

    def OnPreferences(self, event):
        self.logger.debug(u"Preferences not implemented")

    def OnPanel(self, event):
        """
        Opens the mainWindows and raises it
        """
        self.mainWindow.Show()
        self.mainWindow.Raise()

    def OnOptions(self, event):
        """
        Opens the mainWindows on Option tab and raises it
        """
        self.mainWindow.OnPreferencesClick(event)
        self.OnPanel(event)

########NEW FILE########
__FILENAME__ = leaky_bucket
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the leaky_bucket module.


----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx
import logging
from filerockclient.interfaces import PStatuses as Pss


INACTIVE_STATUSES = [
                     Pss.TOBEUPLOADED,
                     Pss.TOBEDOWNLOADED,
                     Pss.DELETETOBESENT
                     ]

ACTIVE_STATUSES = [
                   Pss.UPLOADING,
                   Pss.UPLOADED,
                   Pss.DELETESENT,
                   Pss.DOWNLOADING
                   ]

PERCENTAGE_STATUSES = [
                       Pss.TOBEUPLOADED,
                       Pss.TOBEDOWNLOADED,
                       Pss.UPLOADING,
                       Pss.UPLOADED,
                       Pss.DOWNLOADING
                       ]

MAX_POSTED_STATUSES = 200

class LeakyBucket(object):

    def __init__(self, wx_app, event_class):
        self._wx_app = wx_app
        self._event_class = event_class
        self._logger = logging.getLogger("FR.Gui.LeakyBucket")
        self._clean()
        
    def _post_event(self, pathname, status, extras):
        if status == Pss.ALIGNED:
            self._post_old_pathname()
            
        extras['cached_operations'] = len(self._statuses)
        extras['posted_operations'] = len(self._posted_statuses)

        evt = self._event_class(pathname=pathname,
                                status=status,
                                extras=extras)
        wx.PostEvent(self._wx_app, evt)
    
    
    def _post_old_pathname(self):
        if len(self._statuses) > 0:
            pathname, (status, extras) = self._statuses.popitem()
#             self._logger.info("Posted_event %s" % len(self._posted_statuses))
#             self._logger.info('Posting %s:%s' % (pathname, status))
            self.new_pathname_event(pathname, status, extras) 
    
    def _remove_pathname(self, pathname):
        if pathname in self._statuses:
            del self._statuses[pathname]
        
    def _remove_posted_pathname(self, pathname):
        if pathname in self._posted_statuses:
            del self._posted_statuses[pathname]
    
    def _add_posted_pathname(self, pathname, status, extras):
        self._remove_pathname(pathname)
        if status == Pss.ALIGNED:
            self._remove_posted_pathname(pathname)
        else:
            self._posted_statuses[pathname] = (status, extras)
    
    def _purge_pathname(self, pathname):
        self._remove_pathname(pathname)
        self._remove_posted_pathname(pathname)

    def _clean(self):
        self._posted_event = 0
        self._statuses = {}
        self._posted_statuses = {}
        
    def new_pathname_event(self, pathname, status, extras):
        if status in INACTIVE_STATUSES:
            self._statuses[pathname] = (status, extras)
        
        if (status == Pss.ALIGNED) and pathname not in self._posted_statuses:
            self._remove_pathname(pathname)
            return
        
        if (status in ACTIVE_STATUSES + [Pss.ALIGNED]) \
        or len(self._posted_statuses) < MAX_POSTED_STATUSES:
            self._add_posted_pathname(pathname, status, extras)
            self._post_event(pathname, status, extras)
        
        
        
        
########NEW FILE########
__FILENAME__ = MainWindow
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the MainWindow module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

# generated by wxGlade 0.6.3 on Fri Jun 22 16:20:43 2012

import wx
import sys
import logging

from filerockclient.util.utilities import format_bytes
from filerockclient.interfaces import GStatus, GStatuses
from filerockclient.ui.wxGui import Messages
from filerockclient.ui.wxGui.Utils import STATEMESSAGES


FORCE_WIN = False
FORCE_OSX = False

from filerockclient.ui.wxGui.default.Template import MainWindow as TMainWindow
if sys.platform.startswith('win') or sys.platform.startswith('darwin'):
    from filerockclient.ui.wxGui.default.panel_2 import Panel2
    from filerockclient.ui.wxGui.default.panel_1 import Panel1
    from filerockclient.ui.wxGui.default.panel_3 import Panel3
else:
    from filerockclient.ui.wxGui.linux.panel_2 import Panel2
    from filerockclient.ui.wxGui.linux.panel_1 import Panel1
    from filerockclient.ui.wxGui.linux.panel_3 import Panel3


from wx.lib.newevent import NewEvent

# this custom event is raised when an GUI should be updated,
# that is global status or hash changes
OnInit, EVT_INIT = NewEvent()

# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode

# end wxGlade
ONEMEGAINBYTES = (1024*1024)
ONEGIGAINBYTES = ONEMEGAINBYTES * 1024

MAXUSERNAMELEN = 15
MAXHOSTNAMELEN = 10


class MainWindow(TMainWindow.MainWindow):
    def __init__(self, app, images_dir, icons_dir, *args, **kwds):
        # begin wxGlade: MainWindow.__init__
        super(MainWindow, self).__init__(images_dir, icons_dir, *args, **kwds)
        self.logger = logging.getLogger("FR.Gui." + self.__class__.__name__)
        self.loggerViewer = None
        self.app = app
        self.append_panel(self.sizer_2)
        self.__personalization()
        self.OnStatusClick(None)

    def OnStatusClick(self, event):  # wxGlade: MainWindow.<event_handler>
        self.enlight_button('status')
        self.panel_1.Show()
        self.panel_2.Hide()
        self.panel_3.Hide()
        self.Layout()

    def OnActivityClick(self, event):  # wxGlade: MainWindow.<event_handler>
        self.enlight_button('activity')
        self.panel_2.Show()
        self.panel_1.Hide()
        self.panel_3.Hide()
        self.Layout()

    def OnPreferencesClick(self, event):  # wxGlade: MainWindow.<event_handler>
        self.enlight_button('preferences')
        self.panel_3.Show()
        self.panel_1.Hide()
        self.panel_2.Hide()
        self.Layout()

    def enlight_button(self, button_name):
        for key, button in self.buttons.iteritems():
            if button_name == key:
                button.SetBitmapLabel(self.BUTTON_ICONS_LIGHT[key])
            else:
                button.SetBitmapLabel(self.BUTTON_ICONS[key])

    def OnLogsClick(self, event):
        self.app.OnLogViewer(event)

    def _state_icon(self, filename):
        return wx.Bitmap(self._icon_path(filename))

    def change_font_size(self, label):
        pass
#        font = label.GetFont()
#        font.SetPointSize(font.GetPointSize()-2)
#        label.SetFont(font)

    def __personalization(self):
#        self.__init_panel1()
        _icon = wx.Icon(self._image_path("other/FileRock.ico"), wx.BITMAP_TYPE_ICO)
        self.SetIcon(_icon)

        self.Bind(wx.EVT_CLOSE, self.OnClose)

        self.BUTTON_ICONS = {
            'status': wx.Bitmap(self._image_path("GUI-icons/dialog-information-48.png"), wx.BITMAP_TYPE_PNG),
            'activity': wx.Bitmap(self._image_path("GUI-icons/activity-48.png"), wx.BITMAP_TYPE_PNG),
            'preferences':  wx.Bitmap(self._image_path("GUI-icons/preferences-system-48.png"), wx.BITMAP_TYPE_PNG)
        }

        self.BUTTON_ICONS_LIGHT = {
            'status': wx.Bitmap(self._image_path("GUI-icons/dialog-information-48-light.png"), wx.BITMAP_TYPE_PNG),
            'activity': wx.Bitmap(self._image_path("GUI-icons/activity-48-light.png"), wx.BITMAP_TYPE_PNG),
            'preferences':  wx.Bitmap(self._image_path("GUI-icons/preferences-system-48-light.png"), wx.BITMAP_TYPE_PNG)
        }

        self.statesMessage = STATEMESSAGES


        assert set(self.statesMessage.keys()) == GStatus.allStates, 'There are not messages to cover %s Client states' % GStatus.allStates.difference(set(self.statesMessage.keys()))


        self.sizer_3_staticbox.SetLabel(Messages.MAINWINDOW_USER_SPACE_SECTION_LABEL)
#        self.sizer_22_staticbox.SetLabel(Messages.MAINWINDOW_INFO_SECTION_LABEL)

        #BUTTONS
        self.start_stop_bitmap_button.SetToolTipString(Messages.MAINWINDOW_START_STOP_BUTTON_TOOLTIP)
        self.status_bitmap_button.SetToolTipString(Messages.MAINWINDOW_STATUS_BUTTON_TOOLTIP)
        self.activity_bitmap_button.SetToolTipString(Messages.MAINWINDOW_ACTIVITY_BUTTON_TOOLTIP)
        self.preferences_bitmap_button.SetToolTipString(Messages.MAINWINDOW_PREFERENCES_BUTTON_TOOLTIP)
        #self.logs_bitmap_button.SetToolTipString(Messages.MAINWINDOW_LOGS_BUTTON_TOOTIP)

        #LABELS
#        self.user_label.SetLabel(Messages.MAINWINDOW_USER_LABEL)
#        self.client_label.SetLabel(Messages.MAINWINDOW_CLIENT_LABEL)
#        self.version_label.SetLabel(Messages.MAINWINDOW_VERSION_LABEL)
        self.status_label.SetLabel(Messages.MAINWINDOW_STATUS_BUTTON_LABEL)
        self.activity_label.SetLabel(Messages.MAINWINDOW_ACTIVITY_BUTTON_LABEL)
        self.preferences_label.SetLabel(Messages.MAINWINDOW_PREFERENCES_BUTTON_LABEL)
        #self.logs_label.SetLabel(Messages.MAINWINDOW_LOGS_BUTTON_LABEL)

        map(self.change_font_size, [self.folder_label,
                                    self.start_stop_label,
                                    self.activity_label,
                                    self.status_label,
                                    self.preferences_label#,
                                    #self.logs_label
                                    ])



        self.get_more_space_button.SetLabel(
                                Messages.MAINWINDOW_MORE_SPACE_BUTTON_LABEL
                                )

        self.SetTitle(Messages.MAINWINDOW_TITLE)

        self.started = False

        self.start_stop_image = {
                True: wx.Bitmap(self._image_path('GUI-icons/pause-48-tango.png'), wx.BITMAP_TYPE_PNG),
                False: wx.Bitmap(self._image_path('GUI-icons/start-48-tango.png'), wx.BITMAP_TYPE_PNG)
        }
        self.start_stop_text = {
                True: Messages.MAINWINDOW_PAUSE_LABEL,
                False: Messages.MAINWINDOW_START_LABEL
        }
        self.connecting_disconnecting_text = {
                True: Messages.MAINWINDOW_DISCONNECTING_LABEL,
                False: Messages.MAINWINDOW_CONNECTING_LABEL
        }
        self._update_start_stop_button()

    def OnStartStop(self, event):
        """
        Action fired by the Pause/Start button
        """
        if self.started:
            self.OnStop(event)
        else:
            self.OnStart(event)
        self.start_stop_bitmap_button.Disable()

    def OnClose(self, event):
        """
        Hides itself
        """
        self.Hide()

    def append_panel(self, sizer):
        """
        Adds the panel into its sizer
        """
        self.panel_1 = Panel1(self)
        self.panel_2 = Panel2(self)
        self.panel_3 = Panel3(self, self.app)
        sizer.Add(self.panel_1, 1, wx.EXPAND, 0)
        sizer.Add(self.panel_2, 1, wx.EXPAND, 0)
        sizer.Add(self.panel_3, 1, wx.EXPAND, 0)
        self.panel_1.Hide()
        self.panel_2.Hide()
        self.panel_3.Hide()
        self.panel_1.Show()
        self.Fit()
        self.SetMinSize(self.GetSize())


    def OnUpdateClientInfo(self, event):
        '''
        event.infos contains:
            username: string
            client_id: number
            client_hostname: string
            client_platform: string
            client_version: string
            basis: string
            last_commit_timestamp: number or None
            used_space: number or None
            user_quota: number or None
        '''

        client_id = event.infos['client_id']
        hostname = event.infos['client_hostname']
        username = event.infos["username"]

        self.panel_1.version_ctrl.SetValue(event.infos['client_version'], True)
        if client_id is not None:
            self.panel_1.client_ctrl.SetValue(client_id, True)
        if hostname is not None:
            self.panel_1.host_ctrl.SetValue(hostname, True)
        if username is not None:
            self.panel_1.user_ctrl.SetValue(username, True)
        self.OnUpdateSessionInfo(event)
        self.Layout()
        self.panel_1.Layout()
        self.Fit()

    def OnUpdateSessionInfo(self, event):
        '''
        event.infos contains:
            last_commit_client_id: string or None
            last_commit_client_hostname: string or None
            last_commit_client_platform: string or None
            last_commit_timestamp: unix time
            user_quota: number (space in bytes) or None
            used_space: number (space in bytes) or None
            basis
            plan
            status
            expires_on

        '''
        if event.infos['user_quota'] is not None \
        and event.infos['used_space'] is not None:
            self.setSpaceInfo(int(event.infos['user_quota']),
                              int(event.infos['used_space']))
        if 'basis' in event.infos:
            self.panel_1.updateHash(event.infos['basis'])
        if event.infos['last_commit_timestamp'] is not None:
            self.panel_1.updateTimestamp(event.infos['last_commit_timestamp'])

        if ('plan' in event.infos and
                'status' in event.infos and
                'expires_on' in event.infos and 
                'user_quota' in event.infos):
            self.setContractualInfo(event.infos['plan'],
                                    event.infos['status'],
                                    event.infos['expires_on'],
                                    event.infos['user_quota'])

    def OnUpdatePathnameStatus(self, event):
        """
        Catches the updated pathname event and
        delegates it to the right element
        """
        self.updatePathnameStatus(event.pathname, event.status, event.extras)

    def OnUpdateConfig(self, event):
        """
        Asks to the panel3 to update the configuration shown
        """
        self.panel_3.updateConfig(event.cfg)
        self.app.tbicon.unlock()

    def OnRoboHashHelp(self, event):
        """
        Delegates the event to the gui
        """
        self.app.OnRoboHashHelp(event)

    def OnGetMoreSpace(self, event):
        """
        Delegates the event to the gui
        """
        self.app.OnGetMoreSpace(event)

    def OnFileRockFolder(self, event):
        """
        Delegates the event to the gui
        """
        self.app.OnOpenWareboxRequest(event)

    def _update_start_stop_button(self):
        """
        Updates the start/pause button
        """
        self.start_stop_label.SetLabel(self.start_stop_text[self.started])
        self.start_stop_bitmap_button.SetBitmapLabel(
            self.start_stop_image[self.started])
        self.Layout()
        self.start_stop_bitmap_button.Enable()

    def _update_start_stop_status(self, status):
        if self.started and (status == GStatuses.NC_STOPPED):
            self.started = False
            self._update_start_stop_button()
        elif not self.started and (status != GStatuses.NC_STOPPED):
            self.started = True
            self._update_start_stop_button()

    def updateStatus(self, status):
        """
        Updates the status in whole the gui
        """
        self.panel_1.updateStatus(status)
        self.panel_2.updateStatus(status)
        self._update_start_stop_status(status)
#        self.status_bitmap_button.SetBitmapLabel(self.statesBitmap[status])

    def updatePathnameStatus(self, pathname, status, extras):
        """
        Updates the pathname status on panel2
        """
        self.panel_2.updatePathnameStatus(pathname, status, extras)

    def setContractualInfo(self, plan, status, expires_on, current_quota):
        """
        @param plan: the plan described by a dictionary as the following
                  { id: <plan_id>,    # a number
                  space: <plan_space_in_GB>,   # a number (within a plan this is mandatory and 'not None')
                  price: <price_in_$>,      # a number    (if absent or ==None it means "free")
                  payment_type: <(SINGLE|SUBSCRIPTION)>,   # unicode  (present if price is not None)
                  payment_recurrence: <(MONTHLY|YEARLY)>   # unicode  (present if price is not None)
                  }
        @param status:  unicode (mandatory), one of
            ACTIVE_BETA
            ACTIVE_TRIAL
            ACTIVE_PAID
            ACTIVE_SUBSCRIBED
            ACTIVE_GRACE
            SUSPENDED
            MAINTAINANCE

        @param expires_on: <GMT-Date-or-None>    # a number representing a unix timestamp UTC (mandatory)
                 (it might be None if plan is "forever", this is the expiration date of the subscription,
                  it does not change when in grace time).
        """
        try:
            try:
                planspace = str(plan['space'])
            except Exception:
                giga = (1024 * 1024 * 1024)
                planspace = str(current_quota / giga)
                
            if expires_on is not None:
                import time
                expstring = time.strftime("%d %B %Y",
                                          time.localtime(expires_on))

            if status == 'ACTIVE_TRIAL':
                self.panel_1.plan_ctrl.SetValue("Free Trial")
                self.panel_1.expirdate_ctrl.SetValue(expstring)
                self.panel_1.expirdate_ctrl.SetForegroundColour('black')
            elif status == 'ACTIVE_BETA':
                self.panel_1.plan_ctrl.SetValue("%s GB free" % planspace)
                self.panel_1.expirdate_ctrl.SetValue('no expiration date')
                self.panel_1.expirdate_ctrl.SetForegroundColour('black')
            elif status in ['ACTIVE_PAID', 'ACTIVE_SUBSCRIBED', 'ACTIVE_GRACE']:

                # # this was a more sophisticated message, not used at the moment
                #
                #rdesc=dict(MONTHLY='Monthly', YEARLY='Yearly')
                #tdesc=dict(SINGLE='', SUBSCRIPTION='automatically renewed')
                #recurrence_descr=rdesc[plan['payment_recurrence']]
                #payment_type_descr=tdesc[plan['payment_type']]
                #self.panel_1.plan_ctrl.SetValue("%s, %s paid" % (planspace,
                                                             #recurrence_descr,
                                                             #))

                planname = 'PRO' + planspace

                if planspace not in ['1', '4', '16']:
                    planname += '?'

                if status == 'ACTIVE_GRACE':
                    self.panel_1.plan_ctrl.SetValue(planname)
                    self.panel_1.expirdate_ctrl.SetValue(
                        'expired, will be suspended on %s' % expstring)
                    self.panel_1.expirdate_ctrl.SetForegroundColour('red')
                else:
                    self.panel_1.plan_ctrl.SetValue(planname)
                    self.panel_1.expirdate_ctrl.SetValue(expstring)
                    self.panel_1.expirdate_ctrl.SetForegroundColour('black')

            self.Fit()

        except Exception:
            # this code suffer from coordination with server, be fault tolerant
            import traceback
            self.logger.debug("problem with showing contractual info: %r" %
                              traceback.format_exc())

    def setSpaceInfo(self, user_quota, used_space):
        """
        Updates the space info on main window
        """
        string = Messages.SPACE_INFO_STRING % {
                                    "used_space": format_bytes(used_space),
                                    "user_quota": format_bytes(user_quota)
                                    }
        tooltip = Messages.SPACE_INFO_TOOLTIP % {
            "used_space_in_mega": used_space / ONEMEGAINBYTES
                                    }

        self.space_ctrl.SetValue(string)
        self.space_ctrl.SetToolTipString(tooltip)
        self.used_space_bar.SetValue(((used_space * 1000) / user_quota))

    def OnStart(self, event):
        self.app.OnStart(event)

    def OnStop(self, event):
        self.app.OnPause(event)
# end of class MainWindow


########NEW FILE########
__FILENAME__ = Messages
# -*- coding: utf-8 -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the Messages module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import gettext

from filerockclient import APPLICATION_NAME
from filerockclient.ui.wxGui.constants import LOCALE_PATH

# Configure i18n
locale_dir = LOCALE_PATH.strip()
if locale_dir == '':
    # "None" means that gettext will find translations by herself, in
    # some standard location.
    locale_dir = None

gettext.install(domain=APPLICATION_NAME, localedir=locale_dir)


#### SYSTRAY MESSAGES #####


LOGOUT_REQUIRED_DIALOG_TITLE = _(u'Please logout')
LOGOUT_REQUIRED_DIALOG_BODY = _(u'''
FileRock client has detected that you are using Ubuntu with Unity interface.
In order to properly use FileRock client, please logout
and login again.
''')

DISK_QUOTA_EXCEEDED_DIALOG_TITLE = _(u'Disk quota exceeded')
DISK_QUOTA_EXCEEDED_DIALOG_BODY = _(u'\
We are sorry, FileRock couldn\'t synchronize your file \
since it is too large (%(size)s):\n\n"%(pathname)s"\n\n\
You are currently using %(used_space)s on %(total_space)s \
available, get more space on www.filerock.com!')

RENAME_ENCRYPTED_FILE_DIALOG_TITLE = _(u'Attention')
RENAME_ENCRYPTED_FILE_DIALOG_BODY = _(u'\
Client found an file named "encrypted" in the FileRock Folder.\n\
Please, rename it and press OK.')

OTHER_CLIENT_CONNECTED_DIALOG_TITLE = _(u"Another Client Connected")
WEBCLIENT_CONNECTED_DIALOG_BODY = _(u"\
Your web client is already connected.\n\
Press OK to disconnect")

OTHER_CLIENT_CONNECTED_DIALOG_BODY = _(u"\
Client number %(client_id)s \
from computer %(client_hostname)s already connected.\n\
Press OK to disconnect the other client")

UPDATE_CLIENT_DIALOG_TITLE = _(u"New version available")
UPDATE_CLIENT_DIALOG_BODY = _(u"\
A new version of FileRock is available (%(latest_version)s).\n\
Press OK to install.\n(This may take a few minutes, please be patient)\n")

UPDATE_MANDATORY_CLIENT_DIALOG_TITLE = _(u"Upgrade required")
UPDATE_MANDATORY_CLIENT_DIALOG_BODY = _(u"\
FileRock requires to be upgraded to the latest version (%(latest_version)s).\n\
Press OK to install.\n(This may take a few minutes, please be patient)\n")

UPDATE_CLIENT_LINUX_DIALOG_TITLE = _(u"New version available")
UPDATE_CLIENT_LINUX_DIALOG_BODY = _(u"\
A new version of FileRock is available (%(latest_version)s).\n\
Please download it from %(download_url)s \n")

UPDATE_CLIENT_MANDATORY_LINUX_DIALOG_TITLE = _(u"Upgrade required")
UPDATE_CLIENT_MANDATORY_LINUX_DIALOG_BODY = _(u"\
FileRock requires to be upgraded to the latest version (%(latest_version)s).\n\
Please download it from %(download_url)s \n")

ENCRYPTED_DIR_DELETED_DIALOG_TITLE = _(u'encrypted dir deleted')
ENCRYPTED_DIR_DELETED_DIALOG_BODY = _(u'\
The "encrypted" folder has been deleted. \
FileRock will automatically re-create it.')

PROTOCOL_OBSOLETE_DIALOG_TITLE = _(u'Please upgrade')
PROTOCOL_OBSOLETE_DIALOG_BODY = _(u'\
Your current version of FileRock has become unsupported, \
please upgrade before connecting to the service.')

QUIT_DIALOG_TITLE = _(u'Quit request')
QUIT_DIALOG_ISSUED_FROM_CLIENT_BODY = _(u'\
Another client forced your disconnection.\n\
Details about the client that forced your disconnection:\n\
\n\
- Client ID: %(client_id)s\n\
- Installed on computer "%(client_hostname)s" running "%(client_platform)s"\n\
- Connected from IP Address: %(client_ip)s')
QUIT_DIALOG_BODY = _(u'Service currently unavailable, please try later.')

BLACKLISTED_ON_STORAGE_TITLE = _(u'Detected unknown files on storage')
BLACKLISTED_ON_STORAGE_BODY = _(u"\
The following files are blacklisted by FileRock, \
but they have been detected on remote storage. \n\
You must delete them through the web interface at \
https://www.filerock.com/home/")


##### MAINWINDOW #####
SPACE_INFO_STRING = _(u"%(used_space)s of %(user_quota)s")
SPACE_INFO_TOOLTIP = _(u'Used %(used_space_in_mega)s MB')
MAINWINDOW_USER_SPACE_SECTION_LABEL = _(u"Used Space")
MAINWINDOW_INFO_SECTION_LABEL = _(u"Info")

MAINWINDOW_STATUS_BUTTON_LABEL = _(u"Status")
MAINWINDOW_STATUS_BUTTON_TOOLTIP = _(u"Display the status of your files")
MAINWINDOW_START_LABEL = _(u"Start")
MAINWINDOW_PAUSE_LABEL = _(u"Pause")
MAINWINDOW_DISCONNECTING_LABEL = _(u"Disconnecting")
MAINWINDOW_CONNECTING_LABEL = _(u"Connecting")

MAINWINDOW_ACTIVITY_BUTTON_LABEL = _(u"Activities")
MAINWINDOW_ACTIVITY_BUTTON_TOOLTIP = _(u"Show FileRock activities in progress")

MAINWINDOW_PREFERENCES_BUTTON_LABEL = _(u"Options")
MAINWINDOW_PREFERENCES_BUTTON_TOOLTIP = _(u"Edit your FileRock preferences")

MAINWINDOW_LOGS_BUTTON_LABEL = _(u"Logs")
MAINWINDOW_LOGS_BUTTON_TOOTIP = _(u"Open FileRock Log viewer")
MAINWINDOW_MORE_SPACE_BUTTON_LABEL = _(u"Upgrade")

MAINWINDOW_TITLE = _(u"FileRock")
MAINWINDOW_START_STOP_BUTTON_TOOLTIP = _(u'\
Click here to stop or restart FileRock.\n\
When FileRock is stopped, the synchronization will be interrupted, \
hence the network will not be used.')

##### MAINWINDOW PANEL1 #####
PANEL1_ROBOHASH_HELP_TOOLTIP = _(u"\
This robot is a graphic visualization\n\
of the hash generated by your files,\n\
courtesy of http://www.robohash.org/.\n\
The hash and the robot change whenever\n\
you upload, modify or delete files.\n\
See our FAQs for a more detailed explanation.")

PANEL1_USER_LABEL = _(u"Username")
PANEL1_PLAN_LABEL = _(u"Plan")
PANEL1_EXPIRDATE_LABEL = _(u"Expiration Date")
PANEL1_HOSTNAME_LABEL = _(u"Hostname")
PANEL1_CLIENT_LABEL = _(u"Client No.")
PANEL1_VERSION_LABEL = _(u"Software Ver.")
PANEL1_STATUS_LABEL = _(u"Client Status")

PANEL1_TITLE = _(u'Status')
PANEL1_LASTCOMMITTIME_LABEL = _("Last Commit Time:")
PANEL1_UNKNOWN_BASIS_STRING = _(u"Unknown")

##### MAINWINDOW PANEL2 #####
PANEL2_TITLE = _(u"Activities")
PANEL2_PATHNAME_COLUMN_NAME = _(u'Pathname')
PANEL2_STATE_COLUMN_NAME = _(u'State')
#PANEL2_ACTIVEOPERATION = _(u"\
#%(activeOperation)s / %(totalOperation)s in progress")
PANEL2_ACTIVEOPERATION = _(u"Activities: %(totalOperation)s ongoing")
PANEL2_ANDMORETODO = _(u"... and %(cachedOperation)s more.")


##### MAINWINDOW PANEL3 #####
PANEL3_KEY_COLUMN_NAME = _(u'key')
PANEL3_VALUE_COLUMN_NAME = _(u'value')
PANEL3_USER_SECTION_TITLE = _(u'User')
PANEL3_TITLE = _(u'Options')
PANEL3_ADVANCED_BUTTON = _(u'Advanced')
PANEL3_BASIC_BUTTON = _(u'Basic')

##### TBICON MENU #####
MENU_COMMIT_FORCE = _(u'Force Commit')
MENU_OPEN_PANEL = _(u'Open FileRock panel')
MENU_OPEN_OPTIONS = _(u'Open FileRock options')
MENU_OPEN_FILEROCK_FOLDER = _(u'Open FileRock folder')
MENU_SEND_FEEDBACK = _(u'Send us feedback')
MENU_OPEN_FILEROCK_WEBSITE = _(u'Open FileRock website')
MENU_LOG_VIEWER = _(u'Open log viewer')
MENU_PAUSE_SYNC = _(u'Pause')
MENU_FORCE_CONNECT = _(u'Reconnect')
MENU_QUIT = _(u'Quit')
MENU_HELP = _(u'Help')

##### GSTATUS MESSAGES ####
GSTATUS_CONNECTING = _(u'Connecting...')
GSTATUS_STOPPED = _(u'Stopped')
GSTATUS_NOSERVER = _(u"Can't connect to server, retrying...")
GSTATUS_ANOTHER_CLIENT = _(u"Another client is connected")
GSTATUS_NOT_AUTHORIZED = _(u"Authentication failed")
GSTATUS_ALIGNED = _(u"Ok!")
GSTATUS_NOTALIGNED = _(u'Synchronizing data')
GSTATUS_SERVICE_BUSY = _(u"Service busy")
GSTATUS_HASH_MISMATCH_ON_CONNECT = _(u"Critical error")
GSTATUS_BROKEN_PROOF = _(u"ERROR - broken proof")
GSTATUS_HASH_MISMATCH_ON_COMMIT = _(u'\
ERROR - client and server do not agree on hash')

##### LINK DIALOG #####
LINK_TITLE = _(u"Login")
LINK_HEADLINE_LABEL = _(u"Please insert your FileRock credentials")
LINK_USERNAME_LABEL = _(u"Username:")
LINK_PASSWORD_LABEL = _(u"Password:")
LINK_FOOTER_LABEL = _(u"Get your free account at")
LINK_FOOTER_LINK_LABEL = _(u"www.filerock.com")
LINK_PROXY_BUTTON_LABEL = _(u"Configure &Proxy")
##### LINK MESSAGES #####
LINK_SUCCESS = _(u"Linked successfully")
LINK_GENERATING_RSA_KEY = _(u"Generating your private/public keys")
LINK_SERVER_UNREACHABLE = _(u"Linking server unreachable")
LINK_SENDING = _(u"Sending Linking credential...")
LINK_SERVER_ERROR = _(u"Linking server error")
LINK_WRONG_CREDENTIALS = _(u"Wrong user credentials")
LINK_MALFORMED_USERNAME = _(u"Malformed username")
LINK_LINKING_FAILED = _(u"Linking Failed, try again...")
LINK_UNKNOW_ERROR = _(u"Unknow Linking error")


##### SYNC DIALOG #####
SYNC_DIALOG_TITLE = _(u"Sync Report")
SYNC_UNKNOWN_BASIS_STRING = _(u'Unknown')
SYNC_BASIS_MISMATCH_MESSAGE = _(u'Hash Mismatch detected.\n\n\
Your current verified hash is:\n\
\t%(client_hash)s\n\n\
The hash from the server is:\n\
\t%(server_hash)s\n\n\
Press OK to accept the following changes\n\
or Cancel to quit.')

BASIS_MISMATCH_NOTHING_TO_SYNC = _(u'\
There are no necessary operations to be applied,\n\
your local data are already aligned with those on FileRock.\n\
However, either the data have been changed since last time FileRock was running\n\
or this is the first time you run this FileRock client,\n\
therefore the hash will be updated as shown.')

SYNC_BASIS_MISMATCH_HELP_TOOLTIP = _(u"\
Click to learn more about hash mismatch.")
SYNC_PATHNAME_COLUMN_NAME = _(u"Pathname")
SYNC_SIZE_COLUMN_NAME = _(u"Size")
SYNC_STATE_COLUMN_NAME = _(u"State")
SYNC_PANEL_TITLE = _(u"Changes to be applied")

##### SYNC DIALOG PATHNAME STATUS MESSAGES #####

PSTATUS_DOWNLOADNEEDED = _(u'Download')
PSTATUS_LOCALDELETENEEDED = _(u'Delete')
PSTATUS_LOCALRENAMENEEDED = _(u'Rename')
PSTATUS_LOCALCOPYNEEDED = _(u'Copy')
PSTATUS_UPLOADNEEDED = _(u'Upload')
PSTATUS_TOBEUPLOADED = _(u"To be uploaded")
PSTATUS_UPLOADING = _(u'Uploading...')
PSTATUS_UPLOADED = _(u'Uploading...')
PSTATUS_TOBEDOWNLOADED = _(u'To be downloaded')
PSTATUS_DOWNLOADING = _(u'Downloading...')
PSTATUS_DELETETOBESENT = _(u'To be Deleted')
PSTATUS_DELETESENT = _(u'Deleting...')

###### LOG VIEWER ######
LOG_DIALOG_TITLE = _(u"FileRock - Logviewer")

###### SLIDER DIALOG #####
SLIDER_DIALOG_TITLE = _(u"Welcome to FileRock!")
SLIDER_DIALOG_NEXT = _(u"&Next")
SLIDER_DIALOG_SKIP = _(u"&Skip")
SLIDER_DIALOG_PREV = _(u"&Prev")
SLIDER_SHOW_ON_EVERY_STARTUP = _(u"Show welcome at startup")


###### MISC ###########
UNKNOWN = _(u"Unknown")

###### CONFING LABEL ######
CONFIG_CONFIG_DIR_LABEL = _(u"Configuration Dir")
CONFIG_PRIV_KEY_FILE_LABEL = _(u"Private key")
CONFIG_USERNAME_LABEL = _(u"Username")
CONFIG_ON_TRAY_CLICK_LABEL = _(u"Left click on trayicon")
CONFIG_ON_TRAY_CLICK_OPTIONS_0 = _(u"Open FileRock Panel")
CONFIG_ON_TRAY_CLICK_OPTIONS_1 = _(u"Open FileRock Folder")
CONFIG_TEMP_DIR_LABEL = _(u"Temporary Dir")
CONFIG_WAREBOX_PATH_LABEL = _(u"FileRock folder")
CONFIG_CLIENT_ID_LABEL = _(u"Client ID")
CONFIG_OSX_LABEL_LABEL = _(u"Enable labels (Experimental)")
CONFIG_PROXY_LABEL = _(u"Use Proxy")
CONFIG_CLOUD_STORAGE_LABEL = _(u"Cloud storage provider")
CONFIG_CLOUD_REPLICA_LABEL = _(u"Keep data replica on")
CONFIG_PRESENTATION_LABEL = _(u"Show presentation")
CONFIG_AUTOUPDATE_LABEL = _(u"Updates")
CONFIG_LAUNCH_ON_STARTUP_LABEL = _(u"Launch on startup")
CONFIG_BANDWIDTH_LIMIT_LABEL = _(u'Bandwidth limit (KiB/s)')
CONFIG_BANDWIDTH_UPLOAD_LABEL = _(u'Upload:')
CONFIG_BANDWIDTH_DOWNLOAD_LABEL = _(u'Download:')

###### CONFING TOOLTIP ######
CONFIG_CONFIG_DIR_TOOLTIP = _(u"Configuration Dir ToolTip")
CONFIG_PRIV_KEY_FILE_TOOLTIP = _(u"Private key TootTip")
CONFIG_USERNAME_TOOLTIP = _(u"Username ToolTip")
CONFIG_TEMP_DIR_TOOLTIP = _(u"Temporary Dir ToolTip")
CONFIG_WAREBOX_PATH_TOOLTIP = _(u"Change the location of your FileRock Folder")
CONFIG_CLIENT_ID_TOOLTIP = _(u"Client ID ToolTip")
CONFIG_ON_TRAY_CLICK_TOOLTIP = _(u'Defines the action to perform on tray icon left click')
CONFIG_OSX_LABEL_TOOLTIP = _(u'\
Enabling this feature will allow FileRock to use Finder colored labels \
to show you the synchronization status of your files. \
This will overwrite any colored label for all files inside your FileRock folder. \
File colored labels are saved as extended attributes in your filesystem. \
In case you decide to disable this feature, all the colored labels will be removed.\
')
CONFIG_CLOUD_STORAGE_TOOLTIP = _(u"\
Select the Cloud Storage Provider where your data is kept. \
This feature will be available soon.")
CONFIG_CLOUD_REPLICA_TOOLTIP = _(u"For increased protection: select a Cloud \
Storage Provider where you want to keep a replica of all your data. \
This feature will be available soon.")

CONFIG_PRESENTATION_TOOLTIP = _(u"Show presentation when FileRock starts")
CONFIG_AUTOUPDATE_TOOLTIP = _(u"Automatically apply updates")
CONFIG_LAUNCH_ON_STARTUP_TOOLTIP = _(u"Launch FileRock at login")

CONFIG_LEFTCLICK_PANEL = _(u"Open FileRock Panel")
CONFIG_LEFTCLICK_FOLDER = _(u"Open FileRock Folder")

CONFIG_AUTOUPDATE = _(u"Apply updated automatically")
CONFIG_ASKFORUPDATE = _(u"Ask me before applying updates")

CONFIG_BANDWIDTH_LIMIT_UPLOAD_TOOLTIP = _(u'Limit upload bandwidth (KiB/s). When set to 0, all the available bandwidth can be used.')
CONFIG_BANDWIDTH_LIMIT_DOWNLOAD_TOOLTIP = _(u'Limit download bandwidth (KiB/s). When set to 0, all the available bandwidth can be used.')


CONFIG_CLOUD_SEEWEB = _(u"Seeweb")
CONFIG_CLOUD_AMAZON = _(u"Amazon S3")
CONFIG_CLOUD_AZURE = _(u"Azure Cloud Storage")

CONFIG_CLOUD_LABEL = _(u'%(status)s %(cloud)s')
CONFIG_CLOUD_DISABLED_LABEL = _(u'(Coming Soon)')
CONFIG_NOT_AVAILABLE = _(u'Coming Soon')

CONFIG_NOREPLICA = _(u'Do not replicate my data')


HASH_MISMATCH_ON_SYNC_CAPTION = _(u'Critical Error')
HASH_MISMATCH_ON_SYNC_MESSAGE = _(u'\
FileRock has detected an unexpected behavior, and cannot proceed.\n\
This might usually be due to temporary infrastructure maintenance.\n\
Please try to restart the application, the problem is likely to be automatically solved.\n\
However this might be also due to, possibly unintentional, data tampering.\n\
If this is the case, the problem will persist and this message will keep appearing.\n\
If it does, please contact support@filerock.com.\
')

WAREBOX_CHANGED_TITLE = _(u"WARNING")
WAREBOX_NOT_EMPTY = _(u'Attention!\n\
You are selecting as FileRock folder a directory\n\
that already contains some files!\n\
\n\
Local and remote content will be merged together.\n\
Do you want to proceed?')

WAREBOX_CHANGED = _(u'\
Attention!\n\
You are modifying your FileRock folder location\n\
to a directory that already contains some files!\n\
\n\
The FileRock folder will be moved from "%(old_warebox_path)s"\n\
to the non-empty directory "%(new_warebox_path)s"\n\
\n\
Local and remote content will be merged together.\n\
Do you want to proceed?')


WAREBOX_DIALOG_TITLE = _(u"Choose your FileRock folder")
WAREBOX_DIALOG_MESSAGE = _(u"Choose your FileRock folder")


########NEW FILE########
__FILENAME__ = notify_user
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the notify_user module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx

from filerockclient.ui.wxGui import Messages
from filerockclient.util.utilities import format_bytes
from filerockclient.ui.wxGui.dialogs.dialog.MyMessageDialog import MyMessageDialog


class Notify_user(object):

    def __init__(self, app):
        '''
        Constructor
        '''
        self.app = app

    def notifyUser(self, what, *args, **kwds):
        '''
        This method is supposed to be called by a non-gui thread
        to request user notification.
        It is a facade to other methods selected by parameter what.
        '''
        self.app.waitReady()

        method_name = '_notifyUser_' + what

        try:
            askMethod = getattr(self, method_name)
        except AttributeError:
            assert False, "Method %s doesn't exists in %s" % (
                                                method_name,
                                                self.__class__.__name__
                                                )

        askMethod(*args, **kwds)

    def _notifyUser_disk_quota_exceeded(self,
            user_used_space, user_quota, pathname, size):
        caption = Messages.DISK_QUOTA_EXCEEDED_DIALOG_TITLE
        msg = Messages.DISK_QUOTA_EXCEEDED_DIALOG_BODY % {
                'size': format_bytes(size),
                'pathname': pathname,
                'used_space': format_bytes(user_used_space),
                'total_space': format_bytes(user_quota)
                }

        self._notifyUser_message(msg, caption)


    def _notifyUser_hash_mismatch(self):
        caption = Messages.HASH_MISMATCH_ON_SYNC_CAPTION
        msg = Messages.HASH_MISMATCH_ON_SYNC_MESSAGE
        self._notifyUser_message(msg, caption, warning=True)

    def _notifyUser_encryption_dir_deleted(self, firststart=False):
        caption = Messages.ENCRYPTED_DIR_DELETED_DIALOG_TITLE
        msg = Messages.ENCRYPTED_DIR_DELETED_DIALOG_BODY
        return self._notifyUser_message(msg, caption)



    def _notifyUser_message(self, message, caption, bold=False, warning=False):
        '''
        Shows a non-blocking message dialog box
        '''
        def show_message_dialog(message, title, style, bold, warning):
            dlg = MyMessageDialog(None, -1, '')
            dlg.putInfos(message, title, style, bold, warning)
            dlg.Show()
            dlg.Raise()

        style = wx.OK
        # schedule for GUI thread the dialog to pop up asap
        wx.CallAfter(show_message_dialog,
                     message,
                     caption,
                     style,
                     bold,
                     warning
                    )

########NEW FILE########
__FILENAME__ = robohash
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the robohash module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""
#
# Based on the original RoboHash code
# www.robohash.org - https://github.com/e1ven/Robohash
#

import os
import PIL.Image as Image
import hashlib
import io


class Robohash(object):

    def __init__(self, string):
        sha_hash = hashlib.sha512()
        sha_hash.update(string)
        self.hexdigest = sha_hash.hexdigest()
        self.hasharray = []
        self.iter = 4

    def createHashes(self, count):
        for i in range(0,count):
            blocksize = (len(self.hexdigest) / count)
            currentstart = (1 + i) * blocksize - blocksize
            currentend = (1 +i) * blocksize
            self.hasharray.append(int(self.hexdigest[currentstart:currentend],16))

    def dirCount(self, path):
        return sum([len(dirs) for (_, dirs, _) in os.walk(path)])

    def getHashList(self,path):
        completelist = []
        locallist = []
        listdir = os.listdir(path)
        listdir.sort()
        for ls in listdir:
            if not ls.startswith("."):
                if os.path.isdir(path + os.sep + ls):
                    subfiles  = self.getHashList(path + os.sep + ls)
                    if subfiles is not None:
                        completelist = completelist + subfiles
                else:
                    locallist.append( path + os.sep + ls)

        if len(locallist) > 0:
            elementchoice = self.hasharray[self.iter] % len(locallist)
            luckyelement = locallist[elementchoice]
            locallist = []
            locallist.append(luckyelement)
            self.iter += 1

        completelist = completelist + locallist
        return completelist


def get_robohash(images_dir, string=None, sizex=200, sizey=200):
    '''
    Returns an io.BytesIO buffer containing the binary data for a PNG image
    corresponding to the robohash of @string
    '''
    colors = ['blue','brown','green','grey','orange','pink','purple','red','white','yellow']
    if string is None: raise Exception('Sorry, you cannot ask the robohash of nothing')
    r = Robohash(string)
    r.createHashes(11)
    client_set = os.path.join(images_dir, colors[r.hasharray[0] % len(colors)])
    hashlist = r.getHashList(client_set)
    hlcopy = []
    for element in hashlist:
        element = element[0:element.find(os.sep, element.find("#") -4) +1] + element[element.find("#") +1:len(element)]
        hlcopy.append(element)
    duality = zip(hlcopy, hashlist)
    duality.sort()
    hlcopy, hashlist = zip(*duality)

    robohash = Image.open(hashlist[0])
    robohash = robohash.resize((1024,1024))
    for png in hashlist:
        img = Image.open(png)
        img = img.resize((1024,1024))
        robohash.paste(img,(0,0),img)

    robohash = robohash.resize((sizex,sizey),Image.ANTIALIAS)
    iobuffer = io.BytesIO()
    robohash.save(iobuffer, format='png')
    return iobuffer


if __name__ == "__main__":

    print 'Generating robohash...'
    with open('test.png','wb') as f:
        f.write(get_robohash('filerock').getvalue())
    print 'Done (wrote to ./test.png)'



########NEW FILE########
__FILENAME__ = TBIcon
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the TBIcon module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx
import logging
from filerockclient.interfaces import GStatus, GStatuses as GSs
from filerockclient.ui.wxGui import Messages
from filerockclient.ui.wxGui.Utils import _icon

APPSHORTNAME = 'FileRock'

# assert os.path.isdir(ICON_PATH), "cant find dir %s" % ICON_PATH
# ERR = "icons directory does not contain the icons"
# assert os.path.isfile(os.path.join(ICON_PATH, "tskiconAligned.png")), ERR

# each tuple contains: icon filename, tooltip, True if require user input
STATESDETAILS = {
    GSs.NC_CONNECTING:           ('tskiconConnecting.png',
                                  Messages.GSTATUS_CONNECTING,
                                  False),
    GSs.NC_STOPPED:              ('tskiconStopped.png',
                                  Messages.GSTATUS_STOPPED,
                                  False),
    GSs.NC_NOSERVER:             ('tskiconNoServer.png',
                                  Messages.GSTATUS_NOSERVER,
                                  False),
    GSs.NC_ANOTHERCLIENT:        ('tskiconAnotherClient.png',
                                  Messages.GSTATUS_ANOTHER_CLIENT,
                                  False),
    GSs.NC_NOTAUTHORIZED:        ('tskiconNotAuthorized.png',
                                  Messages.GSTATUS_NOT_AUTHORIZED,
                                  True),
    GSs.C_ALIGNED:               ('tskiconAligned.png',
                                  Messages.GSTATUS_ALIGNED,
                                  False),
    GSs.C_NOTALIGNED:            ('tskiconSync.png',
                                  Messages.GSTATUS_NOTALIGNED,
                                  False),
    GSs.C_SERVICEBUSY:           ('tskiconNoServer.png',
                                  Messages.GSTATUS_SERVICE_BUSY,
                                  False),
    GSs.C_HASHMISMATCHONCONNECT: ('tskiconHashMismatchOnCommit.png',
                                  Messages.GSTATUS_HASH_MISMATCH_ON_CONNECT,
                                  True),
    GSs.C_BROKENPROOF:           ('tskiconBrokenProof.png',
                                  Messages.GSTATUS_BROKEN_PROOF,
                                  False),
    GSs.C_HASHMISMATCHONCOMMIT:  ('tskiconHashMismatchOnCommit.png',
                                  Messages.GSTATUS_HASH_MISMATCH_ON_COMMIT,
                                  False)
}


class TBIcon(wx.TaskBarIcon):
    '''
    This is the icon that will appear in the TaskBar
    (or system tray) with associated menus.
    '''
    M_QUIT = 1
    M_PAUSE = 2
    M_FORCECONNET = 3
    M_COMMITFORCE = 4
    M_PANEL = 6
    M_HELP = 7
    M_LAUNCHBROWSER = 8
    M_OPENFILEBROWSER = 9
    M_HASH = 100
    M_PROPOSEDHASH = 101
    M_SENDUSFEEDBACK = 102
    M_TEST = 500
    M_SHOWLOG = 600
    M_SHOWOPTIONS = 601
    M_EXCEPTION_TEST = 900

    def __init__(self, app):
        wx.TaskBarIcon.__init__(self)
        self.logger = logging.getLogger("FR." + self.__class__.__name__)
        self.app = app
        self.menu = None
        self.showmodalinuse = False
        # watever icon, it will be updated soon
        self.update(GSs.NC_CONNECTING)
        # these are aliases to simplify code writing
        self.menuOrder = [
                            TBIcon.M_OPENFILEBROWSER,
                            TBIcon.M_PANEL,
                            TBIcon.M_SHOWOPTIONS,
                            TBIcon.M_LAUNCHBROWSER,
                            TBIcon.M_SENDUSFEEDBACK,
                            TBIcon.M_HELP
                        ]

        # each entry has a list of features, in order...
        #   in which states the entry is shown
        #   in which states the entry is active
        #   label that have to appear in the menu
        #   method to call when entry is selected (None, no method is bound)
        T = TBIcon
        self.menuFeatures = {
            T.M_OPENFILEBROWSER:  (GStatus.allStates,
                                   GStatus.allStates,
                                   Messages.MENU_OPEN_FILEROCK_FOLDER,
                                   self.app.OnOpenWareboxRequest),
            T.M_PANEL:            (GStatus.allStates,
                                   GStatus.allStates,
                                   Messages.MENU_OPEN_PANEL,
                                   self.app.OnPanel),
            T.M_SENDUSFEEDBACK:   (GStatus.allStates,
                                   GStatus.allStates,
                                   Messages.MENU_SEND_FEEDBACK,
                                   self.app.OnSendUsFeedback),
            T.M_HELP:             (GStatus.allStates,
                                   GStatus.allStates,
                                   Messages.MENU_HELP,
                                   self.app.OnHelp),
            T.M_LAUNCHBROWSER:    (GStatus.allStates,
                                   GStatus.allStates,
                                   Messages.MENU_OPEN_FILEROCK_WEBSITE,
                                   self.app.OnLaunchBrowser),
            T.M_SHOWOPTIONS:      (GStatus.allStates,
                                   GStatus.allStates,
                                   Messages.MENU_OPEN_OPTIONS,
                                   self.app.OnOptions)
        }

        if wx.Platform != "__WXMAC__":
            self.menuOrder.append(T.M_QUIT)
            self.menuFeatures[T.M_QUIT] = (GStatus.allStates,
                                           GStatus.allStates,
                                           Messages.MENU_QUIT,
                                           self.app.OnQuit)

        self.allEntries = set(self.menuOrder)
        # ID's should be different
        assert len(self.allEntries) == len(self.menuOrder)
        # all entries should have features specified
        assert set(self.menuFeatures.keys()) == self.allEntries
        self.unlock()

    def update(self, status):
        '''
        Changes the displayed Icon (and possibly Menu) according
        to the passed status

        @param status: one of the statuses from GStatuses
        '''
        iconFilename, tooltip = STATESDETAILS[status][:2]

        # WARNING: the directory containing icons should
        # be determined in some clever way
        icon = _icon(iconFilename)
        self.SetIcon(icon, APPSHORTNAME + ': ' + tooltip)

        if self.menu and type(self.menu) == wx.Menu:
            self.updateMenu(status)

    def unlock(self):
        """
        Unlocks the TrayIcon menu
        """
        if self.showmodalinuse:
            self.Unbind(wx.EVT_TASKBAR_LEFT_UP)
            self.Unbind(wx.EVT_TASKBAR_RIGHT_DOWN)
            self.Bind(wx.EVT_TASKBAR_LEFT_UP, self.app.OnTrayBarLeftClick)
            self.showmodalinuse = False

    def lock(self):
        """
        Locks the TrayIcon menu
        """
        if not self.showmodalinuse:
            self.Unbind(wx.EVT_TASKBAR_LEFT_UP)
            self.Bind(wx.EVT_TASKBAR_LEFT_UP, self.app.OnTBiconLocked)
            self.Bind(wx.EVT_TASKBAR_RIGHT_DOWN, self.app.OnTBiconLocked)
            self.showmodalinuse = True

    def updateMenu(self, status):
        '''
        Updates the menu
        precondition: the self.menu!=None and should not be a dummy object
        for C++ deleted item, check this in advance.
        WARNING: this should thread safe and at the moment it is not!

        @param status: one of the statuses from GStatuses
        '''
        pos = 0
        for mi in self.menuOrder:
            states_view, states_enable, label, action = self.menuFeatures[mi]

            is_already_there = self.menu.FindItemById(mi)
            if status in states_view:
                if not is_already_there:

                    # label exceptions
                    if mi == TBIcon.M_HASH:
                        label = self.app.getLastHash()
                    elif mi == TBIcon.M_PROPOSEDHASH:
                        label = self.app.getProposedHash()

                    self.menu.Insert(pos, mi, label)
                    if action:
                        self.Bind(wx.EVT_MENU, action, id=mi)
                # at this point, if entry should be views, it is in the menu
                pos += 1
                self.menu.Enable(mi, status in states_enable)
            else:
                # should not be views in this state
                if is_already_there:
                    self.menu.DestroyId(mi)

    def CreatePopupMenu(self):
        if self.showmodalinuse:
            return None
#       Sometimes the client raises the exceptions like
#          File "filerockclient\ui\gui\TBIcon.pyc", line 225, in CreatePopupMenu
#          File "wx\_core.pyc", line 11053, in __init__
#          PyAssertionError: C++ assertion "wxThread::IsMain()" failed at ..\..\src\msw\thread.cpp(1354) in wxMutexGuiLeaveOrEnter(): only main thread may call wxMutexGuiLeaveOrEnter()!"
#       The following "if" is a dirty fix to try to solve this problem
        if not wx.Thread_IsMain():
            return None
        self.menu = wx.Menu()
        status = self.app.getClientStatus()
        self.updateMenu(status)

        return self.menu

assert set(STATESDETAILS.keys()) == GStatus.allStates

########NEW FILE########
__FILENAME__ = Utils
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the Utils module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import wx
import os
import sys
import io

from filerockclient.interfaces import GStatuses as GSs
from filerockclient.ui.wxGui import Messages
from filerockclient.ui.wxGui.robohash import get_robohash
from filerockclient.ui.wxGui.constants import IMAGE_PATH, ICON_PATH

UNKNOWN_HASH = None


TASKBARLEFTCLICKACTIONS = [
    u'panel',
    u'folder'
]

STATEMESSAGES = {
    GSs.NC_CONNECTING:           Messages.GSTATUS_CONNECTING,
    GSs.NC_STOPPED:              Messages.GSTATUS_STOPPED,
    GSs.NC_NOSERVER:             Messages.GSTATUS_NOSERVER,
    GSs.NC_ANOTHERCLIENT:        Messages.GSTATUS_ANOTHER_CLIENT,
    GSs.NC_NOTAUTHORIZED:        Messages.GSTATUS_NOT_AUTHORIZED,
    GSs.C_ALIGNED:               Messages.GSTATUS_ALIGNED,
    GSs.C_SERVICEBUSY:           Messages.GSTATUS_SERVICE_BUSY,
    GSs.C_NOTALIGNED:            Messages.GSTATUS_NOTALIGNED,
    GSs.C_HASHMISMATCHONCONNECT: Messages.GSTATUS_HASH_MISMATCH_ON_CONNECT,
    GSs.C_BROKENPROOF:           Messages.GSTATUS_BROKEN_PROOF,
    GSs.C_HASHMISMATCHONCOMMIT:  Messages.GSTATUS_HASH_MISMATCH_ON_COMMIT
}


class MywxStaticText(wx.StaticText):
    """
    Extended StaticText class, trims value longer than maxchar
    double click on it to put it's value into the clipboard
    """
    def __init__(self, *args, **kwds):
        wx.StaticText.__init__(self, *args, **kwds)
        self.Bind(wx.EVT_LEFT_DCLICK, self.copyText)
        self.current_value = ''
        self.SetToolTipString('')

    def SetValue(self, value, trimmed=False, maxchar=20):
        """
        Sets the new value

        @param value: new text value
        @param trimmed: if this is true, value will be trimmed
        @param maxchar: max length of trimmed value
        """
        self.current_value = value
        if trimmed and len(value) > maxchar:
            value = self._trim(value, maxchar)
        self.SetLabel(value)
        self.GetParent().Layout()

    def SetToolTipString(self, msg):
        """
        Sets tooltip string

        @param msg: new tooltip
        """
        mytooltip = "Double Click to copy the value"
        if len(msg) > 0:
            mytooltip = "%s\n%s" % (msg, mytooltip)
        return wx.StaticText.SetToolTipString(self, mytooltip)

    def GetValue(self):
        """
        Returns the current value
        """
        return self.GetLabel()

    def _trim(self, string, length):
        """Trim the string to a specific length and adds "..." at the end"""
        return u"%s..." % string[:length]

    def copyText(self, event):
        """
        Copies StaticText value into the clipboard

        @param event: which events fired this method
        """
        self.dataObj = wx.TextDataObject()
        self.dataObj.SetText(self.current_value)
        if wx.TheClipboard.Open():
            wx.TheClipboard.SetData(self.dataObj)
            wx.TheClipboard.Close()
        else:
            wx.MessageBox("Unable to open the clipboard", "Error")


def GetVHash_from_local(hash_str, size, logger=None):
    '''
    trigger this object to perform update of the visualized vhash
    based on parameter h
    '''
    if hash_str == UNKNOWN_HASH:
        unknown_hash_image = os.path.join(IMAGE_PATH,
                                          'other/unknown_robot_{size}x{size}.png')
        return wx.Bitmap(unknown_hash_image.format(size=size))

    try:
        images_dir = os.path.join(IMAGE_PATH, "robohash")
        buffer_istream = io.BytesIO(get_robohash(images_dir, hash_str, size, size).getvalue())
        image = wx.EmptyImage(1, 1)
        image.LoadStream(buffer_istream)
        bitmap = image.ConvertToBitmap()
        return bitmap

    except Exception as exc:
        if logger:
            logger.debug("exception fetching Visual Hash: %s" % exc)
        connection_problem_image = os.path.join(
                                        IMAGE_PATH,
                                        'other/noconnection_robot_{size}x{size}.png')
        return wx.Bitmap(connection_problem_image.format(size=size),
                         wx.BITMAP_TYPE_ANY)


def GetVHash(hash_str, size, logger=None):
    """
    Returns a wx.Bitmap object representing a visual representation of the
    given hash_str

    @param hash_str: the hash
    @param size: the size of the requested image
    @param logger: a logging.getlogger() object
    """
    return GetVHash_from_local(hash_str, size, logger)


def setBold(staticText):
    """Sets the staticText style to FONTWEIGHT_BOLD

    @param staticText: an instace of wx.StaticText()
    """
    font = staticText.GetFont()
    font.SetWeight(wx.FONTWEIGHT_BOLD)
    staticText.SetFont(font)


def _img(filepath):
    """
    Load an image file

    @param filepath: the file path
    @return: wx.Bitmap object
    """
    filename = os.path.normpath(filepath)
    return wx.Bitmap(os.path.join(IMAGE_PATH, filename))


def _icon(filename):
    """
    Returns proper wx.Icon object for current platform

    @param filename: the icon name
    @return: wx.Icon object
    """
    if sys.platform == 'darwin':
        icon_size = '48'
    elif sys.platform == 'linux2':
        icon_size = '32'
    elif sys.platform == 'win32':
        icon_size = '32'
    else:
        icon_size = '32'

    pathname = os.path.join(ICON_PATH, icon_size, filename)
    return wx.Icon(pathname, wx.BITMAP_TYPE_PNG)

########NEW FILE########
__FILENAME__ = UpdaterBase
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the UpdaterBase module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""


import sys, urllib, logging, json, os, hashlib, re,  platform, httplib
from filerockclient.util.utilities import format_to_log
from filerockclient.util import https_downloader
from filerockclient.exceptions import UpdateProcedureException, \
    ClientUpdateInfoRetrievingException, UnsupportedPlatformException, \
    UpdateRequestedFromTrunkClient



CLIENT_UPDATE_INFO_HOST = "www.filerock.com"
CLIENT_UPDATE_INFO_URI = "/client-updates"
TRUNK_CLIENT_VERSION = 'trunk'
UPDATE_SERVER_TIMEOUT = 10

from filerockclient.constants import VERSION as CURRENT_CLIENT_VERSION

class UpgradeType:
    MANDATORY = 'MANDATORY'
    OPTIONAL = 'OPTIONAL'
    TRANSITION = 'TRANSITION'


class UpdateFetchingException(Exception): pass

class UpdaterBase:
    """
    Base class for FileRock Client Updater.
    """


    def __init__(self, user_dir, update_server_ssl_cachain):
        self.logger = logging.getLogger('FR.%s' % self.__class__.__name__)
        self.temp_dir = os.path.join(user_dir, 'updates')
        self.update_server_cachain = update_server_ssl_cachain
        # Fetch client update info
        self._fetch_client_update_info()

    ######################################################################
    #   Common methods                                                   #
    ######################################################################


    def get_latest_version_available(self):
        return self.latest_version

    def is_client_version_obsolete(self):
        '''
        Compare given @client_version with CURRENT_CLIENT_VERSION
        Note: version strings must comply with the format MAJOR.MINOR.BUILD
        '''

        latest_client_version = self.latest_version

        latest_major, latest_minor, latest_build =  map(int, latest_client_version.split('.'))
        current_major, current_minor, current_build = map(int, CURRENT_CLIENT_VERSION.split('.'))

        return  latest_major > current_major or (latest_major == current_major and latest_minor > current_minor) \
                or (latest_major==current_major and latest_minor==current_minor and latest_build > current_build)


    def is_update_mandatory(self):
        return self.upgrade_type == UpgradeType.MANDATORY or \
                self.upgrade_type == UpgradeType.TRANSITION

    def _fetch_client_update_info(self):
        """ Fetch client update info from update server """

        connection = None
        try:
            # Create HTTPSConnection object
            connection = https_downloader.HTTPSValidatedConnection(CLIENT_UPDATE_INFO_HOST,
                                                                  self.update_server_cachain,
                                                                   timeout=UPDATE_SERVER_TIMEOUT
                                                                )

            # Sets POST params (current_version, platform, arch)
            request_parameters = {  'current_version' : CURRENT_CLIENT_VERSION,
                                    'platform' : self.get_platform(),
                                    'arch' : platform.architecture()[0],
                                    'platform_version' : self.get_os_version() }
            params = urllib.urlencode(request_parameters)
            headers = {"Content-type": "application/x-www-form-urlencoded",
                       "Accept": "text/plain"}
            connection.request('POST', CLIENT_UPDATE_INFO_URI, params, headers)
            response = connection.getresponse()
            # HTTP response must be 200 OK
            assert int(response.status) == 200, (u"Server response was not 200 OK (got %s %s, content: %s)" % (response.status, response.reason, response.read()))

            # Unpack json & check the presence of all required parameters
            client_update_info = json.loads(response.read())
            for param in ['latest_version', 'download_url', 'expected_checksum', 'upgrade_type', 'transition']:
                assert param in client_update_info, "Missing response parameter '%s'" % param

            # Put response parameters into Updater instance attributes
            self.latest_version = client_update_info['latest_version']
            self.download_url = urllib.unquote(client_update_info['download_url'])
            self.update_checksum = client_update_info['expected_checksum']
            self.upgrade_type = client_update_info['upgrade_type']
            self.transition = client_update_info['transition']


            self.logger.debug("Latest client info: %s" % format_to_log(client_update_info) )

        except Exception as e:
            raise ClientUpdateInfoRetrievingException("%s" % e)
        finally:
            if connection is not None:
                connection.close()

    def _update_file_exists(self):
        return os.path.exists(self.get_update_file_path())

    def fetch_update(self):
        ''' Fetch update from URL provided by server, also performing checksum control '''

        # If update has already been downloaded skip download & return
        if self.is_update_file_fetched() : return

        # Flush any previously download update file
        self.flush_update_file()

        self.logger.info(u"Fetching update file from %s" % self.download_url)

        # Check for temp dir existence (possibly creating it)
        if not os.path.exists(self.temp_dir):
            os.makedirs(self.temp_dir)

        # Extract host & target from download URL
        matches = re.search("^https://([^/]+)(.*)$", self.download_url)
        if matches == None:
            raise UpdateFetchingException("Invalid download URL provided (%s)" % self.download_url)
        update_server_host, update_server_target = matches.groups()

        # Download file from specified URL, validating SSL certificate
        try: https_downloader.download_file(update_server_host, self.update_server_cachain, update_server_target, self.get_update_file_path())
        except Exception as e: raise UpdateFetchingException("update file download error (%s)" % e)

        self.logger.debug(u"Update file downloaded to %s " % self.get_update_file_path())

        # Verify checksum of downloaded file
        if not self.verify_update_file_checksum():
            raise UpdateFetchingException(u"update file signature doesn't match!")

    def is_update_file_fetched(self):
        """
        Check if latest updated has already been fetched, verifying that:
        a) File is present on filesystem
        b) Its checksum matches the one provided by server
        """

        if not self._update_file_exists():
            return False

        self.logger.debug(u"Update file found at %s" % self.get_update_file_path() )

        return self.verify_update_file_checksum()

    def verify_update_file_checksum(self):
        """ Check sha256 sum of fetched updated """

        sha_checksum = hashlib.sha256()
        with open(self.get_update_file_path(),'rb') as fp:
            while True:
                chunk = fp.read(512)
                if not chunk: break
                sha_checksum.update(chunk)

        result = sha_checksum.hexdigest() == self.update_checksum
        self.logger.debug(u"Update file checksum result: %s" % result)
        return result


    def refresh_client_update_info(self):
        """ Refresh client update info """
        self._fetch_client_update_info()

    def execute_update(self):
        """
        Executes update, performing the following steps:
            1) Fetch update calling fetch_update
            2) Apply update calling apply_update
        """
        self.logger.info("execute_update called, starting update procedure")
        # Fetch update
        try: self.fetch_update()
        except UpdateFetchingException as e: raise UpdateProcedureException(e)

        # Apply update
        try: self.apply_update()
        except Exception as e: raise UpdateProcedureException(e)




    ######################################################################
    #   Overridable methods (extending classes MIGHT override them)      #
    ######################################################################

    def prompt_user_for_update(self, ui_controller):
        """
        Prompt user for update
        """
        user_choice = ui_controller.ask_for_user_input('update_client',
                                                        self.get_latest_version_available(),
                                                        self.is_update_mandatory() )

        return user_choice == 'ok'

    def get_platform(self):
        return sys.platform


    def flush_update_file(self):
        """
        Removes update file (if any)
        """
        if self._update_file_exists():
            self.logger.debug(u"Flushing update file (%s)" %
                              self.get_update_file_path())
            try:
                os.unlink(self.get_update_file_path())
            except Exception as e:
                self.logger.warning(u"Could not flush update file: %s" % e)


    ######################################################################
    #   "ABSTRACT" methods (extending classes MUST implement them)       #
    ######################################################################

    def apply_update(self):
        '''
        Apply update
        '''
        assert False, "Method apply_update not implemented in %s" % self.__class__.__name__



    def get_update_file_path(self):
        """ Return filesystem path of update file """
        assert False, "Method get_update_file_path not implemented in %s" % self.__class__.__name__


    def get_os_version(self):
        """
        Returns OS release number
        """
        assert False, "Method get_os_version not implemented in %s" % self.__class__.__name__




# Import here to avoid circular imports
#
# Please check sys.platform and import only the classes you need :)
#
if sys.platform == 'win32':
    from filerockclient.updater.UpdaterWin32 import Updater_win32 as PlatformUpdater
elif sys.platform == 'darwin':
    from filerockclient.updater.UpdaterDarwin import Updater_darwin as PlatformUpdater
elif sys.platform.startswith('linux'):
    from filerockclient.updater.UpdaterLinux import Updater_linux as PlatformUpdater
else:
    raise UnsupportedPlatformException("Unsupported platform %s" % sys.platform)


########NEW FILE########
__FILENAME__ = UpdaterDarwin
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the UpdaterDarwin module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os, shutil, platform, subprocess
from filerockclient.updater.UpdaterBase import UpdaterBase, UpdateFetchingException
from filerockclient.exceptions import UpdateProcedureException

class Updater_darwin(UpdaterBase):
    """
    Updater class for Darwin (Mac OS X) platform
    """

    # Update DMG filename pattern (to be filled with version number)
    UPDATE_FILE_PATTERN = "filerock-update-%s.dmg"
    # Script location within filerock .app bundle
    UPDATE_SCRIPT_LOCATION = 'Contents/Resources/data/update_scripts/'
    # Name of copy of update script made insiede temp dir
    UPDATE_SCRIPT_FILENAME = "update_filerock.sh"
    # Update log filename
    UPDATE_LOG_FILENAME = 'client.log'

    def get_os_version(self):
        """
        Returns OS release number
        """
        return platform.mac_ver()[0]

    def apply_update(self):
        '''
        Apply update running a bash script (@ see data/update_scripts/update_filerock.sh)
        '''

        # Filerock.app path
        app_bundle_path = self._get_application_bundle_path()
        # Update DMG path
        update_dmg_path = self.get_update_file_path()
        # Update script path
        update_script_copy_path = self._move_update_script()
        # Update log file
        update_log_file = os.path.abspath(os.path.join(os.path.dirname(self.temp_dir), self.UPDATE_LOG_FILENAME))

        # Check again existence of DMG update file
        assert os.path.exists(self.get_update_file_path()), "Update DMG file %s doesn't exists" % update_dmg_path
        # Check existence of update script copy within user temp dir
        assert os.path.exists(update_script_copy_path), "Could not find update script @ %s" % update_script_copy_path

        self.logger.info("Starting update script. (Application bundle path: %s, Update DMG path: %s, Logfile: %s)" % (app_bundle_path, update_dmg_path, update_log_file))

        os.execlp("/bin/sh", "/bin/sh", update_script_copy_path, update_dmg_path, app_bundle_path, update_log_file)



    def get_update_file_path(self):
        """ Return filesystem path of update file """
        return os.path.normpath(os.path.abspath(os.path.join(self.temp_dir, self.UPDATE_FILE_PATTERN % self.latest_version)))


    def _move_update_script(self):
        """
        Create a copy of the update script to the user's
        filerock temp directory and return copy path
        """

        # Set update script path (/path/to/filerock.app/Contents/Resources/data/update_scripts/update_filerock_app.applescript)
        script_src_path = os.path.abspath(os.path.join(self._get_application_bundle_path(), self.UPDATE_SCRIPT_LOCATION, self.UPDATE_SCRIPT_FILENAME))
        # Check file existence
        assert os.path.exists(script_src_path) and os.path.isfile(script_src_path), "Could not find update script (%s)" % script_src_path

        # Set update script copying path
        script_dest_path = os.path.abspath(os.path.join(self.temp_dir, self.UPDATE_SCRIPT_FILENAME))

        # Check if script already exists within temp dir (possibly deleting it)
        if os.path.exists(script_dest_path):
            os.unlink(script_dest_path)

        # Move update script out of app bundle path
        shutil.copy(script_src_path, script_dest_path)

        self.logger.debug("Update script moved to %s", script_dest_path)

        return script_dest_path


    def _get_application_bundle_path(self):
        """ Return current .app bundle location """
        return os.path.dirname(os.path.dirname(os.getcwd()))



########NEW FILE########
__FILENAME__ = UpdaterLinux
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the UpdaterLinux module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import platform
from filerockclient.updater.UpdaterBase import UpdaterBase, UpdateFetchingException
from filerockclient.exceptions import UpdateProcedureException

FILEROCK_DOWNLOAD_PAGE_URL = "https://www.filerock.com/download"

class Updater_linux(UpdaterBase):


    def prompt_user_for_update(self, ui_controller):
        """
        Prompt user for update
        """
        user_choice = ui_controller.ask_for_user_input('notify_update_client',
                                                       self.get_latest_version_available(),
                                                       self.is_update_mandatory(),
                                                        FILEROCK_DOWNLOAD_PAGE_URL)



        return user_choice == 'ok'

    def apply_update(self):
        '''
        Apply update
        '''
        assert False, "Method apply_update of %s should never be called" % self.__class__.__name__



    def get_update_file_path(self):
        """ Return filesystem path of update file """
        assert False, "Method get_update_file_path of %s should never be called" % self.__class__.__name__


    def get_os_version(self):
        """
        Returns OS release number
        """
        return platform.platform()


    def get_platform(self):
        """
        Overrides UpdaterBase.get_platform()
        (sys.platform may return both 'linux2' and 'linux3' values)
        """
        return 'linux'

    def flush_update_file(self):
        """
        Overrides UpdaterBase.get_platform()
        (Since there is no auto-update system for linux platform, just pass )
        """
        pass

########NEW FILE########
__FILENAME__ = UpdaterWin32
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the UpdaterWin32 module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.updater.UpdaterBase import UpdaterBase, UpdateFetchingException
from filerockclient.exceptions import UpdateProcedureException
import os, sys, shutil, platform


class Updater_win32(UpdaterBase):
    """
    Updater class for win32 platform
    """

    UPDATE_FILE_PATTERN = "update-%s.msi"
    UPDATER_PATH = "util\updater.exe"

    def get_os_version(self):
        """
        Returns OS release number
        """
        return platform.version()


    def get_update_file_path(self):
        """ Return filesystem path of update file """
        return os.path.normpath(os.path.abspath(os.path.join(self.temp_dir, self.UPDATE_FILE_PATTERN % self.latest_version)))

    def apply_update(self):
        '''
        Apply update running msiexec tool with downloaded MSI installer
        '''

        # execve with msiexec
        # /i flag - install
        # /qb flag - force basic UI mode (just progress bar)

        #self.logger.debug("Calling msiexec with argument %s" % (self.get_update_file_path()))

        #assert os.path.exists(self.get_update_file_path()), "Update MSI file %s doesn't exists" % self.get_update_file_path()
        #os.execvp("msiexec", ['msiexec', '/i "%s" /qb' % self.get_update_file_path()] )


        # BELOW THE NEW PROCEDURE WITH UPDATE LAUNCHER, WAITING TO BE FIXED

        assert os.path.exists(self.get_update_file_path()), "Update MSI file %s doesn't exists" % self.get_update_file_path()

        # Step 1: Move updater executable outside FileRock client installation dir to a temp dir
        try: updater_path = self.move_updater_executable()
        except Exception as e: raise UpdateProcedureException("Error moving update bootstrapper: " % e.message)

        self.logger.debug("Calling %s with argument %s" % (updater_path, self.get_update_file_path()))

        assert os.path.exists(updater_path), "Updater executable file %s doesn't exists" % updater_path

        # Step 2: Execve to updater passing MSI update file path as argument
        os.execvp(updater_path, ['"%s"' % updater_path, '"%s"' % self.get_update_file_path()] )

    def move_updater_executable(self):
        """
        Move updater from FileRock installation directory to a temporary directory.
        Returns (absolute) path of updater copy within temp directory
        """

        filerock_install_dir = os.path.dirname(sys.executable)
        updater_src_path = os.path.abspath(os.path.join(filerock_install_dir, self.UPDATER_PATH))
        updater_dst_path = os.path.abspath(os.path.join(self.temp_dir, 'updater.exe'))

        if os.path.exists(updater_dst_path):
            os.unlink(updater_dst_path)

        shutil.copy2(updater_src_path, updater_dst_path)

        return updater_dst_path



########NEW FILE########
__FILENAME__ = https_downloader
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the https_downloader module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import httplib, socket, ssl, os, re, base64

CONTENT_DISPOSITION_FILENAME_PATTERN = "; filename\=([a-zA-Z0-9%\-\.]+)"
FALLBACK_DOWNLOADED_FILENAME = 'unknown.download'

class HTTPSValidatedConnection(httplib.HTTPSConnection):
    '''
    Class to be used instead of httplib.HTTPSConnection to check
    certificate against a CA chain of certificates specified
    with ca_chain constructor parameter
    '''
    def __init__(self, host, ca_chain, port=None, key_file=None, cert_file=None,
                     strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
                     source_address=None):
        self.ca_chain = ca_chain
        httplib.HTTPSConnection.__init__(self, host, port, key_file, cert_file, strict, timeout, source_address)


    def connect(self):
        ''' Overrides httplib.HTTPSConnection.connect to check ssl certificate with CA_CHAIN file '''
        sock = socket.create_connection((self.host, self.port), self.timeout, self.source_address)
        if self._tunnel_host:
            self.sock = sock
            self._tunnel()
        self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file,
	                            cert_reqs=ssl.CERT_REQUIRED,
				    ca_certs=self.ca_chain)



def download_file(host, ca_chain, target, download_path = None):
    '''
    Download the specified @target with HTTPS protocol
    If @download_dir is None, returns the tuple ( status_code, reason, headers, body )
    Otherwise, just saves the body to the specified @download_dir folder on filesystem.
    The returned content is saved as @downloaded_filename if that is not None.
    Otherwise, the "content-disposition" HTTP header is considered.
    If that is not present, the last part of the specified target is used.
    '''
    try:
        connection = HTTPSValidatedConnection(host, ca_chain)
        connection.request('GET', target)
        response = connection.getresponse()
        # Check response code
        assert int(response.status) == 200, "Response was not 200 (got %s %s)" % (response.status, response.reason)
        # Return it or save it
        if download_path is None: return (response.status, response.reason, response.getheaders(), response.read())
        else: save_downloaded_file(response, download_path)
    except Exception as e:
        raise e
    finally:
        connection.close()


def _get_download_filename(save_as, response_headers, target='download'):
    ''' Returns the filename to be used for saving the downloaded file '''
    if save_as is not None: 
        return save_as
    else:
        for header, value in response_headers:
            if header == 'content-disposition':
                try: return re.search(CONTENT_DISPOSITION_FILENAME_PATTERN, value).group(1)
                except IndexError:
                    return FALLBACK_DOWNLOADED_FILENAME
        return FALLBACK_DOWNLOADED_FILENAME



def save_downloaded_file(response, location):
    ''' Save the returned content in http @response to @save_as file in @location folder '''

    # Read response (with chunk of 1024 bytes)
    with open(os.path.abspath(location), 'wb') as fp:
        while True:
            chunk = response.read()
            if not chunk: break
            fp.write(chunk)




########NEW FILE########
__FILENAME__ = ipc_log_receiver
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the ipc_log_receiver module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
from Queue import Empty
from threading import Thread, Event


class LogsReceiver(Thread):
    """
    Simple Thread which receive strings and logs them.
    """

    def __init__(self, worker_name, logs_queue):
        """
        @param worker_name: the thread name
        @param logs_queue: the queue where read logging messages
        """
        Thread.__init__(self, name=self.__class__.__name__)
        self.logger = logging.getLogger('FR.WorkerChild of %s' % worker_name)
        self.logs_queue = logs_queue
        self.die_plz = False

    def run(self):
        """
        Runs while self.die_plz is set to False
        """
        try:
            while not self.die_plz: self.receive_message()
            flushing = True
            while flushing: flushing = self.receive_message()
        except Exception as e:
            self.logger.debug('something went wrong on IPC LOG RECEIVER %r' % e)

    def receive_message(self):
        """
        Reads, from log_queue queue, tuples which represent the level
        of logging and the message and logs them with python logging system

        Uses a non blocking get method and with an empty queue returns False
        """
        try:
            _, log = self.logs_queue.get(True, 1)
            level, msg = log
            if   level == 'debug':    self.logger.debug(msg)
            elif level == 'info':    self.logger.info(msg)
            elif level == 'warning':  self.logger.warning(msg)
            elif level == 'error':    self.logger.error(msg)
            elif level == 'critical': self.logger.critical(msg)
            return True
        except Empty:
            return False
        except AttributeError: # Queue has been trashed
            self.die_plz = True
            return False

    def stop(self):

        self.die_plz = True

if __name__ == '__main__':
    print "\n This file does nothing on its own, it's just the %s module. \n" % __file__

########NEW FILE########
__FILENAME__ = ipc_subprocess_logger
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the ipc_subprocess_logger module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

class SubprocessLogger(object):
    """
    SubprocessLogger is a workaroung to consolidate logging when multiprocessing is used.
    Each subprocess is given a pipe, and instantiate a SubprocessLogger when is initialized.
    Then, SubprocessLogger is used as a logger, but it sends the msgs to the pipe,
    which is given by reference from the subprocess.
    On the other side of the pipe, LogsReceiver is listening and forwarding logs to
    the main process logger.
    """

    def __init__(self, logs_queue):
        """
        @param logs_queue: queue where put logging messages
        """
        self.logs_queue = logs_queue

    def put(self, msg):
        """
        Puts into the queue a tuple as ('log', msg)

        @param msg the message
        """
        if self.logs_queue is not None:
            self.logs_queue.put(('log', msg))

    def debug(self, msg):
        """
        Generates a message as a tuple ('debug', msg) and
        sends it through the put method

        @param msg: logging message
        """
        self.put(('debug', msg))

    def info(self, msg):
        """
        Generates a message as a tuple ('info', msg) and
        sends it through the put method

        @param msg: logging message
        """
        self.put(('info', msg))

    def warning(self, msg):
        """
        Generates a message as a tuple ('warning', msg) and
        sends it through the put method

        @param msg: logging message
        """
        self.put(('warning', msg))

    def error(self, msg):
        """
        Generates a message as a tuple ('error', msg) and
        sends it through the put method

        @param msg: logging message
        """
        self.put(('error', msg))

    def critical(self, msg):
        """
        Generates a message as a tuple ('critical', msg) and
        sends it through the put method

        @param msg: logging message
        """
        self.put(('critical', msg))

    def exception(self, msg):
        """
        Generates a message as a tuple ('exception', msg) and
        sends it through the put method

        @param msg: logging message
        """
        self.put(('exception', msg))

if __name__ == '__main__':
    print "\n This file does nothing on its own, it's just the %s module. \n" % __file__

########NEW FILE########
__FILENAME__ = match_hostname
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the match_hostname module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

"""
The match_hostname() function from Python 3.2, essential when using SSL.
From http://pypi.python.org/pypi/backports.ssl_match_hostname/3.2a3


"""

import re

__version__ = '3.2a3'

class CertificateError(ValueError):
    pass

def _dnsname_to_pat(dn):
    pats = []
    for frag in dn.split(r'.'):
        if frag == '*':
            # When '*' is a fragment by itself, it matches a non-empty dotless
            # fragment.
            pats.append('[^.]+')
        else:
            # Otherwise, '*' matches any dotless fragment.
            frag = re.escape(frag)
            pats.append(frag.replace(r'\*', '[^.]*'))
    return re.compile(r'\A' + r'\.'.join(pats) + r'\Z', re.IGNORECASE)

def match_hostname(cert, hostname):
    """Verify that *cert* (in decoded format as returned by
    SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 rules
    are mostly followed, but IP addresses are not accepted for *hostname*.

    CertificateError is raised on failure. On success, the function
    returns nothing.
    """
    if not cert:
        raise ValueError("empty or no certificate")
    dnsnames = []
    san = cert.get('subjectAltName', ())
    for key, value in san:
        if key == 'DNS':
            if _dnsname_to_pat(value).match(hostname):
                return
            dnsnames.append(value)
    if not san:
        # The subject is only checked when subjectAltName is empty
        for sub in cert.get('subject', ()):
            for key, value in sub:
                # XXX according to RFC 2818, the most specific Common Name
                # must be used.
                if key == 'commonName':
                    if _dnsname_to_pat(value).match(hostname):
                        return
                    dnsnames.append(value)
    if len(dnsnames) > 1:
        raise CertificateError("hostname %r "
            "doesn't match either of %s"
            % (hostname, ', '.join(map(repr, dnsnames))))
    elif len(dnsnames) == 1:
        raise CertificateError("hostname %r "
            "doesn't match %r"
            % (hostname, dnsnames[0]))
    else:
        raise CertificateError("no appropriate commonName or "
            "subjectAltName fields were found")

########NEW FILE########
__FILENAME__ = multi_queue
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Multi-channel thread-safe queue with a select-like interface.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import collections
import threading


class Empty(Exception):
    pass


class MultiQueue(object):
    """Multi-channel thread-safe queue with a select-like interface.

    A multiqueue object is initialized with a list of queue names to
    support. Messages (actually, any thing) can be put into and got from
    specific queues among those supported. It's also possible to get
    messages from a specific subset of the supported queues, ignoring
    the others.
    The meant behaviour is to have queues that emulate the well-known
    "select" system call usually available on operating systems.
    """

    def __init__(self, queues=['default']):
        self._queues = {q: collections.deque() for q in queues}
        self._cond = threading.Condition()

    def _append(self, msg, queue, insertion_strategy):
        """Insert a message in a queue using the given
        insertion strategy.
        """
        with self._cond:
            insertion_strategy(msg, self._queues[queue])
            self._cond.notify()

    def append(self, msg, queue='default'):
        """Insert a message in the right side of a queue."""
        self._append(msg, queue, lambda msg, queue: queue.append(msg))

    def appendleft(self, msg, queue='default'):
        """Insert a message in the left side of a queue.

        Alias: self.put()
        """
        self._append(msg, queue, lambda msg, queue: queue.appendleft(msg))

    def put(self, msg, queue='default'):
        """Insert a message in a queue with FIFO policy.

        Alias: self.appendleft()
        """
        self.appendleft(msg, queue)

    def _pop(self, queues, blocking, fetching_strategy):
        """Get a message from any of the selected queues using the given
        fetching strategy.
        """
        with self._cond:
            while True:
                try:
                    gen = (q for q in queues if len(self._queues[q]) > 0)
                    queue = gen.next()
                    return (fetching_strategy(self._queues[queue]), queue)
                except StopIteration:
                    # Although threading.Condition.wait() accepts an useful
                    # "timeout" parameter, when used it doesn't tell whether
                    # timeout occurred or not. This makes such functionality
                    # much less useful and it is the reason why we fell back to
                    # a boolean "blocking" parameter, which makes more sense.
                    # Damn threading.Condition.
                    if not blocking:
                        raise Empty()
                    self._cond.wait()

    def pop(self, queues=['default'], blocking=True):
        """Get a message from the right side of any of the
        selected queues.

        Alias: self.get()
        """
        return self._pop(queues, blocking, lambda queue: queue.pop())

    def popleft(self, queues=['default'], blocking=True):
        """Get a message from the left side of any of the
        selected queues.
        """
        return self._pop(queues, blocking, lambda queue: queue.popleft())

    def get(self, queues=['default'], blocking=True):
        """Get a message from any of the selected queues with FIFO policy.

        Alias: self.pop()
        """
        return self.pop(queues, blocking)

    def empty(self, queues=['default']):
        try:
            gen = (q for q in queues if len(self._queues[q]) > 0)
            gen.next()
            return False
        except StopIteration:
            return True

    def clear(self, queues=['default']):
        for queue in queues:
            self._queues[queue].clear()

    def revoke(self, msg, queue='default'):
        """Remove the given msg from the given queue, if present."""
        # TODO: implement this. Probably requiring a mapping structure.
        pass


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = repeating_timer
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the repeating_timer module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import threading

class RepeatingTimer(threading.Thread):

    def __init__(self, interval, callback, start_running=True, *args, **kwargs):
        threading.Thread.__init__(self, name=self.__class__.__name_)
        self.daemon = True
        self.interval = interval
        self.callback = callback
        self.args = args
        self.kwargs = kwargs
        self.must_die = threading.Event()
        self.running = threading.Event()
        if start_running:
            self.running.set()

    def run(self):
        while not self.must_die.is_set():
            self.running.wait()
            self.callback(*self.args, **self.kwargs)
            self.must_die.wait(self.interval)

    def pause(self):
        self.running.clear()

    def resume(self):
        self.running.set()

    def terminate(self):
        self.must_die.set()
########NEW FILE########
__FILENAME__ = scheduler
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the scheduler module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import datetime

import apscheduler.scheduler


class Scheduler(object):

    def __init__(self):
        self._backend = apscheduler.scheduler.Scheduler(daemonic=False)

    def start(self):
        self._backend.start()

    def schedule_action(
            self, func, name=None, args=None, kwargs=None,
            hours=0, minutes=0, seconds=0, repeating=False):

        if repeating:
            self._backend.add_interval_job(
                func=func, name=name, args=args, kwargs=kwargs,
                hours=hours, minutes=minutes, seconds=seconds)
        else:
            date = datetime.datetime.now() + datetime.timedelta(
                seconds=seconds, minutes=minutes, hours=hours)
            self._backend.add_date_job(
                func=func, date=date, args=args, kwargs=kwargs, name=name)

    def unschedule_action(self, func):
        try:
            self._backend.unschedule_func(func)
        except KeyError:
            pass

    def terminate(self):
        self._backend.shutdown()


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = suspendable_thread
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
A special Thread subclass for implementing "suspendable components".

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from threading import Thread, Event, Condition


class ConcurrentSuspensionException(Exception):
    ''' Raised when more than one thread try to control the same Suspendee '''
    pass


class SuspendableThread(Thread):
    '''
    A special Thread subclass for implementing "suspendable components".

    A suspended component can be asked to interrupt its execution and
    wait until she's resumed. Both suspension and resumation are thread-safe,
    and suspension honors the following postcondition: when the suspension
    call returns, the component is really suspended.
    This class is useful for those situations where one wants to stop
    another thread and needs to be sure that she has actually stopped before
    proceeding.
    The suspendable component is called "Suspendee" while its master is the
    "Suspender". There must be at most one Suspender in order to avoid
    deadlocks.
    '''

    def __init__(self, start_suspended=False, **a):
        Thread.__init__(self, **a)
        self.__must_wait = Event()
        self.__waiting = Event()
        self.__must_terminate = Event()
        self.__terminated = Event()
        self.__cond = Condition()
        if start_suspended:
            self.__must_wait.set()

    def start(self):
        '''
        Starts this thread. This method is really like the original
        threading.Thread's start() method, except it makes the caller wait,
        in the case the thread has to start suspended, until it is actually
        suspended.
        '''
        Thread.start(self)
        if self.__must_wait.is_set():
            self.__waiting.wait()

    def run(self):
        '''
        The old good threading.Thread's run() method.
        '''
        self._check_suspension()
        self._main()
        self.__terminated.set()

    def _main(self):
        '''
        Template method to implement in subclasses.
        Contains Suspendee's main logic.
        '''
        msg = u"Template method SuspendableThread._main() not implemented"
        raise Exception(msg)

    def _check_suspension(self):
        '''
        Check if suspension has been requested and suspend if so.
        Call it somewhere in your Suspendee's main logic!
        '''
        if self.__must_wait.is_set():
            self._clear_interruption()
            self.__wait_for_resume()
            return True
        return False

    def suspend_execution(self):
        '''
        The Suspender calls this in order to ask for suspension.
        Hangs until suspension is done.
        '''
        with self.__cond:
            if self.__must_wait.is_set():
                msg = u'Trying to suspend an already suspended component: '
                msg += u'class %s' % self.__class__.__name__
                raise ConcurrentSuspensionException(msg)

            if not self.__must_terminate.is_set():
                self.__must_wait.set()
                self._interrupt_execution()
                self.__cond.wait()
            else:
                # Honor the suspension postcondition
                # by waiting for a calm state
                self.__terminated.wait()

    def resume_execution(self):
        '''
        The Suspender calls this in order to ask for resumation.
        '''
        with self.__cond:
            if not self.__must_wait.is_set():
                msg = u'Trying to resume a non suspended component: '
                msg += u'class %s' % self.__class__.__name__
                raise ConcurrentSuspensionException(msg)
            # No need to check for termination, just return
            self.__must_wait.clear()
            self.__cond.notify()

    def is_suspended(self):
        '''
        Test if the Suspendee is suspended.
        '''
        return self.__waiting.is_set()

    def __wait_for_resume(self):
        '''
        Make the Suspendee hang until she's resumed.
        '''
        with self.__cond:
            if not self.__must_terminate.is_set():
                self.__waiting.set()
                self.__cond.notify()
                self.__cond.wait()
                self.__waiting.clear()

    def _interrupt_execution(self):
        '''
        Template method. The Suspendee may be blocked due to other conditions
        in her main logic. Implement this method to unlock her, making sure
        that she'll get to the _check_suspension() check.
        '''
        msg = u"Template method SuspendableThread._interrupt_execution() "
        msg += "not implemented"
        raise Exception(msg)

    def _clear_interruption(self):
        '''
        Template method. Implement it to clear the state left by
        _interrupt_execution(), if any.
        '''
        msg = u"Template method SuspendableThread._clear_interruption() "
        msg += "not implemented"
        raise Exception(msg)

    def _terminate_suspension_handling(self):
        '''
        Cancel any further call to suspend_execution(), resume_execution(),
        _wait_for_resume(). Call it from the Suspendee terminate() method.
        It's the only "suspension" method meant to be called by any thread,
        that is, not only by the Suspender.
        '''
        with self.__cond:
            self.__must_terminate.set()
            # If anyone between the Suspendee and the Suspender
            # is waiting, wake her up
            self.__cond.notify()


if __name__ == '__main__':
    # Test code

    import sys
    import time

    class Suspendee(SuspendableThread):
        ''' An simple example of suspendable component. '''
        def __init__(self):
            SuspendableThread.__init__(self)
            self._must_die = Event()

        def _interrupt_execution(self):
            pass

        def _clear_interruption(self):
            pass

        def _main(self):
            while not self._must_die.is_set():
                self._check_suspension()
                print >> sys.stderr, '.',
                time.sleep(0.2)

        def terminate(self):
            self._must_die.set()
            self._terminate_suspension_handling()

    COMPONENT = Suspendee()
    COMPONENT.start()
    c = '_'
    while c[0] != 'q':
        c = sys.stdin.readline()
        if c[0] == 'COMPONENT':
            COMPONENT.suspend_execution()
        if c[0] == 'r':
            COMPONENT.resume_execution()
        time.sleep(0.2)
    COMPONENT.terminate()

########NEW FILE########
__FILENAME__ = utilities
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the utilities module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import sys
import os
import time
import calendar
import json
import pickle
import hashlib
import subprocess


def get_hash(obj):
    """
    Return an hash representation of the given object

    @param obj: Any picklable thing
    @return An hash representation (e.g. MD5) of the given object
    """
    obj_dump = pickle.dumps(obj)
    return hashlib.md5(obj_dump).hexdigest()


def nbgetch():
    """
    Non-blocking read a single character from standard input

    @return A character if available, or False if stdin is empty.
    """
    try:
        # Windows
        import msvcrt
        if msvcrt.kbhit():
            return msvcrt.getch()
        else:
            return False
    except ImportError:
        # Unix
        import termios
        import fcntl
        fd = sys.stdin.fileno()
        # Set stdin attributes:
        try:
            oldterm = termios.tcgetattr(fd)
            newattr = termios.tcgetattr(fd)
            # non canonical mode == non buffered stdin
            newattr[3] = newattr[3] & ~termios.ICANON & ~termios.ECHO
            termios.tcsetattr(fd, termios.TCSANOW, newattr)
            # Non blocking mode
            oldflags = fcntl.fcntl(fd, fcntl.F_GETFL)
            fcntl.fcntl(fd, fcntl.F_SETFL, oldflags | os.O_NONBLOCK)
        except Exception:
            # if something goes wrong the terminal might not support it
            # e.g. when running into a debugger
            return False

        try:
            return sys.stdin.read(1)
        except IOError:
            return False
        finally:
            termios.tcsetattr(fd, termios.TCSAFLUSH, oldterm)
            fcntl.fcntl(fd, fcntl.F_SETFL, oldflags)


def increase_exponentially(timer, max_value=float("inf"), min_value=1):
    """
    Return a value multiplied by 2, in the given value range.

    @param timer:
                Numeric value
    @param max_value:
                Maximum value that can be returned
    @param min_value:
                Minimum value that can be returned
    @return
                The value of "timer" multiplied by 2
    """
    if timer < min_value:
        return min_value
    return min(timer * 2, max_value)


def exponential_backoff_waiting(waiting_time, max_waiting_time=0):
    """
    Make the current thread sleep for an interval of time that increases
    exponentially on each call.

    @param waiting_time:
                Number of seconds to sleep
    @param max_waiting_time:
                Maximum number of seconds to sleep. If it is zero, there
                is no maximum.
    @return
                Minimum between "waiting_time" multiplied by 2 and
                "max_waiting_time" (if different from zero)
    """
    wait_for = waiting_time
    if max_waiting_time > 0 and waiting_time > max_waiting_time:
        wait_for = max_waiting_time

    slept = 0
    while slept < wait_for:
        time.sleep(1)
        slept += 1

    wait_for *= 2
    if max_waiting_time > 0 and wait_for > max_waiting_time:
        wait_for = max_waiting_time
    return wait_for


def stoppable_exponential_backoff_waiting(waiting_time,
                                          event,
                                          max_waiting_time=0):
    """
    Make the current thread sleep for an interval of time that increases
    exponentially on each call. The sleeping can be interrupted by an
    external event.

    @param waiting_time:
                Number of seconds to sleep
    @param max_waiting_time:
                Maximum number of seconds to sleep. If it is zero, there
                is no maximum.
    @param event:
                Instance of threading.Event. When set, it interrupts
                the sleeping.
    @return
            Minimum between "waiting_time" multiplied by 2 and
            "max_waiting_time" (if different from zero)
    """
    # TODO: merge with the exponential_backoff_waiting function
    slept = 0
    while not event.is_set() and slept < waiting_time:
        time.sleep(1)
        slept += 1

    waiting_time *= 2
    if max_waiting_time > 0 and waiting_time > max_waiting_time:
        waiting_time = max_waiting_time
    return waiting_time


def install_excepthook_for_threads():
    """
    Emulate sys.excepthook for threads different from the main thread.

    Described at:
    http://spyced.blogspot.com/2007/06/workaround-for-sysexcepthook-bug.html

    https://sourceforge.net/tracker/?func=detail&atid=105470&aid=1230540&group_id=5470.

    Call once from __main__ before creating any threads.
    If using psyco, call psyco.cannotcompile(threading.Thread.run)
    since this replaces a new-style class method.
    """
    import threading
    init_old = threading.Thread.__init__

    def init(self, *args, **kwargs):
        init_old(self, *args, **kwargs)
        run_old = self.run

        def run_with_except_hook(*args, **kw):
            try:
                run_old(*args, **kw)
            except (KeyboardInterrupt, SystemExit):
                raise
            except:
                sys.excepthook(*sys.exc_info())

        self.run = run_with_except_hook
    threading.Thread.__init__ = init


def format_bytes(bytes):
    """
    Format a size in bytes into a human-readable string.

    @param bytes: An integer number of bytes
    @return Human-readable string of "bytes"
    """
    units = ['Bytes', 'Kb', 'Mb', 'Gb', 'Tb', 'Pb']

    def format_float(number):
        return ('%.1f' % number).rstrip('0').rstrip('.')

    bytes_ = float(bytes)
    value = 0
    for pos in xrange(0, len(units)):
        value = pos
        if bytes < 2 ** ((pos + 1) * 10):
            break
    human_repr = bytes_ / 2 ** (value * 10)
    return '%s %s' % (format_float(human_repr), units[value])


def format_to_log(obj):
    """
    Dump any data structure into a human-readable text format.

    @param obj: Any thing that can be serialized.
    @return A json version of "obj".
    """
    try:
        return json.dumps(obj, indent=3, encoding='utf-8')
    except TypeError:
        return obj


def get_unix_and_local_timestamp():
    """
    Get the current time as unix timestamp and localtime.

    @return a tuple: (seconds since the epoc, localtime string formatted)
    """
    gmtime_struct = time.gmtime()
    unix_gmtime = calendar.timegm(gmtime_struct)
    local_time_struct = time.localtime(unix_gmtime)
    string_localtime = time.asctime(local_time_struct)
    return unix_gmtime, string_localtime


def convert_line_endings(temp, mode=None):
    """
    Normalizes line-endings across platforms (Unix, OSX, Windows).

    Adapted from:
    http://code.activestate.com/recipes/66434-change-line-endings/

    @param temp:
                String whose line-endings must be normalized
    @param mode:
                Target line-ending mode for the conversion: 'unix',
                'osx', 'windows' or None. If None is given, the correct
                line-ending for the current platform is auto-detected.
    @return
                The value of "temp" with line-endings in the "mode" format.
    """
    if mode is None:
        import os
        if os.linesep == '\r\n':
            mode = 'windows'
        elif os.linesep == '\r':
            mode = 'osx'
        else:
            mode = 'unix'

    import string
    if mode == 'unix':
        temp = string.replace(temp, '\r\n', '\n')
        temp = string.replace(temp, '\r', '\n')
    elif mode == 'osx':
        temp = string.replace(temp, '\r\n', '\r')
        temp = string.replace(temp, '\n', '\r')
    elif mode == 'windows':
        import re
        temp = re.sub("\r(?!\n)|(?<!\r)\n", "\r\n", temp)
    else:
        raise ValueError('Bad line separator mode: %r' % mode)

    return temp


def _try_remove(pathname, logger=None):
    max_retry = 2
    for i in range(max_retry):
        try:
            os.remove(pathname)
        except Exception:
            if logger is not None:
                logger.debug(u"Failed to delete %s" % pathname)
            if i == (max_retry-1):
                if logger is not None:
                    logger.debug("Giving up on %s deletion" % pathname)
            else:
                if logger is not None:
                    logger.debug(u"I'll retry after one second")
                time.sleep(1)
        else:
            if logger is not None:
                logger.debug(u'File %s deleted' % pathname)
            break


def open_folder_in_system_shell(folder_path):
    """Open the given folder path in the system shell.
    """
    if not os.path.isdir(folder_path):
        return

    if sys.platform.startswith('linux'):
        os.system('xdg-open %s' % folder_path)

    elif sys.platform.startswith('win'):
        subprocess.Popen('explorer "%s"' % folder_path)

    elif sys.platform.startswith('darwin'):
        os.system('open %s' % folder_path)


#_replace_with_slash_pattern=re.compile("/\./|//")
#_forbidden_pattern=re.compile("/\./|//|(/$)|/\.\./|(/\.\.$)")

#def fastnormpath(p):
    #"""This is a fast replacement of os.path.normpath() for all
    #cases that are useful in this software. That is,
    #it replaces one occurrence of "/./" and "//" with "/",
    #delete one trailing "/". Ignore "/../" and "/.." at the end.
    #It checks for normalized path with an assertion at the end so
    #that any use that returns a not normalized path is trapped.
    #"""

    #np=re.sub(_replace_with_slash_pattern, "/", p)
    #if np[-1]=="/":
        #np=np[:-1]

    #assert not re.search(_forbidden_pattern, np)
    #return np


# fastjoin() optimization has been reverted because it does not work in all cases.

#def fastjoin(p1, p2):
    #"""This is a fast replecement of os.path.join with some semantic
    #differences. It just concats p1 and p2 with the right separator.
    #"""
    #if len(p1)==0:
        #p=p2
    #else:
        #p=p1+os.sep+p2
    #assert p==os.path.join(p1,p2)
    #return p


def fastjoin(p1, p2):
    return os.path.join(p1, p2)


def fastrelpath(path, start):
    """This is a fast replacement of os.path.relpath()
    with a slightly different semantic useful for typicall
    use cases. That is, stript the first len(start) characters
    of path. It checks by "assert" that what has been strept is
    equal to start.
    Parameter start must end with  '/'.
    If start==path then '' is returned.
    """
    assert path[-3:] != "/.."
    assert path[-2:] != "/."
    assert path.find("/./") == -1
    assert path.find("/../") == -1
    assert path.find("//") == -1

    startpath = start
    startlength = len(startpath)
    S = len(os.sep)
    assert path[:startlength] == startpath

    try:
        if path[startlength:startlength + S] == os.sep:
            startlength += S
    except IndexError:
        pass
    relativepath = path[startlength:]

    assert len(relativepath) == 0 or relativepath[:S] != os.sep
    assert (relativepath if len(relativepath) > 0 else '.') \
        == os.path.relpath(path, start)

    return relativepath


if sys.platform.startswith("win"):
    def fastnormpath(p):
        """This is a fast replacement of os.path.normpath() for all
        cases that are useful in this software. That is,
        it replaces one occurrence of "//" with "/",
        delete one trailing "/". Ignore "/../", "/.." at the end.
        It checks for normalized path with an assertion at the end so
        that any use that returns a not normalized path is trapped.
        """
        np0 = p.replace("\\", "/")
        np = np0.replace("//", "/")

        if np[-1] == "/":
            np = np[:-1]

        assert np[-1] != "/"
        assert np[-3:] != "/.."
        assert np[-2:] != "/."
        assert np.find("/./") == -1
        assert np.find("/../") == -1
        assert np.find("//") == -1

        np2 = np.replace("/", "\\")

        assert np2 == os.path.normpath(p)
        return np2

else:
    def fastnormpath(p):
        """This is a fast replacement of os.path.normpath() for all
        cases that are useful in this software. That is,
        it replaces one occurrence of "//" with "/",
        delete one trailing "/". Ignore "/../", "/.." at the end.
        It checks for normalized path with an assertion at the end so
        that any use that returns a not normalized path is trapped.
        """
        np = p.replace("//", "/")

        if np[-1] == "/":
            np = np[:-1]

        assert np[-1] != "/"
        assert np[-3:] != "/.."
        assert np[-2:] != "/."
        assert np.find("/./") == -1
        assert np.find("/../") == -1
        assert np.find("//") == -1
        assert np == os.path.normpath(p)

        return np


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = warebox
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Interface toward the warebox.

In FileRock internal vocabulary, the "warebox" is the directory in the
filesystem of the user that holds the data and that is kept synchronized
by FileRock with the remote storage.
This module contains interfaces for accessing and modifying the warebox.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os
import hashlib
import contextlib
import binascii
import sys
import stat
import time
import datetime
import distutils.dir_util
import shutil
from StringIO import StringIO

from filerockclient.exceptions import FileRockException, ExecutionInterrupted
from filerockclient.databases.warebox_cache import WareboxCache
from filerockclient.blacklist.blacklist import Blacklist
from filerockclient.blacklist.blacklisted_expressions import \
    BLACKLISTED_DIRS, BLACKLISTED_FILES, CONTAINS_PATTERN, EXTENTIONS
from filerockclient import config
from filerockclient.util.utilities import fastnormpath, fastrelpath, fastjoin

MAX_ATTEMPTS_ON_MOVE = 3

BLACKLISTED_DIR = config.BLACKLISTED_DIR

# Note: pathnames in this list are absolute, i.e. 'filename.txt' matches only
# if the file is in the root of the warebox.
# You can use the * wildcard in the same way as the UNIX ls command.

BLACKLISTED_DIRS.append(BLACKLISTED_DIR + '/*')


class CantReadPathnameException(FileRockException):
    """Exception raised due to failing in interacting with the filesystem"""

    pass


class CantWritePathnameException(FileRockException):
    """Exception raised due to failing in interacting with the filesystem"""

    def __init__(self, *argc, **kwdn):
        Exception.__init__(self, *argc)
        self.source = None
        self.errno = None
        self.strerror = None
        self.filename = None
        for key in kwdn:
            self.__setattr__(key, kwdn[key])


class WareboxPathIsAFileException(FileRockException):
    pass


class Warebox(object):
    """
    Interface toward the warebox.

    In FileRock internal vocabulary, the "warebox" is a directory in the
    filesystem of the user that holds the data and that is kept
    synchronized by FileRock with the remote storage.

    This class is the interface to access or modify the content of the
    warebox. Each element in the warebox is identified by a relative
    pathname, using the UNIX style directory separator (forward slash,
    "/"). By convention, a pathname that identifies a directory always
    end with a separator.

    The Warebox class features a blacklist for its content, so that
    blacklisted pathnames won't be returned by queries.
    """

    def __init__(self, cfg):
        """
        @param cfg:
                    Instance of filerockclient.config.ConfigManager.
        """
        path = cfg.get('Application Paths', 'warebox_path')
        assert path.__class__.__name__ == 'unicode', \
            'Non unicode-ness detected in Warebox.__init__: %r' % path
        self._warebox_path = path
#        self._logger = logging.getLogger("FR." + self.__class__.__name__)
#        self.logger = self._logger
        self._check_warebox()
        self._check_blacklisted_dir()
#         self._clean_temp_dir()
        self.blacklist = Blacklist(BLACKLISTED_DIRS,
                                   BLACKLISTED_FILES,
                                   CONTAINS_PATTERN,
                                   EXTENTIONS)
        self.cache = WareboxCache(cfg.get('Application Paths',
                                          'warebox_cache_db'))

    def get_warebox_path(self):
        """
        @return The filesystem absolute pathname of the warebox.
        """
        return self._warebox_path

    def absolute_pathname(self, internal_pathname):
        """Convert a warebox relative pathname into the corresponding
        filesystem absolute pathname.

        @param internal_pathname:
                    A pathname relative to the warebox.
        @return
                    The filesystem absolute version of internal_pathname.
        """

        absolute_name = fastjoin(self._warebox_path, internal_pathname)
        n = fastnormpath(absolute_name)
        return n

    def internal_pathname(self, absolute_pathname):
        """Convert a filesystem absolute pathname into a warebox
        relative pathname.

        An internal pathname has the following properties:
        * it is relative to the warebox root
        * it uses forward slashes as separators
        * it has a trailing forward slash IFF it represents a directory

        This method raises :class:`ValueError` if `absolute_pathname` is
        not contained in the warebox.

        @param absolute_pathname:
                    A filesystem absolute pathname.
        """

        relative_name = os.path.relpath(absolute_pathname, self._warebox_path)

        if relative_name.startswith('..'+os.sep):
            raise ValueError('"%r" is not contained in the warebox'
                             % absolute_pathname)

        if os.path.isdir(absolute_pathname):
            relative_name += '/'

        if sys.platform.startswith('win'):
            relative_name = relative_name.replace('\\', '/')
        return relative_name

    def _clean_temp_dir(self):
        """Delete everything from the temporary directory.

        The warebox contains an hidden special folder used by FileRock
        as a working directory. It doesn't get synchronized along with
        the user data.
        """
        blacklisted_dir = self.absolute_pathname(BLACKLISTED_DIR)
        for the_file in os.listdir(blacklisted_dir):
            file_path = os.path.join(blacklisted_dir, the_file)
            try:
                if os.path.isfile(file_path):
                    os.unlink(file_path)
            except Exception:
                pass

    def _check_blacklisted_dir(self):
        """Create the temporary directory, if it doesn't exist.
        """
        blacklisted_dir = self.absolute_pathname(BLACKLISTED_DIR)
        if self._check_warebox():
            if os.path.exists(blacklisted_dir) and os.path.isdir(blacklisted_dir):
                if sys.platform.startswith('win'):
                    import win32con
                    import win32file
                    #make the file hidden
                    win32file.SetFileAttributesW(
                        blacklisted_dir, win32con.FILE_ATTRIBUTE_HIDDEN)
                return True
            elif os.path.exists(blacklisted_dir) and not os.path.isdir(blacklisted_dir):
                os.unlink(blacklisted_dir)
            elif not os.path.exists(blacklisted_dir):
                self.make_directory(BLACKLISTED_DIR)
                if sys.platform.startswith('win'):
                    import win32con
                    import win32file
                    #make the file hidden
                    win32file.SetFileAttributesW(
                        blacklisted_dir, win32con.FILE_ATTRIBUTE_HIDDEN)

    def _check_warebox(self):
        """Check for warebox inexistence and create it if needed.
        If warebox exists it must be empty, raise an exception otherwise.
        """
        if os.path.exists(self._warebox_path) and os.path.isdir(self._warebox_path):
            return True

        if os.path.exists(self._warebox_path) and not os.path.isdir(self._warebox_path):
            raise WareboxPathIsAFileException('Warebox path MUST be a directory')

        if not os.path.exists(self._warebox_path):
            os.mkdir(self._warebox_path)

    def is_directory(self, pathname):
        """Tells if a pathname corresponds to a directory.

        @param pathname:
                    A warebox relative pathname.
        @return
                    Boolean.
        """
        return pathname.endswith('/')

    def open(self, pathname, mode='r'):
        """Opens a pathname in the Warebox and returns an handle to it,
        just as the standard "open" call would do.

        Directories are opened as well and can be treated as normal
        files.
        Raises CantReadPathnameException if the pathname can't be opened
        for any reason related to filesystem access.

        @param pathname:
                A warebox relative pathname.
        @return
                A file-like object.
        """
        if self.is_directory(pathname):
            return contextlib.closing(StringIO(''))
        abs_path = self.absolute_pathname(pathname)
        counter = 0
        handle = None
        while counter < 3:
            try:
                if mode.find('b') == -1:
                    mode += 'b'
                handle = open(abs_path, mode)
                break
            except IOError as e:
                error = repr(e)
                counter = counter + 1
                time.sleep(1)
        if handle is None:
            if mode.find('w') == -1:
                excp = CantReadPathnameException
            else:
                excp = CantWritePathnameException
            exc = excp('Warebox.open(%r): %r' % (abs_path, error))
            exc.errno = None
            raise exc
        return handle

    def make_directory(self, pathname):
        """Create a new directory in the warebox.

        All folder in pathname_new must exist.

        @param pathname:
                    Warebox relative pathname, the directory to create.
        """
        abs_path = self.absolute_pathname(pathname)
        try:
            os.mkdir(abs_path)
        except Exception as e:
            exc = CantWritePathnameException(
                u'Warebox.make_directory(%r): %r' % (abs_path, e))
            exc.errno = e.errno if hasattr(e, 'errno') else None
            raise exc

    def make_directories_to(self, pathname):
        """Create all directories in pathname.

        If the rightmost name ends with a '/', then it's a directory and
        it's created as well.

        @param pathname:
                    A warebox relative pathname.
        """
        basepath, _ = os.path.split(pathname)
        abs_path = self.absolute_pathname(basepath)
        try:
            distutils.dir_util.mkpath(abs_path)
        except Exception as e:
            exc = CantWritePathnameException(
                u'Warebox.make_directories_to(%r): %r' % (abs_path, e))
            exc.errno = e.errno if hasattr(e, 'errno') else None
            raise exc

    def delete(self, pathname):
        """Delete a pathname from the warebox.

        If pathname is a directory then it must be empty.

        @param pathname:
                    A warebox relative pathname.
        """
        abs_path = self.absolute_pathname(pathname)
        try:
            if self.is_directory(pathname):
                os.rmdir(abs_path)
            else:
                os.remove(abs_path)
        except Exception as e:
            exc = CantWritePathnameException(
                u'Warebox.delete(%r): %r' % (abs_path, e))
            exc.errno = e.errno if hasattr(e, 'errno') else None
            raise exc

    def delete_tree(self, pathname):
        """Delete a whole subtree from the warebox.

        @param pathname:
                    A warebox relative pathname.
        """
        abs_path = self.absolute_pathname(pathname)
        try:
            if self.is_directory(pathname):
                shutil.rmtree(abs_path)
            else:
                os.remove(abs_path)
        except Exception as e:
            exc = CantWritePathnameException(
                u'Warebox.delete_tree(%r): %r' % (abs_path, e))
            exc.errno = e.errno if hasattr(e, 'errno') else None
            raise exc

    def _assert_unicode(self, pathname, warebox_path, folder,
                        abs_folder, prefix, filename):
        """Test if any of the arguments is not an unicode object.

        Geez, unicode errors are very irritating.
        """
        assert type(pathname) == unicode
        assert type(warebox_path) == unicode
        assert type(folder) == unicode
        assert type(abs_folder) == unicode
        assert type(prefix) == unicode
        assert type(filename) == unicode

    def is_blacklisted(self, pathname):
        """Tell whether the given pathname is blacklisted.

        @param pathname:
                    A warebox relative pathname.
        @return
                    Boolean.
        """
        return self.blacklist.is_blacklisted(pathname)

    def get_blacklist_hash(self):
        """
        @return An hash representing the current blacklist.
        """
        return self.blacklist.get_hash()

    def _can_i_add_this_file(self, active_blacklist, rel_pathname):
        """Tell whether a pathname could be created in the warebox.

        It couldn't if it already exists or is blacklisted.

        @param active_blacklist:
                    Boolean telling whether the blacklist is active.
        @param rel_pathname:
                    A warebox relative pathname.
        @return
                    Boolean.
        """
        abspath = self.absolute_pathname(rel_pathname)
        blacklisted = active_blacklist and self.is_blacklisted(rel_pathname)
        if blacklisted:
            return False
        try:
            statresult = os.stat(abspath)
        except os.error:
            return False

        return stat.S_ISREG(statresult.st_mode)

    def _check_interruption(self, interruption):
        if interruption is not None and interruption.is_set():
            raise ExecutionInterrupted()

    def get_content(self,
                    folder=u'',
                    recursive=True,
                    blacklisted=True,
                    interruption=None):
        """Get the list of pathnames contained in the given folder.

        If "folder" is omitted than a list of the whole Warebox is
        returned.

        @param folder:
                    A warebox relative directory of the warebox to whom
                    read the content.
        @param recursive:
                    Boolean telling whether the scan should be recursive.
        @param blacklisted:
                    Boolean telling whether blacklisted pathnames must
                    be returned too.
        @return
                    List of pathnames.
        """
        pathnames = []
        abs_folder = self.absolute_pathname(folder)

        for curr_folder, contained_folders, contained_files in os.walk(abs_folder):
            self._check_interruption(interruption)
            folders_to_not_walk_into = []
            #prefix = os.path.relpath(curr_folder, self._warebox_path)
            #if prefix == u'.':
                #prefix = u''
            prefix = fastrelpath(curr_folder, self._warebox_path)

            for a_folder in contained_folders:
                self._check_interruption(interruption)
                _a_folder = fastjoin(prefix, a_folder)
                _a_folder = _a_folder.replace('\\', '/')  # Damn Windows
                _a_folder += '/' if not _a_folder.endswith('/') else ''
                if not blacklisted or not self.is_blacklisted(_a_folder):
                    pathnames.append(_a_folder)
                else:
                    folders_to_not_walk_into.append(a_folder)

                # It seems that get_content() can return non-unicode pathnames.
                # This guard checks against it.
                self._assert_unicode(
                    _a_folder, self._warebox_path, folder,
                    abs_folder, prefix, a_folder)

            for folder in folders_to_not_walk_into:
                contained_folders.remove(folder)

            for a_file in contained_files:
                self._check_interruption(interruption)
                _a_file = fastjoin(prefix, a_file)
                _a_file = _a_file.replace('\\', '/')  # Damn Windows
                if self._can_i_add_this_file(blacklisted, _a_file):
                    pathnames.append(_a_file)

                # It seems that get_content() can return non-unicode pathnames.
                # This guard checks against it.
                self._assert_unicode(
                    _a_file, self._warebox_path, folder,
                    abs_folder, prefix, a_file)

            if not recursive:
                break

        all_pathnames = set(self.cache.get_all_keys())
        self.cache.delete_records(all_pathnames.difference(set(pathnames)))
        return pathnames

    def get_size(self, pathname):
        """
        @param pathname:
                    A warebox relative pathname.
        @return
                    The size in byte of "pathname" as read from the
                    filesystem. Directories have size 0.
        """
        if not self.is_directory(pathname):
            return os.stat(self.absolute_pathname(pathname))[stat.ST_SIZE]
            #os.path.getsize(self._absolute_pathname(pathname))
        else:
            return 0

    def get_last_modification_time(self, pathname):
        """
        @param pathname:
                    A warebox relative pathname.
        @return
                    The time of last modification of "pathname" as read
                    from the filesystem. The max between creation time
                    and modification time is returned.
        """
        abs_path = self.absolute_pathname(pathname)
        try:
            lmtime = os.stat(abs_path)[stat.ST_MTIME]
            lmtime = datetime.datetime.fromtimestamp(lmtime)
            return lmtime
        except Exception as e:
            exc = CantReadPathnameException(
                u'Warebox.get_last_modification_time(%r): %r' % (abs_path, e))
            exc.errno = e.errno if hasattr(e, 'errno') else None
            raise exc

    def _is_new(self, pathname):
        """Tell whether a pathname is not contained in the internal cache.

        @param pathname:
                    A warebox relative pathname.
        @return
                    Boolean.
        """
        if self.cache.exist_record(pathname):
            _, csize, clmtime, cetag = self.cache.get_record(pathname)
            if (clmtime == unicode(self.get_last_modification_time(pathname)))\
            and (csize) == self.get_size(pathname):
                return False
        return True

    def compute_md5(self, pathname):
        """Compute the binary MD5 hash of the given pathname.

        Raises CantReadPathnameException is the pathname can't be opened
        for any reason related to filesystem access.

        @param pathname:
                    A warebox relative pathname.
        @return
                    The binary MD5 hash of the pathname content.
        """

        def aux():
            """Auxiliary function which actually does the work."""
            md5 = hashlib.md5()
            with self.open(pathname) as file_:
                for chunk in iter(lambda: file_.read(8192), ''):
                    md5.update(chunk)
            return md5.digest()

        counter = 0
        final_md5 = None
        lmtime = self.get_last_modification_time(pathname)
        size = self.get_size(pathname)

        potential_md5 = aux()

        if lmtime == self.get_last_modification_time(pathname) \
        and size == self.get_size(pathname):
            final_md5 = potential_md5
        else:
            while counter < 2:
                another_md5 = aux()
                if another_md5 == potential_md5:
                    final_md5 = potential_md5
                    break
                potential_md5 = another_md5
                counter = counter + 1
                time.sleep(1)
        if final_md5 is None:
            exc = CantReadPathnameException(
                'Warebox.compute_md5(%s)' % repr(pathname))
            exc.errno = None

        return final_md5

    def _update_cache(self, pathname, md5_hex):
        """Update the internal cache with the given data.

        @param pathname:
                    A warebox relative pathname.
        @param md5_hex:
                    The hexadecimal MD5 hash of the pathname content.
        """
        if self.cache.exist_record(pathname):
            self.cache.update_record_fields(
                pathname,
                size=self.get_size(pathname),
                lmtime=self.get_last_modification_time(pathname),
                etag=md5_hex)
        else:
            self.cache.update_record(
                unicode(pathname),
                self.get_size(pathname),
                self.get_last_modification_time(pathname),
                md5_hex)

    def compute_md5_hex(self, pathname):
        """Compute the hexadecimal text representation of the MD5 hash
        of the given pathname's data.

        @param pathname:
                    A warebox relative pathname.
        @return
                    The hexadecimal MD5 hash of the pathname content.
        """
        if not self._is_new(pathname):
            _, _, _, etag = self.cache.get_record(pathname)
            return etag

        md5_hex = binascii.hexlify(self.compute_md5(pathname))
        self._update_cache(pathname, md5_hex)

        return md5_hex

    def rename(self, pathname_from, pathname_to, prefix=None):
        """Rename an element in the warebox.

        All directories in pathname_to must exist.

        @param pathname_from:
                    A warebox relative pathname.
        @param pathname_to:
                    A warebox relative pathname.
        @param prefix:
                    A string to append to the destination pathname.
        """
        # TODO: why is the third parameter called prefix and not suffix!?
        source = self.absolute_pathname(pathname_from)
        target = self.absolute_pathname(pathname_to)
        try:
            return self._try_move(source, target, prefix)
        except CantWritePathnameException:
            raise
        except Exception as e:
            raise CantWritePathnameException(e.message)

    def _find_new_name(self, pathname, prefix='Conflicted'):
        """Tries to find a non-existing pathname using the format:
            pathname (prefix on YYYY-mm-DD HH_MM_SS_####).ext

        @param pathname:
                    A warebox relative pathname.
        @param prefix:
                    A string to append to the destination pathname.
        @return
                    A new pathname in the warebox.
        """
        found = False
        while not found:
            curr_time = datetime.datetime.now().strftime('%Y-%m-%d %H_%M_%S_%f')
            suffix_str = u' ({prefix} on {timestr})'
            suffix = suffix_str.format(prefix=prefix, timestr=curr_time)
            basename, ext = os.path.splitext(pathname)
            new_pathname = basename + suffix + ext
            if not os.path.exists(new_pathname):
                found = True
        return new_pathname

    def _try_move(self, src, dest, prefix=None):
        """Try to rename src to dest.

        If a prefix is passed it will used for search for a new dest name
        (check _find_new_name method)
        If it fails MAX_ATTEMPTS_ON_MOVE times an Exceptions will raised
        returns True in case of success
        """
        max_attempts = MAX_ATTEMPTS_ON_MOVE
        destination = dest
#        initial_msg = u"Moving {src} to {dest}..."
#        success_msg = u"{src} moved to {dest}"
#        fail_msg = u"file {dest} exists, I'll try to find a new name"
        error_msg = u"Maximum attempts reached on move {src} to {dest}"

        while max_attempts > 0:
            if prefix:
                destination = self._find_new_name(dest, prefix)
            try:
                if os.path.exists(src):
                    os.rename(src, destination)
                    return destination
            except IOError as e:
                if e.errno == 17:
                    # file exists
                    max_attempts -= 1
                    continue
                else:
                    raise CantWritePathnameException(
                        e.message, errno=e.errno, filename=e.filename,
                        strerror=e.strerror, source=src)
        if max_attempts == 0:
            log_str = error_msg.format(src=src, dest=dest)
            raise CantWritePathnameException(log_str, source=src, filename=dest)

    def move(self, source, relative_destination, isconflicted=False):
        """
        Moves the source file in the warebox.

        if realtive_destination exists a Conflicted copy will created:
            dest = wareboxpath/relative_destination
            move source to "dest (New on ...).ext"
            move dest to "dest (Conflicted on ...).ext"
            move "dest (New on ...).ext" to dest.ext
        else:
            move source to dest

        @param source:
                    A warebox relative pathname.
        @param relative_destination:
                    A warebox relative pathname.
        @param isconflicted:
                    Boolean telling whether source is a conflicted
                    pathname.
        """
        # TODO: isn't this a duplicate of the rename() method?
        # The Warebox class shouldn't be aware of conflicts!

#        new_file=None
#        conflicted=None
#        result=None
#
#        initial_msg =  u"Moving {src} to {dest}..."
#        conflict_msg = u"{dest} file exists, i'll backup it"
#        success_msg = u"{conflicted} was created\n\
#                       {new_file} was created and then renamed to {result}"
        dest = self.absolute_pathname(relative_destination)
        if os.path.exists(source) and os.path.isfile(source):
            if os.path.exists(dest) and os.path.isfile(dest):
                if self.compute_md5_hex(source) == self.compute_md5_hex(dest):
                    #The same file
                    return
                try:
#                    new_file = self._try_move(source, dest, 'New')
                    if isconflicted:
#                        conflicted = self._try_move(dest, dest, 'Conflicted')
                        self._try_move(dest, dest, 'Conflicted')
                    else:
                        os.unlink(dest)
#                    result = self._try_move(source, dest)
                    self._try_move(source, dest)
                except CantWritePathnameException:
                    raise
                except Exception as e:
                    raise CantWritePathnameException(e,
                                                     filename=dest,
                                                     source=source)
            else:
                # No Conflict
                try:
                    self._try_move(source, dest)
                except CantWritePathnameException:
                    raise
                except Exception as e:
                    raise CantWritePathnameException(e)


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = bandwidth
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Bandwidth limit module

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""
from time import time, sleep
from threading import Lock

FROM_KBIT_TO_BYTE = 122
FROM_KB_TO_BYTE = 1024

CHUNK_SIZE = 1024

class Bandwidth(object):
    
    def __init__(self, limit, max_chunk_size=CHUNK_SIZE):
        self.start =  time()
        self.max_chunk_size = max_chunk_size
        self.limit = limit * FROM_KB_TO_BYTE
        if (limit <= 0):
            self.limit=0     
#         print "KB/s LIMIT %s " % (self.limit/1024)
        self._reset_limit()
        self.lock = Lock()
    
    def _reset_limit(self):
        self.remaining = self.limit    

    def _check_timer(self):
        now = time()
        elapsed = now-self.start
        if (elapsed) > 1:
            self.start = now
            self._reset_limit()


    def _remaining(self):
        now = time()
        diff = (now-self.start)
        if (diff < 1) and (diff > 0):
            return (1-diff)
        else:
            return 0
        
    def _next_chunk_len(self):
        to_send = self.remaining - self.remaining/2
        self.remaining /= 2
        return to_send
    
    def _is_enabled(self):
        return (self.limit > 0)
        
    def byte_to_send(self):
        if not self._is_enabled():
            return self.max_chunk_size
        with self.lock:
            while True:
                self._check_timer()
                to_send = self._next_chunk_len()
                if to_send > 0:
                    break
                else:
                    sleep(self._remaining())
            return to_send
########NEW FILE########
__FILENAME__ = connector
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the connector module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import Queue, logging
from worker_watcher import WorkerWatcher as AbstractWorkerWatcher


class Connector(object):

    def __init__(self, index, statuses, resultsQueue, freeWorkers):
        """
        Launches and connects single thread (workerwatcher) with a queue

        @param index: an index
        @param statuses: lists [off, free, working] containing the stopped worker
        @param resultsQueue: output queue, the complete/rejected/aborted tasks are sent back through it
        @param freeWorkers: threading.semaphore instance, counts the free workers
        @param loglevel: as the name tell, set the level of logger
        """

        self.queue = Queue.Queue()
        self.worker = None
        self.off = statuses['off']
        self.free = statuses['free']
        self.working = statuses['working']
        self.resultsQueue = resultsQueue
        self.freeWorker = freeWorkers
        self.index = index

        logger_prefix = "FR.Filter."
        self.logger = logging.getLogger(logger_prefix+self.__class__.__name__)

        self._on_init()

        self.status = self.off
        self.off.append(self)
        self.logger.debug(u"Starting...")

    def send_msg(self, msg):
        """
        Sends a message (task) to the associated WorkerWatcher

        @param msg: the task to send to the workerwatcher
        """
        self.logger.debug(u"Sending enc/dec task for %s", msg)
        self.queue.put(msg)


    def terminate(self):
        """
        Sends termination message to the associated WorkerWatcher
        """
        self.logger.debug(u"Sending termination task")
        self.send_msg(None)

    def set_free(self):
        """
        Moves the Connector in the free list and call the release on worker Semaphore
        """
        self.status.remove(self)
        self.free.append(self)
        self.status = self.free
        self.freeWorker.release()


    def set_off(self):
        """
        Moves the Connector in the off list
        """
        self.status.remove(self)
        self.off.append(self)
        self.status = self.off

    def set_working(self, task):
        """
        Moves the Connector in the working list and send a task to the thread

        @param task: the task to send to workerwatcher
        """
        self.status.remove(self)
        self.working.append(self)
        self.status = self.working
        self.send_msg(task)



    def send_task_back(self, task):
        """
        Sends the task back putting it on result queue

        @param task: the task to send back
        """
        self.logger.debug(u"Sending task on %s back" % task.pathname)
        self.resultsQueue.put(task, 'operation')


    ##########################
    # Overridable
    ##########################

    def _on_init(self):
        '''
        Override this method to execute custom actions on connector init
        '''
        self.WorkerWatcher = AbstractWorkerWatcher

    def start_WorkerWatcher(self):
        """
        Override this method if you want pass more parameter to WorkerWatcher
        """
        self.worker = self.WorkerWatcher(self.index, self.queue, self)
        self.worker.start()

########NEW FILE########
__FILENAME__ = filter
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the filter module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import threading, Queue, logging

from connector import Connector as AbstractConnector


WAIT_SEC_BEFORE_RETRY = 1


class Filter(threading.Thread):
    """
    Reads the task from a queue end send it to a Free/Off Worker

    If all workers are Working, wait on self.freeWorker semaphore
    """

    def __init__(self, operationQueue, resultQueue, maxWorker, name):
        """
        Constructor

        @param operationQueue: Queue representing the list of operation
        @param resultQueue: Queue where send back completed tasks
        @param maxWorker: Max number of worker to run
        @param name: the name of current thread
        """
        threading.Thread.__init__(self, name=name)
        if maxWorker < 1:
            self.maxWorker = 1
        else:
            self.maxWorker = maxWorker

        self.operations = operationQueue
        self.resultsQueue = resultQueue

        self.freeWorker = threading.Semaphore(self.maxWorker)

        self.force_termination=False
        self.off = []
        self.free = []
        self.working = []
        self.statuses = {'off': self.off,
                         'free': self.free,
                         'working':self.working
                         }
        self.connectors = []
        self.freeQueue = Queue.Queue()

        self.logger = logging.getLogger('FR.%s' % name)
        self._on_init()

    def run(self):
        self._start_WorkerWatchers()
        task = self.operations.get()
        while task and not self.force_termination:
            if (not task.is_aborted()) and (self._is_my_responsability(task)):
                self.freeWorker.acquire()
                if self.free != []:
                    self.free[0].set_working(task)
                elif self.off != []:
                    self.off[0].set_working(task)
            else:
                self.resultsQueue.put(task, 'operation')
            task = self.operations.get()

    def __on_terminate(self):
        """
        Calls terminate on all connector and wait for worker termination
        """
        self.logger.debug(u"Shutting down all Workers")
        for connector in self.connectors:
            connector.terminate()
        for connector in self.connectors:
            if connector.worker is not None \
            and connector.worker.isAlive() \
            and connector.worker is not threading.current_thread():
                self.logger.debug(u"Joining thread %s" % connector.worker.name)
                connector.worker.join()
                self.logger.debug(u"Thread %s joined" % connector.worker.name)
        self.logger.debug(u'All workers stopped')

    def terminate(self):
        '''
        Terminates the filter, put a None operations in operations queue and
        executes the __on_terminate method
        '''
        self.logger.debug(u"Terminating %s..." % self.getName())
        self.force_termination=True
        self.operations.put(None) #Needed for pass the task = self.operations.get() in case of no tasks presence
        self.__on_terminate()
#         self.join() if self.isAlive() and self is not threading.current_thread() else None
        self.logger.debug(u"%s terminated." % self.getName())

    ###############
    # Overridable #
    ###############

    def _start_WorkerWatchers(self):
        """
        Override this method if you want start WorkerWatchers in a different way
        """
        for i in range(self.maxWorker):
            self.logger.debug(u"Starting Worker Watcher %d/%d" % (i,self.maxWorker))
            connector = self.Connector(i, self.statuses, self.resultsQueue, self.freeWorker)
            connector.start_WorkerWatcher()
            self.connectors.append(connector)

    def _is_my_responsability(self, task):
        '''
        The filter will execute this task only if this method return True

        @param task: the given task
        '''
        return task.verb in self.verbs

    def _on_init(self):
        '''
        Override this method to execute custom actions on init
        '''
        self.Connector = AbstractConnector
        self.verbs = ['time']

if __name__ == "__main__":
    pass
########NEW FILE########
__FILENAME__ = task_wrapper
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the task_wrapper module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

class TaskWrapper(object):
    """
    # Note: keep this class picklable
    Use TaskWrapper to add information to a task

    The original task can be found on taskWrapper.task
    """

    def __init__(self, task=None):
        """
        @param task: the original task to wrap
        """
        self.task = task

    ##########################
    # Overridable
    ##########################

    def prepare(self, cfg=None):
        """
        Sets additional params to the task

        @param cfg: instance of filerockclient.config
        """
        pass

if __name__ == '__main__':
    import pickle
    tw = TaskWrapper()
    tw.prepare()
    print pickle.dumps(tw)
########NEW FILE########
__FILENAME__ = worker
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the worker module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import multiprocessing, time, Queue

class Worker(multiprocessing.Process):
    """
        A Worker process

        manages task till a None task is received
    """
    def __init__(self, tasksQueue, cmdQueue, terminationQueue):
        """
        Initialize the Worker process

        @param tasksQueue: the tasks queue
        @param cmdQueue: the queue where wait for the abort message
        @param terminationQueue: the queue where send the termination message
        """
        multiprocessing.Process.__init__(self)
        self.tasks = tasksQueue
        self.cmd = cmdQueue
        self.termination = terminationQueue
        self.times = 0


    def run(self):
        """
        Executes the task by step, it sends back to the termination queue a True if a the task terminated naturally, a False if a Poison Pill was received
        After every step, the cmd Queue is checked looking for a poison pill
        """
        self._more_init()
        tw = self.tasks.get() #If someone has start the process for do a task no timeout is needed
        while tw and tw.task:
            self.task_poison_pill = False
            try:
                self._on_new_task(tw)
                while not self.task_poison_pill:
                    try:
                        self.task_poison_pill = self.cmd.get_nowait() # Check if stop message is present
                        if self.task_poison_pill: self._on_task_abort(tw) # If stop message is True clean the environment
                        self.__force_termination(u'task aborted') # Send termination message to False
                    except Queue.Empty: #Do step
                        if not self._is_task_completed(tw):
                            self._task_step(tw)
                        else:
                            self._on_task_complete(tw)
                            try:
                                self.termination.put_nowait({'success':True}) #On termination Send Back the task
                            except Queue.Full:
                                pass
                            break

                tw = self.tasks.get() #Waiting for the next task, send None for shutdown the process
            except KeyboardInterrupt:
                self.__force_termination(u'Worker Terminated by KeyboardInterrupt')
        self.__on_terminate()


    def __force_termination(self, msg):
        """
        Forces the termination of current task
        """
        self.task_poison_pill = True
        try:
            self.termination.put_nowait({'success':False,'message':msg})
        except Queue.Full:
            pass


    def __on_terminate(self):
        """
        Called at the end of process
        """
        self.times = 0

#################################################################################################
# You can define a new kind of worker extending this class and overriding the following methods #
#################################################################################################


    def _on_new_task(self, tw):
        """
        Gets ready the environment for the new task
        """
        task = tw.task
        self.times = task.sec/2

    def _on_task_abort(self, tw):
        """
        Clean the environment in case of abort message is received
        """
        self.times = 0

    def _on_task_complete(self, tw):
        """
        Clean the environment in case of task complete successfully
        """
        self.times = 0

    def _task_step(self, tw):
        """
        Exec a single step of a task
        """
        self.times -= 1
        time.sleep(2)

    def _is_task_completed(self, tw):
        return self.times == 0

    def _more_init(self):
        """
        Called as first function on run()
        Initializes non picklable parameters
        """
        pass
########NEW FILE########
__FILENAME__ = worker_watcher
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the worker_watcher module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import threading, multiprocessing, Queue, logging, sys
from task_wrapper import TaskWrapper as AbstractTaskWrapper
from worker import Worker as AbstractWorker

WAITING_SEC_FOR_NEXT_TASK = 5


class WorkerWatcher(threading.Thread):
    """
        Worker Watcher is a thread, stops and starts a Worker and sends
        it the tasks

    """
    def __init__(self, index, queue, connector, name):
        """
        @param index:
        @param queue: An instance of Queue.Queue where get the next Task
        @param connector: An instance of Connector.Connector
        @param name: thread name
        """
        threading.Thread.__init__(self, name=name)
        self.queue = queue
        self.connector = connector
        self.tasks = None
        self.cmd = None
        self.termination = None
        self.process = None
        self.index = index
        logger_name = "FR.%s" % name
        self.logger = logging.getLogger(logger_name)
        self._on_init()


    def run(self):
        """
        It waits on a queue for a new task until it receives a None Task
        If the Worker is not alive it creates and run a new worker
        Registers the termination handler on the task
        Wraps the task with a TaskWrapper Class received on __init__
        Sends the Wrapped Task to the worker the wait for the termination
        If no new task arrives in the next "WAITING_SEC_FOR_NEXT_TASK sec" it shutdowns the process

        When a None Task is received, if the process is alive, WorkerWatcher sends a PoisonPill to it and waits for the termination
        then terminates itself
        """
        try:
            self.name += '_%s' % self.ident
            self.logger.debug(u"Hello, this is WorkerWatcher %d" % self.index)
            task = self.queue.get()

            self._on_new_task(task)

            while task:
                #self.logger.info(u"Task number %s arrived to WW" % task.number)
                task.lock.acquire()
                if not task.is_aborted():
                    task.register_abort_handler(self.__abort_handler) #if task is not just aborted register the handler

                    tw=self._wrap_task(task)
                    result = self.__send_task_to_process(tw)
                    if result['success']: #Waiting for termination Message
                        try:
                            self._on_success(tw, result)
                            self.__send_task_back(tw.task)
                        except Exception as e:
                            self.logger.exception(u"Something went wrong in task: %r" % e)
                            self.logger.debug(u"Rejecting task on %s", tw.task.pathname)
                            tw.task.reject()
                    else:
                        self.logger.debug(u'WW %d Operation ABORTED with message\n%s' % (self.index, result['message']))
                        self._on_fail(tw, result)
                        self.logger.debug(u"Rejecting task on %s", tw.task.pathname)
                        tw.task.reject()
                else:
                    task.lock.release()

                self.__im_free(task)

                try:
                    task = self.queue.get(True, WAITING_SEC_FOR_NEXT_TASK) #Wait # seconds for the next task
                except Queue.Empty:
                    self.__im_off() # Set the thread to off and shutdown the process
                    #self.logger.info(u"Waiting for next Task")
                    task = self.queue.get() # wait for the next task
        finally:
            self.logger.debug(u"WorkerWatcher Shutdown...")
            self.__im_off()
            self.logger.debug(u"WorkerWatcher Shutdown completed.")

    def __im_free(self, task):
        """
        Sets the process as free delegating the procedure to the connector
        """
        #self.logger.debug(u"Setting Worker as Free")
        self.connector.set_free()

    def __close_queue(self, queue):
        """
        Closes a multiprocessing queue, waiting for its termination

        @param queue: instance of multiprocessing.Queue
        """
        if queue is not None:
            queue.close()
            queue.join_thread()
            queue = None

    def __close_queues(self):
        """
        Closes the multiprocessing queues
        """
        self.__close_queue(self.tasks)
        self.__close_queue(self.cmd)
        self.__close_queue(self.termination)

    def __create_queues(self):
        '''
        Closes all the multiprocessing queues and recreates them
        '''
        self.__close_queues()
        self.tasks = multiprocessing.Queue(1)
        self.cmd = multiprocessing.Queue(1)
        self.termination = multiprocessing.Queue(1)

    def __im_off(self):
        """
        Shutdowns the process and sets it as off
        """
        #self.logger.debug(u"Setting Worker as Off")
        if self.process and self.process.is_alive():
            self.tasks.put(False) #Shutdown the process
            self.process.join() # Waiting for process shutdown
        self.process = None
        self.__close_queues()
        self.connector.set_off()
        #self.logger.debug(u"Worker is Off")

    def __abort_handler(self, op):
        """
        Use this method as abort_handler in the task object

        @param op: instance of filerockclient.pathname_operation
        """
        self.cmd.put(True)

    def __terminate_process(self):
        """
        Terminates the process
        """
        self.process.terminate()
        self.process.join()

    def __send_task_back(self, task):
        """
        Delegates the send task back actions to the connector

        @param task: instance of filerockclient.pathname_operation.PathnameOperation
        """

        if (not task.is_completed()):
            self.connector.send_task_back(task)

    def __send_task_to_process(self, tw):
        """
        Sends the task to the process if it is not aborted,
        relaunches the process if it is died

        @param tw:
                a wrapped task, task has been wrapped from
                filerockclient.workers.filters.abstract.task_wrapper.TaskWrapper
        """
        task = tw.task
        try:
            self.__start_process() #If no process is alive start it
        except Exception:
            self.logger.error("Unexpected error: %s", sys.exc_info()[0])
            task.lock.release()
            raise

        self.tasks.put(tw) #sending task to process

        task.lock.release()

        result = self.termination.get()

        with task.lock:
            if task.is_aborted():
                try:
                    self.cmd.get_nowait()
                except Queue.Empty:
                    pass
            try:
                task.abort_handlers.remove(self.__abort_handler)
            except ValueError:
                pass

        return result


    def __start_process(self):
        """
        If no process is alive, starts a new one
        Returns True if a process is running False otherwise
        """
        if self.process is not None and not self.process.is_alive():
            self.process = None
        if self.process is None:
            self.__create_queues()
            self.process = self._create_worker()
            self.process.start()
        return self.process is not None

    ##########################
    # Overridable
    ##########################


    def _on_init(self):
        '''
        Override this method to execute custom actions on init
        '''
        self.TaskWrapper = AbstractTaskWrapper
        self.Worker = AbstractWorker

    def _create_worker(self):
        """
        Override this method to create a custom worker
        """
        return self.Worker(self.tasks, self.cmd, self.termination)

    def _on_new_task(self, task):
        """
        Override this method to execute custom action on new task received
        """
        pass

    def _wrap_task(self, task):
        """
        Override this method to wrap the task with your custom settings
        """
        tw = self.TaskWrapper(task) #wrap the task with
        tw.prepare() #add information to the task
        return tw


    def _on_success(self, tw, result):
        """
        Override this method to define custom action on task success
        """
        pass

    def _on_fail(self, tw, result):
        """
        Override this method to define custom action on task fail
        """
        pass
########NEW FILE########
__FILENAME__ = adapter
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the adapter module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import Queue, logging

from filerockclient.workers.filters.encryption import utils as CryptoUtils
from filter import CryptoFilter
import os

NUMBER_OF_WORKER = 2


class Adapter(object):
    """
    Adapter for the crypto filter
    """

    def __init__(self, cfg, warebox, output_queue, lockfile_fd,
                 enc_dir='enc', first_startup=False):
        """
        Constructor

        @param cfg:
                    the config object
        @param warebox:
                    the warebox object
        @param output_queue:
                    the queue where task are send back
        @param lockfile_fd:
                    File descriptor of the lock file which ensures there
                    is only one instance of FileRock Client running.
                    Child processes have to close it to avoid stale locks.
        @param enc_dir:
                    the directory used for encrypt the data, it will create
                    into user temp dir
        @param first_startup:
                    boolean self explaining
        """
        logger_prefix = "FR.CryptoFilter."
        self.cfg = cfg
        self.warebox = warebox
        self.logger = logging.getLogger(logger_prefix+self.__class__.__name__)
        self.input_queue = Queue.Queue()
        self.output_queue = output_queue
        self.enc_dir = os.path.join(self.cfg.get('Application Paths', 'temp_dir'), enc_dir)
        if first_startup:
            CryptoUtils.create_encrypted_dir(warebox, self.logger)
        self.crypto_filter = CryptoFilter(self.input_queue, self.output_queue,
                             NUMBER_OF_WORKER, cfg, warebox, lockfile_fd)

    def check_precondition(self, ui):
        """
        Checks the presence of encryption dir, and eventually recreates it

        @param ui: the ui interface class
        """
        encryptedDir = self.warebox.absolute_pathname('encrypted')
        result = True
        if not os.path.exists(encryptedDir) or os.path.isfile(encryptedDir):
            result = CryptoUtils.recreate_encrypted_dir(self.warebox, self.logger, ui)
        return result

    def start(self):
        self._try_create_enc_dir()
        return self.crypto_filter.start()

    def empty(self):
        return self.output_queue.empty()

    def put(self, pathname_operation):
        """
        Insert a pathname operation into the filter input_queue

        @param pathname_operation: the pathname operation object
        """
        self.input_queue.put(pathname_operation)

    def _clean_enc_dir(self):
        """
        Deletes all the files in the encryption dir
        """
        folder = self.enc_dir
        self.logger.debug('Cleaning encryption dir %s' % folder)
        for the_file in os.listdir(folder):
            file_path = os.path.join(folder, the_file)
            try:
                if os.path.isfile(file_path):
                    self.logger.debug('Unlinking file %s' % file_path)
                    os.unlink(file_path)
            except Exception:
                self.logger.exception('Error cleaning temp encryption dir')

    def get_enc_dir(self):
        """
        @return enc_dir the encryption dir path
        """
        return self.enc_dir

    def _try_create_enc_dir(self):
        """
        Tries to recreate the encryption dir, if a file with the same name is
        present deletes it and recreate the dir
        """
        self.logger.debug('Checking for encryption dir: %s' % self.enc_dir)
        if os.path.exists(self.enc_dir) and not os.path.isdir(self.enc_dir):
            os.unlink(self.enc_dir)
        if os.path.exists(self.enc_dir):
            self._clean_enc_dir()
        else:
            self.logger.debug('Creating encryption dir: %s' % self.enc_dir)
            os.mkdir(self.enc_dir)

    def terminate(self):
        self.crypto_filter.terminate()

########NEW FILE########
__FILENAME__ = connector
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the connector module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.workers.filters.abstract.connector import Connector as AbstractConnector
from worker_watcher import WorkerWatcher


class Connector(AbstractConnector):
    """
    CryptoConnector extend the prototypes.Connector.Connector
    """

    def __init__(self, index, statuses, resultsQueue, freeWorker, cfg, warebox, enc_dir, lockfile_fd):
        """
        Initializes the connector adding configuration object and WorkerWatcher class

        @param index: an index
        @param statuses: lists [off, free, working] containing the stopped worker
        @param resultsQueue: output queue, the complete/rejected/aborted tasks are sent back through it
        @param freeWorkers: threading.semaphore instance, counts the free workers
        @param cfg: configuration object
        @param lockfile_fd:
                    File descriptor of the lock file which ensures there
                    is only one instance of FileRock Client running.
                    Child processes have to close it to avoid stale locks.
        """
        AbstractConnector.__init__(self, index, statuses, resultsQueue, freeWorker)
        self.cfg = cfg
        self.warebox = warebox
        self.enc_dir = enc_dir
        self.lockfile_fd = lockfile_fd

    def start_WorkerWatcher(self):
        """
        Runs the WorkerWatcher specific instance
        """
        self.worker = self.WorkerWatcher(self.index, self.queue, self, self.cfg, self.warebox, self.enc_dir, self.lockfile_fd)
        self.worker.start()

    def _on_init(self):
        self.WorkerWatcher = WorkerWatcher
########NEW FILE########
__FILENAME__ = decrypter
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the decrypter module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os, struct
from Crypto.Cipher import AES
from pkcs7_padder import PKCS7Padder
import utils as CryptoUtils

class Decrypter(object):
    """
    Implement the encryption task by step
    """

    def __init__(self, warebox_path=None, chunksize=None):
        """
        Set the chunksize, if not chuncksize is passed the default value will be 64*1024

        Reads the input filename from task.pathname.local_src
        Reads the output filename from taskwrapper.out_filename
        Every TaskStep read a chunksize from input filename and write it crypet to output filename

        @param chunksize:
                Sets the size of the chunk which the function
                uses to read and encrypt the file. Larger chunk
                sizes can be faster for some files and machines.
                chunksize must be divisible by 16.
        """
        self.chunksize=chunksize or CryptoUtils.CHUNK_SIZE
        self.padder = PKCS7Padder()
        self.completed = False
        self.warebox_path = warebox_path

    def _on_new_task(self, tw):
        """
        Gets ready the environment for the new task

        @param tw: the wrapped task
        """
        self.completed = False #set the task as not completed
        in_filename = tw.task.encrypted_pathname #read filename from task
        
        if hasattr(tw.task, 'temp_pathname'):
            out_filename = tw.task.temp_pathname
        else:
            out_filename = tw.task.pathname #read output filename from taskwrapper

        self.infile = open(in_filename, mode='rb')

        if self.warebox_path is not None:
            out_filename = os.path.join(self.warebox_path, out_filename)
        
        self.outfile = open(out_filename, 'wb') #Open output file in writebinary mode

        protocol_version = self.infile.read(len(CryptoUtils.PROTOCOL_VERSION))

        if CryptoUtils.PROTOCOL_VERSION != protocol_version:
            raise CryptoUtils.ProtocolVersionMismatch("Can't decrypt, file crypted with protocol version %s", protocol_version)

        self.iv = self.infile.read(16)
        self.decryptor = AES.new(tw.key, AES.MODE_CFB, self.iv, segment_size=128)
        self.chunk = self.infile.read(self.chunksize)

    def _on_task_abort(self, tw):
        """
        Cleans the environment in case of abort

        @param tw: the wrapper task
        """
        self.outfile.close() #Close the output file
        if os.path.exists(tw.out_pathname):
            os.remove(tw.out_pathname) #Remove the incomplete output file
        self.infile.close() #Close the input file
        self.completed = False


    def _on_task_complete(self, tw):
        """
        Cleans the environment in case of task complete successfully

        @param tw: the wrapper task
        """
        self.outfile.close()
        self.infile.close()

    def _task_step(self, tw):
        """
        Exec a single step of a task

        @param tw: the wrapper task
        """
        if not self.completed:
            nextchunk = self.infile.read(self.chunksize)
            if len(nextchunk) > 0:
                self.outfile.write(self.decryptor.decrypt(self.chunk))
                self.chunk = nextchunk
            else:
                decrypted_chunk = self.decryptor.decrypt(self.chunk)
                chunk_unpadded = self.padder.decode(decrypted_chunk)
                self.outfile.write(chunk_unpadded)
                self.completed = True

    def _is_task_completed(self, tw):
        """
        return true if the task was completed

        @param tw: the wrapped task
        """
        return self.completed
########NEW FILE########
__FILENAME__ = encrypter
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the encrypter module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os
from Crypto.Cipher import AES
from filerockclient.workers.filters.encryption import utils as CryptoUtils
from filerockclient.workers.filters.encryption.pkcs7_padder import PKCS7Padder


class Encrypter(object):
    """
    Implement the encryption task by step
    """


    def __init__(self, warebox_path=None, chunksize=None):
        """
        Set the chunksize, if not chuncksize is passed the default value will be 64*1024

        Reads the input filename from task.pathname.local_src
        Reads the output filename from taskwrapper.out_filename
        Every TaskStep read a chunksize from input filename and write it crypet to output filename

        @param chunksize:
                Sets the size of the chunk which the function
                uses to read and encrypt the file. Larger chunk
                sizes can be faster for some files and machines.
                chunksize must be divisible by 16.
        """
        self.chunksize=chunksize or CryptoUtils.CHUNK_SIZE
        self.padder = PKCS7Padder()
        self.completed = False
        self.warebox_path = warebox_path


    def _on_new_task(self, tw):
        """
        Gets ready the environment for the new task

        @param tw: the wrapper task
        """
        self.completed = False #set the task as not completed
        in_filename = tw.task.pathname #read filename from task
        out_filename = tw.task.encrypted_pathname #read output filename from taskwrapper

        if self.warebox_path is not None:
            in_filename = os.path.join(self.warebox_path, in_filename)

        self.infile = open(in_filename, mode='rb')

        self.outfile = open(out_filename, mode='wb') #Open output file in write binary mode

        iv = tw.iv
        self.encryptor = AES.new(tw.key, AES.MODE_CFB, iv, segment_size=128) #Initialize encryptor
        self.outfile.write(CryptoUtils.PROTOCOL_VERSION)
        self.outfile.write(iv) #Write initialization vector in output file
        self.chunk = self.infile.read(self.chunksize)

    def _on_task_abort(self, tw):
        """
        Clean the environment in case of abort

        @param tw: the wrapper task
        """
        self.outfile.close() #Close the output file
        if os.path.exists(tw.out_pathname):
            os.remove(tw.out_pathname) #Remove the incomplete output file
        self.infile.close() #Close the input file

    def _on_task_complete(self, tw):
        """
        Clean the environment in case of task complete successfully

        @param tw: the wrapper task
        """
        self.outfile.close()
        self.infile.close()

    def _task_step(self, tw):
        """
        Exec a single step of a task

        @param tw: the wrapper task
        """
        if not self.completed:
            nextchunk = self.infile.read(self.chunksize)
            if len(nextchunk) > 0:
                self.outfile.write(self.encryptor.encrypt(self.chunk))
                self.chunk = nextchunk
            else:
                chunk_padded = self.padder.encode(self.chunk)
                encrypted_chunk=self.encryptor.encrypt(chunk_padded)
                self.outfile.write(encrypted_chunk)
                self.completed = True

    def _is_task_completed(self, tw):
        """
        return true if the task was completed

        @param tw: the wrapped task
        """
        return self.completed

########NEW FILE########
__FILENAME__ = filter
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the filter module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.workers.filters.abstract.filter import Filter as AbstractFilter
from filerockclient.workers.filters.encryption.connector import Connector
from filerockclient.workers.filters.encryption import utils as CryptoUtils
import logging, os


class CryptoFilter(AbstractFilter):
    """
    Crypto Filter manages tasks with Encrypt and Decrypt verbs,
    it pass the tasks to a pool of processes and wait the completion on a Queue
    """

    def __init__(self, operationQueue, resultsQueue, maxWorker, cfg, warebox, lockfile_fd):
        """
        @param operationQueue: the input queue, cryptoFilter reads the new tasks from it
        @param resultsQueue: the output queue, the managed tasks will be sent back through it
        @param maxWorker: the maximum number of workers running at the same time
        @param cfg: an instance of ConfigurationManager
        @param warebox: an instance of Warebox class
        @param lockfile_fd:
                    File descriptor of the lock file which ensures there
                    is only one instance of FileRock Client running.
                    Child processes have to close it to avoid stale locks.
        """
        AbstractFilter.__init__(self, operationQueue, resultsQueue, maxWorker, name=self.__class__.__name__)
        self.logger = logging.getLogger('FR.%s' % self.getName())
        self.cfg=cfg
        self.enc_dir=CryptoUtils.get_encryption_dir(cfg)
        self.warebox = warebox
        self.lockfile_fd = lockfile_fd

    def _start_WorkerWatchers(self):
        """
        Starts the worker watchers pool
        """
        workers = self.maxWorker
        for i in range(workers):
            self.logger.debug(u"Start Worker Watcher %d/%d" % (i,workers))
            connector = self.Connector(i,
                                       self.statuses,
                                       self.resultsQueue,
                                       self.freeWorker,
                                       self.cfg,
                                       self.warebox,
                                       self.enc_dir,
                                       self.lockfile_fd)
            connector.start_WorkerWatcher()
            self.connectors.append(connector)

    def _is_my_responsability(self, task):
        """
        Return true if the filter can handle the task
        """
        return task.to_encrypt or task.to_decrypt

    def _on_init(self):
        """
        Initialize the filter with custom parameter
        """
        self.Connector = Connector
        self.verbs = ['Encrypt','Decrypt']

########NEW FILE########
__FILENAME__ = helpers
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the helpers module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os, hashlib, time
from binascii import hexlify, unhexlify
from filerockclient.workers.filters.encryption.task_wrapper import TaskWrapper
from filerockclient.workers.filters.encryption.decrypter import Decrypter
from filerockclient.workers.filters.encryption.encrypter import Encrypter
from filerockclient.pathname_operation import PathnameOperation
from filerockclient.workers.filters.encryption import utils as CryptoUtils
from Crypto.Cipher import AES
from filerockclient.exceptions import ExecutionInterrupted
from filerockclient.workers.filters.encryption.pkcs7_padder import PKCS7Padder


def decrypt(pathname_operation, warebox, cfg, logger=None):
    """
    Decrypts a file

    @param pathname_operation: an instance of pathname_operation class
    @param warebox: an instance of warebox class
    @cfg an instance of cfg class
    @logger optional logger object
    """
    try:
        tw = TaskWrapper(pathname_operation)
        enc_dir = CryptoUtils.get_encryption_dir(cfg)
        tw.prepare(cfg, enc_dir)
        if logger:
            logger.debug(u'Decrypting file %s to %s' % (tw.task.encrypted_pathname, tw.task.temp_pathname))
        decrypter = Decrypter(warebox)
        decrypter._on_new_task(tw)
        while not decrypter._is_task_completed(tw):
            decrypter._task_step(tw)
        decrypter._on_task_complete(tw)
    except Exception as e:
        if logger: logger.exception(u'Decryption task fail on %s' % pathname_operation.pathname)
        on_decrypt_fail(pathname_operation, e, logger)
        raise

def on_decrypt_fail(pathname_operation, excp, logger=None):
    """
    Cleans the environment in case of decryption failure

    @param pathname_operation: an instance of pathname_operation
    @param the: exception raised from decryption failure

    """
    if logger: logger.debug(u'Decryption task fail cleaning environment')
    clean_env(pathname_operation)
    if pathname_operation.to_decrypt: #if decrypt task fails, also the uncompleted decrypted files have to be deleted
        try:
            if os.path.exists(pathname_operation.pathname):
                os.remove(pathname_operation.pathname)
            if logger:
                logger.debug(u'Encrypted file %s deleted' % pathname_operation.encrypted_pathname)
        except OSError:
            pass

def clean_env(pathname_operation, logger=None):
    """
    Remove the encrypted file

    @param pathname_operation:
    """
    if pathname_operation.to_decrypt or pathname_operation.to_encrypt:
#        os.close(pathname_operation.encrypted_fd)
        if os.path.exists(pathname_operation.encrypted_pathname):
            os.remove(pathname_operation.encrypted_pathname)
        if logger:
            logger.debug(u'Encrypted file %s deleted' % pathname_operation.encrypted_pathname)

def compute_md5_hex(pathname):
    '''
    Returns an hexadecimal text representation of the MD5 hash of the
    given pathname's data.
    '''
    return hexlify(get_local_file_etag(pathname))

def recalc_encrypted_etag(ivs, warebox, cfg, interruption=None):
    return recalc_encrypted_etag_in_mem(ivs, warebox, cfg, interruption)
    """
    Encrypt all the files into the encrypted folder and return a list of etag

    @param ivs: a dictionary with pathname as key and ivs as value
    @param warebox: an instance of warebox class
    @param cfg: an instance of config class
    """
    encrypted_etags = dict()
    enc_dir = CryptoUtils.get_encryption_dir(cfg)
    encrypter = Encrypter(warebox)
    for pathname in ivs:
        pathname_operation = PathnameOperation(None, None, u'UPLOAD', pathname)
        pathname_operation.to_encrypt=True
        try:
            wrapped_task = TaskWrapper(pathname_operation)
            wrapped_task.prepare(cfg, enc_dir)
            wrapped_task.iv = unhexlify(ivs[pathname])
            encrypter._on_new_task(wrapped_task)
            while not encrypter._is_task_completed(wrapped_task):
                encrypter._task_step(wrapped_task)
            encrypter._on_task_complete(wrapped_task)
            encrypted_etags[pathname] = compute_md5_hex(wrapped_task.task.encrypted_pathname)
            clean_env(pathname_operation)
        except Exception:
            clean_env(pathname_operation)
            raise
    return encrypted_etags


def recalc_encrypted_etag_in_mem(ivs, warebox, cfg, interruption=None):
    """
    Encrypt all the files into the encrypted folder and return a list of etag

    @param ivs: a dictionary with pathname as key and ivs as value
    @param warebox: an instance of warebox class
    @param cfg: an instance of config class
    """
    key = unhexlify(cfg.get('User', 'encryption_key'))
    encrypted_etags = dict()
    chunksize = CryptoUtils.CHUNK_SIZE
    padder = PKCS7Padder()
    for pathname in ivs:
        if interruption is not None and interruption.is_set():
            raise ExecutionInterrupted()
        try:
            fp = warebox.open(pathname, mode="rb")
            md5 = hashlib.md5()
            iv = unhexlify(ivs[pathname])
            encryptor = AES.new(key, AES.MODE_CFB, iv, segment_size=128) #Initialize encryptor
            md5.update(CryptoUtils.PROTOCOL_VERSION)
            md5.update(iv)
            completed = False
            chunk = fp.read(chunksize)
            while not completed:
                next_chunk = fp.read(chunksize)
                if len(next_chunk) > 0:
                    md5.update(encryptor.encrypt(chunk))
                    chunk = next_chunk
                else:
                    chunk_padded = padder.encode(chunk)
                    encrypted_chunk=encryptor.encrypt(chunk_padded)
                    md5.update(encrypted_chunk)
                    completed = True
            encrypted_etags[pathname] = md5.hexdigest()
        except Exception:
            raise
        finally:
            fp.close()
    return encrypted_etags

def get_local_file_etag(pathname):
    """
    Returns result of proper hash function defined in configuration file.
    Large files are processed in chunks to avoid memory consumption.
    Returns the hash of an empty string if file is ... well, not a file or a symlink
    """
    result = False
    counter = 0
    while counter < 3:
        try:
            md5 = hashlib.md5()
            if not os.path.isfile(pathname):
                md5.update('') # Right now, etag for dir is built on '' ... we might put information in here
            else:
                with open(pathname, 'rb') as current_file:
                    for chunk in iter(lambda: current_file.read(8192), ''):
                        md5.update(chunk)
            result=True
            break
        except IOError as e:
            error = repr(e)
            counter += 1
            time.sleep(1)
    if not result:
        raise IOError

    return md5.digest()
########NEW FILE########
__FILENAME__ = pkcs7_padder
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the pkcs7_padder module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import binascii
import StringIO

class PKCS7Padder(object):
    '''
    RFC 2315: PKCS#7 page 21
    Some content-encryption algorithms assume the
    input length is a multiple of k octets, where k > 1, and
    let the application define a method for handling inputs
    whose lengths are not a multiple of k octets. For such
    algorithms, the method shall be to pad the input at the
    trailing end with k - (l mod k) octets all having value k -
    (l mod k), where l is the length of the input. In other
    words, the input is padded at the trailing end with one of
    the following strings:

             01 -- if l mod k = k-1
            02 02 -- if l mod k = k-2
                        .
                        .
                        .
          k k ... k k -- if l mod k = 0

    The padding can be removed unambiguously since all input is
    padded and no padding string is a suffix of another. This
    padding method is well-defined if and only if k < 256;
    methods for larger k are an open issue for further study.
    '''
    def __init__(self, k=16):
        self.k = k

    ## @param text: The padded text for which the padding is to be removed.
    # @exception ValueError Raised when the input padding is missing or corrupt.
    def decode(self, text):
        '''
        Remove the PKCS#7 padding from a text string
        '''
        nl = len(text)
        val = int(binascii.hexlify(text[-1]), 16)
        if val > self.k:
            raise ValueError('Input is not padded or padding is corrupt')

        l = nl - val
        return text[:l]

    ## @param text: The text to encode.
    def encode(self, text):
        '''
        Pad an input string according to PKCS#7
        '''
        l = len(text)
        output = StringIO.StringIO()
        val = self.k - (l % self.k)
        for _ in xrange(val):
            output.write('%02x' % val)
        return text + binascii.unhexlify(output.getvalue())

########NEW FILE########
__FILENAME__ = task_wrapper
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the task_wrapper module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from filerockclient.workers.filters.abstract.task_wrapper import TaskWrapper as AbstractTaskWrapper
from filerockclient.workers.filters.encryption import utils as CryptoUtils
from tempfile import mkstemp
from binascii import unhexlify, hexlify
from Crypto import Random
import os


class TaskWrapper(AbstractTaskWrapper):
    """
    Wraps the task and adds useful information
    """

    def __init__(self, task=None):
        """
        Allocates the taskwrapper class with the given task

        @param task: task to wrap
        """
        Random.atfork()
        AbstractTaskWrapper.__init__(self, task)

    def __check_enc_dir(self, pathname):
        """
        Checks for enc dir inexistence and create it if needed

        @param pathname: the path of encryption dir
        """
        if os.path.exists(pathname) and os.path.isdir(pathname):
            return True

        if os.path.exists(pathname) and not os.path.isdir(pathname):
            os.unlink(pathname)

        if not os.path.exists(pathname):
            os.makedirs(pathname)

    def prepare(self, cfg, enc_dir):
        """
        Adds out_pathname and key parameters depending on the task's verb
        and configuration object

        @param cfg: configuration manager instance
        @param enc_dir: the encryption directory path
        """
        self.key = unhexlify(cfg.get('User', 'encryption_key'))
        self.__check_enc_dir(enc_dir)
        if self.task.to_encrypt:
            CryptoUtils.set_temp_file(self.task, cfg, enc_dir)
            self.iv = Random.new().read(16)
            self.task.iv = unicode(hexlify(self.iv))
            self.out_pathname = self.task.encrypted_pathname
        elif self.task.to_decrypt:
            if not self.task.encrypted_pathname:
                CryptoUtils.set_temp_file(self.task, cfg, enc_dir)
            self.in_pathname = self.task.encrypted_pathname



if __name__ == '__main__':
    import pickle, ConfigParser
    cfg = ConfigParser.SafeConfigParser()
    cfg.add_section('User')
    cfg.set('User', 'tempdir', '/tmp')
    tw = TaskWrapper()
    tw.prepare(cfg)
    print pickle.dumps(tw)
########NEW FILE########
__FILENAME__ = utils
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the utils module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os
from tempfile import mkstemp

import random
from datetime import datetime
from Crypto.Cipher import AES
from hashlib import sha256, sha1
from Crypto import Random
from pbkdf2 import PBKDF2
import time
from filerockclient.warebox import CantWritePathnameException
from filerockclient.util.utilities import _try_remove

ENCRYPTED_FOLDER_NAME = u'encrypted/'
PROTOCOL_VERSION = u'FileRock01'
CHUNK_SIZE = 64*1024
ENC_DIR = u'enc'

class ProtocolVersionMismatch(Exception):
    pass

def generate_encryption_key():
    """
    Reads from 100 to 150 random bytes from PyCrypto.Random
    Returns sha256 digest of the random bytes
    """

    rndfile = Random.new()

    password = rndfile.read(random.randint(100, 150))
    return sha256(password).digest()

def enckey_to_encmk(enc_key, pre_salt, secret):
    """
    Generates the encryption master key within the combination of
        _ enc_key
        _ password (the secret)
        _ sha1(pre_salt).digest() (the salt)
        _ iv (16 bytes from Crypto.Random)

    enc_mk is the result of:
        iv = Crypto.Random.new().read(16)
        hp2 = pbkdf2.PBKDF2(password, sha1(username).digest()).read(32)
        mode = Crypto.Cipher.AES.MODE_CFB
        cipher = Crypto.Cipher.AES(hp2, mode, iv)
        enc_mk = iv + cipher.encrypt(enc_key)
    """
    rndfile = Random.new()

    hp2 = PBKDF2(secret, sha1(pre_salt).digest()).read(32)
    iv= rndfile.read(16)

    cipher = AES.new(hp2, AES.MODE_CFB, iv, segment_size=128)
    enc_mk = iv+cipher.encrypt(enc_key)
    return enc_mk

def encmk_to_enckey(enc_mk, pre_salt, secret):
    """
    Get the encryption_key from enc_mk

    enc_mk is the result of:
        iv = Crypto.Random.new().read(16)
        hp2 = pbkdf2.PBKDF2(password, sha1(username).digest()).read(32)
        mode = Crypto.Cipher.AES.MODE_CFB
        cipher = Crypto.Cipher.AES(hp2, mode, iv)
        enc_mk = iv + cipher.encrypt(enc_key)
    """
    hp2 = PBKDF2(secret, sha1(pre_salt).digest()).read(32)
    iv = enc_mk[0:16]

    cipher = AES.new(hp2, AES.MODE_CFB, iv, segment_size=128)
    enc_key = cipher.decrypt(enc_mk[16:])
    return enc_key

def _find_new_name(pathname):
    """
    Creates a new name appending the suffix (Conflicted on %Y-%m-%d %H_%M_%S)

    @param pathname:
    """
    # TODO: try harder in finding a name that is available
    curr_time = datetime.now().strftime('%Y-%m-%d %H_%M_%S')
    suffix = ' (Conflicted on %s)' % curr_time
    if pathname.endswith('/'):
        new_pathname = pathname[:-1] + suffix + '/'
    else:
        basename, ext = os.path.splitext(pathname)
        new_pathname = basename + suffix + ext

    return new_pathname

def _rename_conflicting_pathname(warebox, pathname):
    """
    Finds a new name for the file and rename it

    @param warebox: the warebox object
    @param pathname:
    """
    new_pathname = _find_new_name(pathname)
    warebox.rename(pathname, new_pathname)
    return new_pathname

def create_encrypted_dir(warebox, logger=None, ui=None):
    """
    Creates the encryption directory

    @param warebox: the warebox object
    @param logger: a logger object
    @param ui: an ui controller object
    """
    encryptedDir = warebox.absolute_pathname('encrypted')
    created = True
    if not os.path.exists(encryptedDir) or os.path.isfile(encryptedDir):
        created=False
        while not created:
            try:
                warebox.make_directory(u'encrypted')
                created = True
            except CantWritePathnameException as e:
                if e.errno==17 \
                and os.path.isfile(warebox.absolute_pathname(u'encrypted')): 
                    if ui:
                        ask_what = u'rename_encrypted_file'
                        if ui.ask_for_user_input(ask_what) == 'ok':
                            continue
                        else:
                            break
                    else:
                        renamed_on=warebox.rename(u'encrypted', 
                                                  u'encrypted',
                                                  'Renamed')
                        if logger:
                            msg = u'encrypted file moved on %s'
                            logger.debug(msg % renamed_on)
    return created


def recreate_encrypted_dir(warebox, logger=None, ui=None):
    """
    Recreates the encryption dir

    @param warebox: the warebox object
    @param logger: a logger object
    @param ui: an ui controller object
    """
    if ui:
        ui.notify_user(u'encryption_dir_deleted')
    return create_encrypted_dir(warebox, logger, ui)


def is_pathname_encrypted(pathname):
    """
    Returns true if the pathname is into the encryption dir
    """
    return pathname.startswith(u'encrypted/')

def prepare_operation(pathname_operation, temp_dir=ENC_DIR):
    """
    Prepares the pathname_operation for the encryption/decryption dir adding
    custom field.

    @param pathname_operation: an instance of pathname_operation class
    @temp_dir a temporary folder
    """
    if pathname_operation.is_directory():
        return False

    if pathname_operation.verb == u'DELETE':
        return False

    if pathname_operation.verb == u'UPLOAD' \
    and pathname_operation.pathname.startswith(u'encrypted/'):
        pathname_operation.to_encrypt = True
        return True

    if pathname_operation.verb == u'DOWNLOAD' \
    and pathname_operation.pathname.startswith(u'encrypted/'):
        pathname_operation.to_decrypt = True
        return True

    if pathname_operation.verb == u'REMOTE_COPY' and \
    not pathname_operation.oldpath.strartswith(u'encrypted/') and \
    not pathname_operation.pathname.strartswith(u'encrypted/'):
        if pathname_operation.oldpath.strartswith(u'encrypted/'):
            pathname_operation.verb = u'UPLOAD'
            return False
        elif pathname_operation.pathname.startswith(u'encrypted/'):
            pathname_operation.verb = u'UPLOAD'
            pathname_operation.to_encrypt = True
            return True

def get_encryption_dir(cfg):
    return os.path.join(cfg.get('Application Paths', 'temp_dir'), ENC_DIR)

def set_temp_file(pathname_operation, cfg, enc_dir=None):
    """
    Creates a temporary file and adds its path to pathname_operation
    """
    if pathname_operation.to_encrypt \
    or pathname_operation.to_decrypt:
        if enc_dir is not None:
            temp_dir = enc_dir
        else:
            temp_dir=get_encryption_dir(cfg)
            
        encrypted_fd, encrypted_pathname = mkstemp(dir=temp_dir)
        os.close(encrypted_fd)
        pathname_operation.encrypted_pathname = encrypted_pathname
        pathname_operation.encrypted_fd = encrypted_fd

def clean_env(pathname_operation, logger=None):
    """
    Cleans environment after encryption operations, removing encrypted file
    """
    if pathname_operation.to_encrypt:
        if os.path.exists(pathname_operation.encrypted_pathname):
            _try_remove(pathname_operation.encrypted_pathname, logger)
            if logger:
                msg = u'Encrypted file %s deleted'
                logger.debug(msg % pathname_operation.encrypted_pathname)



def to_encrypt(pathname_operation):
    """
    Returns true if the pathname operation should be encrypted
    """
    return pathname_operation.to_encrypt \
        and pathname_operation.encrypted_pathname is None

def to_decrypt(pathname_operation):
    """
    Returns true if the pathname operation should be decrypted
    """
    return pathname_operation.to_decrypt \
        and pathname_operation.encrypted_pathname is None


def filter_encrypted_pathname(conflicts):
    """
    Filter the path names, returning the ones who are in the encrypted folder

    @param conflicts: list of pathnames
    """
    return filter(lambda p: p.startswith(u'encrypted/') \
                  and not p.endswith('/'), conflicts)

########NEW FILE########
__FILENAME__ = worker
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the worker module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os
import sys

from filerockclient.workers.filters.abstract.worker import Worker as AbstractWorker
# from filerockclient.warebox import Warebox
import traceback
from encrypter import Encrypter
from decrypter import Decrypter


class Worker(AbstractWorker):
    """
    CryptoWorker implements Encryption and Decryption tasks

    Extends the prototypes.Worker.Worker Class
    """
    def __init__(self, tasksQueue, cmdQueue, terminationQueue, warebox_path, lockfile_fd):
        """
        @param tasksQueue:
                    the tasks queue
        @param cmdQueue:
                    the queue where wait for the abort message
        @param terminationQueue:
                    the queue where send the termination message
        @param warebox_path:
                    The FileRock folder pathname.
        @param lockfile_fd:
                    File descriptor of the lock file which ensures there
                    is only one instance of FileRock Client running.
                    Child processes have to close it to avoid stale locks.
        """
        AbstractWorker.__init__(self, tasksQueue, cmdQueue, terminationQueue)
        self.warebox_path = warebox_path
        self.lockfile_fd = lockfile_fd

    def _more_init(self):
        """
        Called as first function in run()
        """
        # Closing the lockfile descriptor.
        #
        # The multiprocessing library behaves differently on Windows and Unix:
        #   - on Windows it spawns a Python interpreter in a brand new process,
        #     which doesn't share any resource with the father process;
        #   - on Unix it forks. The child process inherits by default all
        #     file descriptors from the father, that is, open files, sockets,
        #     etc.
        # We want subprocesses not to inherit the lockfile descriptor in
        # order to avoid stale locks (see module: filerockclient.application).
        # It isn't possible to avoid Unix subprocesses to inherit descriptors,
        # so the only safe option is to explicitly close the lockfile in the
        # child. However, it must not be done on Windows, since multiprocessing
        # very likely uses the very same file descriptor for different
        # resources.
        # The developers of multiprocessing seem to be working on the fd
        # inheritance problem right in these days, see:
        #     http://bugs.python.org/issue8713
        if not sys.platform.startswith('win'):
            os.close(self.lockfile_fd)

#         self.warebox = Warebox(self.cfg)
        self.encrypter = Encrypter(self.warebox_path)
        self.decrypter = Decrypter(self.warebox_path)



    def _on_new_task(self, tw):
        """
        Gets ready the environment for the new task

        @param tw: the wrapped task
        """
        if not tw.task.to_encrypt and not tw.task.to_decrypt:
            return self.__force_termination('TaskNotSupported')

        if tw.task.to_encrypt:
            self.op = self.encrypter
        elif tw.task.to_decrypt:
            self.op = self.decrypter

        try:
            self.op._on_new_task(tw)
        except Exception as e:
            self.__force_termination(traceback.format_exc())

    def _on_task_abort(self, tw):
        """
        Clean the environment in case of abort message is received
        """
        try:
            self.op._on_task_abort(tw)
        except Exception as e:
            self.__force_termination(traceback.format_exc())

    def _on_task_complete(self, tw):
        """
        Clean the environment in case of task complete successfully
        """
        try:
            self.op._on_task_complete(tw)
        except Exception as e:
            self.__force_termination(traceback.format_exc())

    def _task_step(self, tw):
        """
        Exec a single step of a task
        """
        try:
            self.completed = self.op._task_step(tw)
        except Exception as e:
            self.__force_termination(traceback.format_exc())

    def _is_task_completed(self, tw):
        return self.op.completed

########NEW FILE########
__FILENAME__ = worker_watcher
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the worker_watcher module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
from filerockclient.workers.filters.abstract.worker_watcher import WorkerWatcher as AbstractWorkerWatcher
from filerockclient.workers.filters.encryption import utils
from filerockclient.interfaces import PStatuses

import hashlib
from task_wrapper import TaskWrapper
from worker import Worker
import os, time
import stat
from binascii import hexlify


class WorkerWatcher(AbstractWorkerWatcher):
    """
    CryptoWorkerWatcher wrap the task and send it to the Worker

    Extends the prototypes.WorkerWatcher.WorkerWatcher Class
    """


    def __init__(self, index, queue, connector, cfg, warebox, enc_dir, lockfile_fd):
        """
        Initializes the WorkerWatcher adding configuration object, TaskWrapper and Worker specific classes

        """
        AbstractWorkerWatcher.__init__(self, index, queue, connector, 'CryptoWorkerWatcher')
        self.logger = logging.getLogger('FR.%s' % self.getName())
        self.cfg = cfg
        self.warebox = warebox
        self.enc_dir = enc_dir
        self.lockfile_fd = lockfile_fd

    def _on_init(self):
        """
        Initializes the worker watcher
        """
        self.TaskWrapper = TaskWrapper
        self.Worker = Worker

    def _create_worker(self):
        """
        Creates a worker
        """
        return self.Worker(self.tasks, 
                           self.cmd,
                           self.termination,
                           self.warebox.get_warebox_path(),
                           self.lockfile_fd)

    def _wrap_task(self, task):
        """
        Wraps a task
        """
        tw = self.TaskWrapper(task)
        tw.prepare(self.cfg, self.enc_dir)
        return tw

    def __is_directory(self, pathname):
        """
        Tells if a pathname corresponds to a directory.

        """
        return pathname.endswith('/')

    def __get_local_file_etag(self, pathname):
        """
        Returns result of proper hash function defined in configuration file.
        Large files are processed in chunks to avoid memory consumption.
        Returns the hash of an empty string if file is ... well, not a file or a symlink
        """
        result = False
        counter = 0
        while counter < 3:
            try:
                md5 = hashlib.md5()
                if not os.path.isfile(pathname):
                    md5.update('') # Right now, etag for dir is built on '' ... we might put information in here
                else:
                    with open(pathname,'rb') as current_file:
                        for chunk in iter(lambda: current_file.read(8192), ''):
                            md5.update(chunk)
                result=True
                break
            except IOError:
                counter += 1
                time.sleep(1)
        if not result:
            raise IOError

        return md5.digest()


    def __check_enc_dir(self, pathname):
        """
        checks for enc dir inexistence and create it if needed
        """
        if os.path.exists(pathname) and os.path.isdir(pathname):
            return True

        if os.path.exists(pathname) and not os.path.isdir(pathname):
            os.unlink(pathname)

        if not os.path.exists(pathname):
            os.makedirs(pathname)


    def __compute_md5_hex(self, pathname):
        '''
        Returns an hexadecimal text representation of the MD5 hash of the
        given pathname's data.
        '''
        return hexlify(self.__get_local_file_etag(pathname))

    def __get_local_file_size(self, pathname):
        """
        Returns the size of the given pathname
        """
        if not self.__is_directory(pathname):
            return os.stat(pathname)[stat.ST_SIZE]
        else:
            return 0

    def _on_new_task(self, task):
        """
        Applies custom action on new task
        """
        self.__check_enc_dir(self.enc_dir)
        self.warebox._check_blacklisted_dir()

    def _try_remove(self, pathname):
        max_retry = 2
        for i in range(max_retry):
            try:
                os.remove(pathname)
            except Exception:
                self.logger.debug(u"Failed to delete %s" % pathname)
                if i == (max_retry-1):
                    self.logger.debug("Giving up on %s deletion" % pathname)
                else:
                    self.logger.debug(u"I'll retry after one second")
                    time.sleep(1)
            else:
                self.logger.debug(u'File %s deleted' % pathname)
                break


    def _on_success(self, tw, result):
        """
        Applies custom actions on task if its computation ends successfully
        """
        if tw.task.to_encrypt:
            tw.task.storage_size = self.__get_local_file_size(tw.task.encrypted_pathname)
            tw.task.storage_etag = self.__compute_md5_hex(tw.task.encrypted_pathname)
            self.logger.debug(u'Successfully encrypted %s to %s' % (tw.task.pathname, tw.task.encrypted_pathname))
        elif tw.task.to_decrypt:
            self.warebox.move(tw.task.temp_pathname,
                              tw.task.pathname,
                              tw.task.conflicted)
            tw.task.warebox_etag = self.warebox.compute_md5_hex(tw.task.pathname)
            tw.task.warebox_size = self.warebox.get_size(tw.task.pathname)

            lmtime = self.warebox.get_last_modification_time(tw.task.pathname)
            tw.task.lmtime = lmtime
            tw.task.notify_pathname_status_change(PStatuses.ALIGNED)

            self.logger.debug(u'Successfully decrypted %s to %s' % (tw.task.encrypted_pathname, tw.task.pathname))
            if os.path.exists(tw.task.encrypted_pathname):
                self._try_remove(tw.task.encrypted_pathname)
            
            tw.task.complete()

    def _on_fail(self, tw, result):
        """
        Applies custom actions on task if its computation ends unsuccessfully
        """
        if (tw.task.to_encrypt or tw.task.to_decrypt) \
        and tw.task.encrypted_pathname is not None \
        and os.path.exists(tw.task.encrypted_pathname):
            self._try_remove(tw.task.encrypted_pathname)

        if tw.task.to_decrypt \
        and tw.task.temp_pathname is not None \
        and os.path.exists(tw.task.temp_pathname): #if decrypt task fails, also the uncompleted decrypted files have to be deleted
            self._try_remove(tw.task.temp_pathname)

########NEW FILE########
__FILENAME__ = worker
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the worker module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os
import logging
import threading
import multiprocessing
import Queue
import traceback
from threading import Thread
from datetime import datetime

from filerockclient.pathname_operation import PathnameOperation
from filerockclient.serversession.states.sync_download import \
    CreateDirectoriesTask, DeleteLocalTask, ResolveDeletionConflictsTask
from filerockclient.util.ipc_log_receiver import LogsReceiver
from filerockclient.workers.worker_child import WorkerChild
from filerockclient.interfaces import PStatuses
from filerockclient.workers.filters.encryption import utils as CryptoUtils
from filerockclient.util.utilities import _try_remove
from filerockclient.integritycheck.IntegrityManager import \
    IntegrityManager, WrongBasisFromProofException
from filerockclient.integritycheck.ProofManager import MalformedProofException


class OperationRejection(Exception):

    def __init__(self, operation, message=''):
        Exception.__init__(self, message)
        self.operation = operation


class Worker(Thread):
    '''A worker takes something to do and does it, and then again takes
    something to do etc.
    '''

    def __init__(self,
                 warebox,
                 operation_queue,
                 server_session,
                 cfg,
                 cryptoAdapter,
                 worker_pool):
        """
        @param warebox:
                    Instance of filerockclient.warebox.Warebox.
        @param cfg:
                    Instance of filerockclient.config.ConfigManager.
        @param operation_queue:
                    A threading queue, where worker receives the operations
        @param worker_pool:
                    Instance of filerockclient.workers.worker.Worker
        """
        Thread.__init__(self, name=self.__class__.__name__)
        self.cfg = cfg
        self.operation_queue = operation_queue
        self._server_session = server_session
        self.warebox = warebox
        self.child = None

        self.input_queue = None
        self.communicationQueue = None
        self.child_logger = None
        self.child_logs_queue = None
        self.cryptoAdapter = cryptoAdapter
        self.integrity_manager = IntegrityManager(None)

        self._worker_pool = worker_pool
        self.must_die = threading.Event()
        self.last_send = datetime.now()
        self.communicationQueue = None
        self.child_logs_queue = None

    def run(self):
        """
        Serves file operations until termination request is received
        """
        try:
            self.name += "_%s" % self.ident
            self.logger = logging.getLogger("FR.%s" % self.getName())
            self.logger.debug(u'Started.')
            while not self._termination_requested():
                self._serve_file_operations()
            self.logger.debug(u"I'm terminated.")
        finally:
            self._terminate_child()

    def _serve_file_operations(self):
        """
        Blocks on operation queue until a message is received

        If the message is a POISON_PILL the worker terminate it self
        If the message is a non aborted file operation,
        an abort handler is registered to it and the operation is handled
        """

        file_operation = self.operation_queue.get()
        if file_operation == 'POISON_PILL':
            self._on_poison_pill()
            return

        assert type(file_operation) in [PathnameOperation,
                                        CreateDirectoriesTask,
                                        DeleteLocalTask,
                                        ResolveDeletionConflictsTask]

        self.logger.debug(u"worker executing: %s", file_operation)
        if __debug__:
            self._worker_pool.track_assign_worker_to_pathname(
                self.ident,
                file_operation.pathname)

        try:
            self.warebox._check_blacklisted_dir()
            if file_operation.is_aborted():
                self.logger.debug(u"Got an already aborted operation, "
                                  "giving up: %s" % file_operation)
            else:
                self.logger.debug(u"Got an operation to handle: %s",
                                  file_operation)
                file_operation.register_abort_handler(self.on_operation_abort)
                self._handle_file_operation(file_operation)

        except Exception:
            self.logger.error(u"Some problem occurred in worker "
                              u"handling operation %r" % file_operation)
            raise

        finally:
            self.logger.debug("Releasing a worker")

            if __debug__:
                self._worker_pool.track_assert_assigned(
                    self.ident, file_operation.pathname)

            self._worker_pool.release_worker()

            if __debug__:
                self._worker_pool.track_release_worker(
                    self.ident,
                    file_operation.pathname)

    def _handle_file_operation(self, file_operation):
        if file_operation.verb == 'UPLOAD':
            self._handle_upload_file_operation(file_operation)
        elif file_operation.verb == 'DOWNLOAD':
            self._handle_download_file_operation(file_operation)
        elif file_operation.verb == 'DELETE_LOCAL':
            self._handle_delete_local_file_operation(file_operation)
        elif file_operation.verb == 'CREATE_DIRECTORIES':
            self._handle_operation_create_directories(file_operation)
        elif file_operation.verb == 'RESOLVE_DELETION_CONFLICTS':
            self._handle_operation_resolve_deletion_conflicts(file_operation)
        else:
            self.logger.warning(u"I should not handle a '%s' operation! "
                                "I'm rejecting it", file_operation.verb)
            file_operation.reject()

    def _send_percentage(self, file_operation, status, percentage):
        now = datetime.now()
        delta = now - self.last_send
        if ((delta.seconds + delta.microseconds/1000000.) > 0.5) \
                or (percentage == 100):
            file_operation.notify_pathname_status_change(
                status, {'percentage': percentage})
            self.last_send = now

    def _handle_network_transfer_operation(self, file_operation):
        '''By locking we mantain the following invariant: if the
        EventQueue tries to abort this operation due to a conflicting
        operation, then EventQueue waits until this operation either
        aborts or completes.
        This preserves the ordering of execution for the conflicting
        operations - that is, the EventQueue doesn't emit
        the conflicting operation while this one is still working.
        '''

        with file_operation.lock:
            if not file_operation.is_aborted():
                self.logger.debug(u"Starting child process to handle file"
                                  " operation: %s" % file_operation)
                try:
                    self._spawn_child(file_operation)
                    self.input_queue.put(('FileOperation', file_operation))
                except Exception as e:
                    self.logger.error(
                        u"Could not spawn a child process: %r" % e)
                    raise OperationRejection(file_operation)
            else:
                self.logger.debug(u"Got an already aborted operation, "
                                  "giving up: %s" % file_operation)
                return False

        if file_operation.verb == 'UPLOAD':
            status = PStatuses.UPLOADING
        else:
            status = PStatuses.DOWNLOADING

        self._send_percentage(file_operation, status, 0)
        termination = False
        max_retry = 3

        while not termination:
            message, content = self.communicationQueue.get()
            self.logger.debug(u'Worker send back %s with content %s'
                              % (message, content))

            if message == 'completed':
                termination = True
                if file_operation.verb == 'DOWNLOAD':
                    return {'actual_etag': content['actual_etag']}
                else:
                    return True

            elif message == 'interrupted':
                self.logger.debug(u"Child has been terminated by "
                                  "Software Operation: %s"
                                  % file_operation)
                file_operation.abort()
                termination = True
                return False

            elif message == 'failed':
                self.logger.error(u"Child has been terminated, "
                                  "Assuming failure for operation: %s"
                                  % file_operation)
                max_retry -= 1
                if max_retry == 0:
                    raise OperationRejection(file_operation)
                self.input_queue.put(('FileOperation', file_operation))

            elif message == 'percentage':
                self._send_percentage(file_operation, status, content)

            elif message == 'log':
                level, msg = content
                self.child_logger[level](msg)

            elif message == 'ShuttingDown':
                self.logger.debug(u"Get a shutting down message from process")
                termination = True
                return False

            elif message == 'DIED':
                self.child = None
                termination = True
                raise OperationRejection(file_operation)

    def _handle_upload_file_operation(self, operation):
        try:
            success = self._handle_network_transfer_operation(operation)
            if success:
                CryptoUtils.clean_env(operation, self.logger)
                self.logger.debug(u"Operation has been completed "
                                  "successfully: %s" % operation)
                self.logger.info(u'Synchronized pathname: %s "%s", which '
                                 'will be persisted after a commit'
                                 % (operation.verb, operation.pathname))
                operation.notify_pathname_status_change(PStatuses.UPLOADED,
                                                        {'percentage': 100})
                operation.complete()

        except Exception as e:
            self.logger.error(u"Error while uploading: %r."
                              " Rejecting the operation: %s" % (e, operation))
            operation.reject()

    def _handle_operation_create_directories(self, task):
        operations = sorted(task.operations, key=lambda op: op.pathname)
        actual_etag = 'd41d8cd98f00b204e9800998ecf8427e'

        for operation in operations:

            # Check integrity
            operation.notify_pathname_status_change(PStatuses.DOWNLOADING)
            res = self._check_download_integrity(operation, actual_etag)
            if not res['valid']:
                # Detected an integrity error. Badly bad.
                self._server_session.signal_download_integrity_error(
                    operation, res['reason'],
                    res['expected_etag'], res['expected_basis'],
                    res['actual_etag'], res['computed_basis'])
                return

            # The directory is valid, create it
            self._make_directories_to(operation.pathname)
            lmtime = self.warebox.get_last_modification_time(operation.pathname)
            operation.lmtime = lmtime
            operation.notify_pathname_status_change(PStatuses.ALIGNED)
            operation.complete()
            self.logger.info(u'Synchronized pathname: %s "%s"'
                             % (operation.verb, operation.pathname))
            self.logger.debug(u"Operation has been completed "
                              "successfully: %s" % operation)

        task.complete()

    def _handle_download_file_operation(self, operation):
        try:
            # Note: it is a normal file, not a directory
            CryptoUtils.set_temp_file(operation, self.cfg)
            success = self._handle_network_transfer_operation(operation)

            if success:

                actual_etag = success['actual_etag']
                res = self._check_download_integrity(operation, actual_etag)
                if not res['valid']:
                    # Detected an integrity error. Badly bad.
                    self._server_session.signal_download_integrity_error(
                        operation, res['reason'],
                        res['expected_etag'], res['expected_basis'],
                        res['actual_etag'], res['computed_basis'])
                    return

                self._make_directories_to(operation.pathname)

                if operation.to_decrypt:
                    # We have not finished yet, leaving the rest to decrypter.
                    # Note: the decrypter duplicates the following ending logic
                    self.cryptoAdapter.put(operation)
                    return

                # It is a valid cleartext file, move it to the warebox
                self.warebox.move(operation.temp_pathname,
                                  operation.pathname,
                                  operation.conflicted)

                self.logger.debug(u"Operation has been completed "
                                  "successfully: %s" % operation)
                self.logger.info(u'Synchronized pathname: %s "%s"'
                                 % (operation.verb, operation.pathname))

                lmtime = self.warebox.get_last_modification_time(operation.pathname)
                operation.lmtime = lmtime
                operation.notify_pathname_status_change(PStatuses.ALIGNED)
                operation.complete()

        except Exception as e:
            self.logger.error(u"Error while downloading: %r."
                              " Rejecting the operation: %s" % (e, operation))
            self.logger.error(u"Stacktrace: %r" % traceback.format_exc())
            operation.reject()

        finally:
            # Just in case the move had failed for any reason
            if not operation.to_decrypt:
                if operation.temp_pathname is not None \
                and os.path.exists(operation.temp_pathname):
                    _try_remove(operation.temp_pathname, self.logger)

    def _make_directories_to(self, pathname):
        """Make sure that the full path for this file exists. It may be
        either a file or a directory.

        There are a couple of reasons why the full path may not exist:
        1) Data has been loaded on the storage with an external tool
           that doesn't explicitly support directories, so they have
           not been created. Treating these directories as something
           to download is wrong: they wouldn't pass the integrity
           check (they really doesn't exist in the trusted dataset),
           so it is better to make them as new local modifications.
        2) The user has deleted while offline a directory that is
           needed by a download. We call it "hierarchy conflict" and
           is uncovered by the diff algorithm, since case 1 would
           still remain unhandled.
        """
        self.warebox.make_directories_to(pathname)

    def _check_download_integrity(self, operation, actual_etag):
        pathname = operation.pathname
        proof = operation.download_info['proof']
        basis = operation.download_info['trusted_basis']

        self.integrity_manager.trusted_basis = basis

        result = {}
        result['valid'] = None
        result['reason'] = None
        result['expected_etag'] = operation.storage_etag
        result['expected_basis'] = basis
        result['actual_etag'] = actual_etag
        result['computed_basis'] = None

        if operation.storage_etag != actual_etag:
            # Note: the etag inside the proof will be
            # checked by the integrity manager.
            self.logger.debug(
                u"Invalid etag of download operation. "
                "Expected etag %s but found %s. %s"
                % (operation.storage_etag, actual_etag, operation))
            result['valid'] = False
            result['reason'] = "Expected etag different from actual etag"
            return result

        try:
            self.integrity_manager.addOperation('DOWNLOAD',
                                                pathname,
                                                proof,
                                                actual_etag)
            result['valid'] = True
            result['computed_basis'] = basis

        except MalformedProofException as e:
            self.logger.debug(u"Invalid proof of download operation: "
                              "%s. %r, %r" % (e, operation, proof))
            self.logger.debug(traceback.format_exc())
            result['valid'] = False
            result['reason'] = "%s" % e

        except WrongBasisFromProofException as e:
            self.logger.debug(u"Integrity check of download operation failed."
                              "Basis %s was expected but the proof computed "
                              "%s. Error details: %s. %r, %r" %
                              (basis, e.operation_basis, e, operation, proof))
            self.logger.debug(traceback.format_exc())
            result['valid'] = False
            result['reason'] = "%s" % e
            result['computed_basis'] = e.operation_basis

        except Exception as e:
            self.logger.debug(u"Integrity check of download operation failed"
                              " with unknown reason: %s. %r, %r"
                              % (e, operation, proof))
            self.logger.debug(traceback.format_exc())
            result['valid'] = False
            result['reason'] = "%s" % e

        finally:
            self.integrity_manager.clear()

        return result

    def _handle_delete_local_file_operation(self, task):
        pathnames = sorted(task.pathname2proof.keys())
        #self.logger.debug("Going to delete pathnames: %s" % pathnames)

        for pathname in pathnames:
            basis = task.trusted_basis
            proof = task.pathname2proof[pathname]
            res = self._check_deletelocal_integrity(pathname, proof, basis)
            if not res['valid']:
                # Detected an integrity error. Badly bad.
                self._server_session.signal_deletelocal_integrity_error(
                    pathname, proof, res['reason'],
                    res['expected_basis'], res['computed_basis'])
                return

        roots = {}
        for pathname in pathnames:
            found_ancestor = False
            for root in roots:
                if pathname.startswith(root):
                    found_ancestor = True
                    break
            if not found_ancestor:
                roots[pathname] = True

        try:
            for pathname in roots.iterkeys():
                self.warebox.delete_tree(pathname)
        except Exception as e:
            self.logger.error(
                u"Caught an operating system exception while "
                u"modifying the filesystem. Are you locking the Warebox? % r"
                % e)
            raise

        task.complete()

    def _check_deletelocal_integrity(self, pathname, proof, trusted_basis):
        self.integrity_manager.trusted_basis = trusted_basis

        result = {}
        result['valid'] = None
        result['reason'] = None
        result['expected_basis'] = trusted_basis
        result['computed_basis'] = None

        try:
            self.integrity_manager.addOperation('DELETE_LOCAL',
                                                pathname,
                                                proof,
                                                None)
            result['valid'] = True
            result['computed_basis'] = trusted_basis

        except MalformedProofException as e:
            self.logger.debug(u"Invalid proof of delete_local operation: "
                              "%s. %s, %s" % (e, pathname, proof.raw))
            self.logger.debug(traceback.format_exc())
            result['valid'] = False
            result['reason'] = "%s" % e

        except WrongBasisFromProofException as e:
            self.logger.debug(u"Integrity check of delete_local operation failed."
                              "Basis %s was expected but the proof computed "
                              "%s. Error details: %s. %r, %r" %
                              (trusted_basis, e.operation_basis, e, pathname, proof.raw))
            self.logger.debug(traceback.format_exc())
            result['valid'] = False
            result['reason'] = "%s" % e
            result['computed_basis'] = e.operation_basis

        except Exception as e:
            self.logger.debug(u"Integrity check of delete_local operation"
                              " failed with unknown reason: %s. %r, %r"
                              % (e, pathname, proof.raw))
            self.logger.debug(traceback.format_exc())
            result['valid'] = False
            result['reason'] = "%s" % e

        finally:
            self.integrity_manager.clear()

        return result

    def _find_new_name(self, pathname):
        # TODO: try harder in finding a name that is available
        curr_time = datetime.now().strftime('%Y-%m-%d %H_%M_%S')
        suffix = ' (Conflicted on %s)' % curr_time
        if pathname.endswith('/'):
            new_pathname = pathname[:-1] + suffix + '/'
        else:
            basename, ext = os.path.splitext(pathname)
            new_pathname = basename + suffix + ext
        return new_pathname

    def _rename_conflicting_pathname(self, pathname, prefix=None):
        new_pathname = self.warebox.rename(pathname, pathname, prefix)
        return new_pathname

    def _handle_operation_resolve_deletion_conflicts(self, task):
        """Solve deletion conflicts by renaming the local file to a new
        pathname. The old pathname will result implicitly deleted.

        Deletion conflicts are tough to resolve. A conflicting pathname:
        a) has been deleted by the server
        b) has an ancestor folder that has been deleted by the server
        c) both
        It must be checked if it's safe leaving the file in its original
        folder (that is, if it still exists).
        """
        conflicts = task.deletion_conflicts
        content_to_delete_locally = task.content_to_delete_locally

        for pathname in conflicts:
            basis = task.trusted_basis
            proof = task.pathname2proof[pathname]
            res = self._check_deletelocal_integrity(pathname, proof, basis)
            if not res['valid']:
                # Detected an integrity error. Badly bad.
                self._server_session.signal_deletelocal_integrity_error(
                    pathname, proof, res['reason'],
                    res['expected_basis'], res['computed_basis'])
                return

        try:
            backupped_folders = {}
            for pathname in conflicts:
                missing_ancestor_folders = filter(lambda p: pathname.startswith(p), content_to_delete_locally)
                # Is it safe leaving the file in its original folder?
                if len(missing_ancestor_folders) > 0:
                    # No, it's been deleted. Backup the whole deleted subtree
                    missing_ancestor_folders = sorted(missing_ancestor_folders)
                    highest_missing_folder = missing_ancestor_folders[0]
                    if not highest_missing_folder in backupped_folders:
                        backup_folder = self._find_new_name(highest_missing_folder)
                        self.warebox.make_directory(backup_folder)
                        backupped_folders[highest_missing_folder] = backup_folder
                    backup_folder = backupped_folders[highest_missing_folder]
                    new_pathname = pathname.replace(highest_missing_folder, backup_folder, 1)
                    self.warebox.make_directories_to(new_pathname)
                    if not self.warebox.is_directory(new_pathname):
                        self.warebox.rename(pathname, new_pathname)
                else:
                    # Yes, just rename the file
                    new_pathname = self._rename_conflicting_pathname(pathname, 'Deleted')
                    self.logger.warning(
                        u"Conflict detected for pathname %r, which has been "
                        u"remotely deleted. Moved the local copy to: %r"
                        % (pathname, new_pathname))

            task.complete()

        except Exception:
            self.logger.error(
                u"Caught an operating system exception while modifying the "
                u"filesystem. Are you locking the Warebox?")
            raise

    def _start_child_logger(self):
        self._stop_child_logger()
        self.child_logs_queue = multiprocessing.Queue()
        self.child_logger = LogsReceiver(self.getName(), self.child_logs_queue)
        self.child_logger.start()
        if self.child_logger is None:
            logger = logging.getLogger(u'FR.WorkerChild of %s' % self.getName())
            self.child_logger = {
                'info': logger.info,
                'debug': logger.debug,
                'warning': logger.warning,
                'error': logger.error,
                'critical': logger.critical
            }

    def _stop_child_logger(self):
        if self.child_logger is not None:
            self.child_logger.stop()
            self.child_logs_queue.put(('log', ('debug', 'Die please!')))
            self.child_logger.join()
            self.child_logger = None

        if self.child_logs_queue is not None:
            self.child_logs_queue.close()
            self.child_logs_queue.join_thread()
            self.child_logs_queue = None

    def _create_multiprocessing_queues(self):
        self._destroy_multiprocessing_queues()
        self.input_queue = Queue.Queue()
        self.communicationQueue = Queue.Queue()

    def _destroy_multiprocessing_queue(self, queue):
        if queue is not None:
            while not queue.empty():
                queue.get_nowait()
#             queue.close()
#             queue.join_thread()
            queue = None

    def _destroy_multiprocessing_queues(self):
        self._destroy_multiprocessing_queue(self.input_queue)
        self._destroy_multiprocessing_queue(self.communicationQueue)

    def _spawn_child(self, file_operation):
        if self.child is None or not self.child.is_alive():
#             self.terminationEvent = multiprocessing.Event()
            self.terminationEvent = threading.Event()
            self._create_multiprocessing_queues()
            self._start_child_logger()
            try:
                self.logger.debug(u"Allocating child process to handle file "
                                  "operation: %s" % file_operation)
                self.child = WorkerChild(self.warebox,
                                         self.input_queue,
                                         self.communicationQueue,
                                         self.terminationEvent,
                                         self._send_percentage,
                                         #self.child_logs_queue,
                                         self.cfg,
                                         self._worker_pool)

                self.child.start()
                self.logger.debug(u"Child process Started to handle file "
                                  "operation: %s" % file_operation)
            except Exception:
                self._stop_child_logger()
                raise

    def on_operation_abort(self, file_operation):
        self.logger.debug(u'Abort detected for the operation I am handling: '
                          '%s. Terminating child process...' % file_operation)
        self.abort_operation()

    def abort_operation(self):
        if self.child is not None and self.child.is_alive():
            try:
                if self.terminationEvent is not None:
                    self.terminationEvent.set()
#                 else:
#                     self.child.terminate()
            except:
                pass

    def _terminate_child(self):
        self.stop_network_transfer()
        if self.child is not None:
            self.input_queue.put(('PoisonPill', None))
            self.child.join(5)
            self.child = None

    def _clean_env(self):
        self._terminate_child()
        self._stop_child_logger()
        self._destroy_multiprocessing_queues()

    def _on_poison_pill(self):
        self.logger.debug(u"Got poison pill.")
        self.must_die.set()
        self._clean_env()

    def terminate(self):
        '''
        Signal the worker that the time has come.
        '''
        self.abort_operation()

    def stop_network_transfer(self):
        self.abort_operation()

    def _termination_requested(self):
        return self.must_die.wait(0.01)


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = worker_child
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the worker_child module.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from tempfile import mkstemp
import traceback
import os
import logging
from threading import Thread

from filerockclient.interfaces import PStatuses
from filerockclient.storage_connector import StorageConnector
from filerockclient.util.utilities import stoppable_exponential_backoff_waiting


DOWNLOAD_DIR = 'downloads'

SUCCESS = 0
INTERRUPTED = 1
FAILED = 2


class WorkerChild(Thread):
    """
    Handle the upload and download of files

    Communicates with the core within multiprocess queues
    """

    def __init__(self,
                 warebox,
                 inputQueue,
                 communicationQueue,
                 terminationEvent,
                 percentage_callback,
                 cfg,
                 pool):
        """
        @param inputQueue:
                    multiprocess queue used to send pathname_operation
                    to the child
        @param communcationQueue:
                    multiprocess queue used to send back results
        @param terminationEvent:
                    multiprocess event used to stop the upload/download
        @param logs_queue:
                    multiprocess queue used to send back log messages
        @param cfg:
                    instance of filerockclient.config.ConfigManager
        """
        super(WorkerChild, self).__init__(name=self.__class__.__name__)

        self.inputQueue = inputQueue
        self.communicationQueue = communicationQueue
        self.terminationEvent = terminationEvent
        self.cfg = cfg
        self.up_bandwidth = pool.up_bandwidth
        self.down_bandwidth = pool.down_bandwidth
        self.percentage_callback = percentage_callback
        self.warebox = warebox

    def _check_download_dir(self, download_dir):
        if os.path.exists(download_dir) and os.path.isdir(download_dir):
            return True
        elif os.path.exists(download_dir) and not os.path.isdir(download_dir):
            os.unlink(download_dir)
        elif not os.path.exists(download_dir):
            os.makedirs(download_dir)

    def _get_download_dir(self):
        temp_dir = self.cfg.get('Application Paths', 'temp_dir')
        temp_dir = os.path.join(temp_dir, DOWNLOAD_DIR)
        self._check_download_dir(temp_dir)
        return temp_dir

    def _get_temp_file(self, file_operation):
        if file_operation.verb == 'DOWNLOAD':
            temp_dir = self._get_download_dir()
            temp_fd, temp_pathname = mkstemp(dir=temp_dir)
            os.close(temp_fd)
            file_operation.temp_pathname = temp_pathname
            file_operation.temp_fd = temp_fd

    def _more_init(self):
        """
        Executed after the process has started.
        Set here non-picklable attributes
        """
        self.name += "_%s" % self.ident
        self.logger = self.logger = logging.getLogger("FR.%s" % self.getName())
        self.connector = StorageConnector(self.warebox, self.cfg)

    def run(self):
        """
        Handles file operation received through the inputQueue until
        a poison pill is received, sends back logs and results through
        communicationQueue
        """

        try:
            self._more_init()
            termination = False

            while not termination:

                operation, file_operation = self.inputQueue.get()
                self.logger.debug('==> Operation type %s, content %s' %
                                  (operation, file_operation))

                if operation == 'FileOperation':
                    self.terminationEvent.clear()
                    self.logger.debug(u'Started to handle %s' % file_operation)
                    self._get_temp_file(file_operation)
                    result = self._handle_operation(file_operation)

                    if result['status'] == SUCCESS:
                        self.logger.debug(
                                u'Operation completed: %s. Returning.'
                                % file_operation)
                        self.communicationQueue.put(('completed', result))

                    elif result['status'] == INTERRUPTED:
                        self.logger.debug(
                                u'Failed performing operation %s. '
                                'INTERRUPTED.' % file_operation)
                        self.communicationQueue.put(('interrupted', None))

                    elif result['status'] == FAILED:
                        self.logger.debug(
                                u'Failed performing operation %s. '
                                'Returning.' % file_operation)
                        self.communicationQueue.put(('failed', None))

                elif operation == 'PoisonPill':
                    termination = True
                    self.logger.debug(u"I'm going to die")
                    self.communicationQueue.put(('ShuttingDown', None))

        except Exception:
            self.communicationQueue.put(('DIED', None))
            raise

    def _handle_operation(self, file_operation):
        """
        Handles a file_operation, uploading o downloading the associated file

        @param file_operation: instance of filerockclient.pathname_operation
        """
        try:
            if file_operation.verb == 'UPLOAD':
                result = self._handle_upload_operation(file_operation)
                return result
            elif file_operation.verb == 'DOWNLOAD':
                result = self._handle_download_operation(file_operation)
                return result
            else:
                self.logger.debug(u'Unsupported verb for operation,'
                                  ' giving up: %s' % file_operation)
                result = {'status': FAILED}
                return result
        except Exception as e:
            self.logger.debug(u'Exception caught: %s\n%s'
                              % (e, traceback.format_exc()))
            result = {'status': FAILED}
            return FAILED

    def _handle_upload_operation(self, file_operation):
        """
        Handles upload operation

        Prepares useful data and delegates to the connector the upload

        @param file_operation: instance of filerockclient.pathname_operation
        """

        if file_operation.to_encrypt:
            pathname = file_operation.encrypted_pathname
            open_function = open
            etag = file_operation.storage_etag
            size = file_operation.storage_size
            iv = file_operation.iv
        else:
            pathname = file_operation.pathname
            open_function = self.warebox.open
            etag = file_operation.warebox_etag
            size = file_operation.warebox_size
            iv = None

        args = [
            pathname,
            file_operation.upload_info['remote_pathname'],
            file_operation.upload_info['remote_ip_address'],
            file_operation.upload_info['bucket'],
            file_operation.upload_info['auth_token'],
            file_operation.upload_info['auth_date'],
            open_function,
            etag,
            size,
            iv
        ]

        percentage_callback = \
            lambda percentage: \
            self.percentage_callback(file_operation,
                                     PStatuses.UPLOADING,
                                     percentage)
        do_upload = \
            lambda event: \
            self.connector.upload_file(*args,
                                       terminationEvent=event,
                                       percentageQueue=percentage_callback,
                                       logger=self.logger,
                                       bandwidth=self.up_bandwidth)

        return self._perform_network_transfer(do_upload, file_operation)

    def _handle_download_operation(self, file_operation):
        """
        Handles download operation

        Prepares useful data and delegates to the connector the download

        @param file_operation: instance of filerockclient.pathname_operation
        """
        if file_operation.to_decrypt:
            pathname = file_operation.encrypted_pathname
            open_function = open
        else:
            pathname = file_operation.temp_pathname
            open_function = open

        args = [
            pathname,
            file_operation.pathname,
            file_operation.download_info['remote_ip_address'],
            file_operation.download_info['bucket'],
            file_operation.download_info['auth_token'],
            file_operation.download_info['auth_date'],
            open_function
        ]

        percentage_callback = \
            lambda percentage: \
            self.percentage_callback(file_operation,
                                     PStatuses.DOWNLOADING,
                                     percentage)

        def do_download(event):
            result = self.connector.download_file(
                *args,
                terminationEvent=event,
                percentageQueue=percentage_callback,
                logger=self.logger,
                bandwidth=self.down_bandwidth)
            return result

        return self._perform_network_transfer(do_download, file_operation)

    def _perform_network_transfer(self, transfer_strategy, file_operation):
        """Does a limited number of attempts to perform the given transfer.

        In case of failure a certain time interval is awaited and another
        attempt is performed. The waiting time is doubled each time until
        the maximum amount of attempts is reached.
        The transfer could be interrupted in any time by setting
        terminationEvent.

        @param transfer_strategy:
                    lambda function wrapping the transfer method.
        @param file_operation:
                    instance of filerockclient.pathname_operation.

        """
        max_attempts = 10
        waiting_time = 1

        attempts = 0
        while not self.terminationEvent.is_set() and attempts <= max_attempts:
            self.logger.debug(u'Started network transfer for: %s "%s":'
                              % (file_operation.verb, file_operation.pathname))
            response = transfer_strategy(self.terminationEvent)

            if response['success']:
                self.logger.debug(u'Successfully ended network transfer'
                                  ' for: %s "%s":' %
                                  (file_operation.verb, file_operation.pathname))
                result = {'status': SUCCESS}
                if file_operation.verb == 'DOWNLOAD':
                    result['actual_etag'] = response['etag']
                return result

            elif 'termination' in response['details']:
                    result = {'status': INTERRUPTED}
                    return result

            self.logger.warning(u'HTTP %s failed for operation: %s. '
                                'Retrying in %s seconds...' %
                                (file_operation.verb, file_operation, waiting_time))
            self.logger.debug(u'Response details: %s' % (response['details']))
            waiting_time = stoppable_exponential_backoff_waiting(
                waiting_time, self.terminationEvent)
            attempts += 1

        if self.terminationEvent.is_set():
            # termination requested from outside
            result = {'status': INTERRUPTED}
            return result

        self.logger.error(u'Ok, I have tried performing %s for %d times.'
                          ' I am done now. Put that stuff in a FedEx box and'
                          ' send it via mail.'
                          % (file_operation, max_attempts))
        result = {'status': FAILED}
        return result


if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = worker_pool
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the worker_pool module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
import threading
import Queue
import os

from filerockclient.config import USER_DEFINED_OPTIONS
from filerockclient.workers.worker import Worker
from filerockclient.workers.worker_child import DOWNLOAD_DIR
from filerockclient.workers.bandwidth import Bandwidth
from filerockclient.workers.bandwidth import CHUNK_SIZE


class MyPriorityQueue(Queue.PriorityQueue):

    def get(self, block=True, timeout=None):
        _, element = Queue.PriorityQueue.get(self, block, timeout)
        return element

    def get_nowait(self):
        return self.get(False)


class WorkerPool(object):
    """Generates a pool of worker and manages them,
    it can send operations to the workers and keep count of free workers.

    The operations are sent through a queue and the counting is done by
    a semaphore.
    """

    def __init__(self, warebox, server_session, cfg, cryptoAdapter):
        """
        @param warebox:
                    Instance of filerockclient.warebox.Warebox.
        @param cfg:
                    Instance of filerockclient.config.ConfigManager.
        @param server_session:
                    Instance of filerockclient.serversession.server_session.
                    ServerSession.
        """

        self.started = False
        self._server_session = server_session
        self.logger = logging.getLogger("FR.%s" % self.__class__.__name__)
        self.how_many_workers = 4

        self.up_bandwidth = Bandwidth(
            cfg.getint(USER_DEFINED_OPTIONS, u'bandwidth_limit_upload'))
        self.down_bandwidth = Bandwidth(
            cfg.getint(USER_DEFINED_OPTIONS, u'bandwidth_limit_download'),
            max_chunk_size=CHUNK_SIZE*10)
        self.cfg = cfg
        self.worker_operation_queue = MyPriorityQueue()
        self.workers = []
        self.free_worker = threading.BoundedSemaphore(self.how_many_workers)

        for _ in range(self.how_many_workers):
            worker = Worker(warebox, self.worker_operation_queue,
                            server_session, cfg, cryptoAdapter, self)
            self.workers.append(worker)

        if __debug__:
            # If an entry (workerid, pathname) exists in both mappings it means
            # that workerid has been acquired and is working with that
            # pathname. If only the mapping pathname -> None exists, it means
            # that the worker has been acquired but has not been assigned to a
            # pathname yet.
            self.track_workerid2pathname = {}
            self.track_pathname2workerid = {}

    if __debug__:
        def track_acquire_anonymous_worker(self, pathname):
            assert pathname not in self.track_pathname2workerid
            self.track_pathname2workerid[pathname] = None
            self.logger.debug("track worker: after acquire %d, %d, %d" % (
                              self.free_worker._Semaphore__value,
                              len(self.track_workerid2pathname),
                              len(self.track_pathname2workerid)))

        def track_assign_worker_to_pathname(self, workerid, pathname):
            assert pathname in self.track_pathname2workerid
            assert self.track_pathname2workerid[pathname] is None
            assert workerid not in self.track_workerid2pathname
            self.track_pathname2workerid[pathname] = workerid
            self.track_workerid2pathname[workerid] = pathname
            self.logger.debug("track worker: after assigned %d, %d, %d" % (
                              self.free_worker._Semaphore__value,
                              len(self.track_workerid2pathname),
                              len(self.track_pathname2workerid)))

        def track_release_worker(self, workerid, pathname):
            p = self.track_workerid2pathname[workerid]
            assert p == pathname
            assert self.track_workerid2pathname[workerid] == p
            del self.track_workerid2pathname[workerid]
            del self.track_pathname2workerid[p]
            self.logger.debug("track worker: after release %d, %d, %d" % (
                              self.free_worker._Semaphore__value,
                              len(self.track_workerid2pathname),
                              len(self.track_pathname2workerid)))

        def track_release_unassigned_worker(self, pathname):
            assert pathname in self.track_pathname2workerid
            assert self.track_pathname2workerid[pathname] is None
            del self.track_pathname2workerid[pathname]
            self.logger.debug("track worker: after release unassigned %d, %d, %d" % (
                              self.free_worker._Semaphore__value,
                              len(self.track_workerid2pathname),
                              len(self.track_pathname2workerid)))

        def track_assert_acquired(self, pathname):
            """A worker for the pathname has been acquired but not assigned
            """
            assert pathname in self.track_pathname2workerid
            assert self.track_pathname2workerid[pathname] is None

        def track_assert_assigned(self, workerid, pathname):
            assert workerid in self.track_workerid2pathname
            p = self.track_workerid2pathname[workerid]
            assert p == pathname
            assert self.track_workerid2pathname[workerid] == p

    def start_workers(self):
        """Starts all the workers calling their start method
        """
        self.started = True
        for worker in self.workers:
            worker.start()

    def on_disconnect(self):
        """Terminates the workers processes and waits their termination
        """
        self.logger.debug('Stopping Workers')
        for w in self.workers:
            w.terminate_child()
        for w in self.workers:
            if self.free_worker.acquire(False):
                self.logger.debug('Acquiring the worker Semaphore')
        for w in self.workers:
            self.free_worker.release()
            self.logger.debug('Released the worker Semaphore')
        while True:
            try:
                self.worker_operation_queue.get_nowait()
            except Queue.Empty:
                break

    def on_connect(self):
        pass

    def send_operation(self, operation):
        """Put received operation into the worker operation queue

        @param operation: the operation to send
        """
        if __debug__:
            self.track_assert_acquired(operation.pathname)
        self.worker_operation_queue.put((1, operation))

    def acquire_worker(self):
        """Tries to acquire the free_worker semaphore

        @return: True if the semaphore was acquired, False otherwise
        """
        return self.free_worker.acquire(False)

    def exist_free_workers(self):
        """Checks the presence of a free worker trying to
        acquire the semaphore and releasing it

        @return: True if there is a free worker, false otherwise
        """
        exist = self.free_worker.acquire(False)
        if exist:
            self.free_worker.release()
        return exist

    def release_worker(self):
        """Releases the semaphore and sends a message to server session
        """
        assert len(self.track_pathname2workerid) > 0
        assert self.free_worker._Semaphore__value < self.how_many_workers
        self.free_worker.release()
        self._server_session.signal_free_worker()

    def _terminate_workers(self):
        """Sends the poison pill to each worker and waits for their termination
        """
        for w in self.workers:
            self.worker_operation_queue.put((0, 'POISON_PILL'))
            w.stop_network_transfer()

    def terminate(self):
        """Shutdown procedure.
        """
        self.logger.debug(u"Terminating WorkerPool...")
        if self.started:
            self.logger.debug(u"Terminating workers...")
            self._terminate_workers()
            for w in self.workers:
                w.join() if w is not threading.current_thread() else None
            self.logger.debug(u"Workers terminated.")
        self.logger.debug(u"WorkerPool terminated.")

    def clean_download_dir(self):
        """Deletes all the files in the encryption dir
        """
        folder = os.path.join(self.cfg.get('Application Paths','temp_dir'), DOWNLOAD_DIR)
        self.logger.debug('Cleaning encryption dir %s' % folder)
        if os.path.exists(folder):
            for the_file in os.listdir(folder):
                file_path = os.path.join(folder, the_file)
                try:
                    if os.path.isfile(file_path):
                        self.logger.debug('Unlinking file %s' % file_path)
                        os.unlink(file_path)
                except Exception:
                    self.logger.exception('Error cleaning temp encryption dir')

if __name__ == '__main__':
    pass

########NEW FILE########
__FILENAME__ = JsonSerializable
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Json-serializable object


Provides JsonSerializable class which can
be extended by object to be json-serializable.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""


import json

MESSAGES_LIBRARY_MODULE = 'FileRockSharedLibraries.Communication.Messages'

class BadJsonSerializableParametersSetException(Exception): pass

class JsonSerializable(object):
    ''' 
    Objects which should be packed inside messages must be JsonSerializable.
    That means, they must extend this class and override its methods
    according to what specified in the docstrings.
    At least, they must declare their own fields dictionary, like:
    { 'parameter_name' : < parameter_default_value | None_if_optional > }
    '''
    
    _fields = {}
    
    def __init__(self, parameters):
        '''
        The class constructor gets only one parameter @parameters.
        This could be either a json-encoded dictionary or a dictionary itself.
        For each entry in the dictionary, a field is set for the instance.
        This will successfully create an instance of the class with proper fields,
        but will only work if fields are basic types. Otherwise, this method
        should be overridden to take care of more complex serialized stuff.
        '''
        if not isinstance(parameters, dict): parameters = json.loads(parameters, encoding='utf-8')
        try: assert isinstance(parameters, dict)
        except AssertionError: raise BadJsonSerializableParametersSetException('Wrong parameters arg for JsonSerializable object.')
        for param in parameters.keys(): self.__setattr__(param, parameters[param])
        
    @classmethod
    def _serialize(classname, values={}):
        ''' 
        The static classmethod _serialize, is supposed to return a json-encoded representation of the class fields,
        in the format digested by __init__, i.e., as a dictionary of basic types.
        @values: a dictionary containing the actual values of the fields for the instance to be serialized.
        Extending classes can avoid overriding this method if and only if their fields are basic types. 
        '''
        attributes_map = {}
        module = __import__(MESSAGES_LIBRARY_MODULE, fromlist=['Messages'])
        classtype = getattr(module, classname.__name__)
        for field in classtype._fields.keys():
            if field in values: attributes_map[field] = values[field]
            elif classtype._fields[field] != None : attributes_map[field] = classtype._fields[field]
            else: raise BadJsonSerializableParametersSetException('Required field missing: %s ' % field)
        return json.dumps(attributes_map, encoding='utf-8')
                          
    @classmethod
    def getInstance(classname, argsdict):
        '''
        This static classmethod should return an instance of the current class,
        which is created after the fields passed as argument in argsdict.
        @argsdict: a dictionary containing values for the fields of the instance.
        Calling this method represents the correct way to get a brand new instance of the current class,
        i.e., all the times except when unpacking a message.
        '''
        module = __import__(MESSAGES_LIBRARY_MODULE)
        classtype = getattr(module, classname.__name__)
        return classtype(classtype._serialize(argsdict))
    
    def serialize(self):
        ''' 
        This method return a json-encoded representation of a current instance,
        by calling self._serialize. Calling this method is the correct
        way to get something to be pushed inside a Message object.
        '''
        attributes_map = {}
        for field in self._fields.keys(): 
            try: attributes_map[field] = self.__getattribute__(field)
            except AttributeError: attributes_map[field] = ''
        return self._serialize(attributes_map)
    
    def __repr__(self):
        jsrepr = ''
        for param in self._fields: 
            try: jsrepr += "(%s) %s: %r, " % (self.__class__.__name__, param, self.__getattribute__(param))
            except AttributeError: pass
        if jsrepr.endswith(', '): jsrepr = jsrepr[:-2]
        return jsrepr
    

########NEW FILE########
__FILENAME__ = Messages
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Client-Server communication messages


This module contains the definitions of the the messages
for the communication protocol between the FileRock Client
and the FileRock servers.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import json, zlib
from RequestDetails import RequestDetails
from ResponseDetails import ResponseDetails

MESSAGES_LIBRARY_MODULE = 'FileRockSharedLibraries.Communication.Messages'
DEFAULT_INTERNAL_ERROR_REASON = 'An error has occurred. Service session will be terminated.'


# Exceptions

class MsgPackingException(Exception): pass
class MsgUnpackingException(Exception): pass
class BadParametersSetException(Exception): pass
class UndefinedMessageException(Exception): pass


# Functions

def unpack(message):
    '''
    Returns a Message object instantiated with data obtained
    decompressing and parsing the function argument.
    @message: a zlib compressed json representation of the message.
    '''
    try: return _loadMessageFromJson(zlib.decompress(message))
    except AttributeError as e: raise UndefinedMessageException('Undefined message, %s' % e.message)
    except Exception as e: raise MsgUnpackingException(e.message)

def _loadMessageFromJson(json_encoded_msg):
    '''
    Instantiate a Message object based on the decoded json data.
    Thanks to the aliases defined below, proper class is used for a given message name.
    @json_encoded_msg: a json encoded representation of a message.
    '''
    json_decoded = json.loads(json_encoded_msg, 'utf-8')
    module = __import__(MESSAGES_LIBRARY_MODULE, fromlist=['Messages'])
    classtype = getattr(module, json_decoded['name'])
    return classtype(json_decoded['name'], json_decoded['params'])


# Message objects

class Message(object):
    ''' A Message object represents a communication unit. '''
    
    required_parameters = [] # Extending classes can specify given messages required parameters
    
    def __init__(self, message_name, message_parameters={}):
        '''
        @message_name: the name of the message. This is kept separated because is used to guess the kind of message to be created.
        @message_parameters: other parts of the message. Can be empty {}.
        '''
        self.check_parameters(message_parameters)
        self.name = message_name
        self.parameters = message_parameters
    
    def check_parameters(self, message_parameters=None):
        ''' 
        Implements message check. Raise an exception if the check fails.
        Generic Message class only checks for required parameters.
        Checking specific parameters in extending classes might be a good idea.
        '''
        self._check_for_required_parameters(message_parameters)
    
    def _check_for_required_parameters(self, parameters):
        '''
        Check for all of the required parameters to be in the given dictionary.
        Please note that this should always be called both at __init__
        and at check_parameters, also in any extending class.
        '''
        if parameters == None: parameters = self.parameters
        for required_parameter in self.required_parameters:
            if not required_parameter in parameters: 
                raise BadParametersSetException('Missing required parameter: %s ' % required_parameter)
        
    def _serialize_to_json(self):
        ''' Returns a json representation of the Message object. '''
        return json.dumps({ 'name': self.name, 'params': self.parameters }, encoding='utf-8')

    def pack(self):
        '''
        Returns a zlib compressed json representation of the Message object,
        together with its length. I.e., (<msg-length>, <compressed-msg>)
        '''
        try: msg = zlib.compress(self._serialize_to_json())
        except Exception as e: raise MsgPackingException(e.message)
        return (len(msg), msg)
    
    def getParameter(self, param):
        ''' Returns value of given parameter included in the message, or None if such parameter is not here. '''
        return self.parameters.get(param, None)
    
    def __repr__(self):
        ''' Returns a string representation of the message. Outpt is returned when calling repr(message_instance) '''
        message_repr = "Message: %s \nParameters: \n" % self.name
        for param in self.parameters: message_repr += '%s: %r \n' % (param, unicode(self.parameters[param]))
        return message_repr


#######################################################################################
## Message-extending Classes and Aliases:                                            ##
## ----------------------------------------------------------------------------------##
## these are herein defined in such a way that messages with a given name            ##
## are treated with the proper Message-extending class.                              ##
## ----------------------------------------------------------------------------------##
## Message-extending classes should have a required_parameters field                 ##
## which lists the required parameters for the message to be inside                  ##
## Message.parameters                                                                ##
## ----------------------------------------------------------------------------------##
## Message-extending classes containing complex parameter should override            ##
## proper methods. Those complex parameter should be json-serializabile.             ##
#######################################################################################

class DeclareRequestMessage(Message):
    
    # DeclareRequestMessage holds a RequestDetails object among its parameters.
    required_parameters = ['request_details']

    def __init__(self, name, message_parameters={}):
        
        self.name = name
        self.parameters = message_parameters
        self.parameters['request_details'] = RequestDetails(self.parameters['request_details'])
        self.check_parameters(message_parameters)

    def _serialize_to_json(self):
        '''
        It is required to override this method in order to ensure correct packing of held objects
        '''
        exported_params = {}
        for key in [k for k in self.parameters.keys() if k != 'request_details']: exported_params[key] = self.parameters[key]
        exported_params['request_details'] = self.parameters['request_details'].serialize()
        return json.dumps({ 'name': self.name, 'params': exported_params }, encoding='utf-8')

    def check_parameters(self, message_parameters=None):
        '''
        Overrides Message.check_parameters()
        '''
        Message.check_parameters(self,self.parameters)
        if not isinstance(self.parameters['request_details'], RequestDetails):
            raise BadParametersSetException("Not a RequestDetails instance!")
        
        # Check if RequestDetails object has all required fields
        for field in self.parameters['request_details']._fields:
            if self.parameters['request_details']._fields[field] != '' and not hasattr(self.parameters['request_details'], field): 
                raise BadParametersSetException("Missing '%s' parameter for RequestDetails object" % field)
        

class DeclareResponseMessage(Message):

    required_parameters =  ['response_details']

    def __init__(self, name, message_parameters={}):
        
        self.name = name
        self.parameters = message_parameters
        self.parameters['response_details'] = ResponseDetails(self.parameters['response_details'])        
        self.check_parameters(message_parameters)
        
    def _serialize_to_json(self):
        '''
        It is required to override this method in order to ensure correct packing of held objects
        '''
        exported_params = {}
        for key in [k for k in self.parameters.keys() if k != 'response_details']: exported_params[key] = self.parameters[key]
        exported_params['response_details'] = self.parameters['response_details'].serialize()        
        return json.dumps({ 'name': self.name, 'params': exported_params }, encoding='utf-8')

    def check_parameters(self, message_parameters=None):
        '''
        Overrides Message.check_parameters()
        '''
        Message.check_parameters(self,self.parameters)
        if not isinstance(self.parameters['response_details'],ResponseDetails):
            raise BadParametersSetException("Not a ResponseDetails instance!")
        # Check if ResponseDetails object has all required fields
        for field in self.parameters['response_details']._fields:
            if self.parameters['response_details']._fields[field] != '' and not hasattr(self.parameters['response_details'], field): 
                raise BadParametersSetException("Missing '%s' parameter for RequestDetails object" % field)            


# Messages and aliases

ASK_FOR_FORCE_DISCONNECT_CONNECTED_CLIENT = 'force_other_client_disconnection'
OTHER_CONNECTED_CLIENT = 'other_connected_client'
SESSION_ID = 'session_id'

class KeepAliveMessage(Message):
    required_parameters = ['id']

class ProtocolVersionMessage(Message):
    required_parameters = ['version']
    
class ProtocolVersionAgreementMessage(Message):
    required_parameters = ['response', 'version']

class ChallengeRequestMessage(Message):
    required_parameters = ['client_id', 'username']

class ChallengeRequestResponseMessage(Message):
    required_parameters = ['challenge']
    
class ChallengeResponseMessage(Message):
    required_parameters = ['response']
    
    def set_force_other_client_disconnection(self):
        ''' Include the request to disconnect other connected clients if any. '''
        self.parameters[ASK_FOR_FORCE_DISCONNECT_CONNECTED_CLIENT] = True
    
    def check_force_other_client_disconnection(self):
        ''' Check if the message includes the request to disconnect other connected clients if any. ''' 
        return self.getParameter(ASK_FOR_FORCE_DISCONNECT_CONNECTED_CLIENT) == True
        
class ChallengeVerifyResponseMessage(Message):
    ''' 
    Optionally, can include OTHER_CONNECTED_CLIENT details, as a dict holding other fields:
            client_id       (int)
            hostname        (str)
            platform        (str)
            link_date       (int)
            last_login      (int)
    '''
    
    required_parameters = ['result', 'reason']

    def set_session_id(self, session_id):
        ''' Set a session id, useful for bug reporting purposes. '''
        self.parameters[SESSION_ID] = session_id
        
    def get_session_id(self):
        ''' Retrieving assigned session id '''
        return self.getParameter(SESSION_ID)

    def is_other_client_connected(self):
        ''' Returns True when there is another connected client '''
        return not (self.getParameter(OTHER_CONNECTED_CLIENT) is None)

    def get_other_connected_client(self):
        ''' Returns the OTHER_CONNECTED_CLIENT details '''
        return self.getParameter(OTHER_CONNECTED_CLIENT)
    
    def set_other_connected_client(self, other_connected_client):
        ''' Set OTHER_CONNECTED_CLIENT parameter. '''
        self.parameters[OTHER_CONNECTED_CLIENT] = other_connected_client

class ErrorMessage(Message):
    required_parameters = ['reason']
    
class UnknownClientErrorMessage(ErrorMessage): pass
    
class CommitDoneMessage(Message):
    required_parameters = ['new_basis', 'last_commit_client_id', 'last_commit_client_hostname', 'last_commit_client_platform', 'last_commit_timestamp', 'user_quota', 'used_space']
    
class CommitStartMessage(Message):
    required_parameters = ['achieved_operations']

class WebGetRequestMessage(Message):
    required_parameters = ['pathname']
    
class WebGetResponseMessage(Message):
    required_parameters = ['pathname', 'auth_token', 'auth_date', 'proof', 'bucket']

class WebDeleteFolderRequestMessage(Message):
    required_parameters = ['pathname']

class SyncGetRequestMessage(Message):
    required_parameters = ['pathname']

class SyncGetResponseMessage(Message):
    required_parameters = ['pathname', 'auth_token', 'auth_date', 'bucket']

class SyncGetEncryptedIVsMessage(Message):
    required_parameters = ['requested_files_list']

class SyncEncryptedIVsMessage(Message):
    #ivs is a dict which have pathname as key and iv as value
    required_parameters = ['ivs']

class UserQuotaExceeded(Message):
    required_parameters = ['user_quota', 'user_used_space', 'pathname', 'size', 'request_id']

class QuitMessage(Message):
    required_parameters = ['reason']

class DisconnectRequestMessage(Message):
    required_parameters = ['issued_by', 'reason']

class ListClientResponse(Message):
    # client_list is a list of dict which contains:
    #   client_id       ID of client
    #   hostname        client hostname
    #   platform        client platform
    #   link_date       client link date timestamp  (given as UNIX UTC timestamp)
    #   last_login      client last login timestamp (given as UNIX UTC timestamp)
    required_parameters = ['client_list']


# Linking-related Messages

class ClientLinkingRequestMessage(Message):
    required_parameters = ['linking_protocol_version', 'username', 'authentication_digest', 'CAPubK', 'platform', 'hostname', 'proposed_encryption_key']

class ClientLinkingResponseMessage(Message):
    required_parameters = ['result', 'result_code', 'assigned_client_id', 'assigned_encryption_key']

class ClientUnlinkingRequestMessage(Message):
    required_parameters = ['client_id']

class ClientUnlinkingResponseMessage(Message):
    required_parameters = ['result']

class SyncFilesListMessage(Message):
    
    # @param dataset: a list of dictionaries containing objects' attributes like:
    #                 {'key': key, 'etag': etag, 'lmtime': lmtime, 'size': size}
    
    required_parameters = ['basis', 
                           'dataset', 
                           'last_commit_client_id', 
                           'last_commit_client_hostname', 
                           'last_commit_client_platform', 
                           'last_commit_timestamp', 
                           'user_quota', 
                           'used_space',
                           'status',
                           'expires_on',
                           'plan']
    # new parameters that Client expects about plan and expiration date, and might be put as "required"
    # in the near future
    #
    # plan: a dictionary as follows (mandatory)
    #          { id: <plan_id>,    # a number
    #             space: <plan_space_in_GB>,   # a number (within a plan this is mandatory and 'not None')
    #             price: <price_in_$>,      # a number    (if absent or ==None it means "free")
    #             payment_type: <(SINGLE|SUBSCRIPTION)>,   # unicode  (present if price is not None)
    #             payment_recurrence: <(MONTHLY|YEARLY)>   # unicode  (present if price is not None)
    #            }
    # expires_on: <GMT-Date-or-None>    # a number representing a unix timestamp UTC (mandatory)
    #             (it might be None if plan is "forever", this is the expiration date of the subscription,
    #              it does not change when in grace time).
    # status: unicode (mandatory), one in 
            #ACTIVE_BETA
            #ACTIVE_TRIAL
            #ACTIVE_PAID
            #ACTIVE_SUBSCRIBED
            #ACTIVE_GRACE
            #SUSPENDED
            #MAINTAINANCE     

    

    def __repr__(self):
        message_repr = 'Message: %s \n' % self.name
        message_repr += 'Parameters: \n'
        for i in self.parameters.keys(): 
            if i != 'dataset': message_repr += '%s: %s \n' % (i, self.parameters[i]) 
        message_repr += 'Dataset: \n'
        for i in self.getParameter('dataset'): message_repr += '%s\n' % str(i)
        return message_repr


# Aliases

PROTOCOL_VERSION = ProtocolVersionMessage
PROTOCOL_VERSION_AGREEMENT = ProtocolVersionAgreementMessage

CHALLENGE_REQUEST = ChallengeRequestMessage
CHALLENGE_REQUEST_RESPONSE = ChallengeRequestResponseMessage
CHALLENGE_RESPONSE = ChallengeResponseMessage
CHALLENGE_VERIFY_RESPONSE = ChallengeVerifyResponseMessage

SYNC_FILES_LIST = SyncFilesListMessage
SYNC_GET_REQUEST = SyncGetRequestMessage
SYNC_GET_RESPONSE = SyncGetResponseMessage
SYNC_READY = SYNC_START = SYNC_STATUS = SYNC_DONE = Message
SYNC_GET_ENCRYPTED_FILES_IVS = SyncGetEncryptedIVsMessage
SYNC_ENCRYPTED_FILES_IVS     = SyncEncryptedIVsMessage

WEB_GET_REQUEST = WebGetRequestMessage
WEB_GET_RESPONSE = WebGetResponseMessage
WEB_DELETE_FOLDER_REQUEST = WebDeleteFolderRequestMessage

REPLICATION_START = Message
REPLICATION_DECLARE_REQUEST = DeclareRequestMessage
REPLICATION_DECLARE_RESPONSE = DeclareResponseMessage

ERROR = COMMIT_ERROR = ErrorMessage
UNKNOWN_CLIENT_ID_ERROR = UnknownClientErrorMessage

COMMIT_START = CommitStartMessage
COMMIT_FORCE = WAIT_FOR_COMMIT_DONE = Message
COMMIT_DONE = CommitDoneMessage

TEST = OK  = Message
QUIT = QuitMessage
KEEP_ALIVE = KeepAliveMessage

READY_FOR_SERVICE = SERVICE = REGISTER = STORE_MK = CHANGE_PASSWORD = UNLINK = CHANGE_MK = Message
HELLO = VERIFY_IDENTITY = MALFORMED_MESSAGE = OPERATIONAL_PHASE_ERROR = Message
CHECK_QUOTA = CHECK_FILE_INTEGRITY = CHECK_DATA_INTEGRITY = Message

USER_QUOTA_EXCEEDED = UserQuotaExceeded
DISCONNECT_REQUEST = DisconnectRequestMessage

LIST_CLIENT_REQUEST = Message
LIST_CLIENT_RESPONSE = ListClientResponse

CLIENT_LINKING_REQUEST_MESSAGE = ClientLinkingRequestMessage
CLIENT_LINKING_RESPONSE_MESSAGE = ClientLinkingResponseMessage
CLIENT_UNLINKING_REQUEST = ClientUnlinkingRequestMessage
CLIENT_UNLINKING_RESPONSE = ClientUnlinkingResponseMessage

POISON_PILL = Message("POISON_PILL")


# ERROR CODES

GENERIC_ERROR           = 100
UNEXPECTED_DATA         = 400
MALFORMED_MESSAGE       = 410
MISSING_CONTENT_LENGTH  = 420
EXCEEDING_QUOTA         = 430
PATHNAME_ERROR          = 440
OPERATION_NOT_PERMITTED = 450
INTERNAL_SERVER_ERROR   = 500
PROCEDURE_ERROR         = 510
SERVICE_ERROR           = 520
LINKING_INTERNAL_ERROR  = 530


# End of Messages library. Following code is for test-only purpose.

if __name__ == '__main__':

    print 'Testing...'
    request_details = RequestDetails({ 'pathname': 'my-pathname', 
                                                   'operation': 'my-operation', 
                                                   'request_id': 1 })
    message_parameters = { 'id': 222333444, 'a': 'meohhww', 'b': 'bau', 'request_details': request_details.serialize() }
    msg = REPLICATION_DECLARE_REQUEST("REPLICATION_DECLARE_REQUEST", message_parameters)
    print 'Packing message...'
    size, packed = msg.pack()
    print 'Message packed in %s bytes: \n%s' % (size, packed)
    print 'Unpacking message...'
    unpacked = unpack(packed)
    print 'Unpacked message: \n %s' % unpacked
    print 'Message contained object: \n%s' % unpacked.parameters['request_details']
    print 'Message contained object fields: \n'
    for f in  RequestDetails._fields: print '> %s: %s' % (f, unpacked.parameters['request_details'].__getattribute__(f))
    
    

########NEW FILE########
__FILENAME__ = OperationsHelper
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Operation names from different point of views.


This module defines operation names and provides an helper
to translate them to different glossaries.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""


CLIENT_ISSUED_REMOTE_COPY_OPERATION =   'REMOTE_COPY'
CLIENT_ISSUED_UPLOAD_OPERATION      =   'UPLOAD'
#CLIENT_ISSUED_DOWNLOAD_OPERATION    =   'DOWNLOAD'
CLIENT_ISSUED_DELETE_OPERATION      =   'DELETE'

STORAGE_ACCEPTED_REMOTE_COPY_OPERATION = 'PUT_COPY'
STORAGE_ACCEPTED_UPLOAD_OPERATION      = 'PUT'
#STORAGE_ACCEPTED_DOWNLOAD_OPERATION    = 'GET'
STORAGE_ACCEPTED_DELETE_OPERATION      = 'DELETE'

CLIENT_ISSUED_DEFINED_OPERATIONS    =  [ CLIENT_ISSUED_REMOTE_COPY_OPERATION, 
                                         CLIENT_ISSUED_UPLOAD_OPERATION, 
                                         #CLIENT_ISSUED_DOWNLOAD_OPERATION, 
                                         CLIENT_ISSUED_DELETE_OPERATION ]

STORAGE_ACCEPTED_OPERATIONS    =       [ STORAGE_ACCEPTED_REMOTE_COPY_OPERATION, 
                                         STORAGE_ACCEPTED_UPLOAD_OPERATION, 
                                         #STORAGE_ACCEPTED_DOWNLOAD_OPERATION, 
                                         STORAGE_ACCEPTED_DELETE_OPERATION ]

CLIENT_2_STORAGE_DICTIONARY = { CLIENT_ISSUED_UPLOAD_OPERATION:      STORAGE_ACCEPTED_UPLOAD_OPERATION,
                                CLIENT_ISSUED_REMOTE_COPY_OPERATION: STORAGE_ACCEPTED_REMOTE_COPY_OPERATION,
                                #CLIENT_ISSUED_DOWNLOAD_OPERATION:    STORAGE_ACCEPTED_DOWNLOAD_OPERATION,
                                CLIENT_ISSUED_DELETE_OPERATION:      STORAGE_ACCEPTED_DELETE_OPERATION }


def translateOperationName2StorageGlossary(operation):
    '''
    Returns a translation of given parameter @operation,
    properly converted if required into the storage service glossary.
    '''
    value = CLIENT_2_STORAGE_DICTIONARY.get(operation)
    try: assert value is not None
    except AssertionError: raise UndefinedClientIssuedOperationException('Translation requested for unknown operation: %s' % operation)
    return value

class UndefinedClientIssuedOperationException(Exception): pass
class UncoherentOperationException(Exception): pass


########NEW FILE########
__FILENAME__ = RequestDetails
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Details of a DECLARE_REQUEST message


Provide the RequestDetails class, which models
a container for the details attached to a DECLARE_REQUEST message.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""



from JsonSerializable import JsonSerializable

ENCRYPTED_FILES_IV_HEADER = 'x-amz-meta-encryption-iv'
ENCRYPTED_FILES_IV_HEADER_FIELD_NAME = ENCRYPTED_FILES_IV_HEADER.replace('-','_')

class RequestDetails(JsonSerializable):
    ''' 
    RequestDetails represents the details of a requests. 
    _fields must be a dictionary with class fields as keys.
    values can be None if are required to construct the class or a default value otherwise.
    '''
    _fields = { 'request_id' : None, 
                'pathname': None, 
                'operation': None, 
                'paired_pathname': '', 
                'Content_MD5': '', 
                'Content_Type': '', 
                'Content_Length': '',
                ENCRYPTED_FILES_IV_HEADER_FIELD_NAME: '' }

########NEW FILE########
__FILENAME__ = ResponseDetails
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Details of a DECLARE_RESPONSE message


Provide the ResponseDetails class, which models
a container for the details attached to a DECLARE_RESPONSE message.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""



from JsonSerializable import JsonSerializable

class ResponseDetails(JsonSerializable):
    '''
    ResponseDetails contains the details of a DECLARE-REQUEST response
    _fields must be a dictionary with class fields as keys.
    values can be None if are required to construct the class or a default value otherwise.
    '''
    _fields = { 'request_id' : None,
                'result' : None,
                'auth_token': '',
                'auth_date': '',
                'bucket': '',
                'storage_connector_ip': '',
                'journal_pathname' : '',
                'proof' : None }
    
    def serialize(self):
        ''' Override JsonSerializable.serialize() '''
        attributes_map = {}
        for field in self._fields.keys(): 
            try: attributes_map[field] = self.__getattribute__(field)
            except AttributeError: attributes_map[field] = ''
        try: attributes_map['proof'] = attributes_map['proof'].serialize()
        except KeyError: pass # ResponseDetails has no attached proof
        except Exception: pass # TODO: Handle generic exceptions
        return self._serialize(attributes_map)
    

########NEW FILE########
__FILENAME__ = CryptoLib
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Crypto Utils


This module provides the CryptoUtil class, that wraps
the Crypto library to implement challenge creation,
signing and verification functions

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from random import randint
import hashlib
from Crypto.PublicKey import RSA
from Crypto import Random

class CryptoUtil(object):
    """
    Class that wraps Crypto library and provides challenge creation/signing/verification functions.
    """

    def challenge_create(self, challenge_length):
        """
        Generates a random challenge using OpenSSL rand()

        @param challenge_length: Bytes of the challenge to be created
        """
        nonce = Random.get_random_bytes(challenge_length)
        m = hashlib.sha512()
        m.update(nonce)
        return str(m.hexdigest())


    def challenge_verify(self, challenge, signed, pub_key):
        """
        Verify a signed challenge with RSA pub_key (given as string)

        @param challenge: challenge string
        @param signed:    challenge sign
        @param pub_key:   RSA public key string

        Returns True/False
        """
        RSA_key = RSA.importKey(pub_key)
        try: result = RSA_key.verify(challenge,(signed,))
        except Exception: result = False
        return result


    def challenge_sign(self, challenge, pvt_key):
        """
        Sign a given challenge with RSA pvt_key (given as string)

        @param challenge: challenge string
        @param pvt_key:   RSA private key as string

        Returns signed challenge.
        """
        RSA_key = RSA.importKey(pvt_key)
        signed, = RSA_key.sign(challenge, long(randint(0,65535)))
        return signed


########NEW FILE########
__FILENAME__ = Hashing
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Hashing module


Provides hashing related functions.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from hashlib import md5
from base64 import b64encode


def getHash(elements_to_combine):
    '''
    This method hashes a list of strings or unicode objects, concatenating them.
    Nones are considered empty strings.    
    '''
    hash_function = md5   
    combination = ''.join( [e.encode('utf-8') for e in elements_to_combine if not e == None] )    
    m = hash_function()
    m.update(combination)
    answer = m.hexdigest()    
    return(answer)


def encode(the_string):
    '''
    Encodes in base-64 a given string and returns it.
    It should be used for pathname encoding.
    ''' 
    answer =b64encode(the_string.encode('utf-8'))        
    return answer


def getHashFirstTwoBytes(unicode_object):
    '''
    Given a unicode_object like a pathname, returns the integer representing the first two bytes of the MD5 hash of the argument.
    '''
    m = md5()    
    m.update( unicode_object.encode('utf-8') )    
    blob= m.digest()    
    x = ord(blob[0]) +  ord(blob[1])*256    
    return x

########NEW FILE########
__FILENAME__ = Proof
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
FileRock Integrity Check Proof


Provides FileRock Integrity Check Proof object.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

# ---- Used to run automated test routines and docs generation
import sys
sys.path.append('../../')
# ----

from SkipListNode import SkipListNode, ProxyNode
from FileRockSharedLibraries.Communication.JsonSerializable import JsonSerializable
from FileRockSharedLibraries.Communication.OperationsHelper import STORAGE_ACCEPTED_UPLOAD_OPERATION, \
                                                                   STORAGE_ACCEPTED_REMOTE_COPY_OPERATION, \
                                                                   STORAGE_ACCEPTED_DELETE_OPERATION
import json

VERIFY = 'VERIFY'
DELETE = 'DELETE'
INSERT = 'INSERT'
UPDATE = 'UPDATE'


class Proof(JsonSerializable):
    '''
    Proof contains set of "computation paths" from leafs to root, but also contains operation informations.        
    A "computation path" is a sequence of SkipListNodes which each one may have a ProxyNode attached. 
        
    Proof includes eiher one computation path or two, based on the operation type.
    Note that the field 'proofpath' is a map {starting_pathname : leave} and leave is the lower extreme of 
    that computation path.  
    '''

    def __init__(self, json_serialized):
                
        self.proofpaths = {}        
        json_decoded = json.loads(json_serialized)        
        
        proofpaths = json_decoded['proofpaths']        
        self.pathname = json_decoded['pathname']
        self.operation = json_decoded['operation']
        
        for starting_pathname in proofpaths:
            
            starting_node = None
            previous = None
            for nodedata in proofpaths[starting_pathname]:
                node = SkipListNode(nodedata['pathname'],nodedata['height'], label = nodedata['label'], filehash = nodedata['filehash'])
                proxy = None                
                if nodedata['proxy']!=None:                    
                    proxydata = nodedata['proxy']
                    proxy = ProxyNode(proxydata['pathname'],proxydata['height'],proxydata['label'])        
                    proxyside = nodedata['proxy_side']
                    if proxyside =='r':  node.right_child = proxy
                    if proxyside =='l':  node.lower_child = proxy
                    proxy.father = node                    

                if starting_node==None: starting_node = node

                try: 
                    previous.father = node
                    if previous.pathname == node.pathname:   node.lower_child = previous
                    else: node.right_child = previous

                except: pass

                previous = node

            self.proofpaths[starting_pathname] = starting_node


    def __str__(self):

        pathnames = sorted(self.proofpaths.keys())
        if   len(pathnames) == 2 : message = 'Proofs for what should (not?) be between %s and %s' % (pathnames[0], pathnames[1])
        elif len(pathnames) == 1 : message = 'Proof of integrity for %s' % pathnames[0]
        else: return 'Error! Too many computation paths!'
        return message


    def getStartingNodes(self):
        ''' Returns a list with all the leaves from which computation paths start from.'''
        return self.proofpaths.values()

    def __cmp__(self, other):
        if self.pathname > other.pathname: return 1
        if self.pathname < other.pathname: return -1
        return 0

    def resetOperation(self, operation):
        if   operation == STORAGE_ACCEPTED_UPLOAD_OPERATION: self.operation =      'UPDATE'
        elif operation == STORAGE_ACCEPTED_REMOTE_COPY_OPERATION: self.operation = 'UPDATE'
        elif operation == STORAGE_ACCEPTED_DELETE_OPERATION: self.operation =      'DELETE'
        self.consolidateOperation()


    @classmethod
    def getInstance(classname, pathname, operation, proofpaths):         
        ser = Proof._serialize(pathname, operation, proofpaths)
        return Proof( ser )        
    
    @classmethod
    def _serializeNode(classname, node):
        nodemap = {}
        nodemap['pathname'] = node.pathname
        nodemap['height'] = node.height
        nodemap['label'] = node.label
        nodemap['filehash'] = node.filehash
        return nodemap
    
    @classmethod
    def _serialize(classname, pathname, operation, proofpaths):
        json_map = {}

        json_map['pathname']=pathname
        json_map['operation']=operation
        
        
        proofmap = {}
        for proofpathname in proofpaths:
            #Lo mettiamo in json_map...
            newlist = []
            node = proofpaths[proofpathname]
            while isinstance(node, SkipListNode):
                nodemap = {}
                nodemap['pathname'] = node.pathname
                nodemap['height'] = node.height
                nodemap['label'] = node.label
                nodemap['filehash'] = node.filehash

                if isinstance(node.right_child, ProxyNode):
                    pside = 'r'
                    proxy = Proof._serializeNode(node.right_child)
                elif isinstance(node.lower_child, ProxyNode):
                    pside = 'l'
                    proxy = Proof._serializeNode(node.lower_child)
                else:
                    pside = ''
                    proxy = None

                nodemap['proxy'] = proxy
                nodemap['proxy_side']=pside                
                nodemap['isplateau'] = node.isPlateau()

                newlist.append(nodemap)

                node = node.father
            proofmap[proofpathname]=newlist

        json_map['proofpaths'] = proofmap
        return json.dumps(json_map)


    def consolidateOperation(self):
        '''
        Confirms and eventually sets the operation type.
        It separates insertions from deletions.
        '''

        if self.operation == DELETE: return
        
        if "+INF" in self.proofpaths: del (self.proofpaths["+INF"])

        if len( self.proofpaths.keys() ) == 2: result = INSERT             
        else:
            starting_pathname = self.proofpaths.keys()[0]
            if starting_pathname == self.pathname: result = UPDATE
            else: result = INSERT             
        self.operation = result


    def checkCorrectness(self):
        ''' 
        Checks proof correctness. Raise a descriptive exception if any anomaly is found.
        Note: it uses the operation and pathname in the proof itself.
        raise: UnrelatedProofException if any uncorrectness is found.
        '''
        if self.operation == 'VERIFY': self._checkVerify()
        if self.operation == 'UPDATE': self._checkUpdate()
        if self.operation == 'INSERT': self._checkInsertion()
        if self.operation == 'DELETE': self._checkDeletion()

    def _checkVerify(self):                
        if not len(self.proofpaths) == 1: raise MalformedProofException("Verify proof for %s has more than one proofpath with it." % self.pathname)
        if not self.pathname in self.proofpaths.keys(): raise MalformedProofException("No proofpath for %s in its verify proof." % self.pathname)
        if not self.pathname == self.proofpaths[self.pathname].pathname: raise MalformedProofException("Proofpath not beginning with a leaf marked %s!" % self.pathname)

    def _checkUpdate(self):
        '''
        Checks the validity of the update proof. Raise an Exception if any problem is found.
        '''
        if not self.operation == 'UPDATE': raise Exception("Checking proof as 'update' while it is %s!" % self.operation)        
        if not len(self.proofpaths) == 1: raise MalformedProofException("Update proof for %s has more than one proofpath with it." % self.pathname)
        if not self.pathname in self.proofpaths.keys(): raise MalformedProofException("No proofpath for %s in its update proof." % self.pathname)
        if not self.pathname == self.proofpaths[self.pathname].pathname: raise MalformedProofException("Proofpath not beginning with a leaf marked %s!" % self.pathname)
    
    def _checkDeletion(self):          
        if not len(self.proofpaths) == 2: raise MalformedProofException("Delete proof for %s has more or less proofpaths than two: " % self.pathname, self.proofpaths.keys())        
        if not self.pathname in self.proofpaths.keys(): raise MalformedProofException("No proofpath for %s in its delete proof." % self.pathname)
        pathnames = self.proofpaths.keys()
        pathnames.remove(self.pathname)
        left_pathname = pathnames[0]        
        if not (left_pathname < self.pathname or left_pathname == "-INF"): raise MalformedProofException("A proofpath returned is not useful for deletion.")        
        # Note that deletion has always two proofpaths. One its related to the condemned pathname; the other is the pathname immediately lower. 
        # These two proofpaths must be proved to be adjacent, or that no pathnames stand between them.        
        if not self.pathname == self.proofpaths[self.pathname].pathname: raise MalformedProofException("Proofpath not beginning with a leaf marked %s!" % self.pathname)        
        if not self._checkProofPathsAdjacency(self.proofpaths[left_pathname], self.proofpaths[self.pathname] ):            
            raise MalformedProofException("Harsh proof malformation! Non adjacent proofpaths found!!")

        return True

    def _checkInsertion(self):
        '''
        Returns True if no problems are detected in an insertion proof.
        At current time, is only used for 1 proofpath proof.
        '''
        if len( self.proofpaths.keys() ) >2: raise MalformedProofException("Insertion proof has more than two proofpaths.")
        if len( self.proofpaths.keys() ) == 2:            
            pathnames = sorted( self.proofpaths.keys() )            
            self._checkProofPathsAdjacency (self.proofpaths[pathnames[0]], self.proofpaths[pathnames[1]])            
        else:
            node = self.proofpaths.values()[0]
            if not (node.pathname < self.pathname or node.pathname == "-INF"): raise MalformedProofException("A proofpath returned is not useful for insertion.")
            if not self._checkHighestProofPath(node): raise MalformedProofException("Harsh anomaly: invalid insertion proof: single path has right contributes.")

        '''
        pathname = self.pathname
        starting_pathname = self.proofpaths.keys()[0]
        if ClientSkipList._comparePathnames(starting_pathname, pathname) >=0:
            raise MalformedProofException (" Invalid proof for insertion of %s " % self.pathname)
        # This happens for 1-path insertions.
        node = self.proofpaths[starting_pathname]
        '''
        return True
    
    def _checkProofPathsAdjacency(self, left_leaf, right_leaf):
        '''
        Returns True if a couple of ProofPaths are actually adjacent with the given order.
        False otherwise.
        Note that anomaly is noted when the two paths merge.

        @param left_leaf: the leaf from which left path begins.
        @param right_leaf: the leaf from which right path begins.
        '''
        marked_positions = []
        
        #Both branches must be examined from the leaves.
        left_condition = True
        right_condition = True         
        
        current_node = left_leaf        
        while left_condition:            
            right_child = current_node.right_child
            #print "Current=%s  Righty=%s" % (current_node, right_child)
            marked_positions.append((current_node.pathname, current_node.height))            

            if isinstance(right_child, ProxyNode):    
                #print "Left_section: node %s has a proxy right: %s" % (current_node, right_child)            
                if not (Proof._isNodeOnPath(right_leaf, right_child)): return False             
                #print "Ok, going on..."
                left_condition = False             
            current_node = current_node.father

        current_node = right_leaf
        while right_condition:
            if (current_node.pathname, current_node.height) in marked_positions: break
            lower_child = current_node.lower_child
            #When a proxy is found, it's also searched in the marked nodes list.
            if isinstance(lower_child, ProxyNode) and not ((lower_child.pathname, lower_child.height) in marked_positions):
                #print "Right_section: node %s has a proxy lower unmarked: %s" % (current_node, lower_child)
                if not (Proof._isNodeOnPath(left_leaf, lower_child)): return False
                #print "Ok, going on..."
                right_condition = False                            
            current_node = current_node.father

        return True                


    @staticmethod
    def _isNodeOnPath(starting_leaf, target_node):
        '''
        It searches a node on a path from starting_leaf to the root. 
        Return False if node is never found on such path, True otherwise.

        @param starting_leaf: the leaf from which the path starts from.
        @param target_node: the node to be found

        raise: Exception if a node passed is None.
        '''
        if target_node == None or starting_leaf == None: raise Exception("Invalid check: a None-argument was passed.")
        
        node = starting_leaf
        searching = True
        while searching:            
            if node.__eq__(target_node): return True            
            node = node.father            
            try: still_on_the_right = (SkipListNode.comparePathnames(target_node.pathname, node.pathname) <= 0)
            except: still_on_the_right = False
            searching = (isinstance(node, SkipListNode)) and ( still_on_the_right )
        return False
        
    def _checkHighestProofPath(self, node):
        '''
        Returns True if a proofpath beginning from given node never recieve any contribute from a right.
        This is equal to say that the beginning node belongs to the proofpath of the highest pathname.
        '''
        while isinstance(node, SkipListNode):
            if isinstance(node.right_child, ProxyNode): return False
            node = node.father        
        return True
    
    def checkCoherence(self):
        '''Checks structural coherence of the proof. It may raise MalformedProofExceptions in case of errors.'''
        # TODO: This is an addisional check, to be implemented.
        pass


    def serialize(self):
        ''' 
        This method return a json-encoded representation of a current instance,
        by calling self._serialize. Calling this method is the correct
        way to get something to be pushed inside a Message object.
        '''
        return self._serialize(self.pathname, self.operation, self.proofpaths)


class MalformedProofException(Exception): pass
class UnrelatedProofException(Exception): pass


########NEW FILE########
__FILENAME__ = SkipList
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Shared FileRock Integrity Check skipList.


This module provides a class modeling a skipList
for the FileRock Integrity Check.
Such class is meant to be extended.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from Proof import Proof
from Hashing import getHash, getHashFirstTwoBytes
from random import choice
from SkipListNode import SkipListNode, ProxyNode
from copy import copy
import logging

MAX_TOWER_HEIGHT = 8
POSITIVE_INFINITE = u'+INF'
NEGATIVE_INFINITE = u'-INF'

VERIFY = 'VERIFY'
DELETE = 'DELETE'
INSERT = 'INSERT'
UPDATE = 'UPDATE'

class AbstractSkipList(object):
    ''' 
    This is the skeleton of a SkipList, with its basic common features.
    This SkipList cannot be used as is: instead use ClientSkipList or ServerSkipList, which are way cooler.
    '''
   
    def __init__(self):
        '''
        Main fields are initialized at start.
        '''
        self.pathnames = [NEGATIVE_INFINITE, POSITIVE_INFINITE ]
        self.leaves = {}
        self.plateaus = {}
        self.root = None
        self.who = self.__class__.__name__
        self.logger = None # This is supposed to be set by extending classes
      
        self.leaves[NEGATIVE_INFINITE] = SkipListNode(NEGATIVE_INFINITE, 0, label = NEGATIVE_INFINITE, filehash = NEGATIVE_INFINITE )
        self.leaves[POSITIVE_INFINITE] = SkipListNode(POSITIVE_INFINITE, 0, label = POSITIVE_INFINITE, filehash = POSITIVE_INFINITE )        
        for leaf in self.leaves: self.plateaus[leaf] = self._buildTower(self.leaves[leaf])                
        self.root = self.plateaus[NEGATIVE_INFINITE]
        
    def updateSkipListOnDelete(self, pathname):        
        '''
        Deletes an existing pathname from the skiplist, with its annexed data.
        @pathname: the pathname to be removed from the structure.   
        raise: SkipListHandlingException if illegal operations are performed.     
        '''
         
        if self._isGuard(pathname): raise SkipListHandlingException("%s is a guard!" % pathname)        
        if not pathname in self.pathnames: raise SkipListHandlingException("Pathname  %s  not found in skip list!" % pathname)        
        plateau = self.plateaus[pathname]        
        plateau.father.right_child = None
        plateau.father.outdateAncestors()
                
        node = plateau
        while isinstance(node, SkipListNode):            
            self._extractNode(node)            
            node = node.lower_child    
        del self.leaves[pathname]        
        del self.plateaus[pathname]
        self.pathnames.remove(pathname)  
        self.logger.debug('(%s) Pathname %s deleted from skip list.' % (self.who, pathname))
            
    def updateSkipListOnInsert(self, pathname, data, verbose=False):
        '''        
        Adds a new pathname to the skiplist, with related data. 
        To be called on each insertion.       
        @pathname: the pathname to be inserted in the structure
        @data: its related file content hash.
        raise: SkipListHandlingException if illegal operations are performed.
        '''
        if self._isGuard(pathname): raise SkipListHandlingException("%s is a guard!" % pathname)
        
        if pathname in self.pathnames: raise SkipListHandlingException("Pathname %s already in set" % pathname)
        if data == None: raise SkipListHandlingException("Trying to insert a pathname %s with None filehash attached: " % pathname)
        self.pathnames.append(pathname)        
        newleaf = SkipListNode(pathname, 0, data, filehash = data)        
        newplateau = self._buildTower(newleaf)        
        self.leaves[pathname] = newleaf
        self.plateaus[pathname] = newplateau        
        node = newleaf                
        while isinstance(node, SkipListNode):            
            self._interposeNewNode(node)            
            node = node.father            
        self._linkLeftBuddy(newplateau)        
        newplateau.outdateAncestors()
        if verbose: self.logger.debug('(%s) Pathname %s inserted in skip list with %s.' % (self.who, pathname, data))

    def updateSkipListOnUpdate(self, pathname, data):
        ''' 
        Updates dataset and data structure according to the given pathname, data couple.
        @data: the new file content hash.
        raise: SkipListHandlingException if illegal operations are performed.
        '''
                
        if self._isGuard(pathname):  raise SkipListHandlingException("%s is a guard!" % pathname)
        if not pathname in self.pathnames: raise SkipListHandlingException("Pathname %s not in skip list!" % pathname)
        self.leaves[pathname].filehash = data
        self.leaves[pathname].outdateAncestors()        
        self.logger.debug('(%s) Pathname %s filehash updated to %s.' % (self.who, pathname, data))   
    
    def getBasis(self, forced = False):
        ''' 
        Computes and return basis for current data structure. 
        @forced: if True, recomputation is forced and no lazy-load is performed.
        raise: UnexpectedBasisException in case any anomaly happens while basis is being computed.        
        ''' 
        
        self.logger.debug('(%s) Retrieving basis.  Recomputation forcing = %s' % (self.who, forced))       
        
                
        try :            
            basis = self.root.computeLabel(forced)
            self.logger.debug('(%s) Basis computed = %s on %s pathnames.' % (self.who, basis, len(self.pathnames) ))
            return basis        
        except Exception as e: 
            self.logger.critical(e)
            raise UnexpectedBasisException("Critical error happened during basis computation: some node data could be corrupted or missing. A detail? %s %s" %(e.__class__.__name__, e.message))


    def _interposeNewNode(self, node):    
        '''
        Given a new node, breaks eventual bindings between its left and right buddies and rebuilds them 
        according to new node contribution.
        '''
        left_buddy = self._findLeftBuddy(node)         
        right_buddy = left_buddy.right_child        
        if isinstance(right_buddy, SkipListNode): self._givePlateauForAdoption(left_buddy, right_buddy, node)
        left_buddy.outdateAncestors()
    
    def _givePlateauForAdoption(self, old_father, node, new_father):
        '''
        This method breaks a link between a plateau node and its father, and connect the plateau to a new father.
        @old_father: the node to be removed
        @node: the node to be "given in adoption", or that must change father.
        @new_father: the new father for orphan node.
        '''
        self._linkRightChild(new_father, node)
        old_father.right_child = None              
            
    def _extractNode(self, node):    
        ''' Given a being deleted node, breaks possible binding to its right side and rebinds it to its left tower.  '''
        right_buddy = node.right_child        
        if not isinstance(right_buddy, SkipListNode): return
        # This code runs when given node has a right_child.
        newleft = self._findLeftBuddy(node)   
        self._linkRightChild(newleft, right_buddy)
        newleft.outdateAncestors()
        node.right_child = None
    
    def _linkLeftBuddy(self, right_node):
        ''' This method simply links a node to its left neighbor. Note that this should happen only for future plateaus.'''        
        if right_node.isGuard(): return        
        father = self._findLeftBuddy(right_node)        
        self._linkRightChild(father, right_node)

    def _findLeftBuddy(self, right_node):        
        ''' 
        Returns the left_buddy node with regards to right_node. 
        raise: MalformedSkipListException
        '''

        
        if self.root == None: raise MalformedSkipListException("Anomaly when finding left buddy for (%s,%s). Skip List has None root!" % (right_node.pathname, right_node.height))        
        if right_node.pathname == NEGATIVE_INFINITE: return None  
        
        current = self.root        
        answer = None    
        try :    
            while answer == None:                                    
                right_child = current.right_child            
                if isinstance(right_child, SkipListNode): current, answer = self._nextSearchStepRightCase(right_child, right_node, current)                
                else: current, answer = self._nextSearchStepLowerCase(right_node, current)  
        except Exception as e: raise MalformedSkipListException("Unexpected anomaly when finding left buddy for (%s,%s). " % (right_node.pathname, right_node.height))
        return answer 


    def _nextSearchStepRightCase(self, right_child, right_node, current):
        '''This method implements one of the two basic steps of the searching algorithm in skiplist.'''
        answer = None
        
        if self._comparePathnames(right_child.pathname, right_node.pathname) >=0:
            if current.height==right_node.height: answer = current
            else:  current = current.lower_child        
        else: current = current.right_child
        if current == None: raise MalformedSkipListException("Smart search has None step on its right. Probably malformed skiplist!") 
        return current, answer
    
    def _nextSearchStepLowerCase(self, right_node, current):
        '''This method implements one of the two basic steps of the searching algorithm in skiplist.'''
        answer = None
        if current.height==right_node.height: answer = current
        else: current = current.lower_child        
        if current == None: raise MalformedSkipListException("Smart search has None step on its lower side. Probably malformed skiplist!")
        return current, answer
    
        
    def _buildTower(self, leaf):
        ''' 
        Given a leaf, this method builds the tower of the skiplist linking the nodes.
        Returns the plateau of the tower.
        '''
        tower_height = self._computeTowerHeight(leaf.pathname)
        current_node = leaf
        while current_node.height < (tower_height-1) : current_node = self._createUpperNode(current_node)
        return current_node
        
    def _createUpperNode(self, lower_node):
        ''' 
        Creates a father node in a column, given a child node.
        Returns the newly created upper node.
        '''
        new_node = SkipListNode(lower_node.pathname, lower_node.height + 1)
        self._linkLowerChild(new_node, lower_node)
        return new_node

    def _linkLowerChild(self, father, lower_child):
        ''' Links a given father to given child in a vertical relation.'''
        father.lower_child = lower_child
        lower_child.father = father
        
    def _linkRightChild(self, father, right_child):        
        ''' Links a given father to given child in a horizontal relation.'''
        father.right_child = right_child
        right_child.father = father
          
    def _computeTowerHeight(self, pathname):
        ''' Computes deterministically the tower height for a given pathname. '''
        if pathname == NEGATIVE_INFINITE or pathname == POSITIVE_INFINITE: return MAX_TOWER_HEIGHT + 1
        #This was the previous method.
        #total= len(pathname) % MAX_TOWER_HEIGHT        
         
        x = getHashFirstTwoBytes(pathname)                      
        height = 1 
        stop = False
        while not stop:
            resto = x % 4
            x = x/4
            if resto == 0: height = height+1
            else: stop =True
            if height >= MAX_TOWER_HEIGHT: stop=True            
        return height
    
    def _isGuard(self, pathname):
        ''' Returns True if pathname is -INF or +INF '''
        return (pathname == NEGATIVE_INFINITE or pathname == POSITIVE_INFINITE)

        
    @staticmethod
    def _comparePathnames(a, b):
        '''
        Comparison function:
        - uses alphanumeric ordering
        - +/-INF are lower and greate values possible
        Returns  1 if a is gt b
        Returns -1 if a is lt b
        Returns  0 if a is eq b
        '''
        return SkipListNode.comparePathnames(a, b)


class SkipListHandlingException(Exception):
    ''' A common SkipList Exception.'''    
    pass

class MalformedSkipListException(Exception):
    ''' A SkipList Exception to be used when the skip list seems to be corrupted or broken.'''    
    pass

class UnexpectedBasisException(Exception):
    ''' A SkipList Exception to be used when basis can't be computed.'''


########NEW FILE########
__FILENAME__ = SkipListNode
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Shared FileRock Integrity Check skipList node.


This module provides a class modeling a SkipList node
for the FileRock Integrity Check.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import logging
from Hashing import getHash, encode
POSITIVE_INFINITE = u'+INF'
NEGATIVE_INFINITE = u'-INF'

class SkipListNode():
    '''
    This class represents a node of the SkipList and describes its position in the data structure.
    It also implements the ASL function of label computation.
    It's important to remember that such 'label' is, for root node in the SkipList, the basis.
    '''

    def __init__(self, pathname, height, label = None, filehash = None, loggername = "SkipListNodeLogger"):
        ''' 
        A SkipListNode is identified by a couple (pathname, height), that is its cartesian position in the skip list.
        @label: it is the value needed for authentication process; it should be set at level 0 only, it's None by default.
        @filehash: it is the file content hash; it should be set at level 0 only, None by default.
        @loggername: the name of the logger to be used in it.        
        '''

        self.pathname = pathname  
        self.height = height
        self.label = label
        self.lower_child = None
        self.right_child = None
        self.father = None
        self.outdated_label = True        
        self.filehash = filehash
        self.loggername = loggername
        self.who = self.__class__.__name__

    def isNegativeInfinite(self):
        '''Returns True if node is part of the right guard.'''
        return self.pathname == NEGATIVE_INFINITE
    
    def isPositiveInfinite(self):
        '''Returns True if node is part of the left guard.'''
        return self.pathname == POSITIVE_INFINITE
    
    def isGuard(self):
        '''Returns True if node is part of any guard.'''
        return self.isNegativeInfinite() or self.isPositiveInfinite()
    
    def isPlateau(self):
        ''' Returns True if given node is a plateau. '''

        is_plateau = (self.father == None) or (self.father.pathname != self.pathname)

        # Check for broken links:
        if self.father != None:
            if is_plateau:
                try: assert (self.father.right_child == self)
                except AssertionError: raise MalformedSkipListException('Right child for plateaus\'s father is different from self... what\'s going on here? (%s, %s)' % (self.pathname, self.height))
            else:
                try: assert (self.father.lower_child == self)
                except AssertionError: raise MalformedSkipListException('Lower child for non plateaus\'s father is different from self... what\'s going on here? (%s, %s)' % (self.pathname, self.height))
        return is_plateau
    
    def getSibling(self, child):
        '''
        Given a child of the node, returns its sibling.
        Returns None if 'self' is not father of 'child' at all.
        '''
        if child == self.lower_child: return self.right_child
        if child == self.right_child: return self.lower_child

        return None
    
    def computeLabel(self, forced = False):
        '''
        Computes node label.
        @forced: if True, forces the computation without using lazy-load. False by default
        raise: MalformedNodeException
        '''
        if not (forced or self.outdated_label): return self.label
        
        if self.height == 0:
            if self.filehash == None: raise MalformedNodeException("Leaf of %s has None filehash!" % repr(self.pathname))            
            if isinstance( self.right_child, SkipListNode ):                
                self.label = getHash( [ encode(self.pathname), self.filehash, self.right_child.computeLabel(forced) ] )
            else:
                encoded = encode(self.pathname)                
                self.label = encoded+self.filehash
        else: 
            if not isinstance(self.right_child, SkipListNode): self.label = self.lower_child.computeLabel(forced)
            else: self.label = getHash([self.lower_child.computeLabel(forced), self.right_child.computeLabel(forced)])
        
        self.outdated_label = False        
        return self.label
    
    def outdateAncestors(self):
        ''' 
        Marks the node and its ancestors with outdated mark and nullify its label.
        '''
        self.resetData()
        node = self.father          
        while isinstance(node, SkipListNode):            
            node.resetData()            
            node = node.father
    
    def resetData(self):
        self.label = None
        self.outdated_label=True
    
    def isDescendant(self, ancestor):
        '''
        Returns True if self has an ancestor - a node in the path from it to root - equal to given node.
        Returns also True if the two nodes are equal.
        '''
        node = self
        while isinstance(node, SkipListNode):
            if node == ancestor: return True
            node = node.father
        return False
    
    def __eq__(self, other):
        '''
        Returns true if this node and the given one have the same pathname and height.
        '''
        if (other == None): return False
        return (other.pathname == self.pathname and other.height == self.height)

    def __str__(self):
        return repr(self)

    def __repr__(self):
        return '(%s, %s, {{%s,%s}} [%s])' % (self.pathname, self.height, self.label, self.filehash, hex(id(self)))
    
    def printMe(self):
        print 'Hi, I am a node. Height: %s, Pathname: %s, Label = %s, Lowerchild: %s, Rightchild: %s' % (self.height, self.pathname, self.label, self.lower_child, self.right_child)

    def printMyAncestors(self):
        if isinstance(self.father, SkipListNode):
            print( "--->%s   (%s,%s)" % (self, self.lower_child, self.right_child))
            self.father.printMyAncestors()
        else:
            print("---")

    @staticmethod
    def comparePathnames(a, b):
        '''
        Comparison function:
        - uses alphanumeric ordering
        - +/-INF are lower and greate values possible
        Returns  1 if a is gt b
        Returns -1 if a is lt b
        Returns  0 if a is eq b
        '''
        if a==b     : return 0
        if a == POSITIVE_INFINITE or b == NEGATIVE_INFINITE: return 1
        if b == POSITIVE_INFINITE or a == NEGATIVE_INFINITE: return -1  
        if   a > b  : return 1        
        else        : return -1

class ProxyNode(SkipListNode):
    ''' 
    This class represents a node in a proof path that contributes with its label in the computation, but it has no tree under it.
    Like a SkipListNode, it describes its own identity with its position, but it comes with a fixed label.        
    '''
            
    def computeLabel(self, forced):
        '''
        Returns assigned label.
        raise: MalformedProxyException if proxy has not necessary data.
        '''
        if self.father == None: raise MalformedProxyException("Proxy (%s,%s) has None father!" % (self.pathname, self.height))        
        if self.label == None or self.label == "": raise MalformedProxyException("No label assigned to proxy of (%s,%s) " % (self.pathname, self.height))        
        return self.label    
    
    def resetData(self):
        pass
    
    def __repr__(self):
        return '(%s, %s, {{%s}} PROXY [%s])' % (self.pathname, self.height, self.label, hex(id(self)))


class MalformedSkipListException(Exception): pass
class MalformedNodeException(Exception): pass
class MalformedProxyException(Exception): pass

########NEW FILE########
__FILENAME__ = LinkingServiceCodes
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
FileRock Linking Service codes


This module defines the codes returned by the FileRock Linking Service.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

class LinkingServiceCodes():
    SUCCESS = 0
    LINKING_FAILED = 1
    INVALID_USER_CREDENTIAL = 2
    UNSUPPORTED_PROTOCOL_VERSION = 3
    UNSUPPORTED_MESSAGE_TYPE = 4
    TOO_MANY_BUCKET = 5
    BAD_USERNAME = 6

########NEW FILE########
__FILENAME__ = runtests
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
Nose test runner

Any command line parameter given to this script will be passed to nose.
To selectivly run a package of tests you can do as follows:

# Run only tests in the test.unit package
python runtests.py -A "'tests.unit' in  __module__"

# Run only tests in the test.integration package
python runtests.py -A "'tests.integration' in  __module__"

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import sys
import nose


argv = sys.argv

# Make the client code accessible to tests
#sys.path.append('..')

# Directory where to (recursively) look for tests
argv.append('--where=./tests/')

# Let me print stuff on stdout from tests
argv.append('--nocapture')

# Verbose output
argv.append('-v')

nose.run(argv=argv)

########NEW FILE########
__FILENAME__ = sync_integrity_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the sync_integrity_test module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from nose.tools import *
from mock import patch, MagicMock
import unittest
import datetime
import threading

from utilities import setup_server_session
from filerockclient.interfaces import GStatuses


@patch('filerockclient.serversession.states.sync.SyncDownloadingLeavesState')
@patch('filerockclient.serversession.states.pre_authentication.DisconnectedState')
@patch('filerockclient.serversession.connection_lifekeeper.ConnectionLifeKeeper')
@patch('filerockclient.workers.worker_pool.WorkerPool')
@patch('filerockclient.workers.filters.encryption.adapter.Adapter')
def test_integrity_error_if_different_storage_but_basis_is_trusted(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock):

    from FileRockSharedLibraries.Communication.Messages import SYNC_FILES_LIST

    components = setup_fixtures(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock)

    # There is nothing in the warebox
    components['mock']['warebox'].get_content.return_value = []

    # There is nothing in the storage cache
    assert_equal(components['real']['storage_cache'].get_all_records(), [])

    components['real']['metadata'].set('trusted_basis', 'TRUSTEDBASIS')

    # There is a file on the storage that needs to be downloaded
    storage_content = [
        {
            u'key': u'File.txt',
            u'etag': u'"d41d8cd98f00b204e9800998ecf8427e"',
            u'lmtime': u'1970-01-01T10:00:00.000Z',
            u'size': u'1'
        }
    ]

    # Server's basis is equal to the trusted basis
    msg = SYNC_FILES_LIST('SYNC_FILES_LIST', {
                'basis': 'TRUSTEDBASIS',
                'dataset': storage_content,
                'last_commit_client_id': '0',
                'last_commit_client_hostname': 'myhostname',
                'last_commit_client_platform': 'myplatform',
                'last_commit_timestamp': 'mytimestamp',
                'user_quota': '0',
                'used_space': '100'
                })
    components['real']['input_queue'].put(msg, 'servermessage')

    # Let's start!
    components['real']['server_session'].start()
    components['real']['server_session'].join()

    # The storage content is different from our trusted storage cache,
    # but the basis is equal to the trusted one: it's an attack.
    # We expect the application to have alerted the user about the integrity
    # error and to have gone into BasisMismatchState.
    ui = components['mock']['ui_controller']
    int_f = components['mock']['internal_facade']
    fail_state = components['mock']['integrity_failure_state']

    ui.notify_user.assert_called_with('hash_mismatch')
    int_f.set_global_status.assert_called_with(GStatuses.C_HASHMISMATCHONCONNECT)
    assert_true(fail_state.do_execute.called)


@patch('filerockclient.serversession.states.sync.SyncDownloadingLeavesState')
@patch('filerockclient.serversession.states.pre_authentication.DisconnectedState')
@patch('filerockclient.serversession.connection_lifekeeper.ConnectionLifeKeeper')
@patch('filerockclient.workers.worker_pool.WorkerPool')
@patch('filerockclient.workers.filters.encryption.adapter.Adapter')
def test_integrity_error_if_storage_is_trusted_but_different_basis(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock):

    from FileRockSharedLibraries.Communication.Messages import SYNC_FILES_LIST

    components = setup_fixtures(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock)

    # There is nothing in the warebox
    components['mock']['warebox'].get_content.return_value = []

    # There is nothing in the storage cache
    assert_equal(components['real']['storage_cache'].get_all_records(), [])

    components['real']['metadata'].set('trusted_basis', 'TRUSTEDBASIS')

    # There is nothing on the storage
    storage_content = []

    # Server's basis is different from our trusted basis
    msg = SYNC_FILES_LIST('SYNC_FILES_LIST', {
                'basis': 'MALICIOUSBASIS',
                'dataset': storage_content,
                'last_commit_client_id': '0',
                'last_commit_client_hostname': 'myhostname',
                'last_commit_client_platform': 'myplatform',
                'last_commit_timestamp': 'mytimestamp',
                'user_quota': '0',
                'used_space': '100'
                })
    components['real']['input_queue'].put(msg, 'servermessage')

    # Let's start!
    components['real']['server_session'].start()
    components['real']['server_session'].join()

    # The storage content is equal to our trusted storage cache,
    # but the basis is different from the trusted one: it's an attack.
    # We expect the application to have alerted the user about the integrity
    # error and to have gone into BasisMismatchState.
    ui = components['mock']['ui_controller']
    int_f = components['mock']['internal_facade']
    fail_state = components['mock']['integrity_failure_state']

    ui.notify_user.assert_called_with('hash_mismatch')
    int_f.set_global_status.assert_called_with(GStatuses.C_HASHMISMATCHONCONNECT)
    assert_true(fail_state.do_execute.called)


@patch('filerockclient.serversession.states.sync.SyncDownloadingLeavesState')
@patch('filerockclient.serversession.states.pre_authentication.DisconnectedState')
@patch('filerockclient.serversession.connection_lifekeeper.ConnectionLifeKeeper')
@patch('filerockclient.workers.worker_pool.WorkerPool')
@patch('filerockclient.workers.filters.encryption.adapter.Adapter')
@unittest.skip("Work in progress")
def test_integrity_error_if_different_storage_but_basis_is_candidate(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock):

    from FileRockSharedLibraries.Communication.Messages import SYNC_FILES_LIST
    from filerockclient.pathname_operation import PathnameOperation

    components = setup_fixtures(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock)

    # There is nothing in the warebox
    components['mock']['warebox'].get_content.return_value = []

    # There is nothing in the storage cache...
    assert_equal(components['real']['storage_cache'].get_all_records(), [])

    # ... but one file pending from last commit
    operation = PathnameOperation(
                        application=None, lock=None,
                        verb='UPLOAD', pathname=u'File.txt',
                        etag=u'd41d8cd98f00b204e9800998ecf8427e',
                        size=1, lmtime=datetime.datetime.now())
    transaction_cache = components['real']['server_session'].transaction_cache
    transaction_cache.update_record(1, operation, datetime.datetime.now())

    components['real']['metadata'].set('trusted_basis', 'TRUSTEDBASIS')
    components['real']['metadata'].set('candidate_basis', 'CANDIDATEBASIS')

    # There is nothing on the storage
    storage_content = []

    # Server basis is equal to our candidate basis
    msg = SYNC_FILES_LIST('SYNC_FILES_LIST', {
                'basis': 'CANDIDATEBASIS',
                'dataset': storage_content,
                'last_commit_client_id': '0',
                'last_commit_client_hostname': 'myhostname',
                'last_commit_client_platform': 'myplatform',
                'last_commit_timestamp': 'mytimestamp',
                'user_quota': '0',
                'used_space': '100'
                })
    components['real']['input_queue'].put(msg, 'servermessage')

    # Let's start!
    components['real']['server_session'].start()
    components['real']['server_session'].join()

    # The storage content is different from our candidate storage cache,
    # but the basis is equal to the candidate one: it's an attack.
    # We expect the application to have alerted the user about the integrity
    # error and to have gone into BasisMismatchState.
    ui = components['mock']['ui_controller']
    int_f = components['mock']['internal_facade']
    fail_state = components['mock']['integrity_failure_state']

    ui.notify_user.assert_called_with('hash_mismatch')
    int_f.set_global_status.assert_called_with(GStatuses.C_HASHMISMATCHONCONNECT)
    assert_true(fail_state.do_execute.called)


@patch('filerockclient.serversession.states.sync.SyncDownloadingLeavesState')
@patch('filerockclient.serversession.states.pre_authentication.DisconnectedState')
@patch('filerockclient.serversession.connection_lifekeeper.ConnectionLifeKeeper')
@patch('filerockclient.workers.worker_pool.WorkerPool')
@patch('filerockclient.workers.filters.encryption.adapter.Adapter')
@unittest.skip("Work in progress")
def test_integrity_error_storage_is_candidate_but_different_basis(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock):

    from FileRockSharedLibraries.Communication.Messages import SYNC_FILES_LIST
    from filerockclient.pathname_operation import PathnameOperation

    components = setup_fixtures(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock)

    # There is nothing in the warebox
    components['mock']['warebox'].get_content.return_value = []

    # There is nothing in the storage cache...
    assert_equal(components['real']['storage_cache'].get_all_records(), [])

    # ... but one file pending from last commit
    operation = PathnameOperation(
                        application=None, lock=None,
                        verb='UPLOAD', pathname=u'File.txt',
                        etag=u'd41d8cd98f00b204e9800998ecf8427e',
                        size=1, lmtime=datetime.datetime.now())
    transaction_cache = components['real']['server_session'].transaction_cache
    transaction_cache.update_record(1, operation, datetime.datetime.now())

    components['real']['metadata'].set('trusted_basis', 'TRUSTEDBASIS')
    components['real']['metadata'].set('candidate_basis', 'CANDIDATEBASIS')

    # On the storage there is the same file as in the candidate storage cache
    storage_content = [
        {
            u'key': u'File.txt',
            u'etag': u'"d41d8cd98f00b204e9800998ecf8427e"',
            u'lmtime': u'1970-01-01T10:00:00.000Z',
            u'size': u'1'
        }
    ]

    # Server basis is different from the candidate basis
    msg = SYNC_FILES_LIST('SYNC_FILES_LIST', {
                'basis': 'MALICIOUSBASIS',
                'dataset': storage_content,
                'last_commit_client_id': '0',
                'last_commit_client_hostname': 'myhostname',
                'last_commit_client_platform': 'myplatform',
                'last_commit_timestamp': 'mytimestamp',
                'user_quota': '0',
                'used_space': '100'
                })
    components['real']['input_queue'].put(msg, 'servermessage')

    # Let's start!
    components['real']['server_session'].start()
    components['real']['server_session'].join()

    # The storage content is equal to our candidate storage cache,
    # but the basis is different from the candidate one: it's an attack.
    # We expect the application to have alerted the user about the integrity
    # error and to have gone into BasisMismatchState.
    ui = components['mock']['ui_controller']
    int_f = components['mock']['internal_facade']
    fail_state = components['mock']['integrity_failure_state']

    ui.notify_user.assert_called_with('hash_mismatch')
    int_f.set_global_status.assert_called_with(GStatuses.C_HASHMISMATCHONCONNECT)
    assert_true(fail_state.do_execute.called)


@patch('filerockclient.serversession.states.sync.SyncDownloadingLeavesState')
@patch('filerockclient.serversession.states.pre_authentication.DisconnectedState')
@patch('filerockclient.serversession.connection_lifekeeper.ConnectionLifeKeeper')
@patch('filerockclient.workers.worker_pool.WorkerPool')
@patch('filerockclient.workers.filters.encryption.adapter.Adapter')
def test_integrity_error_if_storage_is_different_but_basis_is_accepted(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock):

    from FileRockSharedLibraries.Communication.Messages import SYNC_FILES_LIST
    from filerockclient.pathname_operation import PathnameOperation
    from filerockclient.serversession.states.register import StateRegister

    components = setup_fixtures(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock)

    # There is nothing in the warebox
    components['mock']['warebox'].get_content.return_value = []

    # There is nothing in the storage cache
    assert_equal(components['real']['storage_cache'].get_all_records(), [])

    components['real']['metadata'].set('trusted_basis', 'TRUSTEDBASIS')

    # On the storage there is one file to download
    storage_content = [
        {
            u'key': u'File.txt',
            u'etag': u'"d41d8cd98f00b204e9800998ecf8427e"',
            u'lmtime': u'1970-01-01T10:00:00.000Z',
            u'size': u'1'
        }
    ]

    # Server basis is new, different from our trusted basis
    msg = SYNC_FILES_LIST('SYNC_FILES_LIST', {
                'basis': 'NEWBASIS',
                'dataset': storage_content,
                'last_commit_client_id': '0',
                'last_commit_client_hostname': 'myhostname',
                'last_commit_client_platform': 'myplatform',
                'last_commit_timestamp': 'mytimestamp',
                'user_quota': '0',
                'used_space': '100'
                })
    components['real']['input_queue'].put(msg, 'servermessage')

    # The user will accept the synchronization the first time
    old_ask_user = components['mock']['ui_controller'].ask_for_user_input
    components['mock']['ui_controller'].ask_for_user_input = MagicMock(return_value='ok')

    reset_done = threading.Event()

    def reset_session():
        reset_done.set()
        return StateRegister.get('SyncStartState')

    # Go back to the start as soon as the user has accepted
    old_downloading_exc = components['mock']['downloading_state'].do_execute
    components['mock']['downloading_state'].do_execute = MagicMock(side_effect=reset_session)

    # Let's start!
    components['real']['server_session'].start()
    reset_done.wait()

    # ServerSession has been reset, restore the previous setting
    components['mock']['ui_controller'].ask_for_user_input = old_ask_user
    components['mock']['downloading_state'].do_execute = old_downloading_exc

    # ServerSession remember to have accepted this synchronization
    last_accepted_state = components['real']['metadata'].get('LastAcceptedState')
    assert_not_equal(last_accepted_state, None)
    last_accepted_basis, _ = last_accepted_state.split()
    assert_equal(last_accepted_basis, 'NEWBASIS')

    # Send again the data to sync, this time with a different storage content
    msg = SYNC_FILES_LIST('SYNC_FILES_LIST', {
                'basis': 'NEWBASIS',
                'dataset': [],
                'last_commit_client_id': '0',
                'last_commit_client_hostname': 'myhostname',
                'last_commit_client_platform': 'myplatform',
                'last_commit_timestamp': 'mytimestamp',
                'user_quota': '0',
                'used_space': '100'
                })
    components['real']['input_queue'].put(msg, 'servermessage')

    components['real']['server_session'].join()

    # The storage content is different from last accepted content,
    # but the basis is equal to the last accepted one: it's an attack.
    # We expect the application to have alerted the user about the integrity
    # error and to have gone into BasisMismatchState.
    ui = components['mock']['ui_controller']
    int_f = components['mock']['internal_facade']
    fail_state = components['mock']['integrity_failure_state']

    ui.notify_user.assert_called_with('hash_mismatch')
    int_f.set_global_status.assert_called_with(GStatuses.C_HASHMISMATCHONCONNECT)
    assert_true(fail_state.do_execute.called)


@patch('filerockclient.serversession.states.sync.SyncDownloadingLeavesState')
@patch('filerockclient.serversession.states.pre_authentication.DisconnectedState')
@patch('filerockclient.serversession.connection_lifekeeper.ConnectionLifeKeeper')
@patch('filerockclient.workers.worker_pool.WorkerPool')
@patch('filerockclient.workers.filters.encryption.adapter.Adapter')
def test_integrity_error_if_storage_is_accepted_but_basis_is_different(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock):

    from FileRockSharedLibraries.Communication.Messages import SYNC_FILES_LIST
    from filerockclient.serversession.states.register import StateRegister

    components = setup_fixtures(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock)

    # There is nothing in the warebox
    components['mock']['warebox'].get_content.return_value = []

    # There is nothing in the storage cache
    assert_equal(components['real']['storage_cache'].get_all_records(), [])

    components['real']['metadata'].set('trusted_basis', 'TRUSTEDBASIS')

    # On the storage there is one file to download
    storage_content = [
        {
            u'key': u'File.txt',
            u'etag': u'"d41d8cd98f00b204e9800998ecf8427e"',
            u'lmtime': u'1970-01-01T10:00:00.000Z',
            u'size': u'1'
        }
    ]

    # Server basis is new, different from our trusted basis
    msg = SYNC_FILES_LIST('SYNC_FILES_LIST', {
                'basis': 'NEWBASIS',
                'dataset': storage_content,
                'last_commit_client_id': '0',
                'last_commit_client_hostname': 'myhostname',
                'last_commit_client_platform': 'myplatform',
                'last_commit_timestamp': 'mytimestamp',
                'user_quota': '0',
                'used_space': '100'
                })
    components['real']['input_queue'].put(msg, 'servermessage')

    # The user will accept the synchronization the first time
    old_ask_user = components['mock']['ui_controller'].ask_for_user_input
    components['mock']['ui_controller'].ask_for_user_input = MagicMock(return_value='ok')

    reset_done = threading.Event()

    def reset_session():
        reset_done.set()
        return StateRegister.get('SyncStartState')

    # Go back to the start as soon as the user has accepted
    old_downloading_exc = components['mock']['downloading_state'].do_execute
    components['mock']['downloading_state'].do_execute = MagicMock(side_effect=reset_session)

    # Let's start!
    components['real']['server_session'].start()
    reset_done.wait()

    # ServerSession has been reset, restore the previous settings
    components['mock']['ui_controller'].ask_for_user_input = old_ask_user
    components['mock']['downloading_state'].do_execute = old_downloading_exc

    # ServerSession remembers to have accepted this synchronization
    last_accepted_state = components['real']['metadata'].get('LastAcceptedState')
    assert_not_equal(last_accepted_state, None)
    last_accepted_basis, _ = last_accepted_state.split()
    assert_equal(last_accepted_basis, 'NEWBASIS')

    # Send again the data to sync, this time with a different basis
    msg = SYNC_FILES_LIST('SYNC_FILES_LIST', {
                'basis': 'MALICIOUSBASIS',
                'dataset': storage_content,
                'last_commit_client_id': '0',
                'last_commit_client_hostname': 'myhostname',
                'last_commit_client_platform': 'myplatform',
                'last_commit_timestamp': 'mytimestamp',
                'user_quota': '0',
                'used_space': '100'
                })
    components['real']['input_queue'].put(msg, 'servermessage')

    components['real']['server_session'].join()

    # The storage content is equal to the last accepted content,
    # but the basis is different from the last accepted one: it's an attack.
    # We expect the application to have alerted the user about the integrity
    # error and to have gone into BasisMismatchState.
    ui = components['mock']['ui_controller']
    int_f = components['mock']['internal_facade']
    fail_state = components['mock']['integrity_failure_state']

    ui.notify_user.assert_called_with('hash_mismatch')
    int_f.set_global_status.assert_called_with(GStatuses.C_HASHMISMATCHONCONNECT)
    assert_true(fail_state.do_execute.called)


def setup_fixtures(adapter_mock, workerpool_mock, connection_lifekeeper,
                   disconnectedstate_cls_mock, downloadstate_cls_mock):

    from filerockclient.serversession.states.register import StateRegister

    components = setup_server_session(
                        __file__,
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock)

    # Note: the StateRegister singleton has been initialized by
    # ServerSession's constructor
    syncstart_state = StateRegister.get('SyncStartState')

    # DisconnectedState is the default initial state, but we want to start
    # from SyncStartState
    disconnected_state_mock = disconnectedstate_cls_mock()
    disconnected_state_mock.do_execute.return_value = syncstart_state

    def fail():
        msg = "ServerSession has attempted to start downloading although an" \
              " integrity error was expected"
        assert_true(False, msg)

    # If we get into SyncDownloadingLeavesState, it means we have
    # passed the integrity check. But we shouldn't had to!
    download_state_mock = downloadstate_cls_mock()
    download_state_mock.do_execute.side_effect = fail

    def ask_user(what, content, client_basis, server_basis):
        if what == 'accept_sync':
            msg = "The user has been asked to accept the synchronization" \
              " although an integrity error was expected"
            assert_true(False, msg)
        return 'ok'

    # If the sync dialog is shown to the user, it means we have
    # passed the integrity check. But we shouldn't had to!
    components['mock']['ui_controller'].ask_for_user_input.side_effect = ask_user

    def terminate():
        components['real']['server_session'].terminate()
        return integrity_failure_state

    # If the integrity check fails, it's fine
    integrity_failure_state = StateRegister.get('BasisMismatchState')
    integrity_failure_state.do_execute = MagicMock(side_effect=terminate)
    components['mock']['integrity_failure_state'] = integrity_failure_state
    components['mock']['downloading_state'] = download_state_mock

    return components

########NEW FILE########
__FILENAME__ = sync_operations_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the sync_operations_test module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from nose.tools import *
from mock import patch

from utilities import setup_server_session


@patch('filerockclient.serversession.states.sync.SyncDownloadingLeavesState')
@patch('filerockclient.serversession.states.pre_authentication.DisconnectedState')
@patch('filerockclient.serversession.connection_lifekeeper.ConnectionLifeKeeper')
@patch('filerockclient.workers.worker_pool.WorkerPool')
@patch('filerockclient.workers.filters.encryption.adapter.Adapter')
def test_nothing_to_sync_from_clean_state(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock):

    from filerockclient.serversession.states.register import StateRegister
    from FileRockSharedLibraries.Communication.Messages import SYNC_FILES_LIST

    components = setup_server_session(
                        __file__,
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock)

    # Note: the StateRegister singleton has been initialized by
    # ServerSession's constructor
    syncstart_state = StateRegister.get('SyncStartState')

    def terminate():
        components['real']['server_session'].terminate()
        return syncstart_state

    # DisconnectedState is the default initial state, but we want to start
    # from SyncStartState
    disconnected_state_mock = disconnectedstate_cls_mock()
    disconnected_state_mock.do_execute.return_value = syncstart_state

    # Stop the test when we get to SyncDownloadingLeavesState
    download_state_mock = downloadstate_cls_mock()
    download_state_mock.do_execute.side_effect = terminate

    # There is nothing in the warebox
    components['mock']['warebox'].get_content.return_value = []

    # Send ServerSession a scenario with no data on the storage.
    components['real']['metadata'].set('trusted_basis', 'TRUSTEDBASIS')
    msg = SYNC_FILES_LIST('SYNC_FILES_LIST', {
                'basis': 'TRUSTEDBASIS',
                'dataset': [],
                'last_commit_client_id': '0',
                'last_commit_client_hostname': 'myhostname',
                'last_commit_client_platform': 'myplatform',
                'last_commit_timestamp': 'mytimestamp',
                'user_quota': '0',
                'used_space': '100'
                })
    components['real']['input_queue'].put(msg, 'servermessage')

    components['real']['server_session'].start()
    components['real']['server_session'].join()

    # No data on the storage, in the warebox or in the storage cache.
    # We expect that nothing has happened.
    assert_false(components['mock']['ui_controller'].ask_for_user_input.called)
    assert_equal(components['real']['storage_cache'].get_all_records(), [])
    assert_true(components['real']['input_queue'].empty(['operation']))


@patch('filerockclient.serversession.states.sync.SyncDownloadingLeavesState')
@patch('filerockclient.serversession.states.pre_authentication.DisconnectedState')
@patch('filerockclient.serversession.connection_lifekeeper.ConnectionLifeKeeper')
@patch('filerockclient.workers.worker_pool.WorkerPool')
@patch('filerockclient.workers.filters.encryption.adapter.Adapter')
def test_download_operations_from_clean_state(
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock):

    from filerockclient.serversession.states.register import StateRegister
    from FileRockSharedLibraries.Communication.Messages import SYNC_FILES_LIST
    from filerockclient.interfaces import PStatuses

    components = setup_server_session(
                        __file__,
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock)

    # Note: the StateRegister singleton has been initialized by
    # ServerSession's constructor
    syncstart_state = StateRegister.get('SyncStartState')

    def terminate():
        components['real']['server_session'].terminate()
        return syncstart_state

    # DisconnectedState is the default initial state, but we want to start
    # from SyncStartState
    disconnected_state_mock = disconnectedstate_cls_mock()
    disconnected_state_mock.do_execute.return_value = syncstart_state

    # Stop the test when we get to SyncDownloadingLeavesState
    download_state_mock = downloadstate_cls_mock()
    download_state_mock.do_execute.side_effect = terminate

    # There is nothing in the warebox
    components['mock']['warebox'].get_content.return_value = []

    components['real']['metadata'].set('trusted_basis', 'TRUSTEDBASIS')

    # Send ServerSession a scenario with one file to download.
    storage_content = [
        {
            u'key': u'File.txt',
            u'etag': u'"d41d8cd98f00b204e9800998ecf8427e"',
            u'lmtime': u'1970-01-01T10:00:00.000Z',
            u'size': u'1'
        }
    ]
    msg = SYNC_FILES_LIST('SYNC_FILES_LIST', {
                'basis': 'NEWBASIS',
                'dataset': storage_content,
                'last_commit_client_id': '0',
                'last_commit_client_hostname': 'myhostname',
                'last_commit_client_platform': 'myplatform',
                'last_commit_timestamp': 'mytimestamp',
                'user_quota': '0',
                'used_space': '100'
                })
    components['real']['input_queue'].put(msg, 'servermessage')

    def user_accepts_sync(what, content, client_basis, server_basis):
        assert_equal(client_basis, 'TRUSTEDBASIS')
        assert_equal(server_basis, 'NEWBASIS')
        assert_equal(len(content), 1)
        assert_equal(content[0]['pathname'], 'File.txt')
        assert_equal(content[0]['status'], PStatuses.DOWNLOADNEEDED)
        assert_equal(content[0]['size'], 1)
        return 'ok'

    components['mock']['ui_controller'].ask_for_user_input.side_effect = user_accepts_sync

    components['real']['server_session'].start()
    components['real']['server_session'].join()

    # We expect to download a file
    assert_true(components['mock']['ui_controller'].ask_for_user_input.called)
    assert_equal(components['real']['storage_cache'].get_all_records(), [])
    assert_false(components['real']['input_queue'].empty(['operation']))
    operation, _ = components['real']['input_queue'].get(['operation'])
    assert_equal(operation.pathname, 'File.txt')
    assert_equal(operation.verb, 'DOWNLOAD')

########NEW FILE########
__FILENAME__ = utilities
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the utilities module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from nose.tools import *
from mock import MagicMock
import os
import logging


def setup_server_session(
                        current_module,
                        adapter_mock, workerpool_mock, connection_lifekeeper,
                        disconnectedstate_cls_mock, downloadstate_cls_mock):

    # Remember: python caches imported modules so not to reload the same
    # module again and again. This can make troubles with mocking: any
    # dependent module that is mocked for the current test but it was not for
    # the previous one wouldn't be reloaded, that is, it would result not
    # mocked. It happens with dependencies in the form "from X import Y".
    # For this reason we reload any module that is not a mock, so to reload
    # its symbol table - any "from X import Y" in its body is executed again.

    import filerockclient.serversession.server_session
    reload(filerockclient.serversession.server_session)
    ServerSession = filerockclient.serversession.server_session.ServerSession

    import filerockclient.serversession.startup_synchronization
    reload(filerockclient.serversession.startup_synchronization)
    StartupSynchronization = filerockclient.serversession.startup_synchronization.StartupSynchronization

    import filerockclient.databases.metadata
    reload(filerockclient.databases.metadata)
    MetadataDB = filerockclient.databases.metadata.MetadataDB

    import filerockclient.databases.storage_cache
    reload(filerockclient.databases.storage_cache)
    StorageCache = filerockclient.databases.storage_cache.StorageCache

    import filerockclient.util.multi_queue
    reload(filerockclient.util.multi_queue)
    MultiQueue = filerockclient.util.multi_queue.MultiQueue

    import filerockclient.events_queue
    reload(filerockclient.events_queue)
    EventsQueue = filerockclient.events_queue.EventsQueue

    # Let the client talk! (requires --nocapture)
    #configure_logging()

    cfg_mock = MagicMock()

    def cfg_return_values(*args):
        filename = get_fresh_filename(current_module, 'transaction_cache')
        values = {
            ('Application Paths', 'transaction_cache_db'): filename,
            ('System', 'storage_endpoint'): 'www.filerock.com'
        }
        try:
            return values[args]
        except KeyError:
            return MagicMock()

    cfg_mock.get.side_effect = cfg_return_values

    # TODO: try to use the real Warebox class instead of a mock.
    # There are a lot of dependancies to filesystem functions to break, maybe
    # some refactoring would make the thing easier.
    warebox_mock = MagicMock()
    warebox_mock.is_blacklisted.return_value = False

    storage_cache = StorageCache(get_fresh_filename(
                                            current_module, 'storage_cache'))
    storage_cache.recreated = False
    fswatcher_mock = MagicMock()
    linker_mock = MagicMock()
    metadata = MetadataDB(get_fresh_filename(current_module, 'metadata'))
    hashes_mock = MagicMock()
    internalfacade_mock = MagicMock()
    internalfacade_mock.is_first_startup.return_value = False
    uicontroller_mock = MagicMock()
    scheduler_mock = MagicMock()

    session_queue = MultiQueue([
        'servermessage',
        'operation',
        'usercommand',
        'sessioncommand',
        'systemcommand'
    ])

    events_queue = EventsQueue(internalfacade_mock, session_queue)

    sync = StartupSynchronization(
                            warebox_mock, storage_cache, events_queue)

    server_session = ServerSession(
        cfg_mock, warebox_mock,
        storage_cache, sync,
        fswatcher_mock, linker_mock,
        metadata, hashes_mock, internalfacade_mock,
        uicontroller_mock, get_lock_filename(current_module), 
        auto_start=False,
        input_queue=session_queue, scheduler=scheduler_mock)

    components = {'real': {}, 'mock': {}}
    components['real']['storage_cache'] = storage_cache
    components['real']['startup_sync'] = sync
    components['real']['metadata'] = metadata
    components['real']['input_queue'] = session_queue
    components['real']['server_session'] = server_session
    components['real']['events_queue'] = events_queue

    components['mock']['cfg'] = cfg_mock
    components['mock']['warebox'] = warebox_mock
    components['mock']['fswatcher'] = fswatcher_mock
    components['mock']['linker'] = linker_mock
    components['mock']['hashes'] = hashes_mock
    components['mock']['internal_facade'] = internalfacade_mock
    components['mock']['ui_controller'] = uicontroller_mock
    components['mock']['scheduler'] = scheduler_mock

    return components


def get_current_dir(current_module):
    return os.path.dirname(os.path.abspath(current_module))

def get_lock_filename(current_module):
    data_dir = os.path.join(get_current_dir(current_module), 'test_data')
    if not os.path.exists(data_dir):
        os.mkdir(data_dir)
    return os.path.join(data_dir, "lockfile")

def get_fresh_filename(current_module, name):
    data_dir = os.path.join(get_current_dir(current_module), 'test_data')
    if not os.path.exists(data_dir):
        os.mkdir(data_dir)
    pathname = os.path.join(data_dir, name)
    if os.path.exists(pathname):
        os.remove(pathname)
    return pathname


def configure_logging():
    logger = logging.getLogger("FR")
    logger.addHandler(logging.StreamHandler())
    logger.setLevel(logging.DEBUG)

########NEW FILE########
__FILENAME__ = blacklist_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the blacklist_test module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import unittest
from filerockclient.blacklist.blacklist import Blacklist
from filerockclient.warebox import BLACKLISTED_DIRS
from filerockclient.warebox import BLACKLISTED_FILES, CONTAINS_PATTERN, EXTENTIONS


class BlacklistTest(unittest.TestCase):

    def setUp(self):
        self.blacklist = Blacklist(BLACKLISTED_DIRS,
                                   BLACKLISTED_FILES,
                                   extentions=EXTENTIONS,
                                   contains=CONTAINS_PATTERN)
        ext = EXTENTIONS[1]
        self.blacklisted_pathnames = [
            'bla/bla/bla/fsdf.%s' % ext,
            's.%s' % ext,
            '/sdf.%s' % ext,
            '/@@@^^.%s' % ext
        ]

        self.whitelisted_pathname = [
            '.%s' % ext,
            '%s' % ext,
            '/.%s' % ext,
            '/%s' % ext,
            '/.%s/sdf/.%s' % (ext, ext),
            'asdfasf.%s/safdfd' % ext
        ]

        self.blacklisted_contains = [
            'blablabla\nasdfasf',
            'asdfaf\n',
            '\r',
            '\n',
            '\n\r',
            '\r\n',
            '\radsfafd',
            '\nsadfasf',
            'a\df\n\raasfd\dfasf',
            'safdasf\nadsfasf'
        ]

        self.blacklisted_folders = [
            ".filerock/",
            ".FileRock/",
            ".FileRockTemp/",
            ".filerock/sadf",
            ".FileRock/sdfsdf",
            ".FileRockTemp/sdfdsf.%s" % ext
        ]

        self.whitelisted_folders = [
            ".filerocksdf/",
            ".FileRocktemp/",
            ".Filerocktemp/"
        ]

    def tearDown(self):
        pass

    def test_extentions(self):
        for pathname in self.blacklisted_pathnames:
            self.assertTrue(self.blacklist.is_blacklisted(pathname), pathname)
        for pathname in self.whitelisted_pathname:
            self.assertFalse(self.blacklist.is_blacklisted(pathname), pathname)

    def test_contains(self):
        for pathname in self.blacklisted_contains:
            self.assertTrue(self.blacklist.is_blacklisted(pathname), pathname)

    def test_folder(self):
        for pathname in self.blacklisted_folders:
            self.assertTrue(self.blacklist.is_blacklisted(pathname), pathname)
        for pathname in self.whitelisted_folders:
            self.assertFalse(self.blacklist.is_blacklisted(pathname), pathname)

########NEW FILE########
__FILENAME__ = config_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the config_test module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import os
from nose.tools import *
from ConfigParser import SafeConfigParser
import codecs

import filerockclient.config
from filerockclient.config import ConfigManager
from filerockclient.config import CONFIG_FILE_NAME
from filerockclient.config import ConfigException


filerockclient.config.CURRENT_CONFIG_VERSION = 1


SIMPLE_CONFIG_FILE = {
    'System': {
        'config_version': '1'
    },
    'User': {
        'temp_dir': 'temp',
        'field': 'value'
    },
    'Application Paths': {
        'caches_dir': 'caches'
    }
}


COMPLEX_CONFIG_FILE = {
    'System': {
        'config_version': '1',
        'server_hostname': 'service.filerock.com',
        'field1': 'new_f1'
    },
    'User': {
        'temp_dir': 'temp',
        'warebox_path': '/home/user/FileRock',
        'client_id': '0',
        'field2': 'new_f2'
    },
    'Client': {
        'commit_threshold_seconds': '15'
    },
    'Application Paths': {
        'caches_dir': 'caches',
        'to_auto_discover': '<AUTO-DISCOVERY>'
    }
}


OBSOLETE_CONFIG_FILE = {
    'System': {
        'config_version': '0',
        'field0': 'f0',
        'field1': 'f1'
    },
    'User': {
        'temp_dir': 'temp',
        'warebox_path': 'C:\\FileRock',
        'field3': 'f3',
        'field2': 'f2'
    },
    'Client': {
        'field3': 'f3'
    },
    'Application Paths': {
        'caches_dir': 'caches'
    }
}


def test_existing_directory_is_accepted():
    test_cfg_dir = get_current_dir()
    test_cfg_file = os.path.join(test_cfg_dir, CONFIG_FILE_NAME)
    cfg = ConfigManager(test_cfg_dir)
    assert_equal(cfg.config_dir, test_cfg_dir)
    assert_equal(cfg.file_path, test_cfg_file)


def test_nonexisting_directory_is_accepted():
    test_cfg_dir = os.path.abspath(u'xsfgsdfghldfgfdgbdf')
    test_cfg_file = os.path.join(test_cfg_dir, CONFIG_FILE_NAME)
    cfg = ConfigManager(test_cfg_dir)
    assert_equal(cfg.config_dir, test_cfg_dir)
    assert_equal(cfg.file_path, test_cfg_file)


def test_file_is_not_accepted_as_directory():
    test_cfg_dir = os.path.abspath(__file__)
    try:
        cfg = ConfigManager(test_cfg_dir)
    except ConfigException:
        assert_true(True, 'Correctly rejected')
        return
    assert_true(False, 'Exception expected')


def test_simple_config_file_is_read():
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, SIMPLE_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
    finally:
        cleanup_configuration(test_cfg_dir)


def test_simple_config_file_is_read_correctly():
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, SIMPLE_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
        assert_equal(cfg.getint('System', 'config_version'), 1)
        assert_equal(cfg.get('Application Paths', 'caches_dir'), u'caches')
        assert_equal(cfg.get('User', 'temp_dir'), u'temp')
        assert_equal(cfg.get('User', 'field'), u'value')
    finally:
        cleanup_configuration(test_cfg_dir)


def test_changed_fields_are_overwritten():
    old_config = filerockclient.config.DEFAULT_CONFIG
    filerockclient.config.DEFAULT_CONFIG = COMPLEX_CONFIG_FILE
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, OBSOLETE_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
        assert_true(cfg.has_option('System', 'field1'))
        assert_equal(cfg.get('System', 'field1'), 'new_f1')
    finally:
        filerockclient.config.DEFAULT_CONFIG = old_config
        cleanup_configuration(test_cfg_dir)


def test_obsolete_fields_are_removed():
    old_config = filerockclient.config.DEFAULT_CONFIG
    filerockclient.config.DEFAULT_CONFIG = COMPLEX_CONFIG_FILE
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, OBSOLETE_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
        assert_false(cfg.has_option('System', 'field0'))
    finally:
        filerockclient.config.DEFAULT_CONFIG = old_config
        cleanup_configuration(test_cfg_dir)


def test_nonwritable_changed_fields_are_not_overwritten():
    old_config = filerockclient.config.DEFAULT_CONFIG
    filerockclient.config.DEFAULT_CONFIG = COMPLEX_CONFIG_FILE
    filerockclient.config.DONT_OVERWRITE_ON_MERGE = [('System', 'field1')]
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, OBSOLETE_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
        assert_true(cfg.has_option('System', 'field1'))
        assert_equal(cfg.get('System', 'field1'), 'f1')
    finally:
        filerockclient.config.DEFAULT_CONFIG = old_config
        filerockclient.config.DONT_OVERWRITE_ON_MERGE = []
        cleanup_configuration(test_cfg_dir)


def test_missing_fields_in_nonwriteable_section_are_created():
    old_config = filerockclient.config.DEFAULT_CONFIG
    filerockclient.config.DEFAULT_CONFIG = COMPLEX_CONFIG_FILE
    filerockclient.config.DONT_OVERWRITE_ON_MERGE = [('System', '*')]
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, OBSOLETE_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
        assert_true(cfg.has_option('System', 'server_hostname'))
        assert_equal(cfg.get('System', 'server_hostname'), 'service.filerock.com')
    finally:
        filerockclient.config.DEFAULT_CONFIG = old_config
        filerockclient.config.DONT_OVERWRITE_ON_MERGE = []
        cleanup_configuration(test_cfg_dir)


def test_changed_fields_in_nonwriteable_section_are_not_overwritten():
    old_config = filerockclient.config.DEFAULT_CONFIG
    filerockclient.config.DEFAULT_CONFIG = COMPLEX_CONFIG_FILE
    filerockclient.config.DONT_OVERWRITE_ON_MERGE = [('System', '*')]
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, OBSOLETE_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
        assert_true(cfg.has_option('System', 'field1'))
        assert_equal(cfg.get('System', 'field1'), 'f1')
    finally:
        filerockclient.config.DEFAULT_CONFIG = old_config
        filerockclient.config.DONT_OVERWRITE_ON_MERGE = []
        cleanup_configuration(test_cfg_dir)


def test_nondeletable_obsolete_fields_are_not_removed():
    old_config = filerockclient.config.DEFAULT_CONFIG
    filerockclient.config.DEFAULT_CONFIG = COMPLEX_CONFIG_FILE
    filerockclient.config.DONT_OVERWRITE_ON_MERGE = [('System', 'field0')]
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, OBSOLETE_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
        assert_false(cfg.has_option('System', 'field0'))
    finally:
        filerockclient.config.DEFAULT_CONFIG = old_config
        filerockclient.config.DONT_OVERWRITE_ON_MERGE = []
        cleanup_configuration(test_cfg_dir)


def test_autodiscovery_fields_are_parsed():
    old_discovery = filerockclient.config.AUTO_DISCOVERY
    filerockclient.config.AUTO_DISCOVERY = {
        ('Application Paths', 'to_auto_discover'): lambda: 'auto_discovered'
    }
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, COMPLEX_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
        value = cfg.get('Application Paths', 'to_auto_discover')
        assert_equal(value, 'auto_discovered')
    finally:
        filerockclient.config.AUTO_DISCOVERY = old_discovery
        cleanup_configuration(test_cfg_dir)


def test_autodiscovery_fields_are_not_saved():
    old_discovery = filerockclient.config.AUTO_DISCOVERY
    filerockclient.config.AUTO_DISCOVERY = {
        ('Application Paths', 'to_auto_discover'): lambda: 'auto_discovered'
    }
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, COMPLEX_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
        value = cfg.get('Application Paths', 'to_auto_discover')
        assert_equal(value, 'auto_discovered')
        cfg.write_to_file()
        plain_cfg = SafeConfigParser()
        with codecs.open(os.path.join(test_cfg_dir, CONFIG_FILE_NAME), encoding='utf-8_sig') as fp:
            plain_cfg.readfp(fp)
        value = plain_cfg.get('Application Paths', 'to_auto_discover')
        assert_equal(value, '<AUTO-DISCOVERY>')
    finally:
        filerockclient.config.AUTO_DISCOVERY = old_discovery
        cleanup_configuration(test_cfg_dir)


def test_autodiscovery_fields_are_saved_if_modified():
    old_discovery = filerockclient.config.AUTO_DISCOVERY
    filerockclient.config.AUTO_DISCOVERY = {
        ('Application Paths', 'to_auto_discover'): lambda: 'auto_discovered'
    }
    test_cfg_dir = get_current_dir()
    create_config_file(test_cfg_dir, COMPLEX_CONFIG_FILE)
    try:
        cfg = ConfigManager(test_cfg_dir)
        cfg.load()
        cfg.set('Application Paths', 'to_auto_discover', 'something')
        cfg.write_to_file()
        plain_cfg = SafeConfigParser()
        with codecs.open(os.path.join(test_cfg_dir, CONFIG_FILE_NAME), encoding='utf-8_sig') as fp:
            plain_cfg.readfp(fp)
        value = plain_cfg.get('Application Paths', 'to_auto_discover')
        assert_equal(value, 'something')
    finally:
        filerockclient.config.AUTO_DISCOVERY = old_discovery
        cleanup_configuration(test_cfg_dir)


# Helper functions:

def get_current_dir():
    return os.path.dirname(os.path.abspath(__file__))


def create_config_file(config_dir, config_content):
    entries = []
    for section in config_content.keys():
        entries.append('[%s]' % section)
        for option, value in config_content[section].iteritems():
            entries.append('%s: %s' % (option, value))
    config_text = '\n'.join(entries)
    cfg_file = os.path.join(config_dir, CONFIG_FILE_NAME)
    with open(cfg_file, 'w') as fp:
        fp.write(config_text)


def exists_config_file(config_dir):
    cfg_file = os.path.join(config_dir, CONFIG_FILE_NAME)
    with open(cfg_file, 'r') as fp:
        return True


def cleanup_configuration(config_dir):
    delete_config_file(os.path.join(config_dir, CONFIG_FILE_NAME))
    delete_config_directory(os.path.join(config_dir, 'caches'))
    delete_config_directory(os.path.join(config_dir, 'temp'))


def delete_config_file(name):
    if os.path.exists(name):
        os.remove(name)


def delete_config_directory(name):
    if os.path.exists(name):
        os.rmdir(name)

########NEW FILE########
__FILENAME__ = abstract_cache_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the abstract_cache_test module.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import unittest
import os

from filerockclient.databases.abstract_cache import (AbstractCache,
                                                     WrongSchema,
                                                     WrongNumberOfParameters,
                                                     NonexistentKey,
                                                     UnknownColumn)

FILENAME = 'test.db'

DATABASE_NAME = 'test_cache'

SCHEMA = ['first int', 'second int', 'third int', 'fourth string']


class Test(unittest.TestCase):

    def setUp(self):
        self.cache = AbstractCache(FILENAME, DATABASE_NAME, SCHEMA, 'first')
        self.cache1 = AbstractCache('cache1.db', DATABASE_NAME, SCHEMA, 'first')
        self.cache2 = AbstractCache('cache2.db', DATABASE_NAME, SCHEMA, 'first')

    def tearDown(self):
        self.cache.destroy()
        self.cache1.destroy()
        self.cache2.destroy()
        assert not os.path.exists(FILENAME)
        assert not os.path.exists('cache1.db')
        assert not os.path.exists('cache2.db')

    def test_reload_with_wrong_schema(self):
        with self.assertRaises(WrongSchema):
            AbstractCache(FILENAME, DATABASE_NAME, SCHEMA[2:], 'first')

    def test_reload_and_destroy(self):
        newCache = AbstractCache(FILENAME, DATABASE_NAME, SCHEMA, 'first')
        newCache.destroy()
        self.assertFalse(os.path.exists(FILENAME))

    def test_set_wrong_key(self):
        with self.assertRaises(NonexistentKey):
            AbstractCache(FILENAME, DATABASE_NAME, SCHEMA, 'bad')

    def test_set_key(self):
        self.cache.key = 'second'

    def insert_right_number_columns(self):
        self.record = (1, 2, 3, 'foo')
        self.cache.update_record(*self.record)

    def test_update_new_record(self):
        self.insert_right_number_columns()
        self.assertEqual(self.cache.get_all_records(), [self.record])

    def test_update_existing_record(self):
        self.cache.update_record(1, 2, 3, 'foo')
        self.cache.update_record(1, 4, 5, 'bar')
        self.assertEqual(self.cache.get_all_records(), [(1, 4, 5, 'bar')])

    def test_update_record_wrong_number_columns(self):
        with self.assertRaises(WrongNumberOfParameters):
            self.cache.update_record(1, 2, 3, 'foo', '123')

    def test_update_fields_without_parameters(self):
        self.insert_right_number_columns()
        with self.assertRaises(WrongNumberOfParameters):
            self.cache.update_record_fields(1)

    def test_update_fields_with_too_many_parameters(self):
        self.insert_right_number_columns()
        with self.assertRaises(WrongNumberOfParameters):
            self.cache.update_record_fields(1,
                                            second=5,
                                            third=10,
                                            fourth='foo',
                                            fifth='alpha')

    def test_update_fields_with_nonexisting_column(self):
        self.insert_right_number_columns()
        with self.assertRaises(UnknownColumn):
            self.cache.update_record_fields(1,
                                            second=5,
                                            third=10,
                                            fifth='alpha')

    def test_update_fields_all_columns(self):
        self.insert_right_number_columns()
        self.cache.update_record_fields(1, second=5, third=10, fourth='alpha')
        self.assertIn((1, 5, 10, u'alpha'), self.cache.get_all_records())

    def test_update_fields_some_columns(self):
        self.insert_right_number_columns()
        self.cache.update_record_fields(1, fourth='alpha')
        self.assertIn((1, 2, 3, u'alpha'), self.cache.get_all_records())

    def test_get_non_existent_record(self):
        self.assertIsNone(self.cache.get_record(123))

    def test_delete_non_existent_record(self):
        self.cache.delete_record('foo')

    def test_delete_record(self):
        self.insert_right_number_columns()
        self.cache.delete_record(1)
        self.assertIsNone(self.cache.get_record(1))
        self.test_emptyness()

    def test_delete_all_records(self):
        self.insert_right_number_columns()
        record2 = (5, 6, 7, 'foo')
        self.cache.update_record(*record2)
        self.cache.delete_records([1, 5])
        self.test_emptyness()

    def test_delete_some_records(self):
        self.insert_right_number_columns()
        record2 = (5, 6, 7, 'foo')
        record3 = (9, 3, 1, 'bar')
        self.cache.update_record(*record2)
        self.cache.update_record(*record3)
        self.cache.delete_records([1, 5])
        self.assertEqual([(9, 3, 1, 'bar')], self.cache.get_all_records())

    def test_emptyness(self):
        self.assertEqual(self.cache.get_all_records(), [])

    def test_multi_cache_transaction(self):
        with self.cache1.transaction(self.cache2) as (c1, c2):
            c1.update_record(1, 2, 3, 'foo')
            c2.update_record(4, 5, 6, 'bar')
        self.assertEqual([(1, 2, 3, 'foo')], self.cache1.get_all_records())
        self.assertEqual([(4, 5, 6, 'bar')], self.cache2.get_all_records())

    def test_rollback_for_multi_cache_transaction(self):
        try:
            with self.cache1.transaction(self.cache2) as (c1, c2):
                c1.update_record(1, 2, 3, 'foo')
                c2.update_record(4, 5, 6, 'bar')
                raise Exception()
        except Exception:
            self.assertEqual([], self.cache1.get_all_records())
            self.assertEqual([], self.cache2.get_all_records())


if __name__ == "__main__":
    #import sys;sys.argv = ['', 'Test.testName']
    unittest.main()

########NEW FILE########
__FILENAME__ = hashes_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the hashes_test module.

----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from nose.tools import *
import os

from filerockclient.databases.hashes import HashesDB


def test_hash_insertion():
    db = HashesDB(get_fresh_filename('hashes.db'))
    db.add('ABC', 'DEF', user_accepted=False)
    print db.list()


# Helper functions:

def get_current_dir(current_module):
    return os.path.dirname(os.path.abspath(current_module))


def get_fresh_filename(name):
    data_dir = os.path.join(get_current_dir(__file__), 'test_data')
    if not os.path.exists(data_dir):
        os.mkdir(data_dir)
    pathname = os.path.join(data_dir, name)
    if os.path.exists(pathname):
        os.remove(pathname)
    return pathname

########NEW FILE########
__FILENAME__ = sqlite_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the sqlite_test module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from nose.tools import *
import os
import threading
import sqlite3

from filerockclient.databases.sqlite_driver import SQLiteDB


def test_object_creation():
    SQLiteDB('foobar')
    assert_true(True)


def test_file_gets_created_on_connect():
    filename = absolute_filename('test.db')
    db = SQLiteDB(filename)
    db._get_connection()
    assert_true(os.path.exists(filename))
    db.close()
    delete_file(filename)


def test_connection_is_singleton():
    filename = absolute_filename('test.db')
    db = SQLiteDB(filename)
    c1 = db._get_connection()
    c2 = db._get_connection()
    assert_true(c1 is c2)
    assert_equal(c1, c2)
    db.close()
    delete_file(filename)


def test_each_thread_has_its_own_connection():
    filename = absolute_filename('test.db')
    db = SQLiteDB(filename)
    connection1 = db._get_connection()

    def other_thread():
        connection2 = db._get_connection()
        assert_true(connection1 is connection1)
        assert_false(connection2 is connection1)
        assert_equal(connection1, connection1)
        assert_not_equal(connection2, connection1)
        db.close()

    try:
        t1 = threading.Thread(target=other_thread)
        t1.start()
        t1.join()
    finally:
        db.close()
        delete_file(filename)


def test_basic_insert_select_statements():
    db = create_onefield_database()
    try:
        db.execute("INSERT INTO test VALUES ('abc')")
        rows = db.query("SELECT * FROM test")
        assert_equal(len(rows), 1)
    finally:
        db.close()
        delete_file(db._filename)


def test_parametric_insert_select_statement():
    db = create_onefield_database()
    try:
        db.execute("INSERT INTO test VALUES (?)", ("abc",))
        rows = db.query("SELECT * FROM test WHERE field1 = ?", ("abc",))
        assert_equal(len(rows), 1)
        assert_equal(rows[0], ("abc",))
    finally:
        db.close()
        delete_file(db._filename)


def test_bulk_insert():
    db = create_onefield_database()
    try:
        values = []
        for n in xrange(0, 100000):
            values.append((n,))
        db.execute("INSERT INTO test VALUES (?)", values)
        rows = db.query("SELECT * FROM test")
        assert_equal(len(rows), 100000)
    finally:
        db.close()
        delete_file(db._filename)


def test_connection_dont_autocommit_by_default():
    db = create_onefield_database()
    try:
        db.execute("INSERT INTO test VALUES ('abc')")
        db.close()
        rows = db.query("SELECT * FROM test")
        assert_equal(len(rows), 0)
    finally:
        db.close()
        delete_file(db._filename)


def test_transaction_rollback():
    db = create_onefield_database()
    try:
        db.begin_transaction()
        db.execute("INSERT INTO test VALUES ('abc')")
        db.execute("INSERT INTO test VALUES ('def')")
        db.rollback_transaction()
        rows = db.query("SELECT * FROM test")
        assert_equal(len(rows), 0)
    finally:
        db.close()
        delete_file(db._filename)


def test_transaction_commit():
    db = create_onefield_database()
    try:
        db.begin_transaction()
        db.execute("INSERT INTO test VALUES ('abc')")
        db.execute("INSERT INTO test VALUES ('def')")
        db.commit_transaction()
        db.close()
        rows = db.query("SELECT * FROM test")
        assert_equal(len(rows), 2)
    finally:
        db.close()
        delete_file(db._filename)


def test_closing_implies_transaction_rollback():
    db = create_onefield_database()
    try:
        db.begin_transaction()
        db.execute("INSERT INTO test VALUES ('abc')")
        db.execute("INSERT INTO test VALUES ('def')")
        db.close()
        rows = db.query("SELECT * FROM test")
        assert_equal(len(rows), 0)
    finally:
        db.close()
        delete_file(db._filename)


def test_no_concurrent_transaction_allowed():
    db = create_onefield_database()

    def other_thread():
        db.begin_transaction()
        try:
            db.execute("INSERT INTO test values ('2')")
        except sqlite3.OperationalError as e:
            assert_equal(e.message, "database is locked")
        else:
            assert_true(False)
        finally:
            db.close()

    try:
        db.begin_transaction()
        db.execute("INSERT INTO test values ('1')")
        th1 = threading.Thread(target=other_thread)
        th1.start()
        th1.join()
    finally:
        db.close()
        delete_file(db._filename)


# Helper functions:

def create_onefield_database():
    filename = absolute_filename('test.db')
    delete_file(filename)
    db = SQLiteDB(filename)
    db.execute("CREATE TABLE test (field1 text)")
    return db


def absolute_filename(filename):
    curr_dir = get_current_dir()
    abs_filename = os.path.join(curr_dir, filename)
    return abs_filename


def get_current_dir():
    return os.path.dirname(os.path.abspath(__file__))


def delete_file(name):
    if os.path.exists(name):
        os.remove(name)

########NEW FILE########
__FILENAME__ = filesystemwatcher_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the filesystemwatcher_test module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

from nose.tools import *
from filerockclient.filesystemwatcher.FileSystemWatcherCrossPlatform import WareboxSnapshot
import random


def test_split_preservers_all_pathnames():
    snapshot = create_snapshot_with_different_filesizes()
    num_of_pathnames = len(snapshot.pathnames)
    snapshot._split_on_sizes = [0, 10, 100, 1000]
    chunks = snapshot.split_by_size()
    num_of_pathnames_after = sum(map(lambda x: len(x.pathnames), chunks))
    assert_equal(num_of_pathnames, num_of_pathnames_after)


def test_split_produces_correct_num_of_chunks():
    snapshot = create_snapshot_with_different_filesizes()
    snapshot._split_on_sizes = [0, 10, 100, 1000]
    chunks = snapshot.split_by_size()
    assert_equal(len(chunks), 4)


def test_split_doesnt_produce_empty_chunks():
    snapshot = create_snapshot_with_different_filesizes()
    # Note: the [80..90) class is empty
    snapshot._split_on_sizes = [0, 10, 80, 90, 100, 1000]
    chunks = snapshot.split_by_size()
    assert_equal(len(chunks), 5)


def test_split_produces_consistent_chunks():
    snapshot = create_snapshot_with_different_filesizes()
    snapshot._split_on_sizes = [0, 10, 100, 1000]
    chunks = snapshot.split_by_size()
    limits = (0, 10, 100, 1000, float('inf'))
    for i, chunk in enumerate(chunks):
        lower = limits[i]
        upper = limits[i + 1]
        for pathname in chunk.pathnames:
            assert_true(lower <= chunk.metadata[pathname]['size'] < upper)


def test_pathname_creations_are_detected():
    snapshot1 = create_snapshot_before_modification()
    snapshot2 = create_snapshot_after_modification()
    created_pathnames, _, _ = snapshot2.detect_modifications_from(snapshot1)
    assert_equal(len(created_pathnames), 1)
    assert_equal(created_pathnames[0], 'file0.txt')


def test_pathname_modifications_are_detected():
    snapshot1 = create_snapshot_before_modification()
    snapshot2 = create_snapshot_after_modification()
    _, modified_pathnames, _ = snapshot2.detect_modifications_from(snapshot1)
    assert_equal(len(modified_pathnames), 3)
    assert_in('file2.txt', modified_pathnames)
    assert_in('file3.txt', modified_pathnames)
    assert_in('file4.txt', modified_pathnames)


def test_pathname_copies_are_detected():
    snapshot1 = create_snapshot_before_modification()
    snapshot2 = create_snapshot_after_modification()
    _, _, copied_pathnames = snapshot2.detect_modifications_from(snapshot1)
    assert_equal(len(copied_pathnames), 6)
    copied_pathnames_ = dict(copied_pathnames)
    assert_in('file5.txt', copied_pathnames_)
    assert_in('file7.txt', copied_pathnames_)
    assert_in('file8.txt', copied_pathnames_)
    assert_in('file9.txt', copied_pathnames_)
    assert_in('fileA.txt', copied_pathnames_)
    assert_in('fileB.txt', copied_pathnames_)


def test_pathname_deletions_are_detected():
    snapshot1 = create_snapshot_before_modification()
    snapshot2 = create_snapshot_after_modification()
    deleted_pathnames = snapshot2.detect_deletions_from(snapshot1)
    assert_equal(len(deleted_pathnames), 2)
    assert_in('file6.txt', deleted_pathnames)
    assert_in('fileC.txt', deleted_pathnames)


def test_folders_are_not_copied():
    snapshot1 = create_snapshot_with_hierarchy_before_modification()
    snapshot2 = create_snapshot_with_hierarchy_after_modification()
    created_pathnames, _, _ = snapshot2.detect_modifications_from(snapshot1)
    assert_in('folder2/', created_pathnames)
    assert_in('folder3/', created_pathnames)
    assert_in('folder4/', created_pathnames)


def test_small_files_are_not_copied():
    snapshot1 = create_snapshot_with_hierarchy_before_modification()
    snapshot2 = create_snapshot_with_hierarchy_after_modification()
    first_copied_file =  ('folder3/file.txt', 'folder1/file.txt')  # size 2
    second_copied_file = ('folder4/file.txt', 'folder2/file.txt')  # size 3

    snapshot2._dont_copy_below_size = 2
    _, _, copied_pathnames = snapshot2.detect_modifications_from(snapshot1)
    assert_in(first_copied_file, copied_pathnames)
    assert_in(second_copied_file, copied_pathnames)

    snapshot2._dont_copy_below_size = 3
    _, _, copied_pathnames = snapshot2.detect_modifications_from(snapshot1)
    assert_not_in(first_copied_file, copied_pathnames)
    assert_in(second_copied_file, copied_pathnames)

    snapshot2._dont_copy_below_size = 4
    _, _, copied_pathnames = snapshot2.detect_modifications_from(snapshot1)
    assert_not_in(first_copied_file, copied_pathnames)
    assert_not_in(second_copied_file, copied_pathnames)


def test_pathnames_are_created_after_their_parents():
    snapshot1 = create_snapshot_with_hierarchy_before_modification()
    snapshot2 = create_snapshot_with_hierarchy_after_modification()
    created_pathnames, _, _ = snapshot2.detect_modifications_from(snapshot1)
    folder_position = created_pathnames.index('folder2/')
    file_position = created_pathnames.index('folder2/file.txt')
    assert_less(folder_position, file_position)


def test_pathnames_are_deleted_before_their_parents():
    snapshot1 = create_snapshot_with_hierarchy_before_modification()
    snapshot2 = create_snapshot_with_hierarchy_after_modification()
    snapshot1.pathnames.reverse()
    deleted_pathnames = snapshot2.detect_deletions_from(snapshot1)
    folder_position = deleted_pathnames.index('folder5/')
    file_position = deleted_pathnames.index('folder5/file.txt')
    assert_greater(folder_position, file_position)


def test_etag_is_recomputed_only_if_necessary():
    snapshot1 = create_snapshot_with_etags_before_modification()
    warebox_mock = EtagRecomputingWareboxMock()
    snapshot2 = create_snapshot_with_etags_after_modification(warebox_mock)
    snapshot2.update_etag(snapshot1)
    assert_equal(snapshot2.metadata['file1.txt']['etag'], 'RECOMPUTED')
    assert_equal(snapshot2.metadata['file2.txt']['etag'], 'LAST_ETAG_02')
    assert_equal(warebox_mock.recomputed_pathnames, ['file1.txt'])


''' Helper functions: '''

def create_snapshot_with_different_filesizes():
    metadata = {}
    metadata['file1.txt'] = { 'size': 1 }
    metadata['file2.txt'] = { 'size': 9 }
    metadata['file3.txt'] = { 'size': 10 }
    metadata['file4.txt'] = { 'size': 11 }
    metadata['file5.txt'] = { 'size': 99 }
    metadata['file6.txt'] = { 'size': 100 }
    metadata['file7.txt'] = { 'size': 101 }
    metadata['file8.txt'] = { 'size': 999 }
    metadata['file9.txt'] = { 'size': 1000 }
    metadata['fileA.txt'] = { 'size': 1001 }
    metadata['fileA.txt'] = { 'size': 9999 }
    metadata['dir1/'] = { 'size': 0 }
    metadata['dir1/file1.txt'] = { 'size': 1 }
    metadata['dir1/file1.txt'] = { 'size': 5 }
    metadata['dir1/file1.txt'] = { 'size': 9 }
    metadata['dir1/dir2/'] = { 'size': 0 }
    metadata['dir1/dir2/file1.txt'] = { 'size': 10 }
    metadata['dir1/dir2/file2.txt'] = { 'size': 50 }
    metadata['dir1/dir2/file3.txt'] = { 'size': 99 }
    metadata['dir1/dir2/dir3/'] = { 'size': 0 }
    metadata['dir1/dir2/dir3/file1.txt'] = { 'size': 100 }
    metadata['dir1/dir2/dir3/file2.txt'] = { 'size': 500 }
    metadata['dir1/dir2/dir3/file3.txt'] = { 'size': 999 }
    for pathname in metadata:
        metadata[pathname]['lmtime'] = 0
        metadata[pathname]['etag'] = ''
    pathnames = metadata.keys()
    random.shuffle(pathnames)
    snapshot = WareboxSnapshot(pathnames, metadata, None)
    return snapshot

def create_snapshot_before_modification():
    metadata = {}
    metadata['file1.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG01' }
    metadata['file2.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG02' }
    metadata['file3.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG03' }
    metadata['file4.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG0B' }
    metadata['file5.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG04' }
    metadata['file6.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG05' }
    metadata['file7.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG06' }
    metadata['fileC.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG06' }
    pathnames = sorted(metadata.keys())
    snapshot = WareboxSnapshot(pathnames, metadata, None)
    snapshot._dont_copy_below_size = 1
    return snapshot

def create_snapshot_after_modification():
    metadata = {}
    metadata['file0.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG00' } # new
    metadata['file1.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG01' } # unchanged
    metadata['file2.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG12' } # modified (etag)
    metadata['file3.txt'] = { 'size': 3, 'lmtime': 0, 'etag': 'ETAG13' } # modified (etag+size)
    metadata['file4.txt'] = { 'size': 2, 'lmtime': 0, 'etag': 'ETAG0B' } # modified (size)
    metadata['file5.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG02' } # modified but copyable from "before"
    # file6.txt deleted
    metadata['file7.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG12' } # modified but copyable from "after"
    # fileC.txt deleted
    metadata['file8.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG01' } # new but copyable from "before"
    metadata['file9.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG06' } # renamed
    metadata['fileA.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG12' } # new but copyable from "after"
    metadata['fileB.txt'] = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG00' } # new but copyable from "after"
    pathnames = sorted(metadata.keys())
    snapshot = WareboxSnapshot(pathnames, metadata, None)
    snapshot._dont_copy_below_size = 1
    return snapshot


def create_snapshot_with_hierarchy_before_modification():
    metadata = {}
    metadata['folder1/']          = { 'size': 0, 'lmtime': 0, 'etag': 'ETAG00' }
    metadata['folder1/file.txt']  = { 'size': 2, 'lmtime': 0, 'etag': 'ETAG01' }
    metadata['folder5/']          = { 'size': 0, 'lmtime': 0, 'etag': 'ETAG00' }
    metadata['folder5/file.txt']  = { 'size': 1, 'lmtime': 0, 'etag': 'ETAG05' }
    pathnames = sorted(metadata.keys())
    snapshot = WareboxSnapshot(pathnames, metadata, None)
    snapshot._dont_copy_below_size = 1
    return snapshot


def create_snapshot_with_hierarchy_after_modification():
    metadata = {}
    metadata['folder1/']          = {'size': 0, 'lmtime': 0, 'etag': 'ETAG00'}  # normal
    metadata['folder1/file.txt']  = {'size': 1, 'lmtime': 0, 'etag': 'ETAG01'}  # normal
    metadata['folder2/']          = {'size': 0, 'lmtime': 0, 'etag': 'ETAG00'}  # new
    metadata['folder2/file.txt']  = {'size': 3, 'lmtime': 0, 'etag': 'ETAG02'}  # new
    metadata['folder3/']          = {'size': 0, 'lmtime': 0, 'etag': 'ETAG00'}  # copied from last
    metadata['folder3/file.txt']  = {'size': 2, 'lmtime': 0, 'etag': 'ETAG01'}  # copied from last
    metadata['folder4/']          = {'size': 0, 'lmtime': 0, 'etag': 'ETAG00'}  # copied from curr
    metadata['folder4/file.txt']  = {'size': 3, 'lmtime': 0, 'etag': 'ETAG02'}  # copied from curr
    # folder5/ deleted
    # folder5/file.txt deleted
    pathnames = sorted(metadata.keys())
    snapshot = WareboxSnapshot(pathnames, metadata, None)
    snapshot._dont_copy_below_size = 1
    return snapshot


class EtagRecomputingWareboxMock(object):

    def __init__(self):
        self.recomputed_pathnames = []

    def compute_md5_hex(self, pathname):
        self.recomputed_pathnames.append(pathname)
        return 'RECOMPUTED'


def create_snapshot_with_etags_before_modification():
    metadata = {}
    metadata['file1.txt'] = {'size': 1, 'lmtime': 1, 'etag': 'LAST_ETAG_01'}
    metadata['file2.txt'] = {'size': 2, 'lmtime': 1, 'etag': 'LAST_ETAG_02'}
    pathnames = sorted(metadata.keys())
    snapshot = WareboxSnapshot(pathnames, metadata, None)
    snapshot._dont_copy_below_size = 1
    return snapshot

def create_snapshot_with_etags_after_modification(warebox_mock):
    metadata = {}
    metadata['file1.txt'] = {'size': 1, 'lmtime': 2, 'etag': 'WRONG_ETAG_01'}
    metadata['file2.txt'] = {'size': 2, 'lmtime': 1, 'etag': 'WRONG_ETAG_02'}
    pathnames = sorted(metadata.keys())
    snapshot = WareboxSnapshot(pathnames, metadata, warebox_mock)
    snapshot._dont_copy_below_size = 1
    return snapshot


########NEW FILE########
__FILENAME__ = multi_queue_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

"""
This is the multi_queue_test module.




----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import threading
import time
from nose.tools import *

from filerockclient.util.multi_queue import MultiQueue, Empty


def setup_module():
    import sys
    reload(sys.modules[__name__])


def test_noarg_multiqueue_works_like_standard_queue():
    queue = MultiQueue()
    queue.put(1)
    queue.put(2)
    value, _ = queue.get()
    assert_equal(value, 1)
    value, _ = queue.get()
    assert_equal(value, 2)


def test_access_specific_queue():
    queue = MultiQueue(['myqueue'])
    queue.put(1, 'myqueue')
    value, from_queue = queue.get(['myqueue'])
    assert_equal(value, 1)
    assert_equal(from_queue, 'myqueue')


def test_select_queue_to_get_from():
    queue = MultiQueue(['q1', 'q2'])
    queue.put(1, 'q1')
    queue.put(2, 'q2')
    value, from_queue = queue.get(['q2'])
    assert_equal(value, 2)
    assert_equal(from_queue, 'q2')


def test_get_from_many_queues():
    queue = MultiQueue(['q1', 'q2'])
    queue.put(1, 'q1')
    queue.put(2, 'q2')
    value, from_queue = queue.get(['q1', 'q2'])
    assert_equal(value, 1)
    assert_equal(from_queue, 'q1')
    value, from_queue = queue.get(['q1', 'q2'])
    assert_equal(value, 2)
    assert_equal(from_queue, 'q2')


@raises(KeyError)
def test_put_to_nonexistent_queue():
    queue = MultiQueue(['q1'])
    queue.put(1, 'q2')


@raises(KeyError)
def test_get_from_nonexistent_queue():
    queue = MultiQueue(['q1'])
    queue.get(['q1', 'q2'])


def test_blocked_if_selected_queue_is_empty():
    queue = MultiQueue(['q1', 'q2'])
    output = []

    def consumer():
        output.append(queue.get(['q2']))

    queue.put(1, 'q1')
    tconsumer = threading.Thread(target=consumer)
    tconsumer.start()
    time.sleep(0.5)
    assert_equal(len(output), 0)
    queue.put(2, 'q2')
    time.sleep(0.5)
    assert_equal(len(output), 1)
    value, from_queue = output[0]
    assert_equal(value, 2)
    assert_equal(from_queue, 'q2')
    tconsumer.join()


def test_bidirectional_put():
    queue = MultiQueue()
    queue.put(1)
    queue.append(2)
    queue.appendleft(3)
    assert_equal(queue.get(), (2, 'default'))
    assert_equal(queue.get(), (1, 'default'))
    assert_equal(queue.get(), (3, 'default'))


def test_bidirectional_get():
    queue = MultiQueue()
    queue.put(1)
    queue.put(2)
    queue.put(3)
    assert_equal(queue.get(), (1, 'default'))
    assert_equal(queue.popleft(), (3, 'default'))
    assert_equal(queue.pop(), (2, 'default'))


def test_queue_emptiness():
    queue = MultiQueue(['q1', 'q2'])
    assert_true(queue.empty(['q1']))
    assert_true(queue.empty(['q2']))
    assert_true(queue.empty(['q1', 'q2']))


def test_queue_non_emptiness():
    queue = MultiQueue(['q1', 'q2'])
    queue.put(1, 'q1')
    assert_false(queue.empty(['q1']))
    assert_true(queue.empty(['q2']))
    assert_false(queue.empty(['q1', 'q2']))


def test_clearing_empty_queue():
    queue = MultiQueue()
    queue.clear()
    assert_true(True)


def test_clearing_non_empty_queue():
    queue = MultiQueue(['q1', 'q2'])
    queue.put(1, 'q1')
    queue.clear(['q2'])
    assert_false(queue.empty(['q1']))
    queue.clear(['q1'])
    assert_true(queue.empty(['q1']))


def test_successful_nonblocking_get():
    queue = MultiQueue()
    queue.put(1)
    assert_equal(queue.get(blocking=False), (1, 'default'))


def test_unsuccessful_nonblocking_get():
    queue = MultiQueue()
    with assert_raises(Empty):
        queue.get(blocking=False)

########NEW FILE########
__FILENAME__ = platform_settings_linux_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#


"""
This is the PlatformSettingsLinux module test


----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""
import sys


if sys.platform.startswith("linux"):

    import unittest, os
    from filerockclient.osconfig.PlatformSettingsLinux import PlatformSettingsLinux

    class PlatformSettingsLinuxTest(unittest.TestCase):

        platform_settings = None
        xdg_config_fallback = "fallback"

        def setUp(self):
            self.platform_settings = PlatformSettingsLinux(executable_path="some_executable_path",
                                                        cmdline_args="some-cmdline_args")
            # Save original value os XDG_CONFIG_HOME (might be changed during tests)
            self.xdg_config_home = os.getenv(self.platform_settings.XDG_CONFIG_HOME_ENV)
            

        def tearDown(self):
            # Restore original value os XDG_CONFIG_HOME
            if self.xdg_config_home is not None:
                os.environ[self.platform_settings.XDG_CONFIG_HOME_ENV] = self.xdg_config_home


        def test_set_enable_autostart_with_env_var(self):

            # Override XDG_CONFIG_HOME_ENV
            os.environ[self.platform_settings.XDG_CONFIG_HOME_ENV] = os.path.abspath(".")
            self.platform_settings.DESKTOP_ENTRY_DIR = "../data"
            expected_desktop_file_path = self._get_exptected_desktop_filepath_with_env_var()
            try:
                self.platform_settings.set_autostart(True)
                self.assertTrue(os.path.exists(expected_desktop_file_path))
                desktop_file_content = self._read_desktop_file_to_dict(expected_desktop_file_path)
                self.assertEqual(desktop_file_content['Hidden'], "False")
            finally:
                if os.path.exists(expected_desktop_file_path):
                    os.unlink(expected_desktop_file_path)
                    os.rmdir(os.path.dirname(expected_desktop_file_path))

        def test_set_enable_autostart_twice_with_env_var(self):

            # Override XDG_CONFIG_HOME_ENV
            os.environ[self.platform_settings.XDG_CONFIG_HOME_ENV] = os.path.abspath(".")
            self.platform_settings.DESKTOP_ENTRY_DIR = "../data"
            expected_desktop_file_path = self._get_exptected_desktop_filepath_with_env_var()
            try:
                self.platform_settings.set_autostart(True)
                self.platform_settings.set_autostart(True)
                self.assertTrue(os.path.exists(expected_desktop_file_path))
                desktop_file_content = self._read_desktop_file_to_dict(expected_desktop_file_path)
                self.assertEqual(desktop_file_content['Hidden'], "False")
            finally:
                if os.path.exists(expected_desktop_file_path):
                    os.unlink(expected_desktop_file_path)
                    os.rmdir(os.path.dirname(expected_desktop_file_path))

        def test_set_disable_autostart_with_env_var(self):

            # Override XDG_CONFIG_HOME_ENV
            os.environ[self.platform_settings.XDG_CONFIG_HOME_ENV] = os.path.abspath(".")
            expected_desktop_file_path = self._get_exptected_desktop_filepath_with_env_var()

            if not os.path.exists(os.path.dirname(expected_desktop_file_path)):
                os.makedirs(os.path.dirname(expected_desktop_file_path))            
            with open(expected_desktop_file_path, "w") as fp:
                fp.write("")
            try:
                self.platform_settings.set_autostart(False)
                self.assertFalse(os.path.exists(expected_desktop_file_path))
            finally:
                if os.path.exists(expected_desktop_file_path):
                    os.unlink(expected_desktop_file_path)
                    os.rmdir(os.path.dirname(expected_desktop_file_path))

        def test_set_disable_autostart_twice_with_env_var(self):

            # Override XDG_CONFIG_HOME_ENV
            os.environ[self.platform_settings.XDG_CONFIG_HOME_ENV] = os.path.abspath(".")
            expected_desktop_file_path = self._get_exptected_desktop_filepath_with_env_var()
            if not os.path.exists(os.path.dirname(expected_desktop_file_path)):
                os.makedirs(os.path.dirname(expected_desktop_file_path))   
            with open(expected_desktop_file_path, "w") as fp:
                fp.write("")
            try:
                self.platform_settings.set_autostart(False)
                self.platform_settings.set_autostart(False)
                self.assertFalse(os.path.exists(expected_desktop_file_path))
            finally:
                if os.path.exists(expected_desktop_file_path):
                    os.unlink(expected_desktop_file_path)
                    os.rmdir(os.path.dirname(expected_desktop_file_path))


        def test_set_enable_autostart_without_env_var(self):

            # Override XDG_CONFIG_HOME_FALLBACK 
            self.platform_settings.XDG_CONFIG_HOME_FALLBACK = self.xdg_config_fallback
            # Make sure XDG_CONFIG_HOME is not set
            del os.environ[self.platform_settings.XDG_CONFIG_HOME_ENV]

            self.platform_settings.DESKTOP_ENTRY_DIR = "../data"
            expected_desktop_file_path = self._get_exptected_desktop_filepath_without_env_var()
            try:
                self.platform_settings.set_autostart(True)
                self.assertTrue(os.path.exists(expected_desktop_file_path))
            finally:
                if os.path.exists(expected_desktop_file_path):
                    os.unlink(expected_desktop_file_path)
                    os.rmdir(os.path.dirname(expected_desktop_file_path))

        def test_set_disable_autostart_without_env_var(self):

            # Override XDG_CONFIG_HOME_FALLBACK 
            self.platform_settings.XDG_CONFIG_HOME_FALLBACK = self.xdg_config_fallback
            # Make sure XDG_CONFIG_HOME is not set
            del os.environ[self.platform_settings.XDG_CONFIG_HOME_ENV]

            self.platform_settings.DESKTOP_ENTRY_DIR = "../data"
            expected_desktop_file_path = self._get_exptected_desktop_filepath_without_env_var()

            if not os.path.exists(os.path.dirname(expected_desktop_file_path)):
                os.makedirs(os.path.dirname(expected_desktop_file_path))   
            with open(expected_desktop_file_path, "w") as fp:
                fp.write("")

            try:
                self.platform_settings.set_autostart(False)
                self.assertFalse(os.path.exists(expected_desktop_file_path))
            finally:
                if os.path.exists(expected_desktop_file_path):
                    os.unlink(expected_desktop_file_path)
                    os.rmdir(os.path.dirname(expected_desktop_file_path))

        def test_whitelist_tray_icon(self):
            # TODO: to be done
            pass

        def test_whitelist_tray_icon_already_whitelisted(self):
            # TODO: to be done
            pass

        def test_is_systray_icon_whitelisted(self):
            # TODO: to be done
            pass


        def _get_exptected_desktop_filepath_with_env_var(self):
            return os.path.abspath(
                                    os.path.join(
                                            os.getenv(self.platform_settings.XDG_CONFIG_HOME_ENV),
                                            "autostart",
                                            self.platform_settings.DESKTOP_ENTRY_FILENAME
                                            )
                                    )

        def _get_exptected_desktop_filepath_without_env_var(self):
            return os.path.abspath(
                                    os.path.join(
                                            self.xdg_config_fallback,
                                            "autostart",
                                            self.platform_settings.DESKTOP_ENTRY_FILENAME
                                            )
                                    )

        def _read_desktop_file_to_dict(self,path):
            """
            Read .desktop file @path, and return a dict with its
            values
            """
            result = {}
            with open(path,"r") as fp:
                while True:
                    line = fp.readline()
                    if not len(line):
                        break
                    split = line.split("=")
                    if len(split) == 2:
                        result[split[0]] = split[1].strip()
            return result

else:
    print "Skipping PlatformSettingsLinux tests..."

########NEW FILE########
__FILENAME__ = platform_settings_osx_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#


"""
This is the PlatformSettingsOSX module test


----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""
import sys


if sys.platform == "darwin":
    from filerockclient.osconfig.PlatformSettingsOSX import PlatformSettingsOSX
    import unittest, os

    class PlatformSettingsOSXTest(unittest.TestCase):

        platform_settings = None
    
        def setUp(self):
            self.platform_settings = PlatformSettingsOSX(executable_path="some_executable_path",
                                                        cmdline_args="some-cmdline_args")


        def test_set_enable_autostart(self):
            # Set path for launch agent to current dir
            self.platform_settings.LAUNCH_AGENTS_PATH = "."
            exptected_launch_agent_pathname = os.path.join(self.platform_settings.LAUNCH_AGENTS_PATH, self.platform_settings.LAUNCH_AGENT_PLIST_FILENAME)
            try:
                self.platform_settings.set_autostart(True)
                self.assertTrue(os.path.exists(exptected_launch_agent_pathname))
            finally:
                os.unlink(exptected_launch_agent_pathname)

        def test_set_twice_enable_autostart(self):
            # Set path for launch agent to current dir
            self.platform_settings.LAUNCH_AGENTS_PATH = "."
            exptected_launch_agent_pathname = os.path.join(self.platform_settings.LAUNCH_AGENTS_PATH, self.platform_settings.LAUNCH_AGENT_PLIST_FILENAME)
            try:
                self.platform_settings.set_autostart(True)
                self.platform_settings.set_autostart(True)
                self.assertTrue(os.path.exists(exptected_launch_agent_pathname))
            finally:
                os.unlink(exptected_launch_agent_pathname)

        def test_set_enable_autostart_without_launch_agent_folder(self):
            self.platform_settings.LAUNCH_AGENTS_PATH = "./non-existing-path"

            # Just to be sure...
            if os.path.exists(self.platform_settings.LAUNCH_AGENTS_PATH):
                if os.path.isdir(self.platform_settings.LAUNCH_AGENTS_PATH):
                    import shutil
                    shutil.rmtree(self.platform_settings.LAUNCH_AGENTS_PATH)
                else:
                    os.unlink(self.platform_settings.LAUNCH_AGENTS_PATH)

            exptected_launch_agent_pathname = os.path.join(self.platform_settings.LAUNCH_AGENTS_PATH, self.platform_settings.LAUNCH_AGENT_PLIST_FILENAME)

            try:
                self.platform_settings.set_autostart(True)
                self.assertTrue(os.path.exists(exptected_launch_agent_pathname))
            finally:
                os.unlink(exptected_launch_agent_pathname)
                os.rmdir(self.platform_settings.LAUNCH_AGENTS_PATH)


        def test_set_disable_autostart(self):
            # Set path for launch agent to current dir
            self.platform_settings.LAUNCH_AGENTS_PATH = "."
            exptected_launch_agent_pathname = os.path.join(self.platform_settings.LAUNCH_AGENTS_PATH, self.platform_settings.LAUNCH_AGENT_PLIST_FILENAME)
            self.platform_settings.set_autostart(False)
            self.assertTrue(not os.path.exists(exptected_launch_agent_pathname))

        def test_set_disable_autostart_twice(self):
            # Set path for launch agent to current dir
            self.platform_settings.LAUNCH_AGENTS_PATH = "."
            exptected_launch_agent_pathname = os.path.join(self.platform_settings.LAUNCH_AGENTS_PATH, self.platform_settings.LAUNCH_AGENT_PLIST_FILENAME)
            self.platform_settings.set_autostart(False)
            self.platform_settings.set_autostart(False)
            self.assertTrue(not os.path.exists(exptected_launch_agent_pathname))

        def test_set_disable_autostart_with_existing_agent(self):
            # Set path for launch agent to current dir
            self.platform_settings.LAUNCH_AGENTS_PATH = "."
            exptected_launch_agent_pathname = os.path.join(self.platform_settings.LAUNCH_AGENTS_PATH, self.platform_settings.LAUNCH_AGENT_PLIST_FILENAME)
            try:
                with open(exptected_launch_agent_pathname, "w") as fp:
                    fp.write("")
                self.platform_settings.set_autostart(False)
                self.assertTrue(not os.path.exists(exptected_launch_agent_pathname))
            finally:
                if os.path.exists(exptected_launch_agent_pathname):
                    os.unlink(exptected_launch_agent_pathname)


        def test_is_systray_icon_whitelisted(self):
            self.assertTrue(self.platform_settings.is_systray_icon_whitelisted)
else:
    print "Skipping PlatformSettingsOSX tests..."
########NEW FILE########
__FILENAME__ = platform_settings_win_test
# -*- coding: ascii -*-
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#


"""
This is the PlatformSettingsWindows module test


----

This module is part of the FileRock Client.

Copyright (C) 2012 - Heyware s.r.l.

FileRock Client is licensed under GPLv3 License.

"""

import sys


if sys.platform.startswith("win"):

    from filerockclient.osconfig.PlatformSettingsWindows import PlatformSettingsWindows
    import unittest, os, _winreg

    class PlatformSettingsWindowsTest(unittest.TestCase):

        platform_settings = None

        def setUp(self):
            self.platform_settings = PlatformSettingsWindows(executable_path="some_executable_path",
                                                        cmdline_args="some-cmdline_args")
            # Override AUTORUN_APPLICATION_NAME to avoid interferences with installed clients
            self.platform_settings.AUTORUN_APPLICATION_NAME = r"FileRock Client Unittest"


        def _create_registry_entry(self, key, value):


            with self._create_key_handle(key) as key_handle:
                _winreg.SetValueEx( key_handle,
                                    key,
                                    0,
                                    _winreg.REG_SZ,
                                    value
                                    )
                

        def _create_key_handle(self, key):
            return _winreg.CreateKey(_winreg.HKEY_CURRENT_USER,
                                    key
                                    )

        def _open_key_handle(self, key):
            """
            Open an handle for given registry HKCU\@key
            """
            return _winreg.OpenKey(_winreg.HKEY_CURRENT_USER,
                                    key,
                                    0,
                                    _winreg.KEY_ALL_ACCESS
                                    )

        def _registry_entry_exists(self, key, value):
            """
            Check if autostart entry exists within Windows registry.
            @return True/False
            """

            with self._open_key_handle(key) as key_handle:
                try:
                    _winreg.QueryValueEx(   key_handle,
                                            value
                                        )
                except WindowsError as e:
                    return False
                else:
                    return True

        def _delete_registry_entry(self, key, value):
            """
            Deletes autostart entry for current user within Windows registry
            """
            
            with self._open_key_handle(key) as key_handle:
                    _winreg.DeleteValue(key_handle,
                                        value
                                        )


        def test_set_enable_autostart(self):
            try:
                self.platform_settings.set_autostart(True)
                self.assertTrue(self._registry_entry_exists(
                                            self.platform_settings.AUTORUN_KEY,
                                            self.platform_settings.AUTORUN_APPLICATION_NAME
                                                            )
                                )
            finally:
                self._delete_registry_entry(self.platform_settings.AUTORUN_KEY,
                                            self.platform_settings.AUTORUN_APPLICATION_NAME)

        def test_set_enable_autostart_twice(self):
            try:
                self.platform_settings.set_autostart(True)
                self.platform_settings.set_autostart(True)
                self.assertTrue(self._registry_entry_exists(
                                            self.platform_settings.AUTORUN_KEY,
                                            self.platform_settings.AUTORUN_APPLICATION_NAME
                                                            )
                                )
            finally:
                self._delete_registry_entry(self.platform_settings.AUTORUN_KEY,
                                            self.platform_settings.AUTORUN_APPLICATION_NAME)

        def test_set_disable_autostart(self):

            with self._create_key_handle(self.platform_settings.AUTORUN_KEY) as key_handle:
                _winreg.SetValueEx( key_handle,
                                    self.platform_settings.AUTORUN_APPLICATION_NAME,
                                    0,
                                    _winreg.REG_SZ,
                                    self.platform_settings.AUTORUN_APPLICATION_PATH
                                    )
            
            try:
                self.platform_settings.set_autostart(False)
                self.assertFalse(self._registry_entry_exists(
                                            self.platform_settings.AUTORUN_KEY,
                                            self.platform_settings.AUTORUN_APPLICATION_NAME
                                                            )
                                )
            except Exception:
                self._delete_registry_entry(self.platform_settings.AUTORUN_KEY,
                                            self.platform_settings.AUTORUN_APPLICATION_NAME)
                raise

        def test_set_disable_autostart_twice(self):

            with self._create_key_handle(self.platform_settings.AUTORUN_KEY) as key_handle:
                _winreg.SetValueEx( key_handle,
                                    self.platform_settings.AUTORUN_APPLICATION_NAME,
                                    0,
                                    _winreg.REG_SZ,
                                    self.platform_settings.AUTORUN_APPLICATION_PATH
                                    )

            try:
                self.platform_settings.set_autostart(False)
                self.platform_settings.set_autostart(False)
                self.assertFalse(self._registry_entry_exists(
                                            self.platform_settings.AUTORUN_KEY,
                                            self.platform_settings.AUTORUN_APPLICATION_NAME
                                                            )
                                )
            except Exception:
                self._delete_registry_entry(self.platform_settings.AUTORUN_KEY,
                                            self.platform_settings.AUTORUN_APPLICATION_NAME)
                raise

        def test_is_systray_icon_whitelisted(self):
            self.assertTrue(self.platform_settings.is_systray_icon_whitelisted)
else:
    print "Skipping PlatformSettingsWindows tests..."

########NEW FILE########
__FILENAME__ = handlers_test
#  ______ _ _      _____            _       _____ _ _            _
# |  ____(_) |    |  __ \          | |     / ____| (_)          | |
# | |__   _| | ___| |__) |___   ___| | __ | |    | |_  ___ _ __ | |_
# |  __| | | |/ _ \  _  // _ \ / __| |/ / | |    | | |/ _ \ '_ \| __|
# | |    | | |  __/ | \ \ (_) | (__|   <  | |____| | |  __/ | | | |_
# |_|    |_|_|\___|_|  \_\___/ \___|_|\_\  \_____|_|_|\___|_| |_|\__|
#
# Copyright (C) 2012 Heyware s.r.l.
#
# This file is part of FileRock Client.
#
# FileRock Client is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# FileRock Client is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with FileRock Client. If not, see <http://www.gnu.org/licenses/>.
#

import sys
if not sys.platform.startswith("win"):
    print "SKIPPED %s since Windows is needed" % __name__
else:

    from nose.tools import assert_equal, assert_true, assert_false

    from filerockclient.interfaces import PStatuses
    from filerockclient.ui.shellextension.win32.driver.shellext_pb2 import Status
    from filerockclient.ui.shellextension.win32.driver.handlers import is_encrypted, transcode_status


    def test_detects_encrypted_files_by_prefix():
        assert_true(is_encrypted(u'encrypted/'))
        assert_true(is_encrypted(u'encrypted/bar.txt'))

        assert_false(is_encrypted(u'foo/'))
        assert_false(is_encrypted(u'foo/bar.txt'))


    def test_transcodes_aligned_status():
        assert_equal(transcode_status(PStatuses.ALIGNED, False), Status.OK_CLEARTEXT)
        assert_equal(transcode_status(PStatuses.ALIGNED, True), Status.OK_ENCRYPTED)


    def test_transcodes_brokenproof_status():
        assert_equal(transcode_status(PStatuses.BROKENPROOF, False),
            Status.INTEGRITY_KO)
        assert_equal(transcode_status(PStatuses.BROKENPROOF, True),
            Status.INTEGRITY_KO)


    def test_transcodes_unknown_status():
        assert_equal(transcode_status(PStatuses.UNKNOWN, False), Status.STILL_UNSEEN)
        assert_equal(transcode_status(PStatuses.UNKNOWN, True), Status.STILL_UNSEEN)


    def test_transcodes_syncronizing_statuses():
        for pstatus in (PStatuses.TOBEUPLOADED, PStatuses.UPLOADING, PStatuses.UPLOADED,
                        PStatuses.TOBEDOWNLOADED, PStatuses.DOWNLOADING,
                        PStatuses.RENAMETOBESENT, PStatuses.RENAMESENT,
                        PStatuses.DELETETOBESENT, PStatuses.DELETESENT):
            assert_equal(transcode_status(pstatus, False), Status.SYNCRONIZING)
            assert_equal(transcode_status(pstatus, True), Status.SYNCRONIZING)

########NEW FILE########
